计算机系统由“硬件”和“软件”两大部分组成。所谓“硬件”，是指计算机的实体部分，它由看得见摸得着的各种电子元器件，各类光、电、机设备的实物组成，如主机、外部设备等。所谓“软件”，它看不见摸不着，由人们事先编制的具有各类特殊功能的程序组成。通常把这些程序寄寓于各类媒体(如RAM、ROM、磁带、磁盘、光盘，甚至纸带等)，它们通常存放在计算机的主存或辅存内。由于“软件”的发展不仅可以充分发挥机器的“硬件”功能，提高机器的工作效率，而且已经发展到能局部模拟人类的思维活动，因此在整个计算机系统内，“软件”的地位和作用已经成为评价计算机系统性能好坏的重要标志。当然，“软件”性能的发挥也必须依托“硬件”的支撑。因此，概括而言，计算机性能的好坏取决于“软”“硬”件功能的总和。计算机的软件通常又可以分为两大类：系统软件和应用软件。系统软件又称为系统程序，主要用来管理整个计算机系统，监视服务，使系统资源得到合理调度，高效运行。它包括：标准程序库、语言处理程序(如将汇编语言翻译成机器语言的汇编程序或将高级语言翻译成机器语言的编译程序)、操作系统(如批处理系统、分时系统、实时系统)、服务程序(如诊断程序、调试程序、连接程序等)、数据库管理系统、网络软件等。应用软件又称为应用程序，它是用户根据任务需要所编制的各种程序，如科学计算程序、数据处理程序、过程控制程序、事务管理程序等。现代计算机的解题过程如下。通常由用户用高级语言编写程序(称为源程序)，然后将它和数据一起送入计算机内，再由计算机将其翻译成机器能识别的机器语言程序(称为目标程序)，机器自动运行该机器语言程序，并将计算结果输出。其过程如图1.1所示。实际上，早期的计算机只有机器语言(用0、1代码表示的语言)，用户必须用二进制代码(0、1)来编写程序(即机器语言程序)。这就要求程序员对他们所使用的计算机硬件及其指令系统十分熟悉，编写程序难度很大，操作过程也极容易出错。但用户编写的机器语言程序可以直接在机器上执行。直接执行机器语言的机器称为实际机器M₁，如图1.2所示。实际机器M₁机器语言程序直接在M₁上执行(机器语言程序)20世纪50年代开始出现了符号式的程序设计语言，即汇编语言。它用符号ADD、SUB、MUL、DIV等分别表示加、减、乘、除等操作，并用符号表示指令或数据所在存储单元的地址，使程序员可以不再使用繁杂而又易错的二进制代码来编写程序。但是，实际上没有一种机器能直接识别这种汇编语言程序，必须先将汇编语言程序翻译成机器语言程序，然后才能被机器接受并自动运行。这个翻译过程是由机器系统软件中的汇编程序来完成的。如果把具有翻译功能的汇编程序的计算机看作一台机器M₂,，那么，可以认为M₂在M₁之上，用户可以利用M₂的翻译功能直接向M₂输入汇编语言程序，而M₂又会将翻译后的机器语言程序输入给M₁,M₁执行后将结果输出。因此，M₂并不是一台实际机器，它只是人们感到存在的一台具有翻译功能的机器，称这类机器为虚拟机。这样，整个计算机系统便具有两级层次结构，如图1.3所示。尽管有了虚拟机M₂使用户编程更为方便，但从本质上看，汇编语言仍是一种面向实际机器的语言，它的每一条语句都与机器语言的某一条语句(0、1代码)一一对应。因此，使用汇编语言编写程序时，仍要求程序员对实际机器M₁的内部组成和指令系统非常熟悉，也就是说，程序员必须经过专门的训练，否则是无法操作计算机的。另一方面，由于汇编语言摆脱不了实际机器的指令系统，因此，汇编语言没有通用性，每台机器必须有一种与之相对应的汇编语言。这使得程序员要掌握不同机器的指令系统，不利于计算机的广泛应用和发展。20世纪60年代开始先后出现了各种面向问题的高级语言,如FORTRAN、BASIC、Pascal、C等。这类高级语言对问题的描述十分接近人们的习惯，并且还具有较强的通用性。程序员完全不必了解、掌握实际机器M₁的机型、内部的具体组成及其指令系统，只要掌握这类高级语言的语法和语义，便可直接用这种高级语言来编程，这给程序员带来了极大的方便。当然，机器M₁本身是不能识别高级语言的，因此，在进入机器M₁运行前，必须先将高级语言程序翻译成汇编语言程序(或其他中间语言程序)，然后再将其翻译成机器语言程序；也可以将高级语言程序直接翻译成机器语言程序。这些工作都是由虚拟机器M₃来完成的，对程序员而言，他们并不知道这个翻译过程。由此又可得出具有三级层次结构的计算机系统，如图1.4所示。通常，将高级语言程序翻译成机器语言程序的软件称为翻译程序。翻译程序有两种：一种是编译程序，另一种是解释程序。编译程序是将用户编写的高级语言程序(源程序)的全部语句一次全部翻译成机器语言程序，而后再执行机器语言程序。因此，只要源程序不变，就无须再次进行翻译。例如，FORTRAN、Pascal等语言就是用编译程序来完成翻译的。解释程序是将源程序的一条语句翻译成对应于机器语言的一条语句，并且立即执行这条语句，接着翻译源程序的下一条语句，并执行这条语句，如此重复直至完成源程序的全部翻译任务。它的特点是翻译一次执行一次，即使下一次重复执行该语句时，也必须重新翻译。例如，BASIC语言的翻译就有解释程序和编译程序两种。从上述介绍中不难看出，由于软件的发展，使实际机器M₁向上延伸构成了各级虚拟机器。同理，机器M₁内部也可向下延伸而形成下一级的微程序机器M₀。机器M₀是直接将机器M₁中的每一条机器指令翻译成一组微指令，即构成一个微程序。机器M。每执行完对应于一条机器指令的一个微程序后，便由机器M₁中的下一条机器指令使机器M₀自动进入与其相对应的另一个微程序的执行。由此可见，微程序机器M₀可看作是对实际机器M₁的分解，即用M₀的微程序解释并执行M₁的每一条机器指令(有关微程序机器的介绍，详见第10章)。由于机器M₀也是实际机器，因此，为了区别于M₁,通常又将M₁称为传统机器，将M₀称为微程序机器。这样又可认为计算机系统具有四级层次结构，如图1.5所示。在上述四级层次结构的系统中，实际上在实际机器M₁与虚拟机器M₂之间还有一级虚拟机器，它是由操作系统软件构成的。操作系统提供了在汇编语言和高级语言的使用和实现过程中所需的某些基本操作，还起到控制并管理计算机系统全部硬件和软件资源的作用，为用户使用计算机系统提供极为方便的条件。操作系统的功能是通过其控制语言来实现的。图1.6描绘了一个常见的五级计算机系统的层次结构。虚拟机器M₄还可向上延伸，构成应用语言虚拟机。这一级是为使计算机满足某种用途而专门设计的，该级所用的语言是各种面向问题的应用语言，如用于人工智能和计算机设计等方面的语言。应用语言编写的程序一般由应用程序包翻译到虚拟机器M₄上。从计算机系统的多级层次结构来看，可以将硬件研究的主要对象归结为传统机器M₁和微程序机器M₀。软件的研究对象主要是操作系统级以上的各级虚拟机。值得指出的是，软硬件交界界面的划分并不是一成不变的。随着超大规模集成电路技术的不断发展，一部分软件功能将由硬件来实现，例如，目前操作系统已实现了部分固化(把软件永恒地存于只读存储器中)，称为固件等。可见，软硬件交界界面变化的趋势正沿着图1.6所示的方向向上发展。本书主要讨论传统机器M₁和微程序机器M₀的组成原理及设计思想，其他各级虚拟机的内容均由相应的软件课程讲授。在学习计算机组成时，应当注意如何区别计算机体系结构与计算机组成这两个基本概念。计算机体系结构是指那些能够被程序员所见到的计算机系统的属性，即概念性的结构与功能特性。计算机系统的属性通常是指用机器语言编程的程序员(也包括汇编语言程序设计者和汇编程序设计者)所看到的传统机器的属性，包括指令集、数据类型、存储器寻址技术、I/O机理等，大都属于抽象的属性。由于计算机系统具有多级层次结构，因此，站在不同层次上编程的程序员所看到的计算机属性也是各不相同的。例如，用高级语言编程的程序员可以把IBMPC与RS6000两种机器看成是同一属性的机器。可是，对使用汇编语言编程的程序员来说，IBMPC与RS6000是两种截然不同的机器。因为程序员所看到的这两种机器的属性，如指令集、数据类型、寻址技术等，都完全不同，因此，认为这两种机器的结构是各不相同的。计算机组成是指如何实现计算机体系结构所体现的属性，它包含了许多对程序员来说是透明的硬件细节。例如，指令系统体现了机器的属性，这是属于计算机结构的问题。但指令的实现，即如何取指令、分析指令、取操作数、运算、送结果等，这些都属于计算机组成问题。因此，当两台机器指令系统相同时，只能认为它们具有相同的结构。至于这两台机器如何实现其指令的功能，完全可以不同，则它们的组成方式是不同的。例如，一台机器是否具备乘法指令的功能，这是一个结构问题，可是，实现乘法指令采用什么方式，则是一个组成问题。实现乘法指令可以采用一个专门的乘法电路，也可以采用连续相加的加法电路来实现，这两者的区别就是计算机组成的区别。究竟应该采用哪种方式来组成计算机，要考虑到各种因素，如乘法指令使用的频度、两种方法的运行速度、两种电路的体积、价格、可靠性等。不论是过去还是现在，区分计算机结构与计算机组成这两个概念都是十分重要的。例如，许多计算机制造商向用户提供一系列体系结构相同的计算机，而它们的组成却有相当大的差别，即使是同一系列不同型号的机器，其价格和性能也是有极大差异的。因此，只知其结构，不知其组成，就选不好性能价格比最合适的机器。此外，一种机器的体系结构可能维持许多年，但机器的组成却会随着计算机技术的发展而不断变化。例如，1970年首次推出了IBMSystem/370结构，它包含了许多机型。一般需求的用户可以买价格便宜的低速机型；对需求高的用户，可以买一台升级的价格稍贵的机型，而不必抛弃原来已开发的软件。许多年来，不断推出性能更高、价格更低的机型，新机型总归保留着原来机器的结构，使用户的软件投资不致浪费。本书主要研究计算机的组成，有关计算机体系结构的内容将在“计算机体系结构”课程中讲述。1945年,数学家冯·诺依曼(vonNeumann)在研究EDVAC机时提出了“存储程序”的概念。以此概念为基础的各类计算机通称为冯·诺依曼机。它的特点可归结如下：·计算机由运算器、存储器、控制器、输入设备和输出设备五大部件组成。·指令和数据以同等地位存放于存储器内，并可按地址寻访。●指令和数据均用二进制数表示。·指令由操作码和地址码组成，操作码用来表示操作的性质，地址码用来表示操作数在存储器中的位置。·指令在存储器内按顺序存放。通常，指令是顺序执行的，在特定条件下，可根据运算结果或根据设定的条件改变执行顺序。•机器以运算器为中心，输入输出设备与存储器间的数据传送通过运算器完成。典型的冯·诺依曼计算机是以运算器为中心的，如图1.7所示。现代的计算机已转化为以存储器为中心，如图1.8所示。图中各部件的功能如下：·运算器用来完成算术运算和逻辑运算，并将运算的中间结果暂存在运算器内。●存储器用来存放数据和程序。·控制器用来控制、指挥程序和数据的输入、运行以及处理运算结果。·输入设备用来将人们熟悉的信息形式转换为机器能识别的信息形式，常见的有键盘、鼠标等。·输出设备可将机器运算结果转换为人们熟悉的信息形式，如打印机输出、显示器输出等。计算机的五大部件(又称五大子系统)在控制器的统一指挥下，有条不紊地自动工作。由于运算器和控制器在逻辑关系和电路结构上联系十分紧密，尤其在大规模集成电路制作工艺出现后，这两大部件往往集成在同一芯片上，因此，通常将它们合起来统称为中央处理器(CentralProcessingUnit,CPU)。把输入设备与输出设备简称为I/O设备(Input/OutputEquip-ment)。这样,现代计算机可认为由三大部分组成:CPU、I/O设备及主存储器(MainMemory,MM),如图1.9所示。CPU与主存储器合起来又可称为主机，I/O设备又可称为外部设备。图1.9中的主存储器是存储器子系统中的一类，用来存放程序和数据，可以直接与CPU交换信息。另一类称为辅助存储器，简称辅存，又称外存，其功能参阅4.4节。算术逻辑单元(ArithmeticLogicUnit,ALU)简称算逻部件,用来完成算术逻辑运算。控制单元(ControlUnit，CU)用来解释存储器中的指令，并发出各种操作命令来执行指令。ALU和CU是CPU的核心部件。I/O设备也受CU控制，用来完成相应的输入、输出操作。可见，计算机有条不紊地自动工作都是在控制器统一指挥下完成的。用计算机解决一个实际问题通常包含两大步骤。一个是上机前的各种准备，另一个是上机运行。1.上机前的准备在许多科学技术的实际问题中，往往会遇到许多复杂的数学方程组，而数字计算机通常只能执行加、减、乘、除四则运算，这就要求在上机解题前，先由人工完成一些必要的准备工作。这些工作大致可归纳为：建立数学模型、确定计算方法和编制解题程序3个步骤。(1)建立数学模型有许多科技问题很难直接用物理模型来模拟被研究对象的变化规律，如地球大气环流、原子反应堆的核裂变过程、航天飞行速度对飞行器的影响等。不过，通过大量的实验和分析，总能找到一系列反映研究对象变化规律的数学方程组。通常，将这类方程组称为被研究对象变化规律的数学模型。一旦建立了数学模型，研究对象的变化规律就变成了解一系列方程组的数学问题，这便可通过计算机来求解。因此，建立数学模型是用计算机解题的第一步。(2)确定计算方法由于数学模型中的数学方程式往往是很复杂的，欲将其变成适合计算机运算的加、减、乘、除四则运算，还必须确定对应的计算方法。例如，欲求sinx的值，只能采用近似计算方法，用四则运算的式子来求得(因计算机内部没第1章计算机系统概论11有直接完成三角函数运算的部件)。又如，计算机不能直接求解开方x，但可用迭代公式：通过多次迭代，便可求得相应精度的\sqrt{x}值。(3)编制解题程序程序是适合于机器运算的全部步骤，编制解题程序就是将运算步骤用一一对应的机器指令描述。将上述运算步骤写成某计算机一一对应的机器指令，就完成了运算程序的编写。设某机的指令字长为16位，其中操作码占6位，地址码占10位,如图1.10所示。操作码表示机器所执行的各种操作，如取数、存数、加、减、乘、除、停机、打印等。地址码表示参加运算的数在存储器内的位置。机器指令的操作码和地址码都采用0、1代码的组合来表示。表1.1列出了某机与上例有关的各条机器指令的操作码及其操作性质的对应关系。操作码操作性质具体内容000001取数将指令地址码指示的存储单元中的操作数取到运算器的累加器ACC中000010存数将ACC中的数存至指令地址码指示的存储单元中000011加将ACC中的数与指令地址码指示的存储单元中的数相加，结果存于ACC中000100乘将ACC中的数与指令地址码指示的存储单元中的数相乘，结果存于ACC中000101打印将指令地址码指示的存储单元中的操作数打印输出000110停机此例中所用到的数a、b、c、x，事先需存入存储器的相应单元内。按ax²+bx+c的运算分解，可用上述机器指令编写出一份运算的程序清单，如表1.2所列。指令和数据存于主存单元的地址指令注释操作码地址码00000010000001000取数x至ACC10001000000001001乘a得ax,存于ACC中20000110000001010加b得ax+b,存于ACC中30001000000001000乘x得(ax+b)x,存于ACC中40000110000001011加c得(ax²+bx+c,存于ACC中50000100000001100存数，将(ax²+bx+c存于主存单元60001010000001100打印7000110停机8x原始数据x9a原始数据a10b原始数据b11C原始数据c12存放结果以上程序编完后，便可进入下一步上机。为了比较形象地了解计算机的工作过程，首先分析一个比图1.9更细化的计算机组成框图，如图1.11所示。(1)主存储器主存储器(简称主存或内存)包括存储体M、各种逻辑部件及控制电路等。存储体由许多存储单元组成，每个存储单元又包含若干个存储元件(或称存储基元、存储元)，每个存储元件能寄存一位二进制代码“0”或“1”。可见，一个存储单元可存储一串二进制代码，称这串二进制代码为一个存储字，这串二进制代码的位数称为存储字长。存储字长可以是8位、16位或32位等。一个存储字可代表一个二进制数，也可代表一串字符，如存储字为0011011001111101，既可表示为由十六进制字符组成的367DH(有关十六进制数制详见附录6A)，又可代表16位的二进制数,此值对应十进制数为13949,还可代表两个ASCⅡ码:“6”和“}”(参见附录5AASCⅡ编码表)。一个存储字还可代表一条指令(参阅表1.2)。如果把一个存储体看作一幢大楼，那么每个存储单元可看作大楼中的每个房间，每个存储元可看作每个房间中的一张床位，床位有人相当于“1”，无人相当于“0”。床位数相当于存储字长。显然，每个房间都需要有一个房间编号，同样可以赋予每个存储单元一个编号，称为存储单元的地址号。主存的工作方式就是按存储单元的地址号来实现对存储字各位的存(写入)、取(读出)。这种存取方式称为按地址存取方式，即按地址访问存储器(简称访存)。存储器的这种工作性质对计算机的组成和操作是十分有利的。例如，人们只要事先将编好的程序按顺序存入主存各单元，当运行程序时，先给出该程序在主存的首地址，然后采用程序计数器加1的方法，自动形成下一条指令所在存储单元的地址，机器便可自动完成整个程序的操作。又如，由于数据和指令都存放在存储体内各自所占用的不同单元中，因此，当需要反复使用某个数据或某条指令时，只要指出其相应的单元地址号即可，而不必占用更多的存储单元重复存放同一个数据或同一条指令，大大提高了存储空间14第1篇概论的利用率。此外，由于指令和数据都由存储单元地址号来反映，因此，取一条指令和取一个数据的操作完全可视为是相同的，这样就可使用一套控制线路来完成两种截然不同的操作。为了能实现按地址访问的方式，主存中还必须配置两个寄存器MAR和MDR。MAR(MemoryAddressRegister)是存储器地址寄存器，用来存放欲访问的存储单元的地址，其位数对应存储单元的个数(如MAR为10位，则有2¹⁰=1024个存储单元,记为1K)。MDR(MemoryDataRegister)是存储器数据寄存器，用来存放从存储体某单元取出的代码或者准备往某存储单元存入的代码，其位数与存储字长相等。当然，要想完整地完成一个取或存操作，CPU还得给主存加以各种控制信号，如读命令、写命令和地址译码驱动信号等。随着硬件技术的发展，主存都制成大规模集成电路的芯片，而将MAR和MDR集成在CPU芯片中(参阅图4.5)。早期计算机的存储字长一般和机器的指令字长与数据字长相等，故访问一次主存便可取一条指令或一个数据。随着计算机应用范围的不断扩大，解题精度的不断提高，往往要求指令字长是可变的，数据字长也要求可变。为了适应指令和数据字长的可变性，其长度不由存储字长来确定，而由字节的个数来表示。1个字节(Byte)被定义为由8位(bit)二进制代码组成。例如，4字节数据就是32位二进制代码；2字节构成的指令字长是16位二进制代码。当然，此时存储字长、指令字长、数据字长三者可各不相同，但它们必须是字节的整数倍。(2)运算器运算器最少包括3个寄存器(现代计算机内部往往设有通用寄存器组)和一个算术逻辑单元(ALU)。其中ACC(Accumulator)为累加器,MQ(Multiplier-QuotientRegister)为乘商寄存器,X为操作数寄存器。这3个寄存器在完成不同运算时，所存放的操作数类别也各不相同。表1.3列出了寄存器存放不同类别操作数的情况。不同机器的运算器结构是不同的。图1.11所示的运算器可将运算结果从ACC送至存储器中的MDR；而存储器的操作数也可从MDR送至运算器中的ACC、MQ或X。有的机器用MDR取代X寄存器。下面简要地分析一下这种结构的运算器加、减、乘、除四则运算的操作过程。设：M表示存储器的任一地址号，[M]表示对应M地址号单元中的内容；X表示X寄存器，[X]表示X寄存器中的内容；ACC表示累加器，[ACC]表示累加器中的内容；MQ表示乘商寄存器，[MQ]表示乘商寄存器中的内容。假设ACC中已存有前一时刻的运算结果，并作为下述运算中的一个操作数，则●加法操作过程为[M]→X[ACC]+[X]→ACC即将[ACC]看作被加数，先从主存中取一个存放在M地址号单元内的加数[M]，送至运算器的X寄存器中,然后将被加数[ACC]与加数[X]相加,结果(和)保留在ACC中。●减法操作过程为[M]→X[ACC]-[X]→ACC即将[ACC]看作被减数，先取出存放在主存M地址号单元中的减数[M]并送入X，然后[ACC]-[X],结果(差)保留在ACC中。●乘法操作过程为[M]→MQ[ACC]→X0→ACC[X]×[MQ]→ACC‖MQ⁰即将[ACC]看作被乘数，先取出存放在主存M号地址单元中的乘数[M]并送入乘商寄存器MQ,再把被乘数送入X寄存器,并将ACC清“0”,然后[X]和[MQ]相乘,结果(积)的高位保留在ACC中,低位保留在MQ中。●除法操作过程为[M]→X[ACC]÷[X]→MQ余数R在ACC中即将[ACC]看作被除数，先取出存放在主存M号地址单元内的除数[M]并送至X寄存器，然后[ACC]除以[X],结果(商)暂留于MQ,[ACC]为余数R。若需要将商保留在ACC中,只需做一步[MQ]→ACC即可。(3)控制器控制器是计算机的神经中枢，由它指挥各部件自动、协调地工作。具体而言，它首先要命令存储器读出一条指令，称为取指过程(也称取指阶段)。接着，它要对这条指令进行分析，指出该指令要完成什么样的操作，并按寻址特征指明操作数的地址，称为分析过程(也称分析阶段)。最后根据操作数所在的地址以及指令的操作码完成某种操作，称为执行过程(也称执行阶段)。①∥表示两个寄存器串接。以上就是通常所说的完成一条指令操作的取指、分析和执行3个阶段。控制器由程序计数器(ProgramCounter,PC)、指令寄存器(InstructionRegister,IR)以及控制单元(CU)组成。PC用来存放当前欲执行指令的地址，它与主存的MAR之间有一条直接通路，且具有自动加1的功能，即可自动形成下一条指令的地址。IR用来存放当前的指令，IR的内容来自主存的MDR。IR中的操作码(OP(IR))送至CU,记作OP(IR)→CU,用来分析指令;其地址码(Ad(IR))作为操作数的地址送至存储器的MAR,记作Ad(IR)→MAR。CU用来分析当前指令所需完成的操作，并发出各种微操作命令序列，用以控制所有被控对象。(4)I/OI/O子系统包括各种I/O设备及其相应的接口。每一种I/O设备都由I/O接口与主机联系，它接收CU发出的各种控制命令，并完成相应的操作。例如，键盘(输入设备)由键盘接口电路与主机联系；打印机(输出设备)由打印机接口电路与主机联系。下面结合图1.11进一步深入领会计算机工作的全过程。首先按表1.2所列的有序指令和数据，通过键盘输入到主存第0号至第12号单元中，并置PC的初值为0(令程序的首地址为0)。启动机器后，计算机便自动按存储器中所存放的指令顺序有序地逐条完成取指令、分析指令和执行指令，直至执行到程序的最后一条指令为止。例如，启动机器后，控制器立即将PC的内容送至主存的MAR(记作PC→MAR)，并命令存储器做读操作,此刻主存“0”号单元的内容“0000010000001000”(表1.2所列程序的第一条指令)便被送入MDR内。然后由MDR送至控制器的IR(记作MDR→IR)，完成了一条指令的取指过程。经CU分析(记作OP(IR)→CU),操作码“000001”为取数指令,于是CU又将IR中的地址码“0000001000”送至MAR(记作Ad(IR)→MAR),并命令存储器做读操作,将该地址单元中的操作数x送至MDR，再由MDR送至运算器的ACC(记作MDR→ACC)，完成此指令的执行过程。此刻，也即完成了第一条取数指令的全过程，即将操作数x送至运算器ACC中。与此同时，PC完成自动加1的操作，形成下一条指令的地址“1”号。同上所述，由PC将第二条指令的地址送至MAR,命令存储器做读操作,将“0001000000001001”送入MDR,又由MDR送至IR。接着CU分析操作码“000100”为乘法指令，故CU向存储器发出读命令，取出对应地址为“0000001001”单元中的操作数a，经MDR送至运算器MQ，CU再向运算器发送乘法操作命令，完成ax的运算，并把运算结果ax存放在ACC中。同时PC又完成一次(PC)+1→PC，形成下一条指令的地址“2”号。依次类推，逐条取指、分析、执行，直至打印出结果。最后执行完停机指令后，机器便自动停机。衡量一台计算机性能的优劣是根据多项技术指标综合确定的。其中，既包含硬件的各种性能指标，又包括软件的各种功能。这里主要讨论硬件的技术指标。机器字长是指CPU一次能处理数据的位数，通常与CPU的寄存器位数有关。字长越长，数的表示范围越大，精度也越高。机器的字长也会影响机器的运算速度。倘若CPU字长较短，又要运算位数较多的数据，那么需要经过两次或多次的运算才能完成，这样势必影响机器的运算速度。机器字长对硬件的造价也有较大的影响。它将直接影响加法器(或ALU)、数据总线以及存储字长的位数。所以机器字长的确定不能单从精度和数的表示范围来考虑。存储器的容量应该包括主存容量和辅存容量。主存容量是指主存中存放二进制代码的总位数。即存储容量=存储单元个数×存储字长图1.11中MAR的位数反映了存储单元的个数，MDR的位数反映了存储字长。例如，MAR为16位,根据2¹⁶=65536,表示此存储体内有65536个存储单元(即64K个存储字，1K=1024=2¹⁰);而MDR为32位，表示存储容量为2¹⁶×32=2²¹=2M位(1M=2²⁰)。现代计算机中常以字节数来描述容量的大小，因一个字节已被定义为8位二进制代码，故用字节数便能反映主存容量。例如，上述存储容量为2M位，也可用2¹⁸字节表示，记作2¹⁸B或256KB(B用来表示一个字节)。辅存容量通常用字节数来表示，例如，某机辅存(如硬盘)容量为80GB(1G=1024M=2¹⁰×2²⁰=2³⁰)。计算机的运算速度与许多因素有关，如机器的主频、执行什么样的操作、主存本身的速度(主存速度快，取指、取数就快)等都有关。早期用完成一次加法或乘法所需的时间来衡量运算速度，即普通法，显然是很不合理的。后来采用吉普森(Gibson)法，它综合考虑每条指令的执行时间以及它们在全部操作中所占的百分比，即T_{M}=\sum\limits_{i=1}^{n}f_{i}t_{i}其中，TM为机器运行速度；f₁为第i种指令占全部操作的百分比数；t₁为第i种指令的执行时间。现在机器的运算速度普遍采用单位时间内执行指令的平均条数来衡量，并用MIPS(MillionIn-structionPerSecond,百万条指令每秒)作为计量单位。例如,某机每秒能执行200万条指令,则记作2MIPS。也可以用CPI(CyclePerInstruction)即执行一条指令所需的时钟周期(机器主频的倒数)数,或用FLOPS(FloatingPointOperationPerSecond,浮点运算次数每秒)来衡量运算速度。本书介绍计算机组成原理，其内容安排如下：第1篇：概论，介绍计算机系统的基本组成、应用与发展。第2篇：计算机系统的硬件结构，引导读者自顶向下了解计算机系统的硬件结构，包括中央处理器、存储器、I/O等主要部件以及连接它们的系统总线。其中，除中央处理器比较复杂放在第3篇单独讲述外，其他各部件均在此篇介绍。第3篇：中央处理器(CPU)，本篇讲述CPU的功能和结构，并对影响CPU特性、结构和功能的算逻单元及其运算方法、指令系统、指令流水、中断系统等进行详细分析。有关控制单元(CU)在第4篇单独介绍。第4篇：控制单元(CU)，本篇在详细分析时序系统以及微操作命令节拍安排的基础上，分别介绍如何用组合逻辑控制及微程序控制两种方法设计和实现控制单元。总之，全书按自顶向下、由表及里的层次结构，向读者展示计算机的组成及其工作原理，目的是使读者能先从整体上对计算机有一个粗略的认识，然后，逐步深入到机器内核，从而更容易形成计算机的整体概念。图1.12形象地描述了上述各章节之间的联系。谁也不曾想到，当初只是当作军事计算工具应用的电子计算机，在半个世纪中竟然会成为改变社会结构，乃至促使人们的工作和生活方式发生惊人变化的宠儿，真可谓20世纪下半世纪科技发展最有影响的发明，并且它还将继续影响着未来世界的变化，使数千年人类文明史中曾有过的各种神话般的幻想逐渐变为现实。1943年，第二次世界大战进入后期，因战争的需要，美国国防部批准了由Pennsyivania大学JohnMauchly教授和JohnPresperEckert工程师提出的建造一台用电子管组成的电子数字积分机和计算机(ElectronicNumericalIntegratorAndComputer,ENIAC)的计划,用它来解决当时国防部弹道研究实验室(BRL)开发新武器的射程和检测模拟运算表的难题。当时，由于运算能力不足，该实验室无法在规定的时间内拿出准确的运算表，严重影响了新武器的制作。ENIAC于1946年交付使用，其首要任务就是完成了一系列测定氢弹可靠性的复杂运算。ENIAC采用十进制运算，电路结构十分复杂，使用18000多个电子管，运行时耗电量达150千瓦，体积庞大，重量达30吨，占地面积为1500平方英尺，而且需用手工搬动开关和拔、插电缆来编制程序，使用极不方便，但它比任何机械计算机快得多，每秒可进行5000多次加法运算。ENIAC的出现不但实现了制造一台通用计算机的目标，而且标志计算工具进入了一个崭新的时代，是人类文明发展史中的一个里程碑。仅仅半个世纪，计算机已经使人类社会从工业化社会发展到了信息化社会。虽然ENIAC于1955年正式退役，并陈列于美国国立博物馆供人们参观，但它的丰功伟绩将永远记载在人类的文明史册中。1945年，ENIAC的顾问、数学家冯·诺依曼在为一台新的计算机EDVAC(电子离散变量计算机)所制定的计划中首次提出了存储程序的概念，即将程序和数据一起存放在存储器中，使编程更加方便。这个思想几乎同时被科学家图灵(Turing)想到了。1946年,冯·诺依曼与他的同行们在PrincetonInstitute进行高级研究时,设计了一台存储程序的计算机IAS，可惜因种种原因直到1952年IAS也未能问世。但IAS的总体结构从此得到了认可，并成为后来通用计算机的原型，图2.1就是IAS计算机的总体结构示意图。它由几部分组成：一个同时存放指令和数据的主存储器、一个二进制的算逻运算部件、一个解释存储器中的指令并能控制指令执行的程序控制部件以及由控制部件操作的I/O设备。20世纪50年代，美国出现了Sperry和IBM两大制造计算机的公司，后来又从Sperry公司分离出了UNIVAC子公司，他们控制着计算机市场。1947年，Eckert和Mauchly共同建立了生产商用计算机的计算机公司，他们第一个成功的产品是UNIVACI(UniversalAutomaticComputer),后来Eckert-Mauchly公司成为从Sperry-Rand公司分离出来的UNIVAC子公司,并继续制造了一系列产品,如UNIVACⅡ及UNIVAC1100系列产品，它们成为科学和商用计算机的主流产品。同时IBM公司在1953年推出了首台存储程序的计算机701机，1955年又推出了702机，使之更适用于科学计算和商业应用，后来形成了700/7000系列，使IBM成为计算机制造商的绝对权威。自从ENIAC问世后，人类为提高电子计算机性能的欲望从未减退过，并在20世纪50年代初，除美国外，英、法、苏联、日本、意大利等国都相继研制出本国的第一台电子计算机，我国也于1958年研制成自己的第一台电子计算机。可是在这十多年的时间里，计算机的性能并未出现奇迹般的提高，它的运算速度每秒仅在数千次至上万次左右，其体积虽然不像ENIAC那样庞大，但也占了相当大的空间，耗电量也很大。直到20世纪50年代末，计算机技术迎来了第一次大飞跃的发展机遇，其性能出现了数十倍以至几百倍的提高，这就是用晶体管替代电子管的重大变革。1947年在贝尔实验室成功地用半导体硅作为基片，制成了第一个晶体管，它的小体积、低耗电以及载流子高速运行的特点，使真空管望尘莫及。进入20世纪50年代后，全球出现了一场以晶体管替代电子管的革命，计算机的性能有了很大的提高。以IBM700/7000系列为例，晶体管机7094(1964年)与电子管机701(1952年)相比,其主存容量从2K字增加到32K字;存储周期从30μs下降到1.4μs；指令操作码数从24增加到185；运算速度从每秒上万次提高到每秒50万次。7094机还采用了数据通道和多路转换器等在当时看来是最新的技术。尽管用晶体管代替电子管已经使电子计算机的面貌焕然一新，但是随着对计算机性能越来越高的追求，新的计算机所包含的晶体管个数已从一万个左右骤增到数十万个，人们需要把晶体管、电阻、电容等一个个元件都焊接到一块电路板上，再由一块块电路板通过导线连接成一台计算机。其复杂的工艺不仅严重影响制造计算机的生产效率，更严重的是，由几十万个元件产生几百万个焊点导致计算机工作的可靠性不高。随着1958年微电子学的深入研究，特别是新的光刻技术和设备的成熟，为计算机的发展又开辟了一个崭新时代——集成电路时代。仔细分析就会发现，计算机的数据存储、数据处理、数据传送以及各类控制功能基本上都是由具有布尔逻辑功能的各类门电路完成的，而大量的门电路又都是由晶体管、电阻、电容等搭接而成，因此，当集成电路制造技术出现后，可以利用光刻技术把晶体管、电阻、电容等构成的单个电路制作在一块极小(如几个平方微米)的硅片上。进一步发展，实现了将成百上千个这样的门电路全部制作在一块极小(如几个平方毫米)的硅片上，并引出与外部连接的引线，这样，一次便能制作成成百上千个相同的门电路，又一次大大地缩小了计算机的体积，大幅度下降了耗电量，极大地提高了计算机的可靠性。这就是人们称为小规模集成电路(SSI)和中等规模集成电路(MSI)的第三代计算机,其典型代表为IBM的System/360和DEC的PDP-8。1964年，IBM推出了一个新的计算机系列System/360，打破了7000系列在体系结构方面的一些约束。为了推动集成电路技术，改进原来的结构，IBM投入了大量的人力和物力进行技术开发，作为回报，它最终占领了大约70%的市场份额，成为计算机制造的最大制造商。System/360系列中有不同的机型，但它们又都是互相兼容的，即在某种机型上运行的程序可以在这一系列中的另一种机型上运行。它们具有类似或相同的指令系统(该系列中低档机的指令系统可以是高档机指令系统的一个子集)，各机型有类似或相同的操作系统，而且随着机器档次的提高，机器的速度、存储器的容量、I/O端口的数量以及价格都有所增长。另一种有代表性的机器是DEC的PDP-8，它采用总线结构，有迷你机之称。它以低价格、小体积吸引了不少用户，售价仅16000美元，而当时System/360大型机的售价为数十万美元。PDP-8使DEC迅速发展起来，使其成为继IBM之后的第二大计算机制造商。从1946年的ENIAC到1964年的IBMSystem/360,历时不到20年,计算机的发展经历了电子管一晶体管一集成电路3个阶段，通常称为计算机的3代。显然，早期计算机的更新换代主要集中体现在组成计算机基本电路的元器件(电子管、晶体管、集成电路)上。第三代计算机之后，人们没有达成定义新一代计算机的一致意见。表2.1列出了硬件技术对计算机更新换代的影响。进入到20世纪70年代后，把计算机当作高级计算工具的狭隘观念已被人们逐渐摒弃，计算机成为一门独立的学科而迅猛发展，并且影响、改变着人类的生活方式，这是由于微处理器的出现(采用大规模和超大规模集成电路)、软件技术的完善及应用范围的不断拓宽所带来的必然结果。集成电路技术把计算机的控制单元和算逻单元集成到一个芯片上，制成了微处理器芯片。1971年，美国Intel公司31岁的工程师霍夫研制成世界上第一个4位的微处理器芯片4004，集成了2300个晶体管。随后，微处理器经历了4位、8位、16位、32位和64位几个阶段的发展，芯片的集成度和速度都有很大的提高。与此同时，半导体存储器的研制也正在进行，1970年，Fairchild制作了第一个存储芯片，该芯片大约只有一个磁心这么大，却能保存256位二进制信息，但是每位的价格高于磁心。1974年后，随着半导体存储器价格的迅速下降，位密度的不断提高,存储芯片的容量经历了1K位,4K位,16K位,64K位,256K位,1M位,4M位,16M位,64M位，…，1G位这几个阶段，每个新的阶段都比过去提高到4倍的容量，而价格和访问时间都有所下降。总之，芯片集成度不断提高，从在一个芯片上集成成百上千个晶体管的中、小规模集成电路，逐渐发展到能集成成千上万个晶体管的大规模集成电路(LSI)和能容纳百万个以上晶体管的超大规模集成电路(VLSI)。微芯片集成晶体管的数目验证了Intel公司的缔造者之一GordonMoore提出的“微芯片上集成的晶体管数目每3年翻两番”的规律，这就是人们常说的Moore(摩尔)定律。微处理器芯片和存储器芯片出现后，微型计算机也随之问世。例如，1971年用4004微处理器制成了MCS-4微型计算机。20世纪70年代中期,8位微处理器8008、8080、R6502、M6800、Z80等相继出现,并用R6502制成了AppleⅡ微型计算机,用Z80制成了CROMEMCO80微型计算机等。最值得一提的是世界上第一大微处理器的制造商Intel，其典型产品如下。·8080：世界上第一个8位通用的微处理器，1974年问世。·8086：16位，2.9万个晶体管，地址20位，采用6个字节指令队列，指令系统与8088完全兼容,1978年问世。·8088:集成度达2.9万个晶体管,主频4.77MHz,字长16位(外部8位),又称准16位,地址20位,采用4个字节指令队列,被IBM首台微型计算机(IBMPC)选用,1979年问世。·80286:16位,13.4万个晶体管,6MHz,地址24位,可用实际内存16MB和虚拟内存1GB,1982年问世。·80386:32位,27.5万个晶体管,12.5MHz、33MHz,地址32位,4GB实际内存,64TB(1"B=2⁴⁰B)虚拟内存，其性能可与几年前推出的小型机和大型机相比，1985年问世。·80486:32位,120万个晶体管,25MHz、33MHz、50MHz,4GB实际内存,64TB虚拟内存，引用更加复杂的Cache技术和指令流水技术，速度比80386快一倍，性能指标比80386高出3~4倍,1989年问世。·Pentium:32位,310万个晶体管,66MHz、100MHz,4GB实际内存,64TB虚拟内存,采用超标量技术，使多条指令可并行执行，速度比80486高出6~8倍，1993年问世。●PentiumPro:64位,550万个晶体管,133MHz、150MHz、200MHz,64GB实际内存,64TB虚拟内存，采用动态执行RISC/CISC技术、分支预测、指令流分析、推理性执行和二级Cache等技术,1995年问世。·PentiumⅡ:64位,750万个晶体管,200~300MHz,64GB实际内存,64TB虚拟内存,融入了专门用于有效处理视频、音频和图形数据的IntelMMX技术，1997年问世。·PentiumⅢ:64位,950万个晶体管,450~600MHz,64GB实际内存,64TB虚拟内存,融入了新的浮点指令，以支持三维图形软件，1999年问世。●Pentium4:64位,4200万个晶体管,1.3~1.8GHz,64GB实际内存,64TB虚拟内存,包括另外的浮点和其他多媒体应用的增强，2000年问世。显然，从20世纪70年代初至今，微型计算机的发展在很大程度上取决于微处理器的发展，而微处理器的发展又依赖于芯片集成度和处理器主频的提高。从2000年IntelPentium4问世至今的发展历程看，处理器的架构变化不大，主要从提高处理器的主频、增加扩展指令集、增加流水线、提高生产工艺水平(晶体管的线宽从180nm→130nm→90nm→65nm)等几方面来不断改进处理器的性能。但制造工艺的缺陷，导致了处理器功耗持续上升。大量研究表明，每推出一代新型处理器，它的功耗是上一代处理器功耗的2倍，倘若芯片集成度达10亿个，处理器的自身功耗将会使人们一筹莫展。可见，有效解决微处理器的功耗和散热问题已成为当务之急。事实上一味追求微芯片集成度的提高，除了引发功耗、散热问题外，还会出现更多的问题，如线延迟问题、软误码率现象等。为了提高计算机的性能，除了提高微处理器的性能外，人们还努力通过开发指令级并行性来实现。可是在指令级并行性应用中，又受到数据预测精度有限、指令窗口不能过大以及顺序程序固有特性的限制等，使得依靠开发指令级并行性来提高计算机的性能又有很大的局限性。虽然很多因素阻碍了微型计算机性能的不断提高，可是随着计算机的广泛应用，尤其是网络技术的迅猛发展，人们依然在追求着机器性能的完美。例如，当前网络的环境基本上是让计算机处于桌面固定的状态，而人们更希望机器能围绕人们的需求转，越来越方便地使用计算机，不希望机器局限于固定的桌面式应用，让机器以手持式或穿戴式以及其他形式，使之更具人性化，能和谐地融合于人们的生活和工作之中。与此相适应的移动计算技术便应运而生。移动计算模式迫切要求微处理器具有响应实时性、处理流式数据类型的能力、支持数据级和线程级并行性、更高的存储和I/O带宽、低功耗、低设计复杂性和设计的可伸缩性。当前主流商用处理器大部分都是超标量结构，是一种在一个时钟周期内同时发射多条标量指令到多个功能部件以提高处理器性能的体系结构，若每周期发送4条指令，已不能满足日渐庞大的应用程序对高性能的需求。而继续开发更大发射带宽的超标量结构将会导致处理器的逻辑设计复杂度大幅增加，正确性验证变得越来越困难。人们开始寻找新的体系结构来适应新的市场和不断变化的应用需要。从20世纪微处理器的发展来看，几乎每3年处理器的性能就能提高4~5倍，但是计算机中一些其他部件性能的提高速度达不到这个水平。因此，必须不断调整计算机的组成和结构，以弥补不同部件性能的不匹配问题。影响它们之间不匹配的主要因素是处理器与主存之间的接口和处理器与外设之间的接口。处理器与主存之间的接口是整个计算机最重要的通路，因为它要负责在主存与处理器之间传送指令和数据，如果主存或主存与处理器之间的传送跟不上处理器的要求，就会使处理器处于等待的状态。为此，可加宽数据总线的宽度，在主存和处理器之间设置高速缓冲存储器(Cache)并发展成片内Cache和分级Cache，采用高速总线和分层总线来缓冲和分流数据，从而提高处理器和存储器之间的连接带宽。处理器和外设之间也存在大量的数据传输要求，可通过各种缓冲机制、加上高速互连总线以及更精致的总线结构来解决它们之间传输速率的不匹配问题。因此，计算机的设计者们必须不断平衡处理器、主存、I/O设备和互连结构之间的数据吞吐率和数据处理的需要，使计算机的性能越来越好。从21世纪初来看，当前通用微处理器的发展重点将在以下几方面。①进一步提高复杂度来提高处理器性能。这种方法沿袭传统的指令级并行方法加速单线程应用，组织更宽的超标量，采用更多的功能部件、多级Cache和激进的数据、控制以及指令轨迹预测,达到使用尽可能多的指令级并行(Instruction-LevelParallelism,ILP)。例如,先进超标量处理器(AdvancedSuperscalarProcessor)、超前瞻处理器(SuperspeculativeProcessor)、多标量处理器(MultiscalarProcessor)、数据标量处理器(DatascalarProcessor)和踪迹处理器(TraceProcessor)等。②通过线程/进程级并行性的开发提高处理器的性能，即通过开发线程级并行性(Thread-LevelParallelism,TLP)或进程级并行性(Process-LevelParallelism,PLP)来提高性能,简化硬件设计。例如,多处理器(Multiprocessor)、单芯片处理器CMP(On-chipMultiprocessor)、多线程处理器(Multi-ThreadedProcessor)以及同时多线程处理器(SimultaneousMulti-ThreadingProcessor)、动态多线程处理器(Dynamic-MultithreadedProcessor)和多路径多线程处理器(ThreadedMultipathPro-cessor)等。③将存储器集成到处理器芯片内来提高处理器性能。采用ILP、TLP、PLP能大大提高处理器内部指令执行的并行度，而指令和数据的供应是充分发挥这些技术的关键问题。传统上以处理器为中心的设计思想导致处理器把大量的复杂性花在解决访存延迟的问题上。然而处理器和存储器性能的差距仍在以每年50%的速度增大，使得访存速度将成为未来提高处理器性能的主要瓶颈。基于此,PIM(ProcessorInMemory)技术提出将处理器和存储器集成在同一个芯片上,这样可使访存延时减少5~10倍，存储器带宽可增加50~100倍。大多数情况下，整个应用在运行期间都可放到片上存储器里。将存储器集成到处理器芯片上后，原来用于增加处理器一存储器带宽的大量存储总线引脚可以被节省下来用于增加I/O带宽，这将有利于提高未来大量的网络应用性能，并且能减少对片外存储器的访问，使处理器的功耗大大降低。④发展嵌入式处理器。由于嵌入式应用需求的广泛性，以及大部分应用功能单一、性质确定的特点，决定了嵌入式处理器实现高性能的途径与通用处理器有所不同。目前嵌入式处理器大多是针对专门的应用领域进行专门设计来满足高性能、低成本和低功耗的要求。例如，视频游戏控制需要很高的图形处理能力；手持、掌上、移动和网络PC要求具备虚存管理和标准的外围设备；手机和个人移动通信设备要求在具有高性能和数字信号处理能力的同时具有超低功耗；调制解调器、传真机和打印机要求低成本的处理器；机顶盒和DVD则要求高度的集成性；数字相机要求既有通用性又有图像处理能力。目前嵌入式处理器的高性能和低成本技术发展趋势是：体系结构需要在新技术与产品、市场和应用需求之间取得平衡；设计方法趋向于走专用、定制和自动化的道路。计算机刚刚问世时，还未建立“软件”这一概念，随着计算机的发展及应用范围的扩大，逐渐形成了软件系统。在早期的计算机中，使用者必须根据机器自身能识别的语言——机器语言(机器指令)按解题要求编写出机器可直接运行的程序。由于机器不同，机器语言也不同，因此人们在不同的机器上编程，就需要熟悉不同机器的机器指令，使用极不方便，写出的程序很难读懂。20世纪50年代后，逐渐形成了符号语言和汇编语言，这种语言虽然可以不用0/1代码编程，改善了程序的可读性，但它们仍是面向机器的，即不同的机器各自有不同的汇编语言。为了使这种符号语言转变成机器能识别的语言，人们又创造了汇编程序，用于把汇编语言翻译成机器语言。为了摆脱对具体机器的依赖，在汇编语言之后又出现了面向问题的高级语言。使用高级语言编程可以不了解机器的结构，高级语言的语句通常是一个或一组英语词汇，词义本身反映出命令的功能，它比较接近人们习惯用的自然语言和数学语言，使程序具有很强的可读性。高级语言的发展经历了几个阶段。第一阶段的代表语言是1954年问世的FORTRAN，它主要面向科学计算和工程计算。第二阶段可视为结构化程序设计阶段，其代表是1968年问世的Pascal语言，它定义了一个真正的标准语言，按严谨的结构化程序编程，具有丰富的数据类型，写出的程序易读懂、易查错。第三阶段是面向对象程序设计阶段，其代表语言是C++。近年来随着网络技术的不断发展，又出现了更适应网络环境的面向对象的Java语言，而且随着Internet技术的发展和应用，Java语言越来越受到人们普遍欢迎。为了使高级语言描述的算法在机器上执行，同样需要有一个翻译系统，于是产生了编译程序和解释程序，它们能把高级语言翻译成机器语言。可见，随着各种语言的出现，汇编程序、编译程序、解释程序的产生，逐渐形成了软件系统。随着计算机应用领域的不断扩大，外部设备的增多，为了使计算机资源让更多用户共享，又出现了操作系统。操作系统能协调管理计算机中各种软件、硬件及其他信息资源，并能调度用户的作业程序，使多个用户能有效地共用一套计算机系统。操作系统的出现使计算机的使用效率成倍地提高，并且为用户提供了方便的使用手段和令人满意的服务质量。例如，DOS、UNIX和Windows等。此外，一些服务性程序，如装配程序、调试程序、诊断程序和排错程序等，也逐渐形成。特别是随着计算机在信息处理、情报检索及各种管理系统中应用的发展，要求大量处理某些数据，建立和检索大量的表格。这些数据和表格按一定的规律组织起来，使用户使用更方便，于是出现了数据库。数据库和数据管理软件一起便组成了数据库管理系统。而且随着网络的发展，又产生了网络软件等。以上所述的各种软件均属于系统软件，而软件发展的另一个主要内容就是应用软件。应用软件种类繁多，它是用户在各自的行业中开发和使用的各种程序。如各种财务软件、办公用的文字处理和排版软件、帮助管理日常业务工作和图文报表的“电子表格”和“数据库”软件、帮助工程设计的CAD软件以及各种实用的网络通信软件等。软件发展有以下几个特点。(1)开发周期长研制一个软件往往因其规模庞大而需较长的开发周期。例如，美国穿梭号宇宙飞船的软件包含4000万行目标代码，倘若一个人一年开发一万行程序，则需集中4000人花一年时间才能完成，而且要做到4000人的默契配合，涉及种种技术问题的协调，如分析方法、设计方法、形式说明方法、版本标准等都得有严格的规范，其难度远远超过自动化程度极高的硬件制造。(2)制作成本昂贵超大规模集成电路技术给硬件制造业带来巨大利益，使硬件的价格不断下降，使一台普通的微型计算机的价格与一台彩色电视机的价格相当，而且还在下降。可是软件的开发完全依赖于人工，致使软件开发成本不断上涨，在美国，软件成本约占计算机系统总成本的90%，已成为司空见惯的现象。(3)检测软件产品质量的特殊性一种软件在刚开始推出时，主要实现其面向领域所需的核心功能，之后逐步集成大量的附加功能。也就是说，要完善一个软件产品，必须在应用过程中不断加以修改、补充。只有使用了一定时间后，才能对软件产品质量进行确定。尽管软件技术兴起和发展比硬件晚，而且其发展速度没有硬件快(如微处理器的性能以Moore定律所述的几何级数增长)，但是仍可以说，如果没有当今的软件技术，计算机系统和应用的发展也不会有今天这样的成就。客观地说，软件的发展不断激励着微处理器和存储器性能的增长。世界各国当前都十分重视软件人才的培养和软件产业的形成，但实际上它们都很难与当前计算机应用普及的广度和深度相适应。也正因为如此，有些软件开发商瞄准了特定的市场，一旦在性能、质量占到上风时，就会很快积聚财富，成为新的世界级富商。例如，美国微软公司十来年的发展就超过传统工业(如汽车制造业)，同样微软公司的组建者也很快成为现代世界最大富商之一。在二三十年软件开发的实践中，人们对软件开发也逐渐有了较深刻的认识，逐渐体会到软件不是简单地编写程序，欲开发成一个优良的软件，和开发其他产品一样，必须明确开发要求，然后做可行性分析，确定基本方法，进行需求分析，再深入用户核准需求，取得一致意见后才能进入软件设计阶段。因此，程序只是完成整个软件产品的一个组成部分，软件生存周期的各个阶段都是以文档资料形式存在。正如著名软件工程专家Boehm曾经指出：“软件是程序以及开发、使用和维护程序需要的所有文档。”可见软件开发不是某种个体劳动的神秘技巧，它是一个组织良好、管理严密、各类人员协同配合共同完成软件工程的全过程。只有这样才能保证软件工程的顺利完成，并能节省大量开发费用；否则将会陷入事倍功半、长期无法正常运行的困境。自ENIAC问世后将近30余年的时间里，计算机一直被作为大学和研究机构的娇贵设备。在20世纪70年代中后期，大规模集成工艺日趋成熟，微芯片上集成的晶体管数一直按每3年翻两番的Moore定律增长，微处理器的性能也按此几何级数提高，而价格也以同样的几何级数下降，以至于以前需花数百万美元的机器(如80MFLOPS的CRAY)变得价值仅为数千美元(而此类机器的性能可达200MFLOPS)，至于对性能不高的微处理器芯片而言，仅花数美元就可购到。因此，人们终于使计算机走出了实验室而渗透到各个领域，乃至走进普通百姓的家中。当然，除了计算机的价格迅速降低以外，计算机软件技术日趋完臻也是计算机获得广泛应用的重要原因。尤其是近年来计算机技术和通信技术相互融合，出现了沟通全球的Internet，使计算机的应用范围从科学计算、数据处理等传统领域扩展到办公自动化、多媒体、电子商务、虚拟工厂、远程教育等，遍及社会、政治、经济、军事、科技以及个人文化生活和家庭生活的各个角落。科学计算一直是计算机的重要应用领域之一。其特点是计算量大和数值变化范围大。在天文学、量子化学、空气动力学和核物理学等领域都要依靠计算机进行复杂的运算。例如，人们日常生活难以摆脱的天气预报，要知道第二天的气候变化，采用1MIPS的计算机顷刻间便可获得。倘若想预报一个月乃至一年的气候变化，使各地提前做好防汛、防旱等工作，则100MIPS或更高的计算机才能满足。现代的航空、航天技术，如超音速飞行器的设计、人造卫星和运载火箭轨道的计算，也都离不开高速运算的计算机。此外，计算机在其他学科和工程设计方面，诸如数学、力学、晶体结构分析、石油勘探、桥梁设第2章计算机的发展及应用29计、建筑、土木工程设计等领域内，都得到了广泛的应用。数据处理也是计算机的重要应用领域之一。早在20世纪五六十年代，人们就把大批复杂的事务数据交给了计算机处理，如政府机关公文、报表和档案。大银行、大公司、大企业的财务、人事、物料，包括市场预测、情报检索、经营决策、生产管理等大量的数据信息，都由计算机收集、存储、整理、检索、统计、修改、增删等，并由此获得某种决策数据或趋势，供各级决策指挥者参考。通过各种传感器获得的各种物理信号经转换为可测可控的数字信号后，再经计算机运算，根据偏差，驱动执行机构来调整，便可达到控制的目的。这种应用已被广泛用于冶金、机械、纺织、化工、电力、造纸等行业中。目前的工业控制远比20世纪六七十年代先进得多。新型的工业自动控制系统以标准的工业计算机软、硬件平台构成集成系统，取代了传统的封闭式系统，具有更强的适应性，更好的开放性，更易于扩展，更经济、更短的开发周期等显著优点。通常将工控系统分为3层：控制层、监控层和管理层。控制层是最下层，它是通过各种传感器来获得各种有效信号的。监控层下连控制层，上连管理层，它不但实现对现场的实时监测与控制，而且常在自动控制系统中完成上传下达，组态开发的重要作用。特别是组态软件的出现，使数据采集、过程控制变得十分简单，它为用户提供良好的开发界面和简捷的使用方法，使用各种软件模块可以非常容易地实现和完成监控层的各种功能。就目前发展趋势而言，工业控制的应用已经向控管一体化方向发展，利用网络技术，通过传感技术和多媒体技术，操作者可以在控制室内通过大屏幕显示，了解各车间、各工位、各部门的生产运行情况，并可直接由控制室发出各种控制命令，指挥全厂正常工作。在军事上，导弹的发射及飞行轨道的计算控制、先进的防空系统等现代化军事设施，通常也都是由计算机构成的控制系统，其中包括雷达、地面设施、海上装备等。例如，将计算机嵌入导弹的弹头内，利用卫星定位系统，将飞行目标和飞行轨迹事先存储在弹载计算机内，导弹在飞行中对实际飞行轨迹进行不断修正，直接袭击目标，其命中率几乎接近100%。美国在海湾战争以及后来的军事冲突中，计算机实时控制技术发挥了极为突出的作用。此外，2003年和2005年我国发射的载人宇宙飞船都属于实时控制的应用范畴。促使计算机网络诞生的最早动机在于实现硬件资源的共享。当时计算机十分昂贵，人们希望能远距离利用计算机，因此在1954年第一次实现了将穿孔卡上的数据从电话线发送到远方的计算机来完成运算，这可以说是计算机网络的雏形，可见网络技术的基础是计算机技术与通信技术的结合。1992年美国政府提出了“国家信息基础设施计划”，1993年西方七国提出“全球信息基础设施计划”，整个世界随着通信技术和计算机技术的结合，在21世纪到来前，一个崭新的全球性的Internet正在形成，并正以更新的姿态屹立在世界的顶端。由于全球网络化消除了人们之间因时间、距离和地理界限所形成的障碍，从而使各国人们在技术交流、商品交换、文化传递、感情沟通等方面变得十分迅捷，十分方便。如果再有性能良好的语言翻译机(实际上目前已经有翻译机了)，那么原有的隔阂和障碍可能会全部消失。正因如此，Internet的发展规模和速度达到了惊人的程度，人们称之为新Moore定律，全球入网量每6个月翻一番。据2007年1月国外网站统计，全世界上网的计算机已超过4.3亿台，上网人数已达11亿。据中国互联网发展状况2007年1月的统计报告,至2006年年底,我国网民人数达1.37亿,比2005年增加2600万,增长率为23.4%,上网计算机达5940万台,比2005年增加990万台,增长率为20%。如果从有Internet开始计算，仅4年的时间网上计算机达5000万台，相比之下，全世界5000万用户拥有电视机却花了13年，拥有收音机经历了38年，拥有电话的时间就更长了。可见网络的发展速度大大超过了电视机、收音机和电话。可以断言，全球网络化不仅改变着商务经济、工业生产、科技发展，还必将影响人们的工作、娱乐和生活，它正在改变着整个世界。网络应用涉及方方面面，在此仅举几个例子。电子商务的含义是任何一个组织机构可利用Internet来改变他们与客户、供应商、业务伙伴和内部员工的交流，也可以认为是消费者、销售者和结算部门之间利用Internet完成商品采购和支付的过程。例如：某企业可以通过在Internet上的网页向全球发布推出的商品，并向他的各地代理商发出各种指令；当某客户欲购此商品时，他可以通过网上直接与生产企业联络，也可与各地代理商联系，进一步了解该商品的性能，并将其姓名、地址、个人电子账号及送货要求等告诉卖主。企业或经销商通过Internet与银行联络，查询核实该客户的资金状况，并通过协定的支付方式由银行实行电子支付，而商品则由企业经销商直接送到客户手中。这种简捷、可靠的商品销售方式可从根本上改变传统的销售方式。它可以不要传统意义上的店铺，而直接用电子店铺来取代；可以一夜之间将自己的品牌通告全世界；可以实现公平竞争，小企业不必害怕大企业的广告效应，大企业也不必顾虑小企业的快速应变能力，各自都可以通过网上信息进行竞争；可以取消纸币交易的各种弊端，完全实现电子货币交换；可以减少很多中间环节，以最高效率、最省人力、最广泛的市场实现商品的全球交换。目前世界各国都在蓬勃发展电子商务，我国的电子商务也在各种城市陆续展开。传统的老师讲、学生听的课堂授教模式随着全球网络化的发展，将会在“知识爆炸”①时代逐渐被淘汰或更新。旧教学模式的最大缺点是，作为受知主体的学生在教学过程中自始至终处于①英国技术预测专家詹姆斯·马丁测算结果表明：人类知识到19世纪50年代增加了1倍；20世纪初是每10年增加1倍；20世纪70年代则是每5年增加1倍；近10年大约每3年增加1倍，故称为“知识爆炸”。受灌输的被动地位，其主动性、积极性难以发挥，学生无法主动探索，主动发现社会上、国际上的信息资源，很难培养具有“信息能力”的劳动者。因此，不利于创新能力的形成和创新型人才的成长。此外，这种模式受场地、空间的限制，投资大，受众有限，不能适应各种学科的终身教育和全面教育。通过教育网络，学生受教可以不受时间、空间和地域的限制，通过网络伸展到全球的每个角落，建立真正意义上的开放式的虚拟学校，每个学生可以在任意时间、任意地点通过网络自由地学习。不论学生的贫富贵贱都可以“聆听”一流老师的指导，都可以向世界最权威的专家请教，都可以从世界任何角落获取最新的信息和资料。到那时可以说，任何人都享有高等教育和终身教育的可能。这种基于网络的教育模式，不仅美、英、日等发达国家在积极实施，我国在有条件的地区和省市也正在加速启动建设教育网络，实现由传统教育体制、教学模式向全新教育体制、教学模式的转变，实现教育的重大革新，满足21世纪人才培养的需求。随着全球信息网络技术的发展，对制造业的制造模式和企业的组成及管理模式也产生了极大影响，新的被称为21世纪制造模式的敏捷制造由此而生。敏捷制造由两部分组成：敏捷制造的基础结构和敏捷制造的虚拟企业。前者为形成虚拟企业提供环境和条件，后者对市场不可预期的变化做出迅速响应。当出现某种市场机遇时，由敏捷制造基础结构所形成的虚拟企业通过网上联络若干个具有核心资格的组织者，他们以各自的资金、技术、厂房、设备等优势，通过国家的法律和彼此的合同，组建成一个虚拟企业。该企业不必有集中的办公场地和固定的组织机构，完全通过网络实现产品的技术设计、制造、网上销售和网上服务，充分发挥各自的优势，以最优化的组合、最低的成本获取最大的利润。这种虚拟企业是在敏捷制造基础结构环境下形成的独立的、实体性的、社会性的团体，同时又是一个动态的联盟，他们可以根据市场的变化和要求，解散原来的虚拟企业，而与新的伙伴组成新的虚拟企业。可见，网络技术的发展对社会原来的固定企业结构形式构成了严峻的挑战。以上仅就几个方面列举了全球网络化对整个社会经济、文化、教育、工业制造等方面的影响。实际上，由于网络技术的发展，现在已经形成了虚拟图书馆、虚拟医院、虚拟商场、虚拟娱乐场所等。事实上Internet早已从对经济的干预发展到对政治的干预。例如，美国前总统克林顿，从他的绯闻到国会弹劾，直至幸免弹劾，都与网民的直接参与分不开。又如非洲尼日利亚总统大选，两名主要的候选人都为选举分别建立了各自的网站。再如在英国戴安娜王妃和英国王室的众多网站上，充满政治性的窃窃私语已司空见惯。可以说全球的网络化必将进一步改变整个世界。虚拟现实是利用计算机生成的一种模拟环境，通过多种传感设备使用户“投入”到该环境中，达到用户与环境直接进行交互的目的。这种模拟环境是用计算机构成的具有表面色彩的立体图形，它可以是某一特定现实世界的真实写照，也可以是纯粹构想出来的世界。这类技术虽然早在20世纪60年代初就开始研究，但只有在计算机技术迅速发展的今天，各种传感设备以及计算机价格的不断降低，软件系统的日趋完善，如实时三维图形生成及显示、三维声音定位与合成、环境建模等技术的发展，才有可能使虚拟现实技术获得迅速发展和广泛应用。虚拟现实在军事、教育、航天、航空、娱乐、生活中的应用不仅会改变人们的思维方式和生活方式，还必将导致一场重大的技术革命。下面列举两个例子以示虚拟现实的巨大魅力。虚拟演播室近年来已成为影视制作的热点，它综合运用现代计算机图形和图像处理、计算机视觉和现代影视技术，将摄像机拍摄的图像实时地与计算机三维虚拟背景或另一地点实拍的背景，按统一的三维透视成像关系进行合成，从而形成一种新的影视节目，其效果是传统影视制作无可比拟的。在虚拟演播室里，演员可以在没有任何道具的舞台上演戏，然后根据剧情需要用计算机制作的画面进行合成。不仅如此，演员也可以是虚拟的，可以根据事先拍好的演员镜头，利用演技数据，用计算机图形学技术制作演员的特定动作，这对于一些特技的制作格外重要。这种在虚拟演播室制作的影视剧大大降低了制作成本，缩短了制作时间，并且可以制作更有魅力的艺术作品。飞行员与汽车驾驶员的仿真训练系统也都广泛应用了虚拟现实技术。在飞行仿真训练系统中，要形成真实的飞行环境和飞行员的真实感觉。例如，在环境图像生成中，以50Hz的频率生成彩色图像，而且具有纹理，还有亮点、透明、天气效果(如雾、雨、雪、晴、云等)、非线性图像映射、碰撞检测、高山地形、细节模拟等。飞机着陆时跑道灯应按飞机着陆角度不同而变换颜色，并能确认飞机与跑道上其他飞机甚至建筑物的相互距离。又如在虚拟现实仿真中，飞行员必须体验到真实飞行的感觉，犹如在一个真实飞机的机舱里，每个仪表都必须像在真实环境下工作，油表指示必须反映虚拟引擎对油的使用率，并且还必须精确地反映动力和温度。在飞机接触跑道时，还必须有真实的冲击感和震动感。显然对于价值数千万美元的飞机来说，让飞行员在仿真训练系统中训练，既不会危及人的生命安全，又不会损坏飞机，也不会造成公害，而且大大降低了训练成本，所以各类仿真模拟训练器都已被广泛应用。顾名思义，办公自动化是利用计算机及自动化的办公设备来替代“笔、墨、纸、砚”及办公人员的部分脑力、体力劳动，从而提高了办公的质量和效率。例如，利用计算机来起草文件；利用计算机来安排日常的各类公务活动，包括会议、会客、外出购票；利用计算机来收集各类信息，将各类信息以电子数字形式存于数据库内，并可随时进行查询、检索及修改。一个完整的办公自动化系统将包括文秘、财务、人事、资料、后勤等各项管理工作。近年来由于Internet的应用，将计算机、自动化办公设备与通信技术相结合，使办公自动化向更高层次发展。例如，电子邮件的收发、远距离会议或电视会议、高密度的电子文件、多媒体的信息处理等将会获得普遍应用。与办公自动化相应的信息管理系统是企业管理信息系统。由于信息技术的飞速发展造就了一个统一的全球市场，导致世界范围市场的激烈竞争。占领并主宰市场的关键在于如何不断开发独占性的产品，不断降低成本，以质优价廉的产品投入市场。实现这个目标离不开信息管理，通过信息的获取、分析，开发独占性产品；通过优化的信息管理，实现质优价廉产品的生产。目前世界各国的企业都充分利用信息技术与现代化管理相结合来产生最优化的生产模式、管理模式、设计技术和制造技术。在企业建立一个管理信息系统，对内完成Intranet的建立，对外实现与Internet相连。通过外部可以迅速了解市场需求和展开全球销售活动，对内可以实现物资采购、生产调度、能耗控制、质量监控等，以最少的库存、最低的能源消耗、最快的生产周期、最佳的售后服务来提高企业的竞争力，并合理地组织各类人才，做出科学的决策，实现企业利润的最大化。20世纪70年代中期，在现代工业生产领域中，已经开始利用计算机来参与产品辅助设计、产品辅助工艺设计、产品模拟样机、产品辅助制造，直至产品制造系统。到了20世纪80年代，这类计算机辅助技术(统称为CAX)有了更高速的发展，目前可以说在机械、电子、航空、船舶、汽车、纺织、服装、化工、建筑等各行各业中，CAX获得了极其广泛的应用，不仅提高了产品设计生产自动化的程度，而且给传统性的生产发展带来了革命性的变化。计算机辅助设计(ComputerAidedDesign,CAD)按设计任务书的要求,可进行各种设计方案的比较，确定产品结构、外形尺寸、材料选择、模拟组装；再对模拟整机进行各种性能测试，包括强度分析、振动分析、运动状态分析等；并任意修正，从性能的先进性、经济的合理性、加工的可行性等方面进行论证，获得最终的设计产品；然后将其分解为零件、分装部件，并给出零件图、分部装配图、总体装配图等。上述全部工作都可以由计算机来完成，大大降低了产品设计的成本，缩短了产品设计的周期，最大限度地降低了产品设计的风险。因此CAD技术已被各制造业广泛应用。目前，随着计算机软、硬件技术的发展，已经可以利用计算机实现产品创意设计，设计者可以提出一个朦胧的思想，在计算机上进行概念设计，并进行不断修改与完善，最后确定一种新颖的产品。计算机辅助制造(ComputerAidedManufacturing,CAM)是以数控机床为主体,利用存有全部加工资料的数据库(如刀具、夹具和各种零件的加工程序，以及在加工过程中的自动换刀及加工数据的控制)，实现对产品加工的自动化。目前人们已经将数控、物料流控制及存储、机器人、柔性制造、生产过程仿真等计算机相关控制技术统称为计算机辅助制造。利用计算机参与人脑的辅助工作非常普遍，而且还在不断开拓新的领域，如计算机辅助工艺规划(ComputerAidedProcessPlanning,CAPP)、计算机辅助工程(ComputerAidedEngineering,CAE)及计算机辅助教学(ComputerAssistedInstruction,CAI)等都得到越来越广泛的应用。计算机集成制造系统(ComputerIntegratedManufacturingSystem,CIMS)是利用信息技术和现代管理技术改造传统制造业、加强新兴制造业、提高企业市场竞争能力的一种生产模式。具体而言，以企业选定的产品为龙头，在产品设计过程、管理决策过程、加工制造过程、产品质量管理和控制等过程中，采用各种计算机辅助技术和先进的科学管理方法，在计算机网络和数据库的支持下，实现信息集成，进而优化企业运行，达到产品上市快、质量好、成本低、服务好的目的，以此提高产品的市场占有率和企业的市场竞争能力。显然，要形成计算机集成制造系统的企业，必须广泛地采用CAD/CAE/CAPP/CAM,并且已经建立了企业的管理信息系统(ManagementInformationSystem，MIS)，只有通过生产、经营各个环节的信息集成，支持技术集成，并由技术集成进入技术、经营管理和人员组织的集成，最终达到物流、信息流、资金流的集成并优化运行，才能提高企业的市场竞争能力和应变能力。多媒体技术是计算机技术和视频、音频及通信等技术相结合的产物。它是用来实现人和计算机交互地对各种媒体(如文字、图形、影像、音频、视频、动画等)进行采集、传输、转换、编辑、存储、管理，并由计算机综合处理为文字、图形、动画、音响、影像等视听信息而有机合成的新媒体。因此它可以将原来仅能体现或保存一种媒体的设备或手段转换为由计算机集成。例如，传统的音响设备只能录音、放音；档案库只能存档文件；图书馆只能收藏书籍；电视只能提供音频和视频信息；电话只能传递语音等。而今用多媒体技术可以使声、图、文合成后全部集成到计算机中。同时，利用计算机还可以制作、创造新的媒体信息，如合成音乐、电子动画等。它不但使社会显得格外绚丽多彩，生活显得格外富有幻想，而且会对政治、经济、军事、工业、环境等都产生巨大的影响，例如，飞行仿真训练系统、虚拟演播室等都离不开多媒体技术。它的深远意义还会影响未来计算机人工智能技术的发展。因此，有关多媒体技术的研究和应用也是当前计算机技术的热点之一。人工智能是专门研究如何使计算机来模拟人的智能的技术。尽管经过了近半个世纪的努力，被人们称为“电脑”的计算机与人脑相比，仍无法相提并论。例如，集成度达1亿个晶体管的处理器芯片仍然无法与人类的10¹¹∼10¹²个神经元相比，因为每个神经元远不是一个晶体管，很可能相当于一台高速运行的处理器。可见“电脑”要真正模拟人脑，特别是要使“电脑”具有人的经验知识以及通过联想、比拟、推断来做出决策的功能，至少从目前来看还有相当距离。尽管如此，人们还是想尽一切办法，赋予“电脑”一部分人脑的智力，并且还在不断扩大和增第2章计算机的发展及应用35强这种智力。近年来在模式识别、语音识别、专家系统和机器人制作方面都取得了很大的成就。模式识别是指对某些感兴趣的客体进行定量的或结构的描述，研究一种自动生成技术，由计算机自动地把待识别的模式分配到各自的模式类中。由此技术派生的图像处理技术和图像识别技术已被广泛应用。例如，对人体细胞显微图像分析，可确定内脏是否发生病变；对动、植物细胞显微图像分析，可确定环境是否被污染；对地表植物经遥感图像分析，可判断作物的长势等；还包括公安系统的指纹分辨及身份、证件、凭证鉴别等。文字/语音识别、语言翻译是人工智能的又一重要应用领域。自计算机问世后，人们就企图让计算机来承担文字、语言的翻译工作，实际上让计算机正确认识文字和语音，正确理解自然语言，实现正确的语言翻译还是十分困难的。虽然经过几十年的努力，目前已有了很大的进展，如手写体的计算机输入系统已被广泛使用，语音录入计算机的软件也开始在市场上问世，当然它的正确识辨率还有待进一步提高。此外，在自然语言理解的基础上研制成的文字/语言翻译机也在陆续问世，但离人们的实用要求还有一定距离，不过这些技术的突破是指日可待的，使计算机会听、会看、会说的时代已经不是很遥远了。专家系统是人工智能的另一重要应用领域。它是利用计算机构成存储量极大的知识库，把各类专家丰富的知识和经验，以数据形式存储于知识库内，通过专用软件，根据用户输入查询的要求，向用户做出所要求的解答。这种系统早已被广泛应用在医学、工程、军事、法律等领域，尤其是Internet的出现，更可以构成远程虚拟医疗、虚拟课堂、虚拟考试等。机器人的出现也是人工智能领域的一项重要应用。通常人们让机器人做一些重复性的劳动，特别是在一些不适宜人们工作的劳动场所，机器人的应用显得格外重要。例如，海底探测，人在海底的时间是非常有限的，如果让机器人进行海底探测就方便多了。可以让机器人配上摄像机，构成它的眼睛；配上双声道的声音接收器，变成它的耳朵；再配上合适的机械装置，使它可以活动、触摸、承受各种信息并直接送到计算机进行处理，这样它就可以模仿人完成海底探测。现在还有一些更高级的“智能机器人”，具有一定的感知和识别能力，还能简单地说话和回答问题。总之，随着科学技术的不断发展，更高级的机器人将会不断出现。从1946年ENIAC问世至今，70多年来计算机技术的进步推动了计算机的发展和广泛的应用，使计算机在人类的全部活动领域里占有极为重要的地位。从超级巨型机到心脏起搏器，从电话网络到汽车的汽化器无处不在，无所不及，几乎能填补甚至取代各类信息处理器，成为人类最得力的助手。世界上不少科学家预言，到了2046年人类社会几乎所有的知识和信息将全部融入于计算机空间，而任何人在任何地方任何时间都可以通过网络，对所有的知识和信息进行在线获取。这个预测是大家所希望的，也是必定会实现的。计算机空间将会为崭新的信息方式、娱乐方式和教育方式提供基础，并会提供新层次的个人服务和健康保健，最大的受益将是人们可以在远距离与他人进行全感知的交流。这种计算机应该具有类似人脑的一些超级智能，具有类似人脑的自组织、自适应、自联想、自修复的能力。人脑的这种功能要求信息处理的计算机速度至少达每秒10¹⁵，存储容量至少为10¹³字节，当然还需要相应的软件支持。倘若计算机的计算速度和存储容量达不到这个指标，那么所谓超级智能计算机只能是一种幻想。因此，尽管20世纪七八十年代，人工智能的研究曾一度出现高潮，特别是日本投入了大量的资金，做了很大的努力，但超级智能计算机的实现远比想像的要艰难得多。显然，欲实现上述目标，首当其冲的应该是努力提高处理器的主频。硅芯片微处理器主频与其集成度紧密相关，但是实现起来并非易事。其一，硅芯片的集成度又受其物理极限的制约，集成度不可能无止境地提高，当集成电路的线宽达到仅为单个分子大小的物理极限时，意味着硅芯片的集成度已到了穷途末路的境地。其二，由于硅芯片集成度提高时，其制作成本也在不断提高，即在微电子工艺发展中还遵循另一规律：“每代芯片的成本大约为前一代芯片成本的两倍”。一般来说，建造一个生产0.25μm工艺芯片的车间大约需20~25亿美元，而使用0.18μm工艺时，费用将跃升到30~40亿美元。按几何级数递增的制作成本情况发展，数年内该费用将达100亿美元，致使企业无法承受。其三，正如前述，随着集成度的提高，微处理器内部的功耗、散热、线延迟等一系列问题将难以解决。因此Intel公司工程师保罗·帕肯在近年来发表了骇人听闻的预测，认为硅芯片技术10年后将走到尽头并非偶然。尽管如此，人类对美好愿望的追求是无止境的，决不会因硅芯片的终结而放弃超级智能计算机的研制。那么究竟谁能接过传统硅芯片发展的接力棒呢?多年来，科学家们把眼光都凝聚在光计算机、生物计算机和量子计算机上，而量子计算机被寄托了极大的希望。光计算机利用光子取代电子进行运算和存储，用不同波长的光代表不同数据，可快速完成复杂计算。然而要想制造光计算机，需开发出可用一条光束控制另一条光束变化的光学晶体管。现有的光学晶体管庞大而笨拙，用其制造台式计算机将有一辆汽车那么大。因此，光计算机短期内难以进入实用阶段。DNA(脱氧核糖核酸)生物计算机是美国南加州大学阿德拉曼博士1994年提出的奇思妙想，它通过控制DNA分子间的生化反应完成运算。但目前流行的DNA计算技术必须将DNA溶于试管液体中。这种计算机由一堆装有有机液体的试管组成，虽然看起来很神奇，但很笨拙。这一问题得不到解决，DNA计算机在可预见的未来将难以取代硅芯片计算机。与前两者相比，量子计算机的前景尤为光明。量子这种常人难以理解的特性，使得具有5000个量子位的量子计算机能在约30s内解决传统硅芯片超级计算机要在100亿年才能解决的大数因子分解问题。量子计算机是利用原子所具有的量子特性进行信息处理的一种全新概念的计算机。原子会旋转，而且不是向上就是向下，正好与数位科技的“0”与“1”完全吻合。既然原子可以同时向上并向下旋转，如果把一群原子聚在一起，它们不会像现在的计算机进行线性运算，而是可以同时第2章计算机的发展及应用37进行所有可能的运算。只要有40个原子一起计算，就可达到相当于现在一部超级计算机的同等性能。专家们认为，如果有一个包含全球电话号码的资料库，找出一个特定的电话号码，一部量子计算机只要27min，而同样的工作交付给10台IBM“深蓝”超级计算机同时运作，也至少需要几个月的时间才能完成。量子计算机以处于量子状态的原子作为中央处理器和内存，其运算能力比目前的硅芯片为电路基础的传统计算机要快几亿倍。当利用高速运行的量子计算机后，再结合现代计算机采用高并行度的体系结构，通过大量高速处理器的高宽带局域网的连接，使它具有类似人脑的高并行性的本质。预计人类级的智能所需的硬件可能在21世纪的前1/4的时间内实现，与20世纪70年代只够得上“昆虫级”智能的计算机硬件能力相比，显然人们对超级智能计算机的研制更充满信心。超级智能计算机不仅需要有硬件支撑，而且还必须有软件支持。模拟大脑功能创建超级智能计算机，除了通过足够的硬件能力和适应计算机学习的软件外，还需有足够的初始体系结构和丰富的感官输入流。当前的技术对后者已经很容易满足，如采用视觉照相机、扬声器和各类触觉传感器，能保证特定的实时世界信息流流入计算机。而前者则更难实现，因为大脑并非一开始就是一片空白。它有一个遗传可编码的初始结构，存在着神经皮层可塑性、大脑皮层的相似性及进化的论点。这些问题的解决必须随着神经科学的进一步发展，在对人脑的神经结构和它的学习算法了解得足够多的前提下，在具有很强计算能力的计算机上实现复制。科学家估计大约在今后10多年内，采用当前的设备支持输入输出渠道，对人脑继续研究，发现新的计算机学习方法和对新神经科学的深入研究，超级智能计算机的出现是势不可挡的必然趋势，只是时间问题。21世纪除了人们继续追求超级智能计算机的问世外，更引起人们注目的是价格低廉、使用方便、体积更小、外形多变、具有人性化的计算机的研究和应用。虽然计算机强大的功能使它能处理相当多的事务，但至今还存在不尽如人意的缺点。因此，普及面仍未达到应有的程度。其原因主要在于对绝大多数人而言，还不能非常方便地对它进行操作，而且很难适应各种场合的需要。因此，除了继续提高芯片主频外，在输入输出方式上应有更多的性能突破。输入输出方式将更多样化和更人性化。除了手写分辨率和速度进一步提高外，语音输入输出将随时可见，包括汽车、家电、电话、电视、玩具、手表等。而且还可用人的手势、表情、眼睛瞳孔的位置，甚至利用人体的气味、体温来控制输入。三维图像输出将能实时地合成真实的视频图像，包括完整的戏剧电影，还允许计算机合成的图像和人面对面交谈。平面液晶显示器将可以像眼镜一般戴在脸上，构成可移动的计算机。计算机的外形及尺寸大小将随着不同的对象和环境而变化，甚至朝着个人化量体定做的方向发展。特别是嵌入式的计算机，可以遍及汽车、房间、车站、机场及各种建筑场，使用者利用随身携带的信息操作器具，无须做任何连接方式，利用红外线传输方式，随时从公共场所服务器主机上接收所需的信息，包括个人的电子邮件等。尤其是个人身上穿戴的计算机连同身上网络，可以随时随地照顾用户健康、安全，并帮助用户在复杂的物理空间环境中工作，如汽车、飞机驾驶等。在普及型的计算机发展同时，大型系统也将获得巨大发展，将来由低价、通用的多处理机组成的群机系统来替代单一的大型系统。在这个群机系统中，每个计算机通过快速的系统级网络(SAN)和其他计算机通信。群机系统可以扩展到上千个结点，对于数据库和即时事务处理(OLTP)的应用，群机能像单机一样运转。群机能开发隐含在处理并行多用户中或在处理包含在多个存储设备的大型查询中的并行性。一个具有几十个结点的PC群机系统，每天可执行10亿多次事务处理，比目前最大的大型机吞吐量还大。科学计算将在高度专用、类似CRAY的多向量结构的计算机上运行。前面提到的网络带宽问题，到2046年，每光波长携带几个GB的光纤将会很普遍地进入广大家庭用户中，那时带宽将不再是问题。它们将为电话、可视电话、电视、网络访问、安全监控、家庭能源管理以及其他各种设备服务。虽然不能对未来的计算机预知得那么清晰、那么准确，但是，仅就上述的描述，也就可以想象几十年后，计算机给人类带来的绚丽多彩的生活和人类社会的美好憧憬绝不是幻想。计算机硬件系统由中央处理器、存储器、I/O系统以及连接它们的系统总线组成。本篇介绍系统总线、存储器和I/O系统三部分，中央处理器将在第3篇单独讲述。计算机系统的五大部件之间的互连方式有两种，一种是各部件之间使用单独的连线，称为分散连接；另一种是将各部件连到一组公共信息传输线上，称为总线连接。早期的计算机大多数用分散连接方式，如图1.7所示。它是以运算器为中心的结构，其内部连线十分复杂，尤其是当I/O与存储器交换信息时，都需经过运算器，致使运算器停止运算，严重影响了CPU的工作效率。后来，虽然改进为以存储器为中心的如图1.8所示的分散连接结构，I/O与主存交换信息可以不经过运算器，又采用了中断、DMA等技术，使CPU工作效率得到很大的提高，但是仍无法解决I/O设备与主机之间连接的灵活性。随着计算机应用领域的不断扩大，I/O设备的种类和数量也越来越多，人们希望随时增添或减撤设备，用分散连接方式简直是一筹莫展，由此出现了总线连接方式。总线是连接多个部件的信息传输线，是各部件共享的传输介质。当多个部件与总线相连时，如果出现两个或两个以上部件同时向总线发送信息，势必导致信号冲突，传输无效。因此，在某一时刻，只允许有一个部件向总线发送信息，而多个部件可以同时从总线上接收相同的信息。总线实际上是由许多传输线或通路组成，每条线可一位一位地传输二进制代码，一串二进制代码可在一段时间内逐一传输完成。若干条传输线可以同时传输若干位二进制代码，例如，16条传输线组成的总线可同时传输16位二进制代码。采用总线连接的计算机结构，如图3.1所示，它是以CPU为中心的双总线结构。其中一组总线连接CPU和主存，称为存储总线(M总线)；另一组用来建立CPU和各I/O设备之间交换信息的通道，称为输入输出总线(I/O总线)。各种I/O设备通过I/O接口挂到I/O总线上，更便于增删设备。这种结构在I/O设备与主存交换信息时仍然要占用CPU，因此还会影响CPU的工作效率。倘若将CPU、主存和I/O设备(通过I/O接口)都挂到一组总线上，便形成单总线结构的计算机,如图3.2所示。图3.2与图3.1相比，最明显的特点是当I/O设备与主存交换信息时，原则上不影响CPU的工作，CPU仍可继续处理不访问主存或I/O设备的操作，这就使CPU工作效率有所提高。但是，因只有一组总线，当某一时刻各部件都要占用总线时，就会发生冲突。为此，必须设置总线判优逻辑，让各部件按优先级高低来占用总线，这也会影响整机的工作速度。PDP-11和国产DJS183机均采用这种结构。还有一种以存储器为中心的双总线结构，如图3.3所示。它是在单总线基础上又开辟出的一条CPU与主存之间的总线，称为存储总线。这组总线速度高，只供主存与CPU之间传输信息。这样既提高了传输效率，又减轻了系统总线的负担，还保留了I/O设备与存储器交换信息时不经过CPU的特点。国产DJS184机采用这种结构。现代计算机大多数采用各类总线结构。总线的应用很广泛，从不同角度可以有不同的分类方法。按数据传送方式可分为并行传输总线和串行传输总线。在并行传输总线中，又可按传输数据宽度分为8位、16位、32位、64位等传输总线。若按总线的使用范围划分，则又有计算机(包括外设)总线、测控总线、网络通信总线等。下面按连接部件不同，介绍三类总线。片内总线是指芯片内部的总线，如在CPU芯片内部，寄存器与寄存器之间、寄存器与算逻单元ALU之间都由片内总线连接。系统总线是指CPU、主存、I/O设备(通过I/O接口)各大部件之间的信息传输线。由于这些部件通常都安放在主板或各个插件板(插卡)上，故又称板级总线(在一块电路板上各芯片间的连线)或板间总线。按系统总线传输信息的不同，又可分为三类：数据总线、地址总线和控制总线。数据总线用来传输各功能部件之间的数据信息，它是双向传输总线，其位数与机器字长、存储字长有关，一般为8位、16位或32位。数据总线的位数称为数据总线宽度，它是衡量系统性能的一个重要参数。如果数据总线的宽度为8位，指令字长为16位，那么，CPU在取指阶段必须两次访问主存。地址总线主要用来指出数据总线上的源数据或目的数据在主存单元的地址或I/O设备的地址。例如，欲从存储器读出一个数据，则CPU要将此数据所在存储单元的地址送到地址线上。又如，欲将某数据经I/O设备输出，则CPU除了需将数据送到数据总线外，还需将该输出设备的地址(通常都经I/O接口)送到地址总线上。可见，地址总线上的代码是用来指明CPU欲访问的存储单元或I/O端口的地址，由CPU输出，单向传输。地址线的位数与存储单元的个数有关，如地址线为20根，则对应的存储单元个数为220。由于数据总线、地址总线都是被挂在总线上的所有部件共享的，如何使各部件能在不同时刻占有总线使用权，需依靠控制总线来完成，因此控制总线是用来发出各种控制信号的传输线。通常对任一控制线而言，它的传输是单向的。例如，存储器读/写命令或I/O设备读/写命令都是由CPU发出的。但对于控制总线总体来说，又可认为是双向的。例如，当某设备准备就绪时，便向CPU发中断请求；当某部件(如DMA接口)需获得总线使用权时，也向CPU发出总线请求。此外，控制总线还起到监视各部件状态的作用。例如，查询该设备是处于“忙”还是“闲”，是否出错等。因此对CPU而言，控制信号既有输出，又有输入。常见的控制信号如下。时钟：用来同步各种操作。复位：初始化所有部件。总线请求：表示某部件需获得总线使用权。总线允许：表示需要获得总线使用权的部件已获得了控制权。中断请求：表示某部件提出中断请求。中断响应：表示中断请求已被接收。存储器写：将数据总线上的数据写至存储器的指定地址单元内。存储器读：将指定存储单元中的数据读到数据总线上。·I/O读：从指定的I/O端口将数据读到数据总线上。·I/O写：将数据总线上的数据输出到指定的I/O端口内。·传输响应：表示数据已被接收，或已将数据送至数据总线上。这类总线用于计算机系统之间或计算机系统与其他系统(如控制仪表、移动通信等)之间的通信。由于这类联系涉及许多方面，如外部连接、距离远近、速度快慢、工作方式等，差别极大，因此通信总线的类别很多。但按传输方式可分为两种：串行通信和并行通信。串行通信是指数据在单条1位宽的传输线上，一位一位地按顺序分时传送。如1字节的数据，在串行传送中，1字节的数据要通过一条传输线分8次由低位到高位按顺序逐位传送。并行通信是指数据在多条并行1位宽的传输线上，同时由源传送到目的地。如1字节的数据，在并行传送中，要通过8条并行传输线同时由源传送到目的地。并行通信适宜于近距离的数据传输，通常小于30m；串行通信适宜于远距离传送，可以从几米到数千千米。而且，串行和并行通信的数据传送速率都与距离成反比。在短距离内，并行数据传送速率比串行数据传送速率高得多。随着大规模和超大规模集成电路的发展，逻辑器件的价格趋低，而通信线路费用趋高，因此对远距离通信而言，采用串行通信费用远比并行通信费用低得多。此外串行通信还可利用现有的电话网络来实现远程通信，降低了通信费用。从物理角度来看，总线由许多导线直接印制在电路板上，延伸到各个部件。图3.4形象地表示了各个部件与总线之间的物理摆放位置。图中CPU、主存、I/O这些插板(又称插卡)通过插头与水平方向总线插槽(按总线标准用印刷电路板或一束电缆连接而成的多头插座)连接。为了保证机械上的可靠连接，必须规定其机械特性；为了确保电气上正确连接，必须规定其电气特性；为保证正确地连接不同部件，还需规定其功能特性和时间特性。随着计算机的发展，PentiumⅢ以上的微型计算机已将CPU芯片直接安置在主板上，而且很多插卡已做成专用芯片，减少了插槽，使其结构更合理。总线特性包括以下几项。机械特性是指总线在机械连接方式上的一些性能，如插头与插座使用的标准，它们的几何尺寸、形状、引脚的个数以及排列的顺序，接头处的可靠接触等。电气特性是指总线的每一根传输线上信号的传递方向和有效的电平范围。通常规定由CPU发出的信号称为输出信号，送入CPU的信号称为输入信号。例如，地址总线属于单向输出线，数据总线属于双向传输线，它们都定义为高电平为“1”，低电平为“0”。控制总线的每一根都是单向的，但从整体看，有输入，也有输出。有的定义为高电平有效，也有的定义为低电平有效，必须注意不同的规格。大多数总线的电平定义与TTL是相符的，也有例外，如RS-232C(串行总线接口标准)，其电气特性规定低电平表示逻辑“1”，并要求电平低于-3V；用高电平表示逻辑“0”,还要求高电平需高于+3V,额定信号电平为-10V和+10V左右。功能特性是指总线中每根传输线的功能，例如，地址总线用来指出地址码；数据总线用来传递数据；控制总线发出控制信号，既有从CPU发出的，如存储器读/写、I/O设备读/写，也有I/O设备向CPU发来的，如中断请求、DMA请求等。由此可见，各条线的功能不同。时间特性是指总线中的任一根线在什么时间内有效。每条总线上的各种信号互相存在一种有效时序的关系，因此，时间特性一般可用信号时序图来描述。总线性能指标如下。①总线宽度:通常是指数据总线的根数,用bit(位)表示,如8位、16位、32位、64位(即8根、16根、32根、64根)。②总线带宽：总线带宽可理解为总线的数据传输速率，即单位时间内总线上传输数据的位数，通常用每秒传输信息的字节数来衡量，单位可用MBps(兆字节每秒)表示。例如，总线工作频率为33MHz,总线宽度为32位(4B),则总线带宽为33×(32÷8)=132MBps。③时钟同步/异步：总线上的数据与时钟同步工作的总线称为同步总线，与时钟不同步工作的总线称为异步总线。④总线复用：一条信号线上分时传送两种信号。例如，通常地址总线与数据总线在物理上是分开的两种总线，地址总线传输地址码，数据总线传输数据信息。为了提高总线的利用率，优化设计，特将地址总线和数据总线共用一组物理线路，在这组物理线路上分时传输地址信号和数据信号，即为总线的多路复用。⑤信号线数：地址总线、数据总线和控制总线三种总线数的总和。⑥总线控制方式：包括突发工作、自动配置、仲裁方式、逻辑方式、计数方式等。⑦其他指标：如负载能力、电源电压(是采用5V还是3.3V)、总线宽度能否扩展等。总线的负载能力即驱动能力，是指当总线接上负载后，总线输入输出的逻辑电平是否能保持在正常的额定范围内。例如，PC总线的输出信号为低电平时，要吸入电流，这时的负载能力即指当它吸收电流时，仍能保持额定的逻辑低电平。总线输出为高电平时，要输出电流，这时的负载能力是指当它向负载输出电流时，仍能保持额定的逻辑高电平。由于不同的电路对总线的负载是不同的，即使同一电路板在不同的工作频率下，总线的负载也是不同的，因此，总线负载能力的指标不是太严格的。通常用可连接扩增电路板数来反映总线的负载能力。表3.1列出了几种流行的微机总线性能，可供参考。总线是在计算机系统模块化的发展过程中产生的，随着计算机应用领域的不断扩大，计算机系统中各类模块(特别是I/O设备所带的各类接口模块)品种极其繁杂，往往一种模块要配一种总线，很难在总线上更换、组合各类模块或设备。20世纪70年代末，为了使系统设计简化，模块生产批量化，确保其性能稳定、质量可靠，实现可移化，便于维护等，人们开始研究如何使总线建立标准，在总线的统一标准下，完成系统设计、模块制作。这样，系统、模块、设备与总线之间不适应、不通用及不匹配的问题就迎刃而解了。所谓总线标准，可视为系统与各模块、模块与模块之间的一个互连的标准界面。这个界面对它两端的模块都是透明的，即界面的任一方只需根据总线标准的要求完成自身一方接口的功能要求，而无须了解对方接口与总线的连接要求。因此，按总线标准设计的接口可视为通用接口。采用总线标准可以为计算机接口的软硬件设计提供方便。对硬件设计而言，使各个模块的接口芯片设计相对独立；对软件设计而言，更有利于接口软件的模块化设计。目前流行的总线标准有以下几种。ISA(IndustrialStandardArchitecture)总线是IBM为了采用全16位的CPU而推出的,又称AT总线，它使用独立于CPU的总线时钟，因此CPU可以采用比总线频率更高的时钟，有利于CPU性能的提高。由于ISA总线没有支持总线仲裁的硬件逻辑，因此它不能支持多台主设备(不支持多台具有申请总线控制权的设备)系统，而且ISA上的所有数据的传送必须通过CPU或DMA(直接存储器存取)接口来管理，因此使CPU花费了大量时间来控制与外部设备交换数据。ISA总线时钟频率为8MHz,最大传输率为16MBps,数据线为16位,地址线为24位。EISA(ExtendedIndustrialStandardArchitecture)是一种在ISA基础上扩充开放的总线标准,与ISA可以完全兼容，从CPU中分离出了总线控制权，是一种具有智能化的总线，能支持多个总线主控器和突发方式(总线上可进行成块的数据传送)的传输。EISA总线的时钟频率为8MHz，最大传输率可达33MBps，数据总线为32位，地址总线为32位，扩充DMA访问范围达2³°。VESA总线是由VESA(VideoElectronicStandardAssociation,视频电子标准协会)提出的局部总线标准，又称为VL-BUS(LocalBUS)总线。所谓局部总线，是指在系统外为两个以上模块提供的高速传输信息通道。VL-BUS是由CPU总线演化而来的,采用CPU的时钟频率达33MHz、数据线为32位，可通过扩展槽扩展到64位，配有局部控制器，最大传输率达133MBps。通过局部总线控制器，将高速I/O设备直接挂在CPU上，实现CPU与高速I/O设备之间的高速数据交换(参见图3.12)。随着图形用户界面(GraphicalUserInterface,GUI)和多媒体技术在PC系统中的广泛应用,ISA总线和EISA总线由于受带宽的限制，已不能适应系统工作的要求，成为整个系统的主要瓶颈。因此对总线提出了更高的性能要求，促使总线技术进一步发展。1991年下半年,Intel公司首先提出PCI(PeripheralComponentInterconnect,外围部件互连)总线的概念,并联合IBM、Compaq、Apple、DEC、AST、HP等计算机业界大户,成立了PCI集团PCISIG(PCISpecialInterestGroup,PCI专门权益组织),于1992年6月22日推出了PCI1.0版,1995年和1999年又先后推出了2.1版和2.2版，PCI总线已成为现代计算机中最常用的总线之一，它的主要特点如下所述。①高性能。PCI总线是一种不依附于某个具体处理器的局部总线。它为系统提供了一个高速的数据传输通道，与CPU时钟频率无关，自身采用33MHz和66MHz的总线时钟，数据线为32位,可扩展到64位,传输速率从132MBps(33MHz时钟,32位数据通路)可升级到528MBps(66MHz时钟，64位数据通路)。它支持突发工作方式，这种方式是指若被传送的数据在主存中连续存放，则在访问此组数据时，只需给出第一个数据的地址，占用一个时钟周期，其后每个数据的传送各占一个时钟周期，不必每次给出各个数据的地址，因此可提高传输速率。②良好的兼容性。PCI总线部件和插件接口相对于处理器是独立的，它支持所有的目前和将来不同结构的处理器，因此具有相对长的生命周期。PCI总线与ISA、EISA总线均可兼容，可以转换为标准的ISA、EISA。③支持即插即用(PlugandPlay)，即任何扩展卡只要插入系统便可工作。PCI设备中配有存放设备具体信息的寄存器，这些信息可供BIOS(基本输入输出系统)和操作系统层的软件自动配置PCI总线部件和插件，使系统使用方便，无须进行复杂的手动配置。④支持多主设备能力。主设备即对总线有控制权的设备，PCI支持多主设备，即允许任何主设备和从设备(对总线没有控制权的设备)之间实现点到点对等存取，体现了接纳设备的高度灵活性。⑤具有与处理器和存储器子系统完全并行操作的能力。PCI总线可视为CPU与外设之间的一个中间层，它通过PCI桥路(PCI控制器)与CPU相连。PCI桥路有多级缓冲，可把一批数据快速写入缓冲器中，在这些数据不断写入PCI设备过程中，可真正实现与处理器/存储器子系统的安全并发工作。⑥提供数据和地址奇偶校验功能，保证了数据的完整和准确。⑦支持两种电压标准:5V和3.3V。3.3~5V的组件技术可以使电压平滑过渡。3.3V电压的PCI总线可用于便携式微型计算机中。⑧可扩充性好。当PCI总线驱动能力不足时，可以采用多层结构(参见图3.14)。⑨软件兼容性好。PCI部件可以完全兼容现有的驱动程序和应用程序。设备驱动程序可被移植到各类平台上。⑩采用多路复用技术，减少了总线引脚个数。上述各类总线的实例将在3.4.3节中介绍。随着网络的高速发展以及其他周边设备的技术革新，诸如千兆网卡之类的设备对PCI总线提出了更高要求。Intel公司近年来又推出了PCI-Express总线，它采用了类似网络传输TCP/IP协议的分层结构和数据帧逐层传递的模式。有关这方面的内容，读者可进一步查找相关资料。随着多媒体计算机的普及，对三维技术的应用也越来越广。处理三维数据不仅要求有惊人的数据量，而且要求有更宽广的数据传输带宽。例如，对640×480像素的分辨率而言，以每秒75次画面更新率计算，要求全部的数据带宽达370MBps；若分辨率提高到800×600像素时，总带宽高达580MBps。因此PCI总线成为传输瓶颈。为了解决此问题,Intel公司于1996年7月又推出了AGP(AcceleratedGraphicsPort,加速图形端口),这是显示卡专用的局部总线,基于PCI2.1版规范并进行扩充修改而成，它采用点对点通道方式，以66.7MHz的频率直接与主存联系，以主存作为帧缓冲器，实现了高速存取。最大数据传输率(数据宽度为32位)为266MBps，是传统PCI总线带宽的2倍。AGP还定义了一种“双激励”(DoublePumping)的传输技术,能在一个时钟的上、下沿双向传递数据，这样，AGP实现的传输频率为66.7MHz×2，即133MHz，最大数据传输率可增为533MBps。后来又依次推出了AGP2X,AGP4X,AGP8X多个版本,数据传输速率可达2.1GBps。RS-232C(RS即RecommendedStandard的缩写,232为标识号,C表示修改次数)是由美国电子工业协会EIA(ElectronicIndustriesAssociation)推荐的一种串行通信总线标准,它是应用于串行二进制交换的数据终端设备(DTE)和数据通信设备(DCE)之间的标准接口，如图3.5所示。在图3.5中,DTE(DataTerminalEquipment)是数据终端设备,它是产生二进制信号的数据源，也是接收信息的目的地，是由数据发生器或接收器或兼具两者组成的设备，它可以是一台计算机。DCE(DataCommunicationEquipment)是数据通信设备,它实质是一个信号的匹配器,既能满足DTE的要求，又能使传输信号符合线路要求。它具有提供数据终端设备与通信线路之间通信的建立、维持和终止连接等功能，同时还执行信号变换与编码。它可以是一个Modem(调制解调器)。DTE与DCE之间传输的是“0”或“1”的数据,通过RS-232C接口规定的各种控制信号,可实现两者之间的协调配合。众所周知，计算机之间通信传送的是数字信号，它要求传送的频带很宽，而计算机远程通信通常是通过载波电话传送的，不可能有这样宽的频带。如果数字信号直接进行通信，经过传输线后，必然会产生畸变。因此在发送端必须通过调制器将数字信号转换成模拟信号，即对载波电话线上载波进行调制；而在接收端又必须用解调器检出从发送端来的模拟信号，并恢复为原来的数字信号。值得注意的是：RS-232C规定的逻辑电平与计算机系统中TTL和MOS电平不一样。在计算机系统中，以+5V代表逻辑“1”，接地电压代表逻辑“0”。而RS-232C的电气特征规定低电平表示逻辑“1”,并要求低电平为-15~-3V;用高电平表示逻辑“0”,并要求高电平为+3~+15V,因此使用RS-232C时，必须实现两种电平的转换。随着计算机网络的发展，现代计算机之间的远距离通信可直接由网卡经网线(8根，双绞线)传输。USB(UniversalSerialBus)通用串行总线是Compaq、DEC、IBM、Intel、Microsoft、NEC(日本)和NorthernTelecom(加拿大)等七大公司于1994年11月联合开发的计算机串行接口总线标准,1996年1月颁布了USB1.0版本。它基于通用连接技术，实现外设的简单快速连接，达到方便用户、降低成本、扩展PC接连外设范围的目的。用户可以将几乎所有的外设装置，包括显示器、键盘、鼠标、打印机、扫描仪、数码相机、U盘、调制解调器等直接插入标准USB插口。还可以将一些USB外设进行串接，使一大串设备共用PC上的端口。它的主要特点是：①具有真正的即插即用特征。用户可以在不关机的情况下很方便地对外设实行安装和拆卸，主机可按外设的增删情况自动配置系统资源，外设装置驱动程序的安装、删除均自动实现。②具有很强的连接能力。使用USBHUB(USB集线器)实现系统扩展，最多可链式连接127个外设到同一系统。图3.6是典型的USB系统拓扑结构。标准USB电缆长度为3m，低速传输方式时可为5m，通过HUB或中继器可使传输距离达30m。③数据传输率(USB1.0版)有两种，即采用普通无屏蔽双绞线，速度可达1.5Mbps，若用带屏蔽的双绞线,速度可达12Mbps。USB2.0版的数据传输率最高可达480Mbps。④标准统一。USB的引入减轻了对目前PC中所有标准接口的需求，如串口的鼠标、键盘，并口的打印机、扫描仪，IDE接口的硬盘，都可以改成以统一的USB标准接入系统，从而减少了对PC插槽的需求，节省空间。⑤连接电缆轻巧，电源体积缩小。USB使用的4芯电缆中的2条用于信号连接，2条用于电源/地，可为外设提供+5V的直流电源，方便用户。⑥生命力强。USB是一种开放性的不具有专利版权的工业标准，它是由一个标准化组织“USB实施者论坛”(该组织由150多家企业组成)制定出来的，因此不存在专利版权问题，USB规范具有强大的生命力。总线结构通常可分为单总线结构和多总线结构两种。图3.2是单总线结构的示意，它是将CPU、主存、I/O设备(通过I/O接口)都挂在一组总线上，允许I/O设备之间、I/O设备与CPU之间或I/O设备与主存之间直接交换信息。这种结构简单，也便于扩充，但所有的传送都通过这组共享总线，因此极易形成计算机系统的瓶颈。它也不允许两个以上的部件在同一时刻向总线传输信息，这就必然会影响系统工作效率的提高。这类总线多数被小型计算机或微型计算机所采用。随着计算机应用范围不断扩大，其外部设备的种类和数量越来越多，它们对数据传输数量和传输速度的要求也就越来越高。倘若仍然采用单总线结构，那么，当I/O设备量很大时，总线发出的控制信号从一端逐个顺序地传递到第n个设备，其传播的延迟时间就会严重地影响系统的工作效率。在数据传输需求量和传输速度要求不太高的情况下，为克服总线瓶颈问题，尽可能采用增加总线宽度和提高传输速率来解决；但当总线上的设备，如高速视频显示器、网络传输接口等，其数据量很大和传输速度要求相当高的时候，单总线结构则不能满足系统工作的需要。因此，为了根本解决数据传输速率，解决CPU、主存与I/O设备之间传输速率的不匹配，实现CPU与其他设备相对同步，不得不采用多总线结构。双总线结构的特点是将速度较低的I/O设备从单总线上分离出来，形成主存总线与I/O总线分开的结构。图中通道是一个具有特殊功能的处理器，CPU将一部分功能下放给通道，使其对I/O设备具有统一管理的功能，以完成外部设备与主存储器之间的数据传送，其系统的吞吐能力可以相当大。这种结构大多用于大、中型计算机系统。如果将速率不同的I/O设备进行分类，然后将它们连接在不同的通道上，那么计算机系统的工作效率将会更高，由此发展成多总线结构。图3.8中主存总线用于CPU与主存之间的传输；I/O总线供CPU与各类I/O设备之间传递信息；DMA总线用于高速I/O设备(磁盘、磁带等)与主存之间直接交换信息。在三总线结构中，任一时刻只能使用一种总线。主存总线与DMA总线不能同时对主存进行存取，I/O总线只有在CPU执行I/O指令时才能用到。图3.9是另一种三总线结构的示意图。由图可见，处理器与Cache(详见4.3节)之间有一条局部总线，它将CPU与Cache或与更多的局部设备连接。Cache的控制机构不仅将Cache连到局部总线上，而且还直接连到系统总线上，这样Cache就可通过系统总线与主存传输信息，而且I/O设备与主存之间的传输也不必通过CPU。还有一条扩展总线，它将局域网、小型计算机接口(SCSI)、调制解调器(Modem)以及串行接口等都连接起来，并且通过这些接口又可与各类I/O设备相连，因此它可支持相当多的I/O设备。与此同时，扩展总线又通过扩展总线接口与系统总线相连，由此便可实现这两种总线之间的信息传递，可见其系统的工作效率明显提高。为了进一步提高I/O设备的性能，使其更快地响应命令，又出现了四总线结构，如图3.10所示。在这里又增加了一条与计算机系统紧密相连的高速总线。在高速总线上挂接了一些高速I/O设备，如高速局域网、图形工作站、多媒体、SCSI等。它们通过Cache控制机构中的高速总线桥或高速缓冲器与系统总线和局部总线相连，使得这些高速设备与CPU更密切。而一些较低速的设备如图文传真FAX、调制解调器及串行接口仍然挂在扩展总线上，并由扩展总线接口与高速总线相连。这种结构对高速设备而言，其自身的工作可以很少依赖CPU，同时它们又比扩展总线上的设备更贴近CPU，可见对于高性能设备与CPU来说，各自的效率将获得更大的提高。在这种结构中，CPU、高速总线的速度以及各自信号线的定义完全可以不同，以至各自改变其结构也不会影响高速总线的正常工作，反之亦然。由图3.11中可见，不论高速局域网、高性能图形还是低速的FAX、Modem都挂接在ISA或EISA总线上，并通过ISA或EISA总线控制器与系统总线相连，这样势必出现总线数据传输的瓶颈。只有将高速、高性能的外设，如高速局域网卡、高性能图形卡等尽量靠近CPU本身的总线，并与CPU同步或准同步，才可能消除瓶颈问题。这就要求改变总线结构来提高数据传送速率，为此，出现了图3.12的VL-BUS局部总线结构。由图3.12中可见，将原先挂在ISA总线上的高速局域网卡、多媒体卡、高性能图形卡等从ISA总线卸下来，挂到局部总线VL-BUS上，再与系统总线相连。而将打印机、FAX、Modem等低速设备仍挂在ISA总线上。局部总线VL-BUS就相当于在CPU与高速I/O设备之间架上了高速通道，使CPU与高性能外设得到充分发挥，满足了图形界面软件的要求。由于VL-BUS是从CPU总线演化而来的，与CPU的关系太紧密(实际上这种总线与486配合最佳)，以致很难支持功能更强的CPU，因此出现了PCI总线。由图3.13可见,PCI总线是通过PCI桥路(包括PCI控制器和PCI加速器)与CPU总线相连。这种结构使CPU总线与PCI总线互相隔离，具有更高的灵活性，可以支持更多的高速运行设备，而且具有即插即用的特性。当然，挂在PCI总线上的设备都要求数据传输速率高的设备，如多媒体卡、高速局域网适配器、高性能图形卡等，与高速CPU总线是相匹配的。至于低速的FAX、Modem、打印机仍然挂在ISA、EISA总线上。当PCI总线驱动能力不足时，可采用多层结构，如图3.14所示。由于总线上连接着多个部件，什么时候由哪个部件发送信息，如何给信息传送定时，如何防止信息丢失，如何避免多个部件同时发送，如何规定接收信息的部件等一系列问题都需要由总线控制器统一管理。它主要包括判优控制(或称仲裁逻辑)和通信控制。总线上所连接的各类设备，按其对总线有无控制功能可分为主设备(模块)和从设备(模块)两种。主设备对总线有控制权，从设备只能响应从主设备发来的总线命令，对总线没有控制权。总线上信息的传送是由主设备启动的，如某个主设备欲与另一个设备(从设备)进行通信时，首先由主设备发出总线请求信号，若多个主设备同时要使用总线时，就由总线控制器的判优、仲裁逻辑按一定的优先等级顺序确定哪个主设备能使用总线。只有获得总线使用权的主设备才能开始传送数据。总线判优控制可分集中式和分布式两种，前者将控制逻辑集中在一处(如在CPU中)，后者将控制逻辑分散在与总线连接的各个部件或设备上。常见的集中控制优先权仲裁方式有以下三种。(1)链式查询链式查询方式如图3.15(a)所示。图中控制总线中有3根线用于总线控制(BS总线(2)计数器定时查询计数器定时查询方式如图3.15(b)所示。与图3.15(a)相比，多了一组设备地址线，少了一根总线同意线BG。总线控制部件接到由BR送来的总线请求信号后，在总线未被使用((BS=0)第3章系统总线59的情况下，总线控制部件中的计数器开始计数，并通过设备地址线，向各设备发出一组地址信号。当某个请求占用总线的设备地址与计数值一致时，便获得总线使用权，此时终止计数查询。这种方式的特点是：计数可以从“0”开始，此时一旦设备的优先次序被固定，设备的优先级就按0，1，…，n的顺序降序排列，而且固定不变；计数也可以从上一次计数的终止点开始，即是一种循环方法，此时设备使用总线的优先级相等；计数器的初始值还可由程序设置，故优先次序可以改变。这种方式对电路故障不如链式查询方式敏感，但增加了控制线(设备地址)数，控制也较复杂。(3)独立请求方式独立请求方式如图3.15(c)所示。由图中可见，每一台设备均有一对总线请求线BRᵢ和总线同意线BGf。当设备要求使用总线时，便发出该设备的请求信号。总线控制部件中有一排队电路，可根据优先次序确定响应哪一台设备的请求。这种方式的特点是：响应速度快，优先次序控制灵活(通过程序改变)，但控制线数量多，总线控制更复杂。链式查询中仅用两根线确定总线使用权属于哪个设备，在计数器查询中大致用log₂n根线，其中n是允许接纳的最大设备数，而独立请求方式需采用2n根线。众多部件共享总线，在争夺总线使用权时，应按各部件的优先等级来解决。在通信时间上，则应按分时方式来处理，即以获得总线使用权的先后顺序分时占用总线，即哪一个部件获得使用权，此刻就由它传送，下一部件获得使用权，接着下一时刻传送。这样一个接一个轮流交替传送。通常将完成一次总线操作的时间称为总线周期，可分为以下4个阶段。①申请分配阶段：由需要使用总线的主模块(或主设备)提出申请，经总线仲裁机构决定下一传输周期的总线使用权授于某一申请者。②寻址阶段：取得了使用权的主模块通过总线发出本次要访问的从模块(或从设备)的地址及有关命令，启动参与本次传输的从模块。③传数阶段：主模块和从模块进行数据交换，数据由源模块发出，经数据总线流入目的模块。④结束阶段：主模块的有关信息均从系统总线上撤除，让出总线使用权。对于仅有一个主模块的简单系统，无须申请、分配和撤除，总线使用权始终归它占有。对于包含中断、DMA控制或多处理器的系统，还需要有其他管理机构来参与。总线通信控制主要解决通信双方如何获知传输开始和传输结束，以及通信双方如何协调如何配合。通常用四种方式：同步通信、异步通信、半同步通信和分离式通信。通信双方由统一时标控制数据传送称为同步通信。时标通常由CPU的总线控制部件发出，送到总线上的所有部件；也可以由每个部件各自的时序发生器发出，但必须由总线控制部件发出的时钟信号对它们进行同步。图3.16表示某个输入设备向CPU传输数据的同步通信过程。图中总线传输周期是连接在总线上的两个部件完成一次完整且可靠的信息传输时间，它包含4个时钟周期T₁、T₂、T₃、T₄。CPU在T₁上升沿发出地址信息；在T₂的上升沿发出读命令；与地址信号相符合的输入设备按命令进行一系列内部操作，且必须在T₃的上升沿到来之前将CPU所需的数据送到数据总线上；CPU在T₃时钟周期内，将数据线上的信息送到其内部寄存器中；CPU在T₄的上升沿撤销读命令，输入设备不再向数据总线上传送数据，撤销它对数据总线的驱动。如果总线采用三态驱动电路，则从T₄起，数据总线呈浮空状态。同步通信在系统总线设计时，对T₁、T₂、T₃、T₄都有明确、唯一的规定。对于读命令，其传输周期如下：T₁主模块发地址。T₂主模块发读命令。T₃从模块提供数据。T₄主模块撤销读命令，从模块撤销数据。对于写命令，其传输周期如下：T₁主模块发地址。T_{1.5}主模块提供数据。T₂主模块发出写命令，从模块接收到命令后，必须在规定时间内将数据总线上的数据写到地址总线所指明的单元中。T₄主模块撤销写命令和数据等信号。写命令传输周期的时序如图3.17所示。这种通信的优点是规定明确、统一，模块间的配合简单一致。其缺点是主、从模块时间配合属于强制性“同步”，必须在限定时间内完成规定的要求。并且对所有从模块都用同一限时，这就势必造成，对各不相同速度的部件而言，必须按最慢速度的部件来设计公共时钟，严重影响总线的工作效率，也给设计带来了局限性，缺乏灵活性。同步通信一般用于总线长度较短、各部件存取时间比较一致的场合。在同步通信的总线系统中，总线传输周期越短，数据线的位数越多，直接影响总线的数据传输率。例3.1假设总线的时钟频率为100MHz，总线的传输周期为4个时钟周期，总线的宽度为32位，试求总线的数据传输率。若想提高一倍数据传输率，可采取什么措施?解：根据总线时钟频率为100MHz，得1个时钟周期为1/100MHz=0.01μs总线传输周期为0.01μs×4=0.04μs由于总线的宽度为32位=4B(字节)故总线的数据传输率为(4B/(0.04μs)=100MBps若想提高一倍数据传输率，可以在不改变总线时钟频率的前提下，将数据线的宽度改为64位，也可以仍保持数据宽度为32位，但使总线的时钟频率增加到200MHz。异步通信克服了同步通信的缺点，允许各模块速度的不一致性，给设计者充分的灵活性和选择余地。它没有公共的时钟标准，不要求所有部件严格的统一操作时间，而是采用应答方式(又称握手方式)，即当主模块发出请求(Request)信号时，一直等待从模块反馈回来“响应”(Ac-knowledge)信号后才开始通信。当然，这就要求主、从模块之间增加两条应答线(握手交互信号线Handshaking)。异步通信的应答方式又可分为不互锁、半互锁和全互锁三种类型，如图3.18所示。(1)不互锁方式主模块发出请求信号后，不必等待接到从模块的回答信号，而是经过一段时间，确认从模块已收到请求信号后，便撤销其请求信号；从模块接到请求信号后，在条件允许时发出回答信号，并且经过一段时间(这段时间的设置对不同设备而言是不同的)确认主模块已收到回答信号后，自动撤销回答信号。可见通信双方并无互锁关系。例如，CPU向主存写信息，CPU要先后给出地址信号、写命令以及写入数据，即采用此种方式。(2)半互锁方式主模块发出请求信号，必须待接到从模块的回答信号后再撤销其请求信号，有互锁关系；而从模块在接到请求信号后发出回答信号，但不必等待获知主模块的请求信号已经撤销，而是隔一段时间后自动撤销其回答信号，无互锁关系。由于一方存在互锁关系，一方不存在互锁关系，故称半互锁方式。例如，在多机系统中，某个CPU需访问共享存储器(供所有CPU访问的存储器)时，该CPU发出访存命令后，必须收到存储器未被占用的回答信号，才能真正进行访存操作。(3)全互锁方式主模块发出请求信号，必须待从模块回答后再撤销其请求信号；从模块发出回答信号，必须待获知主模块请求信号已撤销后，再撤销其回答信号。双方存在互锁关系，故称为全互锁方式。例如，在网络通信中，通信双方采用的就是全互锁方式。异步通信可用于并行传送或串行传送。异步并行通信可参见图5.6，图中“Ready”和“Strobe”就是联络信号。异步串行通信时，没有同步时钟，也不需要在数据传送中传送同步信号。为了确认被传送的字符，约定字符格式为：1个起始位(低电平)、5~8个数据位(如ASCII码为7位)、1个奇偶校验位(作检错用)、1或1.5或2个终止位(高电平)。传送时起始位后面紧跟的是要传送字符的最低位，每个字符的结束是一个高电平的终止位。起始位至终止位构成一帧，两帧之间的间隔可以是任意长度的。图3.19是两种数据传输率的异步串行传送格式，其中图3.19(a)两帧之间有空闲位(高电平)，而图3.19(b)两帧之间无空闲位，故数据传输率更高。异步串行通信的数据传送速率用波特率来衡量。波特率是指单位时间内传送二进制数据的位数，单位用bps(位/秒)表示，记作波特。例3.2在异步串行传输系统中，假设每秒传输120个数据帧，其字符格式规定包含1个起始位、7个数据位、1个奇校验位、1个终止位，试计算波特率。解：根据题目给出的字符格式，一帧包含1+7+1+1=10位故波特率为(1+7+1+1)×120=1200bps=1200波特同步串行传送速度高于异步串行传送速度，可达500千波特，而异步通信传送一般为50~19200波特。例3.4在异步串行传输系统中，若字符格式为：1位起始位、8位数据位、1位奇校验位、1位终止位。假设波特率为1200bps，求这时的比特率。解：根据题目给出的字符格式，有效数据位为8位，而传送一个字符需1+8+1+1=11位，故比特率为1200×(8/11)=872.72bps半同步通信既保留了同步通信的基本特点，如所有的地址、命令、数据信号的发出时间，都严格参照系统时钟的某个前沿开始，而接收方都采用系统时钟后沿时刻来进行判断识别；同时又像异步通信那样，允许不同速度的模块和谐地工作。为此增设了一条“等待"(\overline{WAIT})响应信号线，采用插入时钟(等待)周期的措施来协调通信双方的配合问题。仍以输入为例，在同步通信中，主模块在T₁发出地址，在T₂发出命令，在T₃传输数据，在T₄结束传输。倘若从模块工作速度较慢，无法在T₃时刻提供数据，则必须在T₃到来前通知主模块，给出\overline{WAIT}(低电平)信号。若主模块在T₃到来时刻测得\overline{WAIT}为低电平，就插入一个等待周期Tv(其宽度与时钟周期一致)，不立即从数据线上取数。若主模块在下一个时钟周期到来时刻又测得WAIT为低，就再插入一个TW等待，这样一个时钟周期、一个时钟周期地等待，直到主模块测得\overline{WAIT}为高电平时，主模块即把此刻的下一个时钟周期当作正常周期T₃,，即时获取数据，T₄结束传输。插入等待周期的半同步通信数据输入过程如图3.22所示。由图中可见，半同步通信时序可为以下形式。T₁主模块发出地址信息。T₂主模块发出命令。T₃从模块提供数据。T₄主模块撤销读命令，从模块撤销数据。半同步通信适用于系统工作速度不高但又包含了由许多工作速度差异较大的各类设备组成的简单系统。半同步通信控制方式比异步通信简单，在全系统内各模块又在统一的系统时钟控制下同步工作，可靠性较高，同步结构较方便。其缺点是对系统时钟频率不能要求太高，故从整体上来看，系统工作的速度还不是很高。以上三种通信方式都是从主模块发出地址和读写命令开始，直到数据传输结束。在整个传输周期中，系统总线的使用权完全由占有使用权的主模块和由它选中的从模块占据。进一步分析读命令传输周期，发现除了申请总线这一阶段外，其余时间主要花费在如下3个方面。①主模块通过传输总线向从模块发送地址和命令。②从模块按照命令进行读数据的必要准备。③从模块经数据总线向主模块提供数据。由②可见，对系统总线而言，从模块内部读数据过程并无实质性的信息传输，总线纯属空闲等待。为了克服和利用这种消极等待，尤其在大型计算机系统中，总线的负载已处于饱和状态，充分挖掘系统总线每瞬间的潜力，对提高系统性能起到极大作用。为此人们又提出了“分离式”的通信方式，其基本思想是将一个传输周期(或总线周期)分解为两个子周期。在第一个子周期中，主模块A在获得总线使用权后将命令、地址以及其他有关信息，包括该主模块编号(当有多个主模块时，此编号尤为重要)发到系统总线上，经总线传输后，由有关的从模块B接收下来。主模块A向系统总线发布这些信息只占用总线很短的时间，一旦发送完，立即放弃总线使用权，以便其他模块使用。在第二个子周期中，当B模块收到A模块发来的有关命令信号后，经选择、译码、读取等一系列内部操作，将A模块所需的数据准备好，便由B模块申请总线使用权，一旦获准，B模块便将A模块的编号、B模块的地址、A模块所需的数据等一系列信息送到总线66第2篇计算机系统的硬件结构上，供A模块接收。很明显，上述两个传输子周期都只有单方向的信息流，每个模块都变成了主模块。这种通信方式的特点如下：①各模块欲占用总线使用权都必须提出申请。②在得到总线使用权后，主模块在限定的时间内向对方传送信息，采用同步方式传送，不再等待对方的回答信号。③各模块在准备数据的过程中都不占用总线，使总线可接受其他模块的请求。④总线被占用时都在做有效工作，或者通过它发送命令，或者通过它传送数据，不存在空闲等待时间，充分地利用了总线的有效占用，从而实现了总线在多个主、从模块间进行信息交叉重叠并行式传送，这对大型计算机系统是极为重要的。当然，这种方式控制比较复杂，一般在普通微型计算机系统很少采用。存储器是计算机系统中的记忆设备，用来存放程序和数据。随着计算机发展，存储器在系统中的地位越来越重要。由于超大规模集成电路的制作技术，使CPU的速度变得惊人的高，而存储器的取数和存数的速度与它很难适配，这使计算机系统的运行速度在很大程度上受存储器速度的制约。此外，由于I/O设备不断增多，如果它们与存储器交换信息都通过CPU来实现，这将大大降低CPU的工作效率。为此，出现了I/O与存储器的直接存取方式(DMA)，这也使存储器的地位更为突出。尤其在多处理机的系统中，各处理机本身都需与其主存交换信息，而且各处理机在互相通信中，也都需共享存放在存储器中的数据。因此，存储器的地位就更为显要。可见，从某种意义而言，存储器的性能已成为计算机系统的核心。当今，存储器的种类繁多，从不同的角度对存储器可作不同的分类。存储介质是指能寄存“0”“1”两种代码并能区别两种状态的物质或元器件。存储介质主要有半导体器件、磁性材料和光盘等。(1)半导体存储器存储元件由半导体器件组成的存储器称为半导体存储器。现代半导体存储器都用超大规模集成电路工艺制成芯片，其优点是体积小、功耗低、存取时间短。其缺点是当电源消失时，所存信息也随即丢失，它是一种易失性存储器。近年来已研制出用非挥发性材料制成的半导体存储器，克服了信息易失的弊病。半导体存储器又可按其材料的不同，分为双极型(TTL)半导体存储器和MOS半导体存储器两种。前者具有高速的特点；后者具有高集成度的特点，并且制造简单，成本低廉，功耗小，故MOS半导体存储器被广泛应用。(2)磁表面存储器磁表面存储器是在金属或塑料基体的表面上涂一层磁性材料作为记录介质，工作时磁层随载磁体高速运转，用磁头在磁层上进行读/写操作，故称为磁表面存储器。按载磁体形状的不同，可分为磁盘、磁带和磁鼓。现代计算机已很少采用磁鼓。由于用具有矩形磁滞回线特性的材料作磁表面物质，它们按其剩磁状态的不同而区分“0”或“1”，而且剩磁状态不会轻易丢失，故这类存储器具有非易失性的特点。(3)磁芯存储器磁芯是由硬磁材料做成的环状元件，在磁芯中穿有驱动线(通电流)和读出线，这样便可进行读/写操作。磁芯属磁性材料，故它也是不易失的永久记忆存储器。不过，磁芯存储器的体积.过大、工艺复杂、功耗太大，故20世纪70年代后，逐渐被半导体存储器取代，目前几乎已不被采用。(4)光盘存储器光盘存储器是应用激光在记录介质(磁光材料)上进行读/写的存储器，具有非易失性的特点。由于光盘记录密度高、耐用性好、可靠性高和可互换性强等特点，光盘存储器越来越被用于计算机系统。按存取方式可把存储器分为随机存储器、只读存储器、顺序存取存储器和直接存取存储器。(1)随机存储器(RandomAccessMemory,RAM)RAM是一种可读/写存储器，其特点是存储器的任何一个存储单元的内容都可以随机存取，而且存取时间与存储单元的物理位置无关。计算机系统中的主存都采用这种随机存储器。由于存储信息原理的不同，RAM又分为静态RAM(以触发器原理寄存信息)和动态RAM(以电容充放电原理寄存信息)。(2)只读存储器(ReadOnlyMemory,ROM)只读存储器是能对其存储的内容读出，而不能对其重新写入的存储器。这种存储器一旦存入了原始信息后，在程序执行过程中，只能将内部信息读出，而不能随意重新写入新的信息去改变原始信息。因此，通常用它存放固定不变的程序、常数和汉字字库，甚至用于操作系统的固化。它与随机存储器可共同作为主存的一部分，统一构成主存的地址域。早期只读存储器的存储内容根据用户要求，厂家采用掩模工艺，把原始信息记录在芯片中，一旦制成后无法更改，称为掩模型只读存储器(MaskedROM，MROM)。随着半导体技术的发展和用户需求的变化，只读存储器先后派生出可编程只读存储器(ProgrammableROM，PROM)、可擦除可编程只读存储器(ErasableProgrammableROM,EPROM)以及电擦除可编程只读存储器(Electrically-ErasableProgrammableROM,EEPROM)。近年来还出现了闪速存储器FlashMemory,它具有EEPROM的特点,而速度比EEPROM快得多。(3)串行访问存储器如果对存储单元进行读/写操作时，需按其物理位置的先后顺序寻找地址，则这种存储器称为串行访问存储器。显然这种存储器由于信息所在位置不同，使得读/写时间均不相同。例如，磁带存储器，不论信息处在哪个位置，读/写时必须从其介质的始端开始按顺序寻找，故这类串行访问的存储器又称为顺序存取存储器。还有一种属于部分串行访问的存储器，如磁盘。在对磁盘读/写时，首先直接指出该存储器中的某个小区域(磁道)，然后再顺序寻访，直至找到位置。故其前段是直接访问，后段是串行访问，称为直接存取存储器。按在计算机系统中的作用不同，存储器主要分为主存储器、辅助存储器、缓冲存储器。主存储器(简称主存)的主要特点是它可以和CPU直接交换信息。辅助存储器(简称辅存)是主存储器的后援存储器，用来存放当前暂时不用的程序和数据，它不能与CPU直接交换信息。两者相比，主存速度快、容量小、每位价格高；辅存速度慢、容量大、每位价格低。缓冲存储器(简称缓存)用在两个速度不同的部件之中，例如，CPU与主存之间可设置一个快速缓存(有关内容将在4.3节中讲述)，起到缓冲作用。综上所述，存储器分类如图4.1所示。存储器有3个主要性能指标：速度、容量和每位价格(简称位价)。一般来说，速度越高，位价就越高；容量越大，位价就越低，而且容量越大，速度必越低。人们追求大容量、高速度、低位价的存储器，可惜这是很难达到的。图4.2形象地反映了上述三者的关系。图中由上至下，位价越来越低，速度越来越慢，容量越来越大，CPU访问的频度也越来越少。最上层的寄存器通常都制作在CPU芯片内。寄存器中的数直接在CPU内部参与运算，CPU内可以有十几个、几十个寄存器，它们的速度最快，位价最高，容量最小。主存用来存放将要参与运行的程序和数据，其速度与CPU速度差距较大，为了使它们之间速度更好地匹配，在主存与CPU之间插入了一种比主存速度更快、容量更小的高速缓冲存储器Cache，显然其位价要高于主存。以上三类存储器都是由速度不同、位价不等的半导体存储材料制成的，它们都设在主机内。现代计算机将Cache也制作在CPU内。磁盘、磁带属于辅助存储器，其容量比主存大得多，大都用来存放暂时未用到的程序和数据文件。CPU不能直接访问辅存，辅存只能与主存交换信息，因此辅存的速度可以比主存慢得多。实际上，存储系统层次结构主要体现在缓存-主存和主存-辅存这两个存储层次上，如图4.3所示。显然，CPU和缓存、主存都能直接交换信息；缓存能直接和CPU、主存交换信息；主存可以和CPU、缓存、辅存交换信息。缓存-主存层次主要解决CPU和主存速度不匹配的问题。由于缓存的速度比主存的速度高，只要将CPU近期要用的信息调入缓存，CPU便可以直接从缓存中获取信息，从而提高访存速度。但由于缓存的容量小，因此需不断地将主存的内容调入缓存，使缓存中原来的信息被替换掉。主存和缓存之间的数据调动是由硬件自动完成的，对程序员是透明的。主存-辅存层次主要解决存储系统的容量问题。辅存的速度比主存的速度低，而且不能和CPU直接交换信息，但它的容量比主存大得多，可以存放大量暂时未用到的信息。当CPU需要用到这些信息时，再将辅存的内容调入主存，供CPU直接访问。主存和辅存之间的数据调动是由硬件和操作系统共同完成的。从CPU角度来看，缓存-主存这一层次的速度接近于缓存，高于主存；其容量和位价却接近于主存，这就从速度和成本的矛盾中获得了理想的解决办法。主存-辅存这一层次，从整体分析，其速度接近于主存，容量接近于辅存，平均位价也接近于低速、廉价的辅存位价，这又解决了速度、容量、成本这三者的矛盾。现代的计算机系统几乎都具有这两个存储层次，构成了缓存、主存、辅存三级存储系统。在主存-辅存这一层次的不断发展中，逐渐形成了虚拟存储系统。在这个系统中，程序员编程的地址范围与虚拟存储器的地址空间相对应。例如，机器指令地址码为24位，则虚拟存储器存储单元的个数可达16M。可是这个数与主存的实际存储单元的个数相比要大得多，称这类指令地址码为虚地址(虚存地址、虚拟地址)或逻辑地址，而把主存的实际地址称为物理地址或实地址。物理地址是程序在执行过程中能够真正访问的地址，也是实实在在的主存地址。对具有虚拟存储器的计算机系统而言，程序员编程时，可用的地址空间远远大于主存空间，使程序员以为自己占有一个容量极大的主存，其实这个主存并不存在，这就是将其称为虚拟存储器的原因。对虚拟存储器而言，其逻辑地址变换为物理地址的工作是由计算机系统的硬件和操作系统自动完成的，对程序员是透明的。当虚地址的内容在主存时，机器便可立即使用；若虚地址的内容不在主存，则必须先将此虚地址的内容传递到主存的合适单元后再为机器所用。有关这些方面的内容，读者可在“计算机体系结构”和“操作系统”课程中学到。主存储器(简称主存)的基本结构已在第1章介绍过，如图1.11所示。实际上，根据MAR中的地址访问某个存储单元时，还需经过地址译码、驱动等电路，才能找到所需访问的单元。读出时，需经过读出放大器，才能将被选中单元的存储字送到MDR。写入时，MDR中的数据也必须经过写入电路才能真正写入被选中的单元中。可见，主存的实际结构如图4.4所示。现代计算机的主存都由半导体集成电路构成，图中的驱动器、译码器和读写电路均制作在存储芯片中,而MAR和MDR制作在CPU芯片内。存储芯片和CPU芯片可通过总线连接，如图4.5所示。当要从存储器读出某一信息字时，首先由CPU将该字的地址送到MAR，经地址总线送至主存，然后发出读命令。主存接到读命令后，得知需将该地址单元的内容读出，便完成读操作，将该单元的内容读至数据总线上，至于该信息由MDR送至什么地方，这已不是主存的任务，而是由CPU决定的。若要向主存存入一个信息字时，首先CPU将该字所在主存单元的地址经MAR送到地址总线，并将信息字送入MDR，然后向主存发出写命令，主存接到写命令后，便将数据线上的信息写入对应地址线指出的主存单元中。主存各存储单元的空间位置是由单元地址号来表示的，而地址总线是用来指出存储单元地址号的，根据该地址可读出或写入一个存储字。不同的机器存储字长也不同，为了满足字符处理的需要，常用8位二进制数表示一个字节，因此存储字长都取8的倍数。通常计算机系统既可按字寻址，也可按字节寻址。例如IBM370机的字长为32位，它可按字节寻址，即它的每一个存储字包含4个可独立寻址的字节，其地址分配如图4.6(a)所示。字地址是用该字高位字节的地址来表示，故其字地址是4的整数倍，正好用地址码的末两位来区分同一字的4个字节的位置。但对PDP-11机而言，其字长为16位，字地址是2的整数倍，它用低位字节的地址来表示字地址，如图4.6(b)所示。由图4.6(a)所示，对24位地址线的主存而言，按字节寻址的范围是16M，按字寻址的范围为4M。由图4.6(b)所示，对24位地址线而言，按字节寻址的范围仍为16M，但按字寻址的范围为8M。主存的主要技术指标是存储容量和存储速度。(1)存储容量存储容量是指主存能存放二进制代码的总位数，即存储容量=存储单元个数×存储字长它的容量也可用字节总数来表示，即存储容量=存储单元个数×存储字长/8目前的计算机存储容量大多以字节数来表示，例如，某机主存的存储容量为256MB，则按字节寻址的地址线位数应对应28位。(2)存储速度存储速度是由存取时间和存取周期来表示的。存取时间又称为存储器的访问时间(MemoryAccessTime)，是指启动一次存储器操作(读或写)到完成该操作所需的全部时间。存取时间分读出时间和写入时间两种。读出时间是从存储器接收到有效地址开始，到产生有效输出所需的全部时间。写入时间是从存储器接收到有效地址开始，到数据写入被选中单元为止所需的全部时间。存取周期(MemoryCycleTime)是指存储器进行连续两次独立的存储器操作(如连续两次读操作)所需的最小间隔时间，通常存取周期大于存取时间。现代MOS型存储器的存取周期可达100ns;双极型TTL存储器的存取周期接近于10ns。(3)存储器带宽与存取周期密切相关的指标为存储器带宽，它表示单位时间内存储器存取的信息量，单位可用字/秒或字节/秒或位/秒表示。如存取周期为500ns，每个存取周期可访问16位，则它的带宽为32M位/秒。带宽是衡量数据传输率的重要技术指标。存储器的带宽决定了以存储器为中心的机器获得信息的传输速度，它是改善机器瓶颈的一个关键因素。为了提高存储器的带宽，可以采用以下措施：①缩短存取周期。②增加存储字长，使每个存取周期可读/写更多的二进制位数。③增加存储体(详见4.2.7节)。半导体存储芯片采用超大规模集成电路制造工艺，在一个芯片内集成具有记忆功能的存储矩阵、译码驱动电路和读/写电路等，如图4.7所示。译码驱动能把地址总线送来的地址信号翻译成对应存储单元的选择信号，该信号在读/写电路的配合下完成对被选中单元的读/写操作。读/写电路包括读出放大器和写入电路，用来完成读/写操作。存储芯片通过地址总线、数据总线和控制总线与外部连接。地址线是单向输入的，其位数与芯片容量有关。数据线是双向的(有的芯片可用成对出现的数据线分别作为输入或输出)，其位数与芯片可读出或写入的数据位数有关。数据线的位数与芯片容量有关。地址线和数据线的位数共同反映存储芯片的容量。例如，地址线为10根，数据线为4根，则芯片容量为2¹⁰×4=4K位；又如地址线为14根，数据线为1根，则其容量为16K位。控制线主要有读/写控制线与片选线两种。不同存储芯片的读/写控制线和片选线可以不同。有的芯片的读/写控制线共用1根(如2114)，有的分用两根(如6264)；有的芯片的片选线用1根(如2114)，有的用2根(如6264)。读/写控制线决定芯片进行读/写操作，片选线用来选择存储芯片。由于半导体存储器是由许多芯片组成的，为此需用片选信号来确定哪个芯片被选中。例如，一个64K×8位的存储器可由32片16K×1位的存储芯片组成，如图4.8所示。但每次读出一个存储字时，只需选中8片。半导体存储芯片的译码驱动方式有两种：线选法和重合法，如图4.9和图4.10所示。图4.9是一个16×1字节线选法存储芯片的结构示意图。它的特点是用一根字选择线(字线)，直接选中一个存储单元的各位(如一个字节)。这种方式结构较简单，但只适于容量不大的存储芯片。如当地址线A₃A₂A₁A₀为1111时，则第15根字线被选中，对应图4.9中的最后一行8位代码便可直接读出或写入。图4.10是一个1K×1位重合法结构示意图。显然，只要用64根选择线(X、Y两个方向各32根)，便可选择32×32矩阵中的任一位。例如，当地址线为全0时，译码输出X₀和Y₀有效，矩阵中第0行、第0列共同选中的那位即被选中。由于被选单元是由X、Y两个方向的地随机存取存储器按其存储信息的原理不同，可分为静态RAM和动态RAM两大类。(1)静态RAM基本单元电路存储器中用于寄存“0”和“1”代码的电路称为存储器的基本单元电路，图4.11是一个由6个MOS管组成的基本单元电路。图中T₁~T₄是一个由MOS管组成的触发器基本电路，T₅、T₆犹如一个开关，受行地址选择信号控制。由‘T₁∼T₆这6个MOS管共同构成一个基本单元电路。T₇、T₈受列地址选择控制，分别与位线A'和A相连，它们并不包含在基本单元电路内，而是芯片内同一列的各个基本单元电路所共有的。假设触发器已存有“1”信号，即A点为高电平。当需读出时，只要使行、列地址选择信号均有效，则使T₅、T₆、T₇、T₈均导通，A点高电平通过T₆后，再由位线A通过T₈作为读出放大器的输入信号，在读选择有效时，将“1”信号读出。由于静态RAM是用触发器工作原理存储信息的，因此即使信息读出后，它仍保持其原状态，不需要再生。但电源掉电时，原存信息丢失，故它属易失性半导体存储器。写入时不论触发器原状态如何，只要将写入代码送至图4.11的D_{IN}端，在写选择有效时，经两个写放大器，使两端输出为相反电平。当行、列地址选择有效时，使T₅、T₆、T₇、T₈导通，并将A与A'点置成完全相反的电平。这样，就把欲写入的信息写入该基本单元电路中。如欲写入“1”，即D_{NN}=1,经两个写放大器使位线A为高电平，位线A'为低电平，结果使A点为高，A'点为低，即写入了“1”信息。(2)静态RAM芯片举例Intel2114芯片的基本单元电路由6个MOS管组成,图4.12是一个容量为1K×4位的2114外特性示意图。图中，A₉~A₀为地址输入端；I/0₁∼1/0₄为数据输入输出端；CS为片选信号(低电平有效)；WE为写允许信号(低电平为写，高电平为读)；V_{CC}为电源端；GND为接地端。2114RAM芯片的结构示意图如图4.13所示。图中存储矩阵由(64×64个基本单元电路组成，列I/O电路即读/写电路。10根地址线分为行地址A₈∼A₃和列地址A₉、A₂、A₁、A₀,4根数据线为I/0₄∼I/0₁,它们是受输入输出三态门控制的双向总线。当CS和WE均为低电平时，输入三态门打开，|/0₄∼VO₁上的数据即写入指定地址单元中。当CS为低电平、WE为高电平时，输出三态门打开，列I/O电路的输出经片内总线输出至数据线I/0₄∼I/O₁上。2114RAM芯片内的存储矩阵结构如图4.14所示。其中每一个小方块均为一个由6个MOS管组成的基本单元电路，排列成64×64矩阵,64列对应64对T₇、T₈管。又将64列分成4组,每组包含16列，并与一个读/写电路相连，读/写电路受WE和CS控制，4个读/写电路对应4根数据线I/0₁∼I/0₄。由图中可见，行地址经译码后可选中某一行；列地址经译码后可选中4组中的对应列，共4列。当对某个基本单元电路进行读/写操作时，必须被行、列地址共同选中。例如，当A₉∼A₀为全0时，对应行地址A₈∼A₃为000000,列地址A₉、A₂、A₁、A₀也为0000,则第0行的第0、16、32、48这4个基本单元电路被选中。此刻，若做读操作，则CS为低电平，WE为高电平，在读/写电路的输出端I/0₁∼I/0₄便输出第0行的第0、16、32、48这4个基本单元电路所存的信息。若做写操作，将写入信息送至I/0₁∼I/O₄端口，并使CS为低电平、WE为低电平，同样这4个输入信息将分别写入第0行的第0、16、32、48这4个单元之中。(3)静态RAM读/写时序1)读周期时序图4.15是2114RAM芯片读周期时序，在整个读周期中WE始终为高电平(故图中省略)。读周期tRC是指对芯片进行两次连续读操作的最小间隔时间。读时间tA表示从地址有效到数据稳定所需的时间，显然读时间小于读周期。图中tc₀是从片选有效到输出稳定的时间。可见只有当地址有效经tA后，且当片选有效经tc₀后，数据才能稳定输出，这两者必须同时具备。根据tA和tco的值，便可知当地址有效后，经t_{A}-t_{CO}时间必须给出片选有效信号，否则信号不能出现在数据线上。需注意一点，从片选失效到输出高阻需一段时间t_{0\piD},，故地址失效后，数据线上的有效数据有一段维持时间t_{0HA},以保证所读的数据可靠。2)写周期时序图4.16是2114RAM写周期时序。写周期two是对芯片进行连续两次写操作的最小间隔时间。写周期包括滞后时间：写入时间tw和写恢复时间twR。在有效数据出现前，RAM的数据线上存在着前一时刻的数据Dour(如图4.15所示的维持时间)，故在地址线发生变化后，CS、WE均需滞后tAw再有效，以避免将无效数据写入RAM的错误。但写允许WE失效后，地址必须保持一段时间，称为写恢复时间。此外,RAM数据线上的有效数据(即CPU送至RAM的写入数据DIN)必须在CS、WE失效前的tDw时刻出现，并延续一段时间tDH(此刻地址线仍有效，t_{WR}>t_{DH}),以保证数据可靠写入。已制成的RAM芯片读写时序关系已被确定，因此，将它与CPU连接时，必须注意它们相互间的时序匹配关系，否则RAM将无法正常工作。具体RAM芯片的读/写周期时序可查看相关资料。值得注意的是，不论是对存储器进行读操作还是写操作，在读周期和写周期内，地址线上的地址始终不变。(1)动态RAM的基本单元电路常见的动态RAM基本单元电路有三管式和单管式两种，它们的共同特点都是靠电容存储电荷的原理来寄存信息。若电容上存有足够多的电荷表示存“1”，电容上无电荷表示存“0”。电容上的电荷一般只能维持1~2ms，因此即使电源不掉电，信息也会自动消失。为此，必须在2ms内对其所有存储单元恢复一次原状态，这个过程称为再生或刷新。由于它与静态RAM相比，具有集成度更高、功耗更低等特点，目前被各类计算机广泛应用。图4.17示意了由T₁、T₂、T₃这3个MOS管组成的三管MOS动态RAM基本单元电路。读出时，先对预充电管T₄置一预充电信号(在存储矩阵中，每一列共用一个T₄管)，使读数据线达高电平VDD。然后由读选择线打开T₂，若T₁的极间电容C₆存有足够多的电荷(被认为原存“1”)，使T₁导通，则因T₂、T₁导通接地，使读数据线降为零电平，读出“0”信息。若C₆没有足够电荷(原存“0”)，则T₁截止，读数据线为高电平不变，读出“1”信息。可见，由读出线的高低电平可区分其是读“1”，还是读“0”，只是它与原存信息反相。写入时，将写入信号加到写数据线上，然后由写选择线打开T₃，这样，C₈便能随输入信息充电(写“1”)或放电(写“0”)。为了提高集成度，将三管电路进一步简化，去掉T₁，把信息存在电容C₆上，将T₂、T₃合并成一个管子T，便得到单管MOS动态RAM基本单元电路，如图4.18所示。数据线读出时，字线上的高电平使T导通，若C。有电荷，经T管在数据线上产生电流，可视为读出“1”。若C。无电荷，则数据线上无电流，可视为读出“0”。读操作结束时，C。的电荷已释放完毕，故是破坏性读出，必须再生。写入时，字线为高电平使T导通，若数据线上为高电平，经T管对C.充电，使其存“1”；若数据线为低电平，则C.经T放电，使其无电荷而存“0”。字线(2)动态RAM芯片举例1)三管动态RAM芯片基本单元电路三管动态RAM芯片结构的示意图如图4.19所示。这是一个1K×1位的存储芯片，图中每一小方块代表由3个MOS管组成的动态RAM基本单元电路。它们排列成32×32的矩阵，每列都有一个刷新放大器(用来形成再生信息)和一个预充电管(图中未画)，芯片有10根地址线，采用重合法选择基本单元电路。读出时，先置以预充电信号，接着按行地址A₉~A₅经行译码器给出读选择信号，同时由列地址A₄~A₀经列译码器给出列选择信号。只有在行、列选择信号共同作用下的基本单元电路才能将其信息经读数据线送到读/写控制电路，并从数据线D输出。写入时，在受行地址控制的行译码器给出的写选择信号的作用下，选中芯片的某一行，并在列地址的作用下，由列译码器的输出控制读/写控制电路，只将数据线D的信息送到被选中列的写数据线上，信息即被写入行列共同选中的基本单元电路中。2)单管动态RAM芯片单管动态RAM芯片结构的示意图如图4.20所示。这是一个16K×1位的存储芯片，按理应有14根地址线，但为了减少芯片封装的引脚数，地址线只有7根。因此，地址信息分两次传送，先送7位行地址保存到芯片内的行地址缓存器内，再送7位列地址保存到列地址缓存器中。芯片内有时序电路，它受行地址选通RAS、列地址选通CAS以及写允许信号WE控制。16K×1位的存储芯片共有16K个单管MOS基本单元电路，它们排列成128×128的矩阵，如图4.21所示。图中的行线就是图4.18中的字线，列线就是图4.18中的数据线。128行分布在读放大器的左、右两侧(左侧为0~63行，右侧为64~127行)。每根行选择线与128个MOS管的栅极相连。128列共有128个读放大器，它的两侧又分别与64个MOS管相连，每根列线上都有一个列地址选择管。128个列地址选择管的输出又互相并接在一起与I/O缓冲器相连，I/O缓冲器的一端接输出驱动器，可输出数据；另一端接输入器，供数据输入。读出时，行、列地址受RAS和CAS控制，分两次分别存入行、列地址缓存器。行地址经行译码后选中一行，使该行上所有的MOS管均导通，并分别将其电容Cₙ上的电荷反映到128个读放大器的某一侧(第0~63行反映到读放大器的左侧，第64~127行反映到读放大器的右侧)。读放大器的工作原理像一个跷跷板电路，类似于一个触发器，其左右两侧电平相反。此外列地址经列译码后选中某一列，该列上的列地址选择管导通，即可将读放大器右侧信号经读/写线、I/O缓冲器输出至D₀uT端。例如，选中第63行、第0列的单管MOS电路，若其C₆有电荷为“1”状态，则反映到第0列读放大器的左侧为“1”，右侧为“0”，经列地址选择管输出至DOUT为0，与原存信息反相。同理，第0~62行经读放大器至输出线D₀uT的信息与原存信息均反相。而读出第64~127行时，因它们的电容C。上的电荷均反映到读放大器的右侧，故经列地址选择管输出至D₀UT的信息均同相。写入时，行、列地址也要分别送入芯片内的行、列地址缓存器，经译码可选中某行、某列。输入信息D₁N通过数据输入器，经I/O缓冲器送至读/写线上，但只有被选中的列地址选择管导通，可将读/写线上的信息送至该列的读放大器右侧，破坏了读放大器的平衡，使读放大器的右侧与输入信息同相，左侧与输入信息反相，读放大器的信息便可写入选中行的Cₛ中。例如，选中第64行、第127列，输入信息为“1”，则第127列地址选择管导通，将“1”信息送至第127列的读放大器的右侧。虽然第64行上的128个MOS管均导通，但唯有第64行、第127列的MOS管能将读放大器的右侧信息“1”对C。充电，使其写入“1”。值得注意的是，写入读放大器左侧行的信息与输入信息都是反相的，而由读出过程分析又知，对读放大器左侧行进行读操作时，读出的信息也是反相的，故最终结果是正确的。(3)动态RAM时序由图4.20可知，动态RAM的行、列地址是分别传送的，因此分析其时序时，应特别注意\overline{RAS},\overline{CAS}与地址的关系，即·先由RAS将行地址送入行地址缓存器，再由CAS将列地址送入列地址缓存器，因此，CAS滞后于\overline{RAS}的时间必须要超过其规定值。{}^{\circ}\overline{RAS}和CAS正、负电平的宽度应大于规定值，以保证芯片内部正常工作。·行地址对RAS的下降沿以及列地址对CAS的下降沿应有足够的地址建立时间和地址保持时间，以确定行、列地址均能准确写入芯片。1)读时序在读工作方式时(写允许\overline{WE}=1),读工作周期是指动态RAM完成一次“读”所需的最短时间tcBD，也是RAS的一个周期。如图4.22所示，为了确保读出数据无误，必须要求写允许t_{C_{HD}},WE=1在列地址送入前(即CAS下降沿到来前)建立，而WE=1的撤除应在CAS失效后(即CAS上升沿后)；还要求读出数据应在RAS有效后一段时间t_{\bullet}且CAS有效后一段时间t_{a}\overline{CAS}时出现，而数据有效的撤除时间应在CAS失效后一段时间t_{h\overline{CAS}-0Ur}^{0}2)写时序在写工作方式时(写允许\overline{WE}=0),\overline{RAS}的一个周期t_{c_{WR}}，即为写工作周期，如图4.23所示。为了确保写入数据准确无误，\overline{WE}=0应先于CAS=0,，而且数据的有效存在时间应与CAS及WE的有效相对应，即写入数据应在(CAS有效前的一段时间出现，它的保持时间应为CAS有效后的一段时间，这是因为数据的写入实际上是由CAS的下降沿激发而成的。可见，为了保证正常写入，WE、CAS有效均要大于数据D_{N}有效的时间。此外，动态RAM还有读-改写工作方式和页面工作方式，本书不再赘述。(4)动态RAM的刷新刷新的过程实质上是先将原存信息读出，再由刷新放大器形成原信息并重新写入的再生过程(图4.19中的刷新放大器及图4.21中的读放大器均起此作用)。由于存储单元被访问是随机的，有可能某些存储单元长期得不到访问，不进行存储器的读/写操作，其存储单元内的原信息将会慢慢消失。为此，必须采用定时刷新的方法，它规定在一定的时间内，对动态RAM的全部基本单元电路必作一次刷新，一般取2ms，这个时间称为刷新周期，又称再生周期。刷新是一行行进行的，必须在刷新周期内，由专用的刷新电路来完成对基本单元电路的逐行刷新，才能保证动态RAM内的信息不丢失。通常有三种方式刷新：集中刷新、分散刷新和异步刷新。1)集中刷新集中刷新是在规定的一个刷新周期内，对全部存储单元集中一段时间逐行进行刷新，此刻必须停止读/写操作。例如，对128×128矩阵的存储芯片进行刷新时，若存取周期为0.5μs，刷新周期为2ms(占4000个存取周期)，则对128行集中刷新共需64μs(占128个存取周期)，其余的1936μs(共3872个存取周期)用来读/写或维持信息，如图4.24所示。由于在这64μs时间内不能进行读/写操作,故称为“死时间”,又称访存“死区”,所占比率为128/4000×100%=3.2%,称为死时间率。2)分散刷新分散刷新是指对每行存储单元的刷新分散到每个存取周期内完成。其中，把机器的存取周期tc分成两段，前半段tM用来读/写或维持信息，后半段tR用来刷新，即t_{C}=t_{M}+t_{R}。若读/写周期为0.5μs，则存取周期为1μs。仍以128×128矩阵的存储芯片为例，刷新按行进行，每隔128μs就可将存储芯片全部刷新一遍，如图4.25所示。这比允许的间隔2ms要短得多，而且也不存在停止读/写操作的死时间，但存取周期长了，整个系统速度降低了。3)异步刷新异步刷新是前两种方式的结合，它既可缩短“死时间”，又充分利用最大刷新间隔为2ms的特点。例如，对于存取周期为0.5μs，排列成128×128的存储芯片，可采取在2ms内对128行各刷新一遍，即每隔15.6μs(2000μs÷128≈15.6μs)刷新一行,而每行刷新的时间仍为0.5μs,如图4.26所示。这样，刷新一行只停止一个存取周期，但对每行来说，刷新间隔时间仍为2ms，而“死时间”缩短为0.5μs。如果将动态RAM的刷新安排在CPU对指令的译码阶段，由于这个阶段CPU不访问存储器，所以这种方案既克服了分散刷新需独占0.5μs用于刷新，使存取周期加长且降低系统速度的缺点，又不会出现集中刷新的访存“死区”问题，从根本上提高了整机的工作效率。目前，动态RAM的应用比静态RAM要广泛得多。其原因如下：①在同样大小的芯片中，动态RAM的集成度远高于静态RAM，如动态RAM的基本单元电路为一个MOS管，静态RAM的基本单元电路可为4~6个MOS管。②动态RAM行、列地址按先后顺序输送，减少了芯片引脚，封装尺寸也减少。③动态RAM的功耗比静态RAM小。④动态RAM的价格比静态RAM的价格便宜。当采用同一档次的实现技术时，动态RAM的容量大约是静态RAM容量的4~8倍，静态RAM的存取周期比动态RAM的存取周期快8~16倍,但价格也贵8~16倍。随着动态RAM容量不断扩大，速度不断提高，它被广泛应用于计算机的主存。动态RAM也有缺点:①由于使用动态元件(电容)，因此它的速度比静态RAM低。②动态RAM需要再生，故需配置再生电路，也需要消耗一部分功率。通常，容量不大的高速缓冲存储器大多用静态RAM实现。读存储器按ROM的原始定义，一旦注入原始信息即不能改变，但随着用户的需要，总希望能任意修改ROM内的原始信息。这便出现了PROM、EPROM和EEPROM等。对半导体ROM而言，基本器件为两种：MOS型和TTL型。图4.27所示为MOS型掩模ROM，其容量为1K×1位，采用重合法驱动，行、列地址线分别经行、列译码器，各有32根行、列选择线。行选择线与列选择线交叉处既可有耦合元件MOS管，也可没有。列选择线各控制一个列控制管，32个列控制管的输出端共连一个读放大器。当地址为全“0”时，第0行、0列被选中，若其交叉处有耦合元件MOS管，因其导通而使列线输出为低电平，经读放大器反相为高电平，输出“1”。当地址A₄∼A₀为11111,A₉~A₅为00000时,即第31行、第0列被选中，但此刻行、列的交叉处无MOS管，故0列线输出为高电平，经读放大器反相为“0”输出。可见，用行、列交叉处是否有耦合元件MOS管，便可区分原存“1”还是存“0”。当然，此ROM制成后不可能改变原行、列交叉处的MOS管是否存在，所以，用户是无法改变原始状态的。PROM是可以实现一次性编程的只读存储器，图4.28示意一个由双极型电路和熔丝构成的基本单元电路。在这个电路中，基极由行线控制，发射极与列线之间形成一条镍铬合金薄膜制成的熔丝(可用光刻技术实现)，集电极接电源Vcc。熔丝断和未断可区别其所存信息是“1”或“0”。图4.29是由图4.28所示基本单元电路构成的16×1位双极型镍铬熔丝式PROM芯片。用户在使用前，可按需要将信息存入行、列交叉的耦合元件内。若欲存“0”，则置耦合元件一大电流，将熔丝烧掉。若欲存“1”，则耦合处不置大电流，熔丝不断。当被选中时，熔丝断掉处将读出“0”，熔丝未断处将读出“1”。例如，当地址A₃∼A₀为0000时，第0行、第0列被选中，此刻行、列交叉的耦合元件熔丝未断，故读出D=1；若A₃∼A₀=0001,则式单元电路第1行、第0列被选中，此刻行、列交叉的耦合元件熔丝已断，读出D=0。当然，已断的熔丝是无法再恢复的，故这种ROM往往只能实现一次编程，不得再修改。EPROM是一种可擦除可编程只读存储器。它可以由用户对其所存信息作任意次的改写。目前用得较多的EPROM是由浮动栅雪崩注入型MOS管构成的,又称FAMOS型EPROM,如图4.30所示。图中所示的N型沟道浮动栅MOS电路，在漏端D加上正电压(如25V、50ms宽的正脉冲)，便会形成一个浮动栅，它阻止源S与漏D之间的导通，致使此MOS管处于“0”状态。若对D端不加正电压，则不能形成浮动栅，此MOS管便能正常导通，呈“1”状态。由此，用户可按需要对不同位置的MOS管D端施正电压或不施正电压，便制成了用户所需的ROM。一旦用户需重新改变其状态，可用紫外线照射，驱散浮动栅，再按需要将不同位置的MOS管D端重新置于正电压,又得出新状态的ROM,故称之为EPROM。图4.31为2716型EPROM的逻辑图和引脚图。这类芯片的外引脚除地址线、数据线外，还有两个电源引出头V_{cc}和V_{PP}。其中V_{cc}接+5V;V_{PP}平时接+5V,当其接+25V时用来完成编程。V_{sS}为地。CS为片选端，读出时为低电平，编程写入时为高电平。\overrightarrow{PD}/Progr是功率下降/编程输入端，在读出时为低电平；当此端为高电平时，可以使EPROM功耗由525mW降至132mW;当需编程时,此端需加宽度为50~55ms、+5V的脉冲。EPROM的改写可用两种方法，一种用紫外线照射，但擦除时间比较长，而且不能对个别需改写的单元进行单独擦除或重写。另一种方法用电气方法将存储内容擦除，再重写。甚至在联机条件下，用字擦除方式或页擦除方式，既可局部擦写，又可全部擦写，这种EPROM就是EEPROM。进入到20世纪80年代，又出现了一种闪速存储器(FlashMemory)，又称快擦型存储器，它是在EPROM和EEPROM工艺基础上产生的一种新型的、具有性能价格比更好、可靠性更高的可擦写非易失性存储器。它既有EPROM的价格便宜、集成度高的优点，又有EEPROM电可擦除重写的特性。它具有整片擦除的特点，其擦除、重写的速度快。一块1M位的闪速存储芯片的擦除、重写时间小于5μs，比一般标准的EEPROM快得多，已具备了RAM的功能，可与CPU直接连接。它还具有高速编程的特点，例如，采用快速脉冲编程算法对28F256闪速存储芯片每字节的编程时间仅需100μs。此外，该器件具有存储器访问周期短，功耗低及与计算机接口简单等优点。在需要周期性地修改存储信息的应用场合，闪速存储器是一个极为理想的器件，因为它至少可以擦写/编程10000次，这足以满足用户的需要。它比较适合于作为一种高密度、非易失的数据采集和存储器件，在便携式计算机、工控系统及单片机系统中得到大量应用，近年来已用于微型计算机中存放输入输出驱动程序和参数等。非易失性、长期反复使用的大容量闪速存储器还可替代磁盘，例如，在笔记本手掌型袖珍计算机中都大量采用闪速存储器做成固态盘替代磁盘，使计算机平均无故障时间大大延长，功耗更低，体积更小，消除了机电式磁盘驱动器所造成的数据瓶颈。由于单片存储芯片的容量总是有限的，很难满足实际的需要，因此，必须将若干存储芯片连在一起才能组成足够容量的存储器，称为存储容量的扩展，通常有位扩展和字扩展。(1)位扩展位扩展是指增加存储字长，例如，2片1K×4位的芯片可组成1K×8位的存储器，如图4.32所示。图中2片2114的地址线A₉∼A₀、CS、WE都分别连在一起，其中一片的数据线作为高4位D₇~D₄，另一片的数据线作为低4位)D₃∼D₀。这样，便构成了一个1K×8位的存储器。又如，将8片16K×1位的存储芯片连接，可组成一个16K×8位的存储器，如图4.33所示。(2)字扩展字扩展是指增加存储器字的数量。例如，用2片1K×8位的存储芯片可组成一个2K×8位位的存储器的存储器，即存储字增加了一倍，如图4.34所示。在此，将A₁₀用作片选信号。由于存储芯片的片选输入端要求低电平有效，故当A₁₀为低电平时，\overline{CS}_{0}有效，选中左边的1K×8位芯片；当A₁₀为高电平时，反相后CS₁有效，选中右边的1K×8位芯片。(3)字、位扩展字、位扩展是指既增加存储字的数量，又增加存储字长。图4.35示意用8片1K×4位的芯片组成4K×8位的存储器。由图中可见，每2片构成一组1K×8位的存储器，4组便构成4K×8分位的存储器。地址线A_{11}\sqrt{A_{10}}经片选译码器得到4个片选信号CS₀,CS₁、CS₂、CS₃,分别选择其中1K×8位的存储芯片。WE为读/写控制信号。存储芯片与CPU芯片相连时，特别要注意片与片之间的地址线、数据线和控制线的连接。(1)地址线的连接存储芯片的容量不同，其地址线数也不同，CPU的地址线数往往比存储芯片的地址线数多。94第2篇计算机系统的硬件结构通常总是将CPU地址线的低位与存储芯片的地址线相连。CPU地址线的高位或在存储芯片扩充时用，或做其他用途，如片选信号等。例如，设CPU地址线为16位A₁₅∼A₀,1K×4位的存储芯片仅有10根地址线A₉~A₀,此时,可将CPU的低位地址.A₉∼A₀与存储芯片地址线A₉∼A₀相连。又如，当用16K×1位存储芯片时，则其地址线有14根A₁₃∼A₀,此时，可将CPU的低位地址A₁₃∼A₀与存储芯片地址线.A₁₃∼A₀相连。(2)数据线的连接同样，CPU的数据线数与存储芯片的数据线数也不一定相等。此时，必须对存储芯片扩位，使其数据位数与CPU的数据线数相等。(3)读/写命令线的连接CPU读/写命令线一般可直接与存储芯片的读/写控制端相连，通常高电平为读，低电平为写。有些CPU的读/写命令线是分开的，此时CPU的读命令线应与存储芯片的允许读控制端相连，而CPU的写命令线则应与存储芯片的允许写控制端相连。(4)片选线的连接片选线的连接是CPU与存储芯片正确工作的关键。存储器由许多存储芯片组成，哪一片被选中完全取决于该存储芯片的片选控制端CS是否能接收到来自CPU的片选有效信号。片选有效信号与CPU的访存控制信号\overline{MREQ}(低电平有效)有关，因为只有当CPU要求访存时，才需选择存储芯片。若CPU访问I/O，则MREQ为高电平，表示不要求存储器工作。此外，片选有效信号还和地址有关，因为CPU的地址线往往多于存储芯片的地址线，故那些未与存储芯片连上的高位地址必须和访存控制信号共同产生存储芯片的片选信号。通常需用到一些逻辑电路，如译码器及其他各种门电路，来产生片选有效信号。(5)合理选择存储芯片合理选择存储芯片主要是指存储芯片类型(RAM或ROM)和数量的选择。通常选用ROM存放系统程序、标准子程序和各类常数等。RAM则是为用户编程而设置的。此外，在考虑芯片数量时，要尽量使连线简单方便。例4.1设CPU有16根地址线、8根数据线，并用MREQ作为访存控制信号(低电平有效)，用WR作为读/写控制信号(高电平为读，低电平为写)。现有下列存储芯片:1K×4位RAM、4K×8位RAM、8K×8位RAM、2K×8位ROM、4K×8位ROM、8K×8位ROM及74138译码器和各种门电路，如图4.36所示。画出CPU与存储器的连接图，要求如下：①主存地址空间分配：6000H~67FFH为系统程序区。6800H~6BFFH为用户程序区。②合理选用上述存储芯片，说明各选几片。③详细画出存储芯片的片选逻辑图。第二步，根据地址范围的容量以及该范围在计算机系统中的作用，选择存储芯片。根据6000H~67FFH为系统程序区的范围,应选择1片2K×8位的ROM,若选择4K×8位或8K×8位的ROM,都超出了2K×8位的系统程序区范围。根据6800H~6BFFH为用户程序区的范围,选2片1K×4位的RAM芯片正好满足1K×8位的用户程序区要求。第三步，分配CPU的地址线。将CPU的低11位地址A₁₀~A₀与2K×8位的ROM地址线相连;将CPU的低10位地址A₉~A₀与2片1K×4位的RAM地址线相连。剩下的高位地址与访存控制信号MREQ共同产生存储芯片的片选信号。第四步，片选信号的形成。由图4.36给出的74138译码器输入逻辑关系可知，必须保证控制端G₁为高电平，G_{2A}与G_{2B}为低电平，才能使译码器正常工作。根据第一步写出的存储器地址范围得出，A₁₅始终为低电平，A₁₄始终为高电平，它们正好可分别与译码器的G₂A(低)和G₁(高)对应。而访存控制信号MREQ(低电平有效)又正好可与G₂₈(低)对应。剩下的A₁₃、A₁₂、A₁₁可分别接到译码器的C、B、A输入端。其输出Y₄有效时,选中1片ROM;Y₅.与A₁₀同时有效均为低电平时，与门输出选中2片RAM,如图4.37所示。图中ROM芯片的PD‖Progr端接地，以确保在读出时低电平有效。RAM芯片的读写控制端与CPU的读写命令端WR相连。ROM的8根数据线直接与CPU的8根数据线相连，2片RAM的数据线分别与CPU数据总线的高4位和低4位相连。例4.2假设CPU及其他芯片同例4.1，画出CPU与存储器的连接图。要求主存的地址空间满足下述条件：最小8K地址为系统程序区，与其相邻的16K地址为用户程序区，最大4K地址空间为系统程序工作区。详细画出存储芯片的片选逻辑并指出存储芯片的种类及片数。例4.3设CPU有20根地址线和16根数据线，并用10/M作为访存控制信号，RD为读命98第2篇计算机系统的硬件结构令，WR为写命令。CPU可通过BHE和A₀来控制按字节或字两种形式访存(如表4.1所示)。要求采用图4.39所示的芯片，门电路自定。试回答：(1)CPU按字节访问和按字访问的地址范围各是多少?(2)CPU按字节访问时需分奇偶体，且最大64KB为系统程序区，与其相邻的64KB为用户程序区。写出每片存储芯片所对应的二进制地址码。在计算机运行过程中，由于种种原因致使数据在存储过程中可能出现差错。为了能及时发现错误并及时纠正错误，通常可将原数据配成汉明编码。汉明码是由RichardHanming于1950年提出的,它具有一位纠错能力。由编码纠错理论得知，任何一种编码是否具有检测能力和纠错能力，都与编码的最小距离有关。所谓编码最小距离，是指在一种编码系统中，任意两组合法代码之间的最少二进制位数的差异。根据纠错理论得L-1=D+C且D≥C即编码最小距离L越大，则其检测错误的位数D越大，纠正错误的位数C也越大，且纠错能力恒小于或等于检错能力。例如，当编码最小距离L=3时，这种编码可视为最多能检错二位，或能检错一位、纠错一位。可见，倘若能在信息编码中增加若干位检测位，增大L，显然便能提高检错和纠错能力。汉明码就是根据这一理论提出的具有一位纠错能力的编码。设欲检测的二进制代码为n位，为使其具有纠错能力，需增添k位检测位，组成n+k位的代码。为了能准确对错误定位以及指出代码没错，新增添的检测位数k应满足：2ᵏ≥n+k+1由此关系可求得不同代码长度n所需检测位的位数k，如表4.2所示。表4.2代码长度与检测位位数的关系nk(最小)122~435~11412~26527~57658~1207k的位数确定后，便可由它们所承担的检测任务设定它们在被传送代码中的位置及它们的取值。设n+k位代码自左至右依次编为第1,2,3,…,n+k位，而将k位检测位记作Cᵢ(i=1,2,4,8，…)，分别安插在n+k位代码编号的第1,2,4,8,…,2k⁻\frac{1}{4}位上。这些检测位的位置设置是为了保证它们能分别承担n+k位信息中不同数位所组成的“小组”的奇偶检测任务，使检测位和它所负责检测的小组中1的个数为奇数或偶数，具体分配如下：C₁检测的g₁小组包含1,3,5,7,9,11,…位。C₂检测的g₂小组包含2,3,6,7,10,11,14,15,…位。第4章存储器101C₄检测的g₃小组包含4,5,6,7,12,13,14,15,…位。C₈检测的g₄小组包含8,9,10,11,12,13,14,15,24,…位。⋮其余检测位的小组所包含的位也可类推。这种小组的划分有如下特点：①每个小组g₁有一位且仅有一位为它所独占，这一位是其他小组所没有的，即gᵢ小组独占第2⁻¹位(i=1,2,3,…)。②每两个小组g₁和gⱼ共同占有一位是其他小组没有的，即每两小组gᵢ和gⱼ共同占有第2ⁱ⁻¹+2ʲ⁻¹位(i,j=1,2,…)。③每3个小组g₁、gⱼ和g₁共同占有第2ⁱ⁻¹+2ʲ⁻¹+2ˡ⁻¹位，是其他小组所没有的。依次类推，便可确定每组所包含的各位。例如，欲传递信息为b₄b₃b₂b₁(n=4),根据2ᵏ≥n+k+1,可求出配置成汉明码需增添检测位k=3，且它们位置的安排如下：二进制序号\frac{1}{2}\frac{3}{3}\frac{4}{65}\frac{6}{63}\frac{6}{63}名称\frac{6}{656265}如果按配偶原则来配置汉明码，则C₁应使1、3、5、7位中的“1”的个数为偶数；(C₂应使2、3、6、7位中的“1”的个数为偶数;C₄应使4、5、6、7位中的“1”的个数为偶数。故C₁应为3位⊕5位⊕7位,即C₁=b₄⊕b₃⊕b₁;C₂应为3位⊕6位⊕7位,即C₂=b₄⊕b₂⊕b₁;C₄应为5位⊕6位⊕7位,即C₄=b₃⊕b₂⊕b₁。令b₄b₃b₂b₁=0101,则C₁=b₄⊕b₃⊕b₁=0⊕1④1=0C₂=b₄⊕b₂⊕b₁=0⊕0⊕1=1C₄=b₃④b₂⊕b₁=1④0④1=0故0101的汉明码应为C₁C₂b₄C₄b₃b₂b₁,,即0100101。汉明码的纠错过程实际上是对传送后的汉明码形成新的检测位1P_{i}(i=1,2,4,8,\cdots),，根据Pᵢ的状态，便可直接指出错误的位置。Pi的状态是由原检测位Cᵢ及其所在小组内“1”的个数确定的。倘若按配偶原则配置的汉明码，其传送后形成新的检测位Pᵢ应为0，否则说明传送有错，并且还可直接指出出错的位置。由于Pi与Ci有对应关系，故Pi可由下式确定：P₁=1④3④5⊕7,即P₁=C₁⊕b₄⊕b₃⊕b₁P₂=2④3④6④7,即P₂=C₂⊕b₄⊕b₂⊕b₁P₄=4④5⊕6⊕7,即P₄=C₄⊕b₃⊕b₂⊕b₁设已知传送的正确汉明码(按配偶原则配置)为0100101，若传送后接收到的汉明码为0100111，其出错位可按下述步骤确定。令二进制序号1234567正确的汉明码0100101接收到的汉明码0100111则新的检测位为P₄=4④5⊕6⊕7,即P₄=0⊕1⊕1⊕1=1P₂=2④3⊕6⊕7,即P₂=1⊕0⊕1⊕1=1P₁=1④3④5⊕7,即P₁=0⊕0⊕1⊕1=0由此可见，传送结果P₄和P₂均不呈偶数，显然出了差错。那么，错在哪一位呢?仔细分析发现，只有第6位出错才会同时使P₄和P₂不呈偶数。同时，P₄、P₂、P₁所构成的二进制值恰恰是出错的位置，即P₄P₂P₁=110,表示第6位出错。发现错误后，计算机便自动将错误的第6位“1”纠正为“0”。又如，若收到按偶配置的汉明码为1100101，则经检测得P₄=4⊕5⊕6⊕7,即1P₄=0⊕1⊕0⊕1=0P₂=2④3⊕6④7,即P₂=1⊕0⊕0⊕1=0P₁=1⊕3⊕5⊕7,|即P₁=1⊕0⊕1⊕1=1即P₄P₂P₁=001,表示第1位出错。由于第1位不是欲传送的信息位，而是检测位，而检测位不参与运算，故在一般情况下可以不予纠正。以上均以n=4为例，其实对任意不同n位的信息，均可按上述步骤配置汉明码，即先求出需增加的检测位位数k，再确定C；的位置，然后，按奇或偶原则配置C；各位的值即可。值得注意的是：按奇配置与按偶配置所求得的Cᵢ值正好相反，而新的检测位Pᵢ的取值与奇偶配置原则是相对应的，读者可自行分析。汉明码常常被用在纠错一位的场合，若欲实现检错两位，实用时还得再增添一位检测位。例4.4已知接收到的汉明码为0110101(按配偶原则配置)，试问欲传送的信息是什么?解：由于要求出欲传送的信息，必须是正确的信息，因此不能简单地从接收到的7位汉明码中去掉C₁,C₂,C₄这3位检测位来求得。首先应该判断收到的信息是否出错。纠错过程如下：P₁=1④3④5⊕7=1P₂=2④3④6⊕7=1P₄=4④5④6④7=0所以，P₄P₂P₁=011,第3位出错，可纠正为0100101，故欲传送的信息为0101。例4.5按配奇原则配置1100101的汉明码。解:根据1100101,得n=7。根据2ᵏ≥n+k+1,可求出需增添k=4位检测位，各位的安排如下：二进制序号1234567891011汉明码C₁C₂1C₄100C₈101按配奇原则配置，则C₁=3⊕5⊕7⊕9⊕11=1C₂=3⊕6⊕7⊕10⊕11=1C₄=5④6⊕7=0故新配置的汉明码为11101001101。随着计算机应用领域的不断扩大，处理的信息量越来越多，对存储器的工作速度和容量要求也越来越高。此外，因CPU的功能不断增强，I/O设备的数量不断增多，致使主存的存取速度已成为计算机系统的瓶颈。可见，提高访存速度也成为迫不及待的任务。为了解决此问题，除了寻找高速元件和采用层次结构以外，调整主存的结构也可提高访存速度。由于程序和数据在存储体内是连续存放的，因此CPU访存取出的信息也是连续的，如果可以在一个存取周期内，从同一地址取出4条指令，然后再逐条将指令送至CPU执行，即每隔1/4存取周期，主存向CPU送一条指令，这样显然增大了存储器的带宽，提高了单体存储器的工作速度,如图4.41所示。单字长寄存器W位数据寄存器W位W位W位W位***主存控制器存储体地址寄存器图中示意了一个单体四字结构的存储器，每字W位。按地址在一个存取周期内可读出4×W位的指令或数据，使主存带宽提高到4倍。显然，采用这种办法的前提是：指令和数据在主存内必须是连续存放的，一旦遇到转移指令，或者操作数不能连续存放，这种方法的效果就不明显。多体并行系统就是采用多体模块组成的存储器。每个模块有相同的容量和存取速度，各模块各自都有独立的地址寄存器(MAR)、数据寄存器(MDR)、地址译码、驱动电路和读/写电路，它们能并行工作，又能交叉工作。并行工作即同时访问N个模块，同时启动，同时读出，完全并行地工作(不过，同时读出的N个字在总线上需分时传送)。图4.42是适合于并行工作的高位交叉编址的多体存储器结构示意图，图中程序因按体内地址顺序存放(一个体存满后，再存入下一个体)，故又有顺序存储之称。显然，高位地址可表示体号，低位地址为体内地址。按这种编址方式，只要合理调动，使不同的请求源同时访问不同的体，便可实现并行工作。例如，当一个体正与CPU交换信息时，另一个体可同时与外部设备进行直接存储器访问，实现两个体并行工作。这种编址方式由于一个体内的地址是连续的，有利于存储器的扩充。图4.43是按低位交叉编址的多体模块结构示意图。由于程序连续存放在相邻体中，故又有交叉存储之称。显然低位地址用来表示体号，高位地址为体内地址。这种编址方法又称为模M编址(M等于模块数)，表4.3列出了模4交叉编址的地址号。一般模块数M取2的方幂，使硬件电路比较简单。有的机器为了减少存储器冲突，采用质数个模块，例如，我国银河机的M为31，其硬件实现比较复杂。体号体内地址序号最低两位地址M₀0,4,8,12,…,4i+000M₁1,5,9,13,…,4i+101M₂2,6,10,14,…,4i+210M₃3,7,11,15,…,4i+311多体模块结构的存储器采用交叉编址后，可以在不改变每个模块存取周期的前提下，提高存储器的带宽。图4.44示意了CPU交叉访问4个存储体的时间关系，负脉冲为启动每个体的工作信号。虽然对每个体而言，存取周期均未缩短，但由于CPU交叉访问各体，使4个存储体的读/写过程重叠进行，最终在一个存取周期的时间内，存储器实际上向CPU提供了4个存储字。如果每个模块存储字长为32位，则在一个存取周期内(除第一个存取周期外)，存储器向CPU提供了32×4=128位二进制代码，大大增加了存储器的带宽。假设每个体的存储字长和数据总线的宽度一致，并假设低位交叉的存储器模块数为n，存取周期为T，总线传输周期为τ，那么当采用流水线方式(如图4.44所示)存取时，应满足T=nτ。为了保证启动某体后，经nr时间再次启动该体时，它的上次存取操作已完成，要求低位交叉存储器的模块数大于或等于n。以四体低位交叉编址的存储器为例，采用流水方式存取的示意图如图4.45所示。解：顺序存储(高位交叉编址)和交叉存储(低位交叉编址)连续读出4个字的信息量是32×4=128位。水线工作方式示意图顺序存储存储器连续读出4个字的时间是200ns×4=800ns=8×10⁻⁷s交叉存储存储器连续读出4个字的时间是200ns+50ns×(4-1)=350ns=3.5×10⁻⁷s顺序存储器的带宽是128‖(8×10⁻⁷)=16×10⁷bps交叉存储器的带宽是128↓(3.5×10⁻⁷)=37×10⁷bps多体模块存储器不仅要与CPU交换信息，还要与辅存、I/O设备，乃至I/O处理机交换信息。因此，在某一时刻，决定主存究竟与哪个部件交换信息必须由存储器控制部件(简称存控)来承担。存控具有合理安排各部件请求访问的顺序以及控制主存读/写操作的功能。图4.46是一个存控基本结构框图，它由排队器、控制线路、节拍发生器及标记触发器等组成。存控(1)排队器标记触发器由于要求访存的请求源很多，而且访问都是随机的，这样有可能在同一时刻出现多个请求源请求访问同一个存储体。为了防止发生两个以上的请求源同时占用同一存储体，并防止将代码错送到另一个请求源等各种错误的发生，在存控内需设置一个排队器，由它来确定请求源的优先级别。其确定原则如下：①对易发生代码丢失的请求源，应列为最高优先级，例如，外设信息最易丢失，故它的级别最高。②对严重影响CPU工作的请求源，给予次高优先级，否则会导致CPU工作失常。例如，写数请求高于读数，读数请求高于读指令。若运算部件不能尽快送走已算出的结果，会严重影响后续指令的执行，因此，发生这种情况时，写数的优先级比读数、读指令都高。若没有操作数参与运算，取出更多的指令也无济于事，故读数的优先级又应比读指令高。(2)存控标记触发器CM它用来接受排队器的输出信号，一旦响应某请求源的请求，CM被置“1”，以便启动节拍发生器工作。(3)节拍发生器它用来产生固定节拍，与机器主脉冲同步，使控制线路按一定时序发出信号。(4)控制线路由它将排队器给出的信号与节拍发生器提供的节拍信号配合，向存储器各部件发出各种控制信号，用以实现对总线控制及完成存储器读/写操作，并向请求源发出回答信号，表示存储器已响应了请求等。采用高性能存储芯片也是提高主存速度的措施之一。DRAM集成度高，价格便宜，广泛应用于主存。其发展速度很快，几乎每隔3年存储芯片的容量就翻两番。为了进一步提高DRAM的性能,人们开发了许多对基本DRAM结构的增强功能,出现了SDRAM、RDRAM和CDRAM。(1)SDRAM(SynchronousDRAM,同步DRAM)SDRAM与常用的异步DRAM不同，它与处理器的数据交换同步于系统的时钟信号，并且以处理器-存储器总线的最高速度运行，而不需要插入等待状态。典型的DRAM中，处理器将地址和控制信号送至存储器后，需经过一段延时，供DRAM执行各种内部操作(如输入地址、读出数据等)，才能将数据从存储器中读出或将数据写入存储器中。此时，如果CPU的速度与DRAM匹配，那么这个延时不会影响CPU的工作速度；如果CPU的速度更高，那么在这段时间内，CPU只能“等待”，降低了CPU的执行速度。而SDRAM能在系统时钟的控制下进行数据的读出和写入，CPU给出的地址和控制信号会被SDRAM锁存，直到指定的时钟周期数后再响应。此时CPU可执行其他任务，无须“等待”。例如，系统的时钟周期为10ns，存储器接到地址后需50ns读出数据。对于异步工作的DRAM，CPU要“等待”50ns获得数据，而对同步工作的SDRAM而言，CPU只需把地址放入锁存器中，在存储器进行读操作期间去完成其他操作。当CPU计时到5个时钟周期后，便可获得从存储器读出的数据。SDRAM还支持猝发访问模式，即CPU发出一个地址就可以连续访问一个数据块(通常为32字节)。SDRAM芯片内还可以包含多个存储体，这些体可以轮流工作，提高访问速度。现在又出现了双数据速率的SDRAM(DoubleDataRateSDRAM,DDR-SDRAM),它是SDRAM的增强型版本，可以每周期两次向处理器送出数据。(2)RDRAM(RambusDRAM)由Rambus开发的RDRAM采用专门的DRAM和高性能的芯片接口取代现有的存储器接口。它主要解决存储器带宽的问题，通过高速总线获得存储器请求(包括操作时所需的地址、操作类型和字节数)，总线最多可寻址320块RDRAM芯片，传输率可达1.6GBps。它不像传统的DRAM采用\overline{RAS}、\overline{CAS}和WE信号来控制，而是采用异步的面向块的传输协议传送地址信息和数据信息。一个RDRAM芯片就像一个存储系统，通过一种新的互连电路RamLink，将各个RDRAM芯片连接成一个环，数据通信在主存控制器的控制下进行，数据交换以包为单位。图4.47示意了RamLink体系结构。(3)带Cache的DRAM(CDRAM)带Cache的DRAM是在通常的DRAM芯片内又集成了一个小的SRAM，又称增强型的DRAM(EDRAM)。图4.48是1M×4位的CDRAM,其中SRAM为:512×4位,DRAM排列成2048×512×4位的阵列。由图中可见，地址引脚线只有11根((A₁₀∼A₀),而1M×4位的存储芯片对应20位地址，此20位地址需分时送入芯片内部。首先在行选通信号作用下，高11位地址经地址引脚线输入，分别保存在行地址锁存器中和最后读出行地址锁存器中。在DRAM的2048行中，此指定行地址的全部数据512×4位被读到SRAM中暂存。然后在列选通信号作用下，低9位地址经地址引脚线输入，保存到列地址锁存器中。在读命令有效时，512个4位组的SRAM中某一4位组被这个列地址选中，经数据线D₃~D₀从芯片输出。下一次读取时，输入的行地址立即与最后读出行锁存器的内容进行11位比较。若比较相符，说明该数据在SRAM中，再由输入列地址选择某一4位组输出；若比较不相符，则需驱动DRAM阵列更新SRAM和最后读出行地址锁存器中的内容，并送出指定的4位组。由此可见，以SRAM保存一行内容的方法，当对连续高11位地址相同(属于同一行地址)的数据进行读取时，只需连续变动9位列地址就可使相应的4位组连续读出，这被称为猝发式读取，对成块传送十分有利。从图4.48所示的结构可见，芯片内的数据输出路径(由SRAM到I/O)与数据输入路径(由I/O到读放大器和列写选择)是分开的，这就允许在写操作完成的同时启动同一行的读操作。此外，在SRAM读出期间可同时对DRAM阵列进行刷新。在多体并行存储系统中，由于I/O设备向主存请求的级别高于CPU访存，这就出现了CPU等待I/O设备访存的现象，致使CPU空等一段时间，甚至可能等待几个主存周期，从而降低了CPU的工作效率。为了避免CPU与I/O设备争抢访存，可在CPU与主存之间加一级缓存(参见图4.3)，这样，主存可将CPU要取的信息提前送至缓存，一旦主存在与I/O设备交换时，CPU可直接从缓存中读取所需信息，不必空等而影响效率。从另一角度来看，主存速度的提高始终跟不上CPU的发展。据统计，CPU的速度平均每年改进60%，而组成主存的动态RAM速度平均每年只改进7%，结果是CPU和动态RAM之间的速度间隙平均每年增大50%。例如,100MHz的Pentium处理器平均每10ns就执行一条指令,而动态RAM的典型访问时间为60~120ns。这也希望由高速缓存Cache来解决主存与CPU速度的不匹配问题。Cache的出现使CPU可以不直接访问主存，而与高速Cache交换信息。那么，这是否可能呢?通过大量典型程序的分析，发现CPU从主存取指令或取数据，在一定时间内，只是对主存局部地址区域的访问。这是由于指令和数据在主存内都是连续存放的，并且有些指令和数据往往会被多次调用(如子程序、循环程序和一些常数)，即指令和数据在主存的地址分布不是随机的，而是相对的簇聚，使得CPU在执行程序时，访存具有相对的局部性，这就称为程序访问的局部性110第2篇计算机系统的硬件结构原理。根据这一原理，很容易设想，只要将CPU近期要用到的程序和数据提前从主存送到Cache,那么就可以做到CPU在一定时间内只访问Cache。一般Cache采用高速的SRAM制作,其价格比主存贵，但因其容量远小于主存，因此能很好地解决速度和成本的矛盾。图4.49是Cache-主存存储空间的基本结构示意图。主存由2"个可编址的字组成，每个字有唯一的n位地址。为了与Cache映射，将主存与缓存都分成若干块，每块内又包含若干个字，并使它们的块大小相同(即块内的字数相同)。这就将主存的地址分成两段：高m位表示主存的块地址，低b位表示块内地址，则2ᵐ=M表示主存的块数。同样，缓存的地址也分为两段：高c位表示缓存的块号，低b位表示块内地址，则2°=C表示缓存块数，且C远小于M。主存与缓存地址中都用b位表示其块内字数，即B=2ᵇ反映了块的大小，称B为块长。任何时刻都有一些主存块处在缓存块中。CPU欲读取主存某字时，有两种可能：一种是所需要的字已在缓存中，即可直接访问Cache(CPU与Cache之间通常一次传送一个字)；另一种是所需的字不在Cache内，此时需将该字所在的主存整个字块一次调入Cache中(Cache与主存之间是字块传送)。如果主存块已调入缓存块，则称该主存块与缓存块建立了对应关系。上述第一种情况为CPU访问Cache命中，第二种情况为CPU访问Cache不命中。由于缓存的块数C远小于主存的块数M，因此，一个缓存块不能唯一地、永久地只对应一个主存块，故每个缓存块需设一个标记(参见图4.49)，用来表示当前存放的是哪一个主存块，该标记的内容相当于主存块的编号。CPU读信息时，要将主存地址的高m位(或m位中的一部分)与缓存块的标记进行比较，以判断所读的信息是否已在缓存中(参见图4.54)。Cache的容量与块长是影响Cache效率的重要因素，通常用“命中率”来衡量Cache的效率。命中率是指CPU要访问的信息已在Cache内的比率。一般而言，Cache容量越大，其CPU的命中率就越高。当然容量也没必要太大，太大会增加成本，而且当Cache容量达到一定值时，命中率已不因容量的增大而有明显的提高。因此，Cache容量是总成本价与命中率的折中值。例如，80386的主存最大容量为4GB，与其配套的Cache容量为16KB或32KB,其命中率可达95%以上。块长与命中率之间的关系更为复杂，它取决于各程序的局部特性。当块由小到大增长时，起初会因局部性原理使命中率有所提高。由局部性原理指出，在已被访问字的附近，近期也可能被访问，因此，增大块长，可将更多有用字存入缓存，提高其命中率。可是，倘若继续增大块长，命中率很可能下降，这是因为所装入缓存的有用数据反而少于被替换掉的有用数据。由于块长的增大，导致缓存中块数的减少，而新装入的块要覆盖旧块，很可能出现少数块刚刚装入就被覆盖，因此命中率反而下降。再者，块增大后，追加上的字距离已被访问的字更远，故近期被访问的可能性会更小。块长的最优值是很难确定的，一般每块取4至8个可编址单位(字或字节)较好，也可取一个主存周期所能调出主存的信息长度。例如，CRAY-1的主存是16体交叉，每个体为单字宽，其存放指令的Cache块长为16个字。又如，IBM370/168机主存是4体交叉，每个体宽为64位(8个字节),其Cache块长为32个字节。Cache的基本结构原理框图如图4.50所示。它主要由Cache存储体、地址映射变换机构、Cache替换机构几大模块组成。(1)Cache存储体Cache存储体以块为单位与主存交换信息，为加速Cache与主存之间的调动，主存大多采用多体结构，且Cache访存的优先级最高。(2)地址映射变换机构地址映射变换机构是将CPU送来的主存地址转换为Cache地址。由于主存和Cache的块大小相同，块内地址都是相对于块的起始地址的偏移量(即低位地址相同)，因此地址变换主要第4章存储器113是主存的块号(高位地址)与Cache块号间的转换。而地址变换又与主存地址以什么样的函数关系映射到Cache中(称为地址映射)有关，这些内容可详见4.3.2节。如果转换后的Cache块已与CPU欲访问的主存块建立了对应关系，即已命中，则CPU可直接访问Cache存储体。如果转换后的Caohe块与CPU欲访问的主存块未建立对应关系，即不命中，此刻CPU在访问主存时，不仅将该字从主存取出，同时将它所在的主存块一并调入Cache,供CPU使用。当然,此刻能将主存块调入Cache内,也是由于Cache原来处于未被装满的状态。反之，倘若Cache原来已被装满，即已无法将主存块调入Cache内时，就得采用替换策略。(3)替换机构当Cache内容已满，无法接受来自主存块的信息时，就由Cache内的替换机构按一定的替换算法来确定应从Cache内移出哪个块返回主存，而把新的主存块调入Cache。有关替换算法详见4.3.3节。特别需指出的是，Cache对用户是透明的，即用户编程时所用到的地址是主存地址，用户根本不知道这些主存块是否已调入Cache内。因为，将主存块调入Cache的任务全由机器硬件自动完成。(4)Cache的读写操作读操作的过程可用流程图4.51来描述。当CPU发出主存地址后，首先判断该存储字是否在Cache中。若命中，直接访问Cache，将该字送至CPU；若未命中，一方面要访问主存，将该字传送给CPU，与此同时，要将该字所在的主存块装入Cache，如果此时Cache已装满，就要执行替换算法，腾出空位才能将新的主存块调入。写操作比较复杂，因为对Cache块内写入的信息，必须与被映射的主存块内的信息完全一致。当程序运行过程中需对某个单元进行写操作时，会出现如何使Cache与主存内容保持一致的问题。目前主要采用以下几种方法。①写直达法(Write-through),又称为存直达法(Store-through),即写操作时数据既写入Cache又写入主存。它能随时保证主存和Cache的数据始终一致，但增加了访存次数。②写回法(Write-back),又称为拷回法(Copy-back),即写操作时只把数据写入Cache而不写入主存，但当Cache数据被替换出去时才写回主存。可见写回法Cache中的数据会与主存中的不一致。为了识别Cache中的数据是否与主存一致，Cache中的每一块要增设一个标志位，该位有两个状态：“清”(表示未修改过，与主存一致)和“浊”(表示修改过，与主存不一致)。在Cache替换时，“清”的Cache块不必写回主存，因为此时主存中相应块的内容与Cache块是一致的。在写Cache时，要将该标志位设置为“浊”，替换时此Cache块要写回主存，同时要使标志位为“清”。写回法和写直达法各有特色。在写直达法中，由于Cache中的数据始终和主存保持一致，在读操作Cache失效时，只需选择一个替换的块(主存块)调入Cache，被替换的块(Cache块)不必写回主存。可见读操作不涉及对主存的写操作。因此这种方法更新策略比较容易实现。但是在写操作时，既要写入Cache又要写入主存，因此写直达法的“写”操作时间就是访问主存的时间。在写回法中，写操作时只写入Cache，故“写”操作时间就是访问Cache的时间，因此速度快。这种方法对主存的写操作只发生在块替换时，而且对Cache中一个数据块的多次写操作只需一次写入主存，因此可减少主存的写操作次数。但在读操作Cache失效时要发生数据替换，引起被替换的块写回主存的操作，增加了Cache的复杂性。对于有多个处理器的系统，各自都有独立的Cache，且都共享主存，这样又出现了新问题。即当一个缓存中数据被修改时，不仅主存中相对应的字无效，连同其他缓存中相对应的字也无效(当然恰好其他缓存也有相应的字)。即使通过写直达法改变了主存的相应字，而其他缓存中数据仍然无效。显然，解决系统中Cache一致性的问题很重要。当今研究Cache一致性问题非常活跃，想进一步了解可查阅有关资料。Cache刚出现时，典型系统只有一个缓存，近年来普遍采用多个Cache。其含义有两方面：一是增加Cache的级数;二是将统一的Cache变成分立的Cache。(1)单一缓存和两级缓存所谓单一缓存，是指在CPU和主存之间只设一个缓存。随着集成电路逻辑密度的提高，又把这个缓存直接与CPU制作在同一个芯片内，故又称为片内缓存(片载缓存)。片内缓存可以提高外部总线的利用率，因为将Cache制作在芯片内，CPU直接访问Cache不必占用芯片外的总线(系统总线)，而且片内缓存与CPU之间的数据通路很短，大大提高了存取速度，外部总线又可更多地支持I/O设备与主存的信息传输，增强了系统的整体效率。例如，Intel80486CPU芯片内就第4章存储器115含8KB的片内缓存。可是，由于片内缓存在芯片内，其容量不可能很大，这就可能致使CPU欲访问的信息不在缓存内，势必通过系统总线访问主存，访问次数多了，整机速度就会下降。如果在主存与片内缓存之间再加一级缓存，称为片外缓存，由比主存动态RAM和ROM存取速度更快的静态RAM组成。而且不使用系统总线作为片外缓存与CPU之间的传送路径，使用一个独立的数据路径，以减轻系统总线的负担。那么，从片外缓存调入片内缓存的速度就能提高，而CPU占用系统总线的时间也就大大下降，整机工作速度有明显改进。这种由片外缓存和片内缓存组成的Cache称为两级缓存，并称片内缓存为第一级，片外缓存为第二级。随着芯片集成度的提高，已有一些处理器将第二级Cache结合到处理器芯片上，改善了性能。(2)统一缓存和分立缓存统一缓存是指指令和数据都存放在同一缓存内的Cache；分立缓存是指指令和数据分别存放在两个缓存中，一个称为指令Cache，另一个称为数据Cache。两种缓存的选用主要考虑如下两个因素。其一，它与主存结构有关，如果计算机的主存是统一的(指令、数据存储在同一主存内)，则相应的Cache采用统一缓存；如果主存采用指令、数据分开存储的方案，则相应的Cache采用分立缓存。其二，它与机器对指令执行的控制方式有关。当采用超前控制或流水线控制方式时，一般都采用分立缓存。所谓超前控制，是指在当前指令执行过程尚未结束时就提前将下一条准备执行的指令取出，称为超前取指或指令预取。所谓流水线控制实质上是多条指令同时执行(详见第8章)，又可视为指令流水。当然，要实现同时执行多条指令，机器的指令译码电路和功能部件也需多个。超前控制和流水线控制特别强调指令的预取和指令的并行执行，因此，这类机器必须将指令Cache和数据Cache分开，否则可能出现取指和执行过程对统一缓存的争用。如果此刻采用统一缓存，则在执行部件向缓存发出取数请求时，一旦指令预取机构也向缓存发出取指请求，那么统一缓存只能先满足执行部件请求，将数据送到执行部件，而让取指请求暂时等待，显然达不到预取指令的目的，从而影响指令流水的实现。可见，这类机器将两种缓存分立尤为重要。图4.52为Pentium4处理器框图。图中有两级共3个Cache,其中一级Cache分L1指令Cache和L1数据Cache,另外还有一个二级L2Cache。图中也有两个Cache。数据Cache通过存/取单元支持整数和浮点操作；指令Cache为只读存储器，支持指令单元。执行部件是3个可并行操作的整数ALU和一个浮点运算部件(有独立的寄存器和乘、加、除部件)。由主存地址映射到Cache地址称为地址映射。地址映射方式很多，有直接映射(固定的映射关系)、全相联映射(灵活性大的映射关系)、组相联映射(上述两种映射的折中)。图4.54示出了直接映射方式主存与缓存中字块的对应关系。图中每个主存块只与一个缓存块相对应，映射关系式为i=jmodC或i=jmod2ᶜ其中，i为缓存块号，j为主存块号，C为缓存块数。映射结果表明每个缓存块对应若干个主存块，如表4.4所示。这种方式的优点是实现简单，只需利用主存地址的某些位直接判断，即可确定所需字块是否在缓存中。由图4.54可见，主存地址高m位被分成两部分：低c位是指Cache的字块地址，高t位(t=m-c)是指主存字块标记，它被记录在建立了对应关系的缓存块的“标记”位中。当缓存接118第2篇计算机系统的硬件结构到CPU送来的主存地址后，只需根据中间c位字段(假设为00…01)找到Cache字块1，然后根据字块1的“标记”是否与主存地址的高t位相符来判断，若符合且有效位为“1”(有效位用来识别Cache存储块中的数据是否有效，因为有时Cache中的数据是无效的，例如，在初始时刻Cache应该是“空”的，其中的内容是无意义的)，表示该Cache块已和主存的某块建立了对应关系(即已命中)，则可根据b位地址从Cache中取得信息；若不符合，或有效位为“0”(即不命中)，则从主存读入新的字块来替代旧的字块，同时将信息送往CPU，并修改Cache“标记”。如果原来有效位为“0”，还得将有效位置成“1”。直接映射方式的缺点是不够灵活，因每个主存块只能固定地对应某个缓存块，即使缓存内还空着许多位置也不能占用，使缓存的存储空间得不到充分的利用。此外，如果程序恰好要重复访问对应同一缓存位置的不同主存块，就要不停地进行替换，从而降低命中率。全相联映射允许主存中每一字块映射到Cache中的任何一块位置上，如图4.55所示。这种映射方式可以从已被占满的Cache中替换出任一旧字块。显然，这种方式灵活，命中率也更高，缩小了块冲突率。与直接映射相比，它的主存字块标记从t位增加到t+c位，这就使Cache“标记”的位数增多，而且访问Cache时主存字块标记需要和Cache的全部“标记”位进行比较，才能判断出所访问主存地址的内容是否已在Cache内。这种比较通常采用“按内容寻址”的相联存储器(见附录4A)来完成。总之，这种方式所需的逻辑电路甚多，成本较高，实际的Cache还要采用各种措施来减少地址的比较次数。组相联映射是对直接映射和全相联映射的一种折中。它把Cache分为Q组，每组有R块，并有以下关系：i=jmodQ其中，i为缓存的组号，j为主存的块号。某一主存块按模Q将其映射到缓存的第i组内，如图4.56所示。组相联映射的主存地址各段与直接映射(参见图4.54)相比，还是有区别的。图4.54中Cache字块地址字段由c位变为组地址字段q位，且q=c-r，其中2°表示Cache的总块数，2°表示Cache的分组个数，2'表示组内包含的块数。主存字块标记字段由t位变为s=t+r位。为了便于理解,假设c=5,q=4,则r=c-q=1。其实际含义为：Cache共有2°=32个字块，共分为2^{q}=16组,每组内包含2'=2块。组内2块的组相联映射又称为二路组相联。根据上述假设条件，组相联映射的含义是：主存的某一字块可以按模16映射到Cache某组的任一字块中。即主存的第0，16，32…字块可以映射到Cache第0组2个字块中的任一字块；主存的第15，31，47…字块可以映射到Cache第15组中的任一字块。显然，主存的第j块会映射到Cache的第i组内，两者之间一一对应，属直接映射关系；另一方面，主存的第j块可以映射到Cache的第i组内中的任一块，这又体现出全相联映射关系。可见，组相联映射的性能及其复杂性介于直接映射和全相联映射两者之间，当r=0时是直接映射方式，当r=c时是全相联映射方式。例4.8假设主存容量为512KB,Cache容量为4KB,每个字块为16个字,每个字32位。(1)Cache地址有多少位?可容纳多少块?(2)主存地址有多少位?可容纳多少块?(3)在直接映射方式下，主存的第几块映射到Cache中的第5块(设起始字块为第1块)?(4)画出直接映射方式下主存地址字段中各段的位数。解:(1)根据Cache容量为4KB(2¹²=4K),Cache地址为12位。由于每字32位,则Cache共有4KB/4B=1K字。因每个字块16个字,故Cache中有1K/16=64块。(2)根据主存容量为512KB(2¹⁹=512K),主存地址为19位。由于每字32位，则主存共有512KB/4B=128K字。因每个字块16个字,故主存中共128K/16=8192块。(3)在直接映射方式下,由于Cache共有64块,主存共有8192块,因此主存的5,64+5,2×64+5,…,2¹³-64+5块能映射到Cache的第5块中。(4)在直接映射方式下，主存地址字段的各段位数分配如图4.57所示。其中字块内地址为6位(4位表示16个字，2位表示每字32位)，缓存共64块，故缓存字块地址为6位，主存字块标记为主存地址长度与Cache地址长度之差,即19-12=7位。例4.9假设主存容量为512K×16位,Cache容量为4096×16位,块长为4个16位的字,访存地址为字地址。(1)在直接映射方式下，设计主存的地址格式。(2)在全相联映射方式下，设计主存的地址格式。(3)在二路组相联映射方式下，设计主存的地址格式。(4)若主存容量为512K×32位，块长不变，在四路组相联映射方式下，设计主存的地址格式。解:(1)根据Cache容量为4096=2¹²字，得Cache字地址为12位。根据块长为4，且访存地址为字地址,得字块内地址为2位,即b=2,且Cache共有4096/4=1024=2¹⁰块,即c=10。根据主存容量为512K=2¹⁹字，得主存字地址为19位。在直接映射方式下，主存字块标记为19-12=7。主存的地址格式如图4.58(a)所示。(2)在全相联映射方式下,主存字块标记为19-b=19-2=17位,其地址格式如图4.58(b)所示。(3)根据二路组相联的条件，一组内有2块，得Cache共分1024/2=512=2^{q}组,即q=9,主存字块标记为19-q-b=19-9-2=8位,其地址格式如图4.58(c)所示。(4)若主存容量改为512K×32位，即双字宽存储器，块长仍为4个16位的字，访存地址仍为字地址，则主存容量可写为1024K×16位，得主存地址为20位。由四路组相联，得Cache共分1024/4=256=2^{q}组，即q=8。。对应该条件下，主存字块标记为20-8-2=10位，其地址格式如图4.58(d)所示。主存字块标记Cache字块地址字块内地址7102(a)直接映射方式主存地址格式主存字块标记字块内地址172(b)全相联映射方式主存地址格式主存字块标记组地址字块内地址892(c)二路组相联映射方式主存地址格式主存字块标记组地址字块内地址1082(d)四路组相联映射方式双字宽主存地址格式例4.10假设Cache的工作速度是主存的5倍，且Cache被访问命中的概率为95%，则采用Cache后，存储器性能提高多少?解：设Cache的存取周期为t，主存的存取周期为5t，则系统的平均访问时间为tₐ=0.95×t+0.05×5t=1.2t性能为原来的5t/1.2t=4.17倍,即提高了3.17倍。例4.11设某机主存容量为16MB,Cache的容量为8KB。每字块有8个字,每字32位。设计一个四路组相联映射的Cache组织。(1)画出主存地址字段中各段的位数。(2)设Cache初态为空,CPU依次从主存第0,1,2,…,99号单元读出100个字(主存一次读出一个字)，并重复此次序读10次，问命中率是多少?122第2篇计算机系统的硬件结构(3)若Cache的速度是主存速度的5倍,试问有Cache和无Cache相比,速度提高多少倍?(4)系统的效率为多少?解：(1)根据每个字块有8个字，每个字32位，得出主存地址字段中字块内地址字段为5位，其中3位为字地址，2位为字节地址。根据Cache容量为8KB=2¹³B,,字块大小为2⁵B,得Cache共有2⁸块,故c=8。根据四路组相联映射2'=4,得r=2,则(q=c-r=8-2=6位。根据主存容量为16MB=2²⁴B,得出主存地址字段中主存字块标记为24-6-5=13位。主存地址字段各段格式如图4.59所示。(2)由于每个字块中有8个字，而且初态Cache为空，因此CPU读第0号单元时，未命中，必须访问主存，同时将该字所在的主存块调入Cache第0组中的任一块内，接着CPU读1~7号单元时均命中。同理，CPU读第8，16，…，96号单元时均未命中。可见CPU在连续读100个字中共有13次未命中，而后9次循环读100个字全部命中，命中率为\frac{100\times10-13}{100\times10}=0.987(3)根据题意,设主存存取周期为5t,Cache的存取周期为t,没有Cache的访问时间为5t×1000,有Cache的访问时间为t(1000-13)+5t×13,则有Cache和没有Cache相比,速度提高的倍数为\frac{5t\times1000}{t(1000-13)+5t\times13}-1\approx3.75(4)根据(2)求得的命中率0.987，主存的存取周期为5t，Cache的存取周期为t，得系统的效率为\frac{t}{0.987\timest+(1-0.987)\times5t}\times100\%=95\%当新的主存块需要调入Cache并且它的可用空间位置又被占满时，需要替换掉Cache的数据，这就产生了替换策略(算法)问题。在直接映射的Cache中，由于某个主存块只与一个Cache字块有映射关系，因此替换策略很简单。而在组相联和全相联映射的Cache中，主存块可以写入Cache中若干位置，这就有一个选择替换掉哪一个Cache字块的问题，即所谓替换算法问题。理想的替换方法是把未来很少用到的或者很久才用到的数据块替换出来，但实际上很难做到。常用的替换算法有先进先出算法、近期最少使用算法和随机法。FIFO算法选择最早调入Cache的字块进行替换，它不需要记录各字块的使用情况，比较容易实现，开销小，但没有根据访存的局部性原理，故不能提高Cache的命中率。因为最早调入的信息可能以后还要用到，或者经常要用到，如循环程序。LRU算法比较好地利用访存局部性原理，替换出近期用得最少的字块。它需要随时记录Cache中各字块的使用情况，以便确定哪个字块是近期最少使用的字块。它实际是一种推测的方法，比较复杂，一般采用简化的方法，只记录每个块最近一次使用的时间。LRU算法的平均命中率比FIFO的高。随机法是随机地确定被替换的块，比较简单，可采用一个随机数产生器产生一个随机的被替换的块，但它也没有根据访存的局部性原理，故不能提高Cache的命中率。辅助存储器作为主存的后援设备又称为外部存储器，简称外存，它与主存一起组成了存储器系统的主存-辅存层次。与主存相比，辅存具有容量大、速度慢、价格低、可脱机保存信息等特点，属“非易失性”存储器。而主存具有速度快、成本高、容量小等特点，而且大多由半导体芯片构成，所存信息无法永久保存，属“易失性”存储器。目前，广泛用于计算机系统的辅助存储器有硬磁盘、软磁盘、磁带、光盘等。前三种均属磁表面存储器。磁表面存储器是在不同形状(如盘状、带状等)的载体上涂有磁性材料层，工作时，靠载磁体高速运动，由磁头在磁层上进行读/写操作，信息被记录在磁层上，这些信息的轨迹就是磁道。磁盘的磁道是一个个同心圆，如图4.60(a)所示，磁带的磁道是沿磁带长度方向的直线，如图4.60(b)所示。(1)记录密度记录密度通常是指单位长度内所存储的二进制信息量。磁盘存储器用道密度和位密度表示；磁带存储器则用位密度表示。磁盘沿半径方向单位长度的磁道数为道密度，单位是tpi(TrackPerInch,道每英寸)或tpm(道每毫米)。为了避免干扰,磁道与磁道之间需保持一定距离，相邻两条磁道中心线之间的距离称为道距，因此道密度D₁等于道距P的倒数，即D_{1}=\frac{1}{P}单位长度磁道能记录二进制信息的位数，称为位密度或线密度，单位是bpi(BitsPerInch，位每英寸)或bpm(位每毫米)。磁带存储器主要用位密度来衡量，常用的磁带有800bpi、1600bpi、6250bpi等。对于磁盘,位密度Db可按下式计算:D_{1}=\frac{f_{1}}{\pid_{\min}}其中，f₁为每道总位数，dmin为同心圆中的最小直径。在磁盘各磁道上所记录的信息量是相同的，而位密度不同，一般泛指磁盘位密度时，是指最内圈磁道上的位密度(最大位密度)。(2)存储容量存储容量是指外存所能存储的二进制信息总数量，一般以位或字节为单位。以磁盘存储器为例，存储容量可按下式计算：C=n×k×s其中，C为存储总容量，n为存放信息的盘面数，k为每个盘面的磁道数，s为每条磁道上记录的二进制代码数。磁盘有格式化容量和非格式化容量两个指标。非格式化容量是磁表面可以利用的磁化单元总数。格式化容量是指按某种特定的记录格式所能存储信息的总量，即用户可以使用的容量，它一般为非格式化容量的60%~70%。(3)平均寻址时间由存取方式分类可知，磁盘采取直接存取方式，寻址时间分为两个部分，其一是磁头寻找目标磁道的找道时间t₆，其二是找到磁道后，磁头等待欲读/写的磁道区段旋转到磁头下方所需要的等待时间tng。由于从最外圈磁道找到最里圈磁道和寻找相邻磁道所需时间是不等的，而且磁头等待不同区段所花的时间也不等，因此，取其平均值，称为平均寻址时间Tₙ，它是平均找道时间tₙ，和平均等待时间tₘ之和；T_{a}=t_{na}+t_{va}=\frac{t_{\max}+t_{\min}}{2}+\frac{t_{v\max}+t_{v\min}}{2}平均寻址时间是磁盘存储器的一个重要指标。硬磁盘的平均寻址时间比软磁盘的平均寻址时间短，所以硬磁盘存储器比软磁盘存储器速度快。磁带存储器采取顺序存取方式，磁头不动，磁带移动，不需要寻找磁道，但要考虑磁头寻找记录区段的等待时间，所以磁带寻址时间是指磁带空转到磁头应访问的记录区段所在位置的时间。(4)数据传输率数据传输率D，是指单位时间内磁表面存储器向主机传送数据的位数或字节数，它与记录密度Db和记录介质的运动速度V有关：D_{r}=D_{b}\timesV此外，辅存和主机的接口逻辑应有足够快的传送速度，用来完成接收/发送信息，以便主机与辅存之间正确无误地传送。(5)误码率误码率是衡量磁表面存储器出错概率的参数，它等于从辅存读出时，出错信息位数和读出信息的总位数之比。为了减少出错率，磁表面存储器通常采用循环冗余码来发现并纠正错误。磁表面存储器通过磁头和记录介质的相对运动完成读/写操作。写入过程如图4.61所示。写入时，记录介质在磁头下方匀速通过，根据写入代码的要求，对写入线圈输入一定方向和大小的电流，使磁头导磁体磁化，产生一定方向和强度的磁场。由于磁头与磁层表面间距非常小，磁力线直接穿透磁层表面，将对应磁头下方的微小区域磁化(称为磁化单元)。可以根据写入驱动电流的不同方向，使磁层表面被磁化的极性方向不同，以区别记录“0”或“1”。12读出时，记录介质在磁头下方匀速通过，磁头相对于一个个被读出的磁化单元作切割磁力线的运动，从而在磁头读线圈中产生感应电势e，且e=-n\frac{d\phi}{dt}(n为读出线圈匝数)，其方向正好和磁通的变化方向相反。由于原来磁化单元的剩磁通φ的方向不同，感应电势方向也不同，便可读出“1”或“0”两种不同信息,如图4.62所示。磁记录方式又称为编码方式，它是按某种规律将一串二进制数字信息变换成磁表面相应的磁化状态。磁记录方式对记录密度和可靠性都有很大影响，常用的记录方式有六种，如图4.63所示。图中波形既代表了磁头线圈中的写入电流波形，也代表磁层上相应位置所记录的理想的磁通变化状态。(1)归零制(RZ)归零制记录“1”时，通以正向脉冲电流，记录“0”时，通以反向脉冲电流。这样使其在磁表面形成两个不同极性的磁饱和状态，分别表示“1”和“0”。由于两位信息之间驱动电流归零，故称为归零制记录方式。这种方式在写入信息时很难覆盖原来的磁化区域，所以为了重新写入信息，在写入前，必须先抹去原存信息。这种记录方式原理简单，实施方便，但由于两个脉冲之间有一段间隔没有电流，相应的该段磁介质未被磁化，即该段空白，故记录密度不高，目前很少使用。(2)不归零制(NRZ)不归零制记录信息时，磁头线圈始终有驱动电流，不是正向，便是反向，不存在无电流状态。这样，磁表面层不是正向被磁化，就是反向被磁化。当连续记录“1”或“0”时，其写电流方向不变，只有当相邻两信息代码不同时，写电流才改变方向，故称为“见变就翻”的不归零制。(3)“见1就翻”的不归零制(NRZ1)“见1就翻”的不归零制在记录信息时，磁头线圈也始终有电流。但只有在记录“1”时电流改变方向，使磁层磁化方向发生翻转；记录“0”时，电流方向保持不变，使磁层的磁化方向也维持原来状态，因此称为“见1就翻”的不归零制。(4)调相制(PM)调相制又称为相位编码(PE)，其特点是记录“1”或“0”的相位相反。如：记录“0”时，写电流由负变正；记录“1”时，写电流由正变负(也可以相反定义)，而且电流变化出现在一位信息记录时间的中间时刻，它以相位差为180°的磁化翻转方向来表示“1”和“0”。因此，当连续记录相同信息时，在每两个相同信息的交界处，电流方向都要变化一次；若相邻信息不同，则两个信息位的交界处电流方向维持不变。调相制在磁带存储器中用得较多。(5)调频制(FM)调频制的记录规则是：以驱动电流变化的频率不同来区别记录“1”还是“0”。当记录“0”时，在一位信息的记录时间内电流保持不变；当记录“1”时，在一位信息记录时间的中间时刻，使电流改变一次方向。而且无论记录“0”还是“1”，在相邻信息的交界处，线圈电流均变化一次。因此，写“1”时，在位单元的起始和中间位置都有磁通翻转；在写“0”时，仅在位单元起始位置有翻转。显然，记录“1”的磁翻转频率为记录“0”的两倍，故又称为倍频制。调频制记录方式被广泛应用在硬磁盘和软磁盘中。(6)改进型调频制(MFM)这种记录方式基本上同调频制，即记录“0”时，在位记录时间内电流不变；记录“1”时，在位记录时间的中间时刻电流发生一次变化。两者不同之处在于，改进型调频制只有当连续记录两个或两个以上的“0”时，才在每位的起始处改变一次电流，不必在每个位起始处都改变电流方向。由于这一特点，在写入同样数据序列时，MFM比FM磁翻转次数少，在相同长度的磁层上可记录的信息量将会增加，从而提高了磁记录密度。FM制记录一位二进制代码最多是两次磁翻转，MFM制最多只要一次翻转，记录密度提高了一倍，故又称为倍密度记录方式。倍密度软磁盘即采用MFM记录方式。此外还有一种二次改进的调频制(M²FM)，，它是在MFM基础上改进的，其记录规则是：当连续记录“0”时，仅在第1个位起始处改变电流方向，以后的位交界处电流方向不变。评价一种记录方式的优劣标准主要反映在编码效率和自同步能力等方面。(1)编码效率编码效率是指位密度与磁化翻转密度的比值，可用记录一位信息的最大磁化翻转次数来表示。例如，FM、PM记录方式中，记录一位信息最大磁化翻转次数为2，因此编码效率为50%；而MFM、NRZ、NRZ1三种记录方式的编码效率为100%，因为它们记录一位信息磁化翻转最多一次。(2)自同步能力自同步能力是指从单个磁道读出的脉冲序列中所提取同步时钟脉冲的难易程度。从磁表面存储器的读出可知，为了将数据信息分离出来，必须有时间基准信号，称为同步信号。同步信号可以从专门设置用来记录同步信号的磁道中取得，这种方法称为外同步，如NRZ1制。图4.64画出了NRZ1制驱动电流、记录磁通、感应电势、同步脉冲、读出代码等几种波形的理想对应关系(图中未反映磁通变化的滞后现象)。读出时将读线圈获得的感应信号放大(负波还要反相)、整形，这样，对于每个记录的“1”都会得到一个正脉冲，再将它们与同步脉冲相“与”，即可得读出代码波形。对于高密度的记录系统，可直接从磁盘读出的信号中提取同步信号，这种方法称为自同步。影响记录方式的优劣因素还有很多，如读分辨力、信息独立性(即某一位信息读出时出现误码而不影响后续其他信息位的正确性)、频带宽度、抗干扰能力以及实现电路的复杂性等。除上述所介绍的6种记录方式外，还有成组编码记录方式，如GCR(5.4)编码，它广泛用于磁带存储器，游程长度受限码(RLL码)是近年发展起来的用于高密度磁盘上的一种记录方式，在此均不详述。硬磁盘存储器是计算机系统中最主要的外存设备。第一个商品化的硬磁盘是由美国IBM公司于1956年研制而成的。60多年来，无论在结构还是在性能方面，磁盘存储器有了很大的发展和改进。硬磁盘存储器的盘片是由硬质铝合金材料制成的，其表面涂有一层可被磁化的硬磁特性材料。按磁头的工作方式可分为固定磁头磁盘存储器和移动磁头磁盘存储器；按磁盘是否具有可换性又可分为可换盘磁盘存储器和固定盘磁盘存储器。固定磁头的磁盘存储器，其磁头位置固定不动，磁盘上的每一个磁道都对应一个磁头，如图4.65(a)所示，盘片也不可更换。其特点是省去了磁头沿盘片径向运动所需寻找磁道的时间，存取速度快，只要磁头进入工作状态即可进行读写操作。移动磁头的磁盘存储器在存取数据时，磁头在盘面上做径向运动，这类存储器可以由一个盘片组成，如图4.65(b)所示。也可由多个盘片装在一个同心主轴上，每个记录面各有一个磁头，如图4.65(c)所示。图4.65(c)中含有6个盘片，除上下两外侧为保护面外，共有10个盘面可作为记录面，并对应10个磁头(有的磁盘组最外两侧盘面也可作为记录面，并分别与一个磁头对应)。所有这些磁头连成一体，固定在一个支架上可以移动，任何时刻各磁头都位于距圆心相等距离的磁道上，这组磁道称为一个柱面。目前，这类结构的硬磁盘存储器应用最广泛。最典型的就是温切斯特磁盘。可换盘磁盘存储器是指盘片可以脱机保存。这种磁盘可以在互为兼容的磁盘存储器之间交换数据，便于扩大存储容量。盘片可以只换单片，如在4片盒式磁盘存储器中，3片磁盘固定，只有1片可换。也可以将整个磁盘组(如6片、11片、12片等)换下。固定盘磁盘存储器是指磁盘不能从驱动器中取下，更换时要把整个头盘组合体一起更换。温切斯特磁盘是一种可移动磁头固定盘片的磁盘存储器，简称温盘。它是目前用得最广，最有代表性的硬磁盘存储器。它于1973年首先应用在IBM3340硬磁盘存储器中。其特点是采用密封组合方式，将磁头、盘片、驱动部件以及读/写电路等制成一个不能随意拆卸的整体，称为头盘组合体。因此，它的防尘性能好，可靠性高，对环境要求不高。过去有些普通的硬磁盘存储器要求在超净环境中应用，往往只能用在特殊条件的大中型计算机系统中。硬磁盘存储器由磁盘驱动器、磁盘控制器和盘片3大部分组成，如图4.66所示。(1)磁盘驱动器磁盘驱动器是主机外的一个独立装置，又称磁盘机。大型磁盘驱动器要占用一个或几个机柜，温盘只是一个比砖还小的小匣子。驱动器主要包括主轴、定位驱动及数据控制3部分。图中主轴上装有6片磁盘，主轴受传动机构控制，可使磁盘组作高速旋转运动。磁盘组共有10个有效记录面，每一面对应一个磁头。10个磁头分装在读/写臂上，连成一体，固定在小车上，犹如一把梳子。在音圈电机带动下，小车可以平行移动，带着磁头作盘的径向运动，以便找到目标磁道。磁头还具备浮动的特性，即当盘面作高速旋转时，依靠盘面形成的高速气流将磁头微微“托”起，使磁头与盘面不直接接触形成微小的气隙。整个驱动定位系统是一个带有速度和位置反馈的闭环调节自控系统。由位置检测电路测得磁头的即时位置，并与磁盘控制器送来的目标磁道位置进行比较，找出位差；再根据磁头即时平移的速度求出磁头正确运动的方向和速度，经放大送回给线性音圈电机，以改变小车的移动方向和速度，由此直到找到目标磁道为止。数据控制部分主要完成数据转换及读/写控制操作。在写操作时，首先接收选头选址信号，用以确定道地址和扇段地址。再根据写命令和写数据选定的磁记录方式，并将其转化为按一定变化规律的驱动电流注入磁头的写线圈中。按4.4.2节所述的工作原理，便可将数据写入指定磁道上。读操作时，首先也要接收选头选址信号，然后通过读放大器以及译码电路，将数据脉冲分离出来。(2)磁盘控制器磁盘控制器通常制作成一块电路板，插在主机总线插槽中。其作用是接收由主机发来的命令，将它转换成磁盘驱动器的控制命令，实现主机和驱动器之间的数据格式转换和数据传送，并控制驱动器的读/写。可见，磁盘控制器是主机与磁盘驱动器之间的接口。其内部又包含两个接口，一个是对主机的接口，称为系统级接口，它通过系统总线与主机交换信息；另一个是对硬盘(设备)的接口，称为设备级接口，又称为设备控制器，它接收主机的命令以控制设备的各种操作。一个磁盘控制器可以控制一台或几台驱动器。图4.68是磁盘控制器接口的示意图。磁盘控制器与主机之间的界面比较清晰，只与主机的系统总线打交道，即数据的发送或接收都是通过总线完成的。磁盘存储器属快速外部设备，它与主机交换信息通常采用直接存储器访问(DMA)的控制方式(详见5.6节)，图中所示的SCSI标准接口即可与系统总线相连。磁盘控制器与驱动器的界面可设在图4.68的A处，则驱动器只完成读写和放大，如ST506接口就属于这种类型。如果将界面设在B处，则将数据分离电路和编码、解码电路划入驱动器内，磁盘控制器仅完成串/并(或并/串)转换、格式控制和DMA控制等逻辑功能，如SMD和ESDI等接口就属于这种类型。如果界面设在C处，则磁盘控制器的功能全部转入设备之中，主机与设备之间便可采用标准通用接口，如SCSI接口。现在的发展趋势是后两类，增强了设备的功能，使设备相对独立。图4.69(a)是采用了SCSI接口的系统结构示意图，其接口信号线如图4.69(b)所示。(3)盘片盘片是存储信息的载体，随着计算机系统的不断小型化，硬盘也在朝着小体积和大容量的方向发展。十几年来商品化的硬盘盘面的记录密度已增长了10倍以上。表4.5列出了1991年以来正在研制或投产的各种硬盘某些主要指标所达到的水平(实际上这些指标都高于商品化硬盘指标)。(1)半导体盘半导体盘是用半导体材料制成的“盘”，它既没有盘，也没有其他运动部件，它是以半导体芯片为核心，加上接口电路和其他控制电路，在功能上模拟硬盘，即按硬盘的工作方式存取数据。如EEPROM，它可用电信号改写，断电时其原存信息也不被丢失，因此，它就可以做成半导体盘，其存取速度比硬盘要快得多，大约在0.1ms以下。FlashMemory是在EPROM和EEPROM基础上产生的一种新型的、具有性能价格比和可靠性更高的可擦写、非易失性的存储器。大容量的FlashMemory既能长期反复使用，又不丢失信息，因此它可以用来替代磁盘。2006年韩国三星电子公司开发的Flash存储芯片的容量已达32GB。(2)提高磁盘记录密度为提高磁盘记录密度，通常可采用以下技术。·采用高密度记录磁头。·采用先进的信息处理技术，克服由高密度带来的读出信号减弱和信号干扰比下降的缺点。·降低磁头浮动高度和采用高性能磁头浮动块。·改进磁头伺服跟踪技术。·采用高性能介质和基板的磁盘。·改进编码方式。(3)提高磁盘的数据传输率和缩短平均存取时间为实现磁盘高速化，可采用如下措施。·提高主轴转速,从过去的2400rpm、3600rpm提高到4400rpm、4500rpm、5400rpm和6300rpm。例如,美国MaxtorCorp开发的MXT-1240S型的3.5英寸硬盘,主轴转速为6300rpm,旋转等待时间为4.76ms,平均存取时间为8.5ms。·采用超高速缓冲存储器Cache芯片作为读/写操作控制电路。例如，IBM3990型14英寸硬盘以及Quantum、Conner、日立制作所的3.5英寸硬盘的Cache容量已达256KB。(4)采用磁盘阵列RAID尽管磁盘存储器的速度有了很大的提高，但与处理器相比，差距仍然很大。这种状态使磁盘存储器成了整个计算机系统功能提高的瓶颈。于是又出现了磁盘阵列RAID(RedundantArrayofIndependentDisks)。它的基本原理是将并行处理技术引入磁盘系统。使用多台小型温盘构成同步化的磁盘阵列，将数据展开分放在多台盘上，而这些盘又能像一台盘那样操作，使数据传输时间为单台盘的1/n(n为并行驱动器个数)。有关RAID的内容，读者可在“计算机体系结构”课程中重点学习。盘面的信息串行排列在磁道上，以字节为单位，若干相关的字节组成记录块，一系列的记录块又构成一个“记录”，一批相关的“记录”组成了文件。为了便于寻址，数据块在盘面上的分布遵循一定规律，称为磁道记录格式。常见的有定长记录格式和不定长记录格式两种。(1)定长记录格式一个具有n个盘片的磁盘组，可将其n个面上同一半径的磁道看成一个圆柱面，这些磁道存储的信息称为柱面信息。在移动磁头组合盘中，磁头定位机构一次定位的磁道集合正好是一个柱面。信息的交换通常在圆柱面上进行，柱面个数正好等于磁道数，故柱面号就是磁道号，而磁头号则是盘面号。盘面又分若干扇区，每条磁道被分割成若干个扇段，数据在盘片上的布局如图4.70所示。扇段是磁盘寻址的最小单位。在定长记录格式中，当台号决定后，磁盘寻址定位首先确定柱面，再选定磁头，最后找到扇段。因此寻址用的磁盘地址应由台号、磁道号、盘面号、扇段号等字段组成，也可将扇段号用扇区号代替。CDC6639型、7637型、ISOT-1370型等磁盘都采用定长记录格式。ISOT-1370型磁盘的磁道记录格式如图4.71所示。ISOT盘共有12个扇区，每个扇段内只记录一个数据块，每个扇段开始由扇区标志盘读出一个扇标脉冲，标志一个扇段的开始，0扇区标志处再增加一个磁道标志，指明是起始扇区。每个扇段的头部是空白段，起到隧道清除作用。序标段以某种约定代码作为数据块的引导。数据段可写入512B，若不满512B，该扇段余下部分为空白；若超过512B，则可占用几个扇段。检验字段写一个校验字，常用循环冗余码(CRC)检验，尾空白段为全0或空白区以示数据结束。这种记录格式结构简单，可按磁道号(柱面号)、盘面号、扇段号进行直接寻址，但记录区的利用率不高。例4.12假设磁盘存储器共有6个盘片，最外两侧盘面不能记录，每面有204条磁道，每条磁道有12个扇段，每个扇段有512B，磁盘机以7200rpm速度旋转，平均定位时间为8ms。(1)计算该磁盘存储器的存储容量。(2)计算该磁盘存储器的平均寻址时间。解:(1)6个盘片共有10个记录面,磁盘存储器的总容量为512B×12×204×10=12533760B(2)磁盘存储器的平均寻址时间包括平均寻道时间和平均等待时间。其中，平均寻道时间即平均定位时间为8ms，平均等待时间与磁盘转速有关。根据磁盘转速为7200rpm，得磁盘每转一周的平均时间为[60s/(7200rpm)]×0.5≈4.165ms故平均寻址时间为8ms+4.165ms=12.165ms例4.13一个磁盘组共有11片，每片有203道，数据传输率为983040Bps，磁盘组转速为3600rpm。假设每个记录块有1024B，且系统可挂16台这样的磁盘机，计算该磁盘存储器的总容量并设计磁盘地址格式。解：(1)由于数据传输速率=每一条磁道的容量×磁盘转速，且磁盘转速为3600rpm=60rps,故每一磁道的容量为983040Bps/60rps=16384B。(2)根据每个记录块(即扇段)有1024B,故每个磁道有16384B/1024B=16个扇段。(3)磁盘地址格式如图4.72所示。其中；台号4位，表示有16台磁盘机；磁道号8位，能反映203道；盘面号5位，对应11个盘片共有20个记录面；扇段号4位，对应16个扇段。例4.14对于一个由6个盘面组成的磁盘存储器，若某个文件长度超过一个磁道的容量，应将它记录在同一个存储面上，还是记录在同一个柱面上?解：如果文件长度超过一个磁道的容量，应将它记录在同一柱面上，因为不需要重新找道，寻址时间减少，数据读/写速度快。(2)不定长记录格式在实践应用中，信息常以文件形式存入磁盘。若文件长度不是定长记录块的整数倍时，往往造成记录块的浪费。不定长记录格式可根据需要来决定记录块的长度。例如，IBM2311、2314等磁盘驱动器采用不定长记录格式，图4.73是IBM2311盘不定长度磁道记录格式的示意图。图中ID是起始标志，又称索引标志，表示磁道的起点。间隙G₁是一段空白区，占36~72个字节长度，其作用是使连续的磁道分成不同的区，以利于磁盘控制器与磁盘机之间的同步和定位。磁道地址块HA又称为标识地址或专用地址，占7个字节，用来表明4部分的状况：磁道是否完好、柱面逻辑地址号、磁头逻辑地址号和校验码。间隙G₂占18~38个字节长度。R₀是磁道标识块，用来说明本磁道的状况，不作为用户数据区。间隙G₃包含一个以专用字符表示的地址标志，指明后面都是数据记录块。数据记录块R₁由计数区、关键字区和数据区3段组成，这3段都有循环校验码。一般要求一个记录限于同一磁道内，若设有专门的磁道溢出手段，则允许继续记录到同一柱面的另一磁道内。数据区长度不定，实际长度由计数区的DL给定，通常为1~64KB。从主存调出数据时，常常带有奇偶校验位，在写入磁盘时，则由磁盘控制器删去奇偶校验位，并在数据区结束时加上循环校验位。当从磁盘读出数据时，需进行一次校验操作，并恢复原来的奇偶校验位。可见，在磁盘数据区中，数据是串行的，字节之间没有间隙，字节后面没有校验位。软磁盘存储器与硬磁盘存储器的存储原理和记录方式是相同的，但在结构上有较大差别：硬盘转速高，存取速度快；软盘转速低，存取速度慢。硬盘有固定磁头、固定盘、盘组等结构；软盘都是活动头，可换盘片结构。硬盘是靠浮动磁头读/写，磁头不接触盘片；软盘磁头直接接触盘片进行读/写。硬盘系统及硬盘片价格比较贵，大部分盘片不能互换；软盘价格便宜，盘片保存方便、使用灵活、具有互换性。硬盘对环境要求苛刻，要求采用超净措施；软盘对环境的要求不苛刻。因此，软盘在微小型计算机系统中获得了广泛的应用，甚至有的大中型计算机系统中也配有软盘。软磁盘存储器的种类主要是按其盘片尺寸不同而区分的，现有8英寸、5.25英寸、3.5英寸和2.5英寸几种。软盘尺寸越小，记录密度就越高，驱动器也越小。从内部结构来看，若按使用的磁记录面(磁头个数)不同和记录密度不同，又可分为单面单密度、单面双密度、双面双密度等多种软盘存储器。世界上第一台软盘机是美国IBM公司于1972年制成的IBM3740数据录入系统。它是8英寸单面单密度软盘，容量只有256KB。1976年出现了5.25英寸软盘，20世纪80年代又出现了3.5英寸和2.5英寸的微型软盘，其容量可达1MB以上。由于软盘价格便宜，使用灵活，盘片保管方便，20世纪八九十年代曾作为外存的主要部件。软盘存储器除主要用作外存设备外，还可以和键盘一起构成脱机输入装置，其作用是给程序员提供输入程序和数据，然后再输入主机上运行，这样使输入操作不占用主机工作时间。软磁盘盘片的盘基是由厚约为76μm的聚酯薄膜制成，其两面涂有厚约为2.3~3μm的磁层。盘片装在塑料封套内，套内有一层无纺布，用来防尘，保护盘面不受碰撞，还起到消除静电的作用。盘片连封套一起插入软盘机中，盘片在塑料套内旋转，磁头通过槽孔和盘片上的记录区接触，无纺布消除因盘片转动而产生的静电，保证信息可以正常读/写。塑料封套均为正方形，其上有许多孔，例如，用来装卡盘片的中心孔、用于定位的索引孔、用于磁头读/写盘片的读/写孔，以及写保护缺口(8英寸盘)或允许写缺口(5.25英寸盘)等。图4.74所示为软磁盘盘片及其外形示意图。8英寸软盘有77个磁道，从外往里依次为00道到76道。5.25英寸软盘有40个和80个磁道两种。与硬磁盘相同，软磁盘盘面也分为若干个扇区(参见图4.70)，每条磁道上的扇段数是相同的，记录同样多的信息。由于靠里的磁道圆周长小于外磁道的圆周长，因此，里圈磁道的位密度比外圈磁道的位密度高。至于一个盘面分成几个扇区，则取决于它的记录方式。区段的划分一般采用软分段方式，由软件写上的标志实现。索引孔可作为旋转一圈开始或结束的标志，通常在盘片和保护套上各打有小孔。当盘片上的小孔转到与保护套上的小孔位置重合时，通过光电检测元件测出信号，即标志磁道已到起点或已为结束点。3.5英寸盘的盘片装在硬塑料封套内，它们的基本结构与8英寸盘和5.25英寸盘类似。按软盘驱动器的性能区分，有单面盘和双面盘。前者驱动器只有一个磁头，盘片只有一个面可以记录信息。双面盘的驱动器有两个磁头，盘片有两个记录面。按记录密度区分，有单密度和双密度两种。前者采用FM记录方式，后者采用MFM记录方式。综上所述,软盘分为单面单密度(SS、SD)、双面单密度(DS、SD)、单面双密度(SS、DD)、双面双密度(DS、DD)四种。对于5.25英寸和3.5英寸的磁盘机而言，均采用双面双密度及高密度(四倍密度)的记录方式。软磁盘存储器采用软分段格式，软分段格式有IBM格式和非IBM格式两种。IBM格式被国际标准化组织(ISO)确定为国际标准。下面以IBM3740的8英寸软盘为例，介绍其软分段格式,如图4.75所示。软分段的磁道由首部、扇区部和尾部3部分组成。当磁盘驱动器检查到索引孔时，标志磁道的起始位已找到。首部是一段空隙，是为避免由于不同软盘驱动器的索引检测器和磁头机械尺寸误差引起读/写错误而设置的。尾部是依次设置在首部和各扇区后所剩下的间隙，起到转速变化的缓冲作用。首部和尾部之间的弧被划分成若干扇区，又称为扇段。图4.75(a)中索引孔信号的前沿标志磁道开始，经46个字节的间隙后，有一个字节的软索引标志，后面再隔26个字节的间隙后，便是26个扇区(每个扇区188个字节)，最后还有247个字节的间隙，表示一个磁道结束。图4.75(b)中标出了一个扇区的188个字节的具体分配。前13个字节是地址区，详细内容可见图4.75(c)。其中地址信息占4个字节，分别指明磁道号、磁头号、区段号和记录长度。地址区字段的最后2个字节是CRC循环冗余校验码。此外，一个扇区内还有131个字节的数据区，它由数据标志、数据、CRC校验码3部分组成。在地址区和数据区后各自都有一段间隙。对图4.75所示的单面单密度软盘而言，其格式化容量为磁道数/盘片×扇区数/磁道×数据字节数/扇区=77×26×128≈256KB不同规格的软盘，每磁道究竟分成多少区段，IBM格式都有明确规定。例如，5.25英寸软盘，每磁道区段数为15、9或8三种，每个区段字节数均为512个。出厂后未使用过的盘片称为白盘，需格式化后才能使用。采用统一的标准记录格式是为了达到盘片互换及简化系统设计的目的。但是软件生产厂家为了保护软件的产权，常用改变盘片上的数据格式来达到软件不被盗版的目的。因为通过对磁盘控制器编程，可以方便地指定每条磁道上的扇区数和所采用的记录格式，甚至可以调整间隙长度，改变磁盘地址的安排顺序等。经过这些处理，使用通用软件就不能正确复制磁盘文件了。软磁盘存储器也由软磁盘驱动器、软磁盘控制器和软磁盘盘片3部分组成。软磁盘驱动器是一个相对独立的装置，又称软盘机，主要由驱动机构、磁头及定位机构和读/写电路组成。软磁盘控制器的功能是解释来自主机的命令，并向软磁盘驱动器发出各种控制信号，同时还要检测驱动器的状态，按规定的数据格式向驱动器发出读/写数据命令等。具体操作如下。①寻道操作：将磁头定位在目标磁道上。②地址检测操作：主机将目标地址送往软磁盘控制器，控制器从驱动器上按记录格式读取地址信息，并与目标地址进行比较，找到欲读(写)信息的磁盘地址。③读数据操作：首先检测数据标志是否正确，然后将数据字段的内容送入主存，最后用CRC校验。④写数据操作：写数据时，不仅要将原始信息经编码后写入磁盘，同时要写上数据区标志和CRC校验码以及间隙。⑤初始化：在盘片上写格式化信息，对每个磁道划分区段。上述所有操作都是由软磁盘控制器完成的，为此设计了软磁盘控制器芯片，将许多功能集成在一块芯片上，如FD1771、FD1991、μPD765等。这些芯片都是可编程的，将磁盘最基本的操作用这些芯片的指令编程，便可实现对驱动器的控制。软磁盘控制器发给驱动器的信号有：驱动器选择信号(表示某台驱动器与控制器接通)、马达允许信号(表示驱动器的主轴电机旋转或停止)、步进信号(使所选驱动器的磁头按指定方向移动，一次移一道)、步进方向(磁头移动的方向)、写数据与写允许信号、选头信号(选择“0”面还是“1”面的磁头)。驱动器提供给控制器的信号有：读出数据信号、写保护信号(表示盘片套上是否贴有写保护标志，如果贴有标记，则发写保护信号)、索引信号(表示盘片旋转到索引孔位置，表明一个磁道的开始)、0磁道信号(表示磁头正停在0号磁道上)。图4.76是IBMPC上的软盘控制器逻辑框图。磁带存储器也属于磁表面存储器，记录原理和记录方式与磁盘存储器是相同的。但从存取方式来看，磁盘存储器属于直接存取设备，即只要知道信息所在盘面、磁道和扇区的位置，磁头便可直接找到其位置并读/写。磁带存储器必须按顺序进行存取，即磁带上的文件是按磁带头尾顺序存放的。如果某文件存在磁带尾部，而磁头当前位置在磁带首部，那么必须等待磁带走到尾部时才能读取该文件，因此磁带存取时间比磁盘长。但由于磁带容量比较大，位价也比磁盘的低，而且格式统一，便于互换，因此，磁带存储器仍然是一种用于脱机存储的后备存储器。磁带存储器由磁带和磁带机两部分组成。磁带按长度分，有2400英尺、1200英尺、600英尺几种;按宽度分,有1/4英寸、1/2英寸、1英寸、3英寸几种;按记录密度分,有800bpi、1600bpi、6250bpi等几种;按磁带表面并行记录信息的道数分,有7道、9道、16道等;按磁带外形分，有开盘式磁带和盒式磁带两种。现在计算机系统较广泛使用的两种标准磁带为：1/2英寸开盘式和1/4英寸盒式。磁带机又有很多种类，按磁带机规模分有标准半英寸磁带机、海量宽带磁带机(MassStorage)和盒式磁带机三种。按磁带机走带速度分，有高速磁带机(4~5m/s)、中速磁带机(2~3m/s)和低速磁带机(2m/s以下)。磁带机的数据传输率取决于记录密度和走带速度。在记录密度相同的情况下，带速越快，传输率就越高。按装卸磁带机构分，有手动装卸式和自动装卸式；按磁带传动缓冲机构分，有摆杆式和真空式；按磁带的记录格式分，有启停式和数据流式。数据流磁带机已成为现代计算机系统中主要的后备存储器，其位密度可达8000bpi。它用于资料保存、文件复制，作为脱机后备存储装置，特别是当温盘出现故障时，用以恢复系统。磁带机正朝着提高传输率、提高记录密度、改善机械结构、提高可靠性等方向发展。数据流磁带机是将数据连续地写到磁带上，每个数据块后有一个记录间隙，使磁带机在数据块间不启停，简化了磁带机的结构，用电子控制替代了机械启停式控制，降低了成本，提高了可靠性。数据流磁带机有1/2英寸开盘式和1/4英寸盒式两种。盒式磁带的结构类似录音带和录像带。盒带内装有供带盘和收带盘，磁带长度有450英尺和600英尺两种，容量分别为45MB和60MB。容量高达1GB和1.35GB的1/4英寸盒式数据流磁带机也已问世。当采用数据压缩技术时，1/4英寸盒式数据流磁带机容量可达2GB或2.7GB。数据流磁带机与传统的启停式磁带机的多位并行读/写不同，它采用类似磁盘的串行读/写方式，记录格式与软盘类似。以4道数据流磁带机为例，4个磁道的排列次序如图4.77所示。在记录信息时，先在第0道上从磁带首端BOT记到磁带末端EOT，然后在第1道上反向记录，即从EOT到BOT，第2道又从BOT到EOT,第3道从EOT到BOT。读出信息时,也是这个顺序。这种方式称为蛇形(Serpentine)记录。9道1/4英寸数据流磁带记录格式也与此相同,偶数磁道从BOT到EOT,奇数磁道从EOT到BOT，依次首尾相接。盒式数据流磁带机与主机的接口是标准的通用接口，可用小型计算机系统接口SCSI与主机相连，也可以通过磁带控制器与主机相连。磁带控制器的作用类似于磁盘控制器，控制主机与磁带机之间进行信息交换。3.磁带的记录格式磁带上的信息可以以文件形式存储，也可以按数据块存储。磁带可以在数据块之间启停，进行数据传输。按数据块存储的磁带互换性更好。磁带机与主机之间进行信息传送的最小单位是数据块或称为记录块(Block)，记录块的长度可以是固定的，也可以是变化的，由操作系统决定。记录块之间有空白间隙，作为磁头停靠的地方，并保证磁带机停止或启动时有足够的惯性缓冲。记录块尾部有几行特殊的标记，表示数据块结束，接着便是校验区。图4.78示意了磁带机上的数据格式。磁带信息的校验属于多重校验，由奇偶校验、循环冗余校验和纵向冗余校验共同完成。以9道磁带为例，横向可以并排记录9位二进制信息(称为一行)，其中8位是数据磁道，存储一个字节，另一位是这一字节的奇偶校验位，称为横向奇偶校验码。在每一个数据块内，沿纵向(走带方向)每一磁道还配有CRC校验码。此外对每一磁道上的信息(包括CRC在内)，又有一个纵向奇偶校验码。纠错的原理是用循环冗余码的规律和专门线路，指出出错的磁道(CRC可发现一个磁道上的多个错误码)，然后用横向校验码检测每一行是否有错，纵横交错后就可指明哪行哪道有错，如有错就立即纠正。磁表面存储器由于磁介质表面的缺陷、尘埃等原因，致使出现多个错误码。循环冗余校验(CyclicRedundancyCheck,CRC)码可以发现并纠正信息在存储或传送过程中连续出现的多位错误代码。因此，CRC校验码在磁介质存储器和计算机之间通信方面得到广泛应用。CRC码是基于模2运算而建立编码规律的校验码。模2运算的特点是不考虑进位和借位的运算，其规律如下：①模2加和模2减的结果是相等的,即0±1=1,0±0=0,1±0=1,1±1=0。可见，两个相同数的模2和恒为0。②模2乘是按模2和求部分积之和。③模2除是按模2减求部分余数。每求一位商应使部分余数减少一位。上商的原则是：当部分余数的首位为1时，上商1；当部分余数的首位为0时，上商0。当部分余数的位数小于除数的位数时，该余数即为最后余数。②和③的实例如下：将收到的循环校验码用约定的生成多项式G(x)去除，如果无错，则余数应为0，如果某一位出错，则余数不为0。不同的出错位其余数也不同，表4.6列出了对应G(x)=1011的出错模式。可以证明，更换不同的待测码字，余数和出错位的对应关系不变，只与码制和生成多项式有关。表4.6给出的关系只对应G(x)=1011的(7，4)码，对于其他码制或选用其他生成多项式，出错模式将发生变化。如果循环码有一位出错，被G(x)模2除将得到一个不为0的余数。如果对余数补0继续除下去，将发现各次所得余数将按表4.6顺序循环。例如，第7位出错，其余数为001，补0后再除，第二次余数为010，以后依次为100，011…，反复循环，这就是“循环码”的名称由来。这个特点正好用来纠错，即当出现不为零的余数后，一方面对余数补0继续做模2除，另一方面将被检测的校验码字循环左移。由表4.6可知，当出现余数为101时，出错位也移到了N₁位置。可通过异或门将其纠正后在下一次移位时送回N₇。这样当移满一个循环[对(7，4)码共移7次]后，就得到一个纠正后的码字。值得指出的是，并不是任何一个(k+1)位多项式都可以作为生成多项式。从检错和纠错的要求出发，生成多项式应满足以下要求：①任何一位发生错误，都应该使余数不为零。②不同位发生错误应使余数不同。③对余数继续做模2除，应使余数循环。达到上述要求的数学关系比较复杂，读者若有兴趣可查阅有关资料。光盘(OpticalDisk)是利用光学方式进行读/写信息的圆盘。光盘存储器是在激光视频唱片和数字音频唱片基础上发展起来的。应用激光在某种介质上写入信息，然后再利用激光读出信息，这种技术称为光存储技术。如果光存储使用的介质是磁性材料，即利用激光在磁记录介质上存储信息，就称为磁光存储。通常把采用非磁性介质进行光存储的技术称为第一代光存储技术，它不能把内容抹掉重写新内容。磁光存储技术是在光存储技术基础上发展起来的，称为第二代光存储技术，主要特点是可擦除重写。根据光存储性能和用途的不同，光盘存储器可分为三类。(1)只读型光盘(CD-ROM)这种光盘内的数据和程序是由厂家事先写入的，使用时用户只能读出，不能修改或写入新的内容。它主要用于电视唱片和数字音频唱片，可以获得高质量的图像和高保真的音乐。在计算机领域里，主要用于检索文献数据库或其他数据库，也可用于计算机的辅助教学等。因它具有ROM特性,故称为CD-ROM(CompactDisk-ROM)。(2)只写一次型光盘(WORM)这种光盘允许用户写入信息，写入后可多次读出，但只能写入一次，而且不能修改，故称其为“写一次型”(WriteOnceReadMany,WORM),主要用于计算机系统中的文件存档,或写入的信息不再需要修改的场合。(3)可擦写型光盘这种光盘类似磁盘，可以重复读/写。从原理上来看，目前仅有光磁记录(热磁反转)和相变记录(晶态-非晶态转变)两种。它是很有前途的辅助存储器。1989年下半年可擦写型5.25英寸的光盘，双面格式化的容量达到500~650MB。2004年索尼公司的ProDATA光盘单面容量已高达25GB,读取速度每秒11MB,刻录速度每秒9MB。2.光盘的存取原理光盘存储器利用激光束在记录表面上存储信息，根据激光束和反射光的强弱不同，可以实现信息的读/写。由于光学读/写头和介质保持较大的距离，因此，它是非接触型读/写的存储器。对于只读型和只写一次型光盘而言，写入时，将光束聚焦成直径为小于1μm的微小光点，使其能量高度集中，在记录的介质上发生物理或化学变化，从而存储信息。例如，激光束以其热作用熔化盘表面的光存储介质薄膜，在薄膜上形成小凹坑，有坑的位置表示记录“1”，没坑的位置表示“0”。又比如，有些光存储介质在激光照射下，使照射点温度升高，冷却后晶体结构或晶粒大小会发生变化，从而导致介质膜光学性质发生变化(如折射率和反射率)，利用这一现象便可记录信息。读出时，在读出光束的照射下，在有凹处和无凹处反射的光强是不同的，利用这种差别，可以读出二进制信息。由于读出光束的功率只有写入光束的1/10，因此不会使盘面熔出新的凹坑。可擦写光盘利用激光在磁性薄膜上产生热磁效应来记录信息(称为磁光存储)。其原理是：在一定温度下，对磁介质表面加一个强度高于该介质矫顽力的磁场，就会发生磁通翻转，便可用于记录信息。矫顽力的大小是随温度而变的。倘若设法控制温度，降低介质的矫顽力，那么外加磁场强度便很容易高于此矫顽力，使介质表面磁通发生翻转。磁光存储就是根据这一原理来存储信息的。它利用激光照射磁性薄膜，使其被照处温度升高，矫顽力下降，在外磁场HR作用下，该处发生磁通翻转，并使其磁化方向与外磁场HR一致，就可视为寄存“1”。不被照射处或HR小于矫顽力处可视为寄存“0”。通常把这种磁记录材料因受热而发生磁性变化的现象称为热磁效应。(a)图4.79(a)表示在记录方向外加一个小于矫顽力的磁场HR，其介质表面不发生翻转；图4.79(b)表示激光照射处温度上升，外加的磁场HR大于矫顽力，而使其发生磁通翻转；图4.79(c)表示照射后，将磁通翻转保持下来，即写入了信息。激光光源HR擦除信息和记录信息原理一样，擦除时外加一个和记录方向相反的磁场HR，对已写入的信息用激光束照射，并使HR大于矫顽力，那么，被照射处又发生反方向磁化，使之恢复为记录前的状态。这种利用激光的热作用改变磁化方向来记录信息的光盘称为磁光盘。(b)3.光盘存储器的组成(c)光盘存储器与磁盘存储器很相似，它也由盘片、驱动器和控制器组成。驱动器同样有读/写头、寻道定位机构、主轴驱动机构等。除了机械电子机构外，还有光学机构。图4.80是写一次型光盘的光学系统的示意图。图中激光器产生的光束经分离器分离后，其中90%的光束用作记录光束，10%的光束作为读出光束。记录光束经调制器，由聚焦系统向光盘记录信息。读出光束经几个反射镜射到光盘盘片，读出光信号再经光电二极管输出。光盘盘片的形状与磁盘盘片类似，但记录材料不同。只读型光盘与只写一次型光盘都是三层式结构。第一层为基板，第二层为涂覆在基板上的一层铝质反射层，最上面一层为很薄的金属膜。反射层和金属薄膜的厚度取决于激光源的波长λ，两者厚度之和为λ/4。金属膜的材料一般是碲(Te)的合金组成，这种材料在激光源的照射下会熔成一个小凹坑，用以表示“1”或“0”。光盘、硬盘、软盘、磁带在记录原理上很相似，都属于表面介质存储器。它们都包括头、精密机械、马达及电子线路等。在技术上都可采用自同步技术、定位和校正技术。它们都包含盘片、控制器、驱动器等。但由于它们各自的特点和功能不同，使其在计算机系统中的应用各不相同。光盘是非接触式读/写信息，光学头与盘面的距离几乎比磁盘的磁头与盘面的间隙大1万倍，互不摩擦，介质不会被破坏，大大提高了光盘的耐用性，其使用寿命可长达数十年以上。光盘可靠性高，对使用环境要求不高，机械振动的问题甚少，不需要采取特殊的防震和防尘措施。由于光盘是靠直径小于1μm的激光束写入每位信息，因此记录密度高，可达10⁸位/cm²，纟约为磁盘的10~100倍。光盘记录头分量重，体积大，使寻道时间长约30~100ms。写入速度低，约为0.2s，平均存取时间为100~500ms，与主机交换信息速度不匹配。因此，它不能代替硬盘，只能作为硬盘的后备存储器。光盘的介质互换性好，存储容量大，可用于文献档案、图书管理、多媒体等方面的应用。但由于目前价格比较贵，故尚不能替代磁带机。硬磁盘存储器容量大，数据传输率比光盘高(采用磁盘阵列，数据传输率可达100Mbps)，等待时间短。它作为主存的后备存储器，用以存放程序的中间和最后结果。软磁盘存储器容量小，数据传输率低，平均寻道时间长，而且是接触式存取，盘片不固定在驱动器中，运行时有大量的灰尘进入盘面，易造成盘面磨损或出现误码，不易提高位密度。近年来软盘已逐渐被淘汰。磁带存储器的历史比磁盘更久，20世纪60年代后期逐渐被磁盘取代。它的数据传输率更低，采用接触式记录，容量也很大，每兆字节价格较低，记录介质也容易装卸、互换和携带，可用作硬盘的后备存储器。据统计，80%的磁带被用作磁盘的后备存储器，20%的磁带用作计算机的输入输出数据和文件的存储。153相联存储器的每个字由若干字段组成，每个字段描述了一个对象的属性，也称一个内容。例如，在存储学生信息的相联存储器中，可分为学号、姓名、年龄、班号、成绩等字段(参见图4.82)。相联存储器的基本组成如图4.81所示。图中检索寄存器CR用来存放检索字，其位数与相联存储器的字长相等。屏蔽寄存器MR用来存放屏蔽码，其位数与检索寄存器位数相同，其内容与需要检索的字段有关。如需检索CR的高6位字段(称为检索项)，则MR的高6位为“1”，其余各位为“0”，即把CR中的第7~n位屏蔽掉，也即这些位不参加比较。比较线路是把检索项和所有存储单元的相应位进行比较，如果比较结果相等，就将符合寄存器RR的相应位置“1”。RR又称为查找结果寄存器，其位数等于相联存储器的字数。如果比较结果第i个字满足要求，则RR的第i位为“1”，其余各位为“0”；如果同时有5个字都满足要求，则RR中就有5位为“1”。有的相联存储器还设有字选择寄存器WSR，用来确定哪些存储字参与检索。若WSR某位为“1”，则表示对应的存储字参与检索，而对应WSR某位为“0”的存储字则不参与检索。可见WSR的位数与存储器字数相同。代码寄存器用来存放从存储体中读出的代码，或存放写至存储体中的代码。相联存储器有三种基本操作：读、写、检索(比较)。读、写操作与传统存储器相同，检索只能按内容进行。例如，某系学生的考试成绩已存入相联存储器中，如图4.82所示。要求列出总分在580~600分范围内的学生名单，可通过两次查找来完成。第一次找出总分大于579的学生名单，第二次找出总分小于601的学生名单。可见总分字段是关键字，故需要将MR中对应的位置成“1”，其他字段置成“0”。第一次查找时，CR中的“总分”字段是579(二进制表相联存储器检索举例这里需要特别指出的是，相联存储器每次查找是将所有存储字的相关字段与检索项同时进行比较，这是由相联存储器的具体电路实现的。如果是按地址访问的存储器，查找时则必须一次读出一个存储字，逐一与检索项进行比较。如果设存储器有M个单元，那么按地址访问的存储器检索出某一单元，平均需进行M/2次操作，而相联存储器仅需进行一次检索操作。由此可见，相联存储器大大提高了处理速度。相联存储器还可以进行各种比较，如大于、小于、相等、不等、求最大值、求最小值、相似、接近以及其他各种类型的逻辑检索。因此，相联存储器的每个单元不仅能存储，还要能进行逻辑运算，需增加很多逻辑电路，所以也称为分布逻辑存储器。显然，其电路比一般存储器复杂得多，故相联存储芯片比一般存储芯片昂贵。随着大规模集成电路集成度的提高，相联存储芯片已由4K位、8K位发展到20K位，商品化容量已经达到256×48位。相联存储器的原理在Cache中得到应用。例如，在Cache中将主存的字块标记同时与每个缓存字块的“标记”进行比较，就可迅速判断出该主存字块是否“命中”。若比较相等，表示命中，即可从缓存中读出信息；若不等，即不命中，则需将新的主存块调入缓存。此外，相联存储器还广泛应用于虚拟存储器中，还常用于数据库和知识库中。近年来，相联存储器在语音识别、图像处理、数据流计算机和Prolog机中也都有所应用。系统除了CPU和存储器两大模块外，计算机硬件系统的第三个关键部分是输入输出模块，又称输入输出系统。随着计算机系统的不断发展，应用范围的不断扩大，I/O设备的数量和种类也越来越多，它们与主机的联络方式及信息的交换方式也各不相同。因此，输入输出系统涉及的内容极其繁杂，既包括具体的各类I/O设备，又包括各种不同的I/O设备如何与主机交换信息。本章重点分析I/O设备与主机交换信息的三种控制方式(程序查询、中断和DMA)及其相应的接口功能和组成，对几种常用的I/O设备也进行简单介绍，旨在使读者对输入输出系统有一个较清晰的认识，进一步加深对整机工作的理解。系统的发展概况输入输出系统的发展大致可分为4个阶段。早期的I/O设备种类较少，I/O设备与主存交换信息都必须通过CPU，如图5.1所示。图5.1I/O设备通过CPU与主存交换信息这种交换方式延续了相当长的时间。当时的I/O设备具有以下几个特点。·每个I/O设备都必须配有一套独立的逻辑电路与CPU相连，用来实现I/O设备与主机之间的信息交换，因此线路十分散乱、庞杂。·输入输出过程是穿插在CPU执行程序过程之中进行的，当I/O设备与主机交换信息时，CPU不得不停止各种运算，因此，I/O设备与CPU是按串行方式工作的，极浪费时间。·每个I/O设备的逻辑控制电路与CPU的控制器紧密构成一个不可分割的整体，它们彼此依赖，相互牵连，因此，欲增添、撤减或更换I/O设备是非常困难的。在这个阶段中，计算机系统硬件价格十分昂贵，机器运行速度不高，配置的I/O设备不多，主机与I/O设备之间交换的信息量也不大，计算机应用尚未普及。这个阶段I/O设备通过接口模块与主机连接，计算机系统采用了总线结构，如图5.2所示。通常，在接口中都设有数据通路和控制通路。数据经过接口既起到缓冲作用，又可完成串-并变换。控制通路用以传送CPU向I/O设备发出的各种控制命令，或使CPU接受来自I/O设备的反馈信号。许多接口还能满足中断请求处理的要求，使I/O设备与CPU可按并行方式工作，大大地提高了CPU的工作效率。采用接口技术还可以使多台I/O设备分时占用总线，使多台I/O设备互相之间也可实现并行工作方式，有利于整机工作效率的提高。虽然这个阶段实现了CPU和I/O设备并行工作，但是在主机与I/O设备交换信息时，CPU要中断现行程序，即CPU与I/O设备还不能做到绝对的并行工作。为了进一步提高CPU的工作效率,又出现了直接存储器存取(DirectMemoryAccess,DMA)技术，其特点是I/O设备与主存之间有一条直接数据通路，I/O设备可以与主存直接交换信息，使CPU在I/O设备与主存交换信息时能继续完成自身的工作，故资源利用率得到了进一步提高。在小型和微型计算机中，采用DMA方式可实现高速I/O设备与主机之间成组数据的交换，但在大中型计算机中，I/O设备配置繁多，数据传送频繁，若仍采用DMA方式会出现一系列问题。①如果每台I/O设备都配置专用的DMA接口，不仅增加了硬件成本，而且为了解决众多DMA接口同时访问主存的冲突问题，会使控制变得十分复杂。②CPU需要对众多的DMA接口进行管理，同样会占用CPU的工作时间，而且因频繁地进入周期挪用阶段，也会直接影响CPU的整体工作效率(详见5.6节)。因此在大中型计算机系统中，采用I/O通道的方式来进行数据交换。图5.3所示为具有通道结构的计算机系统。通道是用来负责管理I/O设备以及实现主存与I/O设备之间交换信息的部件，可以视为一种具有特殊功能的处理器。通道有专用的通道指令，能独立地执行用通道指令所编写的输入输出程序，但不是一个完全独立的处理器。它依据CPU的I/O指令进行启动、停止或改变工作状态，是从属于CPU的一个专用处理器。依赖通道管理的I/O设备在与主机交换信息时，CPU不直接参与管理，故提高了CPU的资源利用率。输入输出系统发展到第四阶段，出现了I/O处理机。I/O处理机又称为外围处理机(Per-ipheralProcessor),它基本独立于主机工作,既可完成I/O通道要完成的I/O控制,又可完成码制变换，格式处理，数据块检错、纠错等操作。具有I/O处理机的输入输出系统与CPU工作的并行性更高，这说明I/O系统对主机来说具有更大的独立性。本章主要介绍第二阶段的输入输出系统，有关通道及I/O处理机管理I/O系统的内容将在“计算机体系结构”课程中讲述。输入输出系统由I/O软件和I/O硬件两部分组成。输入输出系统软件的主要任务如下：①将用户编制的程序(或数据)输入主机内。②将运算结果输送给用户。③实现输入输出系统与主机工作的协调等。不同结构的输入输出系统所采用的软件技术差异很大。一般而言，当采用接口模块方式时，应用机器指令系统中的I/O指令及系统软件中的管理程序便可使I/O设备与主机协调工作。当采用通道管理方式时，除I/O指令外，还必须有通道指令及相应的操作系统。即使都采用操作系统，不同的机器其操作系统的复杂程度差异也是很大的。(1)I/O指令I/O指令是机器指令的一类，其指令格式与其他指令既有相似之处，又有所不同。I/O指令可以和其他机器指令的字长相等，但它还应该能反映CPU与I/O设备交换信息的各种特点，如它必须反映出对多台I/O设备的选择，以及在完成信息交换过程中，对不同设备应做哪些具体操作等。图5.4示意了I/O指令的一般格式。图中的操作码字段可作为I/O指令与其他指令(如访存指令、算逻指令、控制指令等)的判别代码；命令码体现I/O设备的具体操作；设备码是多台I/O设备的选择码。I/O指令的命令码一般可表述如下几种情况。·将数据从I/O设备输入主机。例如，将某台设备接口电路的数据缓冲寄存器中的数据读入CPU的某个寄存器(如累加器ACC)。●将数据从主机输出至I/O设备。例如，将CPU的某个寄存器(如ACC)中的数据写入某台设备接口电路的数据缓冲寄存器内。·状态测试。利用命令码检测各个I/O设备所处的状态是“忙”(Busy)还是“准备就绪”(Ready)，以便决定下一步是否可进入主机与I/O设备交换信息的阶段。·形成某些操作命令。不同I/O设备与主机交换信息时，需要完成不同的操作。例如，磁带机需要正转、反转、读、写、写文件结束等；对于磁盘驱动器，需要读扇区、写扇区、找磁道、扫描记录标识符等。这里值得注意的是，在第4章中，按磁盘机和磁带机的功能来看，它们都被视为存储系统的一部分；但从管理角度来看，调用这些设备与调用其他I/O设备又有共同之处。因此，本章又将它们视为I/O设备。I/O指令的设备码相当于设备的地址。只有对繁多的I/O设备赋以不同的编号，才能准确选择某台设备与主机交换信息。(2)通道指令通道指令是对具有通道的I/O系统专门设置的指令，这类指令一般用以指明参与传送(写入或读取)的数据组在主存中的首地址；指明需要传送的字节数或所传送数据组的末地址；指明所选设备的设备码及完成某种操作的命令码。这类指令的位数一般较长，如IBM370机的通道指令为64位。通道指令又称为通道控制字(ChannelControlWord,CCW),它是通道用于执行I/O操作的指令，可以由管理程序存放在主存的任何地方，由通道从主存中取出并执行。通道程序即由通道指令组成，它完成某种外围设备与主存之间传送信息的操作。例如，将磁带记录区的部分内容送到指定的主存缓冲区内。通道指令是通道自身的指令，用来执行I/O操作，如读、写、磁带走带及磁盘找道等。而I/O指令是CPU指令系统的一部分，是CPU用来控制输入输出操作的指令，由CPU译码后执行。在具有通道结构的计算机中，I/O指令不实现I/O数据传送，主要完成启、停I/O设备，查询通道和I/O设备的状态及控制通道所做的其他操作。具有通道指令的计算机，一旦CPU执行了启动I/O设备的指令，就由通道来代替CPU对I/O设备的管理。输入输出系统的硬件组成是多种多样的，在带有接口的I/O系统中，一般包括接口模块及I/O设备两大部分。图5.2中的接口电路实际上包含许多数据传送通路和有关数据，还包含控制信号通路及其相应的逻辑电路(详见5.3节)。一个通道可以和一个以上的设备控制器相连，一个设备控制器又可以控制若干台同一类型的设备。例如，IBM360系统的一个通道可以连接8个设备控制器，一个设备控制器又与8台设备相连，因此，一个通道可以管理64台设备。如果一台计算机有6个通道，便可带动384台设备。当然，实际上由于设备利用率和通道的频带影响，主机不可能带动这么多的设备。I/O设备与主机交换信息和CPU与主存交换信息相比，有许多不同点。例如，CPU如何对I/O设备编址；如何寻找I/O设备号；信息传送是逐位串行还是多位并行；I/O设备与主机以什么方式进行联络，使它们彼此都知道对方处于何种状态；I/O设备与主机是怎么连接的，等等。这一系列问题统称为I/O设备与主机的联系方式。通常将I/O设备码看作地址码，对I/O地址码的编址可采用两种方式：统一编址或不统一编址。统一编址就是将I/O地址看作存储器地址的一部分。例如，在64K地址的存储空间中，划出8K地址作为I/O设备的地址，凡是在这8K地址范围内的访问，就是对I/O设备的访问，所用的指令与访存指令相似。不统一编址就是指I/O地址和存储器地址是分开的，所有对I/O设备的访问必须有专用的I/O指令。显然统一编址占用了存储空间，减少了主存容量，但无须专用的I/O指令。不统一编址由于不占用主存空间，故不影响主存容量，但需设I/O专用指令。因此，设计机器时，需根据实际情况权衡考虑选取何种编址方式。当设备通过接口与主机相连时，CPU可以通过接口地址来访问I/O设备。由于每台设备都赋予一个设备号，因此，当要启动某一设备时，可由I/O指令的设备码字段直接指出该设备的设备号。通过接口电路中的设备选择电路，便可选中要交换信息的设备。在同一瞬间，n位信息同时从CPU输出至I/O设备，或由I/O设备输入CPU，这种传送方式称为并行传送。其特点是传送速度较快，但要求数据线多。例如，16位信息并行传送需要16根数据线。若在同一瞬间只传送一位信息，在不同时刻连续逐位传送一串信息，这种传送方式称为串行传送。其特点是传送速度较慢，但只需一根数据线和一根地线。当I/O设备与主机距离很远时，采用串行传送较为合理，例如远距离数据通信。不同的传送方式需配置不同的接口电路，如并行传送接口、串行传送接口或串并联用的传送接口等。用户可按需要选择合适的接口电路。不论是串行传送还是并行传送，I/O设备与主机之间必须互相了解彼此当时所处的状态，如是否可以传送、传送是否已结束等。这就是I/O设备与主机之间的联络问题。按I/O设备工作速度的不同，可分为三种联络方式。(1)立即响应方式对于一些工作速度十分缓慢的I/O设备，如指示灯的亮与灭、开关的通与断、A/D转换器缓变信号的输入等，当它们与CPU发生联系时，通常都已使其处于某种等待状态，因此，只要CPU的I/O指令一到，它们便立即响应，故这种设备无须特殊联络信号，称为立即响应方式。(2)异步工作采用应答信号联络当I/O设备与主机工作速度不匹配时，通常采用异步工作方式。这种方式在交换信息前，I/O设备与CPU各自完成自身的任务，一旦出现联络信号，彼此才准备交换信息。图5.6示意了并行传送的异步联络方式。如图5.6所示，当CPU将数据输出到I/O接口后，接口立即向I/O设备发出一个“Ready”(准备就绪)信号，告诉I/O设备可以从接口内取数据。I/O设备收到“Ready”信号后，通常便立即从接口中取出数据，接着便向接口回发一个“Strobe”信号，并让接口转告CPU，接口中的数据已被取走，CPU还可继续向此接口送数据。同理，倘若I/O设备需向CPU传送数据，则先由I/O设备向接口送数据，并向接口发“Strobe”信号，表明数据已送出。接口接到联络信号后便通知CPU可以取数，一旦数据被取走，接口便向I/O设备发“Ready”信号，通知I/O设备，数据已被取走，尚可继续送数据。这种一应一答的联络方式称为异步联络。图5.7示意了串行传送的异步联络方式。I/O设备与CPU双方设定一组特殊标记，用“起始”和“终止”来建立联系。图中9.09ms的低电平表示“起始”，又用2×9.09ms的高电平表示“终止”。(3)同步工作采用同步时标联络同步工作要求I/O设备与CPU的工作速度完全同步。例如，在数据采集过程中，若外部数据以2400bps的速率传送至接口，则CPU也必须以1/2400s的速率接收每一位数。这种联络互相之间还得配有专用电路，用以产生同步时标来控制同步工作。5.I/O设备与主机的连接方式图5.2所示的是总线连接方式，通过一组总线(包括地址线、数据线、控制线等)，将所有的I/O设备与主机连接。这种连接方式是现代大多数计算机系统所采用的方式。5.1.4I/O设备与主机信息传送的控制方式I/O设备与主机交换信息时，共有5种控制方式：程序查询方式、程序中断方式、直接存储器存取方式(DMA)、I/O通道方式、I/O处理机方式。本节主要介绍前3种方式，后两种方式在5.1.1节已进行了一般介绍，更详尽的内容将由“计算机体系结构”课程讲述。程序查询方式是由CPU通过程序不断查询I/O设备是否已做好准备，从而控制I/O设备与主机交换信息。采用这种方式实现主机和I/O设备交换信息，要求I/O接口内设置一个能反映I/O设备是否准备就绪的状态标记，CPU通过对此标记的检测，可得知I/O设备的准备情况。图5.9所示为CPU从某一I/O设备读数据块(例如从磁带上读一记录块)至主存的查询方式流程。当现行程序需启动某I/O设备工作时，即将此程序流程插入运行的程序中。由图中可知，CPU启动I/O设备后便开始对I/O设备的状态进行查询。若查得I/O设备未准备就绪，就继续查询；若查得I/O设备准备就绪，就将数据从I/O接口送至CPU，再由CPU送至主存。这样一个字一个字地传送，直至这个数据块的数据全部传送结束，CPU又重新回到原现行程序。由这个查询过程可见，只要一启动I/O设备，CPU便不断查询I/O设备的准备情况，从而终止了原程序的执行。CPU在反复查询过程中，犹如就地“踏步”。另一方面，I/O设备准备就绪后，CPU要一个字一个字地从I/O设备取出，经CPU送至主存，此刻CPU也不能执行原程序，可见这种方式使CPU和I/O设备处于串行工作状态，CPU的工作效率不高。倘若CPU在启动I/O设备后，不查询设备是否已准备就绪，继续执行自身程序，只是当I/O设备准备就绪并向CPU发出中断请求后才予以响应，这将大大提高CPU的工作效率。图5.10示意了这种方式。由图中可见，CPU启动I/O设备后仍继续执行原程序，在第K条指令执行结束后，CPU响应了I/O设备的请求，中断了现行程序，转至中断服务程序，待处理完后又返回到原程序断点处，继续从第K+1条指令往下执行。由于这种方式使原程序中断了运行，故称为程序中断方式。图5.11示意了采用程序中断方式从I/O设备读数据块到主存的程序流程。由图中可见，CPU向I/O设备发读指令后，仍在处理其他事情(如继续在算题)，当I/O设备向CPU发出请求后，CPU才从I/O接口读一个字经CPU送至主存(这是通过执行中断服务程序完成的)。如果I/O设备的一批数据(一个数据块的全部数据)尚未传送结束时，CPU再次启动I/O设备，命令I/O设备再做准备，一旦又接收到I/O设备中断请求时，CPU重复上述中断服务过程，这样周而复始，直至一批数据传送完毕。显然，程序中断方式在I/O设备进行准备时，CPU不必时刻查询I/O设备的准备情况，不出现“踏步”现象，即CPU执行程序与I/O设备做准备是同时进行的，这种方式和CPU与I/O设备是串行工作的程序查询方式相比，CPU的资源得到了充分的利用。图5.12(a)、(b)分别示意了这两种方式CPU的工作效率。当然，采用程序中断方式，CPU和I/O接口不仅在硬件方面需增加相应的电路，而且在软件方面还必须编制中断服务程序，这方面内容将在5.3和5.5节中详细讲述。虽然程序中断方式消除了程序查询方式的“踏步”现象，提高了CPU资源的利用率，但是CPU在响应中断请求后，必须停止现行程序而转入中断服务程序，并且为了完成I/O设备与主存交换信息，还不得不占用CPU内部的一些寄存器，这同样是对CPU资源的消耗。如果I/O设备能直接与主存交换信息而不占用CPU，那么，CPU的资源利用率显然又可进一步提高，这就出现了直接存储器存取(DMA)的方式。在DMA方式中，主存与I/O设备之间有一条数据通路，主存与I/O设备交换信息时，无须调用中断服务程序。若出现DMA和CPU同时访问主存，CPU总是将总线占有权让给DMA，通常把DMA的这种占有称为窃取或挪用。窃取的时间一般为一个存取周期，故又把DMA占用的存取周期窃取周期或挪用周期。而且，在DMA窃取存取周期时，CPU尚能继续做内部操作(如乘法运算)。可见，与程序查询和程序中断方式相比，DMA方式进一步提高了CPU的资第5章输入输出系统165源利用率。图5.12(c)示意了DMA方式的CPU效率。当然，采用DMA方式时，也需要增加必要的DMA接口电路。有关DMA方式的详细内容将在5.6节讲述。5中央处理器和主存构成了主机，除主机外的大部分硬件设备都可称为I/O设备或外部设备，或外围设备，简称外设。计算机系统没有输入输出设备，就如计算机系统没有软件一样，是毫无意义的。随着计算机技术的发展，I/O设备在计算机系统中的地位越来越重要，其成本在整个系统中所占的比重也越来越大。早期的计算机系统主机结构简单、速度慢、应用范围窄，配置的I/O设备种类有限，数量不多，I/O设备价格仅占整个系统价格的几个百分点。现代的计算机系统I/O设备向多样化、智能化方向发展，品种繁多，性能良好，其价格往往已占到系统总价的80%左右。I/O设备的组成通常可用图5.13点画线框内的结构来描述。图5.13中的设备控制器用来控制I/O设备的具体动作，不同的I/O设备完成的控制功能也不同。机、电、磁、光部件与具体的I/O设备有关，即I/O设备的具体结构大致与机、电、磁、光的工作原理有关。本节主要介绍有关设备控制器的内容，要求读者能理解I/O设备的工作原理。现代的I/O设备一般还通过接口与主机联系，至于接口的详细内容将在5.3节中讲述。I/O设备I/O设备大致可分为三类。(1)人机交互设备它是实现操作者与计算机之间互相交流信息的设备，能将人体五官可识别的信息转换成机器可识别的信息，如键盘、鼠标、手写板、扫描仪、摄像机、语音识别器等。反之，另一类是将计算机的处理结果信息转换为人们可识别的信息，如打印机、显示器、绘图仪、语音合成器等。(2)计算机信息的存储设备系统软件和各种计算机的有用信息，其信息量极大，需存储保留起来。存储设备多数可作为计算机系统的辅助存储器，如磁盘、光盘、磁带等。166第2篇计算机系统的硬件结构(3)机-机通信设备它是用来实现一台计算机与其他计算机或与其他系统之间完成通信任务的设备。例如，两台计算机之间可利用电话线进行通信，它们可以通过调制解调器(Modem)完成。用计算机实现实时工业控制，可通过D/A、A/D转换设备来完成。计算机与计算机及其他系统还可通过各种设备实现远距离的信息交换。表5.1列出了现代常用的I/O设备的名称及用途。本节主要介绍人机交互设备，可分为输入设备和输出设备两种，并且有的设备既具有输入功能，又具有输出功能。关于存储设备已在第4章介绍过，有关机-机通信设备将在“计算机网络”课程中讲述。输入设备完成输入程序、数据和操作命令等功能。当实现人工输入时，往往与显示器联用，以便检查和修正输入时的错误。也可以利用软盘、磁带等脱机录入的介质进行输入。目前已可以实现语音直接输入。键盘是应用最普遍的输入设备。可以通过键盘上的各个键，按某种规范向主机输入各种信息，如汉字、外文、数字等。键盘由一组排列成阵列形式的按键开关组成，如图5.14所示。键盘上的按键分字符键和控制功能键两类。字符键包括字母、数字和一些特殊符号键；控制功能键是产生控制字符的键(由软件系统定义功能)，还有控制光标移动的光标控制键以及用于插入或消除字符的编辑键等。键盘输入信息分为以下3个步骤。①按下一个键。②查出按下的是哪个键。③将此键翻译成ASCⅡ码(参见附录5A)，由计算机接收。按键是由人工操作的，确认按下的是哪一个键可用硬件或软件的方法来实现。采用硬件确认哪个键被按下的方法称为编码键盘法，它由硬件电路形成对应被按键的唯一编码信息。为了便于理解，下面以8×8键盘为例，说明硬件编码键盘法是如何通过对键盘扫描来识别按键所对应的ASCⅡ码的，其原理如图5.15所示。图5.15中的6位计数器经两个八选一的译码器对键盘扫描。若键未按下，则扫描将随着计数器的循环计数而反复进行。一旦扫描发现某键被按下，则键盘通过一个单稳电路产生一个脉冲信号。该信号一方面使计数器停止计数，用以终止扫描，此刻计数器的值便与所按键的位置相对应，该值可作为只读存储器(ROM)的输入地址，而该地址中的内容即为所按键的ASCⅡ码。可见只读存储器存储的内容便是对应各个键的ASCⅡ码。另一方面，此脉冲经中断请求触发器向CPU发中断请求，CPU响应请求后便转入中断服务程序，在中断服务程序的执行过程中，CPU通过执行读入指令，将计数器所对应的ROM地址中的内容，即所按键对应的ASCⅡ码送入CPU中。CPU的读入指令既可作为读出ROM内容的片选信号，而且经一段延迟后，又可用来清除中断请求触发器，并重新启动6位计数器开始新的扫描。采用软件判断键是否按下的方法称为非编码键盘法，这种方法利用简单的硬件和一套专用图5.15带只读存储器的编码键盘原理图键盘编码程序来判断按键的位置，然后由CPU将位置码经查表程序转换成相应的编码信息。这种方法结构简单，但速度比较慢。在按键时往往会出现键的机械抖动，容易造成误动。为了防止形成误判，在键盘控制电路中专门设有硬件消抖电路，或采取软件技术，以便有效地消除因键的抖动而出现的错误。此外，为了提高传输的可靠性，可采用奇偶校验码(见附录5C)来验证信息的准确性。随着大规模集成电路技术的发展，厂商已提供了许多种可编程键盘接口芯片，如Intel8279就是可编程键盘/显示接口芯片，用户可以随意选择。近年来又出现了智能键盘，如IBMPC的键盘内装有Intel8048单片机，用它可完成键盘扫描、键盘监测、消除重键、自动重发、扫描码的缓冲以及与主机之间的通信等任务。鼠标(Mouse)是一种手持式的定位设备，由于它拖着一根长线与接口相连，外形有点像老鼠；故取名为鼠标。常用的鼠标有两种：一种是机械式的，它的底座装有一个金属球，球在光滑表面上摩擦使球转动，球与4个方向的电位器接触，可测得上下左右4个方向的相对位移量，通过显示器便可确定欲寻求的方位。另一种是光电式鼠标，它需要与一块画满小方格的长方形金属板配合使用。安装在鼠标底部的光电转换器可以确定坐标点的位置，同样由显示器显示器所寻找的方位。光电式鼠标比机械式鼠标可靠性高，但需要增加一块金属板。机械式鼠标可以直接在光滑的桌面上摩擦，但往往因桌面上的灰尘随金属球滚动带入鼠标内，致使金属球转动不灵。触摸屏是一种对物体的接触或靠近能产生反应的定位设备。按原理的不同，触摸屏大致可分为5类：电阻式、电容式、表面超声波式、扫描红外线式和压感式。表面超声波式触摸屏是由一个透明的玻璃罩组成的。在罩的x和y轴方向都有一个发射和接收压电转换器和一组反射器条，触摸屏还有一个控制器发送5MHz的触发信号给发射、接收转换器，让它转换成表面超声波，此超声波在屏幕表面传播。当用手指触摸屏幕时，在触摸位置上的超声波被吸收，使接收信号发生变化，经控制分析和数字转换为x和y的坐标值。可见，任何一种触摸屏都是通过某种物理现象来测得人手触及屏幕上各点的位置，从而通过CPU对此做出响应，由显示屏再现所需的位置。由于物理原理不同，体现出各类触摸屏的不同特点及其适用的场合。例如，电阻式能防尘、防潮，并可戴手套触摸，适用于饭店、医院等。电容式触摸屏亮度高，清晰度好，也能防尘、防潮，但不可戴手套触摸，并且易受温度、湿度变化的影响，因此，它适合于游戏机及供公共信息查询系统使用。表面超声波式触摸屏透明、坚固、稳定，不受温度、湿度变化的影响，是一种抗恶劣环境的设备。在此主要介绍图形、图像的输入设备，有关语音和文字的输入设备不做介绍。(1)光笔光笔(LightPen)的外形与钢笔相似，头部装有一个透镜系统，能把进入的光会聚成一个光点。光笔的后端用导线连到计算机输入电路上。光笔头部附有开关，当按下开关时，进行光检测，光笔便可拾取显示屏上的绝对坐标。光笔与屏幕的光标配合，可使光标跟踪光笔移动，在屏幕上画出图形或修改图形，类似人们用钢笔画图的过程。(2)画笔与图形板画笔(Stylus)同样为笔状，但必须配合图形板(Tablet)使用。当画笔接触到图形板上的某一位置时，画笔在图形板上的位置坐标就会自动传送到计算机中，随着画笔在板上的移动可以画出图形。图形板和画笔构成二维坐标的输入设备，主要用于输入工程图等。将图纸贴在图形板上，画笔沿着图纸上的图形移动，即可输入工程图。图形板是一种二维的A/D变换器，又称为数字化板。坐标的测量方法有电阻式、电容式、电磁感应式和超声波式几种。画笔与光笔都是输入绝对坐标，而鼠标只能输入相对坐标。(3)图像输入设备最直接的图像输入设备是摄像机(Camera)，它能摄取任何地点、任何环境下的自然景物和各类物体，经数字量化后变成数字图像存入磁带或磁盘。如果图像已记录在某种介质上，则可用读出装置来读出图像。例如，记录在录像带上的图像可用录放机读出，再将视频信号经图像板量化输入计算机中。记录在数字磁带上的遥感图像可直接从磁带输入计算机中。如果把纸上的图像输入计算机内，则可用摄像机直接摄入，或用装有CCD(电荷耦合器件)的图文扫描仪(Scanner)或图文传真机送入计算机。还有一种专用的光机扫描鼓，也可把纸上的图像直接转换成数字图像存入计算机。(1)概述以可见光的形式传递和处理信息的设备称为显示设备。它是应用最广的人机通信设备。显示设备种类繁多，按显示器件划分，有阴极射线管(CathodeRayTube，CRT)显示器、液晶显示器(LiquidCrystalDisplay,LCD)、等离子显示器(PD)等;按显示内容分有字符显示器、图形显示器和图像显示器；按显示器功能分有普通显示器和显示终端(终端是由显示器和键盘组成的一套独立完整的输入输出设备，它可以通过标准接口连接到远程主机，其结构比显示器复杂得多)两类。在CRT显示器中，按扫描方式不同，可分为光栅扫描和随机扫描两种；按分辨率不同，又可分为高分辨率和低分辨率的显示器。CRT是目前应用最广泛的显示器件，既可作为字符显示器，又可作为图像、图形显示器。CRT是一个漏斗形的电真空器件，由电子枪、荧光屏及偏转装置组成，如图5.17所示。电子枪包括灯丝、阴极、控制(栅)极、第一阳极(加速阳极)、第二阳极(聚焦极)和第三阳极。当灯丝加热后，阴极受热而发射电子，电子的发射量和发射速度受控制极控制。电子经加速、聚焦而形成电子束，在第三阳极形成的均匀空间电位作用下，使电子束高速射到荧光屏上，荧光屏上的荧光粉受电子束的轰击产生亮点，其亮度取决于电子束的轰击速度、电子束电流强度和荧光粉的发光效率。电子束在偏转系统控制下，可在荧光屏的不同位置产生光点，由这些光点可以组成各种所需的字符、图形和图像。彩色CRT的原理与单色CRT的原理是相似的，只是对彩色CRT而言，通常用3个电子枪发射的电子束，经定色机构，分别触发红、绿、蓝三种颜色的荧光粉发光，按三基色迭加原理形成彩色图像。CRT荧光屏尺寸大小是按屏幕对角线长度表示，普通字符显示器的CRT有12英寸和14英寸两种，图形、图像显示器的CRT有15英寸、17英寸和19英寸，目前还出现了21英寸大屏幕CRT。分辨率和灰度等级是CRT的两个重要技术指标。分辨率是指显示屏面能表示的像素点数，分辨率越高，图像越清晰。灰度等级是指显示像素点相对亮暗的级差，在彩色显示器中它还表现为色彩的差别。CRT荧光屏发光是由电子束轰击荧光粉产生的，其发光亮度一般只能维持几十毫秒。为了使人眼能看到稳定的图像，电子束必须在图像变化前不断地进行整个屏幕的重复扫描，这个过程称为刷新。每秒刷新的次数称为刷新频率，一般刷新频率大于30次/秒时，人眼就不会感到闪烁。在显示设备中，通常都采用电视标准，每秒刷新50帧(Frame)图像。为了不断地刷新，必须把瞬时图像保存在存储器中，这种存储器称为刷新存储器，又称帧存储器或视频存储器(VRAM)。刷新存储器的容量由图像分辨率和灰度等级决定。分辨率越高，灰度等级越多，需要的刷新存储器容量就越大。例如，分辨率为512×512像素，灰度等级为256的图像，其刷新存储器的容量需达512×512×8b，即为256KB。此外，刷新存储器的存取周期必须与刷新频率相匹配。计算机的显示器大多采用光栅扫描方式。所谓光栅扫描，是指电子束在荧光屏上按某种轨迹运动，光栅扫描是从上至下顺序扫描，可分为逐行扫描和隔行扫描两种。一般CRT都采用与电视相同的隔行扫描，即把一帧图像分为奇数场(由1、3、5等奇数行组成)和偶数场(由0、2、4、6等偶数行组成)，一帧图像需扫描625行，则奇数场和偶数场各扫描312.5行。扫描顺序是先扫描偶数场，再扫描奇数场，交替进行，每秒显示50场。(2)字符显示器字符显示器是计算机系统中最基本的输出设备，它通常由CRT控制器和显示器(CRT)组成，图5.18示意了它的原理框图。1)显示存储器(刷新存储器)VRAM显示存储器存放欲显示字符的ASCⅡ码，其容量与显示屏能显示的字符个数有关。如显示屏上能显示80列×25行=2000个字符，则显示存储器的容量应为2000×8(字符编码7位，闪烁1位)，每个字符所在存储单元的地址与字符在荧光屏上的位置一一对应，即显示存储器单元的地址顺序与屏面上每行从左到右，按行从上到下的显示器位置对应。2)字符发生器由于荧光屏上的字符由光点组成，而显示存储器中存放的是ASCⅡ码，因此，必须有一个部件能将每个ASCⅡ码转变为一组5×7或7×9的光点矩阵信息。具有这种变换功能的部件称为字符发生器，它实质是一个ROM。图5.19是一个对应7×9光点矩阵的字符发生器原理框图。图中ROM₁的个数与显示器所能显示的字符种类有关，例如，能显示97个字符，则i=1~97。每个ROM，共有9个单元(对应9行)，每个单元中存放7位光点代码。如“C”的9个单元中，所存储的9组光点代码分别为0111110、1000001、1000000、1000000、1000000、1000000、1000000、1000001、0111110(设“1”对应亮点,“0”对应暗点)。字符发生器工作时,由显示存储器输出的ASCⅡ码作为ROM的高位地址(列地址)，而ROM的低位地址(行地址)来自CRT控制器的光栅地址计数器。ROM的输出并行加载到移位寄存器中，然后在点阵时钟控制下，移位输出形成视频信号，作为CRT的亮度控制信号。显示器在水平同步、垂直同步(来自CRT控制器)和视频信号(来自字符发生器)的共同作用下，连续不断地进行屏幕刷新，就能显示稳定而不消失的字符图像。3)CRT控制器CRT控制器通常都做成专用芯片，它可接收来自CPU的数据和控制信号，并给出访问显示存储器的地址和访问字符发生器的光栅地址，还能给出CRT所需的水平同步和垂直同步信号等。该芯片的定时控制电路要对显示每个字符的点(光点)数、每排(字符行)字(7×9点阵)数、每排行(光栅行)数和每场排数计数。因此，芯片中需配置点计数器、字计数器(水平地址计数器)、行计数器(光栅地址计数器)和排计数器(垂直地址计数器)，这些计数器用来控制显示器的逐点、逐行、逐排、逐屏的刷新显示，还可以控制对显示存储器的访问和屏幕间扫描的同步。点计数器记录每个字的横向光点，因每个字符占7个光点，字符间留一个光点作间隙，共占8个光点，故点计数器为模8计数器，计满8个点向字计数器进位。字计数器用来记录屏幕上每排的字数，若每排能显示80个字，考虑到屏幕两边失真较大，各空出5个字符位置，再加上光栅回扫消隐时间(此段时间屏幕不显示)的需要，占20个显示字符的时间，总共80+10+20=110，则字计数器计满110就归零，并向行计数器进位。行计数器用来记录每个字(7×9点阵)的9行光栅地址，外加每排字的3行间隔，总共9+3=12，即行计数器计满12归零，并向排计数器进位。排计数器用来记录每屏字符的排数，若能显示25排，再考虑到屏幕上下失真空一排，则共26排，即排计数器计满26归零，表示一场扫描结束。字计数器反映了光栅扫描的水平方向，排计数器反映了光栅扫描的垂直方向，将这两个方向的同步信号输至CRT的x和y偏转线圈，便可达到按指定位置进行显示的要求。值得注意的是，CRT的扫描方式不是一个字符一个字符地扫描，而是每次对一排字符中所有字符的同一行进行扫描，并显示亮点。例如，某排字符为WELCOME，其显示次序是：先从显示存储器中读出“W”字符，送至字符发生器，并从字符发生器中扫描选出“W”字符的第一行光点代码，于是屏幕上显示出“W”字符第一行的7个光点代码；再从显示存储器中读出“E”字符并送字符发生器，又选出“E”字符的第一行7个光点代码……直到最后一个字符“E”的第一行7个光点代码显示完毕。接着进行每个字符点阵的第二行7个光点代码的扫描⋯⋯直到该排每个字符的第9行光点代码扫描完毕，则屏幕上完整地显示出WELCOME字符。(3)图形显示器图形显示器是用点、线(直线和曲线)、面(平面和曲面)组合成平面或立体图形的显示设备，并可作平移、比例变化、旋转、坐标变换、投影变换(把三维图形变为二维图形)、透视变换(由一个三维空间向另一个三维空间变换)、透视投影(把透视变换和投影变换结合在一起)、轴侧投影(三面图)、单点透视、两点或三点透视以及隐线处理(观察物体时把看不见的部分去掉)等操作。主要用于计算机辅助设计(CAD)和计算机辅助制造(CAM)，如汽车、飞机、舰船、土建以及大规模集成电路板等的设计制造。图形显示器经常配有键盘、光笔、鼠标及绘图仪等。利用CRT显示器产生图形有两种方法：一种是随机扫描法，另一种是光栅扫描法。随机扫描法在随机扫描时，电子束产生图形的过程和人用笔在纸上画图的过程相似，任何图形的线条都被认为是由许多微小的首尾相接的线段来逼近的，这些微小的线段称为矢量，故这种方法又称为矢量法。与此法相对应的显示器称为随机扫描图形显示器，其缺点是在显示复杂图形时，会出现闪烁现象。与光栅扫描法对应的显示器称为光栅扫描图形显示器。其特点是把对应于屏幕上的每个像素信息都存储在刷新存储器中。光栅扫描时，读出这些像素来调制CRT的灰度，以便控制屏幕上像素的亮度。同样也需不断地对屏幕进行刷新，使图形稳定显示。图5.20示意了光栅扫描图形显示器的硬件结构框图。图5.20中的程序段缓存用来存储计算机送来的显示文件和图形操作命令，如图形的局部放大、平移、旋转、比例变换以及图形的检索等。这些操作直接由显示处理器完成。刷新存储器存放一帧图形的形状信息，它与屏幕上的像素一一对应。例如，屏幕的分辨率为1024×1024像素，且像素的灰度为256级，则刷新存储器就需要有1024×1024个单元，每个单元的字长为8位。可见刷新存储器的容量与分辨率、灰度都有关。图5.20中的DDA(DigitalDifferenceAnalyses)是数字差分分析器,它能将显示文件变换成图形形状，是一种完成数据插补的部件，能够根据显示文件给出的曲线类型和坐标值，生成直线、圆、抛物线甚至更复杂的曲线。插补后的数据存入刷新存储器用于显示。此外，对于数字化的图像数据也可直接输入刷新存储器，不经DDA等图形控制部分便可用来显示图像。光栅扫描显示器的通用性强，灰度层次多，色调丰富，显示复杂图形时无闪烁，所形成的图形可以有消除隐藏面、阴影效应和涂色等功能。(4)图像显示器图形显示器所显示的图形是由计算机用一定的算法形成的点、线、面、阴影等，来自主观世界，故又称为主观图像或计算机图像。图像显示器所显示的图像(如遥感图像、医学图像、自然景物、新闻照片等)通常来自客观世界，故又称为客观图像。图像显示器是把由计算机处理后的图像(称为数字图像)以点阵的形式显示出来。通常采用光栅扫描方式，其分辨率为256×256像素或512×512像素，也可与图形显示器兼容，其分辨率可达1024×1024像素，灰度等级可达64至256级。图像显示器除了能存储从计算机输入的图像并在显示屏幕上显示外，还具有灰度变换、窗口技术、真彩色和伪彩色显示等图像增强技术功能。·灰度变换：可使原始图像的对比度增强或改变。●窗口技术：在图像存储器中，每个像素有2048级灰度值，而人的肉眼只能分辨到40级。如果从2048级中开一个小窗口，并把这窗口范围内的灰度级取出，使之变换为64级显示灰度，就可以使原来被掩盖的灰度细节充分显示出来。●真彩色和伪彩色：真彩色是指真实图像色彩显示，采用色还原技术，如彩色电视；伪彩色处理是一种图像增强技术。通常肉眼能分辨黑白色只有几十级灰度，但却能分辨出上千种色彩。利用伪彩色技术可以人为地对黑白图像进行染色，例如，把水的灰度染成蓝色，把植物的灰度染成绿色，把土地的灰度染成黄色等。此外，图像显示器还具有几何处理功能，如图像放大(按2、4、8倍放大)、图像分割或重叠、图像滚动等。图5.21示意了一种简单的图像显示器原理框图。简单的图像显示器只显示由计算机送来的数字图像，图像处理操作在主机中完成，显示器不做任何处理。其中I/O接口、刷新存储器、A/D、D/A转换等组成单独的一部分，称为视频数字化仪(VideoDigitizer)或图像输入控制板(简称图像板)，其功能是实现连续的视频信号与离散的数字量之间的转换。视频数字化仪接收摄像机的视频输入信号，经A/D变换为数字量存入刷新存储器用于显示，并可传送到主机进行图像处理操作。操作后的结果送回刷新存储器，又经D/A变为视频信号输出，由监视器(Monitor)显示输出。监视器只包括扫描、视频放大等有关的显示电路和显像管。也可接至电视机的视频输入端，用电视机代替监视器。一般通用计算机配置一块图像板和监视器便能组成一个图像处理系统。(5)IBMPC系列微型计算机的显示标准IBMPC系列微型计算机配套的显示系统有两大类。一类是基本显示系统，用于字符/图形显示；另一类是专用显示系统，用于高分辨率图形或图像显示。这里仅介绍几种显示标准。1)MDA(MonochromeDisplayAdapter)标准MDA是单色字符显示标准，采用9×14点阵的字符窗口，满屏显示80列、25行字符，对应分辨率为720×350像素。MDA不能兼容图形显示。176第2篇计算机系统的硬件结构2)CGA(ColorGraphicsAdapter)标准CGA是彩色图形/字符显示标准，可兼容字符和图形两种显示方式。在字符方式下，字符窗口为8×8点阵，故字符质量不如MDA，但字符的背景可以选择颜色。在图形方式下，可以显示640×200两种颜色或320×200四种颜色的图形。3)EGA(EnhancedGraphicsAdapter)标准EGA标准集中了MDA和CGA两个显示标准的优点，并有所增强。其字符窗口为8×14点阵，字符显示质量优于CGA而接近MDA。图形方式下分辨率为640×350像素，有16种颜色，彩色图形的质量优于CGA，且兼容原CGA和MDA的各种显示方式。4)VGA(VideoGraphicsArray)标准VGA标准在字符方式下，字符窗口为9×16点阵，在图形方式下分辨率为640×480像素、16种颜色,或320×200像素、256种颜色,还有720×400像素的文本模式。近年来显示标准有了很大发展,改进型的VGA,如SVGA(SuperVGA)标准,分辨率为800×600像素、16种颜色(每像素4位)。XGA(ExtendedGraphicsArray)支持1024×768像素的分辨率、256种颜色(每像素8位),或者640×480像素的分辨率(每像素16位,或称高色)。XGA-2进一步支持1024×768像素的分辨率(高色，更高视频)和1360×1024像素的分辨率(每像素4位,16种颜色可选)。SXGA(SuperXGA)分辨率达1280×1024像素,每个像素用32位表示(本色)。UXGA(UltraXGA)分辨率已达1600×1200像素,每个像素32位表示(本色)。最近笔记本计算机开始流行显示纵横比为16：9的XGA格式，又称为WXGA(WideXGA)标准,其分辨率为1280×720像素。而WUXGA(WideUltraXGA)标准是一种分辨率为1920×1200像素、纵横比为16：10的UXGA格式，这种纵横比在高档15英寸和17英寸笔记本计算机上越来越流行。打印设备可将计算机运行结果输出到纸介质上，并能长期保存，是一种硬拷贝设备。相比之下，显示器在屏幕上的信息是无法长期保存的，故它不属于硬拷贝设备。(1)打印设备的分类打印设备的种类有很多种划分方法。按印字原理划分，有击打式和非击打式两大类。击打式打印机是利用机械动作使印字机构与色带和纸相撞击而打印字符，其特点是设备成本低、印字质量较好，但噪声大、速度慢。击打式打印机又分为活字打印机和点阵针式打印机两种。活字打印机是将字符刻在印字机构的表面上，印字机构的形状有圆柱形、球形、菊花瓣形、鼓轮形、链形等，现在用得越来越少。点阵打印机的字符是点阵结构，它利用钢针撞击的原理印字，目前仍用得较普遍。非击打式打印机采用电、磁、光、喷墨等物理和化学方法来印刷字符，如激光打印机、静电打印机、喷墨打印机等，它们速度快，噪声低，印字质量比击打式的好，但价格比较贵，有的设备需用专用纸张进行打印。按工作方式分，有串行打印机和行式打印机两种。前者是逐字打印，后者是逐行打印，故行式打印机比串行打印机速度快。此外，按打印纸的宽度还可分宽行打印机和窄行打印机，还有能输出图的图形/图像打印机，具有色彩效果好的彩色打印机等。(2)点阵针式打印机点阵针式打印机结构简单、体积小、重量轻、价格低、字符种类不受限制、较易实现汉字打印，还可打印图形和图像，是目前应用最广泛的一种打印设备。一般在微型、小型计算机中都配有这类打印机。点阵针式打印机的印字原理是由打印针(钢针)印出n×m个点阵来组成字符或图形。点越多、越密,字形质量越高。西文字符点阵通常采用5×7、7×7、7×9、9×9几种,汉字的点阵采用16×16、24×24、32×32和48×48多种。图5.22是7×9点阵字符的打印格式和打印头的示意图。打印头中的钢针数与打印机型号有关，有7针、9针，也有双列14(2×7)针或双列24(2×12)针。打印头固定在托架上，托架可横向移动。图5.22中为7根钢针，对应垂直方向的7点，由于受机械安装的限制，这7点之间有一定的间隙。水平方向各点的距离取决于打印头移动的位置，故可密集些，这对形成斜形或弧形笔画非常有利。字符的形成是按字符中各列所包含的点逐列形成的。例如，对于字符E，先打印第2列的1~7个点，再打印第4、6、8列的第1、4、7三点，最后打第10列的1、7两个点。可见每根针可以单独驱动。打印一个字符后，空出3列(第11、0、1列)作为间隙。针式打印机由打印头、横移机构、输纸机构、色带机构和相应的控制电路组成，如图5.23所示。打印机被CPU启动后，在接收代码时序器控制下，功能码判别电路开始接收从主机送来的欲打印字符的字符代码(ASCII码)。首先判断该字符是打印字符码还是控制功能码(如回车、换行、换页等)，若是打印字符码，则送至缓冲存储器，直到把缓冲存储器装满为止；若是控制功能码，则打印控制器停止接收代码并转入打印状态。打印时首先启动打印时序器，并在它控制下，从缓冲存储器中逐个读出打印字符码，再以该字符码作为字符发生器ROM的地址码，从中选出对应的字符点阵信息(字符发生器可将ASCⅡ码转换成打印字符的点阵信息)。然后在列同步脉冲计数器控制下，将一列列读出的字符点阵信息送至打印驱动电路，驱动电磁铁带动相应的钢针进行打印。每打印一列，固定钢针的托架就要横移一列距离，直到打印完最后一列，形成n×m点阵字符。当一行字符打印结束或换行打印或缓存内容已全部打印完毕时，托架就返回到起始位置，并向主机报告，请求打印新的数据。图5.23(a)中的输纸机构受步进电机驱动，每打印完一行字符，按给定要求走纸。色带的作用是供给色源，如同复写纸的作用。如图5.22(a)所示，钢针撞击在色带上，就可将颜色印在纸上，色带机构可使色带不断移动，以改变受击打的位置，避免色带的破损。有的点阵针式打印机内部配有一个独立的微处理器，用来产生各种控制信号，完成复杂的打印任务。上面介绍的针式打印机是串行点阵针式打印机，打印速度每秒100个字符左右，在微型计算机系统广泛采用。在大型、中型通用计算机系统中；为提高打印速度，通常配备行式点阵打印机，它是将多根打印针沿横向排成一行，安装在一块形似梳齿状的梳形板上，每根针各由一个电磁铁驱动。打印时梳形板可向左右移动，每移动一次印出一行印点。当梳形板改变移动方向时，走纸机构使纸移动一个印点间距，如此重复多次即可打印出一行字符。例如，44针行式打印，沿水平方向均匀排列44根打印针，每根针负责打印3个字符，打印行宽为44×3=132列字符。如果每根针负责打印两个字符，则可采用66针结构。(3)激光打印机激光打印机采用了激光技术和照相技术，由于它的印字质量好，在各种计算机系统中广泛采用。激光打印机的工作原理如图5.24所示。激光打印机由激光扫描系统、电子照相系统、字形发生器和接口控制器几部分组成。接口控制器接收由计算机输出的二进制字符编码及其他控制信号；字形发生器可将二进制字符编码转换成字符点阵脉冲信号；激光扫描系统的光源是激光器，该系统受字符点阵脉冲信号的控制，能输出很细的激光束，该激光束对做圆周运动的感光鼓进行轴向(垂直于纸面)扫描。感光鼓是电子照相系统的核心部件，鼓面上涂有一层具有光敏特性的感光材料，主要成分为硒，故感光鼓又称为硒鼓。感光鼓在未被激光扫描之前，先在黑暗中充电，使鼓表面均匀地沉积一层电荷，扫描时激光束对鼓表面有选择地曝光，被曝光的部分产生放电现象，未被曝光的部分仍保留充电时的电荷，这就形成了“潜像”。随着鼓的圆周运动，“潜像”部分通过装有碳粉盒的显像系统，使“潜像”部分(实际上是具有字符信息的区域)吸附上碳粉，达到“显影”的目的。当鼓上的字符信息区和打印纸接触时，由纸的背面施以反向的静电电荷，则鼓面上的碳粉就会被吸附到纸面上，这就是“转印”或“转写”过程。最后经过定影系统就将碳粉永久性地粘在纸上。转印后的鼓面还留有残余的碳粉，故先要除去鼓面上的电荷，经清扫系统将残余碳粉全部清除，然后重复上述充电、曝光、显形、转印、定影等一系列过程。激光打印机可以使用普通纸张打印，输出速度高，一般可达10000行/分(高速的可达70000行/分)，印字质量好，普通激光打印机的印字分辨率可达300dpi(每英寸300个点)或400dpi。字体字形可任意选择，还可打印图形、图像、表格、各种字母、数字和汉字等字符。激光打印机是非击打式硬拷贝输出设备，是逐页输出的，故又有“页式输出设备”之称。普通击打式打印机是逐字或逐行输出的。页式输出设备的速度以每分钟输出的页数(PagesPerMinute,PPM)来描述。高速激光打印机的速度在100ppm以上,中速为30~60ppm,它们主要用于大型计算机系统。低速激光打印机的速度为10~20ppm或10ppm以下，主要用于办公室自动化系统和文字编辑系统。(4)喷墨打印机喷墨打印机是串行非击打式打印机，印字原理是将墨水喷射到普通打印纸上。若采用红、绿、蓝三色喷墨头，便可实现彩色打印。随着喷墨打印技术的不断提高，其输出效果接近于激光打印机，而价格又与点阵针式打印机相当，因此也得到广泛应用。图5.25(a)是一种电荷控制式喷墨打印机的原理框图，主要由喷头、充电电极、墨水供应、过滤回收系统及相应的控制电路组成。喷墨头后部的压电陶瓷受振荡脉冲激励，使喷墨头喷出具有一定速度的一串不连续、不带电的墨水滴。墨水滴通过充电电极时被充上电荷，其电荷量的大小由字符发生器控制。字符发生器可将字符编码转换成字符点阵信息。由于各点的位置不同，充电电极所加的电压也不同，电压越高，充电电荷越多，墨滴经偏转电极后偏移的距离也越大，最后墨滴落在印字纸上。图中只有一对垂直方向的偏转电极，因此墨滴只能在垂直方向偏移。若垂直线段上某处不需喷点(对应字符在此处无点阵信息)，则相应墨滴不充电，在偏转电场中不发生偏转，而射入回收器中。横向没有偏转电极，靠喷头相对于记录纸作横向移动来完成横向偏转。图5.25(b)示意了H字符由5×7点阵组成。墨滴的运动轨迹如图中所示的数字顺序，可见字符中的每个点都要一个个地进行控制，故字符发生器的输出必须是一个点一个点的信息。这与点阵针式打印机的字符发生器一次输出一列上的7个点信息，分5次打印一个字符是完全不同的(参见图5.22)。喷墨打印机还有很多种，如电场控制型连续式喷墨打印机、随机式喷墨打印机以及具有多个喷头的喷墨打印机(如日本EPSON公司的TSQ-4800喷墨打印机有48个喷头)等，在此不做详述。(5)几种打印机的比较以上介绍的三种打印机都配有一个字符发生器，它们的共同点是都能将字符编码信息变为点阵信息，不同的是这些点阵信息的控制对象不同。点阵针式打印机的字符点阵用于控制打印针的驱动电路；激光打印机的字符点阵脉冲信号用于控制激光束；喷墨打印机的字符点阵信息控制墨滴的运动轨迹。此外，点阵针式打印机属于击打式打印机，可以逐字打印，也可以逐行打印；喷墨打印机只能逐字打印；激光打印机属于页式输出设备。后两种都属于非击打式打印机。不同种类的打印机性能和价格差别很大，用户可根据不同需要合理选用。要求印字质量高的场合可选用激光打印机；要求价格便宜的或只需具有文字处理功能的个人用计算机，可配置串行点阵针式打印机；要求处理的信息量很大，速度又要快，应该配行式打印机或高速激光打印机。计算机的I/O设备中有一类既是输入设备，又是输出设备，如磁盘、终端、A/D或D/A转换器以及汉字处理设备等。终端是由显示器和键盘组成的一套独立完整的I/O设备，它可以通过标准接口接到远离主机的地方使用。终端与显示器是两个不同的概念，终端的结构比显示器复杂，它能完成显示控制与存储、键盘管理及通信控制等，还可完成简单的编辑操作。当计算机用于过程控制时，其控制信号是模拟量，而计算机仅能处理数字量，这就要用A/D、D/A转换器来完成模拟量与数字量之间的相互转换任务。A/D转换器是模拟/数字转换器，它能将模拟量转换成数字量，是计算机的输入设备。A/D转换器均已制成各种规格的芯片。D/A转换器是数字/模拟转换器，它能将计算机输出的数字量转换成控制所需的模拟量，以便控制被控对象或直接输出模拟信号，它是计算机的输出设备。D/A转换器现在也均已制成各种规格的芯片。A/D与D/A转换器均属于过程控制设备，往往还需要配置其他设备，如传感器、放大电路、执行机构以及开关量I/O设备等，与计算机共同完成对对象的过程控制。计算机进行汉字信息处理时，必须将汉字代码化，即对汉字进行编码。汉字编码可分为输入码、内码和字形码三大类。输入码是解决汉字的输入和识别问题的；内码是由输入码转换而成的，只有内码才能在计算机内进行加工处理；字形码能显示或打印输出。汉字处理设备包括汉字输入、汉字存储和汉字输出三部分。(1)汉字的输入采用西文标准键盘输入汉字时，必须对汉字进行编码，以便用字母、数字串替代汉字输入。汉字编码方法主要有三类：数字编码、拼音编码和字形编码。●数字编码就是用数字串代表一个汉字的输入，常用的是国标区位码，也有的用电报码。使用区位码输入汉字时，必须根据国标GB2312《信息交换用汉字编码字符集——基本集》，先查出汉字对应的代码，然后才能输入。这种编码输入的优点是无重码，而且输入码和内码的转换比较方便，但每个汉字的编码都是一串等长的数字，很难记忆。·拼音码是以汉语读音为基础的，由于汉字同音字太多，输入重码率很高，因此按拼音输入后还必须进行同音字的选择，影响了输入速度。·字形编码是以汉字形状确定的，由于汉字都是由一笔一画构成的，而笔画又是有限的，而且汉字的结构(又称为部件)也可以归结为几类，因此，把汉字的笔画和部件用字母和数字编码后，再按笔画书写顺序依次输入，就能表示出一个汉字。常用的有五笔字型编码。目前这种编码输入方法的效率是最高的。上面介绍的汉字输入方法均为“手动”操作，主要用键盘输入。为了提高输入速度，又发展了词组输入、联想输入等输入方法。随着计算机技术的不断发展，利用语音或图像识别技术，直接将汉语或文本输入计算机，使计算机既能识别汉字，又能听懂汉语，并将其自动转换成机内代码。近年来有关语音识别、文字识别、自然语言理解及机器视觉等学科的研究都已有了不少好的成果，读者可查阅有关资料进一步了解。(2)汉字的存储汉字的存储包括汉字内码存储和字形码的存储。汉字内码是汉字信息在机内存储、交换、检索等过程中所使用的机内代码，通常用两个字节表示。使用汉字内码字符时，应注意和英文字符区别开。英文字符的机内代码是7位ASCⅡ码，字节的最高位为“0”，而汉字内码的两个字节最高位均为“1”。以汉字操作系统CCDOS中的汉字内码为例，汉字国标码“兵”用十六进制表示为“3224H”，每个字节最高位加“1”后，便得汉字内码为“B2A4H”(参见附录6A中的6A.1)。当使用编辑程序输入汉字时，存储到磁盘上的文件就是用机内码表示汉字的。有些机器把字节的最高位用作奇偶校验位，这时汉字内码需用3个字节表示。汉字输出有打印输出和显示输出两种形式。针式汉字打印机有24针和16针两种，前者印字质量较高。也可采用9针的西文打印机，当用9针打印机打印汉字时，需用软件控制把一行汉字分成两次打印，即每次打印8个点，第一次打印一行汉字的上半部，第二次打印一行汉字的下半部，拼在一起构成16×16的点阵汉字。汉字显示可用通用显示器，在主机内由汉字显示控制板(简称汉卡)或通用的图形显示板形成点阵码，再将点阵码送至显示设备。只要设备具有输出点阵的能力，就可以输出汉字。此外，汉字显示终端除了显示汉字外，还可作为人机通信设备。多媒体是“Multimedia”的汉译,而“Multimedia”一词是由“Multi”和“Media”两个词构成的复合词，直译即为“多媒体”。多媒体一词的核心词是媒体。所谓媒体，是指信息传递和存储的最基本的技术和手段。日常生活中最常用的媒体包括音乐、语言、图片、文件、书籍、电视、广播、电话等。人们可以通过媒体获取他(她)们所需的信息，同时也可以利用这些媒体将有用信息传送出去或保存起来。然而，传统的媒体设施、工具和手段大多是单一功能的。例如，音响设备只能录音或放音；电视只能提供音频和视频信息；报纸只能提供文字和图像图表信息等。由于都是单功能媒体，而且各自均独立分散，为此人们希望能有一个集多种功能的多媒体系统，这就是应用领域向计算机科学与技术和计算机工业提出的迫切要求。此外，计算机本身的发展也提出了同样的要求。回顾一下计算机的发展史，不难发现，计算机与某一信息形式结合便可以开拓一个新的应用领域。在20世纪50年代，计算机局限于处理数字，应用领域也限制在求解复杂的数学问题。到了20世纪60年代，计算机与字符处理、文本处理相结合，就出现了信息管理系统。后来计算机与图形结合，产生了CAD。计算机与照相技术相结合，又产生了图像(静)处理等。20世纪80年代曾是人工智能研究领域的高潮时代，首先是日本提出了以研究具有高度智能的第五代计算机为目标的FGCS计划，给世界计算机技术形成了一次冲击，可是经过了10年含辛茹苦地探索，人们才发现研制人工智能第五代计算机的时代远未成熟，只有在计算机科学理论和信息处理技术的高度发展以及知识库体系自我完备的基础上，第五代人工智能计算机的研制才有可能成为现实。人们在认识世界和对某一事物做出判断时，绝不是或不仅仅是用某种单一媒体上的信息或孤立地利用某一时刻的信息。人脑首先是具有高度的信息融合能力，其次是具有历史和环境提供的启示信息，以减少推理搜索空间的能力。目前的计算机还远远不具备人脑的这种能力，因此，人工智能也很难取得突破性的进展。研究多媒体计算机技术，就是要强调计算机与声音、活动图像和文字相结合。例如，将录像内容输到计算机内(如果需要可进行处理)，在播放时，可与多种其他媒体信息(如文字、声音)混合在一起，形成一个多媒体的演示系统。又如，将计算机产生的图形或动画与摄像机摄得的图像叠加在一起等。此外，采用人机对话方式，对计算机存储的各种信息进行查找、编辑以及实现同时播放，使多媒体系统成为一个交互式的系统。可见，多媒体计算机可作为研制高度智能计算机系统的一个平台。(1)视频和音频数据的压缩与解压缩技术多媒体计算机的关键问题是如何实时综合处理声、图和文字信息，需要将每幅图像从模拟量转换成数字量，然后进行图像处理，与图形、文字复合后存放在机器中。数字化图像和声音的信息量是非常大的。以一般彩色电视信号为例，设代表光强、色彩和色饱和度的YIQ色空间中各分量的带宽分别为4.2MHz、1.5MHz和0.5MHz。根据采样原理，仅当采样频率大于等于2倍的原始信号的频率时，才能保证采样后信号不失真地恢复为原始信号。再设各分量均被数字化为8位，从而1秒钟的电视信号的数据总量应为(4.2+1.5+0.5)×2×8=99.2Mb也就是说，彩色电视节目信号的数据量每秒约为100Mb，因而一个容量为1GB的CD-ROM仅能存放约一分钟的原始电视数据(每字节后面附有2位校验位)，很显然电视信号数字化后直接保存的方法是令人难以接受的。对于语音的数据也一样，一般人类语音的带宽为4kHz，同样依据采样定理，并设数字化精度为8位，则一秒钟的数据量约为4K×2×8=64K位，因此在上述采样条件下，讲一分钟话的数据量约为480KB。由此可见，电视图像、彩色图像、彩色静图像、文件图像以及语音等数据量是相当大的。特别是电视图像的数据量，在相同条件下要比语音数据量大1000倍。再加上计算机总线的传输速率的局限，因此，必须对信息进行压缩和解压缩。所谓图像压缩，是指图像从像素存储的方式经过图像变换、量化和高效编码等处理，转换成特殊形式的编码，从而大大降低计算机所需存储和实时传送的数据量。例如，Intel公司的交互式数字视频系统DVI能将动态图像数据压缩到135KBps的传送速度。信息编码方式很多，应选用符合国际标准的，并能用计算机或VLSI芯片快速实现的编码方法。(2)多媒体专用芯片由于多媒体计算机承担大量与数据信号处理、图像处理、压缩与解压缩以及解决多媒体之间关系等有关的问题，而且要求处理速度快，因此需研制专用芯片。一般多媒体专用芯片有两种类型：固定功能的和可编程的。(3)大容量存储器多媒体计算机需要存储的信息量极大，因此研制大容量的存储器仍是多媒体计算机系统的关键技术。(4)适用于多媒体技术的软件图5.27示意了多媒体系统的层次结构。最底层为计算机硬件，还可配置电视机、录像机及音像设备等。其上层是多媒体实时压缩和解压缩层，它将视频和音频信号压缩后存储在磁盘上，播放时要解压缩，而且要求处理速度快，通常采用以专用芯片为基础的电路卡。应用系统创作系统多媒体核心系统多媒体输入输出控制及接口多媒体实时压缩与解压缩计算机硬件多媒体输入输出控制及接口层与多媒体设备打交道，驱动控制这些硬件设备，并提供与高层软件的接口。多媒体核心系统层是多媒体操作系统，Intel、IBM、Microsoft和Apple等公司都开发了这层软件。创作系统层是为方便用户开发应用系统而设置的，具有编辑和播放等功能。应用系统层包括厂家或用户开发的应用软件。以上除最底层的硬件层外，其他层次都包含适用于多媒体技术的软件。接口可以看作两个系统或两个部件之间的交接部分，它既可以是两种硬设备之间的连接电路，也可以是两个软件之间的共同逻辑边界。I/O接口通常是指主机与I/O设备之间设置的一个硬件电路及其相应的软件控制。由图5.13可知，不同的I/O设备都有其相应的设备控制器，而它们往往都是通过I/O接口与主机取得联系的。主机与I/O设备之间设置接口的理由如下：①一台机器通常配有多台I/O设备，它们各自有其设备号(地址)，通过接口可实现I/O设备的选择。②I/O设备种类繁多，速度不一，与CPU速度相差可能很大，通过接口可实现数据缓冲，达到速度匹配。③有些I/O设备可能串行传送数据，而CPU一般为并行传送，通过接口可实现数据串-并格式的转换。④I/O设备的输入输出电平可能与CPU的输入输出电平不同，通过接口可实现电平转换。⑤CPU启动I/O设备工作，要向I/O设备发各种控制信号，通过接口可传送控制命令。⑥I/O设备需将其工作状态(如“忙”“就绪”“错误”“中断请求”等)及时向CPU报告，通过接口可监视设备的工作状态，并可保存状态信息，供CPU查询。值得注意的是，接口(Interface)和端口(Port)是两个不同的概念。端口是指接口电路中的一些寄存器，这些寄存器分别用来存放数据信息、控制信息和状态信息，相应的端口分别称为数据端口、控制端口和状态端口。若干个端口加上相应的控制逻辑才能组成接口。CPU通过输入指令，从端口读入信息，通过输出指令，可将信息写入端口中。1.总线连接方式的I/O接口电路图5.28所示为总线结构的计算机，每一台I/O设备都是通过I/O接口挂到系统总线上的。图中的I/O总线包括数据线、设备选择线、命令线和状态线。(1)数据线数据线是I/O设备与主机之间数据代码的传送线，其根数一般等于存储字长的位数或字符的位数，它通常是双向的，也可以是单向的。若采用单向数据总线，则必须用两组才能实现数据的输入和输出功能，而双向数据总线只需一组即可。(2)设备选择线设备选择线是用来传送设备码的，它的根数取决于I/O指令中设备码的位数。如果把设备码看作地址号，那么设备选择线又可称为地址线。设备选择线可以有一组，也可以有两组，其中一组用于主机向I/O设备发送设备码，另一组用于I/O设备向主机回送设备码。当然设备选择线也可采用一组双向总线代替两组单向总线。(3)命令线命令线主要用以传输CPU向设备发出的各种命令信号，如启动、清除、屏蔽、读、写等。它是一组单向总线，其根数与命令信号多少有关。第5章输入输出系统187(4)状态线状态线是将I/O设备的状态向主机报告的信号线，例如，设备是否准备就绪，是否向CPU发出中断请求等。它也是一组单向总线。现代计算机中大多采用三态逻辑电路来构成总线。根据上述设置接口的理由，可归纳出接口通常应具有以下几个功能以及相应的硬件配置。(1)选址功能由于I/O总线与所有设备的接口电路相连，但CPU究竟选择哪台设备，还得通过设备选择线上的设备码来确定。该设备码将送至所有设备的接口，因此，要求每个接口都必须具有选址功能，即当设备选择线上的设备码与本设备码相符时，应发出设备选中信号SEL，这种功能可通过接口内的设备选择电路来实现。图5.29所示为接口1和接口2的设备选择电路。这两个电路的具体线路可以不同，它们分别能识别出自身的设备码，一旦某接口设备选择电路有输出时，它便可控制这个设备通过命令线、状态线和数据线与主机交换信息。(2)传送命令的功能当CPU向I/O设备发出命令时，要求I/O设备能做出响应，如果I/O接口不具备传送命令信息的功能，那么设备将无法响应，故通常在I/O接口中设有存放命令的命令寄存器以及命令译码器,如图5.30所示。命令寄存器用来存放I/O指令中的命令码，它受设备选中信号控制。命令线和所有接口电路的命令寄存器相连，只有被选中设备的SEL信号有效，命令寄存器才可接受命令线上的命令码。(3)传送数据的功能既然接口处于主机与I/O设备之间，因此数据必须通过接口才能实现主机与I/O设备之间的传送。这就要求接口中具有数据通路，完成数据传送。这种数据通路还应具有缓冲能力，即能将数据暂存在接口内。接口中通常设有数据缓冲寄存器(DataBufferRegister,DBR),它用来暂存I/O设备与主机准备交换的信息，与I/O总线中的数据线是相连的。每个接口中的数据缓冲寄存器的位数可以各不相同，这取决于各类I/O设备的不同需要。例如，键盘接口的DBR定为8位，因为ASCⅡ码为7位(见附录5A)，再加一位奇偶校验位，故为8位。又如磁盘这类外设，其DBR的位数通常与存储字长的位数相等，而且还要求具有串-并转换能力，既可将从磁盘中串行读出的信息并行送至主存，又可将从主存中并行读出的信息串行输至磁盘。(4)反映I/O设备工作状态的功能为了使CPU能及时了解各I/O设备的工作状态，接口内必须设置一些反映设备工作状态的触发器。例如，用完成触发器D和工作触发器B来标志设备所处的状态。当D=0,B=0时,表示I/O设备处于暂停状态。当D=1,B=0时,表示I/O设备已经准备就绪。当D=0，B=1时，表示I/O设备正处于准备状态。由于现代计算机系统中大多采用中断技术，因此接口电路中一般还设有中断请求触发器INTR，当其为“1”时，表示该I/O设备向CPU发出中断请求。接口内还有屏蔽触发器MASK，它与中断请求触发器配合使用，完成设备的屏蔽功能(有关内容将在8.4节讲述)。所有的状态标志触发器都与I/O总线中的状态线相连。此外，不同的I/O设备的接口电路中还可根据需要增设一些其他状态标志触发器，如“出错”触发器、“数据迟到”触发器，或配置一些奇偶校验电路、循环码校验电路等。随着大规模集成电路制作工艺的不断进步，目前大多数I/O设备所共用的电路都制作在一个芯片内，作为通用接口芯片。另一些I/O设备专用的电路，制作在I/O设备的设备控制器中。本节所讲述的接口功能及组成均是指通用接口所具备的。图5.31所示为I/O接口的基本组成。I/O接口按不同方式分类有以下几种。①按数据传送方式分类，有并行接口和串行接口两类。并行接口是将一个字节(或一个字)的所有位同时传送(如Intel8255);串行接口是在设备与接口间一位一位传送(如Intel8251)。由于接口与主机之间是按字节或字并行传送，因此对串行接口而言，其内部还必须设有串-并转换装置。②按功能选择的灵活性分类，有可编程接口和不可编程接口两种。可编程接口的功能及操作方式可用程序来改变或选择(如Intel8255、Intel8251)；不可编程接口不能由程序来改变其功能，但可通过硬连线逻辑来实现不同的功能(如Intel8212)。③按通用性分类有通用接口和专用接口。通用接口可供多种I/O设备使用，如Intel8255、Intel8212；专用接口是为某类外设或某种用途专门设计的，如Intel8279可编程键盘/显示器接口;Intel8275可编程CRT控制器接口等。④按数据传送的控制方式分类，有程序型接口和DMA型接口。程序型接口用于连接速度较慢的I/O设备，如显示终端、键盘、打印机等。现代计算机一般都可采用程序中断方式实现主机与I/O设备之间的信息交换，故都配有这类接口，如Intel8259。DMA型接口用于连接高速I/O设备，如磁盘、磁带等，如Intel8237。有关这两类接口，将在5.5和5.6节中讲述它们的基本组成原理。为了正确完成这种查询，通常要执行如下3条指令。190第2篇计算机系统的硬件结构①测试指令，用来查询I/O设备是否准备就绪。②传送指令，当I/O设备已准备就绪时，执行传送指令。③转移指令，若I/O设备未准备就绪，执行转移指令，转至测试指令，继续测试I/O设备的状态。图5.34所示为单个I/O设备程序查询方式的程序流程。当需要启动某一I/O设备时，必须将该程序插入现行程序中。该程序包括如下几项，其中①~③为准备工作。①由于这种方式传送数据时要占用CPU中的寄存器，故首先需将寄存器原内容保护起来(若该寄存器中存有有用信息)。②由于传送往往是一批数据，因此需先设置I/O设备与主机交换数据的计数值。③设置欲传送数据在主存缓冲区的首地址。④CPU启动I/O设备。⑤将I/O接口中的设备状态标志取至CPU并测试I/O设备是否准备就绪。如果未准备就绪，则等待，直到准备就绪为止。当准备就绪时，接着可实现传送。对输入而言，准备就绪意味着接口电路中的数据缓冲寄存器已装满欲传送的数据，称为输入缓冲满，CPU即可取走数据；对输出而言，准备就绪意味着接口电路中的数据已被设备取走，故称为输出缓冲空，这样CPU可再次将数据送到接口，设备可再次从接口接收数据。⑥CPU执行I/O指令，或从I/O接口的数据缓冲寄存器中读出一个数据，或把一个数据写入I/O接口中的数据缓冲寄存器内，同时将接口中的状态标志复位。⑦修改主存地址。⑧修改计数值，若原设置计数值为原码，则依次减1；若原设置计数值为负数的补码，则依次加1(有关原码、补码的概念可参阅6.1节)。⑨判断计数值。若计数值不为0，表示一批数据尚未传送完，重新启动外设继续传送；若计数值为0，则表示一批数据已传送完毕。⑩结束I/O传送，继续执行现行程序。5由程序查询流程和5.3.2节所述的接口功能及组成，得出程序查询方式接口电路的基本组成,如图5.35所示。图中设备选择电路用以识别本设备地址，当地址线上的设备号与本设备号相符时，SEL有效，可以接收命令；数据缓冲寄存器用于存放欲传送的数据；D是完成触发器，B是工作触发器，其功能如5.3.2节所述。以输入设备为例，该接口的工作过程如下：①当CPU通过I/O指令启动输入设备时，指令的设备码字段通过地址线送至设备选择电路。②若该接口的设备码与地址线上的代码吻合，其输出SEL有效。③I/O指令的启动命令经过“与非”门将工作触发器B置“1”，将完成触发器D置“0”。④由B触发器启动设备工作。⑤输入设备将数据送至数据缓冲寄存器。⑥由设备发设备工作结束信号，将D置“1”，B置“0”，表示外设准备就绪。⑦D触发器以“准备就绪”状态通知CPU，表示“数据缓冲满”。⑧CPU执行输入指令，将数据缓冲寄存器中的数据送至CPU的通用寄存器，再存入主存相关单元。计算机在执行程序的过程中，当出现异常情况或特殊请求时，计算机停止现行程序的运行，转向对这些异常情况或特殊请求的处理，处理结束后再返回到现行程序的间断处，继续执行原程序，这就是“中断”(参见图5.10)。中断是现代计算机能有效合理地发挥效能和提高效率的一个十分重要的功能。通常又把实现这种功能所需的软硬件技术统称为中断技术。在I/O设备与主机交换信息时，由于设备本身机电特性的影响，其工作速度较低，与CPU无法匹配，因此，CPU启动设备后，往往需要等待一段时间才能实现主机与I/O设备之间的信息交换。如果在设备准备的同时，CPU不做无谓的等待，而继续执行现行程序，只有当I/O设备准备就绪向CPU提出请求后，再暂时中断CPU现行程序转入I/O服务程序，这便产生了I/O中断。图5.36所示为由打印机引起的I/O中断时，CPU与打印机并行工作的时间示意图。其实，计算机系统引入中断技术的原因不仅仅是为了适应I/O设备工作速度低的问题。例如，当计算机正在运行中，若出现突然掉电这种异常情况，将会导致CPU中的全部信息丢失。倘若能在突然掉电的瞬间立即启动另一个备份电源，并迅速进行一些必要的处理，例如，将有用信息送至不受电源影响的存储系统内，待电源恢复后接着使用，这种处理技术也要用中断技术来实现。又如，在实时控制领域中，要求CPU能即时响应外来信号的请求，并能完成相应的操作，也都要求采用中断技术。总之，为了提高计算机的整机效率，为了应付突发事件，为了实时控制的需要，在计算机技术的发展过程中产生了“中断”技术。为了实现“中断”，计算机系统中必须配有相应的中断系统或中断机构。本节着重介绍I/O中断处理的相关内容，有关中断的其他内容将在第8章中讲述。1为处理I/O中断，在I/O接口电路中必须配置相关的硬件线路。每台外部设备都必须配置一个中断请求触发器INTR，当其为“1”时，表示该设备向CPU提出中断请求。但是设备欲提出中断请求时，其设备本身必须准备就绪，即接口内的完成触发器D的状态必须为“1”。由于计算机应用的范围越来越广泛，向CPU提出中断请求的原因也越来越多，除了各种I/O设备外，还有其他许多突发性事件都是引起中断的因素，为此，把凡能向CPU提出中断请求的各种因素统称为中断源。当多个中断源向CPU提出中断请求时，CPU必须坚持一个原则，即在任何瞬间只能接受一个中断源的请求。所以，当多个中断源同时提出请求时，CPU必须对各中断源的请求进行排队，且只能接受级别最高的中断源的请求，不允许级别低的中断源中断正在运行的中断服务程序。这样，在I/O接口中需设置一个屏蔽触发器MASK，当其为“1”时，表示被屏蔽，即封锁其中断源的请求。可见中断请求触发器和中断屏蔽触发器在I/O接口中是成对出现的。有关屏蔽的详细内容将在8.4.6节中讲述。此外，CPU总是在统一的时间，即每条指令执行阶段的最后时刻，查询所有的设备是否有中断请求。如上所述，当多个中断源同时向CPU提出请求时，CPU只能按中断源的不同性质对其排队，给予不同等级的优先权，并按优先等级的高低予以响应。就I/O中断而言，速度越高的I/O设备，优先级越高，因为若CPU不及时响应高速I/O的请求，其信息可能会立即丢失。设备优先权的处理可以采用硬件方法，也可采用软件方法(详见8.4.2节)。硬件排队器的实现方法很多，既可在CPU内部设置一个统一的排队器，对所有中断源进行排队(详见图8.25)，也可在接口电路内分别设置各个设备的排队器，图5.38所示是设在各个接口电路中的排队器电路，又称为链式排队器。图5.38中下面的一排门电路是链式排队器的核心。每个接口中有一个反相器和一个“与非”门(如图中点画线框内所示)，它们之间犹如链条一样串接在一起，故称为链式排队器。该电路中级别最高的中断源是1号，其次是2号、3号、4号。不论是哪个中断源(一个或多个)提出中断请求，排队器输出端INTP；只有一个高电平。当各中断源均无中断请求时，各个\overline{INTR_{i}}为高电平，其INTP'_{1}、INTP'_{2}、INTP'_{3}\cdots均为高电平。一旦某个中断源提出中断请求时，就迫使比其优先级低的中断源INTP；变为低电平，封锁其发中断请求。例如，当2号和3号中断源同时有请求时经分析可知INTP'₁和INTP₂均为高电平,INTP'₃及往后各级的INTP;均为低电平。各个INTP;再经图中上面一排两个输入头的“与非”门，便可保证排队器只有INTP₂为高电平，表示2号中断源排队选中。CPU一旦响应了I/O中断，就要暂停现行程序，转去执行该设备的中断服务程序。不同的设备有不同的中断服务程序，每个服务程序都有一个入口地址，CPU必须找到这个入口地址。入口地址的寻找也可用硬件或软件的方法来完成，这里只介绍硬件向量法。所谓硬件向量法，就是通过向量地址来寻找设备的中断服务程序入口地址，而且向量地址是由硬件电路产生的,如图5.39所示。中断向量地址形成部件的输入是来自排队器的输出INTP_{1},INTP_{2},\cdots,INTP_{n},它的输出是中断向量(二进制代码表示)，其位数与计算机可以处理中断源的个数有关，即一个中断源对应一个向量地址。可见，该部件实质上是一个编码器。在I/O接口中的编码器又称为设备编码器。这里必须分清向量地址和中断服务程序的入口地址是两个不同的概念，图5.40是通过向量地址寻找入口地址的一种方案。其中12H、13H、14H是向量地址，200、300分别是打印机服务程序和显示器服务程序的入口地址。综合5.3.2节对一般接口电路的分析以及上述对实现程序中断方式所需增设硬件的介绍，以输入设备为例，程序中断方式接口电路的基本组成如图5.41所示。例5.2现有3个设备A、B、C，它们的优先级按降序排列。此3个设备的向量地址分别是001010、001011、001100。设计一个链式排队线路和产生3个向量地址的设备编码器。CPU响应I/O设备提出中断请求的条件是必须满足CPU中的允许中断触发器EINT为“1”。该触发器可用开中断指令置位(称为开中断)；也可用关中断指令或硬件自动使其复位(称为关中断)。由图5.37分析可知，I/O设备准备就绪的时间(即D=1)是随机的，而CPU是在统一的时刻(每条指令执行阶段结束前)向接口发中断查询信号，以获取I/O的中断请求。因此，CPU响应中断的时间一定是在每条指令执行阶段的结束时刻。下面以输入设备为例，结合图5.41，说明I/O中断处理的全过程。当CPU通过I/O指令的地址码选中某设备后，则①由CPU发启动I/O设备命令,将接口中的B置“1”,D置“0”。②接口启动输入设备开始工作。③输入设备将数据送入数据缓冲寄存器。④输入设备向接口发出“设备工作结束”信号，将D置“1”，B置“0”，标志设备准备就绪。⑤当设备准备就绪(D=1)，且本设备未被屏蔽(MASK=0)时，在指令执行阶段的结束时刻，由CPU发出中断查询信号。⑥设备中断请求触发器INTR被置“1”，标志设备向CPU提出中断请求。与此同时，INTR送至排队器，进行中断判优。⑦若CPU允许中断(EINT=1)，设备又被排队选中，即进入中断响应阶段，由中断响应信号INTA将排队器输出送至编码器形成向量地址。⑧向量地址送至PC，作为下一条指令的地址。⑨由于向量地址中存放的是一条无条件转移指令(参见图5.40)，故这条指令执行结束后，即无条件转至该设备的服务程序入口地址，开始执行中断服务程序，进入中断服务阶段，通过输入指令将数据缓冲寄存器的输入数据送至CPU的通用寄存器，再存入主存相关单元。⑩中断服务程序的最后一条指令是中断返回指令，当其执行结束时，即中断返回至原程序的断点处。至此，一个完整的程序中断处理过程即告结束。综上所述，可将一次中断处理过程简单地归纳为中断请求、中断判优、中断响应、中断服务和中断返回5个阶段。至于为什么能准确返回至原程序断点，CPU在中断响应阶段除了将向量地址送至PC外，还做了什么其他操作等问题，将在8.4节详细介绍。不同设备的服务程序是不相同的，可它们的程序流程又是类似的，一般中断服务程序的流程分四大部分：保护现场、中断服务、恢复现场和中断返回。保护现场有两个含义，其一是保存程序的断点；其二是保存通用寄存器和状态寄存器的内容。前者由中断隐指令完成(详见8.4.4节)，后者由中断服务程序完成。具体而言，可在中断服务程序的起始部分安排若干条存数指令，将寄存器的内容存至存储器中保存，或用进栈指令(PUSH)将各寄存器的内容推入堆栈保存，即将程序中断时的“现场”保存起来。这是中断服务程序的主体部分，对于不同的中断请求源，其中断服务操作内容是不同的，例如，打印机要求CPU将需打印的一行字符代码，通过接口送入打印机的缓冲存储器中(参见图5.23)以供打印机打印。又如，显示设备要求CPU将需显示的一屏字符代码通过接口送入显示器的显示存储器中(参见图5.18)。这是中断服务程序的结尾部分，要求在退出服务程序前，将原程序中断时的“现场”恢复到原来的寄存器中。通常可用取数指令或出栈指令(POP)，将保存在存储器(或堆栈)中的信息送回到原来的寄存器中。中断服务程序的最后一条指令通常是一条中断返回指令，使其返回到原程序的断点处，以便继续执行原程序。计算机在处理中断的过程中，有可能出现新的中断请求，此时如果CPU暂停现行的中断服务程序，转去处理新的中断请求，这种现象称为中断嵌套，或多重中断。倘若CPU在执行中断服务程序时，对新的中断请求不予理睬，这种中断称为单重中断。这两种处理方式的中断服务程序略有区别。图5.43(a)和图5.43(b)分别为单重中断和多重中断服务程序流程。比较图5.43(a)和图5.43(b)可以发现，其区别在于“开中断”的设置时间不同。CPU一旦响应了某中断源的中断请求后，便由硬件线路自动关中断，即中断允许触发器EINT被置“0”(详见图8.30)，以确保该中断服务程序的顺利执行。因此如果不用“开中断”指令将EINT置“1”，则意味着CPU不能再响应其他任何一个中断源的中断请求。对于单重中断，开中断指令设置在最后“中断返回”之前，意味着在整个中断服务处理过程中，不能再响应其他中断源的请求。对于多重中断，开中断指令提前至“保护现场”之后，意味着在保护现场后，若有级别更高的中断源提出请求(这是实现多重中断的必要条件)，CPU也可以响应，即再次中断现行的服务程序，转至新的中断服务程序，这是单重中断与多重中断的主要区别。有关多重中断的详细内容参见8.4.6节。综上所述，从宏观上分析，程序中断方式克服了程序查询方式中的CPU“踏步”现象，实现了CPU与I/O的并行工作，提高了CPU的资源利用率。但从微观操作分析，发现CPU在处理中断服务程序时仍需暂停原程序的正常运行，尤其是当高速I/O设备或辅助存储器频繁地、成批地与主存交换信息时，需不断地打断CPU执行主程序而执行中断服务程序。图5.44是主程序和服务程序抢占CPU的示意图。为此，人们探索出使CPU效率更高的DMA控制方式。图5.45示意了DMA方式与程序中断方式的数据通路。由图中可见，由于主存和DMA接口之间有一条数据通路，因此主存和设备交换信息时，不通过CPU，也不需要CPU暂停现行程序为设备服务，省去了保护现场和恢复现场，因此工作速度比程序中断方式的工作速度高。这一特点特别适合于高速I/O或辅存与主存之间的信息交换。因为高速I/O设备若每次申请与主机交换信息时，都要等待CPU做出中断响应后再进行，很可能因此使数据丢失。值得注意的是，若出现高速I/O(通过DMA接口)和CPU同时访问主存，CPU必须将总线(如地址线、数据线)占有权让给DMA接口使用，即DMA采用周期窃取的方式占用一个存取周期。在DMA方式中，由于DMA接口与CPU共享主存，这就有可能出现两者争用主存的冲突。为了有效地分时使用主存，通常DMA与主存交换数据时采用如下三种方法。(1)停止CPU访问主存当外设要求传送一批数据时，由DMA接口向CPU发一个停止信号，要求CPU放弃地址线、数据线和有关控制线的使用权。DMA接口获得总线控制权后，开始进行数据传送，在数据传送结束后，DMA接口通知CPU可以使用主存，并把总线控制权交回给CPU，图5.46(a)是该方式的时间示意图。这种方式的优点是控制简单，适用于数据传输率很高的I/O设备实现成组数据的传送。缺点是DMA接口在访问主存时，CPU基本上处于不工作状态或保持原状态。而且即使I/O设备高速运行，两个数据之间的准备间隔时间也总大于一个存取周期，因此，CPU对主存的利用率并没得到充分的发挥。如软盘读一个8位二进制数大约需要32μs，而半导体存储器的存取周期远小于1μs，可见在软盘准备数据的时间内，主存处于空闲状态，而CPU又暂停访问主存。为此在DMA接口中，一般设有一个小容量存储器(这种存储器是用半导体芯片制作的)，使I/O设备首先与小容量存储器交换数据，然后由小容量存储器与主存交换数据，这便可减少DMA传送数据时占用总线的时间，即可减少CPU的暂停工作时间。(2)周期挪用(或周期窃取)在这种方法中，每当I/O设备发出DMA请求时，I/O设备便挪用或窃取总线占用权一个或几个主存周期，而DMA不请求时，CPU仍继续访问主存。I/O设备请求DMA传送会遇到三种情况。一种是CPU此时不需要访问主存(如CPU正在202第2篇计算机系统的硬件结构执行乘法指令，由于乘法指令执行时间较长，此时CPU不需要访问主存)，故I/O设备与CPU不发生冲突。第二种情况是I/O设备请求DMA传送时，CPU正在访问主存，此时必须待存取周期结束，CPU才能将总线占有权让出。第三种情况是I/O设备要求访问主存时，CPU也要求访问主存，这就出现了访问冲突。此刻，I/O访存优先于CPU访问主存，因为I/O不立即访问主存就可能丢失数据，这时I/O要窃取一两个存取周期，意味着CPU在执行访问主存指令过程中插入了DMA请求，并挪用了一两个存取周期，使CPU延缓了一两个存取周期再访问主存。图5.46(b)示意了DMA周期挪用的时间对应关系。与CPU暂停访存的方式相比，这种方式既实现了I/O传送，又较好地发挥了主存与CPU的效率，是一种广泛采用的方法。应该指出，I/O设备每挪用一个主存周期都要申请总线控制权、建立总线控制权和归还总线控制权。因此，尽管传送一个字对主存而言只占用一个主存周期，但对DMA接口而言，实质上要占2~5个主存周期(由逻辑线路的延迟特性而定)。因此周期挪用的方法比较适合于I/O设备的读/写周期大于主存周期的情况。(3)DMA与CPU交替访问这种方法适合于CPU的工作周期比主存存取周期长的情况。例如，CPU的工作周期为1.2μs，主存的存取周期小于0.6μs，那么可将一个CPU周期分为C₁和C₂两个分周期，其中C₁专供DMA访存,C₂专供CPU访存,如图5.46(c)所示。这种方式不需要总线使用权的申请、建立和归还过程，总线使用权是通过C₁和C₂分别控制的。CPU与DMA接口各自有独立的访存地址寄存器、数据寄存器和读/写信号。实际上总线变成了在C₁和C₂控制下的多路转换器，其总线控制权的转移几乎不需要什么时间，具有很高的DMA传送速率。在这种工作方式下，CPU既不停止主程序的运行也不进入等待状态，即完成了DMA的数据传送。当然其相应的硬件逻辑变得更为复杂。利用DMA方式传送数据时，数据的传输过程完全由DMA接口电路控制，故DMA接口又有DMA控制器之称。DMA接口应具有如下几个功能。①向CPU申请DMA传送。②在CPU允许DMA工作时，处理总线控制权的转交，避免因进入DMA工作而影响CPU正常活动或引起总线竞争。③在DMA期间管理系统总线，控制数据传送。④确定数据传送的起始地址和数据长度，修正数据传送过程中的数据地址和数据长度。⑤在数据块传送结束时，给出DMA操作完成的信号。最简单的DMA接口组成原理如图5.47所示，它由以下几个逻辑部件组成。(1)主存地址寄存器(AR)AR用于存放主存中需要交换数据的地址。在DMA传送数据前，必须通过程序将数据在主存中的首地址送到主存地址寄存器。在DMA传送过程中，每交换一次数据，将地址寄存器内容加1，直到一批数据传送完毕为止。(2)字计数器(WC)WC用于记录传送数据的总字数，通常以交换字数的补码值预置。在DMA传送过程中，每传送一个字，字计数器加1，直到计数器为0，即最高位产生进位时，表示该批数据传送完毕(若交换字数以原码值预置，则每传送一个字，字计数器减1，直到计数器为0时，表示该批数据传送结束)。于是DMA接口向CPU发中断请求信号。(3)数据缓冲寄存器(BR)BR用于暂存每次传送的数据。通常DMA接口与主存之间采用字传送，而DMA与设备之间可能是字节或位传送。因此DMA接口中还可能包括有装配或拆卸字信息的硬件逻辑，如数据移位缓冲寄存器、字节计数器等。(4)DMA控制逻辑DMA控制逻辑负责管理DMA的传送过程，由控制电路、时序电路及命令状态控制寄存器等组成。每当设备准备好一个数据字(或一个字传送结束)，就向DMA接口提出申请(DREQ)，DMA控制逻辑便向CPU请求DMA服务，发出总线使用权的请求信号(HRQ)。待收到CPU发出的响应信号HLDA后，DMA控制逻辑便开始负责管理DMA传送的全过程，包括对主存地址寄存器和字计数器的修改、识别总线地址、指定传送类型(输入或输出)以及通知设备已经被授予一个DMA周期(DACK)等。(5)中断机构当字计数器溢出(全“0”)时，表示一批数据交换完毕，由“溢出信号”通过中断机构向CPU提出中断请求，请求CPU作DMA操作的后处理。必须注意，这里的中断与5.5节介绍的I/O中断的技术相同，但中断的目的不同，前面是为了数据的输入或输出，而这里是为了报告一批数据传送结束。它们是I/O系统中不同的中断事件。(6)设备地址寄存器(DAR)DAR存放I/O设备的设备码或表示设备信息存储区的寻址信息，如磁盘数据所在的区号、盘面号和柱面号。具体内容取决于设备的数据格式和地址的编址方式。DMA的数据传送过程分为预处理、数据传送和后处理3个阶段。(1)预处理在DMA接口开始工作之前，CPU必须给它预置如下信息。·给DMA控制逻辑指明数据传送方向是输入(写主存)还是输出(读主存)。·向DMA设备地址寄存器送入设备号，并启动设备。·向DMA主存地址寄存器送入交换数据的主存起始地址。●对字计数器赋予交换数据的个数。上述工作由CPU执行几条输入输出指令完成，即程序的初始化阶段。这些工作完成后，CPU继续执行原来的程序,如图5.48(a)所示。当I/O设备准备好发送的数据(输入)或上次接收的数据已经处理完毕(输出)时，它便通过DMA接口向CPU提出占用总线的申请，若有多个DMA同时申请，则按轻重缓急由硬件排队判优逻辑决定优先等。待I/O设备得到主存总线的控制权后，数据的传送便由该DMA接口进行管理。(2)数据传送DMA方式是以数据块为单位传送的，以周期挪用的DMA方式为例，其数据传送的流程如图5.48(b)所示。结合图5.47，以数据输入为例，具体操作如下。①当设备准备好一个字时，发出选通信号，将该字读到DMA的数据缓冲寄存器(BR)中，表示数据缓冲寄存器“满”(如果I/O设备是面向字符的，则一次读入一个字节，组装成一个字)。②与此同时设备向DMA接口发请求(DREQ)。③DMA接口向CPU申请总线控制权(HRQ)。④CPU发回HLDA信号，表示允许将总线控制权交给DMA接口。⑤将DMA主存地址寄存器中的主存地址送地址总线，并命令存储器写。⑥通知设备已被授予一个DMA周期(DACK)，并为交换下一个字做准备。⑦将DMA数据缓冲寄存器的内容送数据总线。⑧主存将数据总线上的信息写至地址总线指定的存储单元中。⑨修改主存地址和字计数值。⑩判断数据块是否传送结束，若未结束，则继续传送；若已结束，(字计数器溢出)，则向CPU申请程序中断，标志数据块传送结束。若为输出数据，则应完成以下操作：①当DMA数据缓冲寄存器已将输出数据送至I/O设备后，表示数据缓冲寄存器已“空”。②设备向DMA接口发请求(DREQ)。③DMA接口向CPU申请总线控制权(HRQ)。④CPU发回HLDA信号，表示允许将总线控制权交给DMA接口使用。⑤将DMA主存地址寄存器中的主存地址送地址总线，并命令存储器读。⑥通知设备已被授予一个DMA周期(DACK)，并为交换下一个字做准备。⑦主存将相应地址单元的内容通过数据总线读入DMA的数据缓冲寄存器中。⑧将DMA数据缓冲寄存器的内容送到输出设备，若为字符设备，则需将其拆成字符输出。⑨修改主存地址和字计数值。⑩判断数据块是否已传送完毕，若未完毕，继续传送；若已传送完毕，则向CPU申请程序中断。(3)后处理当DMA的中断请求得到响应后，CPU停止原程序的执行，转去执行中断服务程序，做一些DMA的结束工作，如图5.48(a)的后处理部分。这包括校验送入主存的数据是否正确；决定是否继续用DMA传送其他数据块，若继续传送，则又要对DMA接口进行初始化，若不需要传送，则停止外设；测试在传送过程中是否发生错误，若出错，则转错误诊断及处理错误程序。DMA接口与系统的连接方式有两种，如图5.49所示。图5.49(a)为具有公共请求线的DMA请求方式，若干个DMA接口通过一条公用的DMA请求线向CPU申请总线控制权。CPU发出响应信号，用链式查询方式通过DMA接口，首先选中的设备获得总线控制权，即可占用总线与主存传送信息。208第2篇计算机系统的硬件结构图5.49(b)是独立的DMA请求方式，每一个DMA接口各有一对独立的DMA请求线和DMA响应线，它由CPU的优先级判别机构裁决首先响应哪个请求，并在响应线上发出响应信号，被获得响应信号的DMA接口便可控制总线与主存传送数据。与程序中断方式相比，DMA方式有如下特点。①从数据传送看，程序中断方式靠程序传送，DMA方式靠硬件传送。②从CPU响应时间看，程序中断方式是在一条指令执行结束时响应，而DMA方式可在指令周期内的任一存取周期结束时响应。③程序中断方式有处理异常事件的能力，DMA方式没有这种能力，主要用于大批数据的传送，如硬盘存取、图像处理、高速数据采集系统等，可提高数据吞吐量。④程序中断方式需要中断现行程序，故需保护现场；DMA方式不中断现行程序，无须保护现场。⑤DMA的优先级比程序中断的优先级高。现代集成电路制造技术已将DMA接口制成芯片，通常有选择型和多路型两类。这种类型的DMA接口的基本组成如图5.47所示，它的主要特点是在物理上可连接多个设备，在逻辑上只允许连接一个设备，即在某一段时间内，DMA接口只能为一个设备服务，关键是在预处理时将所选设备的设备号送入设备地址寄存器。图5.50是选择型DMA接口的逻辑框图。选择型DMA接口特别适用于数据传输率很高的设备。多路型DMA接口不仅在物理上可以连接多个设备，而且在逻辑上也允许多个设备同时工作，各个设备采用字节交叉的方式通过DMA接口进行数据传送。在多路型DMA接口中，为每个与它连接的设备都设置了一套寄存器，分别存放各自的传送参数。图5.51(a)和(b)分别是链式多路型DMA接口和独立请求多路型DMA接口的逻辑框图。这类接口特别适合于同时为多个数据传输率不十分高的设备服务。图5.52是多路型DMA接口工作原理示意图。图中磁盘、磁带、打印机同时工作。磁盘、磁带、打印机分别每隔30μs、45μs、150μs向DMA接口发DMA请求,磁盘的优先级高于磁带,磁带的优先级高于打印机。假设DMA接口完成一次DMA数据传送需5μs，由图5.52可见，打印机首先发请求，故DMA接口首先为打印机服务(T₁)；接着磁盘、磁带同时又有DMA请求，DMA接口按优先级别先响应磁盘请求(T₂)，再响应磁带请求(T₃)，每次DMA传送都是一个字节。这样，在90多微秒的时间里，DMA接口为打印机服务一次(T₁)，为磁盘服务4次((T₂、T₄、T₆、T₇),为磁带服务3次(T₃、T₅、T₈)。可见DMA接口还有很多空闲时间，可再容纳更多的设备。以上各章节基本上把CPU看作一个“黑匣子”，并且分析了它通过总线与存储器和I/O部件之间的相互关系。本篇将剖析其内部结构，讲述CPU的功能，包括计算机的运算、指令系统、指令流水、时序系统、中断系统及控制单元。除时序系统和控制单元将在第4篇单独讲述外，其余部分均在此篇介绍。计算机的应用领域极其广泛，但不论其应用在什么地方，信息在机器内部的形式都是一致的，即均为0和1组成的各种编码。本章主要介绍参与运算的各类数据(包括无符号数和有符号数、定点数和浮点数等)，以及它们在计算机中的算术运算方法。使读者进一步认识到计算机在自动解题过程中数据信息的加工处理流程，从而进一步加深对计算机硬件组成及整机工作原理的理解。有关逻辑运算以及计算机中采用的各种进位制均在前修课中介绍过，本章只在附录中给出了各种进位制及其相互转换的关系(可参阅附录6A)。至于计算机中的字符编码以及校验码,读者可分别参阅本书附录5A、附录5B、附录5C、4.2.6节和4.4.6节等。在计算机中参与运算的数有两大类：无符号数和有符号数。计算机中的数均放在寄存器中，通常称寄存器的位数为机器字长。所谓无符号数，即没有符号的数，在寄存器中的每一位均可用来存放数值。当存放有符号数时，则需留出位置存放符号。因此，在机器字长相同时，无符号数与有符号数所对应的数值范围是不同的。以机器字长为16位为例，无符号数的表示范围为0~65535，而有符号数的表示范围为-32768~+32767(此数值对应补码表示，详见6.1.2节)。对有符号数而言，符号的“正”“负”机器是无法识别的，但由于“正”“负”恰好是两种截然不同的状态，如果用“0”表示“正”，用“1”表示“负”，这样符号也被数字化了，并且规定将它放在有效数字的前面，即组成了有符号数。把符号“数字化”的数称为机器数，而把带“+”或“-”符号的数称为真值。一旦符号数字化后，符号和数值就形成了一种新的编码。在运算过程中，符号位能否和数值部分一起参加运算?如果参加运算，符号位又需作哪些处理?这些问题都与符号位和数值位所构成的编码有关，这些编码就是原码、补码、反码和移码。原码是机器数中最简单的一种表示形式，符号位为0表示正数，符号位为1表示负数，数值位即真值的绝对值，故原码表示又称为带符号的绝对值表示。上面列举的4个真值所对应的机器数即为原码。为了书写方便以及区别整数和小数，约定整数的符号位与数值位之间用逗号隔开；小数的符号位与数值位之间用小数点隔开。例如，上面4个数的原码分别是0.1011、1.1011、0,1100和1,1100。由此可得原码的定义。整数原码的定义为式中，x为真值，n为整数的位数。例如：当x=+1110时,[x]原=0,1110当x=-1110时,[x]_{底}=2^{4}-(-1110)=1,1110←用逗号将符号位和数值部分隔开小数原码的定义为式中，x为真值。例如：当x=0.1101时,[x]_{阴}=0.1101当x=-0.1101时,[x]原=1-(-0.1101)=1.1101根据定义，已知真值可求原码，反之已知原码也可求真值。例如：当[x]_{吸}=1.0011时，由定义得x=1-[x]_{底}=1-1.0011=-0.0011当[x]原=1,1100时，由定义得x=2"-[x]原=2⁴-1,1100=10000-11100=-1100当[x]_{稀}=0.1101时,x=0.1101当x=0时[+0.0000]_{底}=0.0000[-0.0000]_{吸}=1-(0.0000)=1.0000可见[+0]原不等于[-0]原，即原码中的“零”有两种表示形式。原码表示简单明了，并易于和真值转换。但用原码进行加减运算时，却带来了许多麻烦。例如，当两个操作数符号不同且要做加法运算时，先要判断两数绝对值大小，然后将绝对值大的数减去绝对值小的数，结果的符号以绝对值大的数为准。运算步骤既复杂又费时，而且本来是加法运算却要用减法器实现。那么能否在计算机中只设加法器，只做加法操作呢?如果能找到一个与负数等价的正数来代替该负数，就可把减法操作用加法代替。而机器数采用补码时，就能满足此要求。(1)补数的概念在日常生活中，常会遇到“补数”的概念。例如，时钟指示6点，欲使它指示3点，既可按顺时针方向将分针转9圈，又可按逆时针方向将分针转3圈，结果是一致的。假设顺时针方向转为正，逆时针方向转为负，则有\begin{array}{r}6\underline{-3}3\end{array}由于时钟的时针转一圈能指示12个小时，这“12”在时钟里是不被显示而自动丢失的，即15-12=3，故15点和3点均显示3点。这样-3和+9对时钟而言其作用是一致的。在数学上称12为模,写作mod12,而称+9是-3以12为模的补数,记作-3=+9(mod12)或者说，对模12而言，-3和+9是互为补数的。同理有-4≡+8(mod12)-5=+7(mod12)即对模12而言，+8和+7分别是-4和-5的补数。可见，只要确定了“模”，就可找到一个与负数等价的正数(该正数即为负数的补数)来代替此负数，这样就可把减法运算用加法实现。例如：设A=9,B=5,求A-B(mod12)。解:A-B=9-5=4(作减法)对模12而言，-5可以用其补数+7代替，即-5=+7(mod12)所以A-B=9+7=16(作加法)对模12而言,12会自动丢失,所以16等价于4,即4≡16(mod12)。进一步分析发现，3点、15点、27点……在时钟上看见的都是3点，即3=15=27(mod12)也即3=3+12=3+24=3(mod12)这说明正数相对于“模”的补数就是正数本身。上述补数的概念可以用到任意“模”上，如-3=+7(mod10)+7=+7(mod10)-3=+97(mod10²)+97≡+97(mod10²)-1011≡+0101(mod2⁴)+0101≡+0101(mod2⁴)-0.1001=+1.0111(mod2)+0.1001≡+0.1001(mod2)由此可得如下结论。●一个负数可用它的正补数来代替，而这个正补数可以用模加上负数本身求得。·一个正数和一个负数互为补数时，它们绝对值之和即为模数。·正数的补数即该正数本身。将补数的概念用到计算机中，便出现了补码这种机器数。(2)补码的定义整数补码的定义为式中，x为真值，n为整数的位数。例如：当x=+1010时,[x]_{外}=0,1010↑用逗号将符号位和数值部分隔开当x=-1101时,[x]_{外}=2^{n+1}+x=100000-110l=1,0011用逗号将符号位和数值部分隔开小数补码的定义为[x]_{外}=\begin{cases}x&1>x\ge0\cr2+x&0>x\ge-1\end{cases}(mod2)式中，x为真值。例如：当x=0.1001时,[x]_{水}=0.1001当x=-0.0110时,[x]₂ₖ=2+x=10.0000-0.0110=1.1010当x=0时,[+0.0000]₊=0.0000[-0.0000]_{\#}=2+(-0.0000)=10.0000-0.0000=0.000(、显然[+0]_{浓}=[-0]_{外}=0.0000,即补码中的“零”只有一种表示形式。对于小数，若x=-1，则根据小数补码定义，有[x]_{外}=2+x=10.0000-1.0000=1.0000。可见，-1本不属于小数范围，但却有|[-1]补存在(其实在小数补码定义中已指明)，这是由于补码中的零只有一种表示形式，故它比原码能多表示一个“-1”。此外，根据补码定义，已知补码还可以求真值，例如：若[x]_{\#}=1.0101则x=[x]_{\#}-2=1.0101-10.0000=-0.1011若[x]_{外}=1,1110则x=[x]_{\#}-2^{4+1}=1,1110-100000=-0010若[x]_{差}=0.1101则x=[x]_{外}=0.1101同理，当模数为4时，形成了双符号位的补码。如：x=-0.1001,对(mod2²)而言[x]_{\#}=2^{2}+x=100.0000-0.1001=11.0111这种双符号位的补码又称为变形补码，它在阶码运算和溢出判断中有其特殊作用，后面有关章节中将详细介绍。由上讨论可知，引入补码的概念是为了消除减法运算，但是根据补码的定义，在形成补码的过程中又出现了减法。例如：x=-1011[x]_{水}=2^{4+1}+x=100000-1011=1,0101(6.1)若把模2⁴⁺¹改写成2⁵=100000=11111+00001时,则式(6.1)可写成[x]ₐₕ=2⁵+x=11111+00001+x(6.2)又因x是负数，若x用-x₁x₂x₃x₄表示，其中xᵢ(i=1,2,3,4)不为0则为1,于是式(6.2)可写成[x]_{浓}=2^{5}+x=11111+00001-x_{1}x_{2}x_{3}x_{4}=1\overline{x}_{1}\overline{x}_{2}\overline{x}_{3}\overline{x}_{4}+00001(6.3)因为任一位“1”减去x₁即为x₁,所以式(6.3)成立。由于负数-x₁x₂x₃x₄的原码为1，x₁x₂x₃x₄，因此对这个负数求补，可以看作对它的原码除符号位外，每位求反，末位加1，简称“求反加1”。这样，由真值通过原码求补码就可避免减法运算。同理，对于小数也有同样的结论，读者可以自行证明。“由原码除符号位外，每位求反，末位加1求补码”这一规则同样适用于由[x]₂求[x]_{底}。而对于一个负数，若对其原码除符号位外，每位求反(简称“每位求反”)，或是对其补码减去末位的1，即得机器数的反码。反码通常用来作为由原码求补码或者由补码求原码的中间过渡。反码的定义如下：整数反码的定义为式中，x为真值，n为整数的位数。例如：当x=+1101时,[x]反=0,1101↑用逗号将符号位和数值部分隔开当x=-1101时,[x]_{E}=(2^{4+1}-1)+x=11111-1101=1,0010用逗号将符号位和数值部分隔开小数反码的定义为[x]_{\barz}=\begin{cases}x&1>x\ge0\cr(2-2^{-n})+x&0\gex>-1\end{cases}(mod(2-2^{-n}))式中，x为真值，n为小数的位数。例如：当x=+0.0110时,[x]_{底}=0.0110当x=-0.0110时,x]_{\Xi}=(2-2^{-4})+x=1.1111-0.0110=1.100]当x=0时,[+0.0000]反=0.0000[-0.0000]反=(10.0000-0.0001)-0.0000=1.1111可见[+0]反不等于[-0]反，即反码中的“零”也有两种表示形式。实际上，反码也可看作是mod(2-2⁻ⁿ)(对于小数)或mod(2ⁿ⁺¹-1)(对于整数)的补码。与补码相比，仅在末位差1，因此有些书上称小数的补码为2的补码，而称小数的反码为1的补码。综上所述，三种机器数的特点可归纳如下：●三种机器数的最高位均为符号位。符号位和数值部分之间可用“.”(对于小数)或“，”(对于整数)隔开。·当真值为正时，原码、补码和反码的表示形式均相同，即符号位用“0”表示，数值部分与真值相同。●当真值为负时，原码、补码和反码的表示形式不同，但其符号位都用“1”表示，而数值部分有这样的关系，即补码是原码的“求反加1”，反码是原码的“每位求反”。下面通过实例来进一步理解和掌握三种机器数的表示。例6.1设机器数字长为8位(其中1位为符号位)，对于整数，当其分别代表无符号数、原码、补码和反码时，对应的真值范围各为多少?解：表6.1列出了8位寄存器中所有二进制代码组合与无符号数、原码、补码和反码所代表的真值的对应关系。由此可得出一个结论：由于“零”在补码中只有一种表示形式，故补码比原码和反码可以多表示一个负数。可见，不论真值是正(第一种情况)或负(第二种情况)，由[y]补求[[-y]_{和}都是采用“连同符号位在内，每位取反，末位加1”的规则。这一结论在补码减法运算时将经常用到(详见6.3节有关内容)。有符号数在计算机中除了用原码、补码和反码表示外，在一些通用计算机中还用另一种机器数——移码表示，由于一些突出的优点，目前它已被广泛采用。当真值用补码表示时，由于符号位和数值部分一起编码，与习惯上的表示法不同，因此人们很难从补码的形式上直接判断其真值的大小，例如：十进制数x=21,对应的二进制数为+10101,则[x]_{外}=0,10101十进制数x=-21,对应的二进制数为-10101,则[x]补=1,01011十进制数x=31,对应的二进制数为+11111,则[x]_{外}=0,11111十进制数x=-31,对应的二进制数为-11111,则[x]补=1,00001上述补码表示中的“，”在计算机内部是不存在的，因此，从代码形式看，符号位也是一位二进制数。按这6位二进制代码比较大小的话,会得出101011>010101,100001>011111,其实恰恰相反。如果对每个真值加上一个2"(n为整数的位数)，情况就发生了变化。例如：x=10101加上2⁵可得10101+100000=110101x=-10101加上2⁵可得-10101+100000=001011x=11111加上2⁵可得11111+100000=111111x=-11111加上2⁵可得-11111+100000=000001比较它们的结果可见，1110101>001011,11111>000001。。这样一来，从6位代码本身就可看出真值的实际大小。由此可得移码的定义[x]ᵤ=2ⁿ+x(2ⁿ>x≥-2ⁿ)式中，x为真值，n为整数的位数。其实移码就是在真值上加一个常数2"。在数轴上移码所表示的范围恰好对应于真值在数轴上的范围向轴的正方向移动2"个单元，如图6.1所示，由此而得移码之称。可见[+0]移等于[-0]移，即移码表示中零也是唯一的。此外，由移码的定义可见，当n=5时，其最小的真值为x=-2⁵=-100000,则[-100000]_{\#}=2^{5}+x=100000-100000=0,00000即最小真值的移码为全0，这符合人们的习惯。利用移码的这一特点，当浮点数的阶码用移码表示时，就能很方便地判断阶码的大小(详见6.2.4节)。进一步观察发现，同一个真值的移码和补码仅差一个符号位，若将补码的符号位由“0”改为“1”，或从“1”改为“0”，即可得该真值的移码。表6.2列出了真值、补码和移码的对应关系。在计算机中，小数点不用专门的器件表示，而是按约定的方式标出，共有两种方法表示小数点的存在，即定点表示和浮点表示。定点表示的数称为定点数，浮点表示的数称为浮点数。小数点固定在某一位置的数为定点数，有以下两种格式。当小数点位于数符和第一数值位之间时，机器内的数为纯小数；当小数点位于数值位之后时，机器内的数为纯整数。采用定点数的机器称为定点机。数值部分的位数n决定了定点机中数的表示范围。若机器数采用原码，小数定点机中数的表示范围是-(1-2⁻ⁿ)∼(1-2⁻ⁿ),整数定点机中数的表示范围是-(2ⁿ-1)∼(2ⁿ-1)。在定点机中，由于小数点的位置固定不变，故当机器处理的数不是纯小数或纯整数时，必须乘上一个比例因子，否则会产生“溢出”。实际上计算机中处理的数不一定是纯小数或纯整数(如圆周率3.1416)，而且有些数据的数值范围相差很大(如电子的质量9×10⁻²⁸g,太阳的质量2×10³³g),它们都不能直接用定点小数或定点整数表示，但均可用浮点数表示。浮点数即小数点的位置可以浮动的数，如352.47=3.5247×10²=3524.7×10⁻¹=0.35247×10³显然，这里小数点的位置是变化的，但因为分别乘上了不同的10的方幂，故值不变。通常，浮点数被表示成N=S×rʲ式中，S为尾数(可正可负)，j为阶码(可正可负)，r是基数(或基值)。在计算机中，基数可取2，4、8或16等。以基数r=2为例，数N可写成下列不同的形式：N=11.0101=0.110101×2¹⁰=1.10101×2¹=1101.01×2⁻¹⁰=0.00110101×2¹⁰⁰⋮为了提高数据精度以及便于浮点数的比较，在计算机中规定浮点数的尾数用纯小数形式，故上例中0.110101×2¹⁰和(0.00110101×2¹⁰⁰形式是可以采用的。此外，将尾数最高位为1的浮点数称为规格化数，即.N=0.110101×2¹⁰为浮点数的规格化形式。浮点数表示成规格化形式后，其精度最高。1.浮点数的表示形式浮点数在机器中的形式如下所示。采用这种数据格式的机器称为浮点机。浮点数由阶码j和尾数S两部分组成。阶码是整数，阶符和阶码的位数m合起来反映浮点数的表示范围及小数点的实际位置；尾数是小数，其位数n反映了浮点数的精度；尾数的符号(S₁代表浮点数的正负。以通式N=S×rʲ为例，设浮点数阶码的数值位取m位，尾数的数值位取n位，当浮点数为非规格化数时，它在数轴上的表示范围如图6.2所示。下溢正数区负数区上溢上溢02^{(2^{m}-1)}\times(1-2^{-n})-2^{(2^{m}-1)}\times(1-2^{-n})-2^{-(2^{m}-1)}\times2^{-n}2^{-(2^{m}-1)}\times2^{-n}图6.2浮点数在数轴上的表示范围由图中可见，其最大正数为2^{(2^{n}-1)}\times(1-2^{-n});最小正数为2⁻⁽²ᵐ⁻¹⁾×2⁻ⁿ;最大负数为-2⁻⁽²ᵐ⁻¹⁾×2⁻ⁿ;最小负数为当浮点数阶码大于最大阶码时，称为上溢，此时机器停止运算，进行中断溢出处理；当浮点数阶码小于最小阶码时，称为下溢，此时溢出的数绝对值很小，通常将尾数各位强置为零，按机器零处理，此时机器可以继续运行。一旦浮点数的位数确定后，合理分配阶码和尾数的位数，直接影响浮点数的表示范围和精度。通常对于短实数(总位数为32位)，阶码取8位(含阶符1位)，尾数取24位(含数符1位)；对于长实数(总位数为64位)，阶码取11位(含阶符1位)，尾数取53位(含数符1位)；对于临时实数(总位数为80位)，阶码取15位(含阶符1位)，尾数取65位(含数符1位)。为了提高浮点数的精度，其尾数必须为规格化数。如果不是规格化数，就要通过修改阶码并同时左右移尾数的办法，使其变成规格化数。将非规格化数转换成规格化数的过程称为规格化。对于基数不同的浮点数，因其规格化数的形式不同，规格化过程也不同。当基数为2时，尾数最高位为1的数为规格化数。规格化时，尾数左移一位，阶码减1(这种规格化称为向左规格化，简称左规)；尾数右移一位，阶码加1(这种规格化称为向右规格化，简称右规)。图6.2所示的浮点数规格化后，其最大正数为2^{(2^{m}-1)}\times(1-2^{-n}),最小正数为2^{-(2^{m}-1)}\times2^{-1};最大负数为-2^{-(2^{m}-1)}\times2^{-1},最小负数为-2^{(2^{n}-1)}\times(1-2^{-n})。当基数为4时，尾数的最高两位不全为零的数为规格化数。规格化时，尾数左移两位，阶码减1；尾数右移两位，阶码加1。当基数为8时，尾数的最高三位不全为零的数为规格化数。规格化时，尾数左移三位，阶码减1；尾数右移三位，阶码加1。同理类推，不难得到基数为16或2"时的规格化过程。浮点机中一旦基数确定后就不再变了，而且基数是隐含的，故不同基数的浮点数表示形式完全相同。但基数不同，对数的表示范围和精度等都有影响。一般来说，基数r越大，可表示的浮点数范围越大，而且所表示的数的个数越多。但r越大，浮点数的精度反而下降。如r=16的浮点数，因其规格化数的尾数最高三位可能出现零，故与其尾数位数相同的r=2的浮点数相比，后者可能比前者多三位精度。定点数和浮点数可从如下几个方面进行比较。①当浮点机和定点机中数的位数相同时，浮点数的表示范围比定点数的大得多。②当浮点数为规格化数时，其相对精度远比定点数高。③浮点数运算要分阶码部分和尾数部分，而且运算结果都要求规格化，故浮点运算步骤比定点运算步骤多，运算速度比定点运算的低，运算线路比定点运算的复杂。④在溢出的判断方法上，浮点数是对规格化数的阶码进行判断，而定点数是对数值本身进行判断。例如，小数定点机中的数，其绝对值必须小于1，否则“溢出”，此时要求机器停止运算，进行处理。为了防止溢出，上机前必须选择比例因子，这个工作比较麻烦，给编程带来不便。而浮点数的表示范围远比定点数大，仅当“上溢”时机器才停止运算，故一般不必考虑比例因子的选择。总之，浮点数在数的表示范围、数的精度、溢出处理和程序编程方面(不取比例因子)均优于定点数。但在运算规则、运算速度及硬件成本方面又不如定点数。因此，究竟选用定点数还是浮点数，应根据具体应用综合考虑。一般来说，通用的大型计算机大多采用浮点数，或同时采用定、浮点数；小型、微型及某些专用机、控制机则大多采用定点数。当需要做浮点运算时，可通过软件实现，也可外加浮点扩展硬件(如协处理器)来实现。例6.3设浮点数字长16位，其中阶码5位(含1位阶符)，尾数11位(含1位数符)，将十进制数+\frac{13}{128}写成二进制定点数和浮点数，并分别写出它在定点机和浮点机中的机器数形式。解：令x=+\frac{13}{128}其二进制形式x=0.0001101000定点数表示x=0.0001101000浮点数规格化表示x=0.110100000×2⁻¹¹定点机中[x]_{底}=[x]_{外}=[x]_{\bar{z}}=0.0001101000浮点机中[x]原:1001101101000000或写成1,0011;0.1101000000[x]补:1110101101000000或写成1,1101;0.1101000000[x]反:1110001101000000或写成1,1100;0.1101000000例6.4将十进制数-54表示成二进制定点数和浮点数，并写出它在定点机和浮点机中的机器数形式(其他要求同上例)。解:令x=-54其二进制形式x=-110110定点数表示x=-0000110110浮点数规格化表示x=-(0.1101100000)×2¹¹⁰定点机中[x]原=1,0000110110[x]补=1,1111001010[x]反=1,1111001001浮点机中[x]原=0,0110;1.1101100000[x]补=0,0110;1.0010100000[x]反=0,0110;1.0010011111例6.5写出对应图6.2所示的浮点数的补码形式。设图中n=10，m=4，阶符、数符各取1位。解:真值补码最大正数2¹⁵×(1-2⁻¹⁰)0,1111;0.1111111111最小正数2⁻¹⁵×2⁻¹⁰1,0001;0.0000000001最大负数-2⁻¹⁵×2⁻¹⁰1,0001;1.1111111111最小负数-2¹⁵×(1-2⁻¹⁰)0,1111;1.0000000001计算机中浮点数的阶码和尾数可以采用同一种机器数表示，也可采用不同的机器数表示。例6.6设浮点数字长为16位，其中阶码为5位(含1位阶符)，尾数为11位(含1位数符)，写出-\frac{53}{512}对应的浮点规格化数的原码、补码、反码和阶码用移码，尾数用补码的形式。解：设x=-\frac{53}{512}=-0.000110101=2^{-11}\times(-0.1101010000)[x]原=1,0011;1.1101010000[x]补=1,1101;1.0010110000[x]反=1,1100;1.0010101111[x]阶移,尾补=0,1101;1.0010110000值得注意的是，当一个浮点数尾数为0时，不论其阶码为何值；或阶码等于或小于它所能表示的最小数时，不管其尾数为何值，机器都把该浮点数作为零看待，并称之为“机器零”。如果浮点数的阶码用移码表示，尾数用补码表示，则当阶码为它所能表示的最小数2⁻"(式中m为阶码的位数)且尾数为0时，其阶码(移码)全为0，尾数(补码)也全为0，这样的机器零为000…0000，全零表示有利于简化机器中判“0”电路。现代计算机中，浮点数一般采用IEEE制定的国际标准，这种标准形式如下：阶码(含阶符)S数尾数符小数点位置按IEEE标准，常用的浮点数有三种：符号位S阶码尾数总位数短实数182332长实数1115264临时实数1156480其中，S为数符，它表示浮点数的正负，但与其有效位(尾数)是分开的。阶码用移码表示，阶码的真值都被加上一个常数(偏移量)，如短实数、长实数和临时实数的偏移量用十六进制数表示分别为7FH、3FFH和3FFFH(见附录6A.1)。尾数部分通常都是规格化表示，即非“0”的有效位最高位总是“1”，但在IEEE标准中，有效位呈如下形式。1▲ffff……fff其中▲表示假想的二进制小数点。在实际表示中，对短实数和长实数，这个整数位的1省略，称隐藏位；对于临时实数不采用隐藏位方案。表6.3列出了十进制数178.125的实数表示。定点运算包括移位、加、减、乘、除几种。移位运算在日常生活中常见。例如，15m可写成1500cm，单就数字而言，1500相当于数15相对于小数点左移了两位，并在小数点前面添了两个0；同样15也相当于1500相对于小数点右移了两位，并删去了小数点后面的两个0。可见，当某个十进制数相对于小数点左移n位时，相当于该数乘以10°；右移n位时，相当于该数除以10°。计算机中小数点的位置是事先约定的，因此，二进制表示的机器数在相对于小数点作n位左移或右移时，其实质就是该数乘以或除以2"(n=1，2，…，n)。移位运算称为移位操作，对计算机来说，有很大的实用价值。例如，当某计算机没有乘(除)法运算线路时，可以采用移位和加法相结合，实现乘(除)运算。计算机中机器数的字长往往是固定的，当机器数左移n位或右移n位时，必然会使其n位低位或n位高位出现空位。那么，对空出的空位应该添补0还是1呢?这与机器数采用有符号数还是无符号数有关。对有符号数的移位称为算术移位。对于正数，由于[x]_{吸}=[x]_{外}=[x]_{底}=真值，故移位后出现的空位均以0添之。对于负数，由于原码、补码和反码的表示形式不同，故当机器数移位时，对其空位的添补规则也不同。表6.4列出了三种不同码制的机器数(整数或小数均可)，分别对应正数或负数移位后的添补规则。必须注意的是：不论是正数还是负数，移位后其符号位均不变，这是算术移位的重要特点。①机器数为正时，不论是左移还是右移，添补代码均为0。②由于负数的原码数值部分与真值相同，故在移位时只要使符号位不变，其空位均添0即可。③由于负数的反码各位除符号位外与负数的原码正好相反，故移位后所添的代码应与原码相反，即全部添1。④分析任意负数的补码可发现，当对其由低位向高位找到第一个“1”时，在此“1”左边的各位均与对应的反码相同，而在此“1”右边的各位(包括此“1”在内)均与对应的原码相同。故负数的补码左移时，因空位出现在低位，则添补的代码与原码相同，即添0；右移时因空位出现在高位，则添补的代码应与反码相同，即添1。例6.7设机器数字长为8位(含1位符号位)，若A=±26，写出三种机器数左、右移一位和两位后的表示形式及对应的真值，并分析结果的正确性。解:(1)A=+26=(+11010)=则[A]_{吸}=[A]_{浓}=[A]_{E}=0,0011010移位结果如表6.5所示。可见，对于正数，三种机器数移位后符号位均不变，左移时最高数位丢1，结果出错；右移时最低数位丢1，影响精度。(2)A=-26=(-11010)=三种机器数移位结果如表6.6所示。可见，对于负数，三种机器数算术移位后符号位均不变。负数的原码左移时，高位丢1，结果出错；右移时，低位丢1，影响精度。负数的补码左移时，高位丢0，结果出错；右移时，低位丢1，影响精度。负数的反码左移时，高位丢0，结果出错；右移时，低位丢0，影响精度。图6.3示意了机器中实现算术左移和右移操作的硬件框图。其中，图6.3(a)为真值为正的三种机器数的移位操作；图6.3(b)为负数原码的移位操作；图6.3(c)为负数补码的移位操作；图6.3(d)为负数反码的移位操作。有符号数的移位称为算术移位，无符号数的移位称为逻辑移位。逻辑移位的规则是：逻辑左移时，高位移丢，低位添0；逻辑右移时，低位移丢，高位添0。例如，寄存器内容为01010011，逻辑左移为10100110,算术左移为00100110(最高数位“1”移丢)。又如,寄存器内容为10110010,逻辑右移为01011001，若将其视为补码，算术右移为11011001。显然，两种移位的结果是不同的。上例中为了避免算术左移时最高数位丢1，可采用带进位((C_{y})的移位，其示意图如图6.4所示。算术左移时，符号位移至Cy，最高数位就可避免移丢。加减法运算是计算机中最基本的运算，因减法运算可看作被减数加上一个减数的负值，即A-B=A+(-B)，故在此将机器中的减法运算和加法运算合在一起讨论。现代计算机中都采用补码作加减法运算。1.补码加减运算的基本公式补码加法的基本公式如下：整数[A]_{\neq}+[B]_{外}=[A+B]_{\#}(mod2^{n+1})小数[A]_{\neqk}+[B]_{差}=[A+B]_{\neq}(mod2)即补码表示的两个数在进行加法运算时，可以把符号位与数值位同等处理，只要结果不超出机器能表示的数值范围，运算后的结果按2ⁿ⁺¹取模(对于整数)或按2取模(对于小数)，就能得到本次加法的运算结果。读者可根据补码定义，按两个操作数的四种正负组合情况加以证明。对于减法,因A-B=A+(-B)则[A-B]_{外}=[A+(-B)]_{全}由补码加法基本公式可得整数[A-B]_{\#}=[A]_{\#}+[-B]_{\#}(mod2^{n+1})小数[A-B]_{\#}=[A]_{\#}+[-B]_{\#}(mod2)因此，若机器数采用补码，当求A-B时，只需先求[-B]₂(称[-B]_{和}为“求补”后的减数)，就可按补码加法规则进行运算。而[-B]补由[B]粘连同符号位在内，每位取反，末位加1而得。例6.8已知A=0.1011,B=-0.0101,求{[A+B]₄。解:因为A=0.1011,B=-0.0101所以[A]_{浓}=0.1011,[B]_{\#}=1.1011则[A]_{外}+[B]_{\ast}=0.1011丢掉按模2的意义，最左边的1丢掉，故|[A+B]_{外}=0.0110,结果正确。例6.9已知A=-1001,B=-0101,求[A+B]补。解:因为A=-1001,B=-0101所以[A]_{\#}=1,0111,[B]_{外}=1,1011则[A]_{\#}+[B]_{\#}=1,0111\boxed{1}\frac{+1,1011}{1,0010}=[A+B]_{4}丢掉按模2⁴⁺¹的意义，最左边的1丢掉。例6.10设机器数字长为8位(含1位符号位),若A=+15,B=+24,求|[A-B]_{浓}并还原成真值。解：因为A=+15=+0001111,B=+24=+0011000所以[A]补=0,0001111,[B]补=0,0011000,[-B]补=1,1101000则[A-B]_{外}=[A]_{\neq}+[-B]_{外}=0,0001111\frac{+1,1101000}{1,111011}所以[A-B]补=1,1110111故A-B=-0001001=-9可见，不论操作数是正还是负，在做补码加减法时，只需将符号位和数值部分一起参加运算，并且将符号位产生的进位自然丢掉即可。例6.11设机器数字长为8位，其中1位为符号位，令A=-93,B=+45,求[A-B]₄。解:由A=-93=-1011101,得|[A]_{\#}=1,0100011由B=+45=+0101101,得[B]_{\#}=0,0101101,[-B]_{\#}=1,1010011[A]_{外}=1,0100011丢掉-按模2ⁿ⁺¹的意义，最左边的“1”自然丢掉，故|[A-B]_{\#}=0,1110110,还原成真值得A-B=118,结果出错，这是因为A-B=-138超出了机器字长所能表示的范围。在计算机中，这种超出机器字长的现象叫溢出。为此，在补码定点加减运算过程中，必须对结果是否溢出做出明确的判断。补码定点加减运算判断溢出有两种方法。(1)用一位符号位判断溢出对于加法，只有在正数加正数和负数加负数两种情况下才可能出现溢出，符号不同的两个数相加是不会溢出的。对于减法，只有在正数减负数或负数减正数两种情况下才可能出现溢出，符号相同的两个数相减是不会溢出的。下面以机器字长为4位(含1位符号位)为例，说明机器是如何判断溢出的。机器字长为4位的补码所对应的真值范围为-8~+7，运算结果一旦超过这个范围即为溢出。表6.7列出了四种溢出情况。由于减法运算在机器中是用加法器实现的，因此可得出如下结论：不论是作加法还是减法，只要实际参加操作的两个数(减法时即为被减数和“求补”以后的减数)符号相同，结果又与原操作数的符号不同，即为溢出。由[A+B]_{\#}=1.0000,得A+B=-1,由此可见，用补码表示定点小数时，它能表示-1的值。计算机中采用1位符号位判断时，为了节省时间，通常用符号位产生的进位与最高有效位产生的进位异或操作后，按其结果进行判断。若异或结果为1，即为溢出；异或结果为0，则无溢出。例6.12中符号位有进位，最高有效位无进位，即1⊕0=1，故溢出。例6.13中符号位有进位，最高有效位也有进位，即1⊕1=0，故无溢出。(2)用两位符号位判断溢出在6.1.2节中已提到过2位符号位的补码，即变形补码，它是以4为模的，其定义为[x]_{\neql},=\begin{cases}x&1>x\ge0\cr4+x&0>x\ge-1\end{cases}(mod4)在用变形补码作加法时，2位符号位要连同数值部分一起参加运算，而且高位符号位产生的进位自动丢失，便可得正确结果，即[x]_{\#k}+[y]_{\#},=[x+y]_{\#h},(mod4)变形补码判断溢出的原则是：当2位符号位不同时，表示溢出，否则；无溢出。不论是否发生溢出，高位(第1位)符号位永远代表真正的符号。例6.14设x=+\frac{11}{16},y=+\frac{3}{16},试用变形补码计算x+y。解：因为x=+\frac{11}{16}=0.1011,y=+\frac{3}{16}=0.0011所以[x]_{浓},=00.1011,[y]_{\#}=00.0011则[x]_{+h},+[y]_{\#},=00.1011\frac{+00.0011}{00.1110}故[x+y]_{排}=00.1110x+y=0.1110符号位为“10”，表示溢出。由于第1位符号位为1，则表示负溢出。上述结论对于整数也同样适用。在浮点机中，当阶码用两位符号位表示时，判断溢出的原则与小数的完全相同。这里需要说明一点，采用双符号位方案时，寄存器或主存中的操作数只需保存一位符号位即可。因为任何正确的数，两个符号位的值总是相同的，而双符号位在加法器中又是必要的，故在相加时，寄存器中一位符号的值要同时送到加法器的两位符号位的输入端。图6.5是实现补码定点加减法的基本硬件配置框图。图中寄存器A、X、加法器的位数相等，其中A存放被加数(或被减数)的补码，X存放加数(或减数)的补码。当作减法时，由“求补控制逻辑”将X送至加法器，并使加法器的最末位外来进位为1，以达到对减数求补的目的。运算结果溢出时，通过溢出判断电路置“1”溢出标记V。GA为加法标记，G₅为减法标记。由图可见，加(减)法运算前，被加(减)数的补码在A中，加(减)数的补码在X中。若是加法,直接完成(A)+(X)→A(mod2或:mod2ⁿ⁺¹)的运算；若是减法，则需对减数求补，再和A寄存器的内容相加，结果送A。最后完成溢出判断。在计算机中，乘法运算是一种很重要的运算，有的机器由硬件乘法器直接完成乘法运算，有的机器内没有乘法器，但可以按机器做乘法运算的方法，用软件编程实现。因此，学习乘法运算方法不仅有助于乘法器的设计，也有助于乘法编程。下面从分析笔算乘法入手，介绍机器中用到的几种乘法运算方法。1.分析笔算乘法设A=0.1101,B=0.1011,求A×B。笔算乘法时，乘积的符号由两数符号心算而得：正正得正。其数值部分的运算如下：一品品.A×2⁰…A不移位A×2¹A左移1位…0×2²0左移2位…A×2³A左移3位……10090-所以A×B=+0.10001111可见，这里包含着被乘数A的多次左移，以及4个位积的相加运算。若计算机完全模仿笔算乘法步骤，将会有两大困难：其一，将4个位积一次相加，机器难以实现；其二，乘积位数增长了一倍，这将造成器材的浪费和运算时间的增加。为此，对笔算乘法进行改进。A·B=A·0.1011=0.1A+0.00A+0.001A+0.0001A=0.1A+0.00A+0.001(A+0.1A)=0.1A+0.01[0A+0.1(A+0.1A)]=0.1{A+0.1[0A+0.1(A+0.1A)]}=2⁻¹{A+2⁻¹[0A+2⁻¹(A+2⁻¹A)]}=2⁻¹{A+2⁻¹[0A+2⁻¹(A+2⁻¹(A+0))]}(6.8)由式(6.8)可见，两数相乘的过程，可视为加法和移位(乘2⁻¹相当于做一位右移)两种运算，这对计算机来说是非常容易实现的。从初始值为0开始，对式(6.8)作分步运算，则第一步：被乘数加零A+0=0.1101+0.0000=0.1101第二步：右移一位，得新的部分积2⁻¹(A+0)=0.01101第三步：被乘数加部分积A+2⁻¹(A+0)=0.1101+0.01101=1.00111第四步：右移一位，得新的部分积2⁻¹[A+2⁻¹(A+0)]=0.100111第五步：O⋅A+2⁻¹[A+2⁻¹(A+0)]=0.100111第六步：2⁻¹{0⋅A+2⁻¹[A+2⁻¹(A+0)]}=0.0100111第七步：4+2⁻¹{0⋅A+2⁻¹[A+2⁻¹(A+0)]}=1.0001111第八步：2⁻¹{A+2⁻¹[0⋅A+2⁻¹(A+2⁻¹(A+0))]}=0.1000111]表6.8列出了式(6.8)的全部运算过程。上述运算过程可归纳如下：①乘法运算可用移位和加法来实现，两个4位数相乘，总共需要进行4次加法运算和4次移位。②由乘数的末位值确定被乘数是否与原部分积相加，然后右移一位，形成新的部分积；同时，乘数也右移一位，由次低位作新的末位，空出最高位放部分积的最低位。③每次做加法时，被乘数仅仅与原部分积的高位相加，其低位被移至乘数所空出的高位位置。计算机很容易实现这种运算规则。用一个寄存器存放被乘数，一个寄存器存放乘积的高位，另一个寄存器存放乘数及乘积的低位，再配上加法器及其他相应电路，就可组成乘法器。又因加法只在部分积的高位进行，故不但节省了器材，而且还缩短了运算时间。由于原码表示与真值极为相似，只差一个符号，而乘积的符号又可通过两数符号的逻辑异或求得，因此，上述讨论的结果可以直接用于原码一位乘，只需加上符号位处理即可。(1)原码一位乘运算规则以小数为例：设[x]_{底}=x_{0},x_{1}x_{2}\cdotsx_{n}[y]_{吸}=y_{0}\cdoty_{1}y_{2}\cdotsy_{n}则[x]_{m}\cdot[y]_{m}=x_{0}\oplus)y_{0}.(0.x_{1}x_{2}\cdotsx_{n})(0.y_{1}y_{2}\cdotsy_{n})式中，0.x_{1}x_{2}\cdotsx_{n}为x的绝对值，记作：x^\ast;0.y_{1}y_{2}\cdotsy_{n}为y的绝对值，记作y°。原码一位乘的运算规则如下：①乘积的符号位由两原码符号位异或运算结果决定。②乘积的数值部分由两数绝对值相乘，其通式为x\cdoty^\ast=x^\ast(0.y_{1}y_{2}\cdotsy_{n})=x^{\ast}(y_{1}2^{-1}+y_{2}2^{-2}+\cdots+y_{n}2^{-n})=2⁻¹(y₁x⁺+2⁻¹(y₂x⁺+2⁻¹(…+2⁻¹(yₙ₋₁x⁺+2⁻¹(y₀x⁺+0))…)))z₀(6.9)z₁\overrightarrow{z}_{2}…Zn-1zn再令zi表示第i次部分积，式(6.9)可写成如下递推公式。=\left(\begin{matrix}+0<2(\gamma,&x+x)\cr\ast^{2}(0,&\cdots+4)\cr82^{3}+6x-5x)\cr8&20x^{2}(73x-x+5)\cr\vdots^{2}(0,x+8,&5,\cr3^{2}(0,x+x_{2},\cr\frac{3}{24}x^{2}(0,x+2,)\end{matrix}\right)(6.10)值得注意的是，这里部分积取n+1位，以便存放乘法过程中绝对值大于或等于1的值。此外，由于乘积的数值部分是两数绝对值相乘的结果，故原码一位乘法运算过程中的右移操作均为逻辑右移。(2)原码一位乘所需的硬件配置图中A、X、Q均为n+1位的寄存器，其中X存放被乘数的原码，Q存放乘数的原码。移位和加控制电路受末位乘数Qn的控制(当(Qₙ=1时，A和X内容相加后，A、Q右移一位；当Qₙ=0时,只作A、Q右移一位的操作)。计数器C用于控制逐位相乘的次数。S存放乘积的符号。GM为乘法标记。(3)原码一位乘控制流程原码一位乘控制流程如图6.8所示。乘法运算前，A寄存器被清零，作为初始部分积，被乘数原码在X中，乘数原码在Q中，计数器C中存放乘数的位数n。乘法开始后，首先通过异或运算，求出乘积的符号并存于S，接着将被乘数和乘数从原码形式变为绝对值。然后根据Q。的状态决定部分积是否加上被乘数，再逻辑右移一位，重复n次，即得运算结果。上述讨论的运算规则同样可用于整数原码。为了区别于小数乘法，书写上可将表6.9中的“.”改为“,”。为了提高乘法速度，可采用原码两位乘。(4)原码两位乘原码两位乘与原码一位乘一样，符号位的运算和数值部分是分开进行的，但原码两位乘是用两位乘数的状态来决定新的部分积如何形成，因此可提高运算速度。两位乘数共有四种状态，对应这四种状态可得表6.10。表中2倍被乘数可通过将被乘数左移一位实现，但3倍被乘数的获得较难。此刻可将3视为4-1(11=100-1)，即把乘以3分两步完成，第一步先完成减1倍被乘数的操作，第二步完成加4倍被乘数的操作。而加4倍被乘数的操作实际上是由比“11”高的两位乘数代替完成的，可看作是在高两位乘数上加“1”。这个“1”可暂存在C，触发器中。机器完成C，置“1”，即意味着对高两位乘数加1，也即要求高两位乘数代替本两位乘数“11”来完成加4倍被乘数的操作。由此可得原码两位乘的运算规则如表6.11所示。表中z表示原有部分积，x*表示被乘数的绝对值，y*表示乘数的绝对值，→2表示右移两位，当进行-x*运算时，一般都采用加[-x']₈来实现。这样，参与原码两位乘运算的操作数是绝对值的补码，因此运算中右移两位的操作也必须按补码右移规则完成。尤其应注意的是，乘法过程中可能要加2倍被乘数，即+[2x']_{浓},使部分积的绝对值大于2。为此，只有对部分积取3位符号位，且以最高符号位作为真正的符号位，才能保证运算过程正确无误。此外，为了统一用两位乘数和一位C，共同配合管理全部操作，与原码一位乘不同的是，需在乘数(当乘数位数为偶数时)的最高位前增加两个0。这样，当乘数最高两个有效位出现“11”时，需将C，置“1”，再与所添补的两个0结合呈001状态，以完成加x”的操作(此步不必移位)。不难理解，当乘数为偶数时，需做n/2次移位，最多做n/2+1次加法。当乘数为奇数时，乘数高位前可只增加一个“0”，此时需做n/2+1次移位(最后一步移一位)，最多需做n/2+1次加法。虽然两位乘法可提高乘法速度，但它仍基于重复相加和移位的思想，而且随着乘数位数的增加，重复次数增多，仍然影响乘法速度的进一步提高。采用并行阵列乘法器可大大提高乘法速度。有关阵列乘法器的内容可参见附录6B。原码乘法实现比较容易，但由于机器都采用补码做加减运算，倘若做乘法前再将补码转换成原码，相乘之后又要将负积的原码变为补码形式，这样增添了许多操作步骤，反而使运算复杂。为此，有不少机器直接用补码相乘，机器里配置实现补码乘法的乘法器，避免了码制的转换，提高了机器效率。(1)补码一位乘运算规则设被乘数[x]_{外}=x_{0},x_{1}x_{2}\cdotsx_{n}乘数[y]_{外}=y_{0}\cdoty_{1}y_{2}\cdotsy_{n}1)被乘数x符号任意，乘数y符号为正[x]_{\#}=x_{0},x_{1}x_{2}\cdotsx_{n}=2+x=2^{n+1}+x(\hboxmod2)[y]_{浓}=0.y_{1}y_{2}\cdotsy_{n}=y则[x]_{\#}\cdot[y]_{\#}=[x]_{\#}\cdoty=(2^{n+1}+x)\cdoty=2^{n+1}\cdoty+xy由于y=0.y_{1}y_{2}\cdotsy_{n}=\sum\limits_{l=1}^{n}y_{i}2^{-i},则2^{n+1}\cdoty=2\sum\limits_{i=1}^{n}y_{i}2^{n-i},且\sum\limits_{i=1}^{n}y_{i}2^{n-i}是一个大于或等于1的正整数，根据模运算的性质，有2ⁿ⁺¹⋅y=2(mod2),故[x]补·[y]补=2"+1·y+xy=2+xy=[x·y]补(mod2)即[x\cdoty]_{k}=[x]_{+}\cdot[y]_{外}=[x]_{4}\cdoty对照原码乘法式(6.9)和式(6.10)可见，当乘数y为正数时，不管被乘数x符号如何，都可按原码乘法的规则运算，即(6.11)当然这里的加和移位都必须按补码规则运算。2)被乘数x符号任意，乘数y符号为负[x]_{外}=x_{0}.x_{1}x_{2}\cdotsx_{n}[y]_{外}=1.y_{1}y_{2}\cdotsy_{n}=2+y(mod2)则y=[y]_{\#}-2=1.y_{1}y_{2}\cdotsy_{n}-2=0.y_{1}y_{2}\cdotsy_{n}-1x\cdoty=x(0.y_{1}y_{2}\cdotsy_{n}-1)=x(0,y_{1}y_{2}\cdotsy_{n})-x故[x\cdoty]_{外}=[x(0,y_{1}y_{2}\cdotsy_{n})]_{\#}+[-x]_{\#}将上式(0.y_{1}y_{2}\cdotsy_{n}视为一个正数，正好与上述情况相同。则[x(0.y_{1}y_{2}\cdotsy_{n})]_{差}=[x]_{水}(0.y_{1}y_{2}\cdotsy_{n})所以[x\cdoty]_{外}=[x]_{\#}(0.y_{1}y_{2}\cdotsy_{n})+[-x]f(6.12)由此可得，当乘数为负时是把乘数的补码|[y]_{和}去掉符号位，当成一个正数与[x]₂相乘，然后加上[-x]₄进行校正，也称校正法，用递推公式表示如下：[z₀]补=0[z₁]补=2⁻¹(yn[x]补+[z₀]补)[z₂]补=2⁻¹(yₙ₋₁[x]补+[z₁]补)⋮(6.13)[z₁]补=2⁻¹(yₙ-i+₁[x]补+[z₁-₁]补)|⋮[zn]补=2⁻¹(y₁[x]补+[zₙ₋₁]补)[x·y]补=[zn]补+[-x]补比较式(6.13)与式(6.11)可见，乘数为负的补码乘法与乘数为正时类似，只需最后加上一项校正项[-x]_{浓}即可。例6.19已知|[x]_{浓}=1.0101,[y]_{浓}=0.1101,求[x·y]补。解：因为乘数y>0，所以按原码一位乘的算法运算，只是在相加和移位时按补码规则进行，如表6.13所示。考虑到运算时可能出现绝对值大于1的情况(但此刻并不是溢出)，故部分积和被乘数取双符号位。故乘积[x⋅y]₂=1.01110001由以上两例可见，乘积的符号位在运算过程中自然形成，这是补码乘法和原码乘法的重要区别。上述校正法与乘数的符号有关，虽然可将乘数和被乘数互换，使乘数保持正，不必校正，但当两数均为负时必须校正。总之，实现校正法的控制线路比较复杂。若不考虑操作数符号，用统一的规则进行运算，就可采用比较法。3)被乘数x和乘数y符号均为任意比较法是Booth夫妇首先提出来的，故又称Booth算法。它的运算规则可由校正法导出。设[x]_{外}=x_{0},x_{1}x_{2}\cdotsx_{n}[y]_{外}=y_{0},y_{1}y_{2}\cdotsy_{n}按补码乘法校正法规则，其基本算法可用一个统一的公式表示为[x\cdoty]_{\#}=[x]_{\#}(0.y_{1}y_{2}\cdotsy_{n})-[x]_{\#}\cdoty_{0}(6.14)当y₀=0时，表示乘数y为正，无须校正，即[x\cdoty]_{\#}=[x]_{外}(0.y_{1}y_{2}\cdotsy_{n})(6.15)当y₀=1时，表示乘数y为负，则[x\cdoty]_{浓}=[x]_{\#}(0,y_{1}y_{2}\cdotsy_{n})-[x]_{球}(6.16)比较式(6.12)和式(6.16),在mod2的前提下,[-x]_{浓}=-[x]_{外}成立①,所以式(6.15)和式(6.16)表达的算法与校正法的结论完全相同，故式(6.14)可以改写为[x\cdoty]_{\#}=[x]_{\#}(y_{1}2^{-1}+y_{2}2^{-2}+\cdots+y_{n}2^{-n})-[x]_{+}\cdoty_{0}=[x]_{\#}(-y_{0}+y_{1}2^{-1}+y_{2}2^{-2}+\cdots+y_{n}2^{-n})=[x]_{+}[-y_{0}+(y_{1}-y_{1}2^{-1})+(y_{2}2^{-1}-y_{2}2^{-2})+\cdots+(y_{n}2^{-(n-1)}-y_{n}2^{-n})][x]_{\dagger}[(y_{1}-y_{0})+(y_{2}-y_{1})2^{-1}+\cdots+(y_{n}-y_{n-1})2^{-(n-1)}+(0-y_{n})2^{-n}]==[x]_{\#}[(y_{1}-y_{0})+(y_{2}-y_{1})2^{-1}+\cdots+(y_{n+1}-y_{n})2^{-n}](6.17)其中，yₙ₊₁=0。这样，可得如下递推公式。[z_{0}]_{\neq}=0[z₁]补=2⁻¹{[z₀]补+(yₙ₊₁-yₙ)[x]补}(6.18)[x\cdoty]_{\#}=[z_{n+1}]_{\#}=[z_{n}]_{\#}+(y_{1}-y_{0})[x][x·y]x=[z…]x=[z_l₃+(y₁-y。)[x],科由此可见，开始时yₙ₊₁=0,部分积初值[z_{0}]_{排}为0，每一步乘法由((y_{i+1}-y_{i})(i=1,2,\cdots,n)决定原部分积加[x]补或加[-x]料或加0，再右移一位得新的部分积，以此重复n步。第n+1步由(y₁-y₀)决定原部分积加[x]补或加[-x];或加0,但不移位,即得[x·y]补。这里的((yᵢ₊₁-yᵢ)之差值恰恰与乘数末两位yᵢ及yᵢ₊₁的状态对应，对应的操作如表6.15所示。当运算至最后一步时，乘积不再右移。这样的运算规则计算机很容易实现。①证明:[-x]_{外}=-[x],(mod2)(1)若[x]_{外}=0.x_{1}x_{2}\cdotsx_{n}(2)若[x]_{y}=1,x_{1}x_{2}\cdotsx_{n}则x=0,x_{1}x_{2}\cdotsx_{n}则x=-(0,\overline{x}_{1}\overline{x}_{2}\cdots\overline{x}_{n}+2^{-n})所以-x=-0,x_{1}x_{2}\cdotsx_{n}所以-x=0,x_{1}\overline{x}_{2}\cdotsx_{n}+2^{-k}故[-x]_{底}=1.\overline{x}_{1}\overline{x}_{2}\cdots\overline{x}_{n}+2^{-n}(mod2)(a)故[-x]_{y}=0,\overline{x}_{1}\overline{x}_{2}\cdots\overline{x}_{n}+2^{-n}(mod2)(c)又因为[x]_{y}=0,x_{1}x_{2}\cdotsx_{n}又因为[x]_{外}=1,x_{1}x_{2}\cdotsx_{n}所以-[x]_{外}=-0,x_{1}x_{2}\cdotsx_{n}=-(0,\overline{x}_{1}\overline{x}_{2}\cdots\overline{x}_{n}+2^{-n})(mod2)=2-0,x_{1}x_{2}\cdotsx_{n}(mod2)所以-[x]_{外}=0,\overline{x}_{1}\overline{x}_{2}\cdotsx_{n}+2^{-n}(d)=1,\overline{x}_{1}x_{2}\cdots\overline{x}_{n}+2^{-n}(b)比较(c)、(d)两式可得比较(a)、(b)两式可得[-x]_{浓}=-[x]_{水}(mod2)[-x]_{差}=-[x]_{浓}(mod2)证毕证毕应该注意的是，按比较法进行补码乘法时，像补码加、减法一样，符号位也一起参加运算。由于比较法的补码乘法运算规则不受乘数符号的约束，因此，控制线路比较简明，在计算机中普遍采用。(2)补码比较法(Booth算法)所需的硬件配置图6.9是实现补码一位乘比较法乘法运算的基本硬件配置框图。图中A、X、Q均为n+2位寄存器，其中X存放被乘数的补码(含两位符号位)，Q存放乘数的补码(含最高1位符号位和最末1位附加位)，移位和加控制逻辑受Q寄存器末2位乘数控制。当其为01时，A、X内容相加后A、Q右移一位；当其为10时，A、X内容相减后A、Q右移一位。计数器C用于控制逐位相乘的次数，GM为乘法标记。(3)补码比较法(Booth算法)控制流程补码一位乘比较法的控制流程图如图6.10所示。乘法运算前A寄存器被清零，作为初始部分积。Q寄存器末位清零，作为附加位的初态。被乘数的补码存在X中(双符号位)，乘数的补码在Q高n+1位中，计数器C存放乘数的位数n。乘法开始后，根据Q寄存器末两位(Qₙ、Qₙ₊₁的状态决定部分积与被乘数相加还是相减，或是不加也不减，然后按补码规则进行算术移位，这样重复n次。最后，根据Q的末两位状态决定部分积是否与被乘数相加(或相减)，或不加也不减，但不必移位，这样便可得到最后结果。补码乘法乘积的符号位在运算中自然形成。需要说明的是，图中(A)-(X)→A实际是用加法器实现的，即(A)+(X+1)→A。同理，Booth运算规则也适用于整数补码。为了提高乘法的运算速度，可采用补码两位乘。(4)补码两位乘补码两位乘运算规则是根据补码一位乘的规则，把比较yₙyₙ₊₁的状态应执行的操作和比较yₙ₋₁yₙyn的状态应执行的操作合并成一步得出的。例如，yₙ₋₁yₙyₙ₊₁为011，则第一步由yₙyₙ₊₁=11得出只作右移，即2^{-1}[z_{i}]_{\#},第二步由yₙ₋₁yₙ=01得出需作2^{-1}\{2^{-1}[z_{i}]_{\#}+[x]_{\#}\}的操作，可改写为2^{-2}\{[z_{i}]_{\#}+2[x]_{\#}\},即最后结论为当yₙ₋₁yₙyₙ₊₁为011时,完成2^{-2}\{[z_{i}]_{\#}+2[x]_{\#}\}操作，同理可分析其余7种情况。表6.18列出了补码两位乘的运算规则。由表6.18可见，操作中出现加2[x]补和加2[-x]补，故除右移两位的操作外，还有被乘数左移一位的操作；而加2[x]补和加2[-x]补都可能因溢出而侵占双符号位，故部分积和被乘数采用3位符号位。例6.23已知|[x]_{\#}=0.0101,[y]_{\#}=1.0101,求[x·y]补。解：表6.19列出了此例的求解过程。其中，乘数取2位符号位，外加1位附加位(初态为0),即11.01010,[-x]补=1.1011取3位符号位为111.1011。故[x\cdoty]_{浓}=1.11001001由表6.19可见，与补码一位乘相比(参见表6.16和表6.17)，补码两位乘的部分积多取1位符号位(共3位)，乘数也多取1位符号位(共2位)，这是由于乘数每次右移2位，且用3位判断，故采用双符号位更便于硬件实现。可见，当乘数数值位为偶数时，乘数取2位符号位，共需作n/2次移位，最多作n/2+1次加法，最后一步不移位；当n为奇数时，可补0变为偶数位，以简化逻辑操作。也可对乘数取1位符号位，此时共进行n/2+1次加法运算和n/2+1次移位(最后一步移一位)。对于整数补码乘法，其过程与小数补码乘法完全相同。为了区别于小数乘法，在书写上将符号位和数值位中间的“.”改为“，”即可。以小数为例,设x=-0.1011,y=0.1101,求x/y。笔算除法时，商的符号心算而得：负正得负。其数值部分的运算如下面的竖式所示。2⁻¹·y2⁻²·y2⁻⁴·y所以商x/y=-0.1101,余数=0.00000111其特点可归纳如下：①每次上商都是由心算来比较余数(被除数)和除数的大小，确定商为“1”还是“0”。②每做一次减法，总是保持余数不动，低位补0，再减去右移后的除数。③上商的位置不固定。④商符单独处理。如果将上述规则完全照搬到计算机内，实现起来有一定困难，主要问题如下：①机器不能“心算”上商，必须通过比较被除数(或余数)和除数绝对值的大小来确定商值，即|x|--|y|,若差为正(够减)上商1,差为负(不够减)上商0。②按照每次减法总是保持余数不动低位补0，再减去右移后的除数这一规则，则要求加法器的位数必须为除数的两倍。仔细分析发现，右移除数可以用左移余数的方法代替，其运算结果是一样的，但对线路结构更有利。不过此刻所得到的余数不是真正的余数，只有将它乘上2⁻ⁿ才是真正的余数。③笔算求商时是从高位向低位逐位求的，而要求机器把每位商直接写到寄存器的不同位置也是不可取的。计算机可将每一位商直接写到寄存器的最低位，并把原来的部分商左移一位，这样更有利于硬件实现。综上所述便可得原码除法运算规则。原码除法和原码乘法一样，符号位是单独处理的，下面以小数为例。设[x]_{阴}=x_{0},x_{1}x_{2}\cdotsx_{n}[y]_{稀}=y_{0}\cdoty_{1}y_{2}\cdotsy_{n}则[\frac{x}{y}]_{吸}=(x_{0}\oplusy_{0}).\frac{0.x_{1}x_{2}\cdotsx_{n}}{0.y_{1}y_{2}\cdotsy_{n}}式中，0.x_{1}x_{2}\cdotsx_{n}为x的绝对值,记作x*;0.y₁y₂…yₙ为y的绝对值,记作y*。即商符由两数符号位进行异或运算求得，商值由两数绝对值相除(x*/y*)求得。小数定点除法对被除数和除数有一定的约束，即必须满足下列条件：0<|被除数|≤|除数|实现除法运算时，还应避免除数为0或被除数为0。前者结果为无限大，不能用机器的有限位数表示；后者结果总是0，这个除法操作没有意义，浪费了机器时间。商的位数一般与操作数的位数相同。原码除法中由于对余数的处理不同，又可分为恢复余数法和不恢复余数法(加减交替法)两种。(1)恢复余数法恢复余数法的特点是：当余数为负时，需加上除数，将其恢复成原来的余数。由上所述，商值的确定是通过比较被除数和除数的绝对值大小，即x^{\ast}-y^{4}实现的，而计算机内只设加法器，故需将x*-y*操作变为|[x^{\ast}]_{水}+[-y^{{}^{\circ}}]_{浓}的操作。例6.24已知x=-0.1011,y=-0.1101,求[\frac{x}{y}]_{吸}。解:由x=-0.1011,y=-0.1101得[x]_{加}=1.1011,x'=0.1011[y]_{底}=1.1101,y^{\ast}=0.1101,[-y^{\ast}]_{\#}=1.001表6.20列出了例6.24商值的求解过程。故商值为0.1101商的符号位为x₀⊕y₀=1⊕1=0所以[\frac{x}{y}]=0.1101由此例可见，共左移(逻辑左移)4次，上商5次，第一次上的商在商的整数位上，这对小数除法而言，可用它作溢出判断。即当该位为“1”时，表示此除法溢出，不能进行，应由程序进行处理；当该位为“0”时，说明除法合法，可以进行。在恢复余数法中，每当余数为负时，都需恢复余数，这就延长了机器除法的时间，操作也很不规则，对线路结构不利。加减交替法可克服这些缺点。(2)加减交替法加减交替法又称不恢复余数法，可以认为它是恢复余数法的一种改进算法。分析原码恢复余数法得知：当余数R₂>0时，可上商“1”，再对R₁左移一位后减除数，即2Rᵢ-y^*。当余数Rᵢ<0时，可上商“0”，然后先做R_{i}+y^{\ast},即完成恢复余数的运算，再做2(Rᵢ+y²)-y*,即2Rᵢ+y°。可见，原码恢复余数法可归纳如下：当Rᵢ>0,商上“1”,做2R_{i}-y^{\cdot}的运算。当Rᵢ<0,商上“0”,做2Rᵢ+y⋅的运算。这里已经看不出余数的恢复问题了，而只是做加y*或减y^{\ast},因此，一般将其称为加减交替法或不恢复余数法。例6.25已知x=-0.1011,y=0.1101,求[\frac{x}{y}]。解:由x=-0.1011,y=0.1101得[x]ₘ=1.1011,x²=0.1011[y]_{底}=0.1101,y^{\ast}=0.1101,[-y^{\ast}]_{\#}=1.001]商的符号位为x₀⊕y₀=1⊕0=1所以[\frac{x}{y}]_{吸}=1.1101分析此例可见，n位小数的除法共上商n+1次(第一次商用来判断是否溢出)，左移(逻辑左移)n次，可用移位次数判断除法是否结束。倘若比例因子选择恰当，除法结果不溢出，则第一次商肯定是0。如果省去这位商，只需上商n次即可，此时除法运算一开始应将被除数左移一位减去除数，然后再根据余数上商。读者可以自己练习。需要说明一点，表6.21中操作数也可采用双符号位，此时移位操作可按算术左移处理，最高符号位是真正的符号，次高位符号位在移位时可被第一数值位占用。(3)原码加减交替法所需的硬件配置图6.11是实现原码加减交替法运算的基本硬件配置框图。图中A、X、Q均为n+1位寄存器，其中A存放被除数的原码，X存放除数的原码。移位和加控制逻辑受Q的末位Qn控制((Qₙ=1做减法，Qₙ=0做加法)，计数器C用于控制逐位相除的次数n,G_{D}为除法标记，V为溢出标记，S为商符。(4)原码加减交替法控制流程图6.12为原码加减交替法控制流程图。除法开始前，Q寄存器被清零，准备接收商，被除数的原码放在A中，除数的原码放在X中，计数器C中存放除数的位数n。除法开始后，首先通过异或运算求出商符，并存于S。接着将被除数和除数变为绝对值，然后开始用第一次上商判断是否溢出。若溢出，则置溢出标记V为1，停止运算，进行中断处理，重新选择比例因子；若无溢出，则先上商，接着A、Q同时左移一位，然后再根据上一次商值的状态，决定是加还是减除数，这样重复n次后，再上最后一次商(共上商n+1次)，即得运算结果。对于整数除法，要求满足以下条件：0<|除数|≤|被除数|因为这样才能得到整数商。通常在做整数除法前，先要对这个条件进行判断，若不满足上述条件，机器发出出错信号，程序要重新设定比例因子。上述讨论的小数除法完全适用于整数除法，只是整数除法的被除数位数可以是除数的两倍，且要求被除数的高n位要比除数(n位)小，否则即为溢出。如果被除数和除数的位数都是单字长，则要在被除数前面加上一个字的0，从而扩展成双倍字长再进行运算。为了提高除法速度，可采用阵列除法器，有关内容参见附录6B。与补码乘法类似，也可以用补码完成除法操作。补码除法也分恢复余数法和加减交替法，后者用得较多，在此只讨论加减交替法。(1)补码加减交替法运算规则补码除法的符号位和数值部分是一起参加运算的，因此在算法上不像原码除法那样直观，主要需要解决3个问题：①如何确定商值；②如何形成商符；③如何获得新的余数。①欲确定商值，必须先比较被除数和除数的大小，然后才能求得商值。·比较被除数(余数)和除数的大小补码除法的操作数均为补码，其符号又是任意的，因此要比较被除数[x]补和除数|[y]_{和}的大小就不能简单地用[x]补减去[y]#。实质上比较[x]林和[y]#的大小就是比较它们所对应的绝对值的大小。同样在求商的过程中，比较余数[R₁]补与除数[y]补的大小，也是比较它们所对应的绝对值的大小。这种比较的算法可归纳为以下两点。第一，当被除数与除数同号时，做减法，若得到的余数与除数同号，表示“够减”，否则表示“不够减”。第二，当被除数与除数异号时，做加法，若得到的余数与除数异号，表示“够减”，否则表示“不够减”。·商值的确定补码除法的商也是用补码表示的，如果约定商的末位用“恒置1”的舍入规则，那么除末位商外，其余各位的商值对正商和负商而言，上商规则是不同的。因为在负商的情况下，除末位商以外，其余任何一位的商与真值都正好相反。因此，上商的算法可归纳为以下两点。第一，如果[x]补与[y]补同号，商为正，则“够减”时上商“1”，“不够减”时上商“0”(按原码规则上商)。第二，如果[x]补与[y]补异号，商为负，则“够减”时上商“0”，“不够减”时上商“1”(按反码规则上商)。结合比较规则与上商规则，便可得商值的确定方法，如表6.23所示。进一步简化，商值可直接由表6.24确定。②在补码除法中，商符是在求商的过程中自动形成的。在小数定点除法中，被除数的绝对值必须小于除数的绝对值，否则商大于1而溢出。因此，当[x]补与[y]补同号时,[[x]₄-[y]₄所得的余数[R₀]补必与[y]补异号，上商“0”，恰好与商的符号(正)一致;当[x]补与[y]补异号时,[[x]_{浓}+[y]_{外}所得的余数[R₀]补必与[y]补同号，上商“1”，这也与商的符号(负)一致。可见，商符是在求商值过程中自动形成的。此外，商的符号还可用来判断商是否溢出。例如，当[x]补与[y]补同号时，若[[R₀]₄与[y]补同号,上商“1”,即溢出。当[x]补与[y]补:异号时,若[R₀]补与[y]补异号,上商“0”,即溢出。当然，对于小数补码运算，商等于“-1”应该是允许的，但这需要特殊处理，为简化问题，这里不予考虑。③新余数[R_{i+1}]_{\#}的获得方法与原码加减交替法极相似，其算法规则如下：当[R_{i}]_{\#}与[y]补同号时，商上“1”，新余数[R_{i+1}]_{\#}=2[R_{i}]_{\#}-[y]_{\#}=2[R_{i}]_{\#}+[-y]_{\#}当[Rᵢ]₂与[y]补异号时，商上“0”，新余数[R_{i+1}]_{球}=2[R_{i}]_{浓}+[y]_{\#}将此算法列于表6.25中。如果对商的精度没有特殊要求，一般可采用“末位恒置1”法，这种方法操作简单，易于实现，而且最大误差仅为2⁻ⁿ。例6.26已知x=0.1001,y=0.1101,求[\frac{x}{y}]。解:由x=0.1001,y=0.1101得x]_{\#}=0.1001,[y]_{\#}=0.1101,[-y]_{\#}=1.0011其运算过程如表6.26所示。所以[\frac{x}{y}]_{\mu}=0.1011例6.27已知x=-0.1001,y=+0.1101,求[\frac{x}{y}]。解:由x=-0.1001,y=+0.1101得x]_{\#}=1.0111,[y]_{\#}=0.1101,[-y]_{\#}=1.001101其运算过程如表6.27所示。所以[\frac{x}{y}]_{加水}=1.0101可见，n位小数补码除法共上商n+1次(末位恒置“1”)，第一次商可用来判断是否溢出。共移位n次，并用移位次数判断除法是否结束。(2)补码加减交替法所需的硬件配置补码加减交替法所需的硬件配置基本上与图6.11相似，只是图6.11中的S触发器可以省掉，因为补码除法的商符在运算中自动形成。此外，在寄存器中存放的均为补码。例6.28设X、Y、Z均为n+1位寄存器(n为最低位)，机器数采用1位符号位。若除法开始时操作数已放在合适的位置，试分别描述原码和补码除法商符的形成过程。解：设X、Y、Z均为n+1位寄存器，除法开始时被除数在X中，除数在Y中，S为触发器，存放商符，Z寄存器存放商。原码除法的商符由两操作数(原码)的符号位进行异或运算获得，记作X₀⊕Y₀→S。补码除法的商符由第1次上商获得，共分两步。第一步，若两操作数符号相同，则被除数减去除数(加上“求补”以后的除数)，结果送X寄存器；若两操作数符号不同，则被除数加上除数，结果送X寄存器，记作\overline{X_{0}\oplusY_{0}}\cdot(X+\overline{Y}+1)+(X_{0}\oplusY_{0})\cdot(X+Y)\rightarrowX第二步，根据结果的符号和除数的符号确定商值。若结果的符号X₀与除数的符号Y₀同号，则上商“1”，送至Zₙ保存；若结果的符号X₀与除数的符号Y₀异号，则上商“0”，送至Zₙ保存，记作X₀⊕Y₀→Zₙ如果机器数采用补码，实现乘法和除法均用补码运算，那么，为了与补码乘法取得相同的寄存器位数，表6.26和表6.27中的被除数(余数)可取双符号位，整个运算过程与取1位符号位完全相同(见例6.34下的表6.31)。(3)补码加减交替法的控制流程补码加减交替法的控制流程如图6.13所示。除法开始前，Q寄存器被清零，准备接收商，被除数的补码在A中，除数的补码在X中，计数器C中存放除数的位数n。除法开始后，首先根据两操作数的符号确定是做加法还是减法，加(或减)操作后，即上第一次商(商符)，然后A和Q同时左移一位，再根据商值的状态决定加或减除数，这样重复n次后，再上一次末位商“1”(恒置“1”法)，即得运算结果。补充说明几点：①图中未画出补码除法溢出判断的内容。②按流程图所示，多做一次加(或减)法，其实在末位恒置“1”前，只需移位而不必做加(或减)法。③与原码除法一样，图中均未指出对0进行检测。实际上在除法运算前，先检测被除数和除数是否为0。若被除数为0，结果即为0；若除数为0，结果为无穷大。这两种情况都无须继续做除法运算。④为了节省时间，上商和移位操作可以同时进行。以上介绍了计算机定点四则运算方法，根据这些运算规则，可以设计乘法器和除法器。有些机器的乘、除法可用编程来实现。分析上述运算方法对理解机器内部的操作过程和编制乘、除法运算的标准程序都是很有用的。从6.2节浮点数的讨论可知，机器中任何一个浮点数都可写成x=S_{x}\cdotr^{j_{x}}的形式。其中，Sₓ为浮点数的尾数，一般为绝对值小于1的规格化数(补码表示时允许为-1),机器中可用原码或补码表示；j，为浮点数的阶码，一般为整数，机器中大多用补码或移码表示；r为浮点数的基数，常用2、4、8或16表示。以下以基数为2进行讨论。设两个浮点数x=S_{x}\cdotr^{j_{x}}y=S_{y}\cdotr^{j_{y}}由于浮点数尾数的小数点均固定在第一数值位前，所以尾数的加减运算规则与定点数的完全相同。但由于其阶码的大小又直接反映尾数有效值小数点的实际位置，因此当两浮点数阶码不等时，因两尾数小数点的实际位置不一样，尾数部分无法直接进行加减运算。为此，浮点数加减运算必须按以下几步进行。①对阶，使两数的小数点位置对齐。②尾数求和，将对阶后的两尾数按定点加减运算规则求和(差)。③规格化，为增加有效数字的位数，提高运算精度，必须将求和(差)后的尾数规格化。④舍入，为提高精度，要考虑尾数右移时丢失的数值位。⑤溢出判断，即判断结果是否溢出。对阶的目的是使两操作数的小数点位置对齐，即使两数的阶码相等。为此，首先要求出阶差，再按小阶向大阶看齐的原则，使阶小的尾数向右移位，每右移一位，阶码加1，直到两数的阶码相等为止。右移的次数正好等于阶差。尾数右移时可能会发生数码丢失，影响精度。例如，两浮点数x=0.1101×2⁰¹,y=(-0.1010)×2¹¹,求x+y。首先写出x，y在计算机中的补码表示。[x]补=00,01;00.1101,[y]补=00,11;11.0110在进行加法前，必须先对阶，故先求阶差：[\triangle_{j}]_{\#}=[j_{x}]_{\#}-[j_{,}]_{\#}=00,01+11,01=11,10即△ⱼ=-2,表示x的阶码比y的阶码小，再按小阶向大阶看齐的原则，将x的尾数右移两位，其阶码加2,得[x]补=00,11;00.0011此时，△ⱼ=0,表示对阶完毕。将对阶后的两个尾数按定点加(减)运算规则进行运算。如上例中的两数对阶后得[x]补=00,11;00.0011[y]补=00,11;11.0110则[S_{x}+S_{y}]_{2}为[Sx];[Sy]补[Sₓ+Sy]补即[x+y]补=00,11;11.1001由6.2.2节可知，当基值r=2时，尾数S的规格化形式为\frac{1}{2}\le|S|<1(6.19)如果采用双符号位的补码，则当S>0时，其补码规格化形式为[S]_{p}=00.1\times\times\cdots\times(6.20)当S<0时，其补码规格化形式为[S]_{球}=11.0\times\times\cdots\times(6.21)可见，当尾数的最高数值位与符号位不同时，即为规格化形式，但对S<0时，有两种情况需特殊处理。\enclose{circle}{1}S=-\frac{1}{2},则[S]_{浓}=11.100\cdots0。此时对于真值-\frac{1}{2}而言，它满足式(6.19)，对于补码([S]补)而言，它不满足于式(6.21)。为了便于硬件判断，特规定-\frac{1}{2}不是规格化的数(对补码而言)。②S=-1,则[S]_{\neq1}=11.00\cdots0,因小数补码允许表示-1，故-1视为规格化的数。当尾数求和(差)结果不满足式(6.20)或式(6.21)时，则需规格化。规格化又分左规和右规两种。(1)左规当尾数出现00.0××…×或11.1××…×时，需左规。左规时尾数左移一位，阶码减1，直到符合式(6.20)或式(6.21)为止。如上例求和结果为[x+y]补=00,11;11.1001尾数的第一数值位与符号位相同，需左规，即将其左移一位，同时阶码减1，得[x+y]补=00,10;11.0010则x+y=(-0.1110)×2¹⁰(2)右规当尾数出现01.××…×或10.××…×时，表示尾数溢出，这在定点加减运算中是不允许的，但在浮点运算中这不算溢出，可通过右规处理。右规时尾数右移一位，阶码加1。例6.29已知两浮点数.x=0.1101×2¹⁰,y=0.1011×2⁰¹,求x+y。解：x、y在机器中以补码表示为[x]补=00,10;00.1101[y]补=00,01;00.1011①对阶:[\triangle_{j}]_{外}=[j_{x}]_{浓}-[j_{y}]_{8}=00,10+11,11=00,01即△ⱼ=1,表示y的阶码比x的阶码小1，因此将y的尾数向右移一位，阶码相应加1，即[y]'补=00,10;00.0101这时[y]'补的阶码与[x]补的阶码相等，阶差为0，表示对阶完毕。②求和:[Sx]补\overline{00.1101}[Sy]'补[Sₓ+Sy]'补即[x+y]补=00,10;01.0010③右规:运算结果两符号位不等，表示尾数之和绝对值大于1，需右规，即将尾数之和向右移一位，阶码加1，故得[x+y]补=00,11;00.1001则x+y=0.1001×2¹¹在对阶和右规的过程中，可能会将尾数的低位丢失，引起误差，影响精度。为此可用舍入法来提高尾数的精度。常用的舍入方法有以下两种。(1)“0舍1入”法“0舍1入”法类似于十进制数运算中的“四舍五入”法，即在尾数右移时，被移去的最高数值位为0，则舍去；被移去的最高数值位为1，则在尾数的末位加1。这样做可能使尾数又溢出，此时需再做一次右规。(2)“恒置1”法尾数右移时，不论丢掉的最高数值位是“1”或“0”，都使右移后的尾数末位恒置“1”。这种方法同样有使尾数变大和变小的两种可能。综上所述，浮点加减运算经过对阶、尾数求和、规格化和舍入等步骤。与定点加减运算相比，显然要复杂得多。与定点加减法一样，浮点加减运算最后一步也需判断溢出。在浮点规格化中已指出，当尾数之和(差)出现01.××…×或10.××…×时，并不表示溢出，只有将此数右规后，再根据阶码来判断浮点运算结果是否溢出。若机器数为补码，尾数为规格化形式，并假设阶符取2位，阶码的数值部分取7位，数符取2位，尾数的数值部分取n位，则它们能表示的补码在数轴上的表示范围如图6.14所示。图中A、B、a、b的坐标均为补码表示，分别对应最小负数、最大正数、最大负数和最小正数。它们所对应的真值如下：A最小负数2⁺¹²⁷×(-1)B最大正数2⁺¹²⁷×(1-2⁻ⁿ)a最大负数2⁻¹²⁸×(-2⁻¹-2⁻ⁿ)b最小正数2⁻¹²⁸×2⁻¹注意，由于图6.14所示的A、B、a、b均为补码规格化的形式，故其对应的真值与图6.2所示的结果有所不同。在图6.14中a、b之间的阴影部分对应的阶码小于-128，这种情况称为浮点数的下溢。下溢时，浮点数值趋于零，故机器不做溢出处理，仅把它作为机器零。在图6.14中A、B两侧的阴影部分对应的阶码大于+127，这种情况称为浮点数的上溢。此刻，浮点数真正溢出，机器需停止运算，做溢出中断处理。一般说浮点溢出，均是指上溢。可见，浮点机的溢出与否可由阶码的符号决定，即阶码[j]补=01,××…×为上溢。阶码[j]_{浓}=10,\times\times\cdots\times为下溢，按机器零处理。当阶符为“01”时，需做溢出处理。例6.30经舍入处理后得|[x-y]₄=11,101;11.011001,阶符为“11”，不溢出，故最终结果为x-y=2⁻⁰¹¹×(-0.100111)例6.31设机器数字长16位，阶码5位(含1位阶符)，基值为2，尾数11位(含1位数符)。对于两个阶码相等的数按补码浮点加法完成后，由于规格化操作可能出现的最大误差的绝对值是多少?解：两个阶码相等的数按补码浮点加法完成后，仅当尾数溢出需右规时会引起误差。右规时尾数右移一位，阶码加1，可能出现的最大误差是末尾丢1，例如：结果为00,1110;01.×××××××××1右规后得00,1111;00.1×××××××××1考虑到最大阶码是15，最后得最大误差的绝对值为((10000)_{\pm}=2^{4}。当计算机中阶码用移码表示时，移码运算规则参见浮点乘除运算。最后可得浮点加减运算的流程。例6.32要求用最少的位数设计一个浮点数格式，必须满足下列要求。(1)十进制数的范围：负数-10³⁸∼-10⁻³⁸;正数+10⁻³⁸∼10³⁸。(2)精度：7位十进制数据。解:(1)由2¹⁰>10³可得(2¹⁰)¹²>(10³)¹²,即2¹²⁰>10³⁶又因为2⁷>10²所以2⁷×2¹²⁰>10²×10³⁶,即2¹²⁷>10³⁸同理2⁻¹²⁷<10⁻³⁸故阶码取8位(含1位阶符)，当其用补码表示时，对应的数值范围为-128~+127。(2)因为10⁷≈2²³,故尾数的数值部分可取23位。加上数符，最终浮点数取32位，其中阶码8位(含1位阶符)，尾数24位(含1位数符)。6.浮点加减运算流程图6.15为浮点补码加减运算的流程图。6.4.2浮点乘除法运算两个浮点数相乘，乘积的阶码应为相乘两数的阶码之和，乘积的尾数应为相乘两数的尾数之积。两个浮点数相除，商的阶码为被除数的阶码减去除数的阶码，尾数为被除数的尾数除以除数的尾数所得的商，可用下式描述。设两浮点数x=Sₓ⋅rʲˣy=S_{y}\cdotr^{j_{y}}则x\cdoty=(S_{x}\cdotS_{y})\timesr^{j_{x}+j}y\frac{x}{y}=\frac{S_{x}}{S_{y}}\cdotr^{j_{x}-j_{y}}在运算中也要考虑规格化和舍入问题。若阶码用补码运算，乘积的阶码为[j_{x}]_{\#}+[j_{y}]_{\#},商的阶码为[j_{x}]_{浓}-[j_{y}]_{\#}。两个同号的阶码相加或异号的阶码相减可能产生溢出，此时应做溢出判断。若阶码用移码运算，则因为[j_{x}]_{浓}=2^{n}+j_{x}-2^{n}\lej_{x}<2^{n}(n为整数的位数)[j_{y}]_{\psi}=2^{n}+j_{y}-2^{n}\lej_{y}<2^{n}(n为整数的位数)所以[j_{x}]_{浓}+[j_{y}]_{t}=2^{n}+j_{x}+2^{n}+j_{y}=2^{n}+[2^{n}+(j_{x}+j_{y})]=2^{n}+[j_{x}+j_{y}]_{的}可见，直接用移码求阶码和时，最高位多加了一个2ⁿ,，要得到移码形式的结果，必须减去2"。由于同一个真值的移码和补码数值部分完全相同，而符号位正好相反，即[j_{y}]_{\#}=2^{n+1}+j_{y}(mod2^{n+1})因此，求阶码和可用下式完成[j_{x}]_{t}+[j_{y}]_{\neq}=2^{n}+j_{x}+2^{n+1}+j_{y}=2^{n+1}+[2^{n}+(j_{x}+j_{y})]=[j_{x}+j_{y}]_{放}(mod2^{n+1})则直接可得移码形式。同理，当做除法运算时，商的阶码可用下式完成[j_{x}]_{浓}+[-j_{y}]_{外}=[j_{x}-j_{y}]y可见进行移码加减运算时，只需将移码表示的加数或减数的符号位取反(即变为补码)，然后进行运算，就可得阶和(或阶差)的移码。阶码采用移码表示后又如何判断溢出呢?如果在原有移码符号位的前面(即高位)再增加1位符号位，并规定该位恒用“0”表示，便能方便地进行溢出判断。溢出的条件是运算结果移码的最高符号位为1。此时若低位符号位为0，表示上溢；低位符号位为1，表示下溢。如果运算结果移码的最高符号位为0，即表明没有溢出。此时若低位符号位为1，表明结果为正；低位符号位为0，表示结果为负。例如，若阶码取3位(不含符号位)，则对应的真值范围是-8~+7。当j_{x}=+101,j_{y}=+100时，则有[jₓ]移=01,101;[j,]补=00,100故[j_{x}+j_{y}]_{浓}=[j_{x}]_{球}+[j_{\nu}]_{\#}=01,101+00,100=10,001结果上溢[j_{x}-j_{y}]_{球}=[j_{x}]_{\kappa}+[-j_{y}]_{\dag}=01,101+11,100=01,0(1结果为+1当j_{x}=-101,j_{y}=-100时，则有[j_{x}]_{\Psi}=00,011,[j_{y}]_{外}=11,100故[j_{x}+j_{y}]_{球}=[j_{x}]_{浓}+[j_{y}]_{\#}=00,011+11,100=11,111结果下溢j_{x}-j_{y}]_{球}=[j_{x}]_{球}+[-j,]_{+}=00,011+00,100=00,111结果为-1(1)浮点乘法尾数运算两个浮点数的尾数相乘，可按下列步骤进行。①检测两个尾数中是否有一个为0，若有一个为0，乘积必为0，不再做其他操作；如果两尾数均不为0，则可进行乘法运算。②两个浮点数的尾数相乘可以采用定点小数的任何一种乘法运算来完成。相乘结果可能要进行左规，左规时调整阶码后如果发生阶下溢，则作机器零处理；如果发生阶上溢，则作溢出处理。此外，尾数相乘会得到一个双倍字长的结果，若限定只取1倍字长，则乘积的若干低位将会丢失。如何处理丢失的各位值，通常有两种方法。其一，无条件地丢掉正常尾数最低位之后的全部数值，这种方法称为截断处理，处理简单，但影响精度。其二，按浮点加减运算讨论的两种舍入原则进行舍入处理。对于原码，采用0舍1入法时，不论其值是正数或负数，“舍”使数的绝对值变小，“入”使数的绝对值变大。对于补码，采用0舍1入法时，若丢失的位不是全0，对正数来说，“舍”“入”的结果与原码分析正好相同；对负数来说，“舍”“入”的结果与原码分析正好相反，即“舍”使绝对值变大，“入”使绝对值变小。为了使原码、补码舍入处理后的结果相同，对负数的补码可采用如下规则进行舍入处理。①当丢失的各位均为0时，不必舍入。②当丢失的各位数中的最高位为0时，且以下各位不全为0，或丢失的各位数中的最高位为1，且以下各位均为0时，则舍去被丢失的各位。③当丢失的各位数中的最高位为1，且以下各位又不全为0时，则在保留尾数的最末位加1修正。例如，对下列4个补码进行只保留小数点后4位有效数字的舍入操作，如表6.28所示。如果将上述4个补码变成原码后再舍入，其结果列于表6.29中。比较表6.28和表6.29可见，按照上述的约定对负数的补码进行舍入处理，与对其原码进行舍入处理后的真值是一样的。下面举例说明浮点乘法运算的全过程。设机器数阶码取3位(不含阶符)，尾数取7位(不含数符)，要求阶码用移码运算，尾数用补码运算，最后结果保留1倍字长。例6.33已知:x=2⁻¹⁰¹×0.0110011,y=2⁰¹¹×(-0.1110010),求x·y。解：由x=2⁻¹⁰¹×0.0110011,y=2⁰¹¹×(-0.1110010)得[x]补=11,011;00.0110011[y]补=00,011;11.0001110①阶码运算：[j_{x}]_{甲}=00,011,[j_{y}]_{球}=00,011=00,011+00,011=00,110对应真值-2②尾数相乘(采用Booth算法):其过程如表6.30所示。③规格化：尾数相乘结果为[[S_{x}\cdotS_{y}]_{浓}=11.101001010010,，需左规，即[x·y]补=11,110;11.10100101001010左规后[x·y]补=11,101;11.01001010010100④舍入处理：尾数为负，按负数补码的舍入规则，取1倍字长，丢失的7位为0010100，应“舍”，故最终结果为[x·y]补=11,101;11.0100101x⋅y=2⁻⁰¹¹×(-0.1011011)(2)浮点除法尾数运算两个浮点数的尾数相除，可按下列步骤进行。①检测被除数是否为0，若为0，则商为0；再检测除数是否为0，若为0，则商为无穷大，另作处理。若两数均不为0，则可进行除法运算。②两浮点数尾数相除同样可采取定点小数的任何一种除法运算来完成。对已规格化的尾数，为了防止除法结果溢出，可先比较被除数和除数的绝对值，如果被除数的绝对值大于除数的绝对值，则先将被除数右移一位，其阶码加1，再作尾数相除。此时所得结果必然是规格化的定点小数。例6.34按补码浮点运算步骤，计算[2^{5}\times(+\frac{9}{16})]\div[2^{3}\times(-\frac{13}{16})]。解：令x=[2^{5}\times(+\frac{9}{16})]=2^{101}\times(0.1001)y=[2^{3}\times(-\frac{13}{16})]=2^{011}\times(-0.1101)所以[x]补=00,101;00.1001[y]_{\#}=00,011;11.0011,[-S_{,}]_{\#}=00.1101①阶码相减：j_{x}]_{+}-[j_{y}]_{\#}=00,101-00,011=00,101+11,101=00,01[0②尾数相除(采用补码除法)：其过程如表6.31所示。表中被除数(余数)采用双符号位，与采用一位符号位结果一致。所以[\frac{S_{s}}{S_{y}}]=1.0101③规格化：尾数相除结果已为规格化数。所以[\frac{x}{y}]_{4}=00,010;11.0101则[\frac{x}{y}]=2^{010}\times(-0.1011)=[2^{2}\times(-\frac{11}{16})]由于浮点运算分阶码和尾数两部分，因此浮点运算器的硬件配置比定点运算器的复杂。分析浮点四则运算发现，对于阶码只有加减运算，对于尾数则有加、减、乘、除四种运算。可见浮点运算器主要由两个定点运算部件组成。一个是阶码运算部件，用来完成阶码加、减，以及控制对阶时小阶的尾数右移次数和规格化时对阶码的调整；另一个是尾数运算部件，用来完成尾数的四则运算以及判断尾数是否已规格化，此外，还需有判断运算结果是否溢出的电路等。现代计算机可把浮点运算部件做成独立的选件，或称协处理器，用户可根据需要选择，不用选件的机器，也可用编程的方法来完成浮点运算，不过这将会影响机器的运算速度。例如,Intel80287是浮点协处理器,它可与Intel80286或80386微处理器配合处理浮点数的算术运算和多种函数计算。针对每一种算术运算，都必须有一个相对应的基本硬件配置，其核心部件是加法器和寄存器。当需要完成逻辑运算时，势必需要配置相应的逻辑电路，而ALU电路是既能完成算术运算又能完成逻辑运算的部件。图6.16所示是ALU框图。图中A₁和B₁为输入变量；kᵢ为控制信号，kᵢ的不同取值可决定该电路做哪一种算术运算或哪一种逻辑运算；Fi是输出函数。现在ALU电路已制成集成电路芯片，例如，74181是能完成4位二进制代码的算逻运算部件，外特性如图6.17所示。74181有两种工作方式,即正逻辑和负逻辑,分别如图6.17(a)和图6.17(b)所示。表6.32列出了其算术/逻辑运算功能，逻辑电路参见附录6C的图6.30。①1=高电平，0=低电平；②*表示每一位均移到下一个更高位，即A^{\ast}=2A。以正逻辑为例，B₃~B₀和A₃∼A₀是两个操作数，F₃∼F₀为输出结果。C_₁表示最低位的外来进位，Cₙ₊₄是74181向高位的进位；P、G可供先行进位使用(有关P、G的具体含义参见6.5.2节)。M用于区别算术运算还是逻辑运算；S₃∼S₀的不同取值可实现不同的运算。例如，当M=1,S₃∼S₀=0110时,74181做逻辑运算A⊕B;当M=0,S₃∼S₀=0110时,74181做算术运算。由表6.32可见，在正逻辑条件下，M=0,S₃∼S₀=0110,且C₋₁=1时，完成A减B减1的操作。若想完成A减B运算,可使(C₋₁=0。注意，74181的算术运算是用补码实现的，其中减数的反码是由内部电路形成的，而末位加“1”，则通过C₋₁=0来体现(图6.17(a)中C_₁输入端处有一个小圈，意味着C₋₁=0反相后为1)。尤其要注意的是，ALU为组合逻辑电路，因此实际应用ALU时，其输入端口A和B必须与锁存器相连，而且在运算的过程中锁存器的内容是不变的。其输出也必须送至寄存器中保存。现在有的芯片将寄存器和ALU电路集成在一个芯片内，如29C101，如图6.18所示(图中ALU的控制端I₈∼I₀未画出)。该芯片的核心部件是一个容量为16字的双端口RAM和一个高速ALU电路。RAM可视为由16个寄存器组成的寄存器堆。只要给出A₁口或Bᵢ口的4位地址，就可以从A。出口或B。出口读出对应于口地址的存储单元内容。写入时，只能写入由Bᵢ口指定的那个单元内。参与操作的两个数分别由RAM的A。、B。出口输出至两个锁存器中。ALU受I₈∼I₀控制,I₂、I₁、I₀控制ALU的数据源；I₅、I₄、I₃控制ALU所能完成的3种算术运算和5种逻辑运算;I₈~I₆用来控制RAM和Q移位器，决定是否移位以及Y口输出是来自RAM的A出口还是ALU的F出口。ALU的Cᵢₙ为低位来的外来进位，Cₙ₊₁₆为向高位的进位，可供29C101级联时用。ALU结果为0时,F=0可直接输出，OVR为溢出标记。而P\sqrt{G}与74181的P、G含义相同，它们可供先行进位方式时使用。ALU的输出可直接通过移位器存入RAM，也可通过选通门在\overrightarrow{OE}有效时从Y₁₅∼Y₀输出。Q寄存器主要为乘法和除法服务，D₁₅∼D₀为16位立即数的输入口。6.5.2快速进位链随着操作数位数的增加，电路中进位的速度对运算时间的影响也越来越大，为了提高运算速度，本节将通过对进位过程的分析设计快速进位链。1.并行加法器并行加法器由若干个全加器组成，如图6.19所示。n+1个全加器级联就组成了一个n+1位的并行加法器。由于每位全加器的进位输出是高一位全加器的进位输入，因此当全加器有进位时，这种一级一级传递进位的过程将会大大影响运算速度。由全加器的逻辑表达式可知：和S_{i}=\overline{A}_{i}\overline{B}_{i}C_{i-1}+\overline{A}_{i}B_{i}\overline{C}_{i-1}+A_{i}\overline{B}_{i}\overline{C}_{i-1}+A_{i}B_{i}C_{i-1}进位(C_{i}=\overline{A}_{i}B_{i}C_{i-1}+A_{i}\overline{B}_{i}C_{i-1}+A_{i}B_{i}\overline{C}_{i-1}+A_{i}B_{i}C_{i-1}=AᵢBᵢ+(Aᵢ+Bᵢ)Cᵢ₋₁可见，C₁进位由两部分组成：本地进位A₁B₁，可记作dᵢ，与低位无关；传递进位(Aᵢ+Bᵢ)Cᵢ₋₁,与低位有关，可称.Aᵢ+Bᵢ为传递条件，记作t₁，则Cᵢ=dᵢ+tᵢCᵢ₋₁由Ci的组成可以将逐级传递进位的结构转换为以进位链的方式实现快速进位。目前进位链通常采用串行和并行两种。串行进位链是指并行加法器中的进位信号采用串行传递，图6.19所示就是一个典型的串行进位的并行加法器。以四位并行加法器为例，每一位的进位表达式可表示为由式(6.22)可见，采用与非逻辑电路可方便地实现进位传递，如图6.20所示。若设与非门的级延迟时间为t，，那么当d₁、t₁形成后，共需8ty便可产生最高位的进位。实际上每增加一位全加器，进位时间就会增加2ty。n位全加器的最长进位时间为2nty。并行进位链是指并行加法器中的进位信号是同时产生的，又称先行进位、跳跃进位等。理想的并行进位链是n位全加器的n位进位同时产生，但实际实现有困难。通常并行进位链有单重分组和双重分组两种实现方案。(1)单重分组跳跃进位单重分组跳跃进位就是将n位全加器分成若干小组，小组内的进位同时产生，小组与小组之间采用串行进位，这种进位又有组内并行、组间串行之称。以四位并行加法器为例，对式(6.22)稍做变换，便可获得并行进位表达式：C₀=d₀+t₀C₋₁(6.23)5.当地址:_按式(6.23)可得与其对应的逻辑图，如图6.21所示。设与或非门的级延迟时间为1.5t，，与非门的级延迟时间仍为1t_{y},则dᵢ,tᵢ形成后,只需2.5ty就可产生全部进位。如果将16位的全加器按4位一组分组，便可得单重分组跳跃进位链框图，如图6.22所示。不难理解在dᵢ,tᵢ形成后,经2.5t,可产生(C₃、C₂、C₁,C₀这4个进位信息，经10t，就可产生全部进位，而n=16的串行进位链的全部进位时间为32ty，可见单重分组方案进位时间仅为串行进位链的1/3。但随着n的增大，其优势便很快减弱。例如，当n=64时，按4位分组，共为16组，组间有16位串行进位，在dᵢ,tᵢ形成后，还需经40ty才能产生全部进位，显然进位时间太长。如果2能使组间进位也同时产生，必然会更大地提高进位速度，这就是组内、组间均为并行进位的方案。(2)双重分组跳跃进位双重分组跳跃进位就是将n位全加器分成若干大组，每个大组中又包含若干小组，而每个大组内所包含的各个小组的最高位进位是同时产生的，大组与大组间采用串行进位。因各小组最高位进位是同时形成的，小组内的其他进位也是同时形成的(注意：小组内的其他进位与小组的最高位进位并不是同时产生的)，故又有组(小组)内并行、组(小组)间并行之称。图6.23是一个32位并行加法器双重分组跳跃进位链的框图。图中共分两大组，每个大组内包含4个小组，第一大组内的4个小组的最高位进位(C₃₁、C₂₇、C₂₃、C₁₉是同时产生的；第二大组内4个小组的最高位进位C₁₅,C₁₁、C₇、C₃也是同时产生的，而第二大组向第一大组的进位C₁₅采用串行进位方式。以第二大组为例，分析各进位的逻辑关系。按式(6.23)，可写出第八小组的最高位进位表达式C₃=d₃+t₃C₂=d₃+t₃d₂+t₃t₂d₁+t₃t₂t₁d₀+t₃t₂t₁t₀C₋₁=D₈+T₈C₋₁式中，D₈=d₃+t₃d₂+t₃t₂d₁+t₃t₂t₁d₀,仅与本小组内的dᵢ,tᵢ有关，不依赖外来进位C₋₁,故称D₈为第八小组的本地进位；T₈=t₃t₂t₁t₀,是将低位进位(C₋₁传到高位小组的条件，故称T₈为第八小组的传送条件。同理，可写出第五、六、七小组的最高位进位表达式：第七小纟第六小纟\Biggl(\begin{matrix}c=4b+4c+1>62\crC=0b^{2}+76b-47b+64b^{2}+4b+6c+2,\cr1\ge9b^{4}+7b_{4}^{4}+10b^{2}+4b_{2}+14b-64,\cr10>7b^{2}+7b+6b_{4}+8b_{4}+4b_{4}+4b+4b+6b_{4}b^{2}+4b+6b+6)bc_{0}\end{matrix}](6.24)第五小纟进一步展开又得C₃=D₈+T₈C₋₁C₇=D₇+T₇C₃=D₇+T₇D₈+T₇T₈C₋₁(6.25)C₁₁=D₆+T₆C₇=D₆+T₆D₇+T₆T₇D₈+T₆T₇T₈C₋₁C₁₅=D₅+T₅C₁₁=D₅+T₅D₆+T₅T₆D₇+T₅T₆T₇D₈+T₅T₆T₇T₈C₋₁J可见,式(6.25)和式(6.23)极为相似,因此,只需将图6.21中的d₀,d₁,d₂,d₃改为D₈、D₇、D_{6}\sqrt{D_{5}},又将t_{0},t_{1},t_{2}\sqrt{t_{3}}改为T₈、T₇、T₆,T₅便可构成第二重跳跃进位链，即大组跳跃进位链，如图6.24所示。由图可见，当DᵢΓᵢ(i=5∼8)及外来进位C₋₁形成后，再经过2.5t，便可同时产生(C₁₅、C₁₁、C₇、C₃。至于D₁和Tᵢ可由式(6.24)求得，它们都是由小组产生的，按其逻辑表达式可画出相应的电路。实际上只需对图6.21略做修改便可得双重分组进位链中的小组进位链线路，该线路能产生Dᵢ和Tᵢ,,如图6.25所示。可见，每小组可产生本小组的本地进位Dᵢ和传送条件Tᵢ以及组内的各低位进位，但不能产生组内最高位进位，即第五组形成D₅、T₅、C₁₄、C₁₃、C₁₂,不产生C₁₅;第六组形成D₆、T₆、C₁₀、C₉、C₈,，不产生(C₁₁;；第七组形成D₇、T₇,C₆、C₅、C₄,，不产生C₇;第八组形成D₈、T₈、C₂、C₁、C₀,，不产生C₃。图6.24和图6.25两种类型的线路可构成16位加法器的双重分组跳跃进位链框图，如图6.26所示。由图6.24、图6.25和图6.26可计算出从dᵢ,tᵢ及C₋₁(外来进位)形成后开始，经2.5ty形成C₂、C₁、C₀和全部Dᵢ、Tᵢ;再经2.5t，形成大组内的4个进位C₁₅、C₁₁、C₇、C₃;;再经过2.5ty形成第五、六、七小组的其余进位C₁₄、C₁₃、C₁₂、C₁₀、C₉、C₈、C₆、C₅、C₄。。可见，按双重分组设计n=16的进位链，最长进位时间为7.5t，，比单重分组进位链又省了2.5t，。对应图6.23所示的32位加法器的双重分组进位链，不难理解从dᵢtᵢ、C₋₁形成后算起，经2.5ty产生C₂、C₁、C₀及D₁∼D₈、T₁∼T₈;再经2.5t,后产生C₁₅、C₁₁、C,C₃;;再经2.5t,后产生(C₁₈∼C₁₆、C₁₄∼C₁₂、C₁₀∼C₈、C₆∼C₄及C₃₁、C₂₇、C₂₃、C₁₉;;最后经2.5ty产生C₃₀∼C₂₈、C₂₆∼C₂₄、C₂₂∼C₂₀。由此可见，产生全部进位的最长时间为10ty。若采用单重分组进位链，仍以4位一组分组，则产生全部进位时间为20ty，比双重分组多一倍。显然，随着n的增大，双重分组的优越性显得格外突出。机器究竟采用哪种方案，每个小组内应包含几位，应根据运算速度指标及所选元件等诸方面因素综合考虑。由上述分析可知，Di和T₁均是由小组进位链产生的，它们与低位进位无关。而Dᵢ和Tᵢ又是大组进位链的输入，因此，引入Di和Ti可采用双重分组进位链，大大提高了运算速度。6.5.1节介绍的74181芯片是4位ALU电路，其4位进位是同时产生的，多片74181级联就犹如本节介绍的单重分组跳跃进位，即组内(74181片内)并行，组间(74181片间)串行。74181芯片的G、P输出就如本节介绍的D、T。当需要进一步提高进位速度时，将74181与74182芯片配合，就可组成双重分组跳跃进位链，如图6.27所示。图中74182为先行进位部件,两片74182和8片74181组成32位ALU电路,该电路采用双重分组先行进位方案，原理与图6.23类似，不同点是74182还提供了大组的本地进位G和大组的传送条件P。本章主要介绍机器指令系统的分类、常见的寻址方式、指令格式以及设计指令系统时应考虑的各种因素。此外对RISC技术也进行简要的介绍，希望读者进一步体会指令系统与机器的主要功能以及与硬件结构之间存在的密切关系。由第1章可知，计算机能解题是由于机器本身存在一种语言，它既能理解人的意图，又能被机器自身识别。机器语言是由一条条语句构成的，每一条语句又能准确表达某种语义。例如，它可以命令机器做某种操作，指出参与操作的数或其他信息在什么地方等。计算机就是连续执行每一条机器语句而实现全自动工作的。人们习惯把每一条机器语言的语句称为机器指令，而又将全部机器指令的集合称为机器的指令系统。因此机器的指令系统集中反映了机器的功能。计算机设计者主要研究如何确定机器的指令系统，如何用硬件电路、芯片、设备来实现机器指令系统的功能。计算机的使用者则是依据机器提供的指令系统，使用汇编语言来编制各种程序。计算机使用者根据机器指令系统所描述的机器功能，能很清楚地了解计算机内部寄存器-存储器的结构，以及计算机能直接支持的各种数据类型。指令是由操作码和地址码两部分组成的，其基本格式如图7.1所示。操作码用来指明该指令所要完成的操作，如加法、减法、传送、移位、转移等。通常，其位数反映了机器的操作种类，也即机器允许的指令条数，如操作码占7位，则该机器最多包含2⁷=128条指令。操作码的长度可以是固定的，也可以是变化的。前者将操作码集中放在指令字的一个字段内，如图7.1所示。这种格式便于硬件设计，指令译码时间短，广泛用于字长较长的、大中型计算机和超级小型计算机以及RISC(ReducedInstructionSetComputer)中。例如,IBM370和VAX-11系列机，操作码长度均为8位。对于操作码长度不固定的指令，其操作码分散在指令字的不同字段中。这种格式可有效地压缩操作码的平均长度，在字长较短的微型计算机中被广泛采用。例如PDP-11、Intel·8086/80386等，操作码的长度是可变的。操作码长度不固定会增加指令译码和分析的难度，使控制器的设计复杂。通常采用扩展操作码技术，使操作码的长度随地址数的减少而增加，不同地址数的指令可以具有不同长度的操作码，从而在满足需要的前提下，有效地缩短指令字长。图7.2是一种扩展操作码的安排示意图。图7.2中指令字长为16位，其中4位为基本操作码字段OP，另有3个4位长的地址字段为A₁、A₂、A₃。4位基本操作码若全部用于三地址指令，则有16条。若采用扩展操作码技术，如图7.2所示，当操作码取4位时，三地址指令最多为15条；操作码取8位时，二地址指令最多为15条；操作码取12位时，一地址指令最多为15条；操作码取16位时，零地址指令为16条。共61条。可见操作码的位数随地址数的减少而增加。除了这种安排以外，还有其他多种扩展方法，例如，形成15条三地址指令、12条二地址指令、31条一地址指令和16条零地址指令，共74条指令，读者可自行安排。例7.1假设指令字长为16位，操作数的地址码为6位，指令有零地址、一地址、二地址三种格式。(1)设操作码固定，若零地址指令有P种，一地址指令有Q种，则二地址指令最多有几种?(2)采用扩展操作码技术，若二地址指令有X种，零地址指令有Y种，则一地址指令最多有几种?解：(1)根据操作数地址码为6位，则二地址指令中操作码的位数为16-6-6=4。这4位操作码可有2⁴=16种操作。由于操作码固定，则除去了零地址指令P种，一地址指令Q种，剩下二地址指令最多有16-P-Q种。(2)采用扩展操作码技术，操作码位数可变，则二地址、一地址和零地址的操作码长度分别为4位、10位和16位。可见二地址指令操作码每减少一种，就可多构成2⁶种一地址指令操作码；一地址指令操作码每减少一种，就可多构成2⁶种零地址指令操作码。因二地址指令有X种，则一地址指令最多有(2⁴-X)×2⁶种。设一地址指令有M种，则零地址指令最多有[(2⁴-X)×2⁶-M]×2⁶种。根据题中给出零地址指令有Y种，即Y=[(2⁴-X)×2⁶-M]×2⁶则一地址指令M=(2⁴-X)×2⁶-Y×2⁻⁶在设计操作码不固定的指令系统时，应尽量考虑安排指令使用频度(即指令在程序中出现的概率)高的指令占用短的操作码，对使用频度低的指令可占用较长的操作码，这样可以缩短经常使用的指令的译码时间。当然，考虑操作码长度时也应考虑地址码的要求。地址码用来指出该指令的源操作数的地址(一个或两个)、结果的地址以及下一条指令的地址。这里的“地址”可以是主存的地址，也可以是寄存器的地址，甚至可以是I/O设备的地址。下面以主存地址为例，分析指令的地址码字段。(1)四地址指令这种指令的地址字段有4个，其格式如下：OPA₁A₂A₃A₄其中，OP为操作码；A₁为第一操作数地址；A₂为第二操作数地址；A₃为结果地址；A₄为下一条指令的地址。该指令完成((A₁)OP(A₂)→A₃的操作。这种指令直观易懂，后续指令地址可以任意填写，可直接寻址的地址范围与地址字段的位数有关。如果指令字长为32位，操作码占8位，4个地址字段各占6位，则指令操作数的直接寻址范围为2⁶=64。如果地址字段均指示主存的地址，则完成一条四地址指令，共需访问4次存储器(取指令一次，取两个操作数两次，存放结果一次)。因为程序中大多数指令是按顺序执行的，而程序计数器PC既能存放当前欲执行指令的地址，又有计数功能，因此它能自动形成下一条指令的地址。这样，指令字中的第四地址字段A₄便可省去，即得三地址指令格式。(2)三地址指令三地址指令中只有3个地址，其格式如下：OPA₁A₂A₃它可完成((A₁)OP(A₂)→A₃的操作，后续指令的地址隐含在程序计数器PC之中。如果指令字长不变，设OP仍为8位，则3个地址字段各占8位，故三地址指令操作数的直接寻址范围可达2⁸=256。同理，若地址字段均为主存地址，则完成一条三地址指令也需访问4次存储器。机器在运行过程中，没有必要将每次运算结果都存入主存，中间结果可以暂时存放在CPU的寄存器(如ACC)中，这样又可省去一个地址字段A₃，从而得出二地址指令。(3)二地址指令二地址指令中只含两个地址字段，其格式如下：OPA₁A₂它可完成((A₁)OP(A₂)→A₁的操作，即A₁字段既代表源操作数的地址，又代表存放本次运算结果的地址。有的机器也可以表示((A₁)OP(A₂)→A₂的操作，此时.A₂除了代表源操作数的地址外，还代表中间结果的存放地址。这两种情况完成一条指令仍需访问4次存储器。如果使其完成(A₁)OP(A₂)→ACC,此时，它完成一条指令只需3次访存，它的含义是中间结果暂存于累加器ACC中。在不改变指令字长和操作码的位数前提下，二地址指令操作数的直接寻址范围为2¹²=4K。如果将一个操作数的地址隐含在运算器的ACC中，则指令字中只需给出一个地址码，构成一地址指令。(4)一地址指令一地址指令的地址码字段只有一个，其格式如下：OPA₁它可完成((ACC)OP(A₁)→ACC的操作，ACC既存放参与运算的操作数，又存放运算的中间结果，这样，完成一条一地址指令只需两次访存。在指令字长仍为32位、操作码位数仍固定为8位时，一地址指令操作数的直接寻址范围达2²⁴,即16M。在指令系统中，还有一种指令可以不设地址字段，即所谓零地址指令。(5)零地址指令零地址指令在指令字中无地址码，例如，空操作(NOP)、停机(HLT)这类指令只有操作码。而子程序返回(RET)、中断返回(IRET)这类指令没有地址码，其操作数的地址隐含在堆栈指针SP中(有关堆栈的概念详见7.3.2节)。通过上述介绍可见，用一些硬件资源(如PC、ACC)承担指令字中需指明的地址码，可在不改变指令字长的前提下，扩大指令操作数的直接寻址范围。此外，用PC、ACC等硬件代替指令字中的某些地址字段，还可缩短指令字长，并可减少访存次数。因此，究竟采用什么样的地址格式，必须从机器性能出发综合考虑。以上讨论的地址格式均以主存地址为例，实际上地址字段也可用来表示寄存器。当CPU中含有多个通用寄存器时，对每一个寄存器赋予一个编号，便可指明源操作数和结果存放在哪个寄存器中。地址字段表示寄存器时，也可有三地址、二地址、一地址之分。它们的共同点是，在指令的执行阶段都不必访问存储器，直接访问寄存器，使机器运行速度得到提高(因为寄存器类型的指令只需在取指阶段访问一次存储器)。指令字长取决于操作码的长度、操作数地址的长度和操作数地址的个数。不同机器的指令字长是不相同的。早期的计算机指令字长、机器字长和存储字长均相等，因此访问某个存储单元，便可取出一条完整的指令或一个完整的数据。这种机器的指令字长是固定的，控制方式比较简单。随着计算机的发展，存储容量的增大，要求处理的数据类型增多，计算机的指令字长也发生了很大的变化。一台机器的指令系统可以采用位数不相同的指令，即指令字长是可变的，如单字长指令、多字长指令。控制这类指令的电路比较复杂，而且多字长指令要多次访问存储器才能取出一条完整的指令，因此使CPU速度下降。为了提高指令的运行速度和节省存储空间，通常尽可能把常用的指令(如数据传送指令、算逻运算指令等)设计成单字长或短字长格式的指令。例如,PDP-8指令字长固定取12位;NOVA指令字长固定取16位;IBM370指令字长可变,可以是16位(半个字)、32位(一个字)、48位(一字半);Intel8086的指令字长可以为8、16、24、32、40和48位六种。通常指令字长取8的整数倍。机器中常见的操作数类型有地址、数字、字符、逻辑数据等。(1)地址地址实际上也可看作是一种数据，在许多情况下要计算操作数的地址。这时，地址可被认为是一个无符号的整数，有关地址的计算问题将在7.3节讨论。第7章指令系统305(2)数字计算机中常见的数字有定点数、浮点数和十进制数。前两种数字在第6章中已进行了介绍，十进制数已在第5章附录中说明，读者可自行复习。(3)字符在应用计算机时，文本或者字符串也是一种常见的数据类型。由于计算机在处理信息过程中不能以简单的字符形式存储和传送，因此普遍采用ASCII码(见表5.2)，它是很重要的一种字符编码。当然还有其他一些字符编码,如8位EBCDIC码(ExtendedBinaryCodedDecimalInter-changeCode),又称扩展BCD交换码,在此不做详述。(4)逻辑数据计算机除了做算术运算外，有时还需做逻辑运算，此时n个0和1的组合不是被看作算术数字，而是被看作逻辑数。例如，在ASCⅡ码中的0110101，它表示十进制数5，若要将它转换为NB-CD短十进制码，只需通过它与逻辑数0001111完成逻辑与运算，抽取低4位，即可获得0101。此外，有时希望存储一个布尔类型的数据，它们的每一位都代表着真(1)和假(0)，这时n个0和1组合的数就都被看作逻辑数。例如，奔腾处理器的数据类型有逻辑数、有符号数(补码)、无符号数、压缩和未压缩的BCD码、地址指针、位串、字符串以及浮点数(符合IEEE754标准)等。通常计算机中的数据存放在存储器或寄存器中，而寄存器的位数便可反映机器字长。一般机器字长可取字节的1、2、4、8倍，这样便于字符处理。在大、中型机器中字长为32位和64位，在微型计算机中字长从4位、8位逐渐发展到目前的16位、32位和64位。由于不同的机器数据字长不同，每台机器处理的数据字长也不统一，例如奔腾处理器可处理8(字节)、16(字)、32(双字)、64(四字);PowerPC可处理8(字节)、16(半字)、32(字)、64(双字)。因此，为了便于硬件实现，通常要求多字节的数据在存储器的存放方式能满足“边界对准”的要求，如图7.3所示。图7.3中所示的存储器存储字长为32位，可按字节、半字、字、双字访问。在对准边界的32位字长的计算机中(如图7.3(a)所示)，半字地址是2的整数倍，字地址是4的整数倍，双字地址是8的整数倍。当所存数据不能满足此要求时，可填充一个至多个空白字节。而字节的次序有两种，如图7.4所示，其中7.4(a)表示低字节为低地址，图7.4(b)表示高字节为低地址。在数据不对准边界的计算机中，数据(例如一个字)可能在两个存储单元中，此时需要访问两次存储器，并对高低字节的位置进行调整后才能取得一个字，图7.3(b)的阴影部分即属于这种情况。不同的机器，操作类型也是不同的，但几乎所有的机器都有以下几类通用的操作。数据传送包括寄存器与寄存器、寄存器与存储单元、存储单元与存储单元之间的传送。如从源到目的之间的传送、对存储器读(LOAD)和写(STORE)、交换源和目的的内容、置1、清零、进栈、出栈等。这类操作可实现算术运算(加、减、乘、除、增1、减1、取负数即求补)和逻辑运算(与、或、非、异或)。对于低档机而言，一般算术运算只支持最基本的二进制加减、比较、求补等，高档机还能支持浮点运算和十进制运算。有些机器还具有位操作功能，如位测试(测试指定位的值)、位清除(清除指定位)、位求反(对指定位求反)等。移位可分为算术移位、逻辑移位和循环移位三种。算术移位和逻辑移位分别可实现对有符号数和无符号数乘以2°(左移)或整除以2°(右移)的运算，并且移位操作所需时间远比乘除操作执行时间短，因此，移位操作经常被用来代替简单的乘法和除法运算。在多数情况下，计算机是按顺序执行程序的每条指令的，但有时需要改变这种顺序，此刻可采用转移类指令来完成。转移指令按其转移特征又可分为无条件转移、条件转移、跳转、过程调用与返回、陷阱(Trap)等几种。(1)无条件转移无条件转移不受任何条件约束，可直接把程序转移到下一条需执行指令的地址。例如“JMPX”，其功能是将指令地址无条件转至X。(2)条件转移条件转移是根据当前指令的执行结果来决定是否需要转移。若条件满足，则转移；若条件不满足，则继续按顺序执行。一般机器都能提供一些条件码，这些条件码是某些操作的结果。例如：零标志位(Z)，结果为0，Z=1；负标志位(N)，结果为负，N=1；溢出标志位(V)，结果有溢出，V=1;进位标志位(C),最高位有进位,C=1;奇偶标志位(P),结果呈偶数,P=1等。例如，指令“BROX”表示若结果(有符号数)溢出(V=1)，则指令跳转至X。例如，指令“BRCY”表示若最高位有进位(C=1),则指令跳转至Y。还有一种条件转移指令，SKP(Skip)，它暗示其下一条指令将被跳过，从而隐含了转移地址是SKP后的第二条指令。例如：这里“SKPDZ”表示若设备的完成触发器D为零，则执行完205条指令后，立即跳至第207条指令，再顺序执行。(3)调用与返回在编写程序时，有些具有特定功能的程序段会被反复使用。为避免重复编写，可将这些程序段设定为独立子程序，当需要执行某子程序时，只需用子程序调用指令即可。此外，计算机系统还提供了通用子程序，如申请资源、读写文件、控制外设等。需要时均可由用户直接调用，不必重新编写。通常调用指令包括过程调用、系统调用和子程序调用。它可实现从一个程序转移到另一个程序的操作。调用指令(CALL)一般与返回指令(RETURN)配合使用。CALL用于从当前的程序位置转至子程序的入口；RETURN用于子程序执行完后重新返回到原程序的断点。图7.5示意了调用(CALL)和返回(RETURN)指令在程序执行中的流程。图7.5(a)示意了主程序和子程序在主存所占空间。主程序从2000地址单元开始，并在2100处有一个调用指令，当执行到2100处指令时，CPU停止下一条顺序号为2101的指令，而转至2400执行SUB1子程序。在SUB1中又有两次(2500和2560处)调用子程序SUB2。每一次都将SUB1挂起，而执行SUB2。子程序末尾的RETURN指令可使CPU返回调用点。图7.5(b)示意了主程序→SUB1→SUB2→SUB1→SUB2→SUB1→主程序的执行流程。需要注意以下几点。·子程序可在多处被调用。●子程序调用可出现在子程序中，即允许子程序嵌套。●每个CALL指令都对应一条RETURN指令。由于可以在许多处调用子程序，因此，CPU必须记住返回地址，使子程序能准确返回。返回地址可存放在以下3处。●寄存器内。机器内设有专用寄存器，专门用于存放返回地址。·子程序的入口地址内。·栈顶内。现代计算机都设有堆栈，执行RETURN指令后，便可自动从栈顶内取出应返回的地址。(4)陷阱(Trap)与陷阱指令陷阱其实是一种意外事故的中断。例如，机器在运行中，可能会出现电源电压不稳定、存储器校验出差错、输入输出设备出现了故障、用户使用未被定义的指令、除数出现为0、运算结果溢出以及特权指令等种种意外事件，致使计算机不能正常工作。此刻必须及时采取措施，否则将影响整个系统的正常运行。因此，一旦出现意外故障，计算机就发出陷阱信号，暂停当前程序的执行，转入故障处理程序进行相应的故障处理。计算机的陷阱指令一般不提供给用户直接使用，而作为隐指令(即指令系统中不提供的指令)，在出现意外故障时，由CPU自动产生并执行。也有的机器设置供用户使用的陷阱指令或“访管”指令,利用它完成系统调用和程序请求。例如,IBMPC(Intel8086)的软中断INTTYPE(TYPE是8位常数，表示中断类型)，其实就是直接提供给用户使用的陷阱指令，用来完成系统调用。对于I/O单独编址的计算机而言，通常设有输入输出指令，它完成从外设中的寄存器读入一个数据到CPU的寄存器内，或将数据从CPU的寄存器输出至某外设的寄存器中。其他包括等待指令、停机指令、空操作指令、开中断指令、关中断指令、置条件码指令等。为了适应计算机的信息管理、数据处理及办公自动化等领域的应用，有的计算机还设有非数值处理指令。如字符串传送、字符串比较、字符串查询及字符串转换等。在多用户、多任务的计算机系统中，还设有特权指令，这类指令只能用于操作系统或其他系统软件，用户是不能使用的。在有些大型或巨型机中，还设有向量指令，可对整个向量或矩阵进行求和、求积运算。在多处理器系统中还配有专门的多处理机指令。寻址方式是指确定本条指令的数据地址以及下一条将要执行的指令地址的方法，它与硬件结构紧密相关，而且直接影响指令格式和指令功能。寻址方式分为指令寻址和数据寻址两大类。指令寻址比较简单，它分为顺序寻址和跳跃寻址两种。顺序寻址可通过程序计数器PC加1，自动形成下一条指令的地址；跳跃寻址则通过转移类指令实现。图7.6示意了指令寻址过程。如果程序的首地址为0，只要先将0送至程序计数器PC中，启动机器运行后，程序便按0，1，2，3，7，8，9，…顺序执行。其中第1、2、3号指令地址均由PC自动形成。因第3号地址指令为“JMP7”，故执行完第3号指令后，便无条件将7送至PC，因此，此刻指令地址跳过4、5、6三条，直接执行第7条指令，接着又顺序执行第8条、第9条等指令。关于跳跃寻址的转移地址形成方式，将在7.3.2节的直接寻址和相对寻址中做介绍。数据寻址方式种类较多，在指令字中必须设一字段来指明属于哪一种寻址方式。指令的地址码字段通常都不代表操作数的真实地址，故把它称为形式地址，记作A。操作数的真实地址称为有效地址，记作EA，它是由寻址方式和形式地址共同来确定的。由此可得指令的格式应如图7.7所示。为了便于分析研究各类寻址方式，假设指令字长、存储字长、机器字长均相同。立即寻址的特点是操作数本身设在指令字内，即形式地址A不是操作数的地址，而是操作数本身，又称之为立即数。数据是采用补码形式存放的，如图7.8所示，图中“#”表示立即寻址特征标记。可见，它的优点在于只要取出指令，便可立即获得操作数，这种指令在执行阶段不必再访问存储器。显然A的位数限制了这类指令所能表述的立即数的范围。直接寻址的特点是，指令字中的形式地址A就是操作数的真实地址EA，即EA=A它的优点是寻找操作数比较简单，也不需要专门计算操作数的地址，在指令执行阶段对主存只访问一次。它的缺点在于A的位数限制了操作数的寻址范围，而且必须修改A的值，才能修改操作数的地址。隐含寻址是指指令字中不明显地给出操作数的地址，其操作数的地址隐含在操作码或某个寄存器中。例如，一地址格式的加法指令只给出一个操作数的地址，另一个操作数隐含在累加器ACC中，这样累加器ACC成了另一个数的地址。图7.10示意了隐含寻址。又如IBMPC(Intel8086)中的乘法指令,被乘数隐含在寄存器AX(16位)或寄存器AL(8位)中，可见AX(或AL)就是被乘数的地址。又如字符串传送指令MOVS，其源操作数的地址隐含在SI寄存器中(即操作数在SI指明的存储单元中)，目的操作数的地址隐含在DI寄存器中。由于隐含寻址在指令字中少了一个地址，因此，这种寻址方式的指令有利于缩短指令字长。倘若指令字中的形式地址不直接指出操作数的地址，而是指出操作数有效地址所在的存储单元地址，也就是说，有效地址是由形式地址间接提供的，即为间接寻址，即EA=(A)，如图7.11所示。图7.11(a)为一次间接寻址，即A地址单元的内容EA是操作数的有效地址；图7.11(b)为两次间接寻址，即A地址单元的内容A₁还不是有效地址，而由A₁所指单元的内容EA才是有效地址。这种寻址方式与直接寻址相比，它扩大了操作数的寻址范围，因为A的位数通常小于指令字长，而存储字长可与指令字长相等。若设指令字长和存储字长均为16位，A为8位，显然直接寻址范围为2⁸，一次间接寻址的寻址范围可达22¹⁶。当多次间接寻址时，可用存储字的首位来标志间接寻址是否结束。如图7.11(b)中，当存储字首位为“1”时，标明还需继续访存寻址；当存储字首位为“0”时，标明该存储字即为EA。由此可见，存储字首位不能作为EA的组成部分，因此，它的寻址范围为：2¹⁵。间接寻址的第二个优点在于它便于编制程序。例如，用间接寻址可以很方便地完成子程序返回，图7.12示意了用于子程序返回的间址过程。图中表示两次调用子程序，只要在调用前先将返回地址存入子程序最末条指令的形式地址A的存储单元内，便可准确返回到原程序断点。例如，第一次调用前，使[A]=81，第二次调用前，使[A]=202。这样，当第一次子程序执行到最末条指令“JMP@A”(@为间址特征位)，便可无条件转至81号单元。同理，第二次执行完子程序后，便可返回到202号单元。间接寻址的缺点在于指令的执行阶段需要访存两次(一次间接寻址)或多次(多次间接寻址)，致使指令执行时间延长。在寄存器寻址的指令字中，地址码字段直接指出了寄存器的编号，即EA=Rᵢ,如图7.13所示。其操作数在由R₁所指的寄存器内。由于操作数不在主存中，故寄存器寻址在指令执行阶段无须访存，减少了执行时间。由于地址字段只需指明寄存器编号(计算机中寄存器数有限)，故指令字较短，节省了存储空间，因此寄存器寻址在计算机中得到广泛应用。图7.14示意了寄存器间接寻址过程。图中Rᵢ中的内容不是操作数，而是操作数所在主存单元的地址号，即有效地址EA=(Rᵢ)。与寄存器寻址相比，指令的执行阶段还需访问主存。与图7.11(a)相比，因有效地址不是存放在存储单元中，而是存放在寄存器中，故称其为寄存器间接寻址，它比间接寻址少访存一次。基址寻址需设有基址寄存器BR，其操作数的有效地址EA等于指令字中的形式地址与基址寄存器中的内容(称为基地址)相加，即EA=A+(BR)基址寄存器可采用隐式的和显式的两种。所谓隐式，是在计算机内专门设有一个基址寄存器BR，使用时用户不必明显指出该基址寄存器，只需由指令的寻址特征位反映出基址寻址即可。显式是在一组通用寄存器里，由用户明确指出哪个寄存器用作基址寄存器，存放基地址。例如，IBM370计算机中设有16个通用寄存器，用户可任意选中某个寄存器作为基址寄存器。对应图7.15(a)为隐式基址寻址,图7.15(b)为显式基址寻址。基址寻址可以扩大操作数的寻址范围，因基址寄存器的位数可以大于形式地址A的位数。当主存容量较大时，若采用直接寻址，因受A的位数限制，无法对主存所有单元进行访问，但采用基址寻址便可实现对主存空间的更大范围寻访。例如，将主存空间分为若干段，每段首地址存于基址寄存器中，段内的位移量由指令字中形式地址A指出，这样操作数的有效地址就等于基址寄存器内容与段内位移量之和，只要对基址寄存器的内容做修改，便可访问主存的任一单元。基址寻址在多道程序中极为有用。用户可不必考虑自己的程序存于主存的哪一空间区域，完全可由操作系统或管理程序根据主存的使用状况，赋予基址寄存器内一个初始值(即基地址)，便可将用户程序的逻辑地址转化为主存的物理地址(实际地址)，把用户程序安置于主存的某一空间区域。例如，对于一个具有多个寄存器的机器来说，用户只需指出哪一个寄存器作为基址寄存器即可，至于这个基址寄存器应赋予何值，完全由操作系统或管理程序根据主存空间状况来确定。在程序执行过程中，用户不知道自己的程序在主存的哪个空间，用户也不可修改基址寄存器的内容，以确保系统安全可靠地运行。变址寻址与基址寻址极为相似。其有效地址EA等于指令字中的形式地址A与变址寄存器IX的内容相加之和，即EA=A+(IX)显然只要变址寄存器位数足够，也可扩大操作数的寻址范围，其寻址过程如图7.16所示。图7.16(a)、(b)与图7.15(a)、(b)相比，显见变址寻址与基址寻址的有效地址形成过程极为相似。由于两者的应用场合不同，因此从本质来认识，它们还是有较大的区别。基址寻址主要用于为程序或数据分配存储空间，故基址寄存器的内容通常由操作系统或管理程序确定，在程序的执行过程中其值是不可变的，而指令字中的A是可变的。在变址寻址中，变址寄存器的内容是由用户设定的，在程序执行过程中其值可变，而指令字中的A是不可变的。变址寻址主要用于处理数组问题，在数组处理过程中，可设定A为数组的首地址，不断改变变址寄存器IX的内容，便可很容易形成数组中任一数据的地址，特别适合编制循环程序。例如，某数组有N个数存放在以D为首地址的主存一段空间内。如果求N个数的平均值，则用直接寻址方式很容易完成程序的编制。表7.1列出了用直接寻址求N个数平均值的程序。显然，当N=100时，该程序用了102条指令，除数据外，共占用102个存储单元存放指令。而且随N的增加，程序所用的指令数也增加(共N+2条)。若用变址寻址，则只要改变变址寄存器的内容，而保持指令“ADDX，D”(X为变址寄存器，D为形式地址)不变，便可依次完成N个数相加。用变址寻址编制的程序如表7.2所示。该程序仅用了8条指令，而且随N的增加，指令数不变，指令所占的存储单元大大减少。有的机器(如Intel8086、VAX-11)的变址寻址具有自动变址的功能，即每存取一个数据，根据数据长度(即所占字节数)，变址寄存器能自动增量或减量，以便形成下一个数据的地址。变址寻址还可以与其他寻址方式结合使用。例如，变址寻址可与基址寻址合用，此时有效地址EA等于指令字中的形式地址A和变址寄存器IX的内容(IX)及基址寄存器BR中的内容(BR)相加之和,即EA=A+(IX)+(BR)变址寻址还可与间接寻址合用，形成先变址后间址或先间址再变址等寻址方式，读者在使用各类机器时可注意分析。相对寻址的有效地址是将程序计数器PC的内容(即当前指令的地址)与指令字中的形式地址A相加而成，即EA=(PC)+A图7.17示意了相对寻址的过程，由图中可见，操作数的位置与当前指令的位置有一段距离A。相对寻址常被用于转移类指令，转移后的目标地址与当前指令有一段距离，称为相对位移量，它由指令字的形式地址A给出，故A又称位移量。位移量A可正可负，通常用补码表示。倘若位移量为8位,则指令的寻址范围在(PC)+127~(PC)-128之间。相对寻址的最大特点是转移地址不固定，它可随PC值的变化而变，因此，无论程序在主存的哪段区域，都可正确运行，对于编写浮动程序特别有利。例如，表7.2中有一条转移指令“BNEM”,它存于M+3单元内,也即⋮MADDX,DM+1INXM+2CPX#NM+3BNEM显然，随程序首地址改变，M也改变。如果采用相对寻址，将“BNEM”改写为“BNE*-3”(*为相对寻址特征)，就可使该程序浮动至任一地址空间都能正常运行。因为从第M+3条指令转至第M条指令，其相对位移量为-3，故当执行第M+3条指令“BNE*-3”时，其有效地址为EA=(PC)+(-3)=M+3-3=M直接指向了转移后的目标地址。相对寻址也可与间接寻址配合使用。例7.2设相对寻址的转移指令占3个字节，第一字节为操作码，第二、三字节为相对位移量(补码表示)，而且数据在存储器中采用以低字节地址为字地址的存放方式。每当CPU从存储器取出一个字节时，即自动完成(PC)+1→PC。(1)若PC当前值为240(十进制)，要求转移到290(十进制)，则转移指令的第二、三字节的机器代码是什么?(2)若PC当前值为240(十进制)，要求转移到200(十进制)，则转移指令的第二、三字节的机器代码是什么?解：(1)PC当前值为240，该指令取出后PC值为243，要求转移到290，即相对位移量为290-243=47，转换成补码为2FH。由于数据在存储器中采用以低字节地址为字地址的存放方318第3篇中央处理器式，故该转移指令的第二字节为2FH，第三字节为00H。(2)PC当前值为240,该指令取出后PC值为243,要求转移到200,即相对位移量为200-243=-43，转换成补码为D5H，由于数据在存储器中采用以低字节地址为字地址的存放方式，故该转移指令的第二字节为D5H，第三字节为FFH。10.堆栈寻址堆栈寻址要求计算机中设有堆栈。堆栈既可用寄存器组(称为硬堆栈)来实现，也可利用主存的一部分空间作堆栈(称为软堆栈)。堆栈的运行方式为先进后出或先进先出两种，先进后出型堆栈的操作数只能从一个口进行读或写。以软堆栈为例，可用堆栈指针SP(StackPoint)指出栈顶地址，也可用CPU中一个或两个寄存器作为SP。操作数只能从栈顶地址指示的存储单元存或取。可见堆栈寻址也可视为一种隐含寻址，其操作数的地址总被隐含在SP中。堆栈寻址就其本质也可视为寄存器间接寻址，因SP可视为寄存器，它存放着操作数的有效地址。图7.18示意了堆栈寻址过程。图7.18(a)、(b)分别表示进栈“PUSHA”和出栈“POPA”的过程。由于SP始终指示着栈顶地址，因此不论是执行进栈(PUSH)，还是出栈(POP)，SP的内容都需要发生变化。若栈底地址大于栈顶地址，则每次进栈(SP)-Δ→SP；每次出栈(SP)+Δ→SP。Δ取值与主存编址方式有关。若按字编址，则Δ取1(如图7.18所示)；若按字节编址，则需根据存储字长是几个字节构成才能确定Δ，例如字长为16位，则Δ=2，字长为32位,Δ=4。例7.3一条双字长直接寻址的子程序调用指令，其第一个字为操作码和寻址特征，第二个字为地址码5000H。假设PC当前值为2000H,SP的内容为0100H,栈顶内容为2746H,存储器按字节编址，而且进栈操作是先执行(SP)-Δ→SP，后存入数据。试回答下列几种情况下，PC、SP及栈顶内容各为多少?(1)CALL指令被读取前。(2)CALL指令被执行后。(3)子程序返回后。解:(1)CALL指令被读取前,PC=2000H,SP=0100H,栈顶内容为2746H。(2)CALL指令被执行后，由于存储器按字节编址，CALL指令共占4个字节，故程序断点2004H进栈,此时SP=(SP)-2=00FEH,栈顶内容为2004H,PC被更新为子程序入口地址5000H。(3)子程序返回后,程序断点出栈,PC=2004H,SP被修改为0100H,栈顶内容为2746H。由于当前计算机种类繁多，各类机器的寻址方式均有各自的特点，还有些机器的寻址方式可能本书并未提到，故读者在使用时需自行分析，以利于编程。从高级语言角度考虑问题，机器指令的寻址方式对用户无关紧要，但一旦采用汇编语言编程，用户只有了解并掌握机器的寻址方式，才能正确编程，否则程序将无法正常运行。如果读者参与机器的指令系统设计，则了解寻址方式对确定机器指令格式是不可缺少的。从另一角度来看，倘若透彻了解了机器指令的寻址方式，将会使读者进一步加深对机器内信息流程及整机工作概念的理解。指令格式不仅体现了指令系统的各种功能，而且也突出地反映了机器的硬件结构特点。设计指令格式时必须从诸多方面综合考虑，并经一段模拟运行后，最后确定。指令系统集中反映了机器的性能，又是程序员编程的依据。用户在编程时既希望指令系统很丰富，便于用户选择，同时还要求机器执行程序时速度快、占用主存空间少，实现高效运行。此外，为了继承已有的软件，必须考虑新机器的指令系统与同一系列机器指令系统的兼容性，即高档机必须能兼容低档机的程序运行，称之为“向上兼容”。指令格式集中体现了指令系统的功能，为此，在确定指令格式时，必须从以下几个方面综合考虑。①操作类型：包括指令数及操作的难易程度。②数据类型：确定哪些数据类型可以参与操作。③指令格式：包括指令字长、操作码位数、地址码位数、地址个数、寻址方式类型，以及指令字长和操作码位数是否可变等。④寻址方式：包括指令和操作数具体有哪些寻址方式。⑤寄存器个数：寄存器的多少直接影响指令的执行时间。不同机器的指令格式可以有很大的差别，本书不可能将各种机器的指令格式都做介绍，只能列举几种较为典型的格式供读者学习。PDP-8的指令字长统一为12位，CPU内只设一个通用寄存器，即累加器ACC，其主存被划分为若干个容量相等的存储空间(每个相同的空间被称为一页)。该机的指令格式可分为三大类，如图7.19所示。访存类指令属一地址指令。0~2位为操作码(只定义了000~101六种基本操作)；3、4两位为寻址特征位，其中3位表示是否间接寻址，4位表示是当前页面(即PC指示的页面)还是0页面；5~11位为地址码。为了扩大操作种类，对应操作码“111”又配置了辅助操作码，构成了寄存器类指令，这类指令主要对ACC进行各种操作，如清A、对A取反、对A移位、对A加1、根据A的结果是否跳转等。辅助操作码的每一位都有一个明确的操作。第三类指令是I/O类，用0~2位为110作标志，其具体操作内容由9~11位反映，3~8位表示设备号，总共可选64种设备。PDP-8指令格式支持间接寻址、变址寻址、相对寻址。加上操作码扩展技术，共有35条指令。PDP-11机器字长为16位，CPU内设8个16位通用寄存器，其中两个通用寄存器有特殊作用，一个用作堆栈指针SP，一个用作程序计数器PC。PDP-11指令字长有16位、32位和48位三种，采用操作码扩展技术，使操作码位数不固定，指令字的地址格式有零地址、一地址、二地址等共有13类指令格式，图7.20列出了其中五种。图中(a)为零地址格式；(b)为一地址格式，其中6位目的地址码中的3位为寻址特征位，另外3位表示8个寄存器中的任一个；(c)、(d)、(e)均为二地址格式指令，但操作数来源不同，有寄存器-寄存器型、寄存器-存储器型和存储器-存储器型。PDP-11指令系统和寻址方式比较复杂，既增加了硬件的价格，又增加了编程的复杂度，但好处是能编出非常高效的程序。IBM360属于系列机。所谓系列机，是指其基本指令系统相同，基本体系结构相同的一系列计算机。IBM370对IBM360是完全向上兼容的。所以IBM370可看作IBM360的扩展、延伸或改进。IBM360是32位机器，按字节寻址，并可支持多种数据类型，如字节、半字、字、双字(双精度实数)、压缩十进制数、字符串等。在CPU中有16个32位通用寄存器(用户可选定任一个寄存器作为基址寄存器BR或变址寄存器IX)，4个双精度(64位)浮点寄存器。指令字长有16位、32位、48位三种,如图7.21所示。图中共画出了五种指令格式，它们的操作码位数均为8位。RR格式是寄存器-寄存器格式，两个操作数均在寄存器中，完成(R₁)OP(R₂)→R₁的操作。RX是二地址格式的寄存器-存储器型指令，一个操作数在寄存器中，另一个操作数在存储器中，其有效地址由变址(X)和基址(B)寻址方式求得，可以完成(R₁)OPM[(X)+(B)+D]→R₁的操作。RS格式是三地址格式的寄存器-存储器型指令，完成((R₃)OPM[(B)+D]→R₁操作。SI格式中的Ⅰ为立即数，它完成立即数→M[(B)+D]的操作。SS格式是存储器-存储器型指令，两个操作数均在存储器，这类指令用于十进制运算和字符串处理，数据长度字段L可定义一个长度(1~256个字符)或两个长度(每一个为1~16个十进制数)，它完成M[(B₁)+D₁]OPM[(B₂)+D₂]→M[(B₁)+D₁]的操作。Intel8086/80486系列微型计算机的指令字长为1~6个字节，即不定长。例如，零地址格式的空操作指令NOP只占一个字节；一地址格式的CALL指令可以是3字节(段内调用)或5字节(段间调用)；二地址格式指令中的两个操作数既可以是寄存器-寄存器型、寄存器-存储器型，也可以是寄存器-立即数型或存储器-立即数型，它们所占的字节数分别为2、2~4、2~3、3~6个字节。有关该系列机的指令格式，读者可以查阅有关资料自行分析。例7.4某机字长16位，存储器直接寻址空间为128字，变址时的位移量为-64~+63，16个通用寄存器均可作为变址寄存器。设计一套指令系统格式，满足下列寻址类型的要求。(1)直接寻址的二地址指令3条。(2)变址寻址的一地址指令6条。(3)寄存器寻址的二地址指令8条。(4)直接寻址的一地址指令12条。(5)零地址指令32条。试问还有多少种代码未用?若安排寄存器寻址的一地址指令，还能容纳多少条?解：(1)在直接寻址的二地址指令中，根据题目给出直接寻址空间为128字，则每个地址码为7位，其格式如图7.22(a)所示。3条这种指令的操作码为00、01和10，剩下的11可作为下一种格式指令的操作码扩展用。(2)在变址寻址的一地址指令中，根据变址时的位移量为-64~+63，形式地址A取7位。根据16个通用寄存器可作为变址寄存器，取4位作为变址寄存器Rₓ的编号。剩下的5位可作操作码，其格式如图7.22(b)所示。6条这种指令的操作码为11000~11101，剩下的两个编码11110和11111可作为扩展用。(3)在寄存器寻址的二地址指令中，两个寄存器地址R₁和R₁共8位，剩下的8位可作操作码，比格式(b)的操作码扩展了3位，其格式如图7.22(c)所示。8条这种指令的操作码为11110000~11110111。剩下的11111000~11111111这8个编码可作为扩展用。(4)在直接寻址的一地址指令中，除去7位的地址码外，可有9位操作码，比格式(c)的操作码扩展了1位，与格式(c)剩下的8个编码组合，可构成16个9位编码。以11111作为格式(d)指令的操作码特征位,12条这种指令的操作码为111110000~111111011,如图7.22(d)所示。剩下的111111100~111111111可作为扩展用。(5)在零地址指令中，指令的16位都作为操作码，比格式(d)的操作码扩展了7位，与上述剩下的4个操作码组合后，共可构成4×2⁷条指令的操作码。32条这种指令的操作码可取1111111000000000~1111111000011111,如图7.22(e)所示。还有2⁹-32=480种代码未用，若安排寄存器寻址的一地址指令，除去末4位为寄存器地址外，还可容纳30条这类指令。例7.5设某机配有基址寄存器和变址寄存器，采用一地址格式的指令系统，允许直接和间接寻址，且指令字长、机器字长和存储字长均为16位。(1)若采用单字长指令，共能完成105种操作，则指令可直接寻址的范围是多少?一次间接寻址的寻址范围是多少?画出其指令格式并说明各字段的含义。(2)若存储字长不变，可采用什么方法直接访问容量为16MB的主存?且有基址寄存器和变址寄存器，故取2位寻址特征位，其指令格式如下：727OPMAD其中，OP为操作码，可完成105种操作；M为寻址特征，可反映四种寻址方式；AD为形式地址。这种指令格式可直接寻址2⁷=128,一次间接寻址的寻址范围是2¹⁶=65536。(2)容量为16MB的存储器，正好与存储字长为16位的8M存储器容量相等，即16MB=8M×16位。欲使指令直接访问16MB的主存，可采用双字长指令，其操作码和寻址特征位均不变，其格式如下：727OPMAD₁AD₂其中，形式地址为AD₁‖AD₂,,共7+16=23位。2²³=8M,即可直接访问主存的任一位置。例7.6某模型机共有64种操作，操作码位数固定，且具有以下特点。(1)采用一地址或二地址格式。(2)有寄存器寻址、直接寻址和相对寻址(位移量为-128∼+127)三种寻址方式。(3)有16个通用寄存器，算术运算和逻辑运算的操作数均在寄存器中，结果也在寄存器中。(4)取数/存数指令在通用寄存器和存储器之间传送数据。(5)存储器容量为1MB，按字节编址。要求设计算逻指令、取数/存数指令和相对转移指令的格式，并简述理由。解：(1)算逻指令格式为寄存器-寄存器型，取单字长16位。6244OPMRiRj其中，OP为操作码，6位，可实现64种操作；M为寻址模式，2位，可反映寄存器寻址、直接寻址、相对寻址；Rᵢ和Rⱼ各取4位，指出源操作数和目的操作数的寄存器(共16个)编号。(2)取数/存数指令格式为寄存器-存储器型，取双字长32位，格式如下：6244OPMRiA₁A₂其中，OP为操作码，6位不变；M为寻址模式，2位不变；Rᵢ为4位，源操作数地址(存数指令)或目的操作数地址(取数指令)；A₁和A₂共20位，为存储器地址，可直接访问按字节编址的1MB存储器。(3)相对转移指令为一地址格式，取单字长16位，格式如下：628OPMA其中，OP为操作码，6位不变；M为寻址模式，2位不变；A为位移量8位，对应位移量为-128~+127。例7.7设某机共能完成110种操作，CPU有8个通用寄存器(16位)，主存容量为4M字，采用寄存器-存储器型指令。(1)欲使指令可直接访问主存的任一地址，指令字长应取多少位?画出指令格式。(2)若在上述设计的指令字中设置一寻址特征位X，且X=1表示某个寄存器作基址寄存器，画出指令格式。试问基址寻址可否访问主存的任一单元?为什么?如果不能，提出一种方案，使其可访问主存的任一位置。(3)若主存容量扩大到4G字，且存储字长等于指令字长，则在不改变上述硬件结构的前提下，可采用什么方法使指令可访问存储器的任一位置?解：(1)欲使指令可直接访问4M字存储器的任一单元，采用寄存器-存储器型指令，该机指令应包括22位的地址码、3位寄存器编号和7位操作码，即指令字长取22+3+7=32位，指令格式如下：7322OPRA(2)在上述指令格式中增设一寻址特征位，且X=1表示某个寄存器作基址寄存器RB。其指令格式如下：731318OPRxRBA由于通用寄存器仅16位，形式地址18位，不足以覆盖4M地址空间，可将RB寄存器内容左移6位，低位补0，形成22位基地址，然后与形式地址相加，所得的有效地址即可访问4M字存储器的任一单元。(3)若主存容量扩大到4G字，且存储字长等于指令字长，则在不改变上述硬件结构的前提下，采用一次间接寻址即可访问存储器的任一单元，因为间接寻址后得到的有效地址为32位，2³²=4G。RISC即精简指令系统计算机(ReducedInstructionSetComputer),与其对应的是CISC,即复杂指令系统计算机(ComplexInstructionSetComputer)。计算机发展至今，机器的功能越来越强，硬件结构越来越复杂。尤其是随着集成电路技术的发展及计算机应用领域的不断扩大，计算机系统的软件价格相对而言在不断提高。为了节省开销，人们希望已开发的软件能被继承、兼容，这就希望新机种的指令系统和寻址方式一定能包含旧机种所有的指令和寻址方式。通过向上兼容不仅可降低新机种的开发周期和代价，还可吸引更多的新、老用户，于是出现了同类型的系列机。在系列机的发展过程中，致使同一系列计算机指令系统变得越来越复杂，某些机器的指令系统竟可包含几百条指令。例如，DEC公司的VAX-11/780有16种寻址方式、9种数据格式、303条指令。又如，32位的68020微型计算机指令种数比6800多两倍，寻址方式多11种，达18种之多，指令长度从一个字(16位)发展到16个字。这类机器被称为复杂指令系统计算机，简称CISC。通常对指令系统的改进都是围绕着缩小与高级语言语义的差异和有利于操作系统的优化而进行的。由于编写编译器的人们的任务是为每一条高级语言的语句编制一系列的机器指令，如果机器指令能类似于高级语言的语句，显然编写编译器的任务就变得十分简单了。于是人们产生了用增加复杂指令的办法来缩短与语义的差距。后来又发现，倘若编译器过多依赖复杂指令，同样会出现新的矛盾。例如，对减少机器代码、降低指令执行数以及为提高流水性能而优化生成代码等都是非常不利的。尤其当指令过于复杂时，机器的设计周期会很长，资金耗费会更大。例如，Intel8038632位机器耗资达1.5亿美元，开发时间长达三年多，结果正确性还很难保证，维护也很困难。最值得一提的例子是，1975年IBM公司投资10亿美元研制的高速机器FS机，最终以“复杂结构不宜构成高速计算机”的结论宣告研制失败。为了解决这些问题，20世纪70年代中期，人们开始进一步分析研究CISC，发现一个80-20规律，即典型程序中80%的语句仅仅使用处理机中20%的指令，而且这些指令都是属于简单指令，如取数、加、转移等。这一点告诫人们，付出再大的代价增添复杂指令，也仅有20%的使用概率，而且当执行频度高的简单指令时，因复杂指令的存在，致使执行速度也无法提高。表7.3是HP公司对IBM370高级语言中指令使用频度的分析结果。Marathe在1978年对PDP-11机在五种不同应用领域中的指令进行混合测试，也得出了类似的结论。另一方面，在20世纪70年代末80年代初，计算机的器件已进入VLSI时代，复杂的指令系统需要复杂的控制器，这需要占用较多的芯片面积。统计表明，典型的CISC计算机中，控制器约占60%的芯片面积，而且使设计、验证和实现都更加困难。人们从80-20规律中得到启示：能否仅仅用最常用的20%的简单指令，重新组合不常用的80%的指令功能呢?这便引发出RISC技术。1975年IBM公司JohnCocke提出了精简指令系统的设想,1982年美国加州大学伯克利分校的研究人员专门研究了如何有效利用VLSIC(超大规模集成电路)的有效空间。RISC由于设计的指令条数有限，相对而言，它只需用较小的芯片空间便可制作逻辑控制电路，更多的芯片空间可用来增强处理机的性能或使其功能多样化。他们用大部分芯片空间做成寄存器，并且用它们作为暂时数据存储的快速存储区，从而有效地降低了RISC机器在调用子程序时所需付出的时间。他们研制的RISCⅠ(后来又出现RISCⅡ)，采用VLSICPU芯片上的晶体管数量达44000个，线宽为3μm，字长为32位，其中有128个寄存器(而用户只能见到32个)，仅有31条指令和两种寻址方式，访存指令只有两条，即取数(LOAD)和存数(STORE)。显然其指令系统极为简单,但它们的功能已超过VAX-11/780和M68000,其速度比VAX-11/780快了1倍。与此同时,美国斯坦福大学RISC研究的课题是MIPS(MicroProcessorwithoutInterlockingPipelineStages)，即消除流水线各段互锁的微处理器。他们把IBM公司对优化编译程序的研究与加州大学伯克利分校对VLSI有效空间利用的思想结合在一起，最终的研究成果后来转化为MIPS公司RX000的系列产品。IBM公司又继其IBM801型机、IBMRT/PC后,于1990年推出了著名的IBMRS/6000系列产品。加州大学伯克利分校的研究成果最后发展成Sun微系统公司的RISC芯片,称为SPARC(ScalableProcessorARChitecture)。到目前为止，RISC体系结构的芯片可以说已经历了3代：第一代以32位数据通路为代表，支持Cache,软件支持较少,性能与CISC体系结构的产品相当,如RISCⅠ、MIPS、IBM801等。第二代产品提高了集成度，增加了对多处理机系统的支持，提高了时钟频率，建立了完善的存储管理体系，软件支持系统也逐渐完善。它们已具有单指令流水线，可同时执行多条指令，每个时钟周期发出一条指令(有关流水线的概念详见8.3节)。例如，MIPS公司的R3000处理器，时钟频率为25MHz和33MHz,集成度达11.5万个晶体管,字长为32位。第三代RISC产品为64位微处理器，采用了巨型计算机或大型计算机的设计技术——超级流水线(Superpipelining)技术和超标量(Superscalar)技术，提高了指令级的并行处理能力，每个时钟周期发出2条或3条指令，使RISC处理器的整体性能更好。例如,MIPS公司的R4000处理器采用50MHz和75MHz的外部时钟频率，内部流水时钟达100MHz和150MHz，芯片集成度高达110万个晶体管，字长64位，并有16KB的片内Cache。它有R4000PC、R4000SC和R4000MC三种版本,对应不同的时钟频率，分别提供给台式系统、高性能服务器和多处理器环境下使用。表7.4列出了MIPS公司R系列RISC处理器的几项指标。自1983年开始出现商品化的RISC机以来,比较著名的RISC机有IBM公司的IBMRT系列,HP公司的精密结构计算机(HPPA)、MIPSR3000、MotorolaM88000、Intel80960、INMOSTransputer、AMDAM29000、FairchildClipper等。其中,Clipper兼顾了RISC和CISC两方面的特点,又称为类RISC机。在计算机工作站方面,SunMicrosystems公司于1987年推出SPARC,速度达7~10MIPS。1988年Apollo公司推出Series10000个人超级计算机,称为并行精简指令系统多处理机PRISM(ParallelReducedInstructionSetMultiprocessor),单机系统速度达15~25MIPS,四处理机则可达60~100MIPS,后来HP合并了Apollo公司,继续发展工作站。较为著名的第三代RISC机的有关性能指标如表7.5所示。由上分析可知，RISC技术是用20%的简单指令的组合来实现不常用的80%的那些指令功能，但这不意味着RISC技术就是简单地精简其指令集。在提高性能方面，RISC技术还采取了许多有效措施，最有效的方法就是减少指令的执行周期数。计算机执行程序所需的时间P可用下式表述：P=I×C×T其中，I是高级语言程序编译后在机器上运行的机器指令数；C为执行每条机器指令所需的平均机器周期；T是每个机器周期的执行时间。表7.6列出了第二代RISC机与CISC机的I、C、T统计,其中I、T为比值,C为实际周期数。由于RISC指令比较简单，用这些简单指令编制出的子程序来代替CISC机中比较复杂的指令,因此RISC中的I比CISC多20%~40%。但RISC的大多数指令仅用一个机器周期完成,C的.值比CISC小得多。而且RISC结构简单，完成一个操作所经过的数据通路较短，使T值也大大下降。因此总折算结果，RISC的性能仍优于CISC2~5倍。由于计算机的硬件和软件在逻辑上的等效性，使得指令系统的精简成为可能。曾有人在1956年就证明，只要用一条“把主存中指定地址的内容同累加器中的内容求差，把结果留在累加器中并存入主存原来地址中”的指令，就可以编出通用程序。又有人提出，只要用一条“条件传送(CMOVE)”指令就可以做出一台计算机；并且在1982年某大学做出了一台8位的CMOVE系统结构样机，称为SIC(单指令计算机)。而且，指令系统所精简的部分可以通过其他部件以及软件(编译程序)的功能来替代，因此，实现RISC技术是完全可能的。通过对RISC各种产品的分析，可归纳出RISC机应具有如下一些特点。①选取使用频度较高的一些简单指令以及一些很有用但又不复杂的指令，让复杂指令的功能由频度高的简单指令的组合来实现。②指令长度固定，指令格式种类少，寻址方式种类少。③只有取数/存数(LOAD/STORE)指令访问存储器，其余指令的操作都在寄存器内完成。④CPU中有多个通用寄存器。⑤采用流水线技术，大部分指令在一个时钟周期内完成。采用超标量和超流水线技术，可使每条指令的平均执行时间小于一个时钟周期。⑥控制器采用组合逻辑控制，不用微程序控制。⑦采用优化的编译程序。值得注意的是，商品化的RISC机通常不会是纯RISC机，故上述这些特点不是所有RISC机全部具备的。相比之下，CISC的指令系统复杂庞大，各种指令使用频度相差很大；指令字长不固定，指令格式多，寻址方式多；可以访存的指令不受限制；CPU中设有专用寄存器；绝大多数指令需要多个时钟周期方可执行完毕；采用微程序控制器；难以用优化编译生成高效的目标代码。表7.7列出了一些RISC机指令系统的指令条数。下面以RISCⅡ为例，着重分析其指令种类和指令格式。(1)指令种类RISCⅡ共有39条指令,分为以下4类。①寄存器-寄存器操作：移位、逻辑、算术(整数)运算等12条。②取/存数指令：取存字节、半字、字等16条。③控制转移指令：条件转移、调用/返回等6条。④其他：存取程序状态字PSW和程序计数器等5条。在RISCⅡ机中，有一些常用指令未被选中，但用上述这些指令并在硬件系统的辅助下，足以实现其他一些指令的功能。例如，该机约定R₀寄存器内容恒为0，这样加法指令可替代寄存器间的传送指令，即(R_{n})+(R_{o})\rightarrowR_{d},替代了R.→Rd加法指令还可替代清除寄存器指令，即(R_{0})+(R_{0})\rightarrowR_{d},替代了0→Rd减法指令可替代取负数指令，即(R_{0})-(R_{s})\rightarrowR_{d},替代了Rd寄存器内容取负此外，该机可用立即数作为一个操作数，这样当立即数取1时，再用加法(或减法)指令就可替代寄存器内容增1(减1)指令，即(R,)+1\rightarrowR_{d}当立即数取-1时，异或指令可替代求反码指令，即R,\oplus(-1)\rightarrowR_{d}替代\overline{R}_{\bullet}\rightarrowR_{d}(2)指令格式RISC机的指令格式比较简单，寻址方式也比较少，如RISCⅡ的指令格式有两种：短立即数格式和长立即数格式。指令字长固定为32位，指令字中每个字段都有固定位置，如图7.23所示。短立即数格式指令主要用于算逻运算，其中第31位~25位为操作码；两个操作数一个在rs₁中，另一个操作数的来源由指令的第13位决定。当其为0时(如图7.23(a)所示)，第二个操作数在寄存器rs₂中(只用0~4位)；当其为1时(如图7.23(b)所示)，第二个操作数为13位的立即数imm₁₃。运算结果存放在DEST所指示的寄存器r₄中(共32个)。指令字中的第24位S用来表示是否需要根据运算结果置状态位，S=1表示置状态位。RISCⅡ机有4个状态位，即零标志位Z、负标志位N、溢出标志位V、进位标志位C。指令中的DEST字段在条件转移指令中用第22~19位作为转移条件，第23位无用。对于图7.23(b)所示的短立即数指令格式，其imm₁₃即为相对转移位移量。长立即数指令格式主要用于相对转移指令，此时19位的立即数imm₁₉指出转移指令的相对位移量，与13位相比，可扩大相对于PC的转移距离。(3)寻址方式RISCⅡ指令系统有两种访存寻址方式。一种是变址寻址，另一种是相对寻址，还可用组合方式产生其他寻址方式。若令变址寄存器内容为0(因该机约定寄存器R₀内容恒为0，所以只要指定R₀作为变址寄存器即可实现)，则成为直接寻址方式；若令位移量为0，则成为寄存器间接寻址方式。对于LOAD指令，可根据计算所得的有效地址，从存储器中读取数据并送入DEST字段中指示的目的寄存器中。如短立即数指令有效地址为((rs₁)+(rs₂),或为(rs₁)+imm₁₃。对于STORE指令，是将DEST字段指示的源寄存器中的数取出并存入存储器中，有效地址的计算与LOAD指令相同。从实用角度出发，商品化的RISC机，因用途不同还可扩充一些指令，例如：①浮点指令，用于科学计算的RISC机。为了提高机器速度而增设浮点指令。②特权指令，为了便于操作系统管理机器，防止用户破坏机器的运行环境而特设特权指令。③读后置数指令，完成读一修改一写，用于寄存器与存储单元交换数据等。④一些简单的专用指令。例如，某些指令用得较多，实现起来又比较复杂，若用子程序来实现，占用较多的时间，则可考虑设置一条指令来缩短子程序执行时间。有些机器用乘法步指令来加快乘法运算的执行速度。与CISC机相比，RISC机的主要优点可归纳如下：CISC机的控制器大多采用微程序控制(详见第10章)，其控制存储器在CPU芯片内所占的面积为50%以上(如Motorola公司的MC68020占68%)。而RISC机控制器采用组合逻辑控制(详见第10章)，其硬布线逻辑只占CPU芯片面积的10%左右。可见它可将空出的面积供其他功能部件用，例如用于增加大量的通用寄存器(如Sun微系统公司的SPARC有100多个通用寄存器)，或将存储管理部件也集成到CPU芯片内(如MIPS公司的R2000/R3000)。以上两种芯片的集成度分别小于10万个和20万个晶体管。随着半导体工艺技术的提高，集成度可达100万至几百万个晶体管，此时无论是CISC还是RISC都将多个功能部件集成在一个芯片内。但此时RISC已占领了市场，尤其是在工作站领域占有明显的优势。RISC机能提高运算速度，主要反映在以下5个方面。①RISC机的指令数、寻址方式和指令格式种类较少，而且指令的编码很有规律，因此RISC的指令译码比CISC的指令译码快。②RISC机内通用寄存器多，减少了访存次数，可加快运行速度。③RISC机采用寄存器窗口重叠技术，程序嵌套时不必将寄存器内容保存到存储器中，故又提高了执行速度。④RISC机采用组合逻辑控制，比采用微程序控制的CISC机的延迟小，缩短了CPU的周期。⑤RISC机选用精简指令系统，适合于流水线工作，大多数指令在一个时钟周期内完成。RISC机指令系统简单，故机器设计周期短，如美国加州大学伯克利分校的RISCI机从设计到芯片试制成功只用了十几个月，而Intel80386处理器(CISC)的开发花了三年半时间。RISC机逻辑简单，设计出错可能性小，有错时也容易发现，可靠性高。RISC机靠优化编译来更有效地支持高级语言程序。由于RISC指令少，寻址方式少，使编译程序容易选择更有效的指令和寻址方式，而且由于RISC机的通用寄存器多，可尽量安排寄存器的操作，使编译程序的代码优化效率提高。例如，IBM的研究人员发现，IBM801(RISC机)产生的代码大小是IBMS/370(CISC机)的90%。有些RISC机(如Sun公司的SPARC)采用寄存器窗口重叠技术，使过程间的参数传送加快，且不必保存与恢复现场，能直接支持调用子程序和过程的高级语言程序。表7.8列出了一些CISC与RISC微处理器的特征。此外，从指令系统兼容性看，CISC大多能实现软件兼容，即高档机包含了低档机的全部指令，并可加以扩充。但RISC机简化了指令系统，指令数量少，格式也不同于老机器，因此大多数RISC机不能与老机器兼容。PowerPC是IBM、Apple、Motorola三家公司于1991年联合,用Motorola的芯片制造经验、Apple的微型计算机软件支持、IBM的体系结构及其世界计算机市场霸主的地位，向长期被Intel占据的微处理器市场挑战而开发的RISC产品。PowerPC中的“PC”意为“PowerfulChip”,其中“Power”基于20世纪80年代后期,IBM在其801小型机的基础上开发的工作站和服务器中的Power体系,意为“PerformanceOptimizationWithEnhancedRISC(性能优化的增强型RISC)”。PowerPC具有超高的性能、价廉、易仿真CISC指令集、可运行大量的现代CISC计算机应用软件，即集工作站的卓越性能、PC机的低成本及运行众多的软件等优点于一身。此外，PowerPC扩展性强，可覆盖PDA(个人数字助理)到多处理、超并行的中大型机，用单芯片提供整个解决方案。多年来计算机体系结构和组织发展的趋势是增加CPU的复杂性，即使用更多的寻址方式及更加专门的寄存器等。RISC的出现象征着与这种趋势根本决裂，自然地引起了RISC与CISC的争端。随着技术不断发展，RISC与CISC还不能说是截然不同的两大体系，很难对它们做出明确的评价。最近几年，RISC与CISC的争端已减少了很多。原因在于这两种技术已逐渐融合。特别是芯片集成度和硬件速度的增加，RISC系统也越来越复杂。与此同时，在努力挖掘最大性能的过程中，CISC的设计已集中到和RISC相关联的主题上来，例如增加通用寄存器数以及更加强调指令流水线设计，所以更难去评价它们的优越性了。RISC技术发展很快,有关RISC体系结构、RISC流水、RISC编译系统、RISC、CISC和VLIW(VeryLongInstructionWord,超长指令字)技术的融合等方面的资料不少。读者若想深入了解,可以查阅有关文献。由第1章可知，CPU实质包括运算器和控制器两大部分，第6章讨论了计算机内各种运算及相应的硬件配置，这里重点介绍控制器的功能。对于冯·诺依曼结构的计算机而言，一旦程序进入存储器后，就可由计算机自动完成取指令和执行指令的任务，控制器就是专用于完成此项工作的，它负责协调并控制计算机各部件执行程序的指令序列，其基本功能是取指令、分析指令和执行指令。控制器必须具备能自动地从存储器中取出指令的功能。为此，要求控制器能自动形成指令的地址，并能发出取指令的命令，将对应此地址的指令取到控制器中。第一条指令的地址可以人为指定，也可由系统设定。分析指令包括两部分内容：其一，分析此指令要完成什么操作，即控制器需发出什么操作命令；其二，分析参与这次操作的操作数地址，即操作数的有效地址。执行指令就是根据分析指令产生的“操作命令”和“操作数地址”的要求，形成操作控制信号序列(不同的指令有不同的操作控制信号序列)，通过对运算器、存储器以及I/O设备的操作，执行每条指令。此外，控制器还必须能控制程序的输入和运算结果的输出(即控制主机与I/O设备交换信息)以及对总线的管理，甚至能处理机器运行过程中出现的异常情况(如掉电)和特殊请求(如打印机请求打印一行字符)，即处理中断的能力。总之，CPU必须具有控制程序的顺序执行(称指令控制)、产生完成每条指令所需的控制命令(称操作控制)、对各种操作加以时间上的控制(称时间控制)、对数据进行算术运算和逻辑运算(数据加工)以及处理中断等功能。根据CPU的功能不难设想，要取指令，必须有一个寄存器专用于存放当前指令的地址；要分析指令，必须有存放当前指令的寄存器和对指令操作码进行译码的部件；要执行指令，必须有一个能发出各种操作命令序列的控制部件CU；要完成算术运算和逻辑运算，必须有存放操作数的寄存器和实现算逻运算的部件ALU；为了处理异常情况和特殊请求，还必须有中断系统。可见，CPU可由四大部分组成，如图8.1所示。将图8.1细化，又可得图8.2。图中ALU部件实际上只对CPU内部寄存器的数据进行操作，有关ALU的内容已在第6章中有所介绍。第4章图4.2示出了存储器速度、容量和位价的关系，最上层的寄存器速度最快，容量最小，位价最贵，它们通常设在CPU内部。CPU中的寄存器大致可分两类：一类属于用户可见寄存器，用户可对这类寄存器编程，以及通过优化使CPU因使用这类寄存器而减少对主存的访问次数；另一类属于控制和状态寄存器，用户不可对这类寄存器编程，它们被控制部件使用，以控制CPU的操作，也可被带有特权的操作系统程序使用，从而控制程序的执行。通常CPU执行机器语言访问的寄存器为用户可见寄存器，按其特征又可分为以下几类。(1)通用寄存器通用寄存器可由程序设计者指定许多功能，可用于存放操作数，也可作为满足某种寻址方式所需的寄存器。例如，基址寻址所需的基址寄存器、变址寻址所需的变址寄存器和堆栈寻址所需的栈指针，都可用通用寄存器代替。寄存器间接寻址时还可用通用寄存器存放有效地址的地址。当然，也有一些机器用专用寄存器作为基址寄存器、变址寄存器或栈指针，这样，在设计指令格式时只需将这类专用寄存器隐含在操作码中，而不必占用指令字中的位。图7.15(a)所示的就是用专用寄存器作为基址寄存器，而图7.15(b)是用通用寄存器作为基址寄存器，所以指令字中必须有R字段指出寄存器编号。又如图7.21所示的IBM360/370指令格式中，由于用通用寄存器作为变址寄存器和基址寄存器，故在指令字中设有X和B字段，分别指出作为变址寄存器和基址寄存器的通用寄存器编号。(2)数据寄存器数据寄存器用于存放操作数，其位数应满足多数数据类型的数值范围，有些机器允许使用两个连读的寄存器存放双倍字长的值。还有些机器的数据寄存器只能用于保存数据，不能用于操作数地址的计算。(3)地址寄存器地址寄存器用于存放地址，其本身可以具有通用性，也可用于特殊的寻址方式，如用于基址寻址的段指针(存放基地址)、用于变址寻址的变址寄存器和用于堆栈寻址的栈指针。地址寄存器的位数必须足够长，以满足最大的地址范围。(4)条件码寄存器这类寄存器中存放条件码，它们对用户来说是部分透明的。条件码是CPU根据运算结果由硬件设置的位，例如，算术运算会产生正、负、零或溢出等结果。条件码可被测试，作为分支运算的依据。此外，有些条件码也可被设置，例如，对于最高位进位标志C，可用指令对它置位和复位。将条件码放到一个或多个寄存器中，就构成了条件码寄存器。在调用子程序前，必须将所有的用户可见寄存器的内容保存起来，这种保存可由CPU自动完成，也可由程序员编程保存，视不同机器进行不同处理。CPU中还有一类寄存器用于控制CPU的操作或运算。在一些机器里，大部分这类寄存器对用户是透明的。如以下四种寄存器在指令执行过程中起重要作用。①MAR：存储器地址寄存器，用于存放将被访问的存储单元的地址。②MDR：存储器数据寄存器，用于存放欲存入存储器中的数据或最近从存储器中读出的数据。③PC：程序计数器，存放现行指令的地址，通常具有计数功能。当遇到转移类指令时，PC的值可被修改。④IR：指令寄存器，存放当前欲执行的指令。通过这4个寄存器，CPU和主存可交换信息。例如，将现行指令地址从PC送至MAR，启动存储器做读操作，存储器就可将指定地址单元内的指令读至MDR，再由MDR送至IR。在CPU内部必须给ALU提供数据，因此ALU必须可直接访问MDR和用户可见寄存器，ALU的外围还可以有另一些寄存器，这些寄存器用于ALU的输入输出以及用于和MDR及用户可见寄存器交换数据(如图9.4中的Y和Z寄存器)。在CPU的控制和状态寄存器中，还有用来存放程序状态字PSW的寄存器，该寄存器用来存放条件码和其他状态信息。在具有中断系统的机器中还有中断标记寄存器。不同计算机的CPU中,寄存器组织是不一样的,图8.3画出了Z8000、8086和MC68000三种计算机的寄存器组织。ZilogZ8000有16个16位的通用寄存器，这些寄存器可存放地址、数据，也可作为变址寄存器，其中有两个寄存器被用作栈指针，寄存器可被用作8位和32位的运算。Z8000中有5个与程序状态有关的寄存器，一个用于存放状态标记，两个用于程序计数器，两个用于存放偏移量。确定一个地址需要两个寄存器。Intel8086采用不同的寄存器组织，尽管某些寄存器可以通用，但它的每个寄存器大多是专用的。它有4个16位的数据寄存器，即AX(累加器)、BX(基址寄存器)、CX(计数寄存器)和DX(数据寄存器),也可兼作8个8位的寄存器(AH、AL、BH、BL、CH、CL、DH、DL)。另外,还有两个16位的指针(栈指针SP和基址指针BP)和两个变址寄存器(源变址寄存器SI和目的变址寄存器DI)。在一些指令中，寄存器是隐式使用的，如乘法指令总是用累加器。8086还有4个段地址寄存器(代码段CS、数据段DS、堆栈段SS和附加段ES)以及指令指针IP(相当于PC)和状态标志寄存器F。MotorolaMC68000的寄存器组织介于Zilog和Intel微处理器之间,它将32位寄存器分为8个数据寄存器((D₀∼D₇)和9个地址寄存器((A₀∼A₇')。。数据寄存器主要用于数据运算，当需要变址时，也可作变址寄存器使用。寄存器允许8位、16位和32位的数据运算，这由操作码确定。地址寄存器存放32位地址(没有段)，其中两个(A₇和A₇)也可用作堆栈指针，分别供用户和操作系统使用。针对当前执行的模式，这两个寄存器在某个时刻只能用一个。此外，MC68000还有一个32位的程序计数器PC和一个16位的状态寄存器。与Zilog的设计者类似，Motorola设计的寄存器组织也不含专用寄存器。至于到底什么形式的寄存器组织最好，目前尚无一致的观点，主要由设计者根据需要自行决定。计算机的设计者们为了给在早期计算机上编写的程序提供向上的兼容性，在新计算机的设计上经常保留原设计的寄存器组织形式。图8.4就是Zilog80000和Intel80386的用户可见寄存器组织，它们分别是Z8000和8086的扩展，它们都采用32位寄存器，但又分别保留了原先的一些特点。由于受这种限制，因此32位处理器在寄存器组织的设计上只有有限的灵活性。控制单元(CU)是提供完成计算机全部指令操作的微操作命令序列部件。现代计算机中微操作命令序列的形成方法有两种：一种是组合逻辑设计方法，为硬连线逻辑；另一种是微程序设计方法，为存储逻辑。具体内容详见第4篇。中断系统主要用于处理计算机的各种中断，详细内容在8.4节介绍。CPU每取出并执行一条指令所需的全部时间称为指令周期，也即CPU完成一条指令的时间，如图8.5所示。图中的取指阶段完成取指令和分析指令的操作，又称取指周期；执行阶段完成执行指令的操作，又称执行周期。在大多数情况下，CPU就是按“取指一执行一再取指一再执行…”的顺序自动工作的。由于各种指令操作功能不同，因此各种指令的指令周期是不相同的。例如，无条件转移指令“JMPX”，在执行阶段不需要访问主存，而且操作简单，完全可以在取指阶段的后期将转移地址X送至PC，以达到转移的目的。这样，“JMPX”指令的指令周期就是取指周期。又如一地址格式的加法指令“ADDX”，在执行阶段首先要从X所指示的存储单元中取出操作数，然后和ACC的内容相加，结果存于ACC，故这种指令的指令周期在取指和执行阶段各访问一次存储器，其指令周期就包括两个存取周期。再如乘法指令，其执行阶段所要完成的操作比加法指令多得多，故它的执行周期超过了加法指令，如图8.6所示。此外，当遇到间接寻址的指令时，由于指令字中只给出操作数有效地址的地址，因此，为了取出操作数，需先访问一次存储器，取出有效地址，然后再访问存储器，取出操作数，如图7.11(a)所示。这样，间接寻址的指令周期就包括取指周期、间址周期和执行周期3个阶段，其中间址周期用于取操作数的有效地址，因此间址周期介于取指周期和执行周期之间，如图8.7所示。由第5章可知，当CPU采用中断方式实现主机与I/O设备交换信息时，CPU在每条指令执行阶段结束前，都要发中断查询信号，以检测是否有某个I/O设备提出中断请求。如果有请求，CPU则要进入中断响应阶段，又称中断周期。在此阶段，CPU必须将程序断点保存到存储器中。这样，一个完整的指令周期应包括取指、间址、执行和中断4个子周期，如图8.8所示。由于间址周期和中断周期不一定包含在每个指令周期内，故图中用菱形框判断。总之，上述4个周期都有CPU访存操作，只是访存的目的不同。取指周期是为了取指令，间址周期是为了取有效地址，执行周期是为了取操作数(当指令为访存指令时)，中断周期是为了保存程序断点。这4个周期又可称为CPU的工作周期，为了区别它们，在CPU内可设置4个标志触发器，如图8.9所示。图8.9所示的FE、IND、EX和INT分别对应取指、间址、执行和中断4个周期,并以“1”状态表示有效,它们分别由1→FE、1→IND、1→EX和1→INT这4个信号控制。设置CPU工作周期标志触发器对设计控制单元十分有利。例如，在取指阶段，只要设置取指周期标志触发器FE为1，由它控制取指阶段的各个操作，便获得对任何一条指令的取指命令序列。又如，在间接寻址时，间址次数可由间址周期标志触发器IND确定，当它为“0”状态时，表示间接寻址结束。再如，对于一些执行周期不访存的指令(如转移指令、寄存器类型指令)，同样可以用它们的操作码与取指周期标志触发器的状态相“与”，作为相应微操作的控制条件。这些特点读者在控制单元的设计中可进一步体会。为了便于分析指令周期中的数据流，假设CPU中有存储器地址寄存器MAR、存储器数据寄存器MDR、程序计数器PC和指令寄存器IR。图8.10所示的是取指周期的数据流。PC中存放现行指令的地址，该地址送到MAR并送至地址总线，然后由控制部件CU向存储器发读命令，使对应MAR所指单元的内容(指令)经数据总线送至MDR，再送至IR，并且CU控制PC内容加1，形成下一条指令的地址。间址周期的数据流如图8.11所示。一旦取指周期结束，CU便检查IR中的内容，以确定其是否有间址操作，如果需要间址操作，则MDR中指示形式地址的右N位(记作Ad(MDR))将被送到MAR，又送至地址总线，此后CU向存储器发读命令，以获取有效地址并存至MDR。由于不同的指令在执行周期的操作不同，因此执行周期的数据流是多种多样的，可能涉及CPU内部寄存器间的数据传送、对存储器(或I/O)进行读写操作或对ALU的操作，因此，无法用统一的数据流图表示。CPU进入中断周期要完成一系列操作(详见9.1节)，其中PC当前的内容必须保存起来，以待执行完中断服务程序后可以准确返回到该程序的间断处，这一操作的数据流如图8.12所示。图中由CU把用于保存程序断点的存储器特殊地址(如栈指针的内容)送往MAR，并送到地址总线上，然后由CU向存储器发写命令，并将PC的内容(程序断点)送到MDR，最终使程序断点经数据总线存入存储器。此外，CU还需将中断服务程序的入口地址送至PC，为下一个指令周期的取指周期做好准备。由前面各章的介绍可知，为了提高访存速度，一方面要提高存储芯片的性能，另一方面可以从体系结构上，如采用多体、Cache等分级存储措施来提高存储器的性能/价格比。为了提高主机与I/O交换信息的速度，可以采用DMA方式，也可以采用多总线结构，将速度不一的I/O分别挂到不同带宽的总线上，以解决总线的瓶颈问题。为了提高运算速度，可以采用高速芯片和快速进位链，以及改进算法等措施。为了进一步提高处理机速度，通常可从提高器件的性能和改进系统的结构，开发系统的并行性两方面入手。(1)提高器件的性能提高器件的性能一直是提高整机性能的重要途径，计算机的发展史就是按器件把计算机分为电子管、晶体管、集成电路和大规模集成电路4代的。器件的每一次更新换代都使计算机的软硬件技术和计算机性能获得突破性进展。特别是大规模集成电路的发展，由于其集成度高、体积小、功耗低、可靠性高、价格便宜等特点，使人们可采用更复杂的系统结构造出性能更高、工作更可靠、价格更低的计算机。但是由于半导体器件的集成度越来越接近物理极限，使器件速度的提高越来越慢。(2)改进系统的结构，开发系统的并行性所谓并行，包含同时性和并发性两个方面。前者是指两个或多个事件在同一时刻发生，后者是指两个或多个事件在同一时间段发生。也就是说，在同一时刻或同一时间段内完成两种或两种以上性质相同或不同的功能，只要在时间上互相重叠，就存在并行性。并行性体现在不同等级上。通常分为4个级别：作业级或程序级、任务级或进程级、指令之间级和指令内部级。前两级为粗粒度，又称为过程级；后两级为细粒度，又称为指令级。粗粒度并行性(Coarse-grainedParallelism)一般用算法(软件)实现,细粒度并行性(Fine-grainedParallelism)一般用硬件实现。从计算机体系上看，粗粒度并行性是在多个处理机上分别运行多个进程，由多台处理机合作完成一个程序；细粒度并行性是指在处理机的操作级和指令级的并行性，其中指令的流水作业就是一项重要技术。这里只讨论有关指令流水的一些主要问题，其他有关粗粒度并行和粗粒度并行技术将在“计算机体系结构”课程中讲述。指令流水类似于工厂的装配线，装配线利用了产品在装配的不同阶段其装配过程不同这一特点，使不同产品处在不同的装配段上，即每个装配段同时对不同产品进行加工，这样可大大提高装配效率。将这种装配生产线的思想用到指令的执行上，就引出了指令流水的概念。从上面的分析可知，完成一条指令实际上也可分为许多阶段。为简单起见，把指令的处理过程分为取指令和执行指令两个阶段，在不采用流水技术的计算机里，取指令和执行指令是周而复始地重复出现，各条指令按顺序串行执行的，如图8.13所示。图中取指令的操作可由指令部件完成，执行指令的操作可由执行部件完成。进一步分析发现，这种顺序执行虽然控制简单，但执行中各部件的利用率不高，如指令部件工作时，执行部件基本空闲，而执行部件工作时，指令部件基本空闲。如果指令执行阶段不访问主存，则完全可以利用这段时间取下一条指令，这样就使取下一条指令的操作和执行当前指令的操作同时进行，如图8.14所示，这就是两条指令的重叠，即指令的二级流水。由指令部件取出一条指令，并将它暂存起来，如果执行部件空闲，就将暂存的指令传给执行部件执行。与此同时，指令部件又可取出下一条指令并暂存起来，这称为指令预取。显然，这种工作方式能加速指令的执行。如果取指和执行阶段在时间上完全重叠，相当于将指令周期减半。然而进一步分析流水线，就会发现存在两个原因使得执行效率加倍是不可能的。①指令的执行时间一般大于取指时间，因此，取指阶段可能要等待一段时间，也即存放在指令部件缓冲区的指令还不能立即传给执行部件，缓冲区不能空出。②当遇到条件转移指令时，下一条指令是不可知的，因为必须等到执行阶段结束后，才能获知条件是否成立，从而决定下条指令的地址，造成时间损失。通常为了减少时间损失，采用猜测法，即当条件转移指令从取指阶段进入执行阶段时，指令部件仍按顺序预取下一条指令。这样，如果条件不成立，转移没有发生，则没有时间损失；若条件成立，转移发生，则所取的指令必须丢掉，并再取新的指令。尽管这些因素降低了两级流水线的潜在效率，但还是可以获得一定程度的加速。为了进一步提高处理速度，可将指令的处理过程分解为更细的几个阶段。·取指(FI)：从存储器取出一条指令并暂时存入指令部件的缓冲区。·指令译码(DI)：确定操作性质和操作数地址的形成方式。●计算操作数地址(CO)：计算操作数的有效地址，涉及寄存器间接寻址、间接寻址、变址寻址、基址寻址、相对寻址等各种地址计算方式。·取操作数(FO)：从存储器中取操作数(若操作数在寄存器中，则无须此阶段)。·执行指令(EI)：执行指令所需的操作，并将结果存于目的位置(寄存器中)。●写操作数(WO)：将结果存入存储器。为了说明方便起见，假设上述各段的时间都是相等的(即每段都为一个时间单元)，于是可得图8.15所示的指令六级流水时序。在这个流水线中，处理器有6个操作部件，同时对6条指令进行加工，加快了程序的执行速度。图中9条指令若不采用流水线技术，最终出结果需要54个时间单元，采用六级流水只需要14个时间单元就可出最后结果，大大提高了处理器速度。当然，图中假设每条指令都经过流水线的6个阶段，但事实并不总是这样。例如，取数指令并不需要WO阶段。此外，这里还假设不存在存储器访问冲突，所有阶段均并行执行。如FI、FO和WO阶段都涉及存储器访问，如果出现冲突就无法并行执行，图8.15示意了所有这些访问都可以同时进行，但多数存储系统做不到这点，从而影响了流水线的性能。还有一些其他因素也会影响流水线性能，例如，6个阶段时间不等或遇到转移指令，都会出现讨论二级流水时出现的问题。要使流水线具有良好的性能，必须设法使流水线能畅通流动，即必须做到充分流水，不发生断流。但通常由于在流水过程中会出现三种相关，使流水线不断流实现起来很困难，这三种相关是结构相关、数据相关和控制相关。结构相关是当多条指令进入流水线后，硬件资源满足不了指令重叠执行的要求时产生的。数据相关是指令在流水线中重叠执行时，当后继指令需要用到前面指令的执行结果时发生的。控制相关是当流水线遇到分支指令和其他改变PC值的指令时引起的。为了讨论方便起见，假设流水线由5段组成，它们分别是取指令(IF)、指令译码/读寄存器(ID)、执行/访存有效地址计算(EX)、存储器访问(MEM)、结果写回寄存器(WB)。不同类型指令在各流水段的操作是不同的，表8.1列出了ALU类指令、访存类(取数、存数)指令和转移类指令在各流水段中所进行的操作。下面分析上述三种相关对流水线工作的影响。结构相关是当指令在重叠执行过程中，不同指令争用同一功能部件产生资源冲突时产生的，故又有资源相关之称。通常，大多数机器都是将指令和数据保存在同一存储器中，且只有一个访问口，如果在某个时钟周期内，流水线既要完成某条指令对操作数的存储器访问操作，又要完成另一条指令的取指操作，这就会发生访存冲突。如表8.2中，在第4个时钟周期，第i条指令(LOAD)的MEM段和第i+3条指令的IF段发生了访存冲突。解决冲突的方法可以让流水线在完成前一条指令对数据的存储器访问时，暂停(一个时钟周期)取后一条指令的操作，如表8.3所示。当然，如果第i条指令不是LOAD指令，在MEM段不访存，也就不会发生访存冲突。解决访存冲突的另一种方法是设置两个独立的存储器分别存放操作数和指令，以免取指令和取操作数同时进行时互相冲突，使取某条指令和取另一条指令的操作数实现时间上的重叠。还可以采用指令预取技术，例如，在CPU(8086)中设置指令队列，将指令预先取到指令队列中排队。指令预取技术的实现基于访存周期很短的情况，例如，在执行指令阶段，取数时间很短，因此在执行指令时，主存会有空闲，此时，只要指令队列空出，就可取下一条指令，并放至空出的指令队列中，从而保证在执行第K条指令的同时对第K+1条指令进行译码，实现“执行K”与“分析K+1”的重叠。数据相关是流水线中的各条指令因重叠操作，可能改变对操作数的读写访问顺序，从而导致了数据相关冲突。例如，流水线要执行以下两条指令：ADDR₁,R₂,R₃(R₂)+(R₃)→R₁SUBR₄,R₁,R₅;(R₁)-(R₅)→R₄这里第二条SUB指令中R₁的内容必须是第一条ADD指令的执行结果。可见正常的读写顺序是先由ADD指令写入R₁，再由SUB指令来读R₁。在非流水线时，这种先写后读的顺序是自然维持的。但在流水线时，由于重叠操作，使读写的先后顺序关系发生了变化，如表8.4所示。读R₁写R₁由表8.4可见，在第5个时钟周期，ADD指令方可将运算结果写入R₁,但后继SUB指令在第3个时钟周期就要从R₁中读数，使先写后读的顺序改变为先读后写，发生了先写后读(RAW)的数据相关冲突。如果不采取相应的措施，按表8.4的读写顺序，就会使操作结果出错。解决这种数据相关的方法可以采用后推法，即遇到数据相关时，就停顿后继指令的运行，直至前面指令的结果已经生成。例如，流水线要执行下列指令序列：ADDR₁,R₂,R₃;(R₂)+(R₃)→R₁SUBR₄,R₁,R₅;(R₁)-(R₅)→R₄ANDR₆,R₁,R₇;(R₁)AND(R₇)→R₆ORR₈,R₁,R₉(R₁)OR(R₉)→R₈;XORR₁₀,R₁,R₁₁;(R₁,)XOR(R₁₁)→R₁1其中，第一条ADD指令将向R₁寄存器写入操作结果，后继的4条指令都要使用R₁中的值作为一个源操作数，显然，这时就出现了前述的RAW数据相关。表8.5列出了未对数据相关进行特殊处理的流水线，表中ADD指令在WB段才将计算结果写入寄存器R₁中，但SUB指令在其ID段就要从寄存器R₁中读取该计算结果。同样，AND指令、OR指令也要受到这种相关关系的影响。对于XOR指令，由于其ID段(第6个时钟周期)在ADD指令的WB段(第5个时钟周期)之后，因此可以正常操作。如果采用后推法，即将相关指令延迟到所需操作数被写回到寄存器后再执行的方式，就可解决这种数据相关冲突，其流水线如表8.6所示。显然这将要使流水线停顿3个时钟周期。另一种解决方法是采用定向技术，又称为旁路技术或相关专用通路技术。其主要思想是不必待某条指令的执行结果送回到寄存器后，再从寄存器中取出该结果，作为下一条指令的源操作数，而是直接将执行结果送到其他指令所需要的地方。上述5条指令序列中，实际上要写入R₁的ADD指令在EX段的末尾处已形成，如果设置专用通路技术，将此时产生的结果直接送往需要它的SUB、AND和OR指令的EX段，就可以使流水线不发生停顿。显然，此时要对3条指令进行定向传送操作。图8.16示出了带有旁路技术的ALU执行部件。图中有两个暂存器，当AND指令将进入EX段时，ADD指令的执行结果已存入暂存器2，SUB指令的执行结果已存入暂存器1，而暂存器2的内容(存放送往R₁的结果)可通过旁路通道，经多路开关送到ALU中。这里的定向传送仅发生在ALU内部。寄存器堆RF多路开关多路开关根据指令间对同一寄存器读和写操作的先后次序关系，数据相关冲突可分为写后读相关(ReadAfterWrite,RAW)、读后写相关(WriteAfterRead,WAR)和写后写相关(WriteAfterWrite,WAW)。例如,有i和j两条指令，i指令在前，j指令在后，则三种不同类型的数据相关含义如下。ALU①写后读相关：指令j试图在指令i写入寄存器前就读出该寄存器内容，这样，指令j就会错误地读出该寄存器旧的内容。②读后写相关：指令j试图在指令i读出寄存器之前就写入该寄存器，这样，指令i就错误地读出该寄存器新的内容。③写后写相关：指令j试图在指令i写入寄存器之前就写入该寄存器，这样，两次写的先后次序被颠倒，就会错误地使由指令i写入的值成为该寄存器的内容。上述三种数据相关在按序流动的流水线中，只可能出现RAW相关。在非按序流动的流水线中，由于允许后进入流水线的指令超过先进入流水线的指令而先流出流水线，则既可能发生RAW相关,还可能发生WAR和WAW相关。控制相关主要是由转移指令引起的。统计表明，转移指令约占总指令的1/4，比起数据相关来，它会使流水线丧失更多的性能。当转移发生时，将使流水线的连续流动受到破坏。当执行转移指令时，根据是否发生转移，它可能将程序计数器PC内容改变成转移目标地址，也可能只是使PC加上一个增量，指向下一条指令的地址。图8.17示意了条件转移的效果。这里使用了和图8.15相同的程序，并假设指令3是一条条件转移指令，即指令3必须待指令2的结果出现后(第7个时间单元)才能决定下一条指令是4(条件不满足)还是15(条件满足)。由于结果无法预测，此流水线继续预取指令4，并向前推进。当最后结果满足条件时，发现对第4、5、6、7条指令所做的操作全部报废。在第8个时间单元，指令15进入流水线。在时间单元9~12之间没有指令完成，这就是由于不能预测转移条件而带来的性能损失。而图8.15中因转移条件不成立，未发生转移，得到了较好的流水线性能。为了解决控制相关，可以采用尽早判别转移是否发生，尽早生成转移目标地址；预取转移成功或不成功两个控制流方向上的目标指令；加快和提前形成条件码；提高转移方向的猜准率等方法。有关的详细内容，读者可查阅相关资料进一步了解。流水线性能通常用吞吐率、加速比和效率3项指标来衡量。在指令级流水线中，吞吐率是指单位时间内流水线所完成指令或输出结果的数量。吞吐率又有最大吞吐率和实际吞吐率之分。最大吞吐率是指流水线在连续流动达到稳定状态(参见图8.15第6~9个时间单元，流水线中各段都处于工作状态)后所获得的吞吐率。对于m段的指令流水线而言，若各段的时间均为△t，则最大吞吐率为T_{p\max}=\frac{1}{\Deltat}流水线仅在连续流动时才可达到最大吞吐率。实际上由于流水线在开始时有一段建立时间(第一条指令输入后到其完成的时间)，结束时有一段排空时间(最后一条指令输入后到其完成的时间)，以及由于各种相关因素使流水线无法连续流动，因此，实际吞吐率总是小于最大吞吐率。实际吞吐率是指流水线完成n条指令的实际吞吐率。对于m段的指令流水线，若各段的时间均为Δt，连续处理n条指令，除第一条指令需m·Δt外，其余(n-1)条指令，每隔Δt就有一个结果输出，即总共需m·Δt+(n-1)Δt时间，故实际吞吐率为T_{p}=\frac{n}{m\Deltat+(n-1)\Deltat}=\frac{1}{\Deltat[1+(m-1)/n]}=\frac{T_{p\maxx}}{1+(m-1)/n}仅当n>m时，才会有Tₚ≈Tₚₘₐₓ。图8.15所示的六级流水线中，设每段时间为Δt，其最大吞吐率为\frac{1}{\Deltat},完成9条指令的实际吞吐率为\frac{9}{6\Deltat+(9-1)\Deltat}。流水线的加速比是指m段流水线的速度与等功能的非流水线的速度之比。如果流水线各段时间均为Δt，则完成n条指令在m段流水线上共需T=m·Δt+(n-1)Δt时间。而在等效的非流水线上所需时间为T'=nmΔt。故加速比Sp为S_{p}=\frac{nm\Deltat}{m\Deltat+(n-1)\Deltat}=\frac{nm}{m+n-1}=\frac{m}{1+(m-1)/n}可以看出，在n>m时，Sp接近于m，即当流水线各段时间相等时，其最大加速比等于流水线的段数。效率是指流水线中各功能段的利用率。由于流水线有建立时间和排空时间，因此各功能段的设备不可能一直处于工作状态，总有一段空闲时间。图8.18是4段((m=4)流水线的时空图，各段时间相等，均为Δt。图中mnΔt是流水线各段处于工作时间的时空区，而流水线中各段总的时空区是m(m+n-1)Δt。通常用流水线各段处于工作时间的时空区与流水线中各段总的时空区之比来衡量流水线的效率。用公式表示为例8.1假设指令流水线分取指(IF)、译码(ID)、执行(EX)、回写(WR)4个过程段,共有10条指令连续输入此流水线。(1)画出指令周期流程。(2)画出非流水线时空图。(3)画出流水线时空图。(4)假设时钟周期为100ns，求流水线的实际吞吐率。(5)求该流水处理器的加速比。解:(1)指令周期包括IF、ID、EX、WR这4个子过程,图8.19(a)为指令周期流程图。(2)非流水线时空图如图8.19(b)所示。假设一个时间单位为一个时钟周期，则每隔4个时钟周期才有一个输出结果。(3)流水线时空图如图8.19(c)所示。由图中可见，第一条指令出结果需要4个时钟周期。当流水线满载时，以后每一个时钟周期可以出一个结果，即执行完一条指令。(4)由图8.19(c)所示的10条指令进入流水线的时空图可见，在13个时钟周期结束时，CPU执行完10条指令，故实际吞吐率为10/(100ns×13)≈0.77×10⁷条指令/秒(5)在流水处理器中，当任务饱满时，指令不断输入流水线，不论是几级流水线，每隔一个时钟周期都输出一个结果。对于本题四级流水线而言，处理10条指令所需的时钟周期数为T₄=4+(10-1)=13,，而非流水线处理10条指令需4×10=40个时钟周期，故该流水处理器的加速比为40÷13≈3.08。流水线技术使计算机系统结构产生重大革新，为了进一步发展，除了采用好的指令调度算法、重新组织指令执行顺序、降低相关带来的干扰以及优化编译外，还可开发流水线中的多发技术，设法在一个时钟周期(机器主频的倒数)内产生更多条指令的结果。常见的多发技术有超标量技术、超流水线技术和超长指令字技术。假设处理一条指令分4个阶段：取指(IF)、译码(ID)、执行(EX)和回写(WR)。图8.20是三种多发技术与普通四级流水线的比较，其中图8.20(a)为普通四级流水线，一个时钟周期出一个结果。超标量(Superscalar)技术如图8.20(b)所示。它是指在每个时钟周期内可同时并发多条独立指令，即以并行操作方式将两条或两条以上(图中所示为3条)指令编译并执行。要实现超标量技术，要求处理机中配置多个功能部件和指令译码电路，以及多个寄存器端口和总线，以便能实现同时执行多个操作，此外还要编译程序决定哪几条相邻指令可并行执行。例如，下面两个程序段：程序段1程序段2MOVBL,8INCAXADDAX,1756HADDAX,BXADDCL,4EHMOVDS,AX左边程序段中的3条指令是互相独立的，不存在数据相关，可实现指令级并行。右边程序段中的3条指令存在数据相关，不能并行执行。超标量计算机不能重新安排指令的执行顺序，但可以通过编译优化技术，在高级语言翻译成机器语言时精心安排，把能并行执行的指令搭配起来，挖掘更多的指令并行性。超流水线(Superpipeline)技术是将一些流水线寄存器插入流水线段中，好比将流水线再分段，如图8.20(c)所示。图中将原来的一个时钟周期又分成3段，使超流水线的处理器周期比普通流水线的处理器周期(如图8.20(a)所示)短，这样，在原来的时钟周期内，功能部件被使用3次，使流水线以3倍于原来时钟频率的速度运行。与超标量计算机一样，硬件不能调整指令的执行顺序，靠编译程序解决优化问题。超长指令字(VLIW)技术和超标量技术都是采用多条指令在多个处理部件中并行处理的体系结构，在一个时钟周期内能流出多条指令。但超标量的指令来自同一标准的指令流，VLIW则是由编译程序在编译时挖掘出指令间潜在的并行性后，把多条能并行操作的指令组合成一条具有多个操作码字段的超长指令(指令字长可达几百位)，由这条超长指令控制VLIW机中多个独立工作的功能部件，由每一个操作码字段控制一个功能部件，`相当于同时执行多条指令，如图8.20(d)所示。VLIW较超标量具有更高的并行处理能力，但对优化编译器的要求更高，对Cache的容量要求更大。指令流水线是将指令的整个执行过程用流水线进行分段处理，典型的指令执行过程分为“取指令—指令译码—形成地址—取操作数—执行指令—回写结果—修改指令指针”这几个阶段，与此相对应的指令流水线结构由图8.21所示的几个部件组成。指令流水线对机器性能的改善程度取决于把处理过程分解成多少个相等的时间段数。如上述共分7段，若每一段需要一个时钟周期，则当不采用流水技术时，需7个时钟周期出一个结果。采用流水线后，假设流水线不出现断流(如遇到转移指令)，则除第一条指令需7个时钟周期出结果外，以后所有的指令都是一个时钟周期出一个结果。因此，在理想的情况下(流水线不断流)，该流水线的速度约提高到7倍。上述讨论的指令流水线是指令级的流水技术，实际上流水技术还可用于部件级。例如，浮点加法运算，可以分成“对阶”“尾数加”及“结果规格化”3段，每一段都有一个专门的逻辑电路完成操作，并将其结果保存在锁存器中，作为下一段的输入。如图8.22所示，当对阶完成后，将结果存入锁存器，便又可进入下一条指令的对阶运算。若执行浮点乘运算也按浮点加运算那样分段，即分成阶码运算、尾数乘和结果规格化三级流水线，就不够合理。因为尾数乘所需的时间比阶码运算和规格化操作长得多，而且尾数乘可以和阶码运算同时进行，因此，尾数乘本身就可以用流水线。由图8.22可见，流水线相邻两段在执行不同的操作，因此在相邻两段之间必须设置锁存器或寄存器，以保证在一个时钟周期内流水线的输入信号不变。这一指导思想也适用于指令流水。此外，只有当流水线各段工作饱满时，才能发挥最大作用。上例中如果浮点运算没有足够的数据来源，那么流水线中的某些段甚至全部段都处于空闲状态，使流水线的作用没有充分发挥。因此具体是否采用流水线技术以及在计算机的哪一部分采用流水线技术需根据情况而定。第5章已经介绍了有关中断的一些概念，特别对I/O中断做了较详细的讨论。实际上I/O中断只是CPU众多中断中的一种，引起中断的因素很多，为了处理各种中断，CPU内通常设有处理中断的机构——中断系统，以解决各种中断的共性问题。本节进一步分析中断系统的功能，以便更深入地了解中断系统在CPU中的作用和地位。从前面分析可知，采用中断方式实现主机与I/O交换信息可使CPU和I/O并行工作，提高CPU的效率。其实，计算机在运行过程中，除了会遇到I/O中断外，还有许多意外事件发生，如电源突然掉电，机器硬件突然出现故障，人们在机器运行过程中想随机抽查计算的中间结果，实现人机联系等。此外，在实时处理系统中，必须及时处理某个事件或现象，例如，在过程控制系统中，当突然出现温度过高、电压过大等情况时，必须及时将这些信息送至计算机，由计算机暂时中断现行程序，转去执行中断服务程序，以解决这种异常情况。再如，计算机实现多道程序运行时，可以通过分配给每道程序一个固定时间片，利用时钟定时发中断进行程序切换。在多处理机系统中，各处理器之间的信息交流和任务切换也可通过中断来实现。总之，为了提高计算机的效率，为了处理一些异常情况以及实时控制、多道程序和多处理机的需要，提出了中断的概念。解题程序引起中断的因素很多，大致可分为以下几类。(1)人为设置的中断管理程序转管指令这种中断一般称为自愿中断，因为它是在程序中人为设置的，故一旦机器执行这种人为中断，便自愿停止现行程序而转入中断处理，如图8.23所示。图中的“转管指令”可能是转至从I/O设备调入一批信息到主存的管理程序，也可能是转至将一批数据送往打印机打印的管理程序。显然，当用户程序执行了“转管指令”后，便中断现行程序，转入管理程序，这种转移完全是自愿的。IBMPC(Intel8086)的INTTYPE指令类似于这种自愿中断,它完成系统调用。TYPE决定了系统调用的类型。(2)程序性事故如定点溢出、浮点溢出、操作码不能识别、除法中出现“非法”等，这些都属于由程序设计不周而引起的中断。(3)硬件故障硬件故障类型很多，如插件接触不良、通风不良、磁表面损坏、电源掉电等，这些都属于硬设备故障。(4)I/O设备I/O设备被启动以后，一旦准备就绪，便向CPU发出中断请求。每个I/O设备都能发中断请求，因此这种中断与计算机所配置的I/O设备多少有关。(5)外部事件用户通过键盘来中断现行程序属于外部事件中断。上述各种中断因素除自愿中断是人为的以外，大多都是随机的。通常将能引起中断的各个因素称为中断源。中断源可分两大类：一类为不可屏蔽中断，这类中断CPU不能禁止响应，如电源掉电；另一类为可屏蔽中断，对可屏蔽中断源的请求，CPU可根据该中断源是否被屏蔽来确定是否给予响应。若未屏蔽则能响应；若已被屏蔽，则CPU不能响应(有关内容详见8.4.6节中断屏蔽技术)。①各中断源如何向CPU提出中断请求。②当多个中断源同时提出中断请求时，中断系统如何确定优先响应哪个中断源的请求。③CPU在什么条件、什么时候、以什么方式来响应中断。④CPU响应中断后如何保护现场。⑤CPU响应中断后，如何停止原程序的执行而转入中断服务程序的入口地址。⑥中断处理结束后，CPU如何恢复现场，如何返回到原程序的间断处。⑦在中断处理过程中又出现了新的中断请求，CPU该如何处理。要解决上述7个问题，只有在中断系统中配置相应的硬件和软件，才能完成中断处理任务。为了判断是哪个中断源提出请求，在中断系统中必须设置中断请求标记触发器，简称中断请求触发器，记作INTR。当其状态为“1”时，表示中断源有请求。这种触发器可集中设在CPU内，组成一个中断请求标记寄存器，如图8.24所示。图中1,2,3,4,5,…,n分别对应掉电、过热、主存读写校验错、阶上溢、非法除法⋯⋯打印机输出等中断源的中断请求触发器，其中任意一个触发器为1，即表明对应的中断源提出了中断请求。显然，中断请求触发器越多，说明计算机处理中断的能力越强。有一点需要说明，尽管中断请求标记寄存器是由各中断请求触发器组成的，但这些触发器既可以集中在CPU的中断系统内，也可以分散到各个中断源中。在图5.41所示的程序中断方式接口电路中，INTR就是分散在各个接口电路内的中断请求触发器。任何一个中断系统，在任一时刻，只能响应一个中断源的请求。但许多中断源提出请求都是随机的，当某一时刻有多个中断源提出中断请求时，中断系统必须按其优先顺序予以响应，这称为中断判优。各中断源的优先顺序是根据该中断源若得不到及时响应，致使机器工作出错的严重程度而定的。例如，电源掉电对计算机工作影响程度最大，优先等级为最高。又如“定点溢出”对机器正常工作影响也很大，若不及时响应，将使计算机一切运行均无效，故它的优先等级也较高。对于I/O设备，则可按其速度高低安排优先等级，速度高的设备优先级比速度低的设备高。中断判优可用硬件实现，也可用软件实现。(1)硬件排队硬件排队又分两种。一种为链式排队器，对应中断请求触发器分散在各个接口电路中的情况，如图5.38所示，每一个接口电路中都设有一个非门和一个与非门，它们犹如链条一样串接起来。另一种排队器设在CPU内，如图8.25所示，图中假设其优先顺序按1、2、3、4由高向低排列。这样，当最高优先级的中断源有请求时INTR₁=1,就可封住比它级别低的中断源的请求。(2)软件排队软件排队是通过编写查询程序实现的，其程序框图如图8.26所示。程序按中断源的优先等级，从高至低逐级查询各中断源是否有中断请求，这样就可以保证CPU首先响应级别高的中断源的请求。由于不同的中断源对应不同的中断服务程序，故准确找到服务程序的入口地址是中断处理的核心问题。通常有两种方法寻找入口地址：硬件向量法和软件查询法。硬件向量法就是利用硬件产生向量地址，再由向量地址找到中断服务程序的入口地址。向量地址由中断向量地址形成部件产生，这个电路可分散设置在各个接口电路中(如图5.41中的设备编码器)，也可设置在CPU内，如图8.27所示。由向量地址寻找中断服务程序的入口地址通常采用两种办法。一种如图5.40所示，在向量地址内存放一条无条件转移指令，CPU响应中断时，只要将向量地址(如12H)送至PC，执行这条指令，便可无条件转向打印机服务程序的入口地址200。另一种是设置向量地址表，如图8.28所示。该表设在存储器内，存储单元的地址为向量地址，存储单元的内容为入口地址，例如，图8.28中的12H、13H、14H为向量地址,200、300、400为入口地址,只要访问向量地址所指示的存储单元，便可获得入口地址。硬件向量法寻找入口地址速度快，在现代计算机中被普遍采用。用软件寻找中断服务程序入口地址的方法称为软件查询法，其框图同图8.26。由图8.26中可见，当查到某一中断源有中断请求时，接着安排一条转移指令，直接指向此中断源的中断服务程序入口地址，机器便能自动进入中断处理。至于各中断源对应的入口地址，则由程序员(或系统)事先确定。这种方法不涉及硬件设备，但查询时间较长。计算机可具备软、硬件两种方法寻找入口地址，使用户使用更方便、灵活。由第5章已知，CPU响应I/O中断的条件是允许中断触发器必须为“1”，这一结论同样适合于其他中断源。在中断系统中有一个允许中断触发器EINT，它可被开中断指令置“1”，也可被关中断指令置“0”。当允许中断触发器为“1”时，意味着CPU允许响应中断源的请求；当其为“0”时，意味着CPU禁止响应中断。故当EINT=1,.且有中断请求(即中断请求标记触发器INTR=1)时,CPU可以响应中断。与响应I/O中断一样，CPU总是在指令执行周期结束后，响应任何中断源的请求，如图8.8所示。在指令执行周期结束后，若有中断，CPU则进入中断周期；若无中断，则进入下一条指令的取指周期。之所以CPU在指令的执行周期后进入中断周期，是因为CPU在执行周期的结束时刻统一向所有中断源发中断查询信号，只有此时，CPU才能获知哪个中断源有请求。如图8.29所示，图中INTR_{i}(i=1,2,\cdots)是各个中断源的中断请求触发器，触发器的数据端来自各中断源，当它们有请求时，数据端为“1”，而且只有当CPU发出的中断查询信号输入触发器的时钟端时，才能将INTRᵢ置“1”。在某些计算机中，有些指令执行时间很长，若CPU的查询信号一律安排在执行周期结束时刻，有可能因CPU发现中断请求过迟而出差错。为此，可在指令执行过程中设置若干个查询断点，CPU在每个“查询断点”时刻均发中断查询信号，以便发现有中断请求便可及时响应。CPU响应中断后，即进入中断周期。在中断周期内，CPU要自动完成一系列操作，具体如下：(1)保护程序断点保护程序断点就是要将当前程序计数器PC的内容(程序断点)保存到存储器中。它可以存在存储器的特定单元(如0号地址)内，也可以存入堆栈。(2)寻找中断服务程序的入口地址由于中断周期结束后进入下条指令(即中断服务程序的第一条指令)的取指周期，因此在中断周期内必须设法找到中断服务程序的入口地址。由于入口地址有两种方法获得，因此在中断周期内也有两种方法寻找入口地址。其一，在中断周期内，将向量地址送至PC(对应硬件向量法)，使CPU执行下一条无条件转移指令，转至中断服务程序的入口地址。其二，在中断周期内，将如图8.26所示的软件查询入口地址的程序(又称中断识别程序)首地址送至PC，使CPU执行中断识别程序，找到入口地址(对应软件查询法)。(3)关中断CPU进入中断周期，意味着CPU响应了某个中断源的请求，为了确保CPU响应后所需做的一系列操作不至于又受到新的中断请求的干扰，在中断周期内必须自动关中断，以禁止CPU再次响应新的中断请求。图8.30是CPU自动关中断的示意图。图中允许中断触发器EINT和中断标记触发器INT可选用标准的R-S触发器。当进入中断周期时，INT为“1”状态，触发器原端输出有一个正跳变，经反相后产生一个负跳变，使EINT置“O”，即关中断。上述保护断点、寻找入口地址和关中断这些操作都是在中断周期内由一条中断隐指令完成的。所谓中断隐指令，即在机器指令系统中没有的指令，它是CPU在中断周期内由硬件自动完成的一条指令。保护现场应该包括保护程序断点和保护CPU内部各寄存器内容的现场两个方面。程序断点的现场由中断隐指令完成，各寄存器内的现场可在中断服务程序中由用户(或系统)用机器指令编程实现,参见5.5.5节及图5.43。恢复现场是指在中断返回前，必须将寄存器的内容恢复到中断处理前的状态，这部分工作也由中断服务程序完成，如图5.43所示。中断屏蔽技术主要用于多重中断。当CPU正在执行某个中断服务程序时，另一个中断源又提出了新的中断请求，而CPU又响应了这个新的请求，暂时停止正在运行的服务程序，转去执行新的中断服务程序，这称为多重中断，又称中断嵌套，如图8.31所示。如果CPU对新的请求不予响应，待执行完当前的服务程序后再响应，即为单重中断。中断系统若要具有处理多重中断的功能，必须具备各项条件。①提前设置“开中断”指令。由上述分析可知，CPU进入中断周期后，由中断隐指令自动将EINT置“0”，即关中断，这就意味着CPU在执行中断服务程序中禁止响应新的中断请求。CPU若想再次响应中断请求，必须开中断，这一任务通常由中断服务程序中的开中断指令实现。由于开中断指令设置的位置不同，决定了CPU能否实现多重中断。由图5.43可见，多重中断“开中断”指令的位置前于单重中断，从而保证了多重中断允许出现中断嵌套。②优先级别高的中断源有权中断优先级别低的中断源。在满足①的前提下，只有优先级别更高的中断源请求才可以中断比其级别低的中断服务程序，反之则不然。例如，有A、B、C、D4个中断源，其优先级按A→B→C→D由高向低次序排列。在CPU执行主程序期间，同时出现了B和C的中断请求，由于B级别高于C，故首先执行B的服务程序。当B级中断服务程序执行完返回主程序后，由于C请求未撤销，故CPU又再去执行C级的中断服务程序。若此时又出现了D请求，因为D级别低于C，故CPU不响应，当C级中断服务程序执行完返回主程序后再去执行D级的服务程序。若此时又出现了A请求，因A级别高于D，故CPU暂停对D级中断服务程序的执行，转去执行A级中断服务程序，等A级中断服务程序执行完后，再去执行D级中断服务程序。上述的中断处理示意图如图8.32所示。为了保证级别低的中断源不干扰比其级别高的中断源的中断处理过程，保证上述②的实施，可采用屏蔽技术。(1)屏蔽触发器与屏蔽字图5.37示出了程序中断接口电路中完成触发器D、中断请求触发器INTR和屏蔽触发器MASK三者之间的关系。当该中断源被屏蔽时((MASK=1),此时即使D=1,中断查询信号到来时刻只能将INTR置“0”，CPU接收不到该中断源的中断请求，即它被屏蔽。若该中断源未被屏蔽(MASK=0),当设备工作已完成时(D=1)，中断查询信号则将INTR置“1”，表示该中断源向CPU发出中断请求，该信号送至排队器进行优先级判断。如果排队器集中设在CPU内，加上屏蔽条件，就可组成具有屏蔽功能的排队器，如图8.33所示。显然，对应每个中断请求触发器就有一个屏蔽触发器，将所有屏蔽触发器组合在一起，便构成一个屏蔽寄存器，屏蔽寄存器的内容称为屏蔽字。屏蔽字与中断源的优先级别是一一对应的，如表8.7所示。表8.7是对应16个中断源的屏蔽字，每个屏蔽字由左向右排序为第1，2，3…，共16位。不难发现，每个中断源对应的屏蔽字是不同的。1级中断源的屏蔽字是16个1；2级中断源的屏蔽字是从第2位开始共15个1；3级中断源的屏蔽字是从第3位开始共14个1……第16级中断源的屏蔽字只有第16位为1，其余各位为0。在中断服务程序中设置适当的屏蔽字，能起到对优先级别不同的中断源的屏蔽作用。例如，1级中断源的请求已被CPU响应，若在其中断服务程序中(通常在开中断指令前)设置一个全“1”的屏蔽字，便可保证在执行1级中断服务程序过程中，CPU不再响应任何一个中断源(包括本级在内)的中断请求，即此刻不能实现多重中断。如果在4级中断源的服务程序中设置一个屏蔽字000111111111111111,由于第1~3位为0,意味着第1~3级的中断源未被屏蔽,因此在开中断指令后，比第4级中断源级别更高的1、2、3级中断源可以中断4级中断源的中断服务程序，实现多重中断。(2)屏蔽技术可改变优先等级严格地说，优先级包含响应优先级和处理优先级。响应优先级是指CPU响应各中断源请求的优先次序，这种次序往往是硬件线路已设置好的，不便于改动。处理优先级是指CPU实际对各中断源请求的处理优先次序。如果不采用屏蔽技术，响应的优先次序就是处理的优先次序。采用了屏蔽技术后，可以改变CPU处理各中断源的优先等级，从而改变CPU执行程序的轨迹。例如，A、B、C、D这4个中断源的优先级别按A→B→C→D降序排列，根据这一次序，CPU执行程序的轨迹如图8.34所示。当4个中断源同时提出请求时，处理次序与响应次序一致。在不改变CPU响应中断的次序下，通过改变屏蔽字可以改变CPU处理中断的次序。例如，将上述4个中断源的处理次序改为A→D→C→B，则每个中断源所对应的屏蔽字发生了变化，如表8.8所示。表中原屏蔽字对应A→B→C→D的响应顺序，新屏蔽字对应A→D→C→B的处理顺序。在同样中断请求的情况下，CPU执行程序的轨迹发生了变化，如图8.35所示。CPU在运行程序的过程中，若A、B、C、D4个中断源同时提出请求，按照中断级别的高低，CPU首先响应并处理A中断源的请求，由于A的屏蔽字是1111，屏蔽了所有的中断源，故A程序可以全部执行完，然后回到主程序。由于B、C、D的中断请求还未响应，而B的响应优先级高于其他，所以CPU响应B的请求，进入B的中断服务程序。在B的服务程序中，由于设置了新的屏蔽字0100，即A、C、D可打断B，而A程序已执行完，C的响应优先级又高于D，于是CPU响应C，进入C的服务程序。在C的服务程序中，由于设置了新的屏蔽字0110，即A、D可打断C，由于A程序已执行完，于是CPU响应D，执行D的服务程序。在D的服务程序中，屏蔽字变成0111，即只有A可打断D，但A已处理结束，所以D可以一直执行完，然后回到C程序。C程序执行完后，回到B程序。B程序执行完后，回到主程序。至此，A、B、C、D均处理完毕。采用了屏蔽技术后，在中断服务程序中需设置新的屏蔽字，流程如图8.36所示。与第5章图5.43(b)所示的中断服务程序相比，增加了置屏蔽字和恢复屏蔽字两部分内容。而且为了防止在恢复现场过程中又出现新的中断，在恢复现场前又增加了关中断，恢复屏蔽字之后，必须再次开中断。例8.2设某机有4个中断源1、2、3、4，其硬件排队优先次序按1→2→3→4降序排列，各中断源的服务程序中所对应的屏蔽字如表8.9所示。第8章CPU的结构和功能369表8.9例8.2各中断源对应的屏蔽字中断源屏蔽字123411101201003111140101(1)给出上述4个中断源的中断处理次序。(2)若4个中断源同时有中断请求，画出CPU执行程序的轨迹。解：(1)根据表8.9，4个中断源的处理次序是按3→1→4→2降序排列。(2)当4个中断源同时有中断请求时，由于硬件排队的优先次序是1→2→3→4，故CPU先响应1的请求，执行1的服务程序。由于在该服务程序中设置了屏蔽字1101，故开中断指令后转去执行3的服务程序，且3的服务程序执行结束后又回到1的服务程序。1的服务程序结束后，CPU还有2、4两个中断源请求未响应。由于2的响应优先级高于4，故CPU先响应2的请求，执行2的服务程序。在2的服务程序中由于设置了屏蔽字0100，意味着1、3、4可中断2的服务程序。而1、3的请求已处理结束，因此在开中断指令之后转去执行4的服务程序，4的服务程序执行结束后又回到2的服务程序的断点处，继续执行2的服务程序，直至该程序执行结束。图8.37示意了CPU执行程序的轨迹。(3)屏蔽技术的其他作用屏蔽技术还能给程序控制带来更大的灵活性。例如，在浮点运算中，当程序员估计到执行某段程序时可能出现“阶上溢”，但又不希望因“阶上溢”而使机器停机，为此可设一屏蔽字，使对应“阶上溢”的屏蔽位为“1”，这样，即使出现“阶上溢”，机器也不停机。多重中断时，每次中断出现的断点都必须保存起来，如图8.31中共出现了3次中断，有3个断点k+1、l+1、m+1需保存。中断系统对断点的保存都是在中断周期内由中断隐指令实现的，对用户是透明的。断点可以保存在堆栈中，由于堆栈先进后出的特点，因此图8.31中的k+1先进栈，接着是l+1进栈，最后是m+1进栈。出栈时，按相反顺序便可准确返回到程序间断处。断点也可保存在特定的存储单元内，例如约定一律将程序断点存至主存的0号地址单元内。由于保存断点是由中断隐指令自动完成的，因此3次中断的断点都将存入0地址单元，这势必造成前两次存入的断点k+1和l+1被冲掉。为此，在中断服务程序中的开中断指令之前，必须先将0地址单元的内容转存至其他地址单元中，才能真正保存每一个断点。读者可自行练习，画出将程序断点保存到0号地址单元的多重中断服务程序流程。控制单元具有发出各种微操作命令(即控制信号)序列的功能。概括地说，计算机的功能就是执行程序。在执行程序的过程中，控制单元要发出各种微操作命令，而且不同的指令对应不同的命令。进一步分析发现，完成不同指令的过程中，有些操作是相同或相似的，如取指令、取操作数地址(当间接寻址时)以及进入中断周期由中断隐指令完成的一系列操作。为更清晰起见，下面按指令周期的4个阶段进一步分析其对应的微操作命令。为了便于讨论，假设CPU内有4个寄存器，如图8.10所示。MAR与地址总线相连，存放欲访问的存储单元地址；MDR与数据总线相连，存放欲写入存储器的信息或最近从存储器中读出的信息；PC存放现行指令的地址，有计数功能；IR存放现行指令。取指令的过程可归纳为以下几个操作。①现行指令地址送至存储器地址寄存器，记作PC→MAR。②向主存发送读命令，启动主存做读操作，记作1→R。③将MAR(通过地址总线)所指的主存单元中的内容(指令)经数据总线读至MDR内，记作M(MAR)→MDR。④将MDR的内容送至IR,记作MDR→IR。⑤指令的操作码送至CU译码,记作OP(IR)→CU。⑥形成下一条指令的地址,记作(PC)+1→PC。间址周期完成取操作数有效地址的任务，具体操作如下。①将指令的地址码部分(形式地址)送至存储器地址寄存器，记作Ad(IR)→MAR。②向主存发送读命令，启动主存做读操作，记作1→R。③将MAR(通过地址总线)所指的主存单元中的内容(有效地址)经数据总线读至MDR内,记作M(MAR)→MDR。④将有效地址送至指令寄存器的地址字段，记作MDR→Ad(IR)。此操作在有些机器中可省略。不同指令执行周期的微操作是不同的，下面分别讨论非访存指令、访存指令和转移类指令的微操作。这类指令在执行周期不访问存储器。(1)清除累加器指令CLA该指令在执行阶段只完成清除累加器操作，记作O→ACC。(2)累加器取反指令COM该指令在执行阶段只完成累加器内容取反，结果送累加器的操作，记作ACC→ACC。(3)算术右移一位指令SHR该指令在执行阶段只完成累加器内容算术右移一位的操作，记作L(ACC)→R(ACC)，ACC₀→ACC₀(ACC的符号位不变)。(4)循环左移一位指令CSL该指令在执行阶段只完成累加器内容循环左移一位的操作，记作R(ACC)→L(ACC)，ACC₀→ACCₙ(或ρ⁻¹(ACC))。(5)停机指令STP计算机中有一个运行标志触发器G，当G=1时，表示机器运行；当G=0时，表示停机。STP指令在执行阶段只需将运行标志触发器置“0”，记作0→G。这类指令在执行阶段都需要访问存储器。为简单起见，这里只考虑直接寻址的情况，不考虑其他寻址方式。(1)加法指令ADDX该指令在执行阶段需要完成累加器内容与对应于主存X地址单元的内容相加，结果送累加器的操作，具体如下：①将指令的地址码部分送至存储器地址寄存器，记作Ad(IR)→MAR。②向主存发读命令，启动主存做读操作，记作1→R。③将MAR(通过地址总线)所指的主存单元中的内容(操作数)经数据总线读至MDR内，记作M(MAR)→MDR。④给ALU发送加命令,将ACC的内容和MDR的内容相加,结果存于ACC,记作(ACC)+(MDR)→ACC。当然，也有的加法指令指定两个寄存器的内容相加，如“ADDAX，BX”，该指令在执行阶段无须访存,只需完成(AX)+(BX)→AX的操作。(2)存数指令STAX该指令在执行阶段需将累加器ACC的内容存于主存的X地址单元中，具体操作如下。①将指令的地址码部分送至存储器地址寄存器，记作Ad(IR)→MAR。②向主存发写命令，启动主存做写操作，记作1→W。③将累加器内容送至MDR,记作ACC→MDR。④将MDR的内容(通过数据总线)写入MAR(通过地址总线)所指的主存单元中，记作MDR→M(MAR)。(3)取数指令LDAX该指令在执行阶段需将主存X地址单元的内容取至累加器ACC中，具体操作如下。①将指令的地址码部分送至存储器地址寄存器，记作Ad(IR)→MAR。②向主存发读命令，启动主存作读操作，记作1→R。③将MAR(通过地址总线)所指的主存单元中的内容(操作数)经数据总线读至MDR内，记作M(MAR)→MDR。④将MDR的内容送至ACC,记作MDR→ACC。这类指令在执行阶段也不访问存储器。(1)无条件转移指令JMPX该指令在执行阶段完成将指令的地址码部分X送至PC的操作，记作Ad(IR)→PC。(2)条件转移(负则转)指令BANX该指令根据上一条指令运行的结果决定下一条指令的地址，若结果为负(累加器最高位为1,即A₀=1),则指令的地址码送至PC，否则程序按原顺序执行。由于在取指阶段已完成了(PC)+1→PC，所以当累加器结果不为负(即.A₀=0)时，就按取指阶段形成的PC执行，记作A_{0}\cdotAd(IR)+\overline{A}_{0}\cdot(PC)\rightarrowPC。由此可见，不同指令在执行阶段所完成的操作是不同的。如果将访存指令分为直接访存和间接访存两种，则上述三类指令的指令周期如图9.1所示。在执行周期结束时刻，CPU要查询是否有请求中断的事件发生，如果有则进入中断周期。由8.4.4节可知，在中断周期，由中断隐指令自动完成保护断点、寻找中断服务程序入口地址以及硬件关中断的操作。假设程序断点存至主存的0地址单元，且采用硬件向量法寻找入口地址，则在中断周期需完成如下操作。①将特定地址“0”送至存储器地址寄存器，记作0→MAR。②向主存发写命令，启动存储器作写操作，记作1→W。③将PC的内容(程序断点)送至MDR,记作PC→MDR。④将MDR的内容(程序断点)通过数据总线写入MAR(通过地址总线)所指示的主存单元(0地址单元)中,记作MDR→M(MAR)。⑤将向量地址形成部件的输出送至PC，记作向量地址→PC，为下一条指令的取指周期做准备。⑥关中断，将允许中断触发器清零，记作O→EINT(该操作可直接由硬件线路完成，参见图8.30)。如果程序断点存入堆栈，而且进栈操作是先修改栈指针，后存入数据(参见图7.18)，只需将上述①改为(SP)-1→SP,且SP→MAR。上述所有操作都是在控制单元发出的控制信号(即微操作命令)控制下完成的。(1)时钟上述各种操作有以下两点应特别注意。①完成每个操作都需占用一定的时间。②各个操作是有先后顺序的。例如，存储器读操作要用到MAR中的地址，故PC→MAR应先于M(MAR)→MDR。为了使控制单元按一定的先后顺序、一定的节奏发出各个控制信号，控制单元必须受时钟控制，即每一个时钟脉冲使控制单元发送一个操作命令，或发送一组需要同时执行的操作命令。(2)指令寄存器现行指令的操作码决定了不同指令在执行周期所需完成的不同操作，故指令的操作码字段是控制单元的输入信号，它与时钟配合可产生不同的控制信号。(3)标志控制单元有时需依赖CPU当前所处的状态(如ALU操作的结果)产生控制信号，如BAN指令，控制单元要根据上条指令的结果是否为负而产生不同的控制信号。因此“标志”也是控制单元的输入信号。(4)来自系统总线(控制总线)的控制信号例如，中断请求、DMA请求。(1)CPU内的控制信号主要用于CPU内的寄存器之间的传送和控制ALU实现不同的操作。(2)送至系统总线(控制总线)的信号例如，命令主存或I/O读/写、中断响应等。控制单元的主要功能就是能发出各种不同的控制信号。下面以间接寻址的加法指令“ADD@X”为例，进一步理解控制信号在完成一条指令的过程中所起的作用。图9.3示意了未采用CPU内部总线方式的数据通路和控制信号的关系。图中未画出每个寄存器的输入或输出控制门，但标出了控制这些门电路的控制信号Cᵢ,考虑到从存储器取出的指令或有效地址都先送至MDR再送至IR，故这里省去了IR送至MAR的数据通路，凡是需要从IR送至MAR的操作均可由MDR送至MAR代替。(1)取指周期①控制信号C₀有效,打开PC送往MAR的控制门。②控制信号(C₁有效，打开MAR送往地址总线的输出门。③通过控制总线向主存发读命令。④C₂有效，打开数据总线送至MDR的输入门。⑤C₃有效，打开MDR和IR之间的控制门，至此指令送至IR。⑥C₄有效，打开指令操作码送至CU的输出门。CU在操作码和时钟的控制下，可产生各种控制信号。⑦使PC内容加1(图中未标出)。(2)间址周期①C₅有效,打开MDR和MAR之间的控制门,将指令的形式地址送至MAR。②C₁有效，打开MAR送往地址总线的输出门。③通过控制总线向主存发读命令。④C₂有效，打开数据总线送至MDR的输入门，至此，有效地址存入MDR。⑤C₃有效，打开MDR和IR之间的控制门，将有效地址送至IR的地址码字段。(3)执行周期①C₅有效,打开MDR和MAR之间的控制门,将有效地址送至MAR。②C₁有效，打开MAR送往地址总线的输出门。③通过控制总线向主存发读命令。④C₂有效，打开数据总线送至MDR的输入门，至此，操作数存入MDR。⑤C₆、C₇同时有效,打开AC和MDR通往ALU的控制门。⑥通过CPU内部控制总线对ALU发“ADD”加控制信号，完成AC的内容和MDR的内容相加。控制信号⑦C₈有效,打开ALU通往AC的控制门,至此将求和结果存入AC。下面仍以完成间接寻址的加法指令“ADD@X”为例，分析控制单元发出的控制信号。(1)取指周期①PC。和MAR₁有效,完成PC经内部总线送至MAR的操作,即PC→MAR。②通过控制总线(图中未画出)向主存发读命令，即1→R。③存储器通过数据总线将MAR所指单元的内容(指令)送至MDR。④MDR。和IR₁有效,将MDR的内容送至IR,即MDR→IR,至此,指令送至IR,其操作码字段开始控制CU。⑤使PC内容加1(图中未标出)。(2)间址周期①MDR。和MAR₁有效,将指令的形式地址经内部总线送至MAR,即MDR→MAR。②通过控制总线向主存发读命令，即1→R。③存储器通过数据总线将MAR所指单元的内容(有效地址)送至MDR。④MDR。和IR₁有效,将MDR中的有效地址送至IR的地址码字段,即MDR→Ad(IR)。(3)执行周期①MDR。和MAR₁有效,将有效地址经内部总线送至MAR,即MDR→MAR。②通过控制总线向主存发读命令，即1→R。③存储器通过数据总线将MAR所指单元的内容(操作数)送至MDR。④MDR。和Yᵢ有效,将操作数送至Y,即MDR→Y。⑤AC。和ALU₁有效,同时CU向ALU发“ADD”加控制信号,使AC的内容和Y的内容相加(Y的内容送至ALU不必通过总线),结果送寄存器Z,即(AC)+(Y)→Z。⑥Z。和ACᵢ有效,将运算结果存入AC,即Z→AC。现代计算机的CPU都集成在一个硅片内，在芯片内采用内部总线的方式可大大节省芯片内部寄存器之间的连线，使芯片内各部件布局更合理。例9.1设CPU内部采用非总线结构,如图9.3所示。(1)写出取指周期的全部微操作。(2)写出取数指令“LDAM”、存数指令“STAM”、加法指令“ADDM”(M均为主存地址)在执行阶段所需的全部微操作。(3)当上述指令均为间接寻址时，写出执行这些指令所需的全部微操作。(4)写出无条件转移指令“JMPY”和结果为零则转指令“BAZY”在执行阶段所需的全部微操作。解：(1)取指周期的全部微操作如下：PC→MAR现行指令地址→MAR1→R命令存储器读M(MAR)→MDR现行指令从存储器中读至MDRMDR→IR现行指令→IROP(IR)→CU指令的操作码→CU译码(PC)+1→PC形成下一条指令的地址(2)①取数指令“LDAM”执行阶段所需的全部微操作如下：Ad(IR)→MAR指令的地址码字段→MAR1→R命令存储器读M(MAR)→MDR操作数从存储器中读至MDRMDR→ACC操作数→ACC②存数指令“STAM”执行阶段所需的全部微操作如下：Ad(IR)→MAR指令的地址码字段→MAR1→W命令存储器写ACC→MDR欲写入的数据→MDRMDR→M(MAR)数据写至存储器中③加法指令“ADDM”执行阶段所需的全部微操作如下：Ad(IR)→MAR指令的地址码字段→MAR1→R命令存储器读M(MAR)→MDR操作数从存储器中读至MDR(ACC)+(MDR)→ACC两数相加结果送ACC(3)当上述指令为间接寻址时，需增加间址周期的微操作。这3条指令在间址周期的微操作是相同的，即Ad(IR)→MAR指令的地址码字段→MAR1→R命令存储器读M(MAR)→MDR有效地址从存储器中读至MDR进入执行周期，3条指令的第一个微操作均为MDR→MAR(有效地址送MAR)，其余微操作不变。(4)①无条件转移指令“JMPY”执行阶段的微操作如下：Ad(IR)→PC转移(目标)地址Y→PC②结果为零则转指令“BAZY”执行阶段的微操作如下：Z·Ad(IR)→PC当Z=1时,转移(目标)地址Y→PC(Z为标记触发器，结果为0时Z=1)例9.2已知单总线计算机结构如图9.5所示，其中M为主存，XR为变址寄存器，EAR为有效地址寄存器，LATCH为锁存器。图中各寄存器的输入和输出均受控制信号控制，例如，PC₁表示PC的输入控制信号，MDR。表示MDR的输出控制信号。假设指令地址已存于PC中,画出“ADDX,D”(X为变址寄存器XR,D为形式地址)和“STA*D”(*表示相对寻址，D为相对位移量)两条指令的指令周期信息流程图，并列出相应的控制信号序列。解：(1)“ADDX，D”指令取指周期和执行周期的信息流程及相应的控制信号如图9.6所示，图中Ad(IR)为形式地址。PC₀,MAR₁PC→Bus→MARMAR_{o},R\sqrt{W}=R,MDR_{i}M(MAR)→MDR取指MDRo,IRiMDR→Bus→IR(PC)+1→PC+1XR₀,Ad(IR)。,+,EARᵢ(XR)+Ad(IR)→EAREAR₀,MARᵢEAR→Bus→MAR「MARₒ,R/W=R,MDR₁M(MAR)→MDRMDR₀,XᵢMDR→Bus→X指令执行周期(ACC)+(X)→LATCHACC₀,Xₒ,K₁=+,LATCHᵢLATCH₀,ACC₁LATCH→Bus→ACC图9.6“ADDX，D”指令周期的信息流程及相应的控制信号(2)“STA*D”指令取指周期和执行周期的信息流程及相应的控制信号如图9.7所示，图中Ad(IR)为相对位移量的机器代码。第9章控制单元的功能385PC₀,MARᵢPC→Bus→MARMARₒ,R/W=R,MDRᵢM(MAR)→MDR取指MDR₀,IR₁MDR→Bus→IR(PC)+1→PC+1PC。,Ad(IR)。,+,EAR₁(PC)+Ad(IR)→EAREAR→Bus→MAREAR。,MAR₁*V、指令执行周期ACC→Bus→MDRACC。,MDR₁MDR_{0},MAR_{0},R\overrightarrow{W}=WMDR→M(MAR)图9.7.“STA*D”指令周期的信息流程及相应的控制信号机器周期可看作所有指令执行过程中的一个基准时间，机器周期取决于指令的功能及器件的速度。确定机器周期时，通常要分析机器指令的执行步骤及每一步骤所需的时间。例如，取数、存数指令能反映存储器的速度及其与CPU的配合情况；加法指令能反映ALU的速度；条件转移指令因为要根据上一条指令的执行结果，经测试后才能决定是否转移，所需的时间较长。总之，通过对机器指令执行步骤的分析，会找到一个基准时间，在这个基准时间内，所有指令的操作都能结束。若以这个基准时间定为机器周期，显然不是最合理的。因为只有以完成复杂指令功能所需的时间(最长时间)作为基准，才能保证所有指令在此时间内完成全部操作，这对简单指令来说，显然是一种浪费。进一步分析发现，机器内的各种操作大致可归属为对CPU内部的操作和对主存的操作两大类，由于CPU内部的操作速度较快，CPU访存的操作时间较长，因此通常以访问一次存储器的时间定为基准时间较为合理，这个基准时间就是机器周期。又由于不论执行什么指令，都需要访问存储器取出指令，因此在存储字长等于指令字长的前提下，取指周期也可看作机器周期。在一个机器周期里可完成若干个微操作，每个微操作都需要一定的时间，可用时钟信号来控制产生每一个微操作命令(如图9.3中的C₁)。时钟就好比计算机的心脏，只要接通电源，计算机内就会产生时钟信号。时钟信号可由机器主振电路(如晶体振荡器)发出的脉冲信号经整形(或倍频、分频)后产生，时钟信号的频率即为CPU主频。用时钟信号控制节拍发生器，就可产生节拍。每个节拍的宽度正好对应一个时钟周期。在每个节拍内机器可完成一个或几个需同时执行的操作，它是控制计算机操作的最小时间单位。图9.8反映了机器周期、时钟周期和节拍的关系，图中一个机器周期内有4个节拍T_{0},T_{1}\sqrt{T_{2}}.T_{3}。图9.9反映了指令周期、机器周期、节拍(状态)和时钟周期的关系。可见，一个指令周期包含若干个机器周期，一个机器周期又包含若干个时钟周期(节拍)，每个指令周期内的机器周期数可以不等，每个机器周期内的节拍数也可以不等。其中，图9.9(a)为定长的机器周期，每个机器周期包含4个节拍(4个T)；图9.9(b)为不定长的机器周期，每个机器周期包含的节拍数可以为4个，也可以为3个，后者适合于操作比较简单的指令，它可跳过某些时钟周期(如T₃)，从而缩短指令周期。机器周期、节拍(状态)组成了多级时序系统。一般来说，CPU的主频越快，机器的运行速度也越快。在机器周期所含时钟周期数相同的前提下，两机平均指令执行速度之比等于两机主频之比。例如，CPU的主频为8MHz，其平均指令执行速度为0.8MIPS。若想得到平均指令执行速度为0.4MIPS的机器，则只需要用主频为(8MHz×0.4MIPS)/0.8MIPS=4MHz的CPU即可。实际上机器的速度不仅与主频有关，还与机器周期中所含的时钟周期数以及指令周期中所含的机器周期数有关。同样主频的机器，由于机器周期所含时钟周期数不同，运行速度也不同。机器周期所含时钟周期数少的机器，速度更快。例9.3设某计算机的CPU主频为8MHz，每个机器周期平均含2个时钟周期，每条指令的指令周期平均有2.5个机器周期，试问该机的平均指令执行速度为多少MIPS?若CPU主频不变，但每个机器周期平均含4个时钟周期，每条指令的指令周期平均有5个机器周期，则该机的平均指令执行速度又是多少MIPS?由此可得出什么结论?解:由于主频为8MHz,所以时钟周期为1/8=0.125μs,机器周期为0.125×2=0.25μs,指令周期为0.25×2.5=0.625μs。①平均指令执行速度为1/0.625=1.6MIPS。②若CPU主频不变，机器周期含4个时钟周期，每条指令平均含5个机器周期，则指令周期为0.125×4×5=2.5μs,故平均指令执行速度为1/2.5=0.4MIPS。③可见机器的运行速度并不完全取决于主频。此外，机器的运行速度还和其他很多因素有关，如主存的运行速度、机器是否配有Cache、总线的数据传输率、硬盘的运行速度以及机器是否采用流水技术等。机器速度还可以用MIPS(执行百万条指令数每秒)和CPI(执行一条指令所需的时钟周期数)来衡量。控制单元控制一条指令执行的过程实质上是依次执行一个确定的微操作序列的过程。由于不同指令所对应的微操作数及其复杂程度不同，因此每条指令和每个微操作所需的执行时间也不同。通常将如何形成控制不同微操作序列所采用的时序控制方式称为CU的控制方式。常见的控制方式有同步控制、异步控制、联合控制和人工控制四种。同步控制方式是指，任何一条指令或指令中任何一个微操作的执行都是事先确定的，并且都是受统一基准时标的时序信号所控制的方式。图9.9(a)就是一种典型的同步控制方式，每个机器周期都包含4个节拍。如果机器内的存储器存取周期不统一，那么只有把最长的存取周期作为机器周期，才能采用同步控制，否则取指令和取数时间不同，无法用统一的基准。又如有些不访存的指令，执行周期的微操作较少，无须4个节拍。因此，为了提高CPU的效率，在同步控制中又有三种方案。(1)采用定长的机器周期这种方案的特点是：不论指令所对应的微操作序列有多长，也不管微操作的简繁，一律以最长的微操作序列和最繁的微操作作为标准，采取完全统一的、具有相同时间间隔和相同数目的节拍作为机器周期来运行各种不同的指令，如图9.9(a)所示。显然，这种方案对于微操作序列较短的指令来说，会造成时间上的浪费。(2)采用不定长的机器周期采用这种方案时，每个机器周期内的节拍数可以不等，如图9.9(b)所示。这种控制方式可解决微操作执行时间不统一的问题。通常把大多数微操作安排在一个较短的机器周期内完成，而对某些复杂的微操作，采用延长机器周期或增加节拍的办法来解决，如图9.10所示。(3)采用中央控制和局部控制相结合的方法这种方案将机器的大部分指令安排在统一的、较短的机器周期内完成，称为中央控制，而将少数操作复杂的指令中的某些操作(如乘除法和浮点运算等)采用局部控制方式来完成，图9.11所示为中央控制和局部控制的时序关系。在设计局部控制线路时需要注意两点：其一，使局部控制的每一个节拍T^{\ast}的宽度与中央控制的节拍宽度相同；其二，将局部控制节拍作为中央控制中机器节拍的延续，插入中央控制的执行周期内，使机器以同样的节奏工作，保证局部控制和中央控制的同步。T^{\ast}的多少可根据情况而定，对于乘法，当操作数位数固定后，T*的个数也就确定了。而对于浮点运算的对阶操作，由于移位次数不是一个固定值，因此T*的个数不能事先确定。以乘法指令为例，第一个机器周期采用中央控制的节拍控制取指令操作，接着仍用中央控制的T₀、T₁、T₂节拍去完成将操作数从存储器中取出并送至寄存器的操作，然后转局部控制，用局部控制节拍T*完成重复加和移位的操作。异步控制方式不存在基准时标信号，没有固定的周期节拍和严格的时钟同步，执行每条指令和每个操作需要多少时间就占用多少时间。这种方式微操作的时序由专门的应答线路控制，即当CU发出执行某一微操作的控制信号后，等待执行部件完成该操作后发回“回答”(或“结束”)信号，再开始新的微操作，使CPU没有空闲状态，但因需要采用各种应答电路，故其结构比同步控制方式复杂。同步控制和异步控制相结合就是联合控制方式。这种方式对各种不同指令的微操作实行大部分统一、小部分区别对待的办法。例如，对每条指令都有的取指令操作，采用同步方式控制；对那些时间难以确定的微操作，如I/O操作，则采用异步控制，以执行部件送回的“回答”信号作为本次微操作的结束。人工控制是为了调机和软件开发的需要，在机器面板或内部设置一些开关或按键，来达到人工控制的目的。(1)Reset(复位)键按下Reset键，使计算机处于初始状态。当机器出现死锁状态或无法继续运行时，可按此键。若在机器运行时按此键，将会破坏机器内某些状态而引起错误，因此要慎用。有些微型计算机未设此键，当机器死锁时，可采用停电后再加电的办法重新启动计算机。(2)连续或单条执行转换开关由于调机的需要，有时需要观察执行完一条指令后的机器状态，有时又需要观察连续运行程序后的结果，设置连续或单条执行转换开关，能为用户提供这两种选择。(3)符合停机开关有些计算机还配有符合停机开关，这组开关指示存储器的位置，当程序运行到与开关指示的地址相符时，机器便停止运行，称为符合停机。为了加深对本章内容的理解，下面以Intel8085为例，通过对一条I/O写操作指令运行过程的分析，使读者进一步认识多级时序系统与控制单元发出的控制信号的关系。图9.12是Intel8085的组成框图,其内部有3个16位寄存器,即SP、PC和增减地址锁存器IDAL,11个8位寄存器,即B、C、D、E、H、L、IR、AC、暂存器TR以及地址缓冲寄存器ABR和地址数据缓冲寄存器ADBR，以及一个5位的状态标志寄存器FR。ALU能实现8位算术运算和逻辑运算。控制单元的具体组成将在第10章讲述，图中的定时和控制(CU)能对外发出各种控制信号。8085内还有中断控制和I/O控制，内部数据总线为8位。图中未标出8085片内的控制信号。8085芯片引脚图如图9.13所示，共40根引脚。外部信号分以下几类。(1)地址和数据信号①A₁₅∼A₈(出):16位地址的高8位。②AD₇~AD₀(入/出)：16位地址的低8位或8位数据，它们共用相同的引脚。③SID(入):串行输入。④SOD(出):串行输出。(2)定时和控制信号①CLK(出)：系统时钟，每周期代表一个T状态。②X₁、X₂(入)：来自外部晶体或其他设备，以驱动内部的时钟发生器。③ALE(出)：地址暂存使能信号，在机器周期的第一个时钟周期产生，使外围芯片保存地址。X₁401Vcc④S₀、S₁(出)：用于标识读/写操作是否发生。HOLD392x₂338HLDAResetout\enclose{circle}{5}10/\overline{M}(出)：使I/O接口或存储器读/写操作使能。CLK(out)374SOD36Resetin5SID\enclose{circle}{6}\overline{RD}(出)：表示被选中的存储器或I/O接口将所读出的数据送至数据总线上。6Ready35TRAPIO/M734RST7.5833S₁RST6.5⑦WR(出)：表示数据总线上的数据将写入被选中的存储器或I/O接口中。RD932RST5.5\overline{WR}31INTR10(3)存储器和I/O的初始化信号3011ALEINTA12S₀29AD₀①HOLD(入)：请求CPU放弃系统总线的控制和使用，总线将用于DMA操作。2813AD₁A₁₅A₁₄2714AD₂1526A₁₃AD₃②HLDA(出)：总线响应信号，表示总线可被外部占用。A₁₂1625AD₄A₁₁2417AD₅23A₁₀18AD₆③Ready(入):用于CPU与较慢的存储器或设备同步。当某一设备准备就绪后,向CPU发Ready信号,此时CPU可进行输入或输出。AD₇1922A₉Vss2021A₈(4)与中断有关的信号①TRAP(出):重新启动中断(RST7.5、RST6.5、RST5.5)。②INTR(入):中断请求信号。③INTA(出):中断响应信号。(5)CPU初始化①Resetin(入):PC清“0”,假设CPU从0地址开始执行。②Resetout(出):对CPU的置“0”做出响应,该信号能用于重置系统的剩余部分。(6)电源和地①Vcc:+5V电源。②Vss:地。8085的一条指令可分成1~5个机器周期，每个机器周期内又包含3~5个节拍，每个节拍持续一个时钟周期。在每个节拍内，CPU根据控制信号执行一个或一组同步的微操作。下面分析一条输出指令，其功能是将AC的内容写入所选择的设备中，执行该指令的时序图如图9.14所示。由图可见，该指令的指令周期包含3个机器周期M₁、M₂和M₃，每个机器周期内所包含的节拍数不同(M₁含4拍，M₂和M₃均含3拍)。该指令字长为16位，由于数据线只有8位，所以要分两次将指令取至CPU内。第一个机器周期取指令的操作码，第二个机器周期取被选设备的地址，第三个机器周期把AC的内容通过数据总线写入被选中的设备中。具体时序如下。(1)第一个机器周期M₁：存储器读，取指令操作码①T₁状态,10/\overline{M}低电平，表示存储器操作。CPU将PC的高8位送至地址总线A₁₅~A₈,PC的低8位送至地址/数据总线AD₇∼AD₀,并由ALE的下降沿激活存储器保存地址。②T₂状态，RD(低)有效，表示存储器读操作，存储器将指定地址的内容送至数据总线AD₇~AD₀,CPU等待数据线上的数据稳定。③T₃状态，当数据线上的数据稳定后，CPU接收数据，此数据为该指令的第一字节操作码。④T₄状态,CPU进入译码阶段,在T₄最后时刻ALE(高)失效。在T₂或T₃状态可安排(PC)+1→PC操作，图中未标出此控制信号。(2)第二个机器周期M₂：存储器读，取被选设备的地址①T₁状态,同M₁的T₁状态操作。②T₂状态,同M₁的T₂状态操作。③T₃状态，当数据线上的数据稳定后，CPU接收数据，此数据为被选设备的地址。同样可以在T₂或T₃时刻完成(PC)+1→PC操作。这个机器周期内设有指令译码，因此T₄省略。在T₃最后时刻ALE(高)失效。(3)第三个机器周期M₃:I/O写①T₁状态,IO/\overline{M}高电平,表示I/O操作,CPU将I/O口地址送至A₁₅∼A₈和AD₇∼AD₀,并由ALE下降沿激活I/O保存地址。②T₂状态,WR(低)有效,表示I/O写操作,AC的内容通过.AD₇∼AD₀数据总线送至被选中的设备中。可见，控制单元的每一个控制信号都是在指定机器周期内的指定T时刻发出的，反映了多级时序系统与控制信号间的关系。本章以10条机器指令为例，介绍控制单元的两种设计方法，旨在使读者初步掌握设计控制单元的思路，为今后设计计算机打下初步基础。图9.2示出了控制单元的外特性，其中指令的操作码是决定控制单元发出不同控制信号的关键。为了简化控制单元的逻辑，将存放在IR的n位操作码经过一个译码电路产生2°个输出，这样，每对应一种操作码便有一个输出送至CU。当然，若指令的操作码长度可变，指令译码线路将更复杂。控制单元的时钟输入实际上是一个脉冲序列，其频率即为机器的主频，它使CU能按一定的节拍(T)发出各种控制信号。节拍的宽度应满足数据信息通过数据总线从源到目的所需的时间。以时钟为计数脉冲，通过一个计数器，又称节拍发生器，便可产生一个与时钟周期等宽的节拍序列。如果将指令译码和节拍发生器从CU中分离出来，便可得简化的控制单元框图，如图10.1所示。假设机器采用同步控制，每个机器周期包含3个节拍，而且CPU内部结构如图9.3所示，其中MAR和MDR分别直接和地址总线和数据总线相连，并假设IR的地址码部分与MAR之间有通路。安排微操作节拍时应注意以下3点。①有些微操作的次序是不容改变的，故安排微操作节拍时必须注意微操作的先后顺序。②凡是被控制对象不同的微操作，若能在一个节拍内执行，应尽可能安排在同一个节拍内，以节省时间。③如果有些微操作所占的时间不长，应该将它们安排在一个节拍内完成，并且允许这些微操作有先后次序。按上述3条原则，以9.1节所分析的10条指令为例，其微操作的节拍安排如下：·根据原则②,T。节拍可安排两个微操作:PC→MAR,1→R。•根据原则②,T₁节拍可安排M(MAR)→MDR和(PC)+1→PC两个微操作。·T₂节拍可安排MDR→IR，考虑到指令译码时间较短，根据原则③，可将指令译码OP(IR)→ID也安排在T₂节拍内。实际上(PC)+1→PC操作也可安排在T₂节拍内,因一旦PC→MAR后,PC的内容就可修改。T。Ad(IR)→MAR,1→RT₁M(MAR)→MDRT₂MDR→Ad(IR)(1)非访存指令1)清除累加器指令CLA该指令在执行周期只有一个微操作，按同步控制的原则，此操作可安排在T₀∼T₂的任一节拍内，其余节拍空，例如：T₀T₁T₂0→AC2)累加器取反指令COM同理，累加器取反操作可安排在T₀∼T₂的任一节拍中，即T。T₁T₂AC→AC3)算术右移一位指令SHRT。T₁T₂L(AC)→R(AC),AC₀→AC₀4)循环左移一位指令CSLT。T₁T₂R(AC)→L(AC),AC₀→ACₙ(即ρ⁻¹(AC))5)停机指令STPT。T₁T₂0→G(2)访存指令1)加法指令ADDXT。Ad(IR)→MAR,1→RT₁M(MAR)→MDRT₂(AC)+(MDR)→AC(该操作实际包括(AC)→ALU,(MDR)→ALU,ALU→AC)2)存数指令STAXT。Ad(IR)→MAR,1→WT₁AC→MDRT₂MDR→M(MAR)3)取数指令LDAXT。Ad(IR)→MAR,1→RT₁M(MAR)→MDRT₂MDR→AC(3)转移类指令1)无条件转移指令JMPXT。T₁T₂Ad(IR)→PC2)有条件转移(负则转)指令BANXT₀T₁T_{2}A_{0}\cdotAd(IR)+\overline{A}_{0}\cdot(PC)\rightarrowPC在执行周期的最后时刻，CPU要向所有中断源发中断查询信号，若检测到某个中断源有请求，并且未被屏蔽又被排队选中，则在允许中断的条件下，CPU进入中断周期，此时CPU由中断隐指令完成下列操作(假设程序断点存入主存0号地址单元内)：T。0→MAR,1→WT₁PC→MDRT₂MDR→M(MAR),向量地址→PC此外，由图8.30可知，CPU进入中断周期，由硬件置“0”允许中断触发器EINT，即关中断。例10.1设CPU中各部件及其相互连接关系如图10.2所示。图中W是写控制标志，R是读控制标志，R₁和R₂是暂存器。(1)假设要求在取指周期由ALU完成(PC)+1→PC的操作(即ALU可以对它的一个源操作数完成加1的运算)。要求以最少的节拍写出取指周期全部微操作命令及节拍安排。(2)写出指令“ADD#α”(#为立即寻址特征，隐含的操作数在ACC中)在执行阶段所需的微操作命令及节拍安排。解:(1)由于(PC)+1→PC需由ALU完成,因此PC的值可作为ALU的一个源操作数,靠控制ALU做+1运算得到(PC)+1,，结果送至与ALU输出端相连的R₂,,然后再送至PC。此题的关键是要考虑总线冲突的问题，故取指周期的微操作命令及节拍安排如下：T。PC→Bus→MAR,1→R;PC通过总线送MART₁M(MAR)→MDR,(PC)→Bus→ALU₊₁→R₂;PC通过总线送ALU完成(PC)+1→R₂T₂MDR→Bus→IR,;MDR通过总线送IROP(IR)→微操作命令形成部件T₃R₂→Bus→PC;R₂通过总线送PC(2)立即寻址的加法指令执行周期的微操作命令及节拍安排如下：T。Ad(IR)→Bus→R₁；立即数→R₁T₁(ACC)+(R₁)→ALU→R₂;ACC通过总线送ALUT₂R₂→Bus→ACC；结果通过总线送ACC例10.2设CPU内部结构如图10.2所示,且PC有自动加1功能。此外还有B、C、D、E、H、L6个寄存器(图中未画)，它们各自的输入端和输出端都与内部总线Bus相连，并分别受控制信号控制。要求写出完成下列指令组合逻辑控制单元所发出的微操作命令及节拍安排。(1)ADDB,C;(B)+(C)→B(2)SUBE,@H;(E)-((H))→E寄存器间接寻址(3)STA@mem;ACC→((mem))存储器间接寻址解：(1)完成“ADDB，C”指令所需的微操作命令及节拍安排如下：取指周期T。PC→Bus→MAR,1→RT₁M(MAR)→MDR,(PC)+1→PCT₂MDR→Bus→IR,OP(IR)→微操作命令形成部件执行周期T。C→Bus→R₁T₁(B)+(R₁)→ALU→R₂;B通过总线送ALUT₂R₂→Bus→B(2)完成“SUBE，@H”指令所需的微操作命令及节拍安排如下：取指周期T。PC→Bus→MAR,1→RT₁M(MAR)→MDR,(PC)+1→PCT₂MDR→Bus→IR,OP(IR)→微操作命令形成部件间址周期T。H→Bus→MAR,1→RT₁M(MAR)→MDR执行周期T₀MDR→Bus→R₁T₁(E)-(R₁)→ALU→R₂;E通过总线送ALUT₂R₂→Bus→E(3)完成“STA@mem”指令所需的微操作命令及节拍安排如下：取指周期T。PC→Bus→MAR,1→RT₁M(MAR)→MDR,(PC)+1→PCT₂MDR→Bus→IR,OP(IR)→微操作命令形成部件间址周期T。Ad(IR)→Bus→MAR,1→RT₁M(MAR)→MDR.执行周期T。MDR→Bus→MAR,1→WT₁ACC→Bus→MDRT₂MDR→M(MAR)例10.3设寄存器均为16位，实现补码Booth算法的运算器框图如图6.9所示。其中寄存器A、X最高2位A₀、A₁和X₀、X₁为符号位，寄存器Q最高位Q₀为符号位，最末位Q₁₅为附加位。假设上条指令的运行结果存于A(即被乘数)中。(1)若CU为组合逻辑控制，且采用中央和局部控制相结合的方法，写出完成“MULα”(α为主存地址)指令的全部微操作命令及节拍安排。(2)指出哪些节拍属于中央控制节拍，哪些节拍属于局部控制节拍，局部控制最多需要几拍?解:(1)取指阶段T。PC→MAR,1→RT₁M(MAR)→MDR,(PC)+1→PCT₂MDR→IR,OP(IR)→ID执行阶段乘法开始前要将被乘数由A→X，并将乘数从主存α单元取出送至Q寄存器。因(Q₁₅(最末位)为附加位，还必须0→Q₁₅，并将A清零。上述这些操作可安排在中央控制节拍内完成。乘法过程的重复加操作受Q寄存器末两位(Q₁₄、Q₁₅控制，重复移位操作在两个串接的寄存器。A‖Q中完成，这两种操作可安排在局部控制节拍内完成。具体安排如下：T。Ad(IR)→MAR,1→R,A→XT₁M(MAR)→MDR,O→Q₁₅,0→AT₂MDR→Q₀₋₁₄(Q寄存器仅取1位符号位)T_{0}^{\ast}\overline{Q}_{14}Q_{15}\cdot(A+X)+Q_{14}\overline{Q}_{15}\cdot(\Lambda+\overline{X}+1)+\overline{Q}_{14}\overline{Q}_{15}\cdotA+Q_{14}Q_{15}\cdotA\rightarrowAT_{1}^\astL(A\|Q)\rightarrowR(A\|Q)(A\|Q算术右移一位)⋮(2)中央控制节拍包括取指阶段所有节拍和执行阶段的T₀、T₁、T₂3个节拍，完成取指令和取操作数及乘法运算前的准备工作。局部控制节拍是执行阶段的T。和T₁°节拍，其中T_{0}^{\ast}为重复加操作，受Q寄存器末两位Q₁₄、Q₁₅控制，最多执行15次；T；为移位操作，共执行14次。采用组合逻辑设计控制单元时，首先根据上述10条指令微操作的节拍安排，列出微操作命令的操作时间表，然后写出每一个微操作命令(控制信号)的逻辑表达式，最后根据逻辑表达式画出相应的组合逻辑电路图。表10.1列出了上述10条机器指令微操作命令的操作时间表。表中FE、IND和EX为CPU工作周期标志(参见图8.9),T₀~T₂)为节拍，Ⅰ为间址标志，在取指周期的T₂时刻，若测得I=1，则IND触发器置“1”，标志进入间址周期；若I=0，则EX触发器置“1”，标志进入执行周期。同理，在间址周期的T₂时刻，若测得IND=0(表示一次间接寻址)，则EX触发器置“1”，进入执行周期；若测得IND=1(表示多次间接寻址)，则继续间接寻址。在执行周期的T₂时刻，CPU要向所有中断源发中断查询信号，若检测到有中断请求并且满足响应条件，则INT触发器置“1”，标志进入中断周期。表中未列出INT触发器置“1”的操作和中断周期的微操作。表中第一行对应10条指令的操作码，代表不同的指令。若某指令有表中所列的微操作命令，其对应的空格内为1。纵览表10.1便可列出每一个微操作命令的初始逻辑表达式，经化简、整理便可获得能用现成电路实现的微操作命令逻辑表达式。例如，根据表可写出M(MAR)→MDR微操作命令的逻辑表达式：M(MAR)→MDR=FE·T₁+IND·T₁(ADD+STA+LDA+JMP+BAN)+EX·T₁(ADD+LDA)=T₁{FE+IND(ADD+STA+LDA+JMP+BAN)+EX(ADD+LDA)}式中,ADD、STA、LDA、JMP、BAN均来自操作码译码器的输出。3.画出微操作命令的逻辑图对应每一个微操作命令的逻辑表达式都可画出一个逻辑图。例如，M(MAR)→MDR的逻辑表达式所对应的逻辑图如图10.3所示，图中未考虑门的扇入系数。当然，在设计逻辑图时要考虑门的扇入系数和逻辑级数。如果采用现成芯片，还需选择芯片型号。采用组合逻辑设计方法设计控制单元，思路清晰，简单明了，但因为每一个微操作命令都对应一个逻辑电路，因此一旦设计完毕便会发现，这种控制单元的线路结构十分庞杂，也不规范，犹如一棵大树，到处都是不规整的枝杈。而且指令系统功能越全，微操作命令就越多，线路也越复杂，调试就更困难。为了克服这些缺点，可采用微程序设计方案。但是，正如7.5节所述，随着RISC的出现，组合逻辑设计仍然是设计计算机的一种重要方法。微程序设计思想是英国剑桥大学教授M.V.Wilkes在1951年首先提出的。为了克服组合逻辑控制单元线路庞杂的缺点，他大胆设想采用与存储程序相类似的方法，来解决微操作命令序列的形成。Wilkes提出，将一条机器指令编写成一个微程序，每一个微程序包含若干条微指令，每一条微指令对应一个或几个微操作命令。然后把这些微程序存到一个控制存储器中，用寻找用户程序机器指令的方法来寻找每个微程序中的微指令。由于这些微指令是以二进制代码形式表示的，每位代表一个控制信号(若该位为1，表示该控制信号有效；若该位为0，表示此控制信号无效)，因此，逐条执行每一条微指令，也就相应地完成了一条机器指令的全部操作。可见，微程序控制单元的核心部件是一个控制存储器。由于执行一条机器指令必须多次访问控制存储器，以取出多条微指令来控制执行各个微操作，因此要求控制存储器的速度较高。可惜在Wilkes那个年代电子器件生产水平有限，因此微程序设计思想并未实现。直到20世纪60年代出现了半导体存储器，才使这个设计思想成为现实。1964年4月，世界上第一台微程序设计的机器IBM360研制成功。微程序设计省去了组合逻辑设计过程中对逻辑表达式的化简步骤，无须考虑逻辑门级数和门的扇入系数，使设计更简便，而且由于控制信号是以二进制代码的形式出现的，因此只要修改微指令的代码，就可改变操作内容，便于调试、修改，甚至增删机器指令，有利于计算机仿真。采用微程序设计方法设计控制单元的过程就是编写每一条机器指令的微程序，它是按执行每条机器指令所需的微操作命令的先后顺序而控制存储器编写的，因此，一条机器指令对应一个微程序，如MM+1图10.4所示。图中每一条机器指令都与一个以M+1M+2取指周期微程序M+2×××操作性质命名的微程序对应。间址周期微程序转执行周期微程序中断周期微程序转取指周期微程序P+1P对应LDA操作的微程序P+2P+1P+2MQ+1Q由于任何一条机器指令的取指令操作是相同的，因此将取指令操作的命令统一编成一个微程序，这个微程序只负责将指令从主存单元中取出送至指令寄存器中，如图10.4所示的取指周期微程序。此外，如果指令是间接寻址，其操作也是可以预测的，也可先编出对应间址周期的微程序。当出现中断时，中断隐指令所需完成的操作可由一个对应中断周期的微程序控制完成。这样，控制存储器中的微程序个数应为机器指令数再加上对应取指、间接寻址和中断周期的3个微程序。Q+2Q+1对应ADD操作的微程序Q+2M:K+1KK+2对应STA操作的微程序K+1MK+2J+1J对应JMP操作的微程序J+1M图中点画线框内为微程序控制单元，与图9.2相比，它们都有相同的输入，如指令寄存器、各种标志和时钟，输出也是输至CPU内部或系统总线的控制信号。点画线框内的控制存储器(简称控存)是微程序控制单元的核心部件，用来存放全部微程序；CMAR是控存地址寄存器，用来存放欲读出的微指令地址；CMDR是控存数据寄存器，用来存放从控存读出的微指令；顺序逻辑是用来控制微指令序列的，具体就是控制形成下一条微指令(即后续微指令)的地址，其输入与微地址形成部件(与指令寄存器相连)、微指令的下地址字段以及外来的标志有关。有关微指令序列地址的形成将在10.2.4节中介绍。微指令的基本格式如图10.6所示，共分两个字段，一个为操作控制字段，该字段发出各种控制信号；另一个为顺序控制字段，它可指出下条微指令的地址(简称下地址)，以控制微指令序列的执行顺序。假设有一个用户程序如下所示，它存于以2000H为首地址的主存空间内。LDAXADDYSTAZSTP下面结合图10.4和图10.5，分析运行上述程序时微程序控制单元的工作原理。首先将用户程序的首地址送至PC，然后进入取指阶段。(1)取指阶段①将取指周期微程序首地址M→CMAR。②取微指令。将对应控存M地址单元中的第一条微指令读到控存数据寄存器中，记作CM(CMAR)→CMDR。③产生微操作命令。第一条微指令的操作控制字段中为“1”的各位发出控制信号，如PC→MAR，1→R，命令主存接收程序首地址并进行读操作。④形成下一条微指令的地址。此微指令的顺序控制字段指出了下一条微指令的地址为M+1，将M+1送至CMAR，即Ad(CMDR)→CMAR。⑤取下一条微指令。将对应控存M+1地址单元中的第二条微指令读到CMDR中,即CM(CMAR)→CMDR。⑥产生微操作命令。由第二条微指令的操作控制字段中对应“1”的各位发出控制信号，如M(MAR)→MDR使对应主存2000H地址单元中的第一条机器指令从主存中读出送至MDR中。⑦形成下一条微指令的地址。将第二条微指令下地址字段指出的地址M+2送至CMAR，即Ad(CMDR)→CMAR⋮以此类推，直到取出取指周期最后一条微指令，并发出微操作命令为止。此时第一条机器指令“LDAX”已存至指令寄存器IR中。(2)执行阶段①取数指令微程序首地址的形成。当取数指令存入IR后，其操作码OP(IR)直接送到微地址形成部件，该部件的输出即为取数指令微程序的首地址P,且将P送至CMAR,记作OP(IR)→微地址形成部件→CMAR。②取微指令。将对应控存P地址单元中的微指令读到CMDR中,即CM(CMAR)→CMDR。③产生微操作命令。由微指令操作控制字段中对应“1”的各位发出控制信号，如Ad(IR)→MAR，1→R，命令主存读操作数。④形成下一条微指令的地址。将此条微指令下地址字段指出的P+1送至CMAR,即Ad(CMDR)→CMAR。⑤取微指令,即CM(CMAR)→CMDR。⑥产生微操作命令。⋮以此类推，直到取出取数指令微程序的最后一条微指令P+2，并发出微操作命令。至此即完成了将主存X地址单元中的操作数取至累加器AC的操作。这条微指令的顺序控制字段为M，即表明CPU又开始进入下一条机器指令的取指周期，控存又要依次读出取指周期微程序的逐条微指令，发出微操作命令，完成将第二条机器指令“ADDY”从主存取至指令寄存器IR中……微程序控制单元就是这样，通过逐条取出微指令，发出各种微操作命令，从而实现从主存逐条取出、分析并执行机器指令，以达到运行程序的目的。由此可见，对微程序控制单元的控存而言，内部信息一旦按所设计的微程序被灌注后，在机器运行过程中，只需具有读出的性能即可，故可采用ROM。此外，在微程序的执行过程中，关键问题是如何由微指令的操作控制字段形成微操作命令，以及如何形成下一条微指令的地址。这是微程序设计必须解决的问题，它们与微指令的编码方式和微地址的形成方式有关。微指令的编码方式又称微指令的控制方式，它是指如何对微指令的控制字段进行编码，以形成控制信号，主要有以下几种。在微指令的操作控制字段中，每一位代表一个微操作命令，这种编码方式即为直接编码方式。上面所述的用控制字段中的某位为“1”表示控制信号有效(如打开某个控制门)，以及某位为“0”表示控制信号无效(如不打开某个控制门)就是直接控制方式，如图10.7所示。这种方式含义清晰，而且只要微指令从控存读出，即刻可由控制字段发出命令，速度快。但由于机器中微操作命令甚多，可能使微指令操作控制字段达几百位，造成控存容量极大。这种方式就是将微指令的操作控制字段分成若干段，将一组互斥的微操作命令放在一个字段内，通过对这个字段译码，便可对应每一个微命令，如图10.8所示。这种方式因靠字段直接译码发出微命令，故又有显式编码之称。采用字段直接编码方法可用较少的二进制信息表示较多的微操作命令信号。例如，3位二进制代码译码后可表示7个互斥的微命令，留出一种状态表示不发微命令，与直接编码用7位表示7个微命令相比，减少了4位，缩短了微指令的长度。但由于增加了译码电路，使微程序的执行速度稍微减慢。至于操作控制字段应分几段，与需要并行发出的微命令个数有关，若需要并行发出8个微命令，就可分8段。每段的长度可以不等，与具体要求互斥的微命令个数有关，若某类操作要求互斥的微命令仅有6个，则字段只需安排3位即可。这种方式一个字段的某些微命令还需由另一个字段中的某些微命令来解释，如图10.9所示。图中字段1译码的某些输出受字段2译码输出的控制，由于不是靠字段直接译码发出微命令，故称为字段间接编码，又称隐式编码。这种方法虽然可以进一步缩短微指令字长，但因削弱了微指令的并行控制能力，因此通常用作字段直接编码法的一种辅助手段。这种方法是把直接编码和字段编码(直接或间接)混合使用，以便能综合考虑微指令的字长、灵活性和执行微程序的速度等方面的要求。微指令中还可设置常数字段，用来提供常数、计数器初值等。常数字段还可以和某些解释位配合，如解释位为0，表示该字段提供常数；解释位为1，表示该字段提供某种命令，使微指令更灵活。此外，微指令还可用类似机器指令操作码的方式编码，有关内容参见10.2.5节微指令格式。例10.4某机的微指令格式中，共有8个控制字段，每个字段可分别激活5、8、3、16、1、7、25、4种控制信号。分别采用直接编码和字段直接编码方式设计微指令的操作控制字段，并说明两种方式的操作控制字段各取几位。解：(1)采用直接编码方式，微指令的操作控制字段的总位数等于控制信号数，即5+8+3+16+1+7+25+4=69(2)采用字段直接编码方式，需要的控制位少。根据题目给出的10个控制字段及各段可激活的控制信号数，再加上每个控制字段至少要留一个码字表示不激活任何一条控制线，即微指令的8个控制字段分别需给出6、9、4、17、2、8、26、5种状态,对应3、4、2、5、1、3、5、3位,故微指令的操作控制字段的总位数为3+4+2+5+1+3+5+3=26由图10.5可见，后续微指令的地址大致由两种方式形成。图10.4中大部分微指令的下地址字段直接指出了后续微指令的地址。这种方式又称为断定方式。当机器指令取至指令寄存器后，微指令的地址由操作码经微地址形成部件形成。微地址形成部件实际是一个编码器，其输入为指令操作码，输出就是对应该机器指令微程序的首地址。它可采用PROM实现，以指令的操作码作为PROM的地址，而相应的存储单元内容就是对应该指令微程序的首地址。实际上微指令序列地址的形成方式还有以下几种。仔细分析发现，在很多情况下，后续微指令的地址是连续的，因此对于顺序地址，微指令可采用增量计数法，即(CMAR)+1→CMAR来形成后续微指令的地址。当遇到条件转移指令时，微指令出现了分支，必须根据各种标志来决定下一条微指令的地址。微指令的格式如下：操作控制字段转移方式转移地址其中，转移方式指明判别条件，转移地址指明转移成功后的去向，若不成功则顺序执行。也有的转移微指令中设两个转移地址，条件满足时选择其中一个转移地址；条件不满足时选择另一个转移地址。微指令的地址还可通过测试网络形成，如图10.10所示。图中微指令的地址分两部分，高段h为非测试地址，由微指令的H段地址码直接形成；低段l为测试地址，由微指令的L段地址码通过测试网络形成。当电源加电后，第一条微指令的地址可由专门的硬件电路产生，也可由外部直接向CMAR输入微指令的地址，这个地址即为取指周期微程序的入口地址。当有中断请求时，若条件满足，CPU响应中断进入中断周期，此时需中断现行程序，转至对应中断周期的微程序。由于设计控制单元时已安排好中断周期微程序的入口地址(参见图10.4)，故响应中断时，可由硬件产生中断周期微程序的入口地址。同理，当出现间接寻址时，也可由硬件产生间址周期微程序的入口地址。综合上述各种方法，可得出形成后续微指令地址的原理图，如图10.11所示。图中多路选择器可选择以下4路地址。①(CMAR)+1→CMAR。②微指令的下地址字段。③指令寄存器(通过微地址形成部件)。④微程序入口地址。微指令格式与微指令的编码方式有关，通常分为水平型微指令和垂直型微指令两种。水平型微指令的特点是一次能定义并执行多个并行操作的微命令。图10.7就是典型的水平型微指令。从编码方式看，直接编码、字段直接编码、字段间接编码以及直接和字段混合编码都属于水平型微指令。其中，直接编码速度最快，字段编码要经过译码，故速度受影响。垂直型微指令的特点是采用类似机器指令操作码的方式，在微指令字中，设置微操作码字段，由微操作码规定微指令的功能。通常一条微指令有1~2个微命令，控制1~2种操作。这种微指令不强调其并行控制功能。①水平型微指令比垂直型微指令并行操作能力强、效率高、灵活性强。②水平型微指令执行一条机器指令所需的微指令数目少，因此速度比垂直型微指令的速度快。③水平型微指令用较短的微程序结构换取较长的微指令结构，垂直型微指令正相反，它以较长的微程序结构换取较短的微指令结构。④水平型微指令与机器指令差别较大，垂直型微指令与机器指令相似。例10.5某微程序控制器中，采用水平型直接控制(编码)方式的微指令格式，后续微指令地址由微指令的下地址字段给出。已知机器共有28个微命令、6个互斥的可判定的外部条件，控制存储器的容量为512×40位。试设计其微指令格式，并说明理由。解：水平型微指令由操作控制字段、判别测试字段和下地址字段三部分构成。因为微指令采用直接控制(编码)方式，所以其操作控制字段的位数等于微命令数，为28位。又由于后续微指令地址由下地址字段给出，故其下地址字段的位数可根据控制存储器的容量(512×40位)定为9位。当微程序出现分支时，后续微指令地址的形成取决于状态条件，6个互斥的可判定外部条件，可以编码成3位状态位。非分支时的后续微指令地址由微指令的下地址字段直接给出。微指令的格式如图10.12所示。例10.6某机共有52个微操作控制信号，构成5个相斥类的微命令组，各组分别包含5、8、2、15、22个微命令。已知可判定的外部条件有两个，微指令字长28位。(1)按水平型微指令格式设计微指令，要求微指令的下地址字段直接给出后续微指令地址。(2)指出控制存储器的容量。解：(1)根据5个相斥类的微命令组，各组分别包含5、8、2、15、22个微命令，考虑到每组必须增加一种不发命令的情况，条件测试字段应包含一种不转移的情况，则5个控制字段分别需给出6、9、3、16、23种状态,对应3、4、2、4、5位(共18位),条件测试字段取2位。根据微指令字长为28位,则下地址字段取28-18-2=8位,其微指令格式如图10.13所示。(2)根据下地址字段为8位，微指令字长为28位，得控制存储器的容量为256×28位。10.2.6静态微程序设计和动态微程序设计通常指令系统是固定的，对应每一条机器指令的微程序是计算机设计者事先编好的，因此一般微程序无须改变，这种微程序设计技术即称为静态微程序设计，其控制存储器采用ROM。前面讲述的内容基本上属于这一类。如果采用EPROM作为控制存储器，人们可以通过改变微指令和微程序来改变机器的指令系统，这种微程序设计技术称为动态微程序设计。动态微程序设计由于可以根据需要改变微指令和微程序，因此可以在一台机器上实现不同类型的指令系统，有利于仿真。但是这种设计对用户的要求很高，目前难以推广。第10章控制单元的设计41310.2.7毫微程序设计微程序可看作是解释机器指令的，毫微程序可看作是解释微程序的，而组成毫微程序的毫微指令则是用来解释微指令的。采用毫微程序设计计算机的优点是用少量的控制存储器空间来达到高度的并行。毫微程序设计采用两级微程序的设计方法。第一级微程序为垂直型微指令，并行功能不强，但有严格的顺序结构，由它确定后续微指令的地址，当需要时可调用第二级。第二级微程序为水平型微指令，具有很强的并行操作能力，但不包含后续微指令的地址。第二级微程序执行完毕后又返回到第一级微程序。两级微程序分别放在两级控制存储器内。图10.14示意了毫微程序控制存储器的基本组成。图中CMAR₁为第一级控存地址寄存器，CMDR₁存放从第一级控制存储器中读出的微指令，如果该微指令只产生一些简单的控制信号，则可以通过译码，直接形成微操作命令，不必调用第二级。如果需调用第二级控制存储器时，则将毫微程序的地址送至(CMAR₂,，然后由从第二级控制存储器中读出的微指令去直接控制硬件。值得注意的是，垂直型微指令不是和水平型微指令一条一条地对应，而是由水平型微指令(称为毫微指令)组成的毫微程序去执行垂直型微指令的操作。毫微指令与微指令的关系就好比微指令与机器指令的关系一样。二级控制存储器虽然能减少控制存储器的容量，但因有时一条微指令要访问两次控制存储器，影响了速度。与机器指令一样，完成一条微指令也分两个阶段：取微指令和执行微指令。如果这两个阶段按图10.15(a)所示的方式运行，则为串行微程序控制。由于取微指令和执行微指令的操作是在两个完全不同的部件中完成的，因此可将这两部分操作并行进行，以缩短微指令周期，这就是并行微程序控制，如图10.15(b)所示，与指令二级流水相似。第i条微指令周期第i+1条微指令周期取第i条微指令执行第i条微指令取第i+1条微指令执行第i+1条微指令(a)串行操作执行第i条微指令取第i条微指令取第i+1条微指令执行第i+1条微指令执行第i+2条微指令取第i+2条微指令(b)并行操作当采用并行微程序控制时，为了不影响本条微指令的正确执行，需增加一个微指令寄存器来暂存下一条微指令。由于执行本条微指令与取下一条微指令是同时进行的，因此当遇到需要根据本条微指令的处理结果来决定下条微指令的地址时，就不能并行操作，此时可延迟一个微指令周期再取微指令。微程序设计控制单元的主要任务是编写对应各条机器指令的微程序，具体步骤是首先写出对应机器指令的全部微操作及节拍安排，然后确定微指令格式，最后编写出每条微指令的二进制代码(称为微指令码点)。为了便于与组合逻辑设计比较，仍以10条机器指令为例，而且CPU结构同组合逻辑设计假设相同。此外，为了简化起见，不考虑间接寻址和中断的情况。下面分别按取指阶段和执行阶段列出其微操作序列。(1)取指阶段的微操作及节拍安排取指阶段的微操作基本与组合逻辑控制相同，不同的是指令取至IR后，微程序控制需由操作码形成执行阶段微程序的入口地址，即T。PC→MAR,1→RT₁M(MAR)→MDR,(PC)+1→PCT₂MDR→IR,OP(IR)→微地址形成部件(编码器)如果把一个T内的微操作安排在一条微指令中完成，上述微操作对应3条微指令。值得注意的是，由于微程序控制的所有控制信号都来自微指令，而微指令又存于控制存储器中，因此欲完成上述这些微操作，必须先将微指令从控制存储器中读出，也即必须先给出这些微指令的地址。由图10.4可见，在取指微程序中，除第一条微指令外，其余微指令的地址均由上一条微指令的下地址字段直接给出，因此上述每一条微指令都需要增加一个将微指令下地址字段送至CMAR的微操作，记作Ad(CMDR)→CMAR，而这一操作只能由下一个时钟周期T的上升沿将地址打入CMAR内。至于取指微程序的最后一条微指令，其后续微指令的地址是由微地址形成部件形成的，而且也只能由下一个T的上升沿将该地址打入CMAR中，即微地址形成部件→CMAR。为了反映该地址与操作码有关，故记作OP(IR)→微地址形成部件→CMAR。综上所述，考虑到需要形成后续微指令的地址，上述分析的取指操作共需6条微指令完成，即T。PC→MAR,1→RT₁Ad(CMDR)→CMART₂M(MAR)→MDR,(PC)+1→PCT₃Ad(CMDR)→CMAR,T₄MDR→IR,OP(IR)→微地址形成部件(编码器)T₅OP(IR)→微地址形成部件→CMAR所有微指令均由T的上升沿打入CMDR中。(2)执行阶段的微操作及节拍安排执行阶段的微操作由操作码性质而定，同时也需要考虑后续微指令地址的形成问题。1)CLA指令与组合逻辑控制一样，该指令在执行阶段只有一个微操作O→AC，只需一个时钟周期T，故对应一条微指令。该微指令的下地址字段应直接给出取指微程序的入口地址，而且由下一个T的上升沿将地址打入CMAR内。这样，对应CLA指令执行阶段的微指令有两条：T。0→ACT₁Ad(CMDR)→CMAR取指微程序入口地址→CMAR同理可得其余4条非访存指令对应的微操作。2)COM指令T_{0}\overrightarrow{AC}\rightarrowACT₁Ad(CMDR)→CMAR取指微程序入口地址→CMAR3)SHR指令T。L(AC)→R(AC),AC₀→AC₀T₁Ad(CMDR)→CMAR取指微程序入口地址→CMAR416第4篇控制单元4)CSL指令T。R(AC)→L(AC),AC₀→ACn(即ρ⁻¹(AC))T₁Ad(CMDR)→CMAR取指微程序入口地址→CMAR5)STP指令T。0→GT₁Ad(CMDR)→CMAR取指微程序入口地址→CMAR这里由于安排了Ad(CMDR)→CMAR，使再次启动机器时，可直接用已存入CMAR中的取指微程序的入口地址。6)ADD指令T。Ad(IR)→MAR,1→RT₁Ad(CMDR)→CMART₂M(MAR)→MDRT₃Ad(CMDR)→CMART₄(AC)+(MDR)→ACT₅Ad(CMDR)→CMAR取指微程序入口地址→CMAR7)STA指令T。Ad(IR)→MAR,1→WT₁Ad(CMDR)→CMART₂AC→MDRT₃Ad(CMDR)→CMART₄MDR→M(MAR)T₅Ad(CMDR)→CMAR取指微程序入口地址→CMAR8)LDA指令T。Ad(IR)→MAR,1→RT₁Ad(CMDR)→CMART₂M(MAR)→MDRT₃Ad(CMDR)→CMART₄MDR→ACT₅Ad(CMDR)→CMAR取指微程序入口地址→CMAR9)JMP指令T。Ad(IR)→PCT₁Ad(CMDR)→CMAR取指微程序入口地址→CMAR10)BAN指令T_{0}A_{0}\cdotAd(IR)+\overline{A}_{0}\cdot(PC)\rightarrowPCT₁Ad(CMDR)→CMAR取指微程序入口地址→CMAR上述全部微操作共20个，微指令共38条。在上述指令中，1)~5)为非访存指令；6)~8)为访存指令；9)和10)则为转移类指令。微指令的格式包括微指令的编码方式、后续微指令的地址形成方式和微指令字长等3个方面。(1)微指令的编码方式上述微操作数不多，可采用直接编码方式，由微指令控制字段的某一位直接控制一个微操作。(2)后续微指令地址的形成方式根据上述分析，可采用由指令的操作码和微指令的下地址字段两种方式形成后续微指令的地址。(3)微指令字长微指令由操作控制字段和下地址字段两部分组成。根据直接编码方式，20个微操作对应20位操作控制字段；根据38条微指令，对应6位下地址字段。这样，微指令字长至少取26位。仔细分析发现，在38条微指令中有19条微指令是为了控制将后续微指令的地址打入CMAR的操作(其中18条是微指令下地址字段Ad(CMDR)→CMAR，另一条是指令操作码OP(IR)→微地址形成部件→CMAR)，因此实际上是每两个时钟周期才能取出并执行一条微指令。如果能做到每一个时钟周期取出并执行一条微指令，将大大提高微程序控制的速度。事实上如果将CMDR的下地址字段Ad(CMDR)直接接到控制存储器的地址线上，并由下一个时钟周期的上升沿将该地址单元的内容(微指令)读到CMDR中，便能做到在一个时钟周期内读出并执行一条微指令。这就好比将Ad(CMDR)当作CMAR使用。同理，也可将指令寄存器的操作码字段OP(IR)经微地址形成部件形成的后续微指令的地址，直接送到控制存储器的地址线上。这两路地址可通过一个多路选择器，根据需要任选一路，如图10.16所示。综上所述，在省去了19条微指令的同时也省去了两个微操作(微指令下地址字段Ad(CMDR)→CMAR和指令操作码OP(IR)→微地址形成部件→CMAR)。这样,10条机器指令共对应20-2=18个微操作和38-19=19条微指令。为了便于扩充，操作控制字段取24位，下地址字段取6位，其微指令格式如图10.17所示。其中，第0位表示控制PC→MAR微操作第1位表示控制1→R微操作第2位表示控制M(MAR)→MDR第3位表示控制(PC)+1→PC第4位表示控制MDR→IR第5位表示控制0→AC第6位表示控制\overrightarrow{AC}\rightarrowAC第7位表示控制L(AC)→R(AC),AC₀→AC₀第8位表示控制R(AC)→L(AC),AC₀→ACn第9位表示控制0-→G第10位表示控制Ad(IR)→MAR第11位表示控制(MDR)+(AC)→AC第12位表示控制1→W第13位表示控制AC→MDR第14位表示控制MDR→M(MAR)第15位表示控制MDR→AC第16位表示控制Ad(IR)→PC第17位表示控制A_{0}\cdotAd(IR)+\overline{A}_{0}\cdot(PC)\rightarrowPC表10.3列出了对应10条机器指令的微指令码点。表中空格中“0”省略。在确定微指令格式及其字长的过程中，还可将一些微操作命令合用一位代码来控制，这样可大大压缩微指令的操作控制字段，缩短微指令字长。例10.7某机有5条微指令，每条微指令发出的控制信号如表10.4所示。采用直接控制方式设计微指令的控制字段，要求其位数最少，而且保持微指令本身的并行性。解：由表10.4可见，控制信号c、g、i仅在微指令I₁同时出现，可合并用1位控制字段表示。控制信号b、h仅在微指令I₂中同时出现，也可合并用1位控制字段表示。这样10个控制信号a~j可压缩到7个,其格式如图10.18所示。。分布式系统：简介播报编辑分布式系统示例在一个分布式系统中，一组独立的计算机展现给用户的是一个统一的整体，就好像是一个系统似的。系统拥有多种通用的物理和逻辑资源，可以动态的分配任务，分散的物理和逻辑资源通过计算机网络实现信息交换。系统中存在一个以全局的方式管理计算机资源的分布式操作系统。通常，对用户来说，分布式系统只有一个模型或范型。在操作系统之上有一层软件中间件（middleware）负责实现这个模型。一个著名的分布式系统的例子是万维网（WorldWideWeb），在万维网中，所有的一切看起来就好像是一个文档（Web页面）一样。[1]在计算机网络中，这种统一性、模型以及其中的软件都不存在。用户看到的是实际的机器，计算机网络并没有使这些机器看起来是统一的。如果这些机器有不同的硬件或者不同的操作系统，那么，这些差异对于用户来说都是完全可见的。如果一个用户希望在一台远程机器上运行一个程序，那么，他必须登陆到远程机器上，然后在那台机器上运行该程序。[1]分布式系统和计算机网络系统的共同点是：多数分布式系统是建立在计算机网络之上的，所以分布式系统与计算机网络在物理结构上是基本相同的。[1]他们的区别在于：分布式操作系统的设计思想和网络操作系统是不同的，这决定了他们在结构、工作方式和功能上也不同。网络操作系统要求网络用户在使用网络资源时首先必须了解网络资源，网络用户必须知道网络中各个计算机的功能与配置、软件资源、网络文件结构等情况，在网络中如果用户要读一个共享文件时，用户必须知道这个文件放在哪一台计算机的哪一个目录下；分布式操作系统是以全局方式管理系统资源的，它可以为用户任意调度网络资源，并且调度过程是“透明”的。当用户提交一个作业时，分布式操作系统能够根据需要在系统中选择最合适的处理器，将用户的作业提交到该处理程序，在处理器完成作业后，将结果传给用户。在这个过程中，用户并不会意识到有多个处理器的存在，这个系统就像是一个处理器一样。[1]内聚性是指每一个数据库分布节点高度自治，有本地的数据库管理系统。透明性是指每一个数据库分布节点对用户的应用来说都是透明的，看不出是本地还是远程。在分布式数据库系统中，用户感觉不到数据是分布的，即用户不须知道关系是否分割、有无副本、数据存于哪个站点以及事务在哪个站点上执行等。[1]分类播报编辑分布式计算机系统的体系结构可用处理机之间的耦合度为主要标志来加以描述。耦合度是系统模块之间互联的紧密程度，它是数据传输率、响应时间、并行处理能力等性能指标的综合反映，主要取决于所选用体系结构的互联拓扑结构和通信链路的类型。[2]按地理环境衡量耦合度，分布式系统可以分为机体内系统、建筑物内系统、建筑物间系统和不同地理范围的区域系统等，它们的耦合度依次由高到低按应用领域的性质决定耦合度，可以分成三类：[2]第一种是面向计算任务的分布并行计算机系统和分布式多用户计算机系统，它们要求尽可能高的耦合度，以便发展成为能分担大型计算机和分时计算机系统所完成的工作。[2]第二种是面向管理信息的分布式数据处理系统。耦合度可以适当降低。[2]第三种是面向过程控制的分布式计算机控制系统。耦合度要求适中，当然对于某些实时应用，其耦合度的要求可能很高。[2]特征播报编辑分布式系统是多个处理机通过通信线路互联而构成的松散耦合的系统。从系统中某台处理机来看，其余的处理机和相应的资源都是远程的，只有它自己的资源才是本地的。至今，对分布式系统的定义尚未形成统一的见解。一般认为，分布式系统应具有以下四个特征：[3](1)分布性。分布式系统由多台计算机组成，它们在地域上是分散的，可以散布在一个单位、一个城市、一个国家，甚至全球范围内。整个系统的功能是分散在各个节点上实现的，因而分布式系统具有数据处理的分布性。[3](2)自治性。分布式系统中的各个节点都包含自己的处理机和内存，各自具有独立的处理数据的功能。通常，彼此在地位上是平等的，无主次之分，既能自治地进行工作，又能利用共享的通信线路来传送信息，协调任务处理。[3](3)并行性。一个大的任务可以划分为若干个子任务，分别在不同的主机上执行。[3](4)全局性。分布式系统中必须存在一个单一的、全局的进程通信机制，使得任何一个进程都能与其他进程通信，并且不区分本地通信与远程通信。同时，还应当有全局的保护机制。系统中所有机器上有统一的系统调用集合，它们必须适应分布式的环境。在所有CPU上运行同样的内核，使协调工作更加容易。[3]优缺点播报编辑优点(1)资源共享。若干不同的节点通过通信网络彼此互联，一个节点上的用户可以使用其他节点上的资源，如分布式系统允许设备共享，使众多用户共享昂贵的外部设备，如彩色打印机；允许数据共享，使众多用户访问共用的数据库；可以共享远程文件，使用远程特有的硬件设备（如高速阵列处理器），以及执行其他操作。[3](2)加快计算速度。如果一个特定的计算任务可以划分为若干个并行运行的子任务，则可把这些子任务分散到不同的节点上，使它们同时在这些节点上运行，从而加快计算速度。另外，分布式系统具有计算迁移功能，如果某个节点上的负载太重，则可把其中一些作业移到其他节点去执行，从而减轻该节点的负载。这种作业迁移称为负载平衡。[3](3)可靠性高。分布式系统具有高可靠性。如果其中某个节点失效了，则其余的节点可以继续操作，整个系统不会因为一个或少数几个节点的故障而全体崩溃。因此，分布式系统有很好的容错性能。[3]系统必须能够检测节点的故障，采取适当的手段，使它从故障中恢复过来。系统确定故障所在的节点后，就不再利用它来提供服务，直至其恢复正常工作。如果失效节点的功能可由其他节点完成，则系统必须保证功能转移的正确实施。当失效节点被恢复或者修复时，系统必须把它平滑地集成到系统中。[3](4)通信方便、快捷。分布式系统中各个节点通过一个通信网络互联在一起。通信网络由通信线路、调制解调器和通信处理器等组成，不同节点的用户可以方便地交换信息。在低层，系统之间利用传递消息的方式进行通信，这类似于单CPU系统中的消息机制。单CPU系统中所有高层的消息传递功能都可以在分布式系统中实现，如文件传递、登录、邮件、Web浏览和远程过程调用(RemoteProcedurecall，RPC)。[3]分布式系统实现了节点之间的远距离通信，为人与人之间的信息交流提供了很大方便不同地区的用户可以共同完成一个项目，通过传送项目文件，远程登录进入对方系统来运行程序，如发送电子邮件等，协调彼此的工作。[3]缺点尽管分布式系统具备众多优势，但它也有自身的缺点，主要是可用软件不足，系统软件、编程语言、应用程序以及开发工具都相对很少。此外，还存在通信网络饱和或信息丢失和网络安全问题，方便的数据共享同时意味着机密数据容易被窃取。虽然分布式系统存在这些潜在的问题，但其优点远大于缺点，而且这些缺点也正得到克服。因此，分布式系统仍是人们研究、开发和应用的方向。应用播报编辑分布式系统被用在许多不同类型的应用中。以下列出了一些应用。对这些应用而言，使用分布式系统要比其他体系结构如处理机和共享存储器多处理机更优越：[4]并行原则上，并行应用也可以在共享存储器多处理机上运行，但共享存储器系统不能很好地扩大规模以包括大量的处理机。HPCC（高性能计算和通信）应用一般需要一个可伸缩的设计，这种设计取决于分布式处理。[4]容错应用因为每个PE是自治的，所以分布式系统更加可靠。一个单元或资源（软件或硬件）的故障不影响其他资源的正常功能。[4]固有的应用许多应用是固有分布式的。这些应用是突发模式（burstmode）而非批量模式（bulkmode）。这方面的实例有事务处理和InternetJavad，程序。[4]这些应用的性能取决于吞吐量（事务响应时间或每秒完成的事务数）而不是一般多处理机所用的执行时间。[4]对于一组用户而言，分布式系统有一个特别的应用称为计算机支持的协同工作（ComputerSupportedCooperativeWorking，CSCW）或群件（groupware），支持用户协同工作。另一个应用是分布式会议，即通过物理的分布式网络进行电子会议。同样，多媒体远程教学也是一个类似的应用。[4]为了达到互操作性，用户需要一个标准的分布式计算环境，在这个环境里，所有系统和资源都可用。[4]DCE（分布式计算环境）是OSF（开放系统基金会）开发的分布式计算技术的工业标准集。它提供保护和控制对数据访问的安全服务、容易寻找分布式资源的名字服务、以及高度可伸缩的模型用于组织极为分散的用户、服务和数据。DCE可在所有主要的计算平台上运行，并设计成支持异型硬件和软件环境下的分布式应用。[4]DCE已经被包括TRANSVARL在内的一些厂商实现。TRANSVARL是最早的多厂商组（multivendorteam）的成员之一，它提出的建议已成为DCE体系结构的基础。在中可以找到利用DCE开发分布式应用的指南。[4]一些其它标准基于一个特别的模型，比如CORBA（公用对象请求代理程序体系结构），它是由OMG（对象管理组）和多计算机厂商联盟开发的一个标准。CORBA使用面向对象模型实现分布式系统中的透明服务请求。[4]工业界有自己的标准，比如微软的分布式构件对象模型（DCOM）和SunMicrosystem公司的JavaBeans。[4]与计算机网络异同播报编辑分布式计算机系统与计算机网络既有类似之处又有不同点，其主要的异同如下：[5](1)在计算机网络中，每个用户或任务通常只使用一台计算机，若要利用网络中的另一台计算机，则需要远程注册。在分布式计算机系统中，用户进程在系统内各个计算机上动态调度，并根据运行情况由分布式操作系统动态地、透明地将机器分配给用户进程或任务。[5](2)在计算机网络中，用户知道它们的文件存放在何处，并用显示的文件传输命令在机器之间传送文件。在分布式计算机系统中，文件的放置由操作系统管理，用户可用相同方式访问系统中的所有文件而不管它们位于何处。[5](3)在计算机网络中，各结点计算机均有自己的操作系统，资源归局部所有并被局部控制，网络内的进程调度是通过进程迁移和数据迁移实现的。在分布式计算机系统中，每个场点上运行一个局部操作系统，执行的任务可以是独立的，可以是某任务的一个部分，也可以是其他场点上的(部分)任务，且各场点相互协同，合作平衡系统内的负载。[5](4)在计算机网络中，系统几乎无容错能力。在分布式计算机系统中有系统自动重构、适度降级使用及错误恢复功能。[5](5)两者透明性的程度和级别不同。[5](6)就资源共享而言，计算机网络和分布式计算机系统是类似的。[5]系统设计难点播报编辑虽然分布式系统具有很多优点，然而由于分布式系统自身的特点及应用环境的复杂性，分布式系统设计有如下的很多难题需要解决:[6]1.部分失效问题由于分布式系统通常由若干部分组成，各个部分由于各种原因可能发生故障，如硬件故障、软件错误及错误操作等。如果一个分布式系统不对这些故障进行有效的处理，系统某一组成部分的故障可能导致整个系统的瘫痪。[6]2.性能和可靠性过分依赖于网络由于分布式系统是建立在网络之上的，而网络本身是不可靠的，可能经常发生故障，网络故障可能导致系统服务的终止。另外，网络超负荷会导致性能的降低，增加系统的响应时间。[6]3.缺乏统一控制一个分布式系统的控制通常是一个典型的分散控制，没有统一的中心控制。因此，分布式系统通常需要相应的同步机制来协调系统中各个部分的工作。设计与实现一个对用户来说是透明的且具有容错能力的分布式系统是一项具有挑战性的工作，而且所需的机制和策略尚未成熟。因此什么样的程序设计模型、什么样的控制机制最适合分布式系统仍是需要继续研究的课题。[6]4.难以合理设计资源分配策略在集中式系统中，所有的资源都由操作系统管理和分配，但在分布式系统中，资源属于各节点，所以调度的灵活性不如集中式系统，资源的物理分布可能与用户请求的分布不匹配，某些资源可能空闲，而另一些资源可能超载。[6]5.安全保密性问题开放性使得分布式系统中的许多软件接口都提供给用户，这样的开放式结构对于开发人员非常有价值，但同时也为破坏者打开了方便之门。[6]针对分布式系统存在的上述难点，要保证一个分布式系统的正常运行，就必须对系统资源进行有效的管理，对计算机之间的通信、故障、安全等问题提供有效的处理手段和支持机制。[6]用户对分布式系统的要求是透明性、安全性、灵活性、简单性、可靠性，也要求方便在局部失效时重构系统，以及集成不均匀子系统的能力。[6]资源的分布性、缺乏全局状态信息及传输延迟，意味着集中式操作系统的某些方法和技术不能应用于分布式系统中。即使集中式系统中的某些技术满足上面的要求，其实现通常也是要付出很大代价的。[6]总线冲突：通常，连接到总线的集成电路是预先被设计好的，以便总线冲突的可能性降低为零，芯片是在它们的速率设置时间之内被操作等等。然而，如果这个总线故意被驱动太快，这些设置时间可能被干扰而导致无法正常连接。连接也可能出现在那些内存映射是不可编程的系统中，不合法的值被写入到这个寄存器中来控制这个映射。使得计算机总线无法正常工作，进而可能会导致电脑死机系统崩溃。汇编指令：编译背景播报编辑任何一种微处理器（CPU）在设计时，就已规定好自己特定的指令系统，这种指令系统的功能也就决定了由该微处理器构成的计算机系统及其基本功能。指令系统中所设计的每条指令都对应着微处理器要完成的一种规定功能操作，即这些指令功能的实现都是由微处理器中的物理器件完成的。要使计算机完成一个完整的任务，就需要执行一组指令，这组指令通常称为程序。计算机能够执行的各种不同指令的集合就称为处理器（CPU）的指令系统。[3]一台计算机只能识别由二进制编码表示的指令，称之为机器指令。一条机器指令应包括两部分内容：一部分给出该指令应完成何种操作，称为指令操作码部分；另一部分给出参与操作的操作数的值，或指出操作数存放在何处、操作的结果应送往何处等，这一部分称为指令的操作数部分。处理器可根据指令中给出的地址信息求出存放操作数的地址称为有效地址EA（EffectiveAddress），然后对存放在有效地址中的操作数进行存取操作。指令中关于如何求岀存放操作数有效地址的方法称为操作数的寻址方式。计算机按照指令给出的寻址方式求出操作数有效地址进行存取操作数的过程，称为指令的寻址操作。[3]指令的格式播报编辑指令是计算机能够识别和执行的操作命令，由二进制数“0”、“1”组成。每条指令的编码格式由机器指令系统规定。通常，一条指令包含操作码和操作数两部分内容，格式如下图所示：汇编指令格式操作码（OperationCode）用来说明指令操作的性质与功能，常用OP表示。操作码是指令中不可缺少的部分，通常由1~2个字节组成，机器通过译码电路来识别指令。操作数用于提供指令中要处理的数据或数据所在的地址信息。以MOV指令作为例子，MOV指令的格式为：MOVdst，src。其中：MOV为指令助记符，表示传送，dst为目标操作数，src表示源操作数，该指令的功能是将源操作数传送到目标单元。例如：MOV......AL，20H；将8位立即数20H传送到AL中。MOV......AX，1234H；将16位立即数1234H传送到AX中。MOV......EAX，34568020H；将32位立即数34568020H传送到EAX中。[4]寻址方式播报编辑寄存器寻址操作数的值在寄存器中，指令中的地址码字段指出的是寄存器编号，指令执行时直接取出寄存器值来操作。[5]立即寻址立即寻址指令中的操作码字段后面的地址码部分即是操作数本身，也就是说，数据就包含在指令当中，取出指令也就取出了可以立即使用的操作数（立即数）。[5]寄存器移位寻址寄存器移位寻址是ARM指令集特有的寻址方式。当第2个操作数是寄存器移位方式时，第2个寄存器操作数在与第1个操作数结合之前，选择进行移位操作。[5]寄存器间接寻址寄存器间接寻址指令中的地址码给出的是一个通用寄存器的编号，所需的操作数保存在寄存器指定地址的存储单元中，即寄存器为操作数的地址指针。[5]基址寻址基址寻址就是将基址寄存器的内容与指令中给出的偏移量相加，形成操作数的有效地址。基址寻址用于访问基址附近的存储单元，常用于査表、数组操作、功能部件寄存器访问等。[5]多寄存器寻址多寄存器寻址一次可以传送几个寄存器值，允许一条指令传送16个寄存器的任何子集或所有寄存器。[5]堆栈寻址堆栈寻址是一个按特定顺序进行存取的存储区，操作顺序为”后进先出“。堆栈寻址是隐含的，它使用一个专门的寄存器（堆栈指针）指向一块存储区域（堆栈），指针所指向的存储单元即是堆栈的栈顶。[5]数据传输指令播报编辑数据传输类指令主要包括数据传送、数据交换、堆栈操作、查表转换、地址传送、标志位传送、I/O数据传送指令。这类指令的主要特点是大部分指令操作完成后，对FR中的标志位不产生影响。它们在存储器和寄存器、寄存器和输入输出端口之间传送数据。[4]数据传送指令MOV：传送字或字节。MOVSX：先符号扩展，再传送。MOVZX：先零扩展，再传送。PUSH：把字压入堆栈。POP：把字弹出堆栈。PUSHA：把AX，CX，DX，BX，SP，BP，SI，DI依次压入堆栈。POPA：把DI，SI，BP，SP，BX，DX，CX，AX依次弹出堆栈。PUSHAD：把EAX，ECX，EDX，EBX，ESP，EBP，ESI，EDI依次压入堆栈。POPAD：把EDI，ESI，EBP，ESP，EBX，EDX，ECX，EAX依次弹出堆栈。BSWAP：交换32位寄存器里字节的顺序。XCHG：交换字或字节。(至少有一个操作数为寄存器,段寄存器不可作为操作数)CMPXCHG：比较并交换操作数。（第二个操作数必须为累加器AL/AX/EAX）XADD：先交换再累加。(结果在第一个操作数里)XLAT：字节查表转换──BX指向一张256字节的表的起点，AL为表的索引值（0-255，即0-FFH）；返回AL为查表结果（[BX+AL]->AL）[6]输入输出端口传送指令IN：I/O端口输入。（语法：IN累加器，{端口号│DX}）OUT：I/O端口输出.（语法：OUT{端口号│DX}，累加器）输入输出端口由立即方式指定时，其范围是0-255；由寄存器DX指定时，其范围是0-65535。[6]目的地址传送指令LEA：装入有效地址。例：LEADX，string；把偏移地址存到DX。LDS：传送目标指针，把指针内容装入DS。例：LDSSI，string；把段地址：偏移地址存到DS：SI。LES：传送目标指针，把指针内容装入ES。例：LESDI，string；把段地址：偏移地址存到ES：DI。LFS：传送目标指针，把指针内容装入FS。例：LFSDI，string；把段地址：偏移地址存到FS：DI。LGS：传送目标指针，把指针内容装入GS。例：LGSDI，string；把段地址：偏移地址存到GS：DI。LSS：传送目标指针，把指针内容装入SS。例：LSSDI，string；把段地址：偏移地址存到SS：DI。[6]标志传送指令LAHF：标志寄存器传送，把标志装入AH。SAHF：标志寄存器传送，把AH内容装入标志寄存器。PUSHF：标志入栈。POPF：标志出栈。PUSHD：32位标志入栈。POPD：32位标志出栈。[6]算术运算指令播报编辑算数运算类指令包括加减乘除、比较与调整指令。它们可进行8位、16位和32位的运算。参加运算的操作数可以说二进制数和十进制数（BCD码），这些数可以是无符号数，也可以是带符号数。算术运算指令的主要特点是执行结果影响标志寄存器的状态标志位OF、SF、ZF、AF、PF、CF。[4]ADD：加法。ADC：带进位加法。INC：加1。AAA：加法的ASCII码调整。DAA：加法的十进制调整。SUB：减法。SBB：带借位减法。DEC：减1。NEG：取补。CMP：比较。（两操作数作减法，仅修改标志位，不回送结果）AAS：减法的ASCII码调整。DAS：减法的十进制调整。MUL：无符号乘法。结果回送AH和AL（字节运算），或DX和AX（字运算）IMUL：整数乘法。结果回送AH和AL（字节运算），或DX和AX（字运算）AAM：乘法的ASCII码调整。DIV：无符号除法：商回送AL，余数回送AH，（字节运算）；或商回送AX，余数回送DX（字运算）IDIV：整数除法：商回送AL，余数回送AH，（字节运算）；或商回送AX，余数回送DX（字运算）AAD：除法的ASCII码调整。CBW：字节转换为字。（把AL中字节的符号扩展到AH中去）CWD：字转换为双字。（把AX中的字的符号扩展到DX中去）CWDE：字转换为双字。（把AX中的字符号扩展到EAX中去）CDQ：双字扩展。（把EAX中的字的符号扩展到EDX中去）[6]逻辑运算类指令播报编辑逻辑运算类指令分为逻辑运算指令和移位指令两大类。[4]逻辑运算指令AND：与运算。or：或运算。XOR：异或运算。NOT：取反。TEST：测试。（两操作数作与运算，仅修改标志位，不回送结果）[6]移位指令SHL：逻辑左移。SAL：算术左移。(=SHL)SHR：逻辑右移。（每位右移，低位进CF，高位补0）SAR：算术右移。（每位右移，低位进CF，高位不变）ROL：循环左移。ROR：循环右移。RCL：通过进位的循环左移。RCR：通过进位的循环右移。以上八种移位指令，其移位次数可达255次。移位一次时，可直接用操作码，如：SHLAX，1；移位>1次时，则由寄存器CL给出移位次数，如：MOVCL，04；SHLAX，CL。[6]串操作指令播报编辑串操作指令用于处理存放在存储器中的数据串，有串传送、串比较、串扫描、串装入、串存储。其中，仅有串比较和串扫描指令对标志位OF、SF、ZF、AF、PF、CF有影响。[4]DS：SI——源串段寄存器：源串变址。ES：DI——目标串段寄存器：目标串变址。CX：重复次数计数器。AL/AX：扫描值。D标志：0表示重复操作中SI和DI应自动增量；1表示应自动减量。Z标志：用来控制扫描或比较操作的结束。MOVS：串传送。（MOVSB传送字符，MOVSW传送字，MOVSD传送双字）CMPS：串比较。（CMPSB比较字符，CMPSW比较字）SCAS：串扫描。把AL或AX的内容与目标串作比较，比较结果反映在标志位。LODS：装入串。把源串中的元素（字或字节）逐一装入AL或AX中。（LODSB传送字符，LODSW传送字，LODSD传送双字）STOS：保存串。是LODS的逆过程。REP：当CX/ECX<>0时重复。REPE/REPZ：当ZF=1或比较结果相等，且CX/ECX<>0时重复。REPNE/REPNZ：当ZF=0或比较结果不相等，且CX/ECX<>0时重复。REPC：当CF=1且CX/ECX<>0时重复。REPNC：当CF=0且CX/ECX<>0时重复。[6]程序转移指令播报编辑控制转移类指令包括无条件转移指令、条件转移指令、循环控制指令、中断指令、子程序调用和返回指令。[4]无条件转移指令（长转移）JMP：无条件转移指令。CALL：过程调用。RET/RETF：过程返回。[6]条件转移指令（短转移，-128到+127的距离内；当且仅当(SF、XOR、OF)=1时，OP1<OP2）JA/JNBE：大于转移。JAE/JNB：大于或等于转移。JB/JNAE：小于转移。JBE/JNA：小于或等于转移。以上四条，测试无符号整数运算的结果（标志C和Z）JG/JNLE：大于转移。JGE/JNL：大于或等于转移。JL/JNGE：小于转移。JLE/JNG：小于或等于转移。以上四条，测试带符号整数运算的结果（标志S，O和Z）JE/JZ：等于转移。JNE/JNZ：不等于时转移。JC：有进位时转移。JNC：无进位时转移。JNO：不溢出时转移。JNP/JPO：奇偶性为奇数时转移。JNS：符号位为"0"时转移。JO：溢出转移。JP/JPE：奇偶性为偶数时转移。JS：符号位为"1"时转移。[6]循环控制指令（短转移）LOOP：CX不为零时循环。LOOPE/LOOPZ：CX不为零且标志Z=1时循环。LOOPNE/LOOPNZ：CX不为零且标志Z=0时循环。JCXZ：CX为零时转移。JECXZ：ECX为零时转移。[6]中断指令INT：中断指令。INTO：溢出中断。IRET：中断返回。[6]其他指令播报编辑伪指令DB：定义字节（1字节）DW：定义字（2字节）DD：定义双字（4字节）PROC：定义过程。ENDP：过程结束。SEGMENT：定义段。ASSUME：建立段寄存器寻址。ENDS：段结束。END：程序结束。[6]处理机控制指令即标志处理指令，处理机控制指令完成简单的控制功能。CLC：（进位位置0指令）CMC：（进位位求反指令）CLC：（进位位置为0指令）STC：（进位位置为1指令）CLD：（方向标志位置0指令）STD：（方向标志位置1指令）CLI：（中断标志置0指令）STI：（中断标志置1指令）NOP：（无操作）HLT：（停机）WAIT：（等待）ESC：（换码）LOCK：（封锁）[6]冯诺依曼体系结构：发展历史播报编辑在计算机诞生之前，人们在计算的精度和数量上出现了瓶颈，对于计算机这样的机器的需求就十分强烈，冯·诺依曼的逻辑和计算机思想指导他设计并制造出历史上的第一台通用电子计算机。他的计算机理论主要受自身数学基础影响，且具有高度数学化、逻辑化特征，对于该理论，他自己一般会叫作“计算机的逻辑理论”。而他的计算机存储程序的思想，则是他的另一伟大创新，通过内部存储器安放存储程序，成功解决了当时计算机存储容量太小，运算速度过慢的问题。[1]冯·诺依曼第二次世界大战期间，美军要求实验室为其提供计算量庞大的计算结果。于是便有了研制电子计算机的设想。面对这种需求，美国立即组建研发团队，包括许多工程师与物理学家，试图开发全球首台计算机（后世称作ENIAC机）。虽然采取了最先进的电子技术，但缺少原理上的指导。这时，冯·诺依曼出现了。他提出了一个至关重要的方面：计算机的逻辑结构。冯·诺依曼从逻辑入手，带领团队对ENIAC进行改进。他的逻辑设计具有以下特点：（1）将电路、逻辑两种设计进行分离，给计算机建立创造最佳条件；（2）将个人神经系统、计算机结合在一起，提出全新理念，即生物计算机。即便ENIAC机是通过当时美国乃至全球顶尖技术实现的，但它采用临时存储，将运算器确定成根本，故而缺点较多，比如存储空间有限、程序无法存储等，且运行速度较慢，具有先天不合理性。冯·诺依曼以此为前提制定以下优化方案：（1）用二进制进行运算，大大加快了计算机速度；（2）存储程序，也就是通过计算机内部存储器保存运算程序。如此一来，程序员仅仅通过存储器写入相关运算指令，计算机便能立即执行运算操作，大大加快运算效率。[1]冯·诺依曼结构示意图特点及局限播报编辑特点现代计算机发展所遵循的基本结构形式始终是冯·诺依曼机结构。这种结构特点是“程序存储，共享数据，顺序执行”，需要CPU从存储器取出指令和数据进行相应的计算。[2]主要特点有：（1）单处理机结构，机器以运算器为中心；（2）采用程序存储思想；（3）指令和数据一样可以参与运算；（4）数据以二进制表示；（5）将软件和硬件完全分离；（6）指令由操作码和操作数组成；（7）指令顺序执行。[3]局限CPU与共享存储器间的信息交换的速度成为影响系统性能的主要因素，而信息交换速度的提高又受制于存储元件的速度、存储器的性能和结构等诸多条件。传统冯·诺依曼计算机体系结构的存储程序方式造成了系统对存储器的依赖，CPU访问存储器的速度制约了系统运行的速度。集成电路IC芯片的技术水平决定了存储器及其他硬件的性能。为了提高硬件的性能，以英特尔公司为代表的芯片制造企业在集成电路生产方面做出了极大的努力，且获得了巨大的技术成果。现在每隔18个月IC的集成度翻一倍，性能也提升一倍，产品价格降低一半，这就是所谓的“摩尔定律”。这个规律已经持续了40多年，估计还将延续若干年。然而，电子产品面临的二个基本限制是客观存在的：光的速度和材料的原子特性。首先，信息传播的速度最终将取决于电子流动的速度，电子信号在元件和导线里流动会产生时间延迟，频率过高会造成信号畸变，所以元件的速度不可能无限的提高直至达到光速。第二，计算机的电子信号存储在以硅晶体材料为代表晶体管上，集成度的提高在于晶体管变小，但是晶体管不可能小于一个硅原子的体积。随着半导体技术逐渐逼近硅工艺尺寸极限，摩尔定律原导出的规律将不再适用。对冯·诺依曼计算机体系结构缺陷的分析：（1）指令和数据存储在同一个存储器中，形成系统对存储器的过分依赖。如果储存器件的发展受阻，系统的发展也将受阻。（2）指令在存储器中按其执行顺序存放，由指令计数器PC指明要执行的指令所在的单元地址。然后取出指令执行操作任务。所以指令的执行是串行。影响了系统执行的速度。（3）存储器是按地址访问的线性编址，按顺序排列的地址访问，利于存储和执行的机器语言指令，适用于作数值计算。但是高级语言表示的存储器则是一组有名字的变量，按名字调用变量，不按地址访问。机器语言同高级语言在语义上存在很大的间隔，称之为冯·诺依曼语义间隔。消除语义间隔成了计算机发展面临的一大难题。（4）冯·诺依曼体系结构计算机是为算术和逻辑运算而诞生的，目前在数值处理方面已经到达较高的速度和精度，而非数值处理应用领域发展缓慢，需要在体系结构方面有重大的突破。（5）传统的冯·诺依曼型结构属于控制驱动方式。它是执行指令代码对数值代码进行处理，只要指令明确，输入数据准确，启动程序后自动运行而且结果是预期的。一旦指令和数据有错误，机器不会主动修改指令并完善程序。而人类生活中有许多信息是模糊的，事件的发生、发展和结果是不能预期的，现代计算机的智能是无法应对如此复杂任务的。[2]哈佛结构以及两者区别播报编辑哈佛结构哈佛结构的计算机分为三大部件：（1）CPU；（2）程序存储器；（3）数据存储器。它的特点是将程序指令和数据分开存储，由于数据存储器与程序存储器采用不同的总线，因而较大的提高了存储器的带宽，使之数字信号处理性能更加优越。[3]哈佛结构是一种将程序指令存储和数据存储分开的存储器结构。中央处理器首先到程序指令存储器中读取程序指令内容，解码后得到数据地址，再到相应的数据存储器中读取数据，并进行下一步的操作（通常是执行）。程序指令存储和数据存储分开，可以使指令和数据有不同的数据宽度，如Microchip公司的PIC16芯片的程序指令是14位宽度，而数据是8位宽度。为避免将程序和指令共同存储在存储器中，并共用同一条总线，使得CPU和内存的信息流访问存取成为系统的瓶颈，人们设计了哈佛结构，原则是将程序和指令分别存储在不同的存储器中，分别访问。如此设计克服了数据流传输瓶颈，提高了运算速度，但结构复杂，对外围设备的连接与处理要求高，不适合外围存储器的扩展，实现成本高，所以哈佛结构未能得到大范围的应用。但是作为冯式存储程序的改良手段，哈佛结构在CPU内的高速缓存Cache中得到了应用。通过设置指令缓存和数据缓存，指令和数据分开读取，提高了数据交换速度，极大克服了计算机的数据瓶颈。通过增加处理器数量，中央处理单元从最初的单核向双核、四核的方向发展，在冯氏计算机的简单结构下，增加处理器数量，也极大提高了计算机的运算性能。存储程序的方式使得计算机擅长数值处理而限制了其在非数值处理方面的发展。[4]哈佛结构处理器有两个明显的特点：使用两个独立的存储器模块，分别存储指令和数据，每个存储模块都不允许指令和数据并存；使用独立的两条总线，分别作为CPU与每个存储器之间的专用通信路径，而这两条总线之间毫无关联。改进的哈佛结构，其结构特点为：以便实现并行处理；具有一条独立的地址总线和一条独立的数据总线，利用公用地址总线访问两个存储模块（程序存储模块和数据存储模块），公用数据总线则被用来完成程序存储模块或数据存储模块与CPU之间的数据传输。两者区别冯·诺依曼理论的要点是：数字计算机的数制采用二进制；计算机应该按照程序顺序执行。人们把冯诺依曼的这个理论称为冯诺依曼体系结构。从ENIAC到当前最先进的计算机都采用的是冯诺依曼体系结构。所以冯诺依曼是当之无愧的数字计算机之父。根据冯诺依曼体系结构构成的计算机，必须具有如下功能：把需要的程序和数据送至计算机中；必须具有长期记忆程序、数据、中间结果及最终运算结果的能力；能够完成各种算术、逻辑运算和数据传送等数据加工处理的能力；能够根据需要控制程序走向，并能根据指令控制机器的各部件协调操作；能够按照要求将处理结果输出给用户。哈佛结构是为了高速数据处理而采用的，因为可以同时读取指令和数据（分开存储的）。大大提高了数据吞吐率，缺点是结构复杂。通用微机指令和数据是混合存储的，结构上简单，成本低。假设是哈佛结构：你就得在电脑安装两块硬盘，一块装程序，一块装数据，内存装两根，一根储存指令，一根存储数据……是什么结构要看总线结构的。51单片机虽然数据指令存储区是分开的，但总线是分时复用的，所以顶多算改进型的哈佛结构。ARM9虽然是哈佛结构，但是之前的版本也还是冯·诺依曼结构。早期的X86能迅速占有市场，一条很重要的原因，正是靠了冯·诺依曼这种实现简单，成本低的总线结构。处理器虽然外部总线上看是诺依曼结构的，但是由于内部CACHE的存在，因此实际上内部来看已经算是改进型哈佛结构的了。展望播报编辑冯·诺依曼结构开启了计算机系统结构发展的先河，但是因为其集中、顺序的的控制而成为性能提高的瓶颈，因此各国科学家仍然在探索各种非冯·诺依曼结构，比如，数据流计算机，函数式编程语言计算机等都是较为著名的非冯·诺依曼结构。[3]近几年来人们努力谋求突破传统冯·诺依曼体制的局限，各类非诺依曼化计算机的研究如雨后春笋蓬勃发展，主要表现在以下四个方面：（1）对传统冯·诺依曼机进行改良，如传统体系计算机只有一个处理部件是串行执行的，改成多处理部件形成流水处理，依靠时间上的重叠提高处理效率。（2）由多个处理器构成系统，形成多指令流多数据流支持并行算法结构。这方面的研究目前已经取得一些成功。（3）否定冯·诺依曼机的控制流驱动方式。设计数据流驱动工作方式的数据流计算机，只要数据已经准备好，有关的指令就可并行地执行。这是真正非诺依曼化的计算机，这样的研究还在进行中，已获得阶段性的成果，如神经计算机。（4）彻底跳出电子的范畴，以其它物质作为信息载体和执行部件，如光子、生物分子、量子等。众多科学家正在进行这些前瞻性的研究。[2]虚拟存储器：作用播报编辑虚拟存储器虚拟内存的作用内存在计算机中的作用很大，电脑中所有运行的程序都需要经过内存来执行，如果执行的程序很大或很多，就会导致内存消耗殆尽。为了解决这个问题，Windows中运用了虚拟内存技术，即拿出一部分硬盘空间来充当内存使用，当内存占用完时，电脑就会自动调用硬盘来充当内存，以缓解内存的紧张。举一个例子来说，如果电脑只有128MB物理内存的话，当读取一个容量为200MB的文件时，就必须要用到比较大的虚拟内存，文件被内存读取之后就会先储存到虚拟内存，等待内存把文件全部储存到虚拟内存之后，跟着就会把虚拟内存里储存的文件释放到原来的安装目录里了。设置播报编辑虚拟存储器虚拟内存的设置对于虚拟内存主要设置两点，即内存大小和分页位置，内存大小就是设置虚拟内存最小为多少和最大为多少；而分页位置则是设置虚拟内存应使用那个分区中的硬盘空间。对于内存大小的设置，如何得到最小值和最大值呢？你可以通过下面的方法获得：选择“开始→程序→附件→系统工具→系统监视器”（如果系统工具中没有，可以通过“添加/删除程序”中的Windows安装程序进行安装）打开系统监视器，然后选择“编辑→添加项目”，在“类型”项中选择“内存管理程序”，在右侧的列表选择“交换文件大小”。这样随着你的操作，会显示出交换文件值的波动情况，你可以把经常要使用到的程序打开，然后对它们进行使用，这时查看一下系统监视器中的表现值，由于用户每次使用电脑时的情况都不尽相同，因此，最好能够通过较长时间对交换文件进行监视来找出最符合您的交换文件的数值，这样才能保证系统性能稳定以及保持在最佳的状态。找出最合适的范围值后，在设置虚拟内存时，用鼠标右键点击“我的电脑”，选择“属性”，弹出系统属性窗口，选择“性能”标签，点击下面“虚拟内存”按钮，弹出虚拟内存设置窗口，点击“用户自己指定虚拟内存设置”单选按钮，“硬盘”选较大剩余空间的分区，然后在“最小值”和“最大值”文本框中输入合适的范围值。如果您感觉使用系统监视器来获得最大和最小值有些麻烦的话，这里完全可以选择“让Windows管理虚拟内存设置”。调整分页位置播报编辑虚拟存储器Windows9x的虚拟内存分页位置，其实就是保存在C盘根目录下的一个虚拟内存文件（也称为交换文件）Win386.swp，它的存放位置可以是任何一个分区，如果系统盘C容量有限，我们可以把Win386.swp调到别的分区中，方法是在记事本中打开System.ini（C:\\Windows下）文件，在[386Enh]小节中，将“PagingDrive=C:WindowsWin386.swp”，改为其他分区的路径，如将交换文件放在D:中，则改为“PagingDrive=D:Win386.swp”，如没有上述语句可以直接键入即可。而对于使用Windows2000和WindowsXP的，可以选择“控制面板→系统→高级→性能”中的“设置→高级→更改”，打开虚拟内存设置窗口，在驱动器[卷标]中默认选择的是系统所在的分区，如果想更改到其他分区中，首先要把原先的分区设置为无分页文件，然后再选择其他分区。如果你的硬盘够大，那就请你打开”控制面板“中的“系统”，在“性能”选项中打开“虚拟内存”，选择第二项：用户自己设定虚拟内存设置，指向一个较少用的硬盘，并把最大值和最小值都设定为一个固定值，大小为物理内存的2倍左右。这样，虚拟存储器在使用硬盘时，就不用迁就其忽大忽小的差别，而将固定的空间作为虚拟内存，加快存取速度。虚拟内存的设置最好在“磁盘碎片整理”之后进行，这样虚拟内存就分布在一个连续的、无碎片文件的空间上，可以更好的发挥作用。使用技巧播报编辑虚拟内存使用技巧虚拟存储器对于虚拟内存如何设置的问题，微软已经给我们提供了官方的解决办法，对于一般情况下，我们推荐采用如下的设置方法：(1)在Windows系统所在分区设置页面文件，文件的大小由你对系统的设置决定。具体设置方法如下：打开"我的电脑"的"属性"设置窗口，切换到"高级"选项卡，在"启动和故障恢复"窗口的"写入调试信息"栏，如果你采用的是"无"，则将页面文件大小设置为2MB左右，如果采用"核心内存存储"和"完全内存存储"，则将页面文件值设置得大一些，跟物理内存差不多就可以了。小提示：对于系统分区是否设置页面文件，这里有一个矛盾：如果设置，则系统有可能会频繁读取这部分页面文件，从而加大系统盘所在磁道的负荷，但如果不设置，当系统出现蓝屏死机(特别是STOP错误)的时候，无法创建转储文件(Memory.dmp)，从而无法进行程序调试和错误报告了。所以折中的办法是在系统盘设置较小的页面文件，只要够用就行了。虚拟存储器(2)单独建立一个空白分区，在该分区设置虚拟内存，其最小值设置为物理内存的1.5倍，最大值设置为物理内存的3倍，该分区专门用来存储页面文件，不要再存放其它任何文件。之所以单独划分一个分区用来设置虚拟内存，主要是基于两点考虑：其一，由于该分区上没有其它文件，这样分区不会产生磁盘碎片，这样能保证页面文件的数据读写不受磁盘碎片的干扰；其二，按照Windows对内存的管理技术，Windows会优先使用不经常访问的分区上的页面文件，这样也减少了读取系统盘里的页面文件的机会，减轻了系统盘的压力。(3)其它硬盘分区不设置任何页面文件。当然，如果你有多个硬盘，则可以为每个硬盘都创建一个页面文件。当信息分布在多个页面文件上时，硬盘控制器可以同时在多个硬盘上执行读取和写入操作。这样系统性能将得到提高。提示：允许设置的虚拟内存最小值为2MB，最大值不能超过当前硬盘的剩余空间值，同时也不能超过32位操作系统的内存寻址范围——4GB。相关播报编辑虚拟存储器virtualmemory为了给用户提供更大的随机存取空间而采用的一种存储技术。它将内存与外存结合使用，好像有一个容量极大的内存储器，工作速度接近于主存，每位成本又与辅存相近，在整机形成多层次存储系统。虚拟存储器源出于英国ATLAS计算机的一级存储器概念。这种系统的主存为16千字的磁芯存储器，但中央处理器可用20位逻辑地址对主存寻址。到1970年，美国RCA公司研究成功虚拟存储器系统。IBM公司于1972年在IBM370系统上全面采用了虚拟存储技术。虚拟存储器已成为计算机系统中非常重要的部分。虚拟存储器是由硬件和操作系统自动实现存储信息调度和管理的。它的工作过程包括6个步骤：①中央处理器访问主存的逻辑地址分解成组号a和组内地址b，并对组号a进行地址变换，即将逻辑组号a作为索引，查地址变换表，以确定该组信息是否存放在主存内。②如该组号已在主存内，则转而执行④；如果该组号不在主存内，则检查主存中是否有空闲区，如果没有，便将某个暂时不用的组调出送往辅存，以便将这组信息调入主存。③从辅存读出所要的组，并送到主存空闲区，然后将那个空闲的物理组号a和逻辑组号a登录在地址变换表中。④从地址变换表读出与逻辑组号a对应的物理组号a。⑤从物理组号a和组内字节地址b得到物理地址。⑥根据物理地址从主存中存取必要的信息。调度方式有分页式、分段式、段页式3种。页式调度是将逻辑和物理地址空间都分成固定大小的页。主存按页顺序编号，而每个独立编址的程序空间有自己的页号顺序，通过调度辅存中程序的各页可以离散装入主存中不同的页面位置，并可据表一一对应检索。页式调度的优点是页内零头小，页表对程序员来说是透明的，地址变换快，调入操作简单；缺点是各页不是程序的独立模块，不便于实现程序和数据的保护。段式调度是按程序的逻辑结构划分地址空间，段的长度是随意的，并且允许伸长，它的优点是消除了内存零头，易于实现存储保护，便于程序动态装配；缺点是调入操作复杂。将这两种方法结合起来便构成段页式调度。在段页式调度中把物理空间分成页，程序按模块分段，每个段再分成与物理空间页同样小的页面。段页式调度综合了段式和页式的优点。其缺点是增加了硬件成本，软件也较复杂。大型通用计算机系统多数采用段页式调度。替换方法播报编辑随机算法用软件或硬件随机数产生器确定替换的页面。先进先出先调入主存的页面先替换。最近最少使用算法替换最长时间不用的页面。虚拟存储器模型虚实地址播报编辑存储模型1、实地址与虚地址用户编制程序时使用的地址称为虚地址或逻辑地址，其对应的存储空间称为虚存空间或逻辑地址空间；而计算机物理内存的访问地址则称为实地址或物理地址，其对应的存储空间称为物理存储空间或主存空间。程序进行虚地址到实地址转换的过程称为程序的再定位。示意图2、虚存的访问过程虚存空间的用户程序按照虚地址编程并存放在辅存中。程序运行时，由地址变换机构依据当时分配给该程序的实地址空间把程序的一部分调入实存。每次访存时，首先判断该虚地址所对应的部分是否在实存中：如果是，则进行地址转换并用实地址访问主存；否则，按照某种算法将辅存中的部分程序调度进内存，再按同样的方法访问主存。由此可见，每个程序的虚地址空间可以远大于实地址空间，也可以远小于实地址空虚拟存储器模型间。前一种情况以提高存储容量为目的，后一种情况则以地址变换为目的。后者通常出现在多用户或多任务系统中：实存空间较大，而单个任务并不需要很大的地址空间，较小的虚存空间则可以缩短指令中地址字段的长度。异构体系播报编辑从虚存的概念可以看出，主存-辅存的访问机制与cache-主存的访问机制是类似的。这是由cache存储器、主存和辅存构成的三级存储体系中的两个层次。cache和主存之间以及主存和辅存之间分别有辅助硬件和辅助软硬件负责地址变换与管理，以便各级存储器能够组成有机的三级存储体系。cache和主存构成了系统的内存，而主存和辅存依靠辅助软硬件的支持构成了虚拟存储器。地址在三级存储体系中，cache-主存和主存-辅存这两个存储层次有许多相同点：(1)出发点相同：二者都是为了提高存储系统的性能价格比而构造的分层存储体系，都力图使存储系统的性能接近高速存储器，而价格和容量接近低速存储器。(2)原理相同：都是利用了程序运行时的局部性原理把常用的信息块从相对慢速而大容量的存储器调入相对高速而小容量的存储器。存储体系但cache-主存和主存-辅存这两个存储层次也有许多不同之处：存储体系(1)侧重点不同：cache主要解决主存与CPU的速度差异问题；而就性能价格比的提高而言，虚存主要是解决存储容量问题，另外还包括存储管理、主存分配和存储保护等方面。(2)数据通路不同：CPU与cache和主存之间均有直接访问通路，cache不命中时可直接访问主存；而虚存所依赖的辅存与CPU之间不存在直接的数据通路，当主存不命中时只能通过调页解决，CPU最终还是要访问主存。(3)透明性不同：cache的管理完全由硬件完成，对系统程序员和应用程序员均透明；而虚存管理由软件（操作系统）和硬件共同完成，由于软件的介入，虚存对实现存储管理的系统程序员不透明，而只对应用程序员透明（段式和段页式管理对应用程序员“半透明”）。存储体系(4)未命中时的损失不同：由于主存的存取时间是cache的存取时间的5～10倍，而主存的存取速度通常比辅存的存取速度快上千倍，故主存未命中时系统的性能损失要远大于cache未命中时的损失。虚存机制要解决的关键问题(1)调度问题：决定哪些程序和数据应被调入主存。(2)地址映射问题：在访问主存时把虚地址变为主存物理地址（这一过程称为内地址变换）；在访问辅存时把虚地址变成辅存的物理地址（这一过程称为外地址变换），以便换页。此外还要解决主存分配、存储保护与程序再定位等问题。(3)替换问题：决定哪些程序和数据应被调出主存。(4)更新问题：确保主存与辅存的一致性。在操作系统的控制下，硬件和系统软件为用户解决了上述问题，从而使应用程序的编程大大简化。页式调度播报编辑1、页式虚存地址映射页式虚拟存储系统页式虚拟存储系统中，虚地址空间被分成等长大小的页，称为逻辑页；主存空间也被分成同样大小的页，称为物理页。相应地，虚地址分为两个字段：高字段为逻辑页号，低字段为页内地址（偏移量）；实存地址也分两个字段：高字段为物理页号，低字段为页内地址。通过页表可以把虚地址（逻辑地址）转换成物理地址。在大多数系统中，每个进程对应一个页表。页表中对应每一个虚存页面有一个表项，表项的内容包含该虚存页面所在的主存页面的地址（物理页号），以及指示该逻辑页是否已调入主存的有效位。地址变换时，用逻辑页号作为页表内的偏移地址索引页表（将虚页号看作页表数组下标）并找到相应物理页号，用物理页号作为实存地址的高字段，再与虚地址的页内偏移量拼接，就构成完整的物理地址。现代的中央处理机通常有专门的硬件支持地址变换。2、转换后援缓冲器由于页表通常在主存中，因而即使逻辑页已经在主存中，也至少要访问两次物理存储器才能实现一次访存，这将使虚拟存储器的存取时间加倍。为了避免对主存访问次数的增多，可以对页表本身实行二级缓存，把页表中的最活跃的部分存放在高速存储器中，组成快表。这个专用于页表缓存的高速存储部件通常称为转换后援缓冲器(TLB)。保存在主存中的完整页表则称为慢表。3、内页表和外页表页表是虚地址到主存物理地址的变换表，通常称为内页表。与内页表对应的还有外页表，用于虚地址与辅存地址之间的变换。当主存缺页时，调页操作首先要定位辅存，而外页表的结构与辅存的寻址机制密切相关。例如对磁盘而言，辅存地址包括磁盘机号、磁头号、磁道号和扇区号等。段式调度播报编辑段式虚拟存储系统页式虚拟存储系统段是按照程序的自然分界划分的长度可以动态改变的区域。通常，程序员把子程序、操作数和常数等不同类型的数据划分到不同的段中，并且每个程序可以有多个相同类型的段。在段式虚拟存储系统中，虚地址由段号和段内地址（偏移量）组成。虚地址到实主存地址的变换通过段表实现。每个程序设置一个段表，段表的每一个表项对应一个段。每个表项至少包含下面三个字段：(1)有效位：指明该段是否已经调入实存。(2)段起址：指明在该段已经调入实存的情况下，该段在实存中的首地址。(3)段长：记录该段的实际长度。设置段长字段的目的是为了保证访问某段的地址空间时，段内地址不会超出该段长度导致地址越界而破坏其他段。段表本身也是一个段，可以存在辅存中，但一般驻留在主存中。段式虚拟存储器有许多优点：①段的逻辑独立性使其易于编译、管理、修改和保护，也便于多道程序共享。②段长可以根据需要动态改变，允许自由调度，以便有效利用主存空间。段式虚拟存储器也有一些缺点：①因为段的长度不固定，主存空间分配比较麻烦。②容易在段间留下许多外碎片，造成存储空间利用率降低。③由于段长不一定是2的整数次幂，因而不能简单地像分页方式那样用虚地址和实地址的最低若干二进制位作为段内偏移量，并与段号进行直接拼接，必须用加法操作通过段起址与段内偏移量的求和运算求得物理地址。因此，段式存储管理比页式存储管理方式需要更多的硬件支持。段页式调度播报编辑段页式虚拟存储器[1]段页式虚拟存储器是段式虚拟存储器和页式虚拟存储器的结合。实存被等分成页。每个程序则先按逻辑结构分段，每段再按照实存的页大小分页，程序按页进行调入和调出操作，但可按段进行编程、保护和共享。它把程序按逻辑单位分段以后，再把每段分成固定大小的页。程序对主存的调入调出是按页面进行的，但它又可以按段实现共享和保护，兼备页式和段式的优点。缺点是在映象过程中需要多次查表。在段页式虚拟存储系统中，每道程序是通过一个段表和一组页表来进行定位的。段表中的每个表目对应一个段，每个表目有一个指向该段的页表起始地址及该段的控制保护信息。由页表指明该段各页在主存中的位置以及是否已装入、已修改等状态信息。如果有多个用户在机器上运行，多道程序的每一道需要一个基号,由它指明该道程序的段表起始地址。虚拟地址格式如下：基号段号页号页内地址变换算法播报编辑段式管理图虚拟存储器地址变换基本上有3种形虚拟存储器工作过程式：全相联变换、直接变换和组相联变换。任何逻辑空间页面能够变换到物理空间任何页面位置的方式称为全相联变换。每个逻辑空间页面只能变换到物理空间一个特定页面的方式称为直接变换。组联想变换是指各组之间是直接变换，而组内各页间则是全相联变换。替换规则用来确定替换主存中哪一部分，以便腾空部分主存，存放来自辅存要调入的那部分内容。常见的替换算法有4种。①随机算法：用软件或硬件随机数产生器确定替换的页面。②先进先出：先调入主存的页面先替换。③最少使用算法：替换最长时间不用的页面。④最优算法：替换最长时间以后才使用的页面。这是理想化的算法，只能作为衡量其他各种算法优劣的标准。虚拟存储器的效率是系统性能评价的重要内容，它与主存容量、页面大小、命中率，程序局部性和替换算法等因素有关。流水线技术：简介播报编辑借鉴了工业流水线制造的思想，现代CPU也采用了流水线设计。在工业制造中采用流水线可以提高单位时间的生产量；同样在CPU中采用流水线设计也有助于提高CPU的频率。流水线技术先以汽车装配为例来解释流水线的工作方式。假设装配一辆汽车需要4个步骤：1.冲压：制作车身外壳和底盘等部件；2.焊接：将冲压成形后的各部件焊接成车身；3.涂装：将车身等主要部件清洗、化学处理、打磨、喷漆和烘干；4.总装：将各部件（包括发动机和向外采购的零部件）组装成车；同时对应地需要冲压、焊接、涂装和总装四个工人。采用流水线的制造方式，同一时刻四辆汽车在装配。如果不采用流水线，那么第一辆汽车依次经过上述四个步骤装配完成之后，下一辆汽车才开始进行装配，最早期的工业制造就是采用的这种原始的方式。未采用流水线的原始制造方式，同一时刻只有一辆汽车在装配。流水线技术不久之后就发现，某个时段中一辆汽车在进行装配时，其它三个工人处于闲置状态，显然这是对资源的极大浪费。于是开始思考能有效利用资源的方法：在第一辆汽车经过冲压进入焊接工序的时候，立刻开始进行第二辆汽车的冲压，而不是等到第一辆汽车经过全部四个工序后才开始。之后的每一辆汽车都是在前一辆冲压完毕后立刻进入冲压工序，这样在后续生产中就能够保证四个工人一直处于运行状态，不会造成人员的闲置。这样的生产方式就好似流水川流不息，因此被称为流水线。CPU的工作也可以大致分为指令的获取、解码、运算和结果的写入四个步骤，采用流水线设计之后，指令（好比待装配的汽车）就可以连续不断地进行处理。在同一个较长的时间段内，显然拥有流水线设计的CPU能够处理更多的指令。分类播报编辑流水线技术流水线功能繁杂，种类也非常多；如果按照处理级别来分类，流水线可以有操作部件级、指令级和处理机级；如果按照流水线可以完成的动作的数量来分类，又可以分为单功能和多功能流水线；如果按照流水线内部的功能部件的连接方式来分类，则有线性流水线和非线性流水线；按照可处理对象来分类，还可以有标量流水线和向量流水线。按处理级别功能部件级：在实现较为复杂的运算时采用指令级：将一条指令执行过程分为多个阶段处理器间级：每个处理器完成其专门的任务。按完成的功能单功能流水线：只完成一种如乘法或浮点运算等，多用于数字信号处理器（DSP），各处理器可并行完成各自的功能，加快整机处理速度。流水线技术多功能流水线：在不同情况下可完成不同功能按连接的方式分类静态流水线：同一时间内，多功能结构只能按一种功能的连接方式工作。动态流水线：同一时间内，可以有多种功能的连接方式同时工作。按处理的数据类型标量流水线：一般数据向量流水线：矢量数据。X+Y=Z每一个代表一维数据。按流水线结构线性流水线：指各功能模块顺序串行连接，无反馈回路，如前面介绍的。非线性流水线：带有反馈回路的流水线。性能指标播报编辑衡量一种流水线处理方式的性能高低的书面数据主要由吞吐率、效率和加速比这三个参数来决定。吞吐率流水线技术指的是计算机中的流水线在特定的时间内可以处理的任务或输出数据的结果的数量。流水线的吞吐率可以进一步分为最大吞吐率和实际吞吐率。它们主要和流水段的处理时间、缓存寄存器的延迟时间有关，流水段的处理时间越长，缓存寄存器的延迟时间越大，那么，这条流水线的吞吐量就越小。因为，在线性流水线中，最大吞吐率Tpmax=流水线时钟周期△T=1/max（T1,...Ti,..Tm）+T1/1，而其中，m是流水线的段数，i是特定过程段执行时间。如果，一条流水线的段数越多，过程执行时间越长，那么，这条流水线的理论吞吐率就越小。由此，要对于流水线的瓶颈部分的处理主要在于减少流水段的处理时间。实现的方法一般有两种：1、把瓶颈部分的流水线分拆，以便任务可以充分流水处理。流水段的处理时间过长，一般是由于任务堵塞造成的，而任务的堵塞会导致流水线不能在同一个时钟周期内启动另一个操作，可以把流水段划分，在各小流水段中间设置缓存寄存器，缓冲上一个流水段的任务，使流水线充分流水。假如X流水段的处理时间为3T，可以把X流水段再细分成3小段，这样，每小段的功能相同，但是处理时间已经变成3T/3=T了。流水线技术2、在瓶颈部分设置多条相同流水段，并行处理。对付流水段的处理时间过长，还有另外一种方法，那就是把瓶颈流水段用多个相同的并联流水段代替，在前面设一个分派单元来对各条流水段的任务进行分派。仍然假设瓶颈流水段的处理时间是△3T，那么经过3条并联流水段的同时处理，实际需要的时间只是△T。这样，就达到了缩短流水段处理时间，但这种方法比较少以采用，因为要3段相同的流水段并联，成本较高，而且，分派单元会比较麻烦处理。加速比是指某一流水线如果采用串行模式之后所用的时间T0和采用流水线模式后所用时间T的比值，数值越大，说明这条流水线的工作安排方式越好。效率使用效率：指流水线中，各个部件的利用率。由于流水线在开始工作时存在建立时间；在结束时存在排空时间，各个部件不可能一直在工作，总有某个部件在某一个时间处于闲置状态。用处于工作状态的部件和总部件的比值来说明这条流水线的工作效率。影响因素播报编辑流水线技术流水线处理方式是一种时间重叠并行处理的处理技术，具体地说，就是流水线可以在同一个时间启动2个或以上的操作，借此来提高性能。为了实现这一点，流水线必须要时时保存畅通，让任务充分流水，但在实际中，会出现2种情况使流水线停顿下来或不能启动：1、多个任务在同一时间周期内争用同一个流水段。例如，假如在指令流水线中，如果数据和指令是放在同一个储存器中，并且访问接口也只有一个，那么，两条指令就会争用储存器；在一些算数流水线中，有些运算会同时访问一个运算部件。2、数据依赖。比如，A运算必须得到B运算的结果，但是，B运算还没有开始，A运算动作就必须等待，直到B运算完成，两次运算不能同时执行。解决方案：第一种情况，增加运算部件的数量来使他们不必争用同一个部件；第二种情况，用指令调度的方法重新安排指令或运算的顺序。技术规范播报编辑超级流水线超级流水线（SuperPipeline)又叫做深度流水线，它是提高cpu速度通常采取的一种技术。CPU处理指令是通过Clock来驱动的，每个clock完成一级流水线操作。每个周期所做的操作越少，需要的时间就越短，时间越短，频率就可以提得越高。超级流水线就是将cpu处理指令是得操作进一步细分，增加流水线级数来提高频率。频率高了，当流水线开足马力运行时平均每个周期完成一条指令（单发射情况下），这样cpu处理得速度就提高了。当然，这是理想情况下，一般是流水线级数越多，重叠执行的执行就越多，那么发生竞争冲突得可能性就越大，对流水线性能有一定影响现在很多cpu都是将超标量和超级流水线技术一起使用，例如pentiumIV，流水线达到20级，频率最快已经超过3GHZ。教科书上用于教学的经典MIPS只有5级流水。超标量流水线技术将一条指令分成若干个周期处理以达到多条指令重叠处理,从而提高cpu部件利用率的技术叫做标量流水技术。超级标量是指cpu内一般能有多条流水线,这些流水线能够并行处理。在单流水线结构中，指令虽然能够重叠执行，但仍然是顺序的,每个周期只能发射(issue)或退休(retire)一条指令。超级标量结构的cpu支持指令级并行，每个周期可以发射多条指令(2-4条居多)。可以使得cpu的IPC(InstructionPerClock)>，从而提高cpu处理速度。超级标量机能同时对若干条指令进行译码，将可以并行执行的指令送往不同的执行部件，在程序运行期间，由硬件(通常是状态记录部件和调度部件)来完成指令调度。超级标量机主要是借助硬件资源重复(例如有两套译码器和ALU等)来实现空间的并行操作。熟知的pentium系列(可能是p-II开始),还有SUNSPARC系列的较高级型号,以及MIPS若干型号等都采用了超级标量技术。[1]超长指令字超长指令字（VLIW：VeryLongInstructionWord）是由美国Yale大学教授Fisher提出的。它有点类似于超级标量，是一条指令来实现多个操作的并行执行，之所以放到一条指令是为了减少内存访问。通常一条指令多达上百位，有若干操作数，每条指令可以做不同的几种运算。那些指令可以并行执行是由编译器来选择的。通常VLIW机只有一个控制器，每个周期启动一条长指令，长指令被分为几个字段，每个字段控制相应的部件。由于编译器需要考虑数据相关性，避免冲突，并且尽可能利用并行，完成指令调度，所以硬件结构较简单。VLIW机器较少，可能不太容易实现，业界比较有名的VLIW公司之一是Transmeta，在加州硅谷SantaClara（硅谷圣地之一，还有SanJose，PaloAlto）。它做的机器采用X86指令集，VLIW实现，具体资料可以去访问公司的网站。[2]向量机平时接触的计算机都是标量机，向量机都是大型计算机，一般用于军事工业，气象预报，以及其他大型科学计算领域，这也说明了向量机都很贵。国产的银河计算机就是向量机普通的计算机所做的计算，例如加减乘除，只能对一组数据进行操作，被称为标量运算。向量运算一般是若干同类型标量运算的循环。向量运算通常是对多组数据成批进行同样运算，所得结果也是一组数据。很多做科学计算的大（巨）型机都是向量机。SIMD技术单指令多数据（SingleInstructionMultipleData）简称SIMD。SIMD结构的CPU有多个执行部件，但都在同一个指令部件的控制下。SIMD在性能优势呢：以加法指令为例，单指令单数据（SISD）的CPU对加法指令译码后，执行部件先访问内存，取得第一个操作数；之后再一次访问内存，取得第二个操作数；随后才能进行求和运算。而在SIMD型CPU中，指令译码后几个执行部件同时访问内存，一次性获得所有操作数进行运算。这个特点使得SIMD特别适合于多媒体应用等数据密集型运算。AMD公司的3DNOW！技术其实质就是SIMD，这使K6－2处理器在音频解码、视频回放、3D游戏等应用中显示出优异性能。总线频率：1.含义北桥芯片负责联系内存、显卡等数据吞吐量最大的部件，并和南桥芯片连接。CPU就是通过前端总线连接到北桥芯片，进而通过北桥芯片和内存、显卡交换数据。前端总线是CPU和外界交换数据的最主要通道，因此前端总线的数据传输能力对计算机整体性能作用很大，如果没有足够快的前端总线，再强的CPU也不能明显提高计算机整体速度。数据传输最大带宽取决于所有同时传输的数据的宽度和传输频率，即数据带宽=总线频率×（数据位宽÷8）。PC机上所能达到的前端总线频率有266MHz、333MHz、400MHz、533MHz、800MHz、1066MHz、1333MHz、1600MHz、2000MHz几种，前端总线频率越大，代表着CPU与北桥芯片之间的数据传输能力越大，更能充分发挥出CPU的功能。CPU技术发展很快，运算速度提高很快，而足够大的前端总线可以保障有足够的数据供给给CPU，较低的前端总线将无法供给足够的数据给CPU，这样就限制了CPU性能得发挥，成为系统瓶颈。主板支持的前端总线是由芯片组决定的，一般都带有足够的向下兼容性，如865PE主板支持800MHz前端总线，那安装的CPU的前端总线可以是800MHz，也可以是533MHz，但这样就无法发挥出主板的全部功效。2.相对差异前端总线的速度指的是CPU和北桥芯片间总线的速度，更实质性的表示了CPU和外界数据传输的速度。而外频的概念是建立在数字脉冲信号震荡速度基础之上的，也就是说，100MHz外频特指数字脉冲信号在每秒钟震荡一万万次，它更多的影响了PCI及其他总线的频率。之所以前端总线与外频这两个概念容易混淆，主要的原因是在以前的很长一段时间里（主要是在Pentium4出现之前和刚出现Pentium4时），前端总线频率与外频是相同的，因此往往直接称前端总线为外频，最终造成这样的误会。随着计算机技术的发展，人们发现前端总线频率需要高于外频，因此采用了QDR（QuadDateRate）技术，或者其他类似的技术实现这个目的。这些技术的原理类似于AGP的2X或者4X，它们使得前端总线的频率成为外频的2倍、4倍甚至更高，从此之后前端总线和外频的区别才开始被人们重视起来。此外，在前端总线中比较特殊的是AMD64的HyperTransport。3.支持频率3.1Intel平台系列Intel芯片组：845、845D、845GL所支持的前端总线频率是400MHz，845E、845G、845GE、845PE、845GV以及865P、910GL所支持的前端总线频率是533MHz，而865PE、865G、865GV、848P、875P、915P、915G、915GV、915PL、915GL、925X、945PL、945GZ所支持的前端总线频率是800MHz。定位于欢跃(VIIV)平台的945GT所支持的前端总线频率是533MHz和667MHz，高端的925XE、945P、945G、955X、975X所支持的前端总线频率是1066MHz。946PL和946GZ所支持的前端总线频率是800MHz，而P965、G965、Q965和Q963所支持的前端总线频率则都是1066MHz。VIA芯片组：P4X266、P4X266A、P4M266所支持的前端总线频率是400MHz，P4X266E、P4X333、P4X400、P4X533所支持的前端总线频率是533MHz，PT800、PT880、PM800、PM880、P4M800、P4M800Pro、PT880Pro所支持的前端总线频率是800MHz，PT880Ultra、PT894、PT894Pro、PT890所支持的前端总线频率也高达1066MHz。P4M890所支持的前端总线频率是800MHz，而P4M900所支持的前端总线频率则是1066MHz。SIS芯片组：SIS645、SIS645DX、SIS650所支持的前端总线频率是400MHz，SIS651、SIS655、SIS648、SIS661GX所支持的前端总线频率是533MHz，SIS648FX、SIS661FX、SIS655FX、SIS655TX、SIS649、SIS656、SIS662所支持的前端总线频率是800MHz，SIS649FX和SIS656FX所支持的前端总线频率则高达1066MHz。ATI芯片组：Radeon9100IGP、Radeon9100ProIGP、RX330、RadeonXpress200IE(RC410)、RadeonXpress200IE(RXC410)所支持的前端总线频率是800MHz，RadeonXpress200IE(RS400)、RadeonXpress200CrossFireIE(RD400)、CrossFireXpress1600IE所支持的前端总线频率则高达1066MHz。ULI芯片组：M1683和M1685所支持的前端总线频率是800MHz。NVIDIA芯片组：nForce4SLIIE、nForce4SLIX16IE、nForce4SLIXE、nForce4UltraIE所支持的前端总线频率全部都高达1066MHz。nForce590SLIIE、nForce570SLIIE和nForce570UltraIE所支持的前端总线频率全部都是1066MHz。3.2AMD平台系列VIA芯片组：KT266、KT266A、KM266所支持的前端总线频率是266MHz，KT333、KT400、KT400A、KM400、KN400所支持的前端总线频率是333MHz，KT600和KT880所支持的前端总线频率是400MHz。SIS芯片组：SIS735、SIS745、SIS746、SIS740所支持的前端总线频率是266MHz，SIS741GX和SIS746FX所支持的前端总线频率是333MHz，SIS741和SIS748所支持的前端总线频率是400MHz。Uli芯片组：M1647所支持的前端总线频率是266MHz。nVidia芯片组：nForce2IGP、nForce2400和nForce2Ultra400所支持的前端总线频率是400MHz。此外，由于AMD64系列CPU内部整合了内存控制器，其HyperTransport频率只与CPU接口类型有关，而与主板芯片组无关，所以其HyperTransport频率的区分是相当简单的。总线带宽：概念简介播报编辑从电子电路角度出发，带宽（Bandwidth）本意指的是电子电路中存在一个固有通频带，各类复杂的电子电路无一例外都存在电感、电容或相当功能的储能元件，即使没有采用现成的电感线圈或电容，导线自身就是一个电感，而导线与导线之间、导线与地之间便可以组成电容——这就是通常所说的杂散电容或分布电容；不管是哪种类型的电容、电感，都会对信号起着阻滞作用从而消耗信号能量，严重的话会影响信号品质。这种效应与交流电信号的频率成正比关系，当频率高到一定程度、令信号难以保持稳定时，整个电子电路自然就无法正常工作。为此，电子学上就提出了带宽的概念，它指的是电路可以保持稳定工作的频率范围。而属于该体系的有显示器带宽、通讯/网络中的带宽等等。而第二种带宽的概念指的其实是数据传输率，譬如内存带宽、总线带宽、网络带宽等等，都是以字节/秒为单位。对于电子电路中的带宽，决定因素在于电路设计。它主要是由高频放大部分元件的特性决定，而高频电路的设计是比较困难的部分，成本也比普通电路要高很多。这部分内容涉及到电路设计的知识，对此我们就不做深入的分析。而对于总线、内存中的带宽，决定其数值的主要因素在于工作频率和位宽，在这两个领域，带宽等于工作频率与位宽的乘积，因此带宽和工作频率、位宽两个指标成正比。不过工作频率或位宽并不能无限制提高，它们受到很多因素的制约[1]。总线带宽简介播报编辑在计算机系统中，总线的作用就好比是人体中的神经系统，它承担的是所有数据传输的职责，而各个子系统间都必须藉由总线才能通讯，例如，CPU和北桥间有前端总线、北桥与显卡间为AGP总线、芯片组间有南北桥总线，各类扩展设备通过PCI、PCI-X总线与系统连接；主机与外部设备的连接也是通过总线进行，如流行的USB2.0、IEEE1394总线等等，一句话，在一部计算机系统内，所有数据交换的需求都必须通过总线来实现！按照工作模式不同，总线可分为两种类型，一种是并行总线，它在同一时刻可以传输多位数据，好比是一条允许多辆车并排开的宽敞道路，而且它还有双向单向之分；另一种为串行总线，它在同一时刻只能传输一个数据，好比只容许一辆车行走的狭窄道路，数据必须一个接一个传输、看起来仿佛一个长长的数据串，故称为“串行”。并行总线和串行总线的描述参数存在一定差别。对并行总线来说，描述的性能参数有以下三个：总线宽度、时钟频率、数据传输频率。其中，总线宽度就是该总线可同时传输数据的位数，好比是车道容许并排行走的车辆的数量；例如，16位总线在同一时刻传输的数据为16位，也就是2个字节；而32位总线可同时传输4个字节，64位总线可以同时传输8个字节......显然，总线的宽度越大，它在同一时刻就能够传输更多的数据。不过总线的位宽无法无限制增加。总线的带宽指的是这条总线在单位时间内可以传输的数据总量，它等于总线位宽与工作频率的乘积。例如，对于64位、800MHz的前端总线，它的数据传输率就等于64bit×800MHz÷8(Byte)=6.4GB/s；32位、33MHzPCI总线的数据传输率就是32bit×33MHz÷8=132MB/s，等等，这项法则可以用于所有并行总线上面——看到这里，读者应该明白我们所说的总线带宽指的就是它的数据传输率。对串行总线来说，带宽和工作频率的概念与并行总线完全相同，只是它改变了传统意义上的总线位宽的概念。在频率相同的情况下，并行总线比串行总线快得多，那么，为什么各类并行总线反而要被串行总线接替呢？原因在于并行总线虽然一次可以传输多位数据，但它存在并行传输信号间的干扰现象，频率越高、位宽越大，干扰就越严重，因此要大幅提高现有并行总线的带宽是非常困难的；而串行总线不存在这个问题，总线频率可以大幅向上提升，这样串行总线就可以凭借高频率的优势获得高带宽。而为了弥补一次只能传送一位数据的不足，串行总线常常采用多条管线（或通道）的做法实现更高的速度——管线之间各自独立，多条管线组成一条总线系统，从表面看来它和并行总线很类似，但在内部它是以串行原理运作的。对这类总线，带宽的计算公式就等于“总线频率×管线数”，这方面的例子有PCIExpress和HyperTransport，前者有×1、×2、×4、×8、×16和×32多个版本，在第一代PCIExpress技术当中，单通道的单向信号频率可达2.5GHz，我们以×16举例，这里的16就代表16对双向总线，一共64条线路，每4条线路组成一个通道，二条接收，二条发送。这样可以换算出其总线的带宽为2.5GHz×16/10=4GB/s（单向）。除10是因为每字节采用10位编码。内存带宽播报编辑除总线之外，内存也存在类似的带宽概念。其实所谓的内存带宽，指的也就是内存总线所能提供的数据传输能力，但它决定于内存芯片和内存模组而非纯粹的总线设计，加上地位重要，往往作为单独的对象讨论。SDRAM、DDR和DDRⅡ的总线位宽为64位，RDRAM的位宽为16位。而这两者在结构上有很大区别：SDRAM、DDR和DDRⅡ的64位总线必须由多枚芯片共同实现，计算方法如下：内存模组位宽=内存芯片位宽×单面芯片数量（假定为单面单物理BANK）；如果内存芯片的位宽为8位，那么模组中必须、也只能有8颗芯片，多一枚、少一枚都是不允许的；如果芯片的位宽为4位，模组就必须有16颗芯片才行，显然，为实现更高的模组容量，采用高位宽的芯片是一个好办法。而对RDRAM来说就不是如此，它的内存总线为串联架构，总线位宽就等于内存芯片的位宽。和并行总线一样，内存的带宽等于位宽与数据传输频率的乘积，例如，DDR400内存的数据传输频率为400MHz，那么单条模组就拥有64bit×400MHz÷8(Byte)=3.2GB/s的带宽；PC800标准RDRAM的频率达到800MHz，单条模组带宽为16bit×800MHz÷8=1.6GB/s。为了实现更高的带宽，在内存控制器中使用双通道技术是一个理想的办法，所谓双通道就是让两组内存并行运作，内存的总位宽提高一倍，带宽也随之提高了一倍！带宽可以说是内存性能最主要的标志，业界也以内存带宽作为主要的分类标准，但它并非决定性能的要素，在实际应用中，内存延迟的影响并不亚于带宽。如果延迟时间太长的话相当不利，此时即便带宽再高也无济于事[2]。带宽匹配播报编辑计算机系统中存在形形色色的总线，这不可避免带来总线速度匹配问题，其中最常出问题的地方在于前端总线和内存、南北桥总线和PCI总线。前端总线与内存匹配与否对整套系统影响最大，最理想的情况是前端总线带宽与内存带宽相等，而且内存延迟要尽可能低。在Pentium4刚推出的时候，Intel采用RDRAM内存以达到同前端总线匹配，但RDRAM成本昂贵，严重影响推广工作，Intel曾推出搭配PC133SDRAM的845芯片组，但SDRAM仅能提供1.06GB/s的带宽，仅相当于400MHz前端总线带宽的1/3，严重不匹配导致系统性能大幅度下降；后来，Intel推出支持DDR266的845D才勉强好转，但仍未实现与前端总线匹配；接着，Intel将P4前端总线提升到533MHz、带宽增长至4.26GB/s，虽然配套芯片组可支持DDR333内存，可也仅能满足2/3而已；P4的前端总线提升到800MHz，而配套的865/875P芯片组可支持双通道DDR400——这个时候才实现匹配的理想状态，当然，这个时候继续提高内存带宽意义就不是特别大，因为它超出了前端总线的接收能力。南北桥总线带宽曾是一个尖锐的问题，早期的芯片组都是通过PCI总线来连接南北桥，而它所能提供的带宽仅仅只有133MB/s，若南桥连接两个ATA-100硬盘、100M网络、IEEE1394接口......区区133MB/s带宽势必形成严重的瓶颈，为此，各芯片组厂商都发展出不同的南北桥总线方案，如Intel的Hub-Link、VIA的V-Link、SiS的MuTIOL，还有AMD的HyperTransport等等，它们的带宽都大大超过了133MB/s，最高纪录已超过1GB/s，瓶颈效应已不复存在。PCI总线带宽不足还是比较大的矛盾，PC上使用的PCI总线均为32位、33MHz类型，带宽133MB/s，而这区区133MB/s必须满足网络、硬盘控制卡（如果有的话）之类的扩展需要，一旦使用千兆网络，瓶颈马上出现，业界打算自2004年开始以PCIExpress总线来全面取代PCI总线，届时PCI带宽不足的问题将成为历史。显示器播报编辑以上我们所说的“带宽”指的都是速度概念，但对CRT显示器来说，它所指的带宽则是频率概念、属于电路范畴，更符合“带宽”本来的含义。要了解显示器带宽的真正含义，必须简单介绍一下CRT显示器的工作原理——由灯丝、阴极、控制栅组成的电子枪，向外发射电子流，这些电子流被拥有高电压的加速器加速后获得很高的速度，接着这些高速电子流经过透镜聚焦成极细的电子束打在屏幕的荧光粉层上，而被电子束击中的地方就会产生一个光点；光点的位置由偏转线圈产生的磁场控制，而通过控制电子束的强弱和通断状态就可以在屏幕上形成不同颜色、不同灰度的光点——在某一个特定的时刻，整个屏幕上其实只有一个点可以被电子束击中并发光。为了实现满屏幕显示，这些电子束必须从左到右、从上到下一个一个象素点进行扫描，若要完成800×600分辨率的画面显示，电子枪必须完成800×600=480000个点的顺序扫描。由于荧光粉受到电子束击打后发光的时间很短，电子束在扫描完一个屏幕后必须立刻再从头开始——这个过程其实十分短暂，在一秒钟时间电子束往往都能完成超过85个完整画面的扫描、屏幕画面更新85次，人眼无法感知到如此小的时间差异会“误以为”屏幕处于始终发亮的状态。而每秒钟屏幕画面刷新的次数就叫场频，或称为屏幕的垂直扫描频率、以Hz（赫兹）为单位，也就是我们俗称的“刷新率”。以800×600分辨率、85Hz刷新率计算，电子枪在一秒钟至少要扫描800×600×85=40800000个点的显示；如果将分辨率提高到1024×768，将刷新率提高到100Hz，电子枪要扫描的点数将大幅提高。按照业界公认的计算方法，显示器带宽指的就是显示器的电子枪在一秒钟内可扫描的最高点数总和，它等于“水平分辨率×垂直分辨率×场频（画面刷新次数）”，单位为MHz(兆赫)；由于显像管电子束的扫描过程是非线性的，为避免信号在扫描边缘出现衰减影响效果、保证图像的清晰度，总是将边缘扫描部分忽略掉，但在电路中它们依然是存在的。因此，我们在计算显示器带宽的时候还应该除一个取值为0.6~0.8的“有效扫描系数”，故得出带宽计算公式如下：“带宽=水平像素（行数）×垂直像素（列数）×场频（刷新频率）÷扫描系数”。扫描系数一般取为0.744。例如，要获得分辨率1024×768、刷新率85Hz的画面，所需要的带宽应该等于：1024×768×85÷0.744，结果大约是90MHz。不过，这个定义并不符合带宽的原意，称之为“像素扫描频率”似乎更为贴切。带宽的最初概念确实也是电路中的问题——简单点说就是：在“带宽”这个频率宽度之内，放大器可以处于良好的工作状态，如果超出带宽范围，信号会很快出现衰减失真现象。从本质上说，显示器的带宽描述的也是控制电路的频率范围，带宽高低直接决定显示器所能达到的性能等级。由于前文描述的“像素扫描频率”与控制电路的“带宽”基本是成正比关系，显示器厂商就干脆把它当作显示器的“带宽”——这种做法当然没有什么错，只是容易让人产生认识上的误区。当然，从用户的角度考虑没必要追究这么多，毕竟以“像素扫描频率”作为“带宽”是很合乎人们习惯的，大家可方便使用公式计算出达到某种显示状态需要的最低带宽数值。但是反过来说，“带宽数值完全决定着屏幕的显示状态”是否也成立呢？答案是不完全成立，因为屏幕的显示状态除了与带宽有关系之外，还与一个重要的概念相关——它就是“行频”。行频又称为“水平扫描频率”，它指的是电子枪每秒在荧光屏上扫描过的水平线数量，计算公式为：“行频=垂直分辨率×场频（画面刷新率）×1.07”，其中1.07为校正参数，因为显示屏上下方都存在我们看不到的区域。可见，行频是一个综合分辨率和刷新率的参数，行频越大，显示器就可以提供越高的分辨率或者刷新率。例如，1台17寸显示器要在1600×1200分辨率下达到75Hz的刷新率，那么带宽值至少需要221MHz，行频则需要96KHz，两项条件缺一不可；要达到这么高的带宽相对容易，而要达到如此高的行频就相当困难，后者成为主要的制约因素，而出于商业因素考虑，显示器厂商会突出带宽而忽略行频，这种宣传其实是一种误导。通讯带宽播报编辑在通讯和网络领域，带宽的含义又与上述定义存在差异，它指的是网络信号可使用的最高频率与最低频率之差、或者说是“频带的宽度”，也就是所谓的“Bandwidth”、“信道带宽”——这也是最严谨的技术定义。在100M以太网之类的铜介质布线系统中，双绞线的信道带宽通常用MHz为单位，它指的是信噪比恒定的情况下允许的信道频率范围，不过，网络的信道带宽与它的数据传输能力（单位Byte/s）存在一个稳定的基本关系。我们也可以用高速公路来作比喻：在高速路上，它所能承受的最大交通流量就相当于网络的数据运输能力，而这条高速路允许形成的宽度就相当于网络的带宽。显然，带宽越高、数据传输可利用的资源就越多，因而能达到越高的速度；除此之外，我们还可以通过改善信号质量和消除瓶颈效应实现更高的传输速度。网络带宽与数据传输能力的正比关系最早是由贝尔实验室的工程师ClaudeShannon所发现，因此这一规律也被称为Shannon定律。而通俗起见普遍也将网络的数据传输能力与“网络带宽”完全等同起来，这样“网络带宽”表面上看与“总线带宽”形成概念上的统一，但这两者本质上就不是一个意思、相差甚远。总结播报编辑对总线和内存来说，带宽高低对系统性能有着举足轻重的影响——倘若总线、内存的带宽不够高的话，处理器的工作频率再高也无济于事，因此带宽可谓是与频率并立的两大性能决定要素。而对CRT显示器而言，带宽越高，往往可以获得更高的分辨率、显示精度越高，不过CRT显示器的带宽都能够满足标准分辨率下85Hz刷新率或以上的显示需要（相信没有太多的朋友喜欢用非常高的分辨率去运行程序或者游戏），这样带宽高低就不是一个太敏感的参数了，当然，如果你追求高显示品质那是另一回事了[3]。寄存器：基本含义播报编辑寄存器是CPU内部用来存放数据的一些小型存储区域，用来暂时存放参与运算的数据和运算结果。其实寄存器就是一种常用的时序逻辑电路，但这种时序逻辑电路只包含存储电路。寄存器的存储电路是由锁存器或触发器构成的，因为一个锁存器或触发器能存储1位二进制数，所以由N个锁存器或触发器可以构成N位寄存器。寄存器是中央处理器内的组成部分。寄存器是有限存储容量的高速存储部件，它们可用来暂存指令、数据和位址。[2]在计算机领域，寄存器是CPU内部的元件，包括通用寄存器、专用寄存器和控制寄存器。寄存器拥有非常高的读写速度，所以在寄存器之间的数据传送非常快。[2]Cortex-M4总共有18个寄存器，相比传统ARM（如ARM7/ARM9/Cortex-A系列）的38个寄存器已减少很多，减少了内核核心面积(Die-size)。[2]寄存器对于编译器非常友好易用，例如：包含灵活的寄存器配置，任意寄存器之间可实现单周期乘法，任意寄存器可以作为数据、结构或数组的指针。此外，Cortex-M4还包含4个特殊功能寄存器PRIMASK、FAUI。TMASK、BASEPRI和CONTROL。[2]基本概念播报编辑寄存器最起码具备以下4种功能。①清除数码：将寄存器里的原有数码清除。[3]②接收数码：在接收脉冲作用下，将外输入数码存入寄存器中。[3]③存储数码：在没有新的写入脉冲来之前，寄存器能保存原有数码不变。[3]④输出数码：在输出脉冲作用下，才通过电路输出数码。[3]仅具有以上功能的寄存器称为数码寄存器；有的寄存器还具有移位功能，称为移位寄存器。[3]PORT1的控制寄存器(2张)寄存器有串行和并行两种数码存取方式。将n位二进制数一次存入寄存器或从寄存器中读出的方式称为并行方式。将n位二进制数以每次1位，分成n次存入寄存器并从寄存器读出，这种方式称为串行方式。并行方式只需一个时钟脉冲就可以完成数据操作，工作速度快，但需要n根输入和输出数据线。串行方式要使用几个时钟脉冲完成输入或输出操作，工作速度慢，但只需要一根输入或输出数据线，传输线少，适用于远距离传输。[3]结构播报编辑在数字电路中，用来存放二进制数据或代码的电路称为寄存器。寄存器是由具有存储功能的触发器组合起来构成的。一个触发器可以存储1位二进制代码，存放门位二进制代码的寄存器需用逐个触发器来构成。[4]对寄存器中的触发器只要求它们具有置1，置0的功能即可，因而无论是用电平触发的锁存器（latch-up），还是用脉冲触发或边沿触发的触发器（flip-flop），都可以组成寄存器。[4]由电平触发的动作特点可知，在CLK高电平期间，Q端的状态跟随D端状态的改变而改变；CLK变成低电平以后，Q端将保持CLK变为低电平时刻D端的状态。[4]74HC175则是用CMOS边沿触发器组成的4位寄存器，根据边沿触发的动作特点可知，触发器输出端的状态仅仅取决于CLK上升沿到达时刻D端的状态。可见，虽然74LS75和74HC175都是4位寄存器，但由于采用了不同结构类型的触发器，所以动作特点是不同的。[4]为了增加使用的灵活性，在有些寄存器电路中还附加了一些控制电路，使寄存器又增添了异步置零、输出三态控制和保持等功能。这里所说的保持，是指CLK信号到达时触发器不随D端的输入信号而改变状态，保持原来的状态不变。[4]上面介绍的两个寄存器电路中，接收数据时所有各位代码都是同时输入的，而且触发器中的数据是并行地出现在输出端的，因此将这种输入、输出方式称为并行输入、并行输出方式。[4]基本寄存器逻辑图(2张)工作原理播报编辑在计算机及其他计算系统中，寄存器是一种非常重要的、必不可少的数字电路构件，它通常由触发器（D触发器）组成，主要作用是用来暂时存放数码或指令。一个触发器可以存放一位二进制代码，若要存放N位二进制数码，则需用N个触发器。[6]寄存器应具有接收数据、存放数据和输出数据的功能，它由触发器和门电路组成。只有得到“存入脉冲”（又称“存入指令”、“写入指令”）时，寄存器才能接收数据；在得到“读出”指令时，寄存器才将数据输出。[6]寄存器存放数码的方式有并行和串行两种。并行方式是数码从各对应位输入端同时输入到寄存器中；串行方式是数码从一个输入端逐位输入到寄存器中。[6]寄存器读出数码的方式也有并行和串行两种。在并行方式中，被读出的数码同时出现在各位的输出端上；在串行方式中，被读出的数码在一个输出端逐位出现。[6]寄存器(3张)类型播报编辑1.通用寄存器组通用寄存器组包括AX、BX、CX、DX4个16位寄存器，用以存放16位数据或地址。也可用作8位寄存器。用作8位寄存器时分别记为AH、AL、BH、BL、CH、CL、DH、DL。只能存放8位数据，不能存放地址。它们分别是AX、BX、CX、DX的高八位和低八位。若AX=1234H，则AH=12H，AL=34H。通用寄存器通用性强，对任何指令，它们具有相同的功能。为了缩短指令代码的长度，在8086中，某些通用寄存器用作专门用途。例如，串指令中必须用CX寄存器作为计数寄存器，存放串的长度，这样在串操作指令中不必给定CX的寄存器号，缩短了串操作指令代码的长度。下面一一介绍：AX(AH、AL)：累加器。有些指令约定以AX(或AL)为源或目的寄存器。输入/输出指令必须通过AX或AL实现，例如：端口地址为43H的内容读入CPU的指令为INAL，43H或INAX，43H。目的操作数只能是AL/AX，而不能是其他的寄存器。[5]BX(BH、BL)：基址寄存器。BX可用作间接寻址的地址寄存器和基地址寄存器，BH、BL可用作8位通用数据寄存器。[5]CX(CH、CL)：计数寄存器。CX在循环和串操作中充当计数器，指令执行后CX内容自动修改，因此称为计数寄存器。[5]DX(DH、DL)：数据寄存器。除用作通用寄存器外，在I/O指令中可用作端口地址寄存器，乘除指令中用作辅助累加器。[5]2.指针和变址寄存器BP(BasePointerRegister)：基址指针寄存器。[5]SP(StackPointerRegister)：堆栈指针寄存器。[5]SI(SourceIndexRegister)：源变址寄存器。[5]DI(DestinationIndexRegister)：目的变址寄存器。[5]这组寄存器存放的内容是某一段内地址偏移量，用来形成操作数地址，主要在堆栈操作和变址运算中使用。BP和SP寄存器称为指针寄存器，与SS联用，为访问现行堆栈段提供方便。通常BP寄存器在间接寻址中使用，操作数在堆栈段中，由SS段寄存器与BP组合形成操作数地址即BP中存放现行堆栈段中一个数据区的“基址”的偏移量，所以称BP寄存器为基址指针。[5]SP寄存器在堆栈操作中使用，PUSH和POP指令是从SP寄存器得到现行堆栈段的段内地址偏移量，所以称SP寄存器为堆栈指针，SP始终指向栈顶。[5]寄存器SI和DI称为变址寄存器，通常与DS一起使用，为访问现行数据段提供段内地址偏移量。在串指令中，其中源操作数的偏移量存放在SⅠ中，目的操作数的偏移量存放在DI中，SI和DI的作用不能互换，否则传送地址相反。在串指令中，SI、DI均为隐含寻址，此时，SI和DS联用，Dl和ES联用。[5]3.段寄存器8086/8088CPU可直接寻址1MB的存储器空间，直接寻址需要20位地址码，而所有内部寄存器都是16位的，只能直接寻址6KB，因此采用分段技术来解决。将1MB的存储空间分成若干逻辑段，每段最长64KB，这些逻辑段在整个存储空间中可浮动。[5]8086/8088CPU内部设置了4个16位段寄存器，它们分别是代码段寄存器CS、数据段寄存器DS、堆栈段寄存器SS、附加段寄存器ES、由它们给出相应逻辑段的首地址，称为“段基址”。段基址与段内偏移地址组合形成20位物理地址，段内偏移地址可以存放在寄存器中，也可以存放在存储器中。[5]例如：代码段寄存器CS存放当前代码段基地址，IP指令指针寄存器存放了下一条要执行指令的段内偏移地址，其中CS=2000H，IP=001AH。通过组合，形成20位存储单元的寻址地址为2001AH。[5]代码段内存放可执行的指令代码，数据段和附加段内存放操作的数据，通常操作数在现行数据段中，而在串指令中，目的操作数指明必须在现行附加段中。堆栈段开辟为程序执行中所要用的堆栈区，采用先进后出的方式访问它。各个段寄存器指明了一个规定的现行段，各段寄存器不可互换使用。程序较小时，代码段、数据段、堆栈段可放在一个段内，即包含在64KB之内，而当程序或数据量较大时，超过了64KB，那么可以定义多个代码段或数据段、堆栈段、附加段。现行段由段寄存器指明段地址，使用中可以修改段寄存器内容，指向其他段。有时为了明确起见，可在指令前加上段超越的前缀，以指定操作数所在段。[5]4.指令指针寄存器IP8086/8088CPU中设置了一个16位指令指针寄存器IP，用来存放将要执行的下一条指令在现行代码段中的偏移地址。程序运行中，它由BIU自动修改，使IP始终指向下一条将要执行的指令的地址，因此它是用来控制指令序列的执行流程的，是一个重要的寄存器。8086程序不能直接访问IP，但可以通过某些指令修改IP的内容。例如，当遇到中断指令或调用子程序指令时，8086自动调整IP的内容，将IP中下一条将要执行的指令地址偏移量入栈保护，待中断程序执行完毕或子程序返回时，可将保护的内容从堆栈中弹出到IP，使主程序继续运行。在跳转指令时，则将新的跳转目标地址送入IP，改变它的内容，实现了程序的转移。[5]5.标志寄存器FR标志寄存器FR也称程序状态字寄存器。[5]寄存器(2张)FR是16位寄存器，其中有9位有效位用来存放状态标志和控制标志。状态标志共6位，CF、PF、AF、ZF、SF和OF，用于寄存程序运行的状态信息，这些标志往往用作后续指令判断的依据。控制标志有3位，IF、DF和TF，用于控制CPU的操作，是人为设置的。[5]存放代码满足条件播报编辑(1)代码要存得进；(2)代码要记得住；(3)代码要取得出。[7]寄存器是由具有存储功能的触发器组合起来构成的。一个触发器可以存储1位2进制代码，存放n位2进制代码的寄存器，需用n个触发器来构成。对寄存器中的触发器只要求它具有置1、置0的功能即可，因而无论用何种类型的触发器都可组成寄存器。[7]按照功能的不同，寄存器可分为基本寄存器和移位寄存器两大类。基本寄存器只能并行送入数据，需要时也只能并行输出。移位寄存器中的数据可以在移位脉冲作用下依次逐位右移或左移，数据既可以并行输入、并行输出，也可以串行输入、串行输出，还可以并行输入、串行输出或串行输入、并行输出，十分灵活，用途也很广。[7]寄存器组织播报编辑ARM微处理器共有37个32位寄存器，其中31个为通用寄存器，6个为状态寄存器。但是这些寄存器不能被同时访问，具体哪些寄存器是可编程访问的，取决于微处理器的工作状态及具体的运行模式。但在任何时候，通用寄存器R14~R0、程序计数器PC、一个或两个状态寄存器都是可访问的。[8]ARM9处理器共有37个32位长的寄存器，这些寄存器包括：(1)RO～R12：均为32位通用寄存器，用于数据操作。但是注意：绝大多数16位Thumb指令只能访问R0～R7，而32位Thumb-2指令可以访问所有寄存器。[9](2)堆栈指针：堆栈指针的最低两位永远是O，这意味着堆栈总是4字节对齐的。[9](3)链接寄存器：当呼叫一个子程序时，由R14存储返回地址。[9](4)程序计数器：指向当前的程序地址，如果修改它的值，就能改变程序的执行流。[9](5)6个状态寄存器（1个CPSR、5个SPSR），用以标识CPU的工作状态及程序的运行状态，均为32位，目前只使用了其中的一部分。[9]Cortex-A8处理器有40个32位长的寄存器，多了监控模式下的寄存器，如RO～R12、R15、CPSR通用，R13_mon、R14_mon、SPSR_mon三个专用寄存器。[9]寄存器寻址播报编辑寄存器寻址就是利用寄存器中的数值作为操作数，这种寻址方式是各类微处理器经常采用的一种方式，也是一种执行效率较高的寻址方式。[10]寄存器寻址是指操作数存放在CPU内部的寄存器中，指令中给出操作数所在的寄存器名。寄存器操作数可以是8位寄存器AH、AL、BH、BL、CH、CL、DH、DL，也可以是16位寄存器AX、BX、CX、DX、SP、BP、SI、DI等。因为寄存器寻址不需要通过总线操作访问存储器，所以指令执行速度比较快。[11]寄存器寻址(RegisterAddressing)是以通用寄存器的内容作为操作数的寻址方式，在该寻址方式下，操作数存放在寄存器中。寄存器寻址方式的寻址对象为：A，B，DPTR，R0~R7。其中，B仅在乘除法指令中为寄存器寻址，在其他指令中为直接寻址。A可以按寄存器寻址又可以直接寻址，直接寻址时写成ACC。[12]地址寄存器：简介播报编辑地址寄存器（AddressRegister,AR）用来保存当前CPU所访问的内存单元的地址。由于在内存和CPU之间存在着操作速度上的差别，所以必须使用地址寄存器来保持地址信息，直到内存的读/写操作完成为止。[1]数据寄存器DR用来暂存微处理器与存储器或输人/输出接口电路之间待传送的数据。地址寄存器AR和数据寄存器DR在微处理器的内部总线和外部总线之间，还起着隔离和缓冲的作用。结构播报编辑地址寄存器采用单纯的寄存器结构。在对主存或I/O端口进行访问时，地址寄存器存放当前访问的地址，数据缓冲器实现数据的缓冲。CPU通过修改地址寄存器中的值，就可访问不同的存储器单元及不同的I/O端口。[2]地址寄存器可用LPM库中的元件lpm_latch锁存器来完成。图是地址寄存器的结构图。地址寄存器的数据宽度应当与程序计数器的数据宽度一致。data[7…0]是地址寄存器的数据输入端，q[7…0]是地址寄存器的数据输出端，gate是地址锁存器的控制端。gate的作用是当锁存控制脉冲到来时，高电平时数据进入锁存器，低电平时锁存数据，保持输出数据稳定不变。[3]特点播报编辑当CPU和内存进行信息交换，即CPU向内存存/取数据时，或者CPU从内存中读出指令时，都要使用地址寄存器和数据缓冲寄存器。同样，如果我们把外围设备的设备地址作为像内存的地址单元那样来看待，那么，当CPU和外围设备交换信息时，我们同样使用地址寄存器和数据缓冲寄存器。地址寄存器的结构和数据缓冲寄存器、指令寄存器一样，通常使用单纯的寄存器结构。信息的存入一般采用电位-脉冲方式，即电位输入端对应数据信息位，脉冲输入端对应控制信号，在控制信号作用下，瞬时地将信息打入寄存器。8086地址寄存器播报编辑8086有8个16比特的寄存器，包括栈寄存器SP与BP，但不包括指令寄存器IP、控制寄存器FLAGS以及四个段寄存器。AX,BX,CX,DX,这四个寄存器可以按照字节访问；但BP,SI,DI,SP,这四个地址寄存器只能按照16位宽访问。[2]8086以8080和8085（它与8080有汇编语言上的源代码兼容性）的设计为基础，拥有类似的暂存器集合，但是扩充为16位。总线接口单元（BusInterfaceUnit）通过6字节预存（prefetch）的贮列（queue）将指令送给运行单元（ExecutionUnit），所以取指令和运行是同步的－一种流水线的原始形式（8086指令长度变化从1到6字节）。[2]8086有四个完全一样的16位暂存器，但也能够当作八个8位暂存器来访问；以及四个16位变址寄存器（包含堆栈索引）。数据暂存器通常由指令隐含地使用，针对暂存值需要复杂的暂存器配置。它提供64K8位的输出输入（或32K16位）端口，以及固定的矢量中断。大部分的指令只能够访问一个存储器地址，所以其中一个运算符必须是一个暂存器。运算结果会存储在运算符中的一个。[2]64-bit地址寄存器可存储2个地址，存储器的基本单位是Byte，换言之最大支持16EiB存储器，1EiB则相等于1024GiB。但是，现在的64-bitCPU并没有64位地址总线。[2]输出设备：输出设备的作用播报编辑输出设备是对将外部世界信息发送给计算机的设备和将处理结果返回给外部世界的设备的总称。这些返回结果可能是作为使用者能够视觉上体验的，或是作为该计算机所控制的其他设备的输入：对于一台机器人，控制计算机的输出基本上就是这台机器人本身，如做出各种行为。输出设备的功能播报编辑输出设备的功能是将内存中计算机处理后的信息以能为人或其它设备所接收的形式输出。输出设备的种类播报编辑输出设备种类也很多．计算机常用的输出设备有各种打印机、凿孔输出设备、显示设备和绘图机等。打印机和显示设备已成为每台计算机和大多数终端所必需的设备。纸带凿孔输出机计算机用纸带凿孔输出设备。计算机输出信息用凿孔纸带上的小孔表示。这既可将信息长期保存于纸带上,又可利用凿孔纸带再输入计算机。卡片凿孔输出机计算机用卡片凿孔输出设备。凿孔卡片阅读方便，可长期保存，也可作为计算机的输入。输出设备的分类播报编辑显示器黑白显示器显示器（Display）又称监视器,是实现人机对话的主要工具。它既可以显示键盘输入的命令或数据,也可以显示计算机数据处理的结果。常用的显示器主要有两种类型。一种是CRT（Cath-odeRayTube,阴极射线管）显示器,用於一般的台式微机；另一种是液晶（LiquidCrystalDisplay,简称LCD）显示器,用於便携式微机．下面主要介绍CRT显示器．按颜色区分,可以分为单色（黑白）显示器和彩色显示器。彩色显示器又称图形显示器。它有两种基本工作方式:字符方式和图形方式。在字符方式下,显示内容以标准字符为单位,字符的字形由点阵构成，字符点阵存放在字形发生器中。在图形方式下，显示内容以像素为单位,屏幕上的每个点（像素）均可由程序控制其亮度和颜色，因此能显示出较高质量的图形或图像。显示器的分辨率分为高中低三种。分辨率的指标是用屏幕上每行的像素数与每帧（每个屏幕画面）行数的乘积表示的．乘积越大，也就是像素点越小，数量越多，分辨率就越高,图形就越清晰美观。显示器适配器彩色显示器显示器适配器又称显示器控制器，是显示器与主机的接口部件，以硬件插卡的形式插在主机板上。显示器的分辨率不仅决定於阴极射线管本身，也与显示器适配器的逻辑电路有关。常用的适配器有：（1）CGA（ColourGraphicAdapter）彩色图形适配器，俗称CGA卡,适用於低分辨率的彩色和单色显示器。它支持的显示方式为：字符方式下，40列×25行，80列×25行，4色或2色。图形方式下，320×200，4色；640×200，2色。（2）EGA（EnhancedGraphicAdapter）增强型图形适配器，俗称EGA卡，适用於中分辨率的彩色图形显示器．它支持的显示方式为：字符方式下，80×25列，256色图形方式下，640×350，16色超级EGA卡，支持800×600，16色。液晶显示器（3）VGA（VideoGraphicArray）视频图形阵列，俗称VGA卡，适用於高分辨率的彩色图形显示器。标准的分辨率为640×480，256色。使用的多是增强型的VGA卡，比如SuperVGA卡等,分辨率为800×600，1024×768等，256种颜色。（4）中文显示器适配器中国在开发汉字系统过程中，研制了一些支持汉字的显示器适配器，比如GW-104卡、CEGA卡、CVGA卡等，解决了汉字的快速显示问题。打印机打印机打印机（Printer）是将计算机的处理结果打印在纸张上的输出设备。人们常把显示器的输出称为软拷贝，把打印机的输出称为硬拷贝。将计算机输出数据转换成印刷字体的设备。从使用角度看可分为两类。一类具有键盘输入功能，速度较慢，但与计算机有对话能力。它价格低廉，除计算机和终端常用外，通信系统也把它用作常规设备。另一类没有键盘输入功能。这类打印机又可分为条式打印机、窄行式打印机、串行打印机、行式打印机和页式打印机等。按照物理结构，打印机又可分为击打式和非击打式两类。打印机分类按传输方式，可以分为一次打印一个字符的字符打印机、一次打印一行的行式打印机和一次打印一页的页式打印机。打印机按工作机构，可以分为击打式打印机和非击打式印字机。其中击打式又分为字模式打印机和点阵式打印机。非击打式又分为喷墨印字机、激光印字机、热敏印字机和静电印字机。微型计算机最常用的是点阵式打印机。点阵针式打印机特点：结构简单，体积小，价格低，字符种类不受限制，对打印介质要求不高，可以打印多层介质。结构：打印头与字车；输纸机构；色带机构；控制器：与显示控制器类似。它的打印头上安装有若干个针，打印时控制不同的针头通过色带打印纸面即可得到相应的字符和图形，因此,又常称之为针式打印机。日常使用的多为9针或24针的打印机,主要是24针打印机。喷墨印字机和激光印字机也得到广泛应用。喷墨式是通过磁场控制一束很细墨汁的偏转，同时控制墨汁的喷与不喷，即可得到相应的字符或图形。激光式则是利用电子照相原理,由受到控制的激光束射向感光鼓表面，在不同位置吸附上厚度不同的碳粉，通过温度与压力的作用把相应的字符或图形印在纸上．它与静电复印机的方式很相似。激光印字机分辨率高，印出字形清晰美观,但价格较高。喷墨打印机喷墨打印机是类似于用墨水写字一样的打印机,可直接将墨水喷射到普通纸上实现印刷,如喷射多种颜色墨水则可实现彩色硬拷贝输出。喷墨打印机的喷墨技术有连续式和随机式两种,目前市场上流行的各种型号打印机,大多采用随机式喷墨技术。而早年的喷墨打印机以及当前输出的大幅面打印机采用连续式喷墨技术。激光打印机的性能普通激光印字机的印字分辨率都能达到300DPI(每英寸300个点)或400DPI,甚至600DPI。特别是对汉字或图形/图像输出,是理想的输出设备。激光打印机称为“页式输出设备”，用每分钟输出的页数(pagesperminute，简称PPM)来表示。高速的在100PPM以上,中速为30~60PPM,它们主要用于大型计算机系统。低速为10~20PPM，甚至10PPM以下，主要用于办公自动化系统和文字编辑系统。[1]热转印打印机热转印打印机的印字质量优于点阵针式打印机,与喷墨打印机相当,印字速度比较快,串式一般可超过6页/分,分辨率达到360DPI。印字原理热转印打印机中的印字头是用半导体集成电路技术制成的薄膜头,头中有发热电阻,它由一种能耐高功率密度和耐高温的薄膜材料组成。将具有热敏性能的油墨涂在涤纶基膜上便构成热转印色带,色带位于热印字头与记录纸之间。印字时,脉冲信号将印字头中的发热电阻加热到几百度(如300℃),而印字头又压在涤纶膜上,使膜基上的油墨熔化而转移到记录纸上留下色点由色点组成字符,图形或图像。[1]打印机若打印汉字，对於装有汉字库的打印机，可直接打印，打印速度快．如无汉字库，在微机中则需安装该种打印机的汉字驱动程序，使用微机的汉字库，打印速度较慢。工作方式打印机有联机和脱机两种工作方式。所谓联机，就是与主机接通，能够接收及打印主机传送的信息；所谓脱机，就是切断与主机的联系。在脱机状态下，可以进行自检或自动进/退纸，这两种状态由打印机面板上的联机键控制。打印机控制器打印机控制器亦称打印机适配器,是打印机的控制机构。也是打印机与主机的接口部件，以硬件插卡的形式插在主机板上。标准接口是并行接口，它可以同时传送多个数据，比串行接口传输速度快。绘图机绘图机自动绘图机是直接由电子计算机或数字信号控制，用以自动输出各种图形、图像和字符的绘图设备。可采用联机或脱机的工作方式。是计算机辅助制图和计算机辅助设计中广泛使用的一种外围设备。常见的按绘图方式分为跟踪式绘图机（如笔式绘图机）和扫描式绘图机（如静电扫描绘图机、激光扫描绘图机、喷墨式扫描绘图机）等。按机械结构分为滚筒式（鼓式）绘图机和平台式绘图机两大类。数控绘图机的传动方式有钢丝或钢带传动；有滚珠丝杠或齿轮齿条传动；有电机传动，如采用开环控制方式的直线步进电机和采用闭环控制的伺服电机等。绘图仪能按照人们要求自动绘制图形的设备。它可将计算机的输出信息以图形的形式输出。主要可绘制各种管理图表和统计图、大地测量图、建筑设计图、电路布线图、各种机械图与计算机辅助设计图等。最常用的是X-Y绘图仪。现代的绘图仪已具有智能化的功能，它自身带有微处理器，可以使用绘图命令，具有直线和字符演算处理以及自检测等功能。这种绘图仪一般还可选配多种与计算机连接的标准接口。绘图仪绘图仪是一种输出图形的硬拷贝设备。绘图仪在绘图软件的支持下课绘制出复杂、精确的图形，是各种计算机辅助设计不可缺少的工具。绘图仪的性能指标主要有绘图笔数、图纸尺寸、分辨率、接口形式及绘图语言等。绘图仪一般是由驱动电机、插补器、控制电路、绘图台、笔架、机械传动等部分组成。绘图仪除了必要的硬设备之外，还必须配备丰富的绘图软件。只有软件与硬件结合起来，才能实现自动绘图。绘图仪的种类很多，按结构和工作原理可以分为滚筒式和平台式两大类：①滚筒式绘图仪。当X向步进电机通过传动机构驱动滚筒转动时，链轮就带动图纸移动，从而实现X方向运动。Y方向的运动，是由Y向步进电机驱动笔架来实现的。这种绘图仪结构紧凑，绘图幅面大。但它需要使用两侧有链孔的专用绘图纸。②平台式绘图仪。绘图平台上装有横梁，笔架装在横梁上，绘图纸固定在平台上。X向步进电机驱动横梁连同笔架，作X方向运动；Y向步进电机驱动笔架沿着横梁导轨，作Y方向运动。图纸在平台上的固定方法有3种，即真空吸附、静电吸附和磁条压紧。平台式绘图仪绘图精度高，对绘图纸无特殊要求，应用比较广泛。发展前景播报编辑输出设备第一代计算机的输出设备种类非常有限。通常的输入设备是打孔卡片的读卡机，用来将指令和数据导入内存；而用于存储结果的输出设备则一般是磁带。随着科技的进步，输入输出设备的丰富性得到提高。以个人计算机为例：键盘和鼠标是用户向计算机直接输入信息的主要工具，而显示器、打印机、扩音器、耳机则返回处理结果。此外还有许多输入设备可以接受其他不同种类的信息，如数码相机可以输入图像。在输入输出设备中，有两类很值得注意：第一类是二级存储设备，如硬盘，光碟或其他速度缓慢但拥有很高容量的设备。第二个是计算机网络访问设备，通过他们而实现的计算机间直接数据传送极大地提升了计算机的价值。国际互联网成就了数以千万计的计算机彼此间传送各种类型的数据。存储单元：介绍播报编辑存储单元存储单元：在存储器中有大量的存储元，把它们按相同的位划分为组，组内所有的存储元同时进行读出或写入操作，这样的一组存储元称为一个存储单元。一个存储单元通常可以存放一个字节；存储单元是CPU访问存储器的基本单位。[1-2]存储单元播报编辑地址上存储单元的过程在计算机中最小的信息单位是bit，也就是一个二进制位，8个bit组成一个Byte，也就是字节。一个存储单元可以存储一个字节，也就是8个二进制位。计算机的存储器容量是以字节为最小单位来计算的，对于一个有128个存储单元的存储器，可以说它的容量为128字节。如果有一个1KB的存储器则它有1024个存储单元，它的编号为从0－1023。存储器被划分成了若干个存储单元，每个存储单元都是从0开始顺序编号，如一个存储器有128个存储单元，则它的编号就是从0-127。存储地址一般用十六进制数表示，而每一个存储器地址中又存放着一组二进制（或十六进制）表示的数，通常称为该地址的内容。值得注意的是，存储单元的地址和地址中的内容两者是不一样的。前者是存储单元的编号，表示存储器中的一个位置，而后者表示这个位置里存放的数据。正如一个是房间号码，一个是房间里住的人一样。存放一个机器字的存储单元，通常称为字存储单元，相应的单元地址叫字地址。而存放一个字节的单元，称为字节存储单元，相应的地址称为字节地址。如果计算机中可以编址的最小单元是字存储单元，则该计算机称为按字寻址的计算机。如果计算机中可编址的最小单位是字节，则该计算机称为按字节寻址的计算机。如果机器字长等于存储器单元的位数，一个机器字可以包含数个字节，所以一个存储单元也可以包含数个能够单独编址的字节地址。例如一个16位二进制的字存储单元可存放两个字节，可以按字地址寻址，也可以按字节地址寻址。当用字节地址寻址时，16位的存储单元占两个字节地址。最小静态存储单元播报编辑世界上最小的静态存储单元2008年8月18日，美国IBM公司、AMD以及纽约州立大学Albany分校的纳米科学与工程学院（CNSE）等机构共同宣布，世界上首个22纳米节点有效静态随机存储器（SRAM）研制成功。这也是全世界首次宣布在300毫米研究设备环境下，制造出有效存储单元。SRAM芯片是更复杂的设备，比如微处理器的“先驱”。SRAM单元的尺寸更是半导体产业中的关键技术指标。最新的SRAM单元利用传统的六晶体管设计，仅占0.1平方微米，打破了此前的SRAM尺度缩小障碍。新的研究工作是在纽约州立大学Albany分校的纳米科学与工程学院（CNSE）完成的，IBM及其他伙伴的许多顶尖的半导体研究都在这里进行。IBM科技研发部副总裁T.C.Chen博士称，“我们正在可能性的终极边缘进行研究，朝着先进的下一代半导体技术前进。新的研究成果对于不断驱动微电子设备小型化的追求，可以说至关重要。”22纳米是芯片制造的下两代，而下一代是32纳米。在这方面，IBM及合作伙伴正在发展它们无与伦比的32纳米高K金属栅极工艺（high-Kmetalgatetechnology）。从传统上而言，SRAM芯片通过缩小基本构建单元，来制造得更加紧密。IBM联盟的研究人员优化了SRAM单元的设计和电路图，从而提升了稳定性，此外，为了制造新型SRAM单元，他们还开发出几种新的制作工艺流程。研究人员利用高NA浸没式光刻（high-NAimmersionlithography）技术刻出了模式维度和密度，并且在先进的300毫米半导体研究环境中制作了相关部件。与SRAM单元相关的关键技术包括：边带高K金属栅极、<25纳米栅极长度晶体管、超薄隔离结构（spacer）、共同掺杂、先进激活技术、极薄硅化物膜以及嵌入式铜触点等。据悉，在2008年12月15至17日美国旧金山将要举行的IEEE国际电子设备（IEDM）年会上，还会有专门的报告来介绍最新成果的细节。相关应用播报编辑在计算机中，由控制器解释，运算器执行的指令集是一个精心定义的数目十分有限的简单指令集合。一般可以分为四类：1）、数据移动（如：将一个数值从存储单元A拷贝到存储单元B）2）、数逻运算（如：计算存储单元A与存储单元B之和，结果返回存储单元C）3）、条件验证（如：如果存储单元A内数值为100，则下一条指令地址为存储单元F）4）、指令序列改易（如：下一条指令地址为存储单元F）[1]内存碎片：产生播报编辑内存分配有静态分配和动态分配两种。静态分配在程序编译链接时分配的大小和使用寿命就已经确定，而应用上要求操作系统可以提供给进程运行时申请和释放任意大小内存的功能，这就是内存的动态分配。因此动态分配将不可避免会产生内存碎片的问题，那么什么是内存碎片？内存碎片即“碎片的内存”描述一个系统中所有不可用的空闲内存，这些碎片之所以不能被使用，是因为负责动态分配内存的分配算法使得这些空闲的内存无法使用，这一问题的发生，原因在于这些空闲内存以小且不连续方式出现在不同的位置。因此这个问题的或大或小取决于内存管理算法的实现上。为什么会产生这些小且不连续的空闲内存碎片呢？实际上这些空闲内存碎片存在的方式有两种：a.内部碎片b.外部碎片。内部碎片的产生：因为所有的内存分配必须起始于可被4、8或16整除（视处理器体系结构而定）的地址或者因为MMU的分页机制的限制，决定内存分配算法仅能把预定大小的内存块分配给客户。假设当某个客户请求一个43字节的内存块时，因为没有适合大小的内存，所以它可能会获得44字节、48字节等稍大一点的字节，因此由所需大小四舍五入而产生的多余空间就叫内部碎片。外部碎片的产生：频繁的分配与回收物理页面会导致大量的、连续且小的页面块夹杂在已分配的页面中间，就会产生外部碎片。假设有一块一共有100个单位的连续空闲内存空间，范围是0~99。如果你从中申请一块内存，如10个单位，那么申请出来的内存块就为0~9区间。这时候你继续申请一块内存，比如说5个单位大，第二块得到的内存块就应该为10~14区间。如果你把第一块内存块释放，然后再申请一块大于10个单位的内存块，比如说20个单位。因为刚被释放的内存块不能满足新的请求，所以只能从15开始分配出20个单位的内存块。现在整个内存空间的状态是0~9空闲，10~14被占用，15~34被占用，25~99空闲。其中0~9就是一个内存碎片了。如果10~14一直被占用，而以后申请的空间都大于10个单位，那么0~9就永远用不上了，变成外部碎片。[1]分类播报编辑内存碎片分为：内部碎片和外部碎片。内部碎片内部碎片就是已经被分配出去（能明确指出属于哪个进程）却不能被利用的内存空间；内部碎片是处于区域内部或页面内部的存储块。占有这些区域或页面的进程并不使用这个存储块。而在进程占有这块存储块时，系统无法利用它。直到进程释放它，或进程结束时，系统才有可能利用这个存储块。单道连续分配只有内部碎片。多道固定连续分配既有内部碎片，又有外部碎片。外部碎片外部碎片指的是还没有被分配出去（不属于任何进程），但由于太小了无法分配给申请内存空间的新进程的内存空闲区域。外部碎片是出于任何已分配区域或页面外部的空闲存储块。这些存储块的总和可以满足当前申请的长度要求，但是由于它们的地址不连续或其他原因，使得系统无法满足当前申请。多道可变连续分配只有外部碎片[2]。减少方法播报编辑内存碎是因为在分配一个内存块后，使之空闲，但不将空闲内存归还给最大内存块而产生的。最后这一步很关键。如果内存分配程序是有效的，就不能阻止系统分配内存块并使之空闲。即使一个内存分配程序不能保证返回的内存能与最大内存块相连接（这种方法可以彻底避免内存碎片问题），但你可以设法控制并限制内存碎片。所有这些作法涉及到内存块的分割。每当系统减少被分割内存块的数量，确保被分割内存块尽可能大时，你就会有所改进。这样做的目的是尽可能多次反复使用内存块，而不要每次都对内存块进行分割，以正好符合请求的存储量。分割内存块会产生大量的小内存碎片，犹如一堆散沙。以后很难把这些散沙与其余内存结合起来。比较好的办法是让每个内存块中都留有一些未用的字节。留有多少字节应看系统要在多大程度上避免内存碎片。对小型系统来说，增加几个字节的内部碎片是朝正确方向迈出的一步。当系统请求1字节内存时，你分配的存储量取决于系统的工作状态。如果系统分配的内存存储量的主要部分是1～16字节，则为小内存也分配16字节是明智的。只要限制可以分配的最大内存块，你就能够获得较大的节约效果。但是，这种方法的缺点是，系统会不断地尝试分配大于极限的内存块，这使系统可能会停止工作。减少最大和最小内存块存储量之间内存存储量的数量也是有用的。采用按对数增大的内存块存储量可以避免大量的碎片。例如，每个存储量可能都比前一个存储量大20%。在嵌入式系统中采用“一种存储量符合所有需要”对于嵌入式系统中的内存分配程序来说可能是不切实际的。这种方法从内部碎片来看是代价极高的，但系统可以彻底避免外部碎片，达到支持的最大存储量。将相邻空闲内存块连接起来是一种可以显著减少内存碎片的技术。如果没有这一方法，某些分配算法（如最先适合算法）将根本无法工作。然而，效果是有限的，将邻近内存块连接起来只能缓解由于分配算法引起的问题，而无法解决根本问题。而且，当内存块存储量有限时，相邻内存块连接可能很难实现。有些内存分配器很先进，可以在运行时收集有关某个系统的分配习惯的统计数据，然后，按存储量将所有的内存分配进行分类，例如分为小、中和大三类。系统将每次分配指向被管理内存的一个区域，因为该区域包括这样的内存块存储量。较小存储量是根据较大存储量分配的。这种方案是最先适合算法和一组有限的固定存储量算法的一种有趣的混合，但不是实时的。有效地利用暂时的局限性通常是很困难的，但值得一提的是，在内存中暂时扩展共处一地的分配程序更容易产生内存碎片。尽管其它技术可以减轻这一问题，但限制不同存储量内存块的数目仍是减少内存碎片的主要方法。现代软件环境业已实现各种避免内存碎片的工具。例如，专为分布式高可用性容错系统开发的OSE实时操作系统可提供三种运行时内存分配程序：内核alloc()，它根据系统或内存块池来分配；堆malloc()，根据程序堆来分配；OSE内存管理程序alloc_region，它根据内存管理程序内存来分配。从许多方面来看，Alloc就是终极内存分配程序。它产生的内存碎片很少，速度很快，并有判定功能。你可以调整甚至去掉内存碎片。只是在分配一个存储量后，使之空闲，但不再分配时，才会产生外部碎片。内部碎片会不断产生，但对某个给定的系统和八种存储量来说是恒定不变的。Alloc是一种有八个自由表的固定存储量内存分配程序的实现方法。系统程序员可以对每一种存储量进行配置，并可决定采用更少的存储量来进一步减少碎片。除开始时以外，分配内存块和使内存块空闲都是恒定时间操作。首先，系统必须对请求的存储量四舍五入到下一个可用存储量。就八种存储量而言，这一目标可用三个如果语句来实现。其次，系统总是在八个自由表的表头插入或删除内存块。开始时，分配未使用的内存要多花几个周期的时间，但速度仍然极快，而且所花时间恒定不变。堆malloc()的内存开销（8～16字节/分配）比alloc小，所以你可以停用内存的专用权。malloc()分配程序平均来讲是相当快的。它的内部碎片比alloc()少，但外部碎片则比alloc()多。它有一个最大分配存储量，但对大多数系统来说，这一极限值足够大。可选的共享所有权与低开销使malloc()适用于有许多小型对象和共享对象的C++应用程序。堆是一种具有内部堆数据结构的伙伴系统的实现方法。在OSE中，有28个不同的存储量可供使用，每种存储量都是前两种存储量之和，于是形成一个斐波那契（Fibonacci）序列。实际内存块存储量为序列数乘以16字节，其中包括分配程序开销或者8字节/分配（在文件和行信息启用的情况下为16字节）。当你很少需要大块内存时，则OSE内存管理程序最适用。典型的系统要把存储空间分配给整个系统、堆或库。在有MMU的系统中，有些实现方法使用MMU的转换功能来显著降低甚至消除内存碎片。在其他情况下，OSE内存管理程序会产生非常多的碎片。它没有最大分配存储量，而且是一种最先适合内存分配程序的实现方法。内存分配被四舍五入到页面的偶数——典型值是4k字节。网络系统：简介播报编辑NOS与运行在工作站上的单用户操作系统(如WINDOWS系列)或多用户操作系统（UNIX、Linux）由于提供的服务类型不同而有差别。一般情况下，NOS是以使网络相关特性达到最佳为目的的，如共享数据文件、软件应用，以及共享硬盘、打印机、调制解调器、扫描仪和传真机等。一般计算机的操作系统，如DOS和OS/2等，其目的是让用户与系统及在此操作系统上运行的各种应用之间的交互作用最佳。为防止一次有一个以上的用户对文件进行访问，一般网络操作系统都具有文件加锁功能。如果系统没有这种功能，用户将不会正常工作。文件加锁功能可跟踪使用中的每个文件，并确保一次只能一个用户对其进行编辑。文件也可由用户的口令加锁，以维持专用文件的专用性。NOS还负责管理LAN用户和LAN打印机之间的连接。NOS总是跟踪每一个可供使用的打印机，以及每个用户的打印请求，并对如何满足这些请求进行管理，使每个端用户感到进行操作的打印机犹如与其计算机直接相连。由于网络计算的出现和发展，现代操作系统的主要特征之一就是具有上网功能，因此，除了在20世纪90年代初期，Novell公司的Netware等系统被称为网络操作系统之外，人们一般不再特指某个操作系统为网络操作系统。模式分类播报编辑集中模式图示[1]集中式网络操作系统是由分时操作系统加上网络功能演变的。系统的基本单元是由一台主机和若干台与主机相连的终端构成，信息的处理和控制是集中的。UNIX就是这类系统的典型。客户机/服务器模式这种模式是最流行的网络工作模式。服务器是网络的控制中心，并向客户提供服务。客户是用于本地处理和访问服务器的站点。对等模式采用这种模式的站点都是对等的，既可以作为客户访问其它站点，又可以作为服务器向其他站点提供服务。这种模式具有分布处理和分布控制的功能。LAN中的网络操作系统分类播报编辑Windows类对于这类操作系统相信用过电脑的人都不会陌生，这是全球最大的软件开发商--Microsoft（微软）公司开发的。微软公司的Windows系统不仅在个人操作系统中占有绝对优势，它在网络操作系统中也是具有非常强劲的力量。这类操作系统配置在整个局域网配置中是最常见的，但由于它对服务器的硬件要求较高，且稳定性能不是很高，所以微软的网络操作系统一般只是用在中低档服务器中，高端服务器通常采用UNIX、LINUX或Solaris等非Windows操作系统。在局域网中，微软的网络操作系统主要有：WindowsNT4.0Serve、Windows2000Server/AdvanceServer，以及最新的Windows2003Server/AdvanceServer等，工作站系统可以采用任一Windows或非Windows操作系统，包括个人操作系统，如Windows9x/ME/XP等。在整个Windows网络操作系统中最为成功的还是要算了WindowsNT4.0这一套系统，它几乎成为中、小型企业局域网的标准操作系统，一则是它继承了Windows家族统一的界面，使用户学习、使用起来更加容易。再则它的功能也的确比较强大，基本上能满足所有中、小型企业的各项网络需求。虽然相比Windows2000/2003Server系统来说在功能上要逊色许多，但它对服务器的硬件配置要求要低许多，可以更大程度上满足许多中、小企业的PC服务器配置需求。图示[2]NetWare类NetWare操作系统虽然远不如早几年那么风光，在局域网中早已失去了当年雄霸一方的气势，但是NetWare操作系统仍以对网络硬件的要求较低（工作站只要是286机就可以了）而受到一些设备比较落后的中、小型企业，特别是学校的青睐。人们一时还忘不了它在无盘工作站组建方面的优势，还忘不了它那毫无过分需求的大度。且因为它兼容DOS命令，其应用环境与DOS相似，经过长时间的发展，具有相当丰富的应用软件支持，技术完善、可靠。目前常用的版本有3.11、3.12和4.10、V4.11，V5.0等中英文版本，NetWare服务器对无盘站和游戏的支持较好，常用于教学网和游戏厅。目前这种操作系统有市场占有率呈下降趋势，这部分的市场主要被WindowsNT/2000和Linux系统瓜分了。Unix系统目前常用的UNIX系统版本主要有：UnixSUR4.0、HP-UX11.0，SUN的Solaris8.0等。支持网络文件系统服务，提供数据等应用，功能强大，由AT&T和SCO公司推出。这种网络操作系统稳定和安全性能非常好，但由于它多数是以命令方式来进行操作的，不容易掌握，特别是初级用户。正因如此，小型局域网基本不使用Unix作为网络操作系统，UNIX一般用于大型的网站或大型的企、事业局域网中。UNIX网络操作系统历史悠久，其良好的网络管理功能已为广大网络用户所接受，拥有丰富的应用软件的支持。目前UNIX网络操作系统的版本有：AT&T和SCO的UNIXSVR3.2、SVR4.0和SVR4.2等。UNIX本是针对小型机主机环境开发的操作系统，是一种集中式分时多用户体系结构。因其体系结构不够合理，UNIX的市场占有率呈下降趋势。Linux这是一种新型的网络操作系统，它的最大的特点就是源代码开放，可以免费得到许多应用程序。目前也有中文版本的Linux，如REDHAT(红帽子)，红旗Linux等。在国内得到了用户充分的肯定，主要体现在它的安全性和稳定性方面，它与Unix有许多类似之处。但目前这类操作系统目前使仍主要应用于中、高档服务器中。总的来说，对特定计算环境的支持使得每一个操作系统都有适合于自己的工作场合，这就是系统对特定计算环境的支持。例如，Windows2000Professional适用于桌面计算机，Linux目前较适用于小型的网络，而Windows2000Server和UNIX则适用于大型服务器应用程序。因此，对于不同的网络应用，需要我们有目的有选择合适地网络操作系统。网络服务器的架设播报编辑客户端与服务器又称主从式架构(Client/Server)，基本的架构为：客户端（Client），用户将所需的数据通过网络联系服务端，服务器（Server）收到消息后，搜索数据库内符合的数据，再通过网络回应给客户端，所有的需求都须经过网络，所以网络在主从式架构中，扮演着极重的角色。[2]点对点技术（PeertoPeer）又称非中心式网络，每台电脑同时是客户端也是服务器，拥有平等的地位，此技术最大的特性就是资源共享，一般来说，在网络上同一个文件越多人下载就越难下载的到，因为服务端的流量是固定的，导致供不应求，但是P2P通过访问电脑上的带宽，再下载文件的同时利用未使用的上传带宽，分享文件，越多人下载则速度越快。[2]与其他操作系统区别播报编辑网络操作系统是网络上各计算机能方便而有效地共享网络资源，为网络用户提供所需的各种服务的软件和有关规程的集合。网络操作系统与通常的操作系统有所不同，它除了应具有通常操作系统应具有的处理机管理、存储器管理、设备管理和文件管理外，还应具有以下两大功能：(1)提供高效、可靠的网络通信能力；(2)提供多种网络服务功能，如：远程作业录入并进行处理的服务功能；文件转输服务功能；电子邮件服务功能；远程打印服务功能大型计算机：简介播报编辑大型机是用来处理大容量数据的机器。欧盟委员会称，全球绝大多数企业数据依然存储在大型机上，2009年新大型机硬件销售额便达到了85亿欧元，其中仅在欧洲经济区销售额就达到30亿欧元。[1]特征播报编辑现代大型计算机并非主要通过每秒运算次数MIPS来衡量性能，而是可靠性、安全性、向后兼容性和极其高效的I/O性能。主机通常强调大规模的数据输入输出，着重强调数据的吞吐量。[1]大型计算机可以同时运行多操作系统，因此不像是一台计算机而更像是多台虚拟机，因此一台主机可以替代多台普通的服务器，是虚拟化的先驱。同时主机还拥有强大的容错能力。[1]主机的投资回报率取决于处理数据的规模、减少人力开支、实现不间断服务和其他成本的缩减。由于主机的平台与操作系统并不开放，因而很难被攻破，安全性极强。[1]大型机使用专用的操作系统和应用软件，在主机上编程采用COBOL，同时采用的数据库为IBM自行开发的DB2。在大型机上工作的DB2数据库管理员能够管理比其他平台多3～4倍的数据量。[1]历史播报编辑在1960年代，大多数主机没有交互式的界面，通常使用打孔卡、磁带等等。[1]1964年，IBM引入了System/360，它是由5种功能越来越强大的计算机所组成的系列，这些计算机运行同一操作系统并能够使用相同的44个外围设备。[1]1972年，SAP公司为System/360开发了革命性的“企业资源计划”系统。[1]1999年，Linux出现在System/390中，第一次将开放式源代码计算的灵活性与主机的传统可伸缩性和可靠性相结合。[1]与超级计算机的区别播报编辑超级计算机有极强的计算速度，通常由于科学与工程上的计算，这些计算的速度受运算速度与内存大小所限制；而主机运算任务主要受数据传输与转移、可靠性及并发处理性能所限制。[1]主机更倾向于整数运算，如订单数据、银行数据等，同时在安全性、可靠性和稳定性方面优于超级计算机。而超级计算机更强调浮点运算性能，如天气预报。主机在处理数据的同时需要读写或传输大量信息，如海量的交易信息、航班信息等等。[1]优势播报编辑IBMmainframeZ10大型机体系结构的最大好处是无与伦比的I/O处理能力。虽然大型机处理器并不总是拥有领先优势，但是它们的I/O体系结构使它们能处理好几个PC服务器放一起才能处理的数据。大型机的另一些特点包括它们的大尺寸和使用液体冷却处理器阵列。在使用大量中心化处理的组织中，它们仍有重要的地位。[1]由于小型计算机的到来，新型大型机的销售已经明显放慢。在电子商务系统中，如果数据库服务器或电子商务服务器需要高性能、高I/O处理能力，可以采用大型机。[1]在20世纪60－80年代，信息处理主要是采用主机+终端的方式，即主机集中式处理方式。大型机的主要厂商有IBM/日立等。但无论是大型机本身还是它的维护成本都相当昂贵。因此，能够使用大型机的企业寥寥可数。进入80年代以后，随着PC和各种服务器的高速发展，大型机的市场变的越来越小，很多企业都放弃了原来的大型机改用小型机和服务器。[1]另外，客户机/服务器（client/server）技术的飞速发展也是大型机市场萎缩的一个重要原因。这时的大型机就象濒临灭绝的恐龙逐渐走向灭亡。进入90年代后，经济进入全球化，信息技术得以高速的发展，随着企业规模的扩大，信息分散管理的弊端越来越多，运营成本迅速的增长。信息集中成了不可逆转的潮流。这时，人们又把目光集中到大型机的身上，大型机的市场逐渐的恢复了活力，直至今天，大型机还占有了不可替代的市场份额。90年代后期，大型机的技术得以飞速的发展，其处理能力也大踏步的提高，在民用领域，IBM已经完全占据了大型机的市场。[1]发展历史播报编辑1948年，IBM开发制造了基于电子管的计算机SSEC。1952年IBM公司的第一台用于科学计算的大型机IBM701问世，1953年又推出了第一台用于数据处理的大型机IBM702和小型机IBM650，这样第一代商用计算机诞生了。此后，IBM于1965年又推出了701于702的后续产品704和705。1956年，IBM又推出了第一台随机存储系统RAMAC305,RAMAC是”计算与控制随机访问方法”的英文缩写。它是现代磁盘系统的先驱。1958年IBM又推出了7090，1960年又推出7040、7044大型数据处理机。总之，在1955年到1965年，美国名牌大学与大公司使用的计算机大多数是IBM704到IBM7094这些机器。[1]1964年4月7日，IBM公布了360系统，成为计算机发展史上的一个重要了里程碑。System/360系统的主要贡献是：从应用的角度来看，克服了第二代计算机性能单调的弱点，集科学计算，数据处理和实时控制功能于一身，确定了通用性。从生产的角度讲，实现了系列化，360系统的主要型号有：20型、25型和30型小型机44型和50型小型机，65型，75型和85型大型机，以及91型和105型超级计算机。型号虽多，但采用了标准化措施，统一指令格式，统一数据格式，统一字符编码，统一I/O接口，统一中断系统以及统一人机对话方式等。由于确定了兼容性。是同一程序在不同型号的机器语言级上的兼容，促进了计算机工业能力的规模和发展。从发展的角度来看，既采用了新的技术，有留有发展的余地。[1]日后S/370和S/390都是从S/360上发展而来的，他们各自标定着相应的系统体系机构。从使用的角度来看，360系统配有操作系统、汇编语言和FORTRAN、COBOL等高级语言，使用十分方便，更重要的是360在建立计算机系统的继承性上起来开创性的作用。1981年，IBM公布了扩展的System/370体系结构（370－XA）。System/370-XA将地址线位数增加到32位，大大增加了System/370的寻址能力，同时保留了24位的兼容方式（向上兼容）。同时370还增加了扩展存储器（EXPANDEDSTORAGE）。1988年，IBM对System/370做了进一步的改进，ESA（EnterpriseSystemArchitecture）/370。ESA/370增加了访问寄存器，改进了虚存的性能。通过这项技术，应用可以访问称之为数据空间（dataspace）的另一个虚存空间。因此，ESA/370允许应用访问多个2G的数据空间。基于该体系结构的产品系列使得多用户可以更方便得共享系统资源。[1]1990年9月，IBM开发了ESA/390以及ES/9000System/390系列计算机系统，其性价比远远高于System/370系统。IBMS/390系列与以前得S/370系统相比，在体系结构上作了如下改进：[1]⑴、企业系统连接结构ESCON：这是一种新得输入输出结构，它定义了一个规则，使存储器子系统、控制部件、通讯控制部件等I/O设备都通过这套规则与处理器进行通讯。ESCON得通讯速度是17M/S。[1]⑵加密结构：在S/390中，计算机通过集成密码特征来实现对计算机中得信息进行加密或解密，以防止被非法访问。[1]⑶子系统存贮保护：防止诸如CICS等子系统对系统存储器的干扰。这个功能由操作系统和子系统共同提供。[1]⑷数据压缩：S/390在硬件级上提供了数据压缩。其压缩速度是软件压缩的5倍。[1]⑸异步数据转移结构（ADMF）：利用I/O处理器去更有效的实现中央处理器与扩展存储器之间的信息转移，以空出处理器来处理其他任务。[1]⑹DB2排序增强：使用硬件完成DB2的排序算法。[1]工作原理播报编辑架构2000年后，IBM推出Z/Architecture架构主机，Z系列主机的旗舰产品为Z/990，这一体系用来减少由于缺少可寻址的内存而带来的瓶颈，并通过智能资源导向器（IntelligentResourceDirector，IRD）自动将资源分配给高优先级的工作报。z/ArchitectureTM是ESA/390的64位扩展集。z990利用新的超标量体系结构的微型处理器和CMOS9S-SOI技术，它进一步扩展并集成了主要的平台特性，例如混合和无法预测的负载环境中的动态灵活分区和资源管理，为新兴的电子商务应用（例如IBMWebSphereTM，JavaTM和Linux┨峁┝死┱剐浴⒏呖捎眯院头务质量。z990将系统的扩展性以及服务器整合的机会进行了相当大的改进，提供了一个多区域（multi-book）系统结构，可支持配置一到四个区域。每个区域中包括一个多芯片模块（MultiChipModule，MCM）、内存卡—每个区域最多可支持64GB内存—以及新的高性能的自定时互连(Self-TimedInterconnect）。为支持高度可扩展的多区域的系统设计，z990对通道子系统（ChannelSubSystem，CSS）进行了改进，引入了多个逻辑通道子系统（LogicalChannelSubSystem,LCSS），利用这些LCSS，在三个I/O箱中最多可以安装512个通道。TCP/IP通讯的高速互连（称作HiperSockets）使分区之间的TCP/IP传输速度达到内存的速度，而不是受限于网络的速度。支持光纤和铜连线的高速千兆以太网(GigabitEthernet,GbE）是业内线速最先达到每秒千兆的实现之一。[1]技术发展S/390的系统运行方式为了满足各种不同应用业务的需求，S/390可以运行在不同的模式下。[1]S/370本机模式在这种模式下，S/390同样可以执行S/370的217条指令，但是它利用S/370的扩展实寻址的26为地址，可以将重要存储器扩展到64位。中央存储器的容量的增大意味着页面调度次数（PAGING）的减少，因而提高了整个系统的性能。[1]ESA/390方式这个方式的运行是按企业系统结构ESA/390所确定的功能来进行的，其指令集扩展到了229条指令。它使用32位地址，因此虚拟地址空间扩展大了2GB，但仍与24位的程序相兼容。在最大的S/390计算机系统中，总共可以配置256个通道。它支持并行通道，ESCON通道和集成I/O适配器。另外，它在硬件中还有自动处理“通道占线”条件，可以十分有效的减少与I/O动作有关的整个等待或延迟时间。[1]ESA/390LPAR方式，所有的S/390系列计算机都可以在这种方式下运行，在这种模式下系统虽然物理在一个机柜里。但是在逻辑上，它最多可以分成16个部分，这种在逻辑上的划分是由PR/SM微码来完成的。每个系统可以拥有自己的通道CPU和内存，每个部分都可独立工作独立安装一个系统。在这种模式下一个物理CPU和一个物理ESCON通道可以同时划分给不同的LPAR。内存不可以。[1]COUPLEFACILITY方式在这中方式下，S/390主机被作为了一个单独管理数据的主机。这种模式要运行CFCC微码，没有任何应用程序在CFCC里运行。主要是在并行耦合系统中应用。[1]S/390的操作系统在S/390上可以同时运行多个操作系统，每个操作系统都有各自不同的应用程序环境。[1]MVS/ESAMVS/ESA操作系统是S/390上运行的综合能力较强、可靠性较高的操作系统。它实际是1964年IBM在其S/360上运行的OS/360操作系统的后代。1972年IBM又推出了新的操作系统OS/VS2也就是单虚存系统。它最大的特点是提供对虚存的支持。1988年，IBM宣布并发行了MVS/ESA操作系统。同样，MVS/ESA也是为1988年问世的ESA/370的新功能而设计的。MVS/ESA最多可支持2GB的中央存储器并能很好的应用扩展存储器。1990年9月，IBM开发了MVS/ESASPV4。MVS/ESA的这个版本管理存储器的方法与早期的MVS/ESA发行版一样，但它改进了对ESCON通道的复合系统时钟的支持。1994年，IBM发布了MVS/ESA的第5版，实现了操作系统并行耦合的功能，它最大可以支持32个MVS/ESA系统。每个系统都可以是一个多处理器。[1]OS/390OS/390是一个集成的企业服务器操作系统。它将开发的通讯服务器、分布式数据和文件服务、并行耦合系统的支持、面向对象程序设计、DCE以及开发应用程序接口集成成为一个产品。由于它是MVS操作系统基础上发展起来的，因而保留了MVS的高可*性、持续可用性及安全性等优异性能，为用户提供具有可扩充性的系统。但MVS是封闭性的，而OS/390转变为开发性的。它包括许多服务器软件，具有整合的功能。[1]Z/OS-z/OS的内核由OS/390发展而来，同时它又提供了一系列与z/900硬件与微码紧密结合的创新功能。其中的核心之一是智能资源导向器（简称IRD）技术，也曾被称为“LPAR集群”技术。IRD技术的实质是将工作量管理器（简称WLM）目标管理模式，结合并行系统综合体资源共享以及分区资源/系统管理（简称PR/SM）等多种技术，进行有机的整合以产生最大的效益，帮助用户将宝贵的系统资源在合适的时间分配给最需要的任务。-z/Series各操作系统所采用的新技术都为在该平台混合运行多种工作负荷提供了更好的支持。z/OS为传统主机应用和需要最高服务品质的Java及UNⅨ应用提供理想的运行环境。[1]VM和LINUXVM（ⅥSUALMACHINE）是IBM早期在大型机上安装的底层操作系统，在VM上可以同时安装很多其他的操作系统。进入90年代由于S/390LPAR模式的诞生，VM几乎将被淘汰，但由于LINUX的兴起，VM再次被利用起来，在一台S/390的主机上，VM上可以同时运行上千个LINUX。当然LINUX也可以独自运行在S/390的一个分区上。运行在主机上的LINUX大都是TRUBO和SUSE的LINUX。后两家在LINUX进行合作，推出了UNITEDLINUX。[1]组成部分OS/390操作系统由其基本的部分和各个子系统组成，本节就基本部分和各个子系统进行简单介绍。[1]MVS基本控制程序BCP[1]MVS基本控制程序BCP与JES2或JES3组成了OS/390的主干部分。它提供了基本的服务，使得OS/390能够更可靠、完全、完整的处理用户数据。与MVS相比OS/390增强了对LINKLST的处理、系统日志及APPC的支持。作业进入子系统（JES）[1]作业进入子系统接受要处理的作业并处理作业的输出。作业进入子系统共有两个，JES2和JES3。他们基本上提供相同的功能。通常使用的是JES2。JES工作过程如下：作业通过读卡机、分时终端系统或网络进入系统，或者由程序生成后传递给系统。所有的作业都要经过扫描检验其正确性，然后排入适当的队列。JES提供一种手段，使系统以优先权分级结构为基础，通过有序的方式调度工作。转换程序将作业控制语句（JCL）转换成系统能读的内部形式。同时进行一些其他的校验。如果发现错误，将该作业从系统中清除，并向用户发出相应的信息。下一步，作业又一次根据分级与优先权送至系统执行。这时JES放弃对作业的控制权，直到又打印输出被JES截获时，JES把它交付给假脱机磁盘，作业终止系统通知JES，作业进入下一个JES操作输出步骤，输出经过打印或穿孔后从系统中撤销，该作业用过的假脱机空间可以重新使用。JES对优先权进行动态调整，作业等待运行的时间越长，系统将它的优先权提升的越高。[1]存储管理子系统（SMS）存储管理子系统主要完成如下功能：管理外存资源，存储管理子系统可以让你为操作系统定义自动管理外存储系统的策略（主要通过定义适当的SG，MC，SC，DC，ACSROUTE），系统能够安装定义的策略进行自动的管理外存系统。提供编目机制（VTOC,VVDS，VCAT），对磁盘、磁带上的数据进行编目（RMM），以便与用户能够方便迅速的访问数据。把程序存储在程序库中，以便于读出执行。定义系统中的输入输出设备并控制这些设备的操作。支持从工作站、个人计算机或基于SNALU6.2网络的其他系统通过分布式文件管理（DFM）访问主机系统的数据.[1]分时系统（TSO）TSO是支持分时系统的软件，终端用户发出的每一条指令都由TSO处理，用户通过TSO命令和系统进行交互式工作，但这样作不太方便，IBM又在TSO开发了用户程序产品ISPF/PDF（INTERACTⅣEPRODUCTIⅥTYFACILITY/PROGRAMDEVELOPMENTFACILITY）。其中ISPF支持回话功能，PDF支持程序开发功能，从而使终端用户与TSO会话更加简单直观，提高用户的应用开发效率。ISPF/PDF是以屏幕为单位的菜单输入方式，用户只需进行一些简单的菜单选择就可以和系统进行交互了。在TSO下工作了另一个软件是SDSF（SYSTEMDISPLAYANDSEARCHFACILITY），用户利用SDSF可以非常方便的查看用户用户提交给系统的作业的返回信息，也能够修改作业的属性。[1]设备支持机制（ICKDSF）ICKDSF可用于执行对IBM直接访问设备（DASD/硬盘）的安装和使用的任务。例如，你可以使用ICKDSF对DASD进行错误检查，格式化，碎片整理等维护。[1]硬件配置定义（HCD）HCD拥有定义操作系统硬件配置的定义以及处理器硬件配置的定义。由于HCD是在设备定义时验证其数据的有效性，而不是在设备被访问的时候验证，设备定义的不一致性可以得到避免。[1]SMP/ESMP/E是一个安装和维护软件的工具。它提供了一个可靠的方法用于安装维护OS/390中的软件。[1]VTAMVTAM是实现SNA和APPN的网络通讯访问方法，它为在主机处理器上的应用程序和SNA网络上的其他资源之间提供了一个接口。VTAM为网络上的用户建立和终止会话。为了建立和终止这些会话，VTAM按照其控制激活和不激活资源，这些资源包括包括应用程序、网络控制程序（NCP）及其控制的设备以及VTAM直接连接的设备。VTAM也维护网络的配置信息、活动和网络条件。为了帮助用户控制网络，VTAM从操作员接受命令然后执行网络服务。它通过操作员通知操作员网络的状况。Anynet实现了多协议传换网络体系结构。它运行应用和传输服务之间消除强制联网协议约束。换句话说，应用和它们的服务能用超过一个协议通讯而非原始的实现。AnyNet的这一特性使得SNA应用可以在TCP/IP网络上通讯，统一建筑与TCP/IP之上的SNA对逻辑单元通讯提供了支持。它支持所有LU类型，包括LU6.29.TCP/IPTCP/IP是一组工业标准和应用，它允许你与其他的计算机共享数据和计算机资源不管这些机器是IBM或非IBM的。标准的TCP/IP应用包括电子邮件、文件传输、远程登陆等。TCP/IPCICSSOCKET应用提供了在COBOL,PL/1及汇编语言中使用通用的应用程序接口的能力。[1]OS/390安全服务器（RACF）RACF是OS/390中的安全管理服务，它可以保护系统中的所有资源，认证用户的登陆，有效的记录系统中的安全事件。RACF提供：灵活可变的资源保护方式；保护所有资源；可以选择集中保护或分散保护；提供一个ISPF菜单；对最终用户的透明。资源度量设备（RMF）RMF是反应OS/390资源使用情况的一个窗口。它收集在SYSPLEX级和单个系统级和地址级的信息，在SYSPLEX中任何系统上产生报告。用户能在这些报告中选择所关心的活动，比如能专门选择关注的存储器、I/O或处理器数据、RMF的管理器1可以产生长期的报告，用于对RMF收集的长期数据进行详细的分析。这些报告能被打印或显示出来，你可以用RMF电子数据表转换器，从屏幕或MVS数据集下载这些报告。产生工作站上的电子数据表并对其进行详细的分析。[1]DFSMSDFSMS主要由三个部分组成：DFSMSdss是一个DASD数据和空间的管理工具，它可用于卷之间的拷贝，移动数据集；DUMP、恢复数据集及完整的卷或磁道；使数据集和卷改变为SMS管理的或非SMS管理的；压缩分区式的数据集；释放数据集中未使用的工具。DFSMShsm是一个DASD存储管理工具，用于管理较少活动和不活跃的数据。它通过自动管理空间的数据的有效性，在存储体系中改善DASD使用情况。DFSMShsm和SMS一起工作，按照数据集的managementclass对数据集进行空间管理和有效性管理。DFSMSrmm管理磁带卷以及其上的数据集。DFSMSrmm可以管理所有的磁带介质以及其他可移动的介质。例如，DFSMSrmm能记录光盘架的位置，追踪它们的必不可少的记录状态，但不管理光盘的数据。[1]系统显示和查设施（SDSF）系统显示和查找设施（SDSF）提供给用户有关监视、管理和控制OS/390系统信息。SDSF提供一个简单而高效的方法。控制作业的处理和设备的运行。比如你可以在作业运行时监视作业，浏览作业的输出而不打印，你可以浏览包括整个SYSPLEX范围的操作日志和系统日志。SDSF提供对信息进行分类、过滤，查找和打印的功能，帮助你定位和组织信息。菜单和弹出式窗口，使SDSF的使用非常简单。SDSF提供了完整的联机帮助和交互式的入门指导。[1]OS/390作业管理和文件目录系统（JES和CATALOG）[1]在大型服务器系统中，当用户需要使用计算机完成某项任务时，用户必须准备一个作业流。一个作业流中包含一个或多个作业。作业是用户在完成该任务时要求计算机所要完成的工作的集合。JES（JOBENTERSUBSYSTEM）是在OS/390里管理作业的子系统。JES能够从各种途径接受作业，并根据作业的语句和特点向操作系统申请资源完成作业的处理，最后处理作业的输出。JES主要是JES2和JES3,JES2是常用的系统，他是OS/390中不可缺少的子系统，JES2处理主要主要分为如下几个步骤：⑴接收作业⑵处理作业⑶申请资源[1]时钟周期：简介播报编辑时钟周期是同步电路中时钟基础频率的倒数。它以时间动作重复的最小周期来度量，度量单位采用时间单位。在单个时钟周期内（现代非嵌入式微处理器的这个时间一般都短于1纳秒），逻辑零状态与逻辑一状态来回切换。由于发热和电气规格的限制，周期里逻辑零状态的持续时间历来要长于逻辑一状态。应用播报编辑时钟周期是由CPU时钟定义的定长时间间隔，是CPU工作的最小时间单位，也称节拍脉冲或T周期。时钟周期表示了SDRAM所能运行的最高频率。更小的时钟周期就意味着更高的工作频率。对于PC100规格的内存来说，它的运行时钟周期应该不高于10纳秒。纳秒与工作频率之间的转换关系为：1/时钟周期=工作频率。例如，标称10纳秒的PC100内存芯片，其工作频率的表达式就应该是1/10=100MHZ，这说明此内存芯片的额定工作频率为100MHZ。市场上一些质量优秀的内存通常可以工作在比额定频率高的频率下，这为一些喜欢超频的朋友带来了极大的方便。例如KingMAX的PC100内存，此类内存多采用8纳秒的芯片，相对于其100MHZ的频率来说，频率提高的余地还很大，许多用户都可以让它们工作在133MHZ甚至更高的频率下。能不能超频使用很大程度上反应了内存芯片以及PCB板的质量。不过，仅仅凭借时钟周期来判断内存的速度还是不够的，内存CAS的存取时间和延迟时间也在一定程度上决定了内存的性能。[1]单片机时间单位播报编辑在MCS-51中时钟周期也称振荡周期，振荡周期也称为晶振周期，振荡周期是单片机的基本时间单位。8051把一个振荡周期定义为一个节拍（用P表示），两个节拍为一个状态周期。振荡器脉冲信号经过时钟电路二分频之后产生的单片机时钟信号的周期（用S表示）称为状态周期。故一个状态周期S包含2个节拍，前一时钟周期称为P1节拍，后一时钟周期称为P2节拍。若时钟晶振的振荡频率为fosc，则振荡周期Tosc=（1/fosc）。如：晶振频率为12MHZ，则振荡周期Tosc=（1/12us）。相互关系播报编辑1、时钟周期=振荡周期，名称不同而已，都是等于单片机晶振频率的倒数，如常见的外接12M晶振，那它的时钟周期=1/12M。2、机器周期，8051系列单片机的机器周期=12*时钟周期，之所以这样分是因为单个时钟周期根本干不了一件完整的事情（如取指令、写寄存器、读寄存器等），而12个时钟周期就能基本完成一项基本操作了。3、指令周期。一个机器周期能完成一项基本操作，但一条指令常常是需要多项基本操作结合才能完成，完成一条指令所需的时间就是指令周期，当然不同的指令，其指令周期就不一样的了。[2]易失性存储器：简介播报编辑它在任何时候都可以读写，RAM通常是作为操作系统或其他正在运行程序的临时存储介质（可称作系统内存）。不过，当电源关闭时RAM不能保留数据，如果需要保存数据，就必须把它们写入到一个长期的存储器中（例如硬盘）。正因为如此，有时也将RAM称作“可变存储器”。RAM内存可以进一步分为静态RAM（SRAM）和动态内存（DRAM）两大类。DRAM由于具有较低的单位容量价格，所以被大量的采用作为系统的主记忆。应用灵活性播报编辑不同应用在不同的容性负载下需要不同的工作频率，这项要求与芯片组的性能以及电路板布局和复杂性紧密相关。例如，高频工作环境通常对电性能的优化要求严格，设计工程师需要考虑整个电路板上的电噪声，以降低线路的寄生电容。在这种情况下，降低存储器输出驱动器的强度更加受欢迎。此外，还必须根据工作频率优化指令执行速度。有时候，要想在发送命令后取得适合的高效的吞吐量，就必须减少空时钟周期次数。最终使用播报编辑在应用电路板测试阶段，为了正确地激励存储器、查看存储器的响应，微控制器需要全套的命令和功能。这项操作灵活性测试通常用于检测全部系统组件，以确保产品在生命周期内的功能。相反，标准的客户最终应用只使用一个精简的指令集。例如，在使用SPI闪存时，最终应用通常使用读指令(正常、快速和/或4位I/O输入输出)，把启动代码下载到RAM存储器。设计人员应该优化非易失性存储器，以缩减系统上电期间的代码读取和下载时间。在新的先进的平台上，如车用电子、计算机光驱或蓝牙模块，SPI闪存可能用于直接从非易失性存储器读取部分系统固件，以缩短系统固件下载到高速易失性存储器的过程。当然，目前出现的最新应用对存储器的灵活性要求更加严格，本文稍后再做详解。自适应模式播报编辑SPI闪存的的优点是引脚数量少而且固定不变(8个或16个)。串口闪存的这个特性可简化电路板布局，无需更改硬件即可升级固件，从而可以降低系统开发的总体成本。由于在简易性和成本方面的强大优势，PC机和消费电子市场出现了并口闪存改用SPI闪存的发展趋势。只要达到性能要求时，设备厂商就会优先选用串口闪存。计算机光驱、汽车电子、蓝牙模块、机顶盒和调制解调器市场正在引入这种能够把代码直接读到非易失性存储器内的SPI闪存。XiP(片内执行)应用要求串口存储器提供一种“随机访存”仿真功能，即无需发送指令即可访问存储器内容，并准许以最大的吞吐量访问存储器。因为传统用途是存储和下载代码，所以SPI存储器是同步器件，XIP功能迫使设计人员研发灵活的存储器，能够根据芯片组特性灵活地配置串行闪存。例如，在系统上电后，具有XIP功能的器件需要基于命令、地址和数据的JEDEC协议，所以有些逻辑器件不准像管理XIP器件一样管理串口闪存。此外，有些逻辑器件只在一条线上或者最多在两条线上支持XIP模式，因为固有的硬件限制，不可能开启4位I/O输入输出模式。最后，因为实现一个混合协议、接受命令的传统存储器和不接受命令的非易失性存储器的设计困难，芯片组厂商更愿意保留原有的SPI指令结构，即命令、地址和数据。在这些情况下，高速协议结合并行化命令、地址和数据的方案更受市场欢迎。存储器带宽：名词释义播报编辑存储器带宽，体现数据传输速率技术指标（单位：bps,bitpersecond,位/秒，或Bytes/s,字节/秒）存储器的带宽决定了以存储器为中心的机器获取信息的传输速度，它是改善机器瓶颈的一个关键因素。提高措施播报编辑为了提高存储器的带宽，可以采取以下措施：1、缩短存取周期；2、增加存储字长，使每个存取周期可读/写更多的二进制位数；3、增加存储体。计算方法播报编辑带宽我们一般用表示，若存储周期为，每次读/写个字节，则其带宽。如存取周期为500ns，每个存取周期可访问16位，则它的带宽为32M位/s内存泄漏：简介播报编辑内存泄漏（MemoryLeak）是指程序中已动态分配的堆内存由于某种原因程序未释放或无法释放，造成系统内存的浪费，导致程序运行速度减慢甚至系统崩溃等严重后果。内存泄漏缺陷具有隐蔽性、积累性的特征，比其他内存非法访问错误更难检测。因为内存泄漏的产生原因是内存块未被释放，属于遗漏型缺陷而不是过错型缺陷。此外，内存泄漏通常不会直接产生可观察的错误症状，而是逐渐积累，降低系统整体性能，极端的情况下可能使系统崩溃。随着计算机应用需求的日益增加，应用程序的设计与开发也相应的日趋复杂，开发人员在程序实现的过程中处理的变量也大量增加，如何有效进行内存分配和释放，防止内存泄漏的问题变得越来越突出。例如服务器应用软件，需要长时间的运行，不断的处理由客户端发来的请求，如果没有有效的内存管理，每处理一次请求信息就有一定的内存泄漏。这样不仅影响到服务器的性能，还可能造成整个系统的崩溃。因此，内存管理成为软件设计开发人员在设计中考虑的主要方面[1]。泄漏原因播报编辑在C语言中，从变量存在的时间生命周期角度上，把变量分为静态存储变量和动态存储变量两类。静态存储变量是指在程序运行期间分配了固定存储空间的变量，而动态存储变量是指在程序运行期间根据实际需要进行动态地分配存储空间的变量。在内存中供用户使用的内存空间分为三部分：程序存储区静态存储区动态存储区程序中所用的数据分别存放在静态存储区和动态存储区中。静态存储区数据在程序的开始就分配好内存区，在整个程序执行过程中它们所占的存储单元是固定的，在程序结束时就释放，因此静态存储区数据一般为全局变量。动态存储区数据则是在程序执行过程中根据需要动态分配和动态释放的存储单元，动态存储区数据有三类函数形参变量、局部变量和函数调用时的现场保护与返回地址。由于动态存储变量可以根据函数调用的需要，动态地分配和释放存储空间，大大提高了内存的使用效率，使得动态存储变量在程序中被广泛使用。开发人员进行程序开发的过程使用动态存储变量时，不可避免地面对内存管理的问题。程序中动态分配的存储空间，在程序执行完毕后需要进行释放。没有释放动态分配的存储空间而造成内存泄漏，是使用动态存储变量的主要问题。一般情况下，开发人员使用系统提供的内存管理基本函数，如malloc、realloc、calloc、free等，完成动态存储变量存储空间的分配和释放。但是，当开发程序中使用动态存储变量较多和频繁使用函数调用时，就会经常发生内存管理错误，例如：分配一个内存块并使用其中未经初始化的内容；释放一个内存块，但继续引用其中的内容；子函数中分配的内存空间在主函数出现异常中断时、或主函数对子函数返回的信息使用结束时，没有对分配的内存进行释放；程序实现过程中分配的临时内存在程序结束时，没有释放临时内存。内存错误一般是不可再现的，开发人员不易在程序调试和测试阶段发现，即使花费了很多精力和时间，也无法彻底消除。产生方式的分类以产生的方式来分类，内存泄漏可以分为四类：1.常发性内存泄漏：发生内存泄漏的代码会被多次执行到，每次被执行时都会导致一块内存泄漏。2.偶发性内存泄漏：发生内存泄漏的代码只有在某些特定环境或操作过程下才会发生。常发性和偶发性是相对的。对于特定的环境，偶发性的也许就变成了常发性的。所以测试环境和测试方法对检测内存泄漏至关重要。3.一次性内存泄漏：发生内存泄漏的代码只会被执行一次，或者由于算法上的缺陷，导致总会有一块且仅有一块内存发生泄漏。4.隐式内存泄漏：程序在运行过程中不停的分配内存，但是直到结束的时候才释放内存。严格的说这里并没有发生内存泄漏，因为最终程序释放了所有申请的内存。但是对于一个服务器程序，需要运行几天，几周甚至几个月，不及时释放内存也可能导致最终耗尽系统的所有内存。所以，我们称这类内存泄漏为隐式内存泄漏。从用户使用程序的角度来看，内存泄漏本身不会产生什么危害，作为一般的用户，根本感觉不到内存泄漏的存在。真正有危害的是内存泄漏的堆积，这会最终耗尽系统所有的内存。从这个角度来说，一次性内存泄漏并没有什么危害，因为它不会堆积，而隐式内存泄漏危害性则非常大，因为较之于常发性和偶发性内存泄漏它更难被检测到。检测方法播报编辑无论是C还是C++程序，运行时候的变量主要有三种分配方式：堆分配、栈分配、全局和静态内存分配。内存泄漏主要是发生在堆内存分配方式中，即“配置了内存后，所有指向该内存的指针都遗失了”，若缺乏语言这样的垃圾回收机制，这样的内存片就无法归还系统。因为内存泄漏属于程序运行中的问题，无法通过编译识别，所以只能在程序运行过程中来判别和诊断。下面将介绍几种常用的内存检测方法，每种方法均以现有的内存检测工具为分析范例，并对各种方法进行比较。静态分析技术静态分析技术就是直接分析程序的源代码或机器代码，获得一些有用的信息，而并不运行程序本身。目前有许多静态分析的工具，编译器就属于这一类，它读入源程序代码，对源程序进行词法和语法分析，进行数据类型的检查以及一些优化的分析等，以此来提高程序的质量与运行效率。这类静态的分析工具仅仅是读入程序代码进行相关的分析，而并不进行其它额外的操作，如修改源程序代码等。LCLink是一种通过对源代码及添加到源代码中特定格式的注释说明进行静态分析的程序理解和检错工具，的检查对象是源程序，能检查出的内存错误有内存分配释放故障、空指针的错误使用、使用未定义或已被释放的内存等程序错误。LCLink重点分析两类内存释放错误：试图释放某内存块，该内存块有两个或两个以上的有效指针指向它。试图释放某内存块，该内存块没有任何有效指针指向它。解决此类内存错误的方法是规定分配某块内存时返回的指针必须释放该内存。使用注释表示某指针是唯一指向某内存块的指针，使用注释表示被调用函数可能释放函数参数指向的内存块或创建新的指针指向该内存块。源代码插装技术图1为了获得被测程序的动态执行信息，需要对其进行跟踪，一般使用插装方法。所谓插装就是在保持被测程序的逻辑完整性的基础上，在被测程序的特定部位插入一段检测程序又称探针函数，通过探针的执行抛出程序的运行特征数据。基于这些特征数据分析，可以获得程序的控制流及数据流信息，进而获得逻辑覆盖等动态信息，这样就可以在被测程序执行的过程中动态地同步执行程序的检测工作。插装方法又分为源代码级程序插装和目标代码级程序插装。源代码插装测试必须在静态测试部分获得的被测程序的结构信息、静态数据信息、控制流信息等基础上，应用插装技术向被测程序中的适当位置植入相应类型的探针，通过运行带有探针的被测程序而获得程序运行的动态数据。源代码插装要通过运行被测程序来测定程序的各种指标，如覆盖率、时间性能、内存使用等等，实现源代码插装的关键技术是借助于插入到源程序中的监控语句来收集执行信息，以达到揭示程序内部行为和特性的目的，如图1所示。基于源代码插装的动态测试框架分为个主要的阶段：插装交互与动态测试信息分析；插装阶段；插装库制作阶段；测试实施阶段。插装交互与动态测试信息分析是软件测试工具与用户交互的界面。用户通过该界面选择要进行动态测试的程序模块，拓扑产生相应的插装选择记录文件。用户还可以通过该交互界而浏览动态测试结果信息，在软件测试工具的实现上，采用可视化的方式显示这些动态信息。插装阶段实现了在被测程序中植入探针，并生成带有插装信息的源文件。在此过程中，首先将被测程序经过预处理展开为不包含宏、条件编译和头文件的文件格式。然后，按照一定的插装策略，根据前面生成的插装选择记录文件，将探针函数加载到该文件中，最后生成插装后的程序。插装库制作阶段的目的是生成插装库中的探针函数，它含有插装语句调用的函数及其函数的定义。显然，插装过程中生成的目标文件中含有探针函数的桩，而探针函数的实现恰恰在本过程完成。需要指出的是，插装库的制作过程是独立于动态测试过程之外的，可以与软件测试工具开发同步。测试实施阶段将插装过程生成的文件与插装库制作过程生成的插装静态库连接生成带有插装信息的可执行文件，选取测试用例，运行该程序，可以获得被测程序的动态跟踪信息。在以上四个阶段中，其中的插装交互与动态测试信息分析与测试实施阶段是测试人员的可视部分，通过这两部分，用户与系统交互，完成测试工作。而插装阶段与插装库制作阶段对测试人员是不可见的，在后台完成，对于用户而言，这两部分是完全透明的。在性能方面，采用插装方法应尽量减少插装开销。为了达到不同的统计目的如语句覆盖、分支覆盖等，应尽量减少插装次数。若能仅仅插装一次就能完成多种类型的统计，则可使插装代码得到优化。此外，应尽量减少插装代码的数量，减少插装代码的运行次数，从而达到减小插装代码运行开销的目的。特别是对于一些实时系统的测试，在这方面的要求尤为苛刻。一个运行时错误检测工具，能够自动检测一应用中大量的编程和运行时错误。通过使用源码插装和运行时指针跟踪的专利技术，在编译时，附十插入测试和分析代码，它建立一个有关程序中各种对象的数据库。然后在运行时通过检查数据值和内存引用验证对象的一致性和正确性。使用这些技术，包括变异测试技术等，一能够检查和测试用户的代码，精确定位错误的准确位置并给出详细的诊断信息。能够可视化实时内存操作，优化内存算法。还能执行覆盖性分析，清楚地指示那些代码已经测试过。将集成到开发环境中，能够极大地减少调试时间并有效地防止错误。检验每一次内存操作的有效性，包括静态全局和堆栈以及动态分配内存的操作。叶有两种运行模式。监护模式下用户可以快速检测代码中的错误，不需要对代码作任何插装和处理源码插装模式则进行彻底地代码检测。目标代码插装技术图2目标代码插装实现主要分为预处理、测试执行和结果汇总个阶段，工作流程如图2所示，系统主要工作是围绕断点而进行的。在预处理阶段，首先静态分析被测程序的目标代码，查找待测程序中源代码各语句、函数入口点在目标代码中的对`应位置，然后在相应位置插入断点在测试执行阶段，启动调试进程，当被测程序执行到断点处时，响应断点信息，在相应的断点处完成相应的统计操作在结果汇总阶段，根据各断点处的统计结果，按不同的统计角度进行归并、综合得到最终的统计数据。被测代码预处理图3在测试预处理阶段对被测程序的目标代码进行分析，可以获得目标代码与源代码中语句、函数的对应关系。在目标代码中为相对应的源代码的每条语句及每个函数的入口点插入断点。对于第三方代码，只要其目标代码格式与下生成的目标代码格式一致，我们就可以用与分析用户代码同样的方法获取信息。获取断点的信息后，为所有的断点建立断点链表，同时建立语句及函数的信息链表，供随后的测试执行阶段存储信息。预处理流程如图3所示。测试执行阶段图4利用OCI技术，我们把测试执行看作是一个在被测进程和检测进程间不断切换的过程。每当被测进程遇到断点，就会将自身挂起，同时发送消息唤醒检测进程，检测进程根据当前断点的地址在断点链表中查找相应节点，并查找对应的语句或函数信息，记录该语句或函数的执行次数、到达或离开的时刻，供以后统计之用。然后，将插入的断点信息去除，恢复原来的指令，转入被测进程继续执行。在转入被测进程之前，必须将上一个断点处的断点恢复上一个断点处的断点在指令运行时被去除了。具体流程如图4所示。数据统计与结果汇总图5根据各断点处的统计结果，按不同的统计角度进行归并、综合，进行覆盖率及各种时间的计算，得到最终的统计数据。是公司出品的一种软件测试和质量保证工具，它能检测程序内存泄漏和内存访问冲突等错误。使用目标码插装技术，在编译器生成的目标码中直接插入特殊的检查指令实现对内存错误的检测。在程序的所有代码中插入这些检查逻辑，包括第三方目标码库，并且验证系统调用的接口。目标码插装技术分为链接前插装和链接后插装两种插装方法。使用如图5所示的链接前插装法。检查插装后程序的每个内存读写动作，跟踪内存使用情况，使用类似垃圾收集器的技术来检查内存泄漏。垃圾收集机制分为两阶段垃圾检测和垃圾回收。为了不影响程序的执行速度，提供了一个可调用的垃圾检测器，使用类似于保守式垃圾收集算法，即标记一清除算法。在标记阶段，递归地从数据段、堆栈段到数据堆跟踪分析指针，并使用标准保守式方法为所有被引用的内存块做标记。在清除阶段，逐步访问数据堆，并报告已分配但程序不再引用的内存块，即程序的内存泄漏。检测工具播报编辑部分工具1.ccmalloc－Linux和Solaris下对C和C++程序的简单的使用内存泄漏和malloc调试库。2.Dmalloc－DebugMallocLibrary.3.ElectricFence－Linux分发版中由BrucePerens编写的malloc()调试库。4.Leaky－Linux下检测内存泄漏的程序。5.LeakTracer－Linux、Solaris和HP-UX下跟踪和分析C++程序中的内存泄漏。6.MEMWATCH－由JohanLindh编写，是一个开放源代码C语言内存错误检测工具，主要是通过gcc的precessor来进行。7.Valgrind－DebuggingandprofilingLinuxprograms,aimingatprogramswritteninCandC++.8.KCachegrind－AvisualizationtoolfortheprofilingdatageneratedbyCachegrindandCalltree.9.IBMRationalPurifyPlus－帮助开发人员查明C/C++、托管.NET、Java和VB6代码中的性能和可靠性错误。PurifyPlus将内存错误和泄漏检测、应用程序性能描述、代码覆盖分析等功能组合在一个单一、完整的工具包中。10.ParasoftInsure++－针对C/C++应用的运行时错误自动检测工具，它能够自动监测C/C++程序，发现其中存在着的内存破坏、内存泄漏、指针错误和I/O等错误。并通过使用一系列独特的技术（SCI技术和变异测试等），彻底的检查和测试我们的代码，精确定位错误的准确位置并给出详细的诊断信息。能作为MicrosoftVisualC++的一个插件运行。11.CompuwareDevPartnerforVisualC++BoundsCheckerSuite－为C++开发者设计的运行错误检测和调试工具软件。作为MicrosoftVisualStudio和C++6.0的一个插件运行。12.ElectricSoftwareGlowCode－包括内存泄漏检查，codeprofiler，函数调用跟踪等功能。给C++和.Net开发者提供完整的错误诊断，和运行时性能分析工具包。13.CompuwareDevPartnerJavaEdition－包含Java内存检测,代码覆盖率测试,代码性能测试,线程死锁,分布式应用等几大功能模块。14.QuestJProbe－分析Java的内存泄漏。15.ej-technologiesJProfiler－一个全功能的Java剖析工具，专用于分析J2SE和J2EE应用程序。它把CPU、执行绪和内存的剖析组合在一个强大的应用中。16.BEAJRockit－用来诊断Java内存泄漏并指出根本原因，专门针对Intel平台并得到优化，能在Intel硬件上获得最高的性能。存储器管理：操作系统的职能之一，主要任务是为多道程序的运行提供良好的环境，方便用户使用存储器，提高存储器的利用率以及能从逻辑上扩充内存。主要功能：1、内存分配2、内存保护3、地址映射4、内存扩充缓存一致性：简介播报编辑内存系统的本质是，一个内存系统应该能提供一组保存值的存储单元，当对一个存储单元执行读操作时，应该能返回“最近”一个对该存储单元的写操作所写入的值。在串行程序中，程序员利用内存来将程序中某一点计算出来的值，传递到该值的使用点，实际上就是利用了以上的基本性质。同样，运行在单处理器上的多个进程或线程利用共享地址空间进行通信，实际上也是利用了内存系统的这个性质。一个读操作应返回最近的向那个位置的写操作所写的值，而不管是哪个线程写的。当所有的线程运行在同一个物理处理器上时，它们通过相同的高速缓存层次来看内存，因此在这种情况下，高速缓存不会引起问题。当在共享存储的多处理器系统上运行一个具有多个进程的程序时，希望不管这些进程是运行在同一个处理器上，还是在不同的处理器上，程序的运行结果都是相同的。然而，当两个运行在不同的物理处理器上的进程通过不同的高速缓存层次来看共享内存时，其中一个进程可能会看到在它的高速缓存中的新值，而另一个则可能会看到旧值，这样就引起了一致性问题[1]。高速缓冲存储器一致性的比较正式的一个定义是当一个共享存储的机器满足以下条件时，则可以认为该系统是高速缓冲存储器一致的：1.任何进程所发出的访存操作被存储器所观察到的顺序必须与进程发出操作的顺序相同；2.每个读操作所返回的值必须是最后一次对该存储位置的写操作的值。以上定义保证了两个属性写广播和写串行化。写广播指的是写操作被其他所有处理器所观察到。定串行化是指对某一存储位置的所有写操作的顺序，在所有处理器看来都是一样的。高速缓冲存储器一致性可以分为三个层级：1.在进行每个写入运算时都立刻采取措施保证数据一致性；2.每个独立的运算，假如它造成数据值的改变，所有进程都可以看到一致的改变结果；3.在每次运算之后，不同的进程可能会看到不同的值（这也就是没有一致性的行为）。一致性播报编辑关于一致性的概念，直观上可以定义为每个读操作必须返回最后写入此位置的值。对于每个处理器单元的操作都有一个总体的、串行的操作序是我们希望在任何一个一致性存储系统中见到的。因此，可以对高速缓存一致性进行一个更加形式化的定义方法：如果某个程序的任何执行结果都满足下列条件：对于任何单元，有可能建立一个假想的操作序列（也就是说，将所有进程发出的读写操作排成一个全序，此序列与执行结果一致，并且在序列中）：任何特定进程发出的操作所表现出来的序和该进程向存储系统发出它们的序相同，且每个读操作返回的值是对相应单元按照串行顺序写入的最后一值，那么此多处理器存储系统是一致性。此外，关于多个私有缓存还存在另外一方面的问题：如果数据是由一个处理器核对某个单元写入，而另一个处理器从中读出这样的方式来进行传递的话，那么我们前面所关注的一致性将是非常重要的。最终，写在一个单元中的数据将对所有的读取者都会是可见的，但这种一致性并没有指明所写入的数据何时会成为可见的。通常，在编写一个并行程序时，我们希望在写和读之间建立一种序，即我们需要定义一个序模型，依照该模型，程序员能推断他们程序的执行结果及其正确性。这个模型就是存储同一性。一个完整的一致性模型包括高速缓存一致性及存储同一性两个方面，且这两个是互补的：高速缓存一致性定义了对同一个存储地址进行的读写操作行为，而存储同一性模型定义了访问所有存储地址的读写行为。在共享存储空间中，多个进程对存储的不同单元做并发的读写操作，每个进程都会看到一个这些操作被完成的序。一个存储同一性模型规定了对这种序的若干约束，值得一提的是，这里所涉及到的并发存储操作既包括对相同单元的，也包括对不同单元的；即可以来自同一进行，也可以来自不同的进程。在这个意义上，存储同一性包含了高速缓存一致性。实现播报编辑高速缓存一致性协议是解决缓存一致性问题的主要方案，同时也是保证存储同一性的重要手段。它定义了共享缓存块在各个私有缓存中的存在形式，并详细定义了各个私有缓存之间的通信行为。学术界及工业界已经提出了多种高速缓存一致性协议模型，但所有模型的出发点都是一样的，它们都是为了保证存储模型SWMR（single-writer，multiple-reader）属性，即对于一个给定的缓存块，在系统运行的任意时刻，保证（1）同时只能有一个处理器核拥有对此缓存的写权限；或者（2）同时可以有零个或者多个处理器核拥有对此缓存块的读权限。根据共享数据的修改方式的不同，可以将高速缓存一致性协议的实现分为两种形式：写无效协议、写更新协议。其中，在写无效协议中，处理器核在对某个存储块进行写操作之前，必须保证当前的处理器核拥有对此缓存块的读写权。如果两个或者多个处理器核试图同时访问同一个数据项并执行写操作，那么它们中同时只能有一个在进行，另一个访问请求会被阻塞；在某个处理器执行写操作时，其它所有私有缓存中该数据的副本都会被置为无效状态。在当前处理器完成写操作后，后续的对此数据的所有操作，都必须首先获得此新写入数据的副本。因此，写无效型的协议强制执行了写操作的串行化。写更新协议也称为写广播协议，它是指处理器核在对某个数据进行写操作时，同时更新当前数据在其它所有缓存中的数据副本。有两种主要的缓存一致性协议：基于侦听形式的高速缓存一致性协议（或侦听协议）及基于目录结构的高速缓存一致性协议（或目录协议）。在这两种协议中，侦听协议的实现依赖于一个总线或者类总线形式的网络连接，使用此网络，单个处理器核的私有缓存所发出的所有请求会被广播到系统中所有的其它处理器核的私有缓存中，而所有处理器的访问请求也可以在此总线上进行定序操作，以实现缓存一致性模型及存储同一性模型中对访存序的要求。此外，此协议还可以通过总线结构来很好的处理对同一数据块的多个冲突请求，而且多个处理器的私有缓存之间可以通过此总线结构进行直接的通信，减少了通信延迟。但是，由于所有请求都是通过总线来进行传输的，但总线带宽资源有限，因此它会影响整个系统的扩展性。目录协议则是采用一个目录结构来实现对缓存块的管理的。在目录协议中，处理器核的私有缓存发出的访存请求，会首先发送到拥有相应缓存块的目录结构中，此目录结构中记录了当前缓存块的共享情况，目录结构控制器会根据当前缓存块的状态，选取响应此请求或者转发此请求到其它相应的私有缓存中。此种方法不需要依赖于特定拓扑结构的网络，并通过点对点的直接通信形式降低了网络中的带宽消耗，因此这种协议易于扩展。但由于此协议的实现中，所有请求都必须通过目录结构进行处理，因此会引入额外的延迟[2]。MESI协议播报编辑单核Cache中每个Cacheline有2个标志：dirty和valid标志，它们很好的描述了Cache和Memory（内存）之间的数据关系（数据是否有效，数据是否被修改），而在多核处理器中，多个核会共享一些数据，MESI协议就包含了描述共享的状态。在MESI协议中，每个Cacheline有4个状态，可用2个bit表示，它们分别是：M（Modified）：这行数据有效，数据被修改了，和内存中的数据不一致，数据只存在于本Cache中。E（Exclusive）：这行数据有效，数据和内存中的数据一致，数据只存在于本Cache中。S（Shared）：这行数据有效，数据和内存中的数据一致，数据存在于很多Cache中。I（Invalid）：这行数据无效。在该协议的作用下，虽然各cache控制器随时都在监听系统总线，但能监听到的只有读未命中、写未命中以及共享行写命中三种情况。读监听命中的有效行都要进入S态并发出监听命中指示，但M态行要抢先写回主存；写监听命中的有效行都要进入I态，但收到RWITM时的M态行要抢先写回主存。总之监控逻辑并不复杂，增添的系统总线传输开销也不大，但MESI协议却有力地保证了主存块脏拷贝在多cache中的一致性，并能及时写回，保证cache主存存取的正确性[3]。内存屏障：简介播报编辑大多数现代计算机为了提高性能而采取乱序执行，这使得内存屏障成为必须。语义上，内存屏障之前的所有写操作都要写入内存；内存屏障之后的读操作都可以获得同步屏障之前的写操作的结果。因此，对于敏感的程序块，写操作之后、读操作之前可以插入内存屏障。底层体系结构相关的原语播报编辑大多数处理器提供了内存屏障指令:完全内存屏障（fullmemorybarrier）保障了早于屏障的内存读写操作的结果提交到内存之后，再执行晚于屏障的读写操作。内存读屏障（readmemorybarrier）仅确保了内存读操作；内存写屏障(writememorybarrier)仅保证了内存写操作。内存屏障是底层原语，是内存排序的一部分，在不同体系结构下变化很大而不适合推广。需要认真研读硬件的手册以确定内存屏障的办法。x86指令集中的内存屏障指令是：lfence(asm),void_mm_lfence(void)读操作屏障sfence(asm),void_mm_sfence(void)[1]写操作屏障mfence(asm),void_mm_mfence(void)[2]读写操作屏障常见的x86/x64，通常使用lock指令前缀加上一个空操作来实现，注意当然不能真的是nop指令，但是可以用来实现空操作的指令其实是很多的，比如Linux中采用的addl$0,0(%esp)存储器也提供了另一套语义的内存屏障指令:acquiresemantics:该操作结果可利用要早于代码中后续的所有操作的结果。releasesemantics:该操作结果可利用要晚于代码中之前的所有操作的结果。fencesemantics:acquire与release两种语义的共同有效。即该操作结果可利用要晚于代码中之前的所有操作的结果，且该操作结果可利用要早于代码中后续的所有操作的结果。IntelItanium处理器，具有内存屏障mf的指令，具有下述modifiers[1]:acq(acquire)rel(release).WindowsAPI的内存屏障实现播报编辑下述同步函数使用适当的屏障来确保内存有序：进出临界区(criticalsection)的函数触发(signaled)同步对象的函数等待函数(Waitfunction)互锁函数(Interlockedfunction)[1]多线程编程与内存可见性播报编辑多线程程序通常使用高层程序设计语言中的同步原语，如Java与.NETFramework，或者API如pthread或WindowsAPI。因此一般不需要明确使用内存屏障。内存可见性问题，主要是高速缓存与内存的一致性问题。一个处理器上的线程修改了某数据，而在另一处理器上的线程可能仍然使用着该数据在专用cache中的老值，这就是可见性出了问题。解决办法是令该数据为volatile属性，或者读该数据之前执行内存屏障。[2]乱序执行与编译器重排序优化的比较播报编辑C与C++语言中，volatile关键字意图允许内存映射的I/O操作。这要求编译器对此的数据读写按照程序中的先后顺序执行，不能对volatile内存的读写重排序。因此关键字volatile并不保证是一个内存屏障。对于VisualStudio2003，编译器保证对volatile的操作是有序的，但是不能保证处理器的乱序执行。因此，可以使用InterlockedCompareExchange或InterlockedExchange函数。对于VisualStudio2005及以后版本，编译器对volatile变量的读操作使用acquiresemantics，对写操作使用releasesemantics。[1]编译器内存屏障播报编辑编译器会对生成的可执行代码做一定优化，造成乱序执行甚至省略（不执行）。gcc编译器在遇到内嵌汇编语句：asmvolatile("":::"memory");将以此作为一条内存屏障，重排序内存操作。即此语句之前的各种编译优化将不会持续到此语句之后。也可用内建的__sync_synchronizeMicrosoftVisualC++的编译器内存屏障为：_ReadWriteBarrier()MemoryBarrier()IntelC++编译器的内存屏障为[1]：__memory_barrier()程序计数器：简介播报编辑程序计数器是计算机处理器中的寄存器，它包含当前正在执行的指令的地址（位置）。当每个指令被获取，程序计数器的存储地址加一。在每个指令被获取之后，程序计数器指向顺序中的下一个指令。当计算机重启或复位时，程序计数器通常恢复到[1]零。冯·诺伊曼计算机体系结构的主要内容之一就是“程序预存储，计算机自动执行”！处理器要执行的程序（指令序列）都是以二进制代码序列方式预存储在计算机的存储器中，处理器将这些代码逐条地取到处理器中再译码、执行，以完成整个程序的执行。为了保证程序能够连续地执行下去，CPU必须具有某些手段来确定下一条取指指令的地址。程序计数器（PC）正是起到这种作用，所以通常又称之为‘指令计数器’。在程序开始执行前，将程序指令序列的起始地址，即程序的第一条指令所在的内存单元地址送入PC，CPU按照PC的指示从内存读取第一条指令（取指）。当执行指令时，CPU自动地修改PC的内容，即每执行一条指令PC增加一个量，这个量等于指令所含的字节数（指令字节数），使PC总是指向下一条将要取指的指令地址。由于大多数指令都是按顺序来执行的，所以修改PC的过程通常只是简单的对PC加“指令字节数”。当程序转移时，转移指令执行的最终结果就是要改变PC的值，此PC值就是转去的目标地址。处理器总是按照PC指向取指、译码、执行，以此实现了程序转移。ARM处理器中使用R15作为PC，它总是指向取指单元，并且ARM处理器中只有一个PC寄存器，被各模式共用。R15有32位宽度（下述标记为R15[31:0]，表示R15的‘第31位’到‘第0位'），ARM处理器可以直接寻址4GB的地址空间（2^32=4G）。[2]特点播报编辑为了保证程序（在操作系统中理解为进程）能够连续地执行下去，处理器必须具有某些手段来确定下一条指令的地址。而程序计数器正是起到这种作用，所以通常又称为指令计数器。在程序开始执行前，必须将它的起始地址，即程序的第一条指令所在的内存单元地址送入程序计数器，因此程序计数器的内容即是从内存提取的一条指令的地址。当执行指令时，处理器将自动修改PC的内容，即每执行一条指令PC增加一个量，这个量等于指令所含的字节数，以便使其保持的总是将要执行的下一条指令的地址。由于大多数指令都是按顺序来执行的，所以修改的过程通常只是简单的对PC加1。[3]但是，当遇到转移指令如JMP（跳转、外语全称：JUMP）指令时，后继指令的地址（即PC的内容）必须从指令寄存器中的地址字段取得。在这种情况下，下一条从内存取出的指令将由转移指令来规定，而不像通常一样按顺序来取得。因此程序计数器的结构应当是具有寄存信息和计数两种功能的结构。[3]机器指令：机器指令是CPU能直接识别并执行的指令，它的表现形式是二进制编码。机器指令通常由操作码和操作数两部分组成，操作码指出该指令所要完成的操作，即指令的功能，操作数指出参与运算的对象，以及运算结果所存放的位置等。[1]由于机器指令与CPU紧密相关，所以，不同种类的CPU所对应的机器指令也就不同，而且它们的指令系统往往相差很大。但对同一系列的CPU来说，为了满足各型号之间具有良好的兼容性，要做到：新一代CPU的指令系统必须包括先前同系列CPU的指令系统。只有这样，先前开发出来的各类程序在新一代CPU上才能正常运行。机器语言是用来直接描述机器指令、使用机器指令的规则等。它是CPU能直接识别的唯一一种语言，也就是说，CPU能直接执行用机器语言描述的程序。用机器语言编写程序是早期经过严格训练的专业技术人员的工作，普通的程序员一般难以胜任，而且用机器语言编写的程序不易读、出错率高、难以维护，也不能直观地反映用计算机解决问题的基本思路。由于用机器语言编写程序有以上诸多的不便，几乎没有程序员这样编写程序了。主存：产品介绍播报编辑内存在计算机的组成结构中有一个很重要的部分是存储器。它是用来存储程序和数据的部件。对于计算机来说，有了存储器，才有记忆功能，才能保证正常工作。存储器的种类很多。按其用途可分为主存储器和辅助存储器，主存储器又称内存储器（简称内存，港台称之为记忆体）。[2]内存又称主存。它是CPU能直接寻址的存储空间，由半导体器件制成。特点是存取速率快。内存是电脑中的主要部件，它是相对于外存而言的。我们平常使用的程序，如：Windows操作系统、打字软件、游戏软件等。一般安装在硬盘等外存上，但仅此是不能使用其功能，必须把它们调入内存中运行，才能真正使用其功能。我们平时输入一段文字或玩一个游戏，其实是在内存中进行。好比在一个书房，存放书籍的书架和书柜相当于电脑的外存，我们工作的办公桌相当于内存。通常，我们把要永久保存、大量数据存储在外存上，把一些临时或少量的数据和程序放在内存上。当然，内存的好坏会直接影响电脑的运行速度。[2]内存是暂时存储程序以及数据的地方。当我们使用WPS处理文稿时，当你在键盘上敲入字符时，它被存入内存中。当你选择存盘时，内存中的数据才会被存入硬（磁）盘。[2]发展播报编辑计算机诞生初期并不存在内存条的概念。最早的内存是以磁芯的形式排列在线路上，每个磁芯与晶体管组成的一个双稳态电路作为一比特（BIT）的存储器。每一比特都要有玉米粒大小，可以想象一间机房只能装下不超过百k字节左右的容量。后来才出现了焊接在主板上的集成内存芯片，以内存芯片的形式为计算机的运算提供直接支持。那时的内存芯片容量都特别小，最常见的莫过于256K×1bit、1M×4bit。虽然如此，但对于那时的运算任务来说却绰绰有余了。[3]内存条内存芯片的状态一直沿用到286初期。鉴于它存在着无法拆卸更换的弊病，这对计算机的发展造成了现实的阻碍。有鉴于此，内存条便应运而生了。将内存芯片焊接到事先设计好的印刷线路板上，电脑主板上也改用内存插槽。这样，把内存难以安装和更换的问题彻底解决了。[3]在80286主板发布之前，内存没有被世人重视。这个时候的内存直接固化在主板上，容量只有64～256KB。对于当时PC所运行的工作程序来说，这种内存的性能以及容量足以满足当时软件程序的处理需要。随着软件程序和新一代80286硬件平台的出现，程序和硬件对内存性能提出了更高要求。为了提高速度并扩大容量，内存必须以独立的封装形式出现，因而诞生了“内存条”的概念。[3]80286主板刚推出时，内存条采用了SIMM（SingleIn-lineMemoryModules，单边接触内存模组）接口，容量为30pin、256kb，必须是由8片数据位和1片校验位组成1个bank。正因如此，我们见到的30pinSIMM一般是四条一起使用。自1982年PC进入民用市场一直到现在，搭配80286处理器的30pinSIMM内存是内存领域的开山鼻祖。[3]随后，在1988～1990年当中，PC技术迎来另一个发展高峰，也就是386和486时代。此时，CPU已经向16bit发展，所以30pinSIMM内存再也无法满足需求，其较低的内存带宽已经成为急待解决的瓶颈，所以此时72pinSIMM内存出现了。72pinSIMM支持32bit快速页模式内存，内存带宽得以大幅度提升。72pinSIMM内存单条容量一般为512KB～2MB，而且仅要求两条同时使用。由于其与30pinSIMM内存无法兼容，因此这个时候PC业界毅然将30pinSIMM内存淘汰出局了。[3]EDODRAM（ExtendedDateOutRAM外扩充数据模式存储器）内存，这是1991年到1995年之间盛行的内存条。EDODRAM同FPMDRAM（FastPageModeRAM快速页面模式存储器）极其相似，它取消了扩展数据输出内存与传输内存两个存储周期之间的时间间隔，在把数据发送给CPU的同时去访问下一个页面。故而速度要比普通DRAM快15~30%。工作电压为一般为5V，带宽32bit，速度在40ns以上，其主要应用在当时的486及早期的Pentium电脑上。[3]1991年至1995年期间，内存技术发展比较缓慢，几乎停滞不前。我们看到此时EDODRAM有72pin和168pin并存的情况，事实上EDO内存也属于72pinSIMM内存的范畴。不过它采用了全新的寻址方式。EDO在成本和容量上有所突破，凭借着制作工艺的飞速发展。此时单条EDO内存的容量已经达到4～16MB。由于Pentium及更高级别的CPU数据总线宽度都是64bit甚至更高，所以EDODRAM与FPMDRAM都必须成对使用。[3]SDRAM自IntelCeleron系列以及AMDK6处理器以及相关的主板芯片组推出后，EDODRAM内存性能再也无法满足需要了。内存技术必须彻底得到革新才能满足新一代CPU架构的需求，此时内存开始进入比较经典的SDRAM时代。[3]第一代SDRAM内存为PC66规范，但很快由于Intel和AMD的频率之争将CPU外频提升到了100MHz。所以PC66内存很快就被PC100内存取代，接着，133MHz外频的PIII以及K7时代的来临，PC133规范也以相同的方式进一步提升SDRAM的整体性能，带宽提高到1GB/sec以上。由于SDRAM的带宽为64bit，正好对应CPU的64bit数据总线宽度，因此，它只需要一条内存便可工作，便捷性进一步提高。在性能方面，由于其输入输出信号保持与系统外频同步，速度明显超越EDO内存。[3]SDRAM内存由早期的66MHz，发展至后来的100MHz、133MHz。尽管没能彻底解决内存带宽的瓶颈问题，但此时的CPU超频已成为DIY用户永恒的话题。不少用户将品牌好的PC100品牌内存超频到133MHz使用以获得CPU超频成功。为了方便一些超频用户的需求，市场上出现了一些PC150、PC166规范的内存。[3]SDRAMPC133内存的带宽可提高到1064MB/S，加上Intel已开始着手最新的Pentium4计划，所以SDRAMPC133内存不能满足日后的发展需求。Intel为了达到独占市场的目的，与Rambus联合在PC市场推广RambusDRAM内存（称为RDRAM内存）。与SDRAM不同的是，其采用了新一代高速简单内存架构，基于一种类RISC(ReducedInstructionSetComputing，精简指令集计算机)理论，这个理论可以减少数据的复杂性，使得整个系统性能得到提高。[3]在AMD与Intel的竞争中，这属于频率竞备时代。这时CPU的主频不断提升，Intel为了盖过AMD，推出高频PentiumⅢ以及Pentium4处理器。RambusDRAM内存被Intel看着是未来自己的竞争杀手锏。RambusDRAM内存以高时钟频率来简化每个时钟周期的数据量，内存带宽在当时相当出色。如：PC10661066MHz32bits带宽可达到4.2GByte/sec，RambusDRAM曾一度被认为是Pentium4的绝配。[3]RambusRDRAM内存生不逢时，依然要被更高速度的DDR“掠夺”其宝座地位。当时，PC600、PC700的RambusRDRAM内存因出现Intel820芯片组“失误事件”、PC800RambusRDRAM因成本过高而让Pentium4平台高高在上，无法获得大众用户拥戴。发生的种种问题让RambusRDRAM胎死腹中，Rambus曾希望具有更高频率的PC1066规范RDRAM来力挽狂澜，但最终也是拜倒在DDR内存面前。[3]DDR时代DDRSDRAM(DoubleDataRateSDRAM)简称DDR，也是“双倍速率SDRAM”的意思。DDR可说是SDRAM的升级版本。DDR在时钟信号上升沿与下降沿各传输一次数据，使得DDR的数据传输速度为传统SDRAM的两倍。由于仅多采用了下降缘信号，不会造成能耗增加。至于定址与控制信号则与传统SDRAM相同，仅在时钟上升缘传输。[3]DDR内存作为一种性能与成本间折中的解决方案，其目的是迅速建立起牢固的市场空间，继而一步步在频率上高歌猛进，最终弥补内存带宽上的不足。第一代DDR200规范没有得到普及，第二代PC266DDRSRAM（133MHz时钟×2倍数据传输=266MHz带宽）是由PC133SDRAM内存所衍生出的。它将DDR内存带向第一个高潮。2017年还有不少赛扬和AMDK7处理器都在采用DDR266规格的内存，其后来的DDR333内存也属于一种过渡。而DDR400内存成为目前的主流平台选配，双通道DDR400内存已经成为800FSB处理器搭配的基本标准，随后的DDR533规范则成为超频用户的选择对象。[3]DDR2时代随着CPU性能的不断提高，大众对内存性能的要求也逐步提高。依高频率提升带宽的DDR迟早会力不从心，因此JEDEC组织很早就开始酝酿DDR2标准，加上LGA775接口的915/925以及最新的945等新平台开始对DDR2内存的支持，所以DDR2内存将开始演义内存领域的今天。[3]DDR2能够在100MHz的发信频率基础上提供每插脚最少400MB/s的带宽，而且其接口将运行于1.8V电压上，从而进一步降低发热量，以便提高频率。此外，DDR2将融入CAS、OCD、ODT等新性能指标和中断指令，提升内存带宽的利用率。从JEDEC组织者阐述的DDR2标准来看，针对PC等市场的DDR2内存将拥有400、533、667MHz等不同的时钟频率。高端的DDR2内存将拥有800、1000MHz两种频率。DDR-II内存将采用200-、220-、240-针脚的FBGA封装形式。最初的DDR2内存将采用0.13微米的生产工艺，内存颗粒的电压为1.8V，容量密度为512MB。[3]内存技术在2005年将会毫无悬念，SDRAM为代表的静态内存在五年内不会普及。QBM与RDRAM内存也难以挽回颓势，因此DDR与DDR2共存时代将是铁定的事实。[3]PC-100的“接班人”除了PC一133以外，VCM（VirXualChannelMemory）也是很重要的一员。VCM即“虚拟通道存储器”，这也是目前大多数较新的芯片组支持的一种内存标准。VCM内存主要根据由NEC公司开发的一种“缓存式DRAM”技术制造而成。它集成了“通道缓存”，由高速寄存器进行配置和控制。在实现高速数据传输的同时，VCM还维持着对传统SDRAM的高度兼容性，所以通常也把VCM内存称为VCMSDRAM。VCM与SDRAM的差别在于不论是否经过CPU处理的数据，都可先交于VCM进行处理，而普通的SDRAM就只能处理经CPU处理以后的数据，所以VCM要比SDRAM处理数据的速度快20%以上。目前可以支持VCMSDRAM的芯片组很多，包括：Intel的815E、VIA的694X等。[3]RDRAM时代Intel推出PC-100后，由于技术的发展，PC-100内存的800MB/s带宽不能满足更大的需求。而PC-133的带宽提高并不大（1064MB/s），同样不能满足日后的发展需求。Intel为了达到独占市场的目的，与Rambus公司联合在PC市场推广RambusDRAM(DirectRambusDRAM)。[3]RambusDRAM是：Rambus公司最早提出的一种内存规格，采用了新一代高速简单内存架构，基于一种RISC(ReducedInstructionSetComputing，精简指令集计算机)理论，从而可以减少数据的复杂性，使得整个系统性能得到提高。Rambus使用400MHz的16bit总线，在一个时钟周期内，可以在上升沿和下降沿的同时传输数据，这样它的实际速度就为400MHz×2=800MHz，理论带宽为（16bit×2×400MHz/8）1.6GB/s，相当于PC-100的两倍。另外，Rambus也可以储存9bit字节，额外的一比特是属于保留比特，可能以后会作为：ECC(ErroICheckingandCorrection，错误检查修正)校验位。Rambus的时钟可以高达400MHz，而且仅使用了30条铜线连接内存控制器和RIMM(RambusIn-lineMemoryModules，Rambus内嵌式内存模块），减少铜线的长度和数量就可以降低数据传输中的电磁干扰，从而快速地提高内存的工作频率。不过在高频率下，其发出的热量肯定会增加，因此第一款Rambus内存甚至需要自带散热风扇。[3]DDR3时代DDR3相比起DDR2有更低的工作电压，从DDR2的1.8V降落到1.5V，性能更好更为省电；DDR2的4bit预读升级为8bit预读。DDR3目前最高能够达到2000Mhz的速度，尽管目前最为快速的DDR2内存速度已经提升到800Mhz/1066Mhz的速度，但是DDR3内存模组仍会从1066Mhz起跳。[3]DDR3在DDR2基础上采用的新型设计：[3]1．8bit预取设计，而DDR2为4bit预取，这样DRAM内核的频率只有接口频率的1/8，DDR3-800的核心工作频率只有100MHz。2．采用点对点的拓朴架构，以减轻地址/命令与控制总线的负担。3．采用100nm以下的生产工艺，将工作电压从1.8V降至1.5V，增加异步重置（Reset）与ZQ校准功能。部分厂商已经推出1.35V的低压版DDR3内存。[3]DDR4时代2012年，DDR4时代将开启，工作电压降至1.2V，而频率提升至2133MHz，次年进一步将电压降至1.0V，频率则实现2667MHz。新一代的DDR4内存将会拥有两种规格。根据多位半导体业界相关人员的介绍，DDR4内存将会是Single-endedSignaling（传统SE信号）方式DifferentialSignaling（差分信号技术）方式并存。其中AMD公司的PhilHester先生也对此表示了确认。现在有3200Mhz的ddr4和4266Mhz的LPDDR4预计这两个标准将会推出不同的芯片产品，因此在DDR4内存时代我们将会看到两个互不兼容的内存产品。[3]第二代HBM32023年7月消息，美光宣布已出样业界首款8层堆叠的24GB容量第二代HBM3内存，基于1βDRAM制程节点高带宽内存（HBM）解决方案，带宽超过1.2TB/s，引脚速率超过9.2Gb/s，比现有HBM3解决方案性能可提升最高50%。美光介绍，第二代HBM3产品与前一代产品相比，每瓦性能提高2.5倍，可帮助缩短大型语言模型（如GPT-4及更高版本）的训练时间，降低总体拥有成本（TCO）。[8]分类播报编辑内存一般采用半导体存储单元，包括随机存储器（RAM），只读存储器（ROM），以及高速缓存（CACHE）。只不过因为RAM是其中最重要的存储器。（synchronous）SDRAM同步动态随机存取存储器：SDRAM为168脚，这是目前PENTIUM及以上机型使用的内存。SDRAM将CPU与RAM通过一个相同的时钟锁在一起，使CPU和RAM能够共享一个时钟周期，以相同的速度同步工作，每一个时钟脉冲的上升沿便开始传递数据，速度比EDO内存提高50%。DDR（DOUBLEDATARATE）RAM：SDRAM的更新换代产品，他允许在时钟脉冲的上升沿和下降沿传输数据，这样不需要提高时钟的频率就能加倍提高SDRAM的速度。[4]按工作原理分类●只读存储器（ROM）ROM表示只读存储器（ReadOnlyMemory），在制造ROM的时候，信息（数据或程序）就被存入并永久保存。这些信息只能读出，一般不能写入，即使机器停电，这些数据也不会丢失。ROM一般用于存放计算机的基本程序和数据，如BIOSROM。其物理外形一般是双列直插式（DIP）的集成块。[4]现在比较流行的只读存储器是闪存(FlashMemory)，它属于EEPROM(电擦除可编程只读存储器)的升级，可以通过电学原理反复擦写。现在大部分BIOS程序就存储在FlashROM芯片中。U盘和固态硬盘(SSD)也是利用闪存原理做成的。[4]●随机存储器（RAM）内存随机存储器（RandomAccessMemory）表示既可以从中读取数据，也可以写入数据。当机器电源关闭时，存于其中的数据就会丢失。我们通常购买或升级的内存条就是用作电脑的内存，内存条（SIMM）就是将RAM集成块集中在一起的一小块电路板，它插在计算机中的内存插槽上，以减少RAM集成块占用的空间。目前市场上常见的内存条有4G,8G,16G,32G等。RAM分为两种：DRAM和SRAM。[4]1.DRAM(DynamicRAM，动态随机存储器)的存储单元是由电容和相关元件做成的，电容内存储电荷的多寡代表信号0和1。电容存在漏电现象，电荷不足会导致存储单元数据出错，所以DRAM需要周期性刷新，以保持电荷状态。DRAM结构较简单且集成度高，通常用于制造内存条中的存储芯片。[4]2.SRAM(StaticRAM，静态随机存储器)的存储单元是由晶体管和相关元件做成的锁存器，每个存储单元具有锁存“0”和“1”信号的功能。它速度快且不需要刷新操作，但集成度差和功耗较大，通常用于制造容量小但效率高的CPU缓存。[4]●高速缓冲存储器（Cache）Cache也是我们经常遇到的概念，也就是平常看到的一级缓存（L1Cache）、二级缓存（L2Cache）、三级缓存（L3Cache）这些数据，它位于CPU与内存之间，是一个读写速度比内存更快的存储器。当CPU向内存中写入或读出数据时，这个数据也被存储进高速缓冲存储器中。当CPU再次需要这些数据时，CPU就从高速缓冲存储器读取数据，而不是访问较慢的内存，当然，如需要的数据在Cache中没有，CPU会再去读取内存中的数据。[4]按内存技术标准分类按内存技术标准可分为SDRAM，DDRSDRAM，DDR2SDRAM和DDR3SDRAM。[4]1)SDRAM(SynchronousDynamicRAM，同步动态随机存储器)采用3.3V工作电压，内存数据位宽64位。SDRAM与CPU通过一个相同的时钟频率锁在一起，使两者以相同的速度同步工作。SDRAM它在每一个时钟脉冲的上升沿传输数据SDRAM内存金手指为168脚。[4]SDRAM内存有以下几种：PC66/100/133150/166，核心频率分别为66MHz，100Mz133MHz，150MHz，166MHz。时钟频率、等效频率与核心频率相等单根SDRAM内存数据传输带宽最高为166MHz×64bit÷8=1.3GB/s。[4]相关概念核心频率：是内存颗粒内部存储单元的工作频率，即电容的刷新频率。它是内存工作的基础频率，其他频率都是建立在它基础之上的。[4]时钟频率：又称内存总线频率，它是主板时钟芯片提供给内存的工作频率。[4]等效频率：又称等效数据传输频率，它是内存与外界据交换的实际频率。通常内存标签上贴的就是等效效率。[4]2)DDRSDRAM(DoubledataRateSDRAM，双倍速率同步动态随机存储器)采用2.5V工作电压，内存数据位宽64位。DDRSDRAM(简称DDR内存)一个时钟脉冲传输两次数据，分别在时钟脉冲的上升沿和下降沿各传输一次数据，因此称为双倍速率的SDRAM。[4]DDR内存金手指为184脚。DDR内存有以下几种:：DDR200/266/333/400/500。核心频率与时钟频率相等，分别为100MHz，133MHz，166MHz，200MHz，250MHz，等效频分别为200MHz，266MHz，333MHz，400MHz，500MHz，请注意，DDR内存的等效频率是时钟频率的两倍，因为DDR内存是双倍速率工作的。DDR内存核心采用2位数据预读取，也就是一次(一个脉冲)取2位。[4]而DDR内存核心频率等于时钟频率，等效频率是时钟频率的2倍，所以内存核心一次(一个脉冲)取出的数能及时地一次(一个脉冲)传输出去。单根DDR内存数据传输带宽最高为500MHz×64bit8-4GB/s。[4]3)DDR2SDRAM(DoubleDataRate2SDRAM)采用1.8V工作电压，内存数据位宽64位。DDR2内存和DDR内存一样，一个时钟脉冲传输两次数据，但DDR2内存却拥有两倍于上一代DDR内存的预读取能力，即4位数据预读取。[4]DDR2内存金手指为240脚。DDR2内存有以下几种:DDR2533/667/800/1066。核心频率分别为133MHz，166MHz，200MHz，266MHz，时钟频率分别为:266MHz，333MHz，400MHz，533MHz，等效频率分别为533MHz，667MHz，800MHz，1066MHz。[4]前面已经说过，DDR2内存核心采用4位数据预读取，也就是一次(一个脉冲)取4位，如果和上一代DDR内存一样，时钟频率与核心频率相等，等效频率是时钟频率2倍的话，就无法及时地将取出的数传输出去；所以DDR2内存的时钟频率是核心频率的2倍，这样才能将相同时间间隔内从内存核心取出的数，在相同时间间隔内传输出去。[4]单根DDR2内存的数据传输带宽最高为1066MH2zX64bit8-8.6GB/s。[4]4)DDR3SDRAM(DoubleDataRate3SDRAM)采用1.5V工作电压，内存数据位宽64位。同样，DDR3内存拥有两倍于上一代DDR2内存的预读取能力，即8位数据预读取。[4]对于DDR3内存，可以得出以下关系：时钟频率是核心频率的4倍，等效频率是时钟频率的2倍，也就是说DDR3内存等效频率是核心频率的8倍。[4]DDR3内存有以下几种:DDR31066/1333/1600/1800/2000。核心频率分别为133MHz，166MHz，200MHz，225MHz，250MHz，时钟频率分别分533MHz，667MHz，800MHz，900MHz，1000MHz，等效频率分别为:1066MHz，1333MHz，1600MHz，1800MHz，2000MHz。单根DDR3内存的数据传输带宽最高为2000MHz×64bit÷8-16GB/s。[4]5)DDR4SDRAM(DoubleDataRate4SDRAM)采用1.2V工作电压，内存数据位宽64位，16位数据预读取。取消双通道机制，一条内存即为一条通道。工作频率最高可达4266MHz，单根DDR4内存的数据传输带宽最高为34GB/s。[4]按系统逻辑分类1）扩充内存到1984年，即286被普遍接受不久，人们越来越认识到640KB的限制已成为大型程序的障碍，这时，Intel和Lotus，这两家硬、软件的杰出代表，联手制定了一个由硬件和软件相结合的方案，此方法使所有PC机存取640KB以上RAM成为可能。而Microsoft刚推出Windows不久，对内存空间的要求也很高，因此它也及时加入了该行列。[5]在1985年初，Lotus、Intel和Microsoft三家共同定义了LIM－EMS，即扩充内存规范，通常称EMS为扩充内存。当时，EMS需要一个安装在I/O槽口的内存扩充卡和一个称为EMS的扩充内存管理程序方可使用。但是I/O插槽的地址线只有24位（ISA总线），这对于386以上档次的32位机是不能适应的。所以，现在已很少使用内存扩充卡。现在微机中的扩充内存通常是用软件如DOS中的EMM386把扩展内存模拟或扩充内存来使用。所以，扩充内存和扩展内存的区别并不在于其物理存储器的位置，而在于使用什么方法来读写它。下面将作进一步介绍。[5]前面已经说过扩充存储器也可以由扩展存储器模拟转换而成。EMS的原理和XMS不同，它采用了页帧方式。页帧是在1MB空间中指定一块64KB空间（通常在保留内存区内，但其物理存储器来自扩展存储器），分为4页，每页16KB。EMS存储器也按16KB分页，每次可交换4页内容，以此方式可访问全部EMS存储器。符合EMS的驱动程序很多，常用的有EMM386.EXE、QEMM、TurboEMS、386MAX等。DOS和Windows中都提供了EMM386.EXE。[5]2）扩展内存扩展内存图解我们知道，286有24位地址线，它可寻址16MB的地址空间，而386有32位地址线，它可寻址高达4GB的地址空间，为了区别起见，我们把1MB以上的地址空间称为扩展内存XMS（eXtendmemory）。[5]在386以上档次的微机中，有两种存储器工作方式，一种称为实地址方式或实方式，另一种称为保护方式。在实方式下，物理地址仍使用20位，所以最大寻址空间为1MB，以便与8086兼容。保护方式采用32位物理地址，寻址范围可达4GB。DOS系统在实方式下工作，它管理的内存空间仍为1MB，因此它不能直接使用扩展存储器。为此，Lotus、Intel、AST及Microsoft公司建立了MS－DOS下扩展内存的使用标准，即扩展内存规范XMS。我们常在Config.sys文件中看到的Himem.sys就是管理扩展内存的驱动程序。[6]扩展内存管理规范的出现迟于扩充内存管理规范。3）高端内存区在实方式下，内存单元的地址可记为：段地址：段内偏移[5]内存通常用十六进制写为XXXX：XXXX。实际的物理地址由段地址左移4位再和段内偏移相加而成。若地址各位均为1时，即为FFFF：FFFF。其实际物理地址为：FFF0+FFFF=10FFEF，约为1088KB（少16字节），这已超过1MB范围进入扩展内存了。这个进入扩展内存的区域约为64KB，是1MB以上空间的第一个64KB。我们把它称为高端内存区HMA（HighMemoryArea）。HMA的物理存储器是由扩展存储器取得的。因此要使用HMA，必须要有物理的扩展存储器存在。此外HMA的建立和使用还需要XMS驱动程序HIMEM.SYS的支持，因此只有装入了HIMEM.SYS之后才能使用HMA。[5]4）上位内存为了解释上位内存的概念，我们还得回过头看看保留内存区。保留内存区是指640KB～1024KB（共384KB）区域。这部分区域在PC诞生之初就明确是保留给系统使用的，用户程序无法插足。但这部分空间并没有充分使用，因此大家都想对剩余的部分打主意，分一块地址空间（注意：是地址空间，而不是物理存储器）来使用。于是就得到了又一块内存区域UMB。[5]UMB（UpperMemoryBlocks）称为上位内存或上位内存块。它是由挤占保留内存中剩余未用的空间而产生的，它的物理存储器仍然取自物理的扩展存储器，它的管理驱动程序是EMS驱动程序。[5]5）影子内存对于装有1MB或1MB以上物理存储器的机器，其640KB～1024KB这部分物理存储器如何使用的问题。由于这部分地址空间已分配为系统使用，所以不能再重复使用。为了利用这部分物理存储器，在某些386系统中，提供了一个重定位功能，即把这部分物理存储器的地址重定位为1024KB～1408KB。这样，这部分物理存储器就变成了扩展存储器，当然可以使用了。但这种重定位功能在当今高档机器中不再使用，而把这部分物理存储器保留作为Shadow存储器。Shadow存储器可以占据的地址空间与对应的ROM是相同的。Shadow由RAM组成，其速度大大高于ROM。当把ROM中的内容（各种BIOS程序）装入相同地址的ShadowRAM中，就可以从RAM中访问BIOS，而不必再访问ROM。这样将大大提高系统性能。因此在设置CMOS参数时，应将相应的Shadow区设为允许使用（Enabled）。[5]总结经过上面分析，内存储器的划分可归纳如下：[5]●基本内存占据0～640KB地址空间。内存●保留内存占据640KB～1024KB地址空间。分配给显示缓冲存储器、各适配卡上的ROM和系统ROMBIOS，剩余空间可作上位内存UMB。UMB的物理存储器取自物理扩展存储器。此范围的物理RAM可作为ShadowRAM使用。[5]●上位内存（UMB）利用保留内存中未分配使用的地址空间建立，其物理存储器由物理扩展存储器取得。UMB由EMS管理，其大小可由EMS驱动程序设定。[5]●高端内存（HMA）扩展内存中的第一个64KB区域（1024KB～1088KB）。由HIMEM.SYS建立和管理。[5]●XMS内存符合XMS规范管理的扩展内存区。其驱动程序为HIMEM.SYS。[5]●EMS内存符合EMS规范管理的扩充内存区。其驱动程序为EMM386.EXE等。[5]其他类型SRAMSRAM（StaticRAM）意为静态随机存储器。SRAM数据不需要通过不断地刷新来保存，因此速度比DRAM（动态随机存储器）快得多。但是SRAM具有的缺点是：同容量相比DRAM需要非常多的晶体管，发热量也非常大。因此SRAM难以成为大容量的主存储器，通常只用在CPU、GPU中作为缓存，容量也只有几十K至几十M。[5]SRAM目前发展出的一个分支是eSRAM（EnhancedSRAM），为增强型SRAM，具备更大容量和更高运行速度。[5]RDRAMRDRAM是由RAMBUS公司推出的内存。RDRAM内存条为16bit，但是相比同期的SDRAM具有更高的运行频率，性能非常强。[5]然而它是一个非开放的技术，内存厂商需要向RAMBUS公司支付授权费。并且RAMBUS内存的另一大问题是不允许空通道的存在，必须成对使用，空闲的插槽必须使用终结器。因此，除了短寿的Inteli820和i850芯片组对其提供支持外，PC平台没有支持RAMBUS内存的芯片组。可以说，它是一个优秀的技术，但不是一个成功的商业产品。[5]XDRRAMXDR内存是RDRAM的升级版。依旧由RAMBUS公司推出。XDR就是“eXtremeDataRate”的缩写。XDR依旧存在RDRAM不能大面普及的那些不足之处。因此，XDR内存的应用依旧非常有限。比较常见的只有索尼的PS3游戏机。[5]Fe-RAM铁电存储器是一种在断电时不会丢失内容的非易失存储器，具有高速、高密度、低功耗和抗辐射等优点。由于数据是通过铁元素的磁性进行存储，因此，铁电存储器无需不断刷新数据。其运行速度将会非常乐观。而且它相比SRAM需要更少的晶体管。它被业界认为是SDRAM的最有可能的替代者。[5]MRAM磁性存储器。它和Fe-RAM具有相似性，依旧基于磁性物质来记录数据。[5]OUM相变存储器。奥弗辛斯基（StanfordOvshinsky）在1968年发表了第一篇关于非晶体相变的论文，创立了非晶体半导体学。一年以后，他首次描述了基于相变理论的存储器：材料由非晶体状态变成晶体，再变回非晶体的过程中，其非晶体和晶体状态呈现不同的反光特性和电阻特性，因此可以利用非晶态和晶态分别代表“0”和“1”来存储数据。[5]接口类型播报编辑内存的接口类型分DIP，SIMM和DIMM三种(RDRAM又增加了RMM)，其中后两种就是我们要重点论述的内容。[7]DIPDIP是"Dualn-LinePackage"的缩写，即双列直插内存芯片，它的常见单片容量有256KB，IMB等几种。但现在内存发展这么快，哪里还会是几百KB和几兆容量的内存?因此DIP接口早已经是淘汰了的内存接口。[7]在SIMM和DIMM接口类型的内存条上，多个RAM芯片焊在一块小电路板上，通过专用插座装在主板或内存扩充板上，因此它们也可以看作是一个内存芯片。[7]SIMMSIMM是"Singleln-LineMemoryModule"的缩写，即单列直插内存模块，这是5x86及较早的PC机中常用的内存接口方式。在更早的PC机中(486以前)，多采用30针的SIMM接口，而在Pentium级别的机器中，应用更多的则是72针的SIMM接口，或者是与DIMM接口类型并存。72线的内存条体积稍大，并提供32位的有效数据位，常见容量有4MB.8MB，16MB和32MB。[7]DIMMDIMM是"DualIn-LineMemoryModule"缩写，即双列直插内存模块，也就是说这种类型接口的内存的插板的两边都有数据接口触片(俗称为金手指)。[7]这种接口模式的内存广泛应用于现在的计算机中，通常为84针，但由于是双边的，所以一共有168针，也就是人们常说的168线内存条。168线内存条的体积较大，提供64位有效数据位。[7]DRAM内存通常为72线的，SDRAM内存通常为168线的，而EDORAM内存则既有72线的，也有168线的。人们经常用内存的管线数来称呼内存。但需要注意的是，并非只有SDRAM内存是168线的，某些SIMM型内存也具有168线。SIMM的工作电压是5v，DIMM的工作电压是3.3v。[7]技术指标播报编辑内存的技术指标一般包括奇偶校验、引脚数、容量、速度等。引脚数可以归为内存的接口类型，这里不再论述。[7]奇偶校验奇/偶校验（ECC）是数据传送时采用的一种校正数据错误的一种方式，分为奇校验和偶校验两种。[7]如果是采用奇校验，在传送每一个字节的时候另外附加一位作为校验位，当原来数据序列中“1”的个数为奇数时，这个校验位就是“0”，否则这个校验位就是“1”，这样就可以保证传送数据满足奇校验的要求。在接收方收到数据时，将按照奇校验的要求检测数据中“1”的个数，如果是奇数，表示传送正确，否则表示传送错误。[7]同理偶校验的过程和奇校验的过程一样，只是检测数据中“1”的个数为偶数。[7]内存容量内存容量同硬盘、软盘等存储器容量单位都是相同的，它们的基本单位都是字节（B），并且：内存1024B=1KB=1024字节=210字节1024KB=1MB=1048576字节=220字节1024MB=1GB=1073741824字节=230字节1024GB=1TB=1099511627776字节=240字节1024TB=1PB=1125899906842624字节=250字节1024PB=1EB=1152921504606846976字节=260字节1024EB=1ZB=1180591620717411303424字节=270字节1024ZB=1YB=1208925819614629174706176字节=280字节[7]内存条是否能以完整的存储体(Bank)为单位安装将决定内存能否正常工作，这与计算机的数据总线位数是相关的，不同机型的计算机，其数据总线的位数也是不同的。内存条通常有64MB、128MB、256MB等容量级别。从这个级别可以看出，内存条的容量都是翻倍增加的，也就是若内存条容量为512MB，则意味着再往下发展就将为1024MB了。[7]目前，8GB，16GB内存已成了主流配置。SDRAM内存条有双面和单面两种设计，每一面采用8颗或者9颗(多出的一颗为ECC验)SDRAM芯片。[7]存取时间存取时间是内存的另一个重要指标，其单位为纳秒(ns)，常见的SDRAM有6ns，7ns，8ns，10ns等几种，相应在内存条上标为-6，-7，-8，-10等字样。这个数值越小，存取速度越快，但价格也越高。在选配内存时，应尽量挑选与CPU的时钟周期相匹配的内存条，这将有利于最大限度地发挥内存条的效率。[7]内存慢而主板快，会影响CPU的速度，还有可能导致系统崩溃；内存快而主板慢，结果只能是大材小用造成资源浪费。当内存的存取时间是10ns时，它的时钟频率最高可达100MHz，也就是说可以配合100MHz外频的主板使用；当存取时间是7ns时，时钟频率最高可达142MHz，这时主板的外频可以上到133MHz以上。不过目前市场上印有“-8"、“-7"甚至“-6"的内存条，不少都达不到它所标称的指标。[7]CL延迟内存CL反应时间是衡定内存的另一个标志。CL是CASLatency的缩写，指的是内存存取数据所需的延迟时间，简单的说，就是内存接到CPU的指令后的反应速度。一般的参数值是2和3两种。数字越小，代表反应所需的时间越短。在早期的PC133内存标准中，这个数值规定为3，而在Intel重新制订的新规范中，强制要求CL的反应时间必须为2。这样在一定程度上，对于内存厂商的芯片及PCB的组装工艺要求相对较高，同时也保证了更优秀的品质。因此在选购品牌内存时，这是一个不可不察的因素。[7]还有另的诠释：内存延迟基本上可以解释成是系统进入数据进行存取操作就序状态前等待内存响应的时间。打个形象的比喻，就像你在餐馆里用餐的过程一样。你首先要点菜，然后就等待服务员给你上菜。同样的道理，内存延迟时间设置的越短，电脑从内存中读取数据的速度也就越快，进而电脑其他的性能也就越高。这条规则双双适用于基于英特尔以及AMD处理器的系统中。由于没有比2-2-2-5更低的延迟，因此国际内存标准组织认为以现在的动态内存技术还无法实现0或者1的延迟。[7]通常情况下，我们用4个连着的阿拉伯数字来表示一个内存延迟，例如2-2-2-5。其中，第一个数字最为重要，它表示的是CASLatency，也就是内存存取数据所需的延迟时间。第二个数字表示的是RAS-CAS延迟，接下来的两个数字分别表示的是RAS预充电时间和Act-to-Precharge延迟。而第四个数字一般而言是它们中间最大的一个。[7]频率内存频率测试图内存主频和CPU主频一样，习惯上被用来表示内存的速度。它代表该内存能达到的最高工作频率。内存主频是以MHz（兆赫）为单位来计量的。内存主频越高在一定程度上代表内存能达到的速度越快。内存主频决定该内存最高能在什么样的频率正常工作。目前主流的内存频率是DDR4，以及内存频率更高的DDR5。[7]计算机系统的时钟速度是以频率来衡量的。晶体振荡器控制着时钟速度，在石英晶片上加上电压，其就以正弦波的形式震动起来，这一震动可以通过晶片的形变和大小记录下来。晶体的震动以正弦调和变化的电流的形式表现出来，这一变化的电流就是时钟信号。而内存本身并不具备晶体振荡器，因此内存工作时的时钟信号是由主板芯片组的北桥或直接由主板的时钟发生器提供的，也就是说内存无法决定自身的工作频率，其实际工作频率是由主板来决定的。[7]DDR内存和DDR2内存的频率可以用工作频率和等效频率两种方式表示，工作频率是内存颗粒实际的工作频率，但是由于DDR内存可以在脉冲的上升和下降沿都传输数据，因此传输数据的等效频率是工作频率的两倍；而DDR2内存每个时钟能够以四倍于工作频率的速度读/写数据，因此传输数据的等效频率是工作频率的四倍。例如DDR200/266/333/400的工作频率分别是100/133/166/200MHz，而等效频率分别是200/266/333/400MHz；DDR2400/533/667/800的工作频率分别是100/133/166/200MHz，而等效频率分别是400/533/667/800MHz。[7]带宽从功能上理解，我们可以将内存看作是内存控制器（一般位于北桥芯片中）与CPU之间的桥梁或与仓库。显然，内存的容量决定“仓库”的大小，而内存的带宽决定“桥梁”的宽窄，两者缺一不可，这也就是我们常常说道的“内存容量”与“内存速度”。除了内存容量与内存速度，延时周期也是决定其性能的关键。当CPU需要内存中的数据时，它会发出一个由内存控制器所执行的要求，内存控制器接著将要求发送至内存，并在接收数据时向CPU报告整个周期（从CPU到内存控制器，内存再回到CPU）所需的时间。[7]毫无疑问，缩短整个周期也是提高内存速度的关键，这就好比在桥梁上工作的警察，其指挥疏通能力也是决定通畅度的因素之一。更快速的内存技术对整体性能表现有重大的贡献，但是提高内存带宽只是解决方案的一部分，数据在CPU以及内存间传送所花的时间通常比处理器执行功能所花的时间更长，为此缓冲区被广泛应用。其实，所谓的缓冲器就是CPU中的一级缓存与二级缓存，它们是内存这座“大桥梁”与CPU之间的“小桥梁”。事实上，一级缓存与二级缓存采用的是SRAM，我们也可以将其宽泛地理解为“内存带宽”，不过现在似乎更多地被解释为“前端总线”，所以我们也只是简单的提一下。事先预告一下，“前端总线”与“内存带宽”之间有着密切的联系，我们将会在后面的测试中有更加深刻的认识。[7]带宽重要性基本上当CPU接收到指令后，它会最先向CPU中的一级缓存（L1Cache）去寻找相关的数据，虽然一级缓存是与CPU同频运行的，但是由于容量较小，所以不可能每次都命中。这时CPU会继续向下一级的二级缓存（L2Cache）寻找，同样的道理，当所需要的数据在二级缓存中也没有的话，会继续转向L3Cache（如果有的话，如K6-2+和K6-3）、内存和硬盘。[7]由于目前系统处理的数据量都是相当巨大的，因此几乎每一步操作都得经过内存，这也是整个系统中工作最为频繁的部件。如此一来，内存的性能就在一定程度上决定了这个系统的表现，这点在多媒体设计软件和3D游戏中表现得更为明显。3D显卡的内存带宽（或许称为显存带宽更为合适）的重要性也是不言而喻的，甚至其作用比系统的内存带宽更为明显。大家知道，显示卡在进行像素渲染时，都需要从显存的不同缓冲区中读写数据。这些缓冲区中有的放置描述像素ARGB（阿尔法通道，红，绿，蓝）元素的颜色数据，有的放置像素Z值（用来描述像素的深度或者说可见性的数据）。显然，一旦产生Z轴数据，显存的负担会立即陡然提升，在加上各种材质贴图、深度复杂性渲染、3D特效。[7]提高内存带宽内存带宽的计算方法并不复杂，大家可以遵循如下的计算公式：带宽=总线宽度×总线频率×一个时钟周期内交换的数据包个数。很明显，在这些乘数因子中，每个都会对最终的内存带宽产生极大的影响。然而，如今在频率上已经没有太大文章可作，毕竟这受到制作工艺的限制，不可能在短时间内成倍提高。而总线宽度和数据包个数就大不相同了，简单的改变会令内存带宽突飞猛进。DDR技术就使我们感受到提高数据包个数的好处，它令内存带宽疯狂地提升一倍。当然，提高数据包个数的方法不仅仅局限于在内存上做文章，通过多个内存控制器并行工作同样可以起到效果，这也就是如今热门的双通道DDR芯片组（如nForce2、I875/865等）。[7]事实上，双通道DDR内存控制器并不能算是新发明，因为早在RAMBUS时代，RDRAM就已经使用了类似技术，只不过当时RDRAM的总线宽度只有16Bit，无法与DDR的64Bit相提并论。内存技术发展到如今这一阶段，四通道内存控制器的出现也只是时间问题，VIA的QBM技术以及SiS支持四通道RDRAM的芯片组，这些都是未来的发展方向。至于显卡方面，我们对其显存带宽更加敏感，这甚至也是很多厂商用来区分高低端产品的重要方面。同样是使用DDR显存的产品，128Bit宽度的产品会表现出远远胜过64Bit宽度的产品。当然提高显存频率也是一种解决方案，不过其效果并不明显，而且会大幅度提高成本。值得注意的是，目前部分高端显卡甚至动用了DDRII技术，不过至少在目前看来，这项技术还为时过早。[7]识别内存带宽对于内存而言，辨别内存带宽是一件相当简单的事情，因为SDRAM、DDR、RDRAM这三种内存在外观上有着很大的差别，大家通过下面这副图就能清楚地认识到。唯一需要我们去辨认的便是不同频率的DDR内存。目前主流DDR内存分为DDR266、DDR333以及DDR400，其中后三位数字代表工作频率。[7]通过内存条上的标识，自然可以很方便地识别出其规格。相对而言，显卡上显存带宽的识别就要困难一些。在这里，我们应该抓住“显存位宽”和“显存频率”两个重要的技术指标。显存位宽的计算方法是：单块显存颗粒位宽×显存颗粒总数，而显存频率则是由"1000/显存颗粒纳秒数"来决定。一般来说，我们可以从显存颗粒上一串编号的最后2两位看出其纳秒数，从中也就得知其显存频率。至于单块显存颗粒位宽，我们只能在网上查询。HY、三星、EtronTech（钰创）等都提供专用的显存编号查询网站，相当方便。如三星的显存就可以到如下的地址下载，只要输入相应的显存颗粒编号即可。此外，使用RivaTuner也可以检测显卡上显存的总位宽，大家打开RivaTuner在MAIN菜单即可看到。[7]选购方法播报编辑做工要精良对于选择内存来说，最重要的是稳定性和性能，而内存的做工水平直接会影响到性能、稳定以及超频。内存颗粒的好坏直接影响到内存的性能，可以说也是内存最重要的核心元件。所以大家在购买时，尽量选择大厂生产出来的内存颗粒。一般常见的内存颗粒厂商有三星、现代、镁光、南亚、茂矽等，它们都是经过完整的生产工序，因此在品质上都更有保障。而采用这些顶级大厂内存颗粒的内存条品质性能，必然会比其他杂牌内存颗粒的产品要高出许多。[7]内存PCB电路板的作用是连接内存芯片引脚与主板信号线，因此其做工好坏直接关系着系统稳定性。目前主流内存PCB电路板层数一般是6层，这类电路板具有良好的电气性能，可以有效屏蔽信号干扰。而更优秀的高规格内存往往配备了8层PCB电路板，以起到更好的效能。[7]SPD隐藏信息SPD信息可以说非常重要，它能够直观反映出内存的性能及体制。它里面存放着内存可以稳定工作的指标信息以及产品的生产，厂家等信息。不过，由于每个厂商都能对SPD进行随意修改，因此很多杂牌内存厂商会将SPD参数进行修改或者直接COPY名牌产品的SPD，但是一旦上机用软件检测就会原形毕露。[7]因此，大家在购买内存以后，回去用常用的Everest、CPU-Z等软件一查即可明白。不过需要注意的是，对于大品牌内存来说SPD参数是非常重要的，但是对于杂牌内存来说，SPD的信息并不值得完全相信。[7]假冒返修产品目前有一些内存往往使用了不同品牌、型号的内存颗粒，大家一眼就可以看出区别。同时有些无孔不入的JS也会采用打磨内存颗粒的作假手段，然后再加印上新的编号参数。不过仔细观察，就会发现打磨过后的芯片比较暗淡无光，有起毛的感觉，而且加印上的字迹模糊不清晰。这些一般都是假冒的内存产品，需要注意。[7]此外，大家还要观察PCB电路板是否整洁，有无毛刺等等，金手指是否很明显有经过插拔所留下的痕迹，如果有，则很有可能是返修内存产品（当然也不排除有厂家出厂前经过测试，不过比较少数）。需要提醒大家的是，返修和假冒内存无论多么便宜都不值得购买，因为其安全隐患十分严重。[7]故障修复播报编辑1、开机无显示由于内存条原因出现此类故障一般是因为内存条与主板内存插槽接触不良造成，只要用橡皮擦来回擦试其金手指部位即可解决问题（不要用酒精等清洗），还有就是内存损坏或主板内存槽有问题也会造成此类故障。[1]内存[1]由于内存条原因造成开机无显示故障，主机扬声器一般都会长时间蜂鸣（针对AwardBios而言）2、windows系统运行不稳定，经常产生非法错误出现此类故障一般是由于内存芯片质量不良或软件原因引起，如若确定是内存条原因只有更换一途。[1]3、windows注册表经常无故损坏，提示要求用户恢复此类故障一般都是因为内存条质量不佳引起，很难予以修复，唯有更换一途。[1]4、windows经常自动进入安全模式此类故障一般是由于主板与内存条不兼容或内存条质量不佳引起，常见于PC133内存用于某些不支持PC133内存条的主板上，可以尝试在CMOS设置内降低内存读取速度看能否解决问题，如若不行，那就只有更换内存条了。[1]5、随机性死机此类故障一般是由于采用了几种不同芯片的内存条，由于各内存条速度不同产生一个时间差从而导致死机，对此可以在CMOS设置内降低内存速度予以解决，否则，唯有使用同型号内存。还有一种可能就是内存条与主板不兼容，此类现象一般少见，另外也有可能是内存条与主板接触不良引起电脑随机性死机，此类现象倒是比较常见。[1]6、内存加大后系统资源反而降低此类现象一般是由于主板与内存不兼容引起，常见于PC133内存条用于某些不支持PC133内存条的主板上，即使系统重装也不能解决问题。[1]7、windows启动时，在载入高端内存文件himem.sys时系统提示某些地址有问题此问题一般是由于内存条的某些芯片损坏造成，解决方法可参见下面内存维修一法。[1]8、运行某些软件时经常出现内存不足的提示此现象一般是由于系统盘剩余空间不足造成，可以删除一些无用文件，多留一些空间即可，一般保持在300M左右为宜。[1]9、从硬盘引导安装windows进行到检测磁盘空间时，系统提示内存不足此类故障一般是由于用户在config.sys文件中加入了emm386.exe文件，只要将其屏蔽掉即可解决问题。[1]10、安装windows进行到系统配置时产生一个非法错误此类故障一般是由于内存条损坏造成，可以按内存维修一法来解决，如若不行，那就只有更换内存条了。[1]11、启动windows时系统多次自动重新启动此类故障一般是由于内存条或电源质量有问题造成，当然，系统重新启动还有可能是CPU散热不良或其他人为故障造成，对此，唯有用排除法一步一步排除。[1]12、内存维修一法出现上面几种故障后，倘若内存损坏或芯片质量不行，如条件不允许可以用烙铁将内存一边的各芯片卸下，看能否解决问题，如若不行再换卸另一边的芯片，直到成功为止（如此焊工只怕要维修手机的人方可达到）。当然，有条件用示波器检测那就事半功倍了），采用此法后，因为已将内存的一边芯片卸下，所以内存只有一半可用，例如，64M还有32M可用，为此，对于小容量内存就没有维修的必要了。[1]常见误解播报编辑内部外存储器这种情况主要是发生在描述移动设备的内部集成的数据存放空间时。比如一台手机具备512G的数据存储空间，不少人将其描述为“512G内存”，事实上，这种表述是错误的，因为所谓的“512G内存”是一个外存储器。不能将“内部的外存储器”简称为”内存，因为内存是一个特定的概念，为内存储器的简称。[1]存储卡的容量存储卡的容量不应当简称为“内存”，因其也是外存储器。[1]异步总线：定义播报编辑不设时钟信号，利用请求、响应、就绪、等待等握手信号传递数据的总线。出处播报编辑《计算机科学技术名词》第三版。[1]内存映射文件：基本概述播报编辑文件操作是应用程序最为基本的功能之一，Win32API和MFC均提供有支持文件处理的函数和类，常用的有Win32API的CreateFile（）、WriteFile（）、ReadFile（）和MFC提供的CFile类等。一般来说，以上这些函数可以满足大多数场合的要求，但是对于某些特殊应用领域所需要的动辄几十GB、几百GB、乃至几TB的海量存储，再以通常的文件处理方法进行处理显然是行不通的。对于上述这种大文件的操作一般是以内存映射文件的方式来加以处理的。[1]内存映射文件是由一个文件到进程地址空间的映射。Win32中，每个进程有自己的地址空间，一个进程不能轻易地访问另一个进程地址空间中的数据，所以不能像16位Windows那样做。Win32系统允许多个进程（运行在同一计算机上）使用内存映射文件来共享数据。实际上，其他共享和传送数据的技术，诸如使用SendMessage或者PostMessage，都在内部使用了内存映射文件。图1Windows对内存映射文件提供的API如图1中右部所示：数据共享播报编辑文件数据共享这种数据共享是让两个或多个进程映射同一文件映射对象的视图，即它们在共享同一物理存储页。这样，当一个进程向内存映射文件的一个视图写入数据时，其他的进程立即在自己的视图中看到变化。注意，对文件映射对象要使用同一名字。访问方法这样，文件内的数据就可以用内存读/写指令来访问，而不是用ReadFile和WriteFile这样的I/O系统函数，从而提高了文件存取速度。范围应用播报编辑适用范围这种函数最适用于需要读取文件并且对文件内包含的信息做语法分析的应用程序，如：对输入文件进行语法分析的彩色语法编辑器，编译器等。把文件映射后进行读和分析，能让应用程序使用内存操作来操纵文件，而不必在文件里来回地读、写、移动文件指针。应用有些操作，如放弃“读”一个字符，在以前是相当复杂的，用户需要处理缓冲区的刷新问题。在引入了映射文件之后，就简单的多了。应用程序要做的只是使指针减少一个值。映射文件的另一个重要应用就是用来支持永久命名的共享内存。要在两个应用程序之间共享内存，可以在一个应用程序中创建一个文件并映射之，然后另一个应用程序可以通过打开和映射此文件把它作为共享的内存来使用。VC++使用内存映射文件处理大文件内存文件播报编辑内存映射文件与虚拟内存有些类似，通过内存映射文件可以保留一个地址空间的区域，同时将物理存储器提交给此区域，只是内存文件映射的物理存储器来自一个已经存在于磁盘上的文件，而非系统的页文件，而且在对该文件进行操作之前必须首先对文件进行映射，就如同将整个文件从磁盘加载到内存[2]。由此可以看出，使用内存映射文件处理存储于磁盘上的文件时，将不必再对文件执行I/O操作，这意味着在对文件进行处理时将不必再为文件申请并分配缓存，所有的文件缓存操作均由系统直接管理，由于取消了将文件数据加载到内存、数据从内存到文件的回写以及释放内存块等步骤，使得内存映射文件在处理大数据量的文件时能起到相当重要的作用。另外，实际工程中的系统往往需要在多个进程之间共享数据，如果数据量小，处理方法是灵活多变的，如果共享数据容量巨大，那么就需要借助于内存映射文件来进行。实际上，内存映射文件正是解决本地多个进程间数据共享的最有效方法。内存映射文件并不是简单的文件I/O操作，实际用到了Windows的核心编程技术--内存管理。所以，如果想对内存映射文件有更深刻的认识，必须对Windows操作系统的内存管理机制有清楚的认识，下面给出使用内存映射文件的一般方法：首先要通过CreateFile（）函数来创建或打开一个文件内核对象，这个对象标识了磁盘上将要用作内存映射文件的文件。在用CreateFile（）将文件映像在物理存储器的位置通告给操作系统后，只指定了映像文件的路径，映像的长度还没有指定。为了指定文件映射对象需要多大的物理存储空间还需要通过CreateFileMapping（）函数来创建一个文件映射内核对象以告诉系统文件的尺寸以及访问文件的方式。在创建了文件映射对象后，还必须为文件数据保留一个地址空间区域，并把文件数据作为映射到该区域的物理存储器进行提交。由MapViewOfFile（）函数负责通过系统的管理而将文件映射对象的全部或部分映射到进程地址空间。此时，对内存映射文件的使用和处理同通常加载到内存中的文件数据的处理方式基本一样，在完成了对内存映射文件的使用时，还要通过一系列的操作完成对其的清除和使用过资源的释放。这部分相对比较简单，可以通过UnmapViewOfFile（）完成从进程的地址空间撤消文件数据的映像、通过CloseHandle（）关闭前面创建的文件映射对象和文件对象。相关函数播报编辑在使用内存映射文件时，所使用的API函数主要就是前面提到过的那几个函数，下面分别对其进行介绍：HANDLECreateFile(LPCTSTRlpFileName,DWORDdwDesiredAccess,DWORDdwShareMode,LPSECURITY_ATTRIBUTESlpSecurityAttributes,DWORDdwCreationDisposition,DWORDdwFlagsAndAttributes,HANDLEhTemplateFile);函数CreateFile（）即使是在普通的文件操作时也经常用来创建、打开文件，在处理内存映射文件时，该函数来创建/打开一个文件内核对象，并将其句柄返回，在调用该函数时需要根据是否需要数据读写和文件的共享方式来设置参数dwDesiredAccess和dwShareMode，错误的参数设置将会导致相应操作时的失败。HANDLECreateFileMapping(HANDLEhFile,LPSECURITY_ATTRIBUTESlpFileMappingAttributes,DWORDflProtect,DWORDdwMaximumSizeHigh,DWORDdwMaximumSizeLow,LPCTSTRlpName);CreateFileMapping（）函数创建一个文件映射内核对象，通过参数hFile指定待映射到进程地址空间的文件句柄（该句柄由CreateFile（）函数的返回值获取）。由于内存映射文件的物理存储器实际是存储于磁盘上的一个文件，而不是从系统的页文件中分配的内存，所以系统不会主动为其保留地址空间区域，也不会自动将文件的存储空间映射到该区域，为了让系统能够确定对页面采取何种保护属性，需要通过参数flProtect来设定，保护属性PAGE_READONLY、PAGE_READWRITE和PAGE_WRITECOPY分别表示文件映射对象被映射后，可以读取、读写文件数据。在使用PAGE_READONLY时，必须确保CreateFile（）采用的是GENERIC_READ参数；PAGE_READWRITE则要求CreateFile（）采用的是GENERIC_READ|GENERIC_WRITE参数；至于属性PAGE_WRITECOPY则只需要确保CreateFile（）采用了GENERIC_READ和GENERIC_WRITE其中之一即可。DWORD型的参数dwMaximumSizeHigh和dwMaximumSizeLow也是相当重要的，指定了文件的最大字节数，由于这两个参数共64位，因此所支持的最大文件长度为16EB，几乎可以满足任何大数据量文件处理场合的要求。LPVOIDMapViewOfFile(HANDLEhFileMappingObject,DWORDdwDesiredAccess,DWORDdwFileOffsetHigh,DWORDdwFileOffsetLow,DWORDdwNumberOfBytesToMap);MapViewOfFile（）函数负责把文件数据映射到进程的地址空间，参数hFileMappingObject为CreateFileMapping（）返回的文件映像对象句柄。参数dwDesiredAccess则再次指定了对文件数据的访问方式，而且同样要与CreateFileMapping（）函数所设置的保护属性相匹配。虽然这里一再对保护属性进行重复设置看似多余，但却可以使应用程序能更多的对数据的保护属性实行有效控制。MapViewOfFile（）函数允许全部或部分映射文件，在映射时，需要指定数据文件的偏移地址以及待映射的长度。其中，文件的偏移地址由DWORD型的参数dwFileOffsetHigh和dwFileOffsetLow组成的64位值来指定，而且必须是操作系统的分配粒度的整数倍，对于Windows操作系统，分配粒度固定为64KB。当然，也可以通过如下代码来动态获取当前操作系统的分配粒度：SYSTEM_INFOsinf;GetSystemInfo(&sinf);DWORDdwAllocationGranularity=sinf.dwAllocationGranularity;参数dwNumberOfBytesToMap指定了数据文件的映射长度，这里需要特别指出的是，对于Windows9x操作系统，如果MapViewOfFile（）无法找到足够大的区域来存放整个文件映射对象，将返回空值（NULL）；但是在Windows2000下，MapViewOfFile（）只需要为必要的视图找到足够大的一个区域即可，而无须考虑整个文件映射对象的大小。在完成对映射到进程地址空间区域的文件处理后，需要通过函数UnmapViewOfFile（）完成对文件数据映像的释放，该函数原型声明如下：BOOLUnmapViewOfFile(LPCVOIDlpBaseAddress);唯一的参数lpBaseAddress指定了返回区域的基地址，必须将其设定为MapViewOfFile（）的返回值。在使用了函数MapViewOfFile（）之后，必须要有对应的UnmapViewOfFile（）调用，否则在进程终止之前，保留的区域将无法释放。除此之外，前面还曾由CreateFile（）和CreateFileMapping（）函数创建过文件内核对象和文件映射内核对象，在进程终止之前有必要通过CloseHandle（）将其释放，否则将会出现资源泄漏的问题。除了前面这些必须的API函数之外，在使用内存映射文件时还要根据情况来选用其他一些辅助函数。例如，在使用内存映射文件时，为了提高速度，系统将文件的数据页面进行高速缓存，而且在处理文件映射视图时不立即更新文件的磁盘映像。为解决这个问题可以考虑使用FlushViewOfFile（）函数，该函数强制系统将修改过的数据部分或全部重新写入磁盘映像，从而可以确保所有的数据更新能及时保存到磁盘。应用示例播报编辑下面结合一个具体的实例来进一步讲述内存映射文件的使用方法。该实例从端口接收数据，并实时将其存放于磁盘，由于数据量大（几十GB），在此选用内存映射文件进行处理。下面给出的是位于工作线程MainProc中的部分主要代码，该线程自程序运行时启动，当端口有数据到达时将会发出事件hEvent[0]，WaitForMultipleObjects（）函数等待到该事件发生后将接收到的数据保存到磁盘，如果终止接收将发出事件hEvent[1]，事件处理过程将负责完成资源的释放和文件的关闭等工作。下面给出此线程处理函数的具体实现过程：//创建文件内核对象，其句柄保存于hFileHANDLEhFile=CreateFile("Recv1.zip",GENERIC_WRITE|GENERIC_READ,FILE_SHARE_READ,NULL,CREATE_ALWAYS,FILE_FLAG_SEQUENTIAL_SCAN,NULL);//创建文件映射内核对象，句柄保存于hFileMappingHANDLEhFileMapping=CreateFileMapping(hFile,NULL,PAGE_READWRITE,0,0x4000000,NULL);//释放文件内核对象CloseHandle(hFile);//设定大小、偏移量等参数//尽量把文件设置大一些，如果写的数据超过，设定的值，再次映射文件会报错getlasterror=183;__int64qwFileSize=0x4000000;__int64qwFileOffset=0;__int64T=600*sinf.dwAllocationGranularity;DWORDdwBytesInBlock=1000*sinf.dwAllocationGranularity;//将文件数据映射到进程的地址空间PBYTEpbFile=(PBYTE)MapViewOfFile(hFileMapping,FILE_MAP_ALL_ACCESS,(DWORD)(qwFileOffset>>32),(DWORD)(qwFileOffset&0xFFFFFFFF),dwBytesInBlock);while(bLoop){//捕获事件hEvent[0]和事件hEvent[1]DWORDret=WaitForMultipleObjects(2,hEvent,FALSE,INFINITE);ret-=WAIT_OBJECT_0;switch(ret){//接收数据事件触发case0://从端口接收数据并保存到内存映射文件nReadLen=syio_Read(port[1],pbFile+qwFileOffset,QueueLen);qwFileOffset+=nReadLen;//当数据写满60%时，为防数据溢出，需要在其后开辟一新的映射视图if(qwFileOffset>T){T=qwFileOffset+600*sinf.dwAllocationGranularity;UnmapViewOfFile(pbFile);pbFile=(PBYTE)MapViewOfFile(hFileMapping,FILE_MAP_ALL_ACCESS,(DWORD)(qwFileOffset>>32),(DWORD)(qwFileOffset&0xFFFFFFFF),dwBytesInBlock);}break;//终止事件触发case1:bLoop=FALSE;//从进程的地址空间撤消文件数据映像UnmapViewOfFile(pbFile);//关闭文件映射对象CloseHandle(hFileMapping);break;}}…在终止事件触发处理过程中如果只简单的执行UnmapViewOfFile（）和CloseHandle（）函数将无法正确标识文件的实际大小，即如果开辟的内存映射文件为30GB，而接收的数据只有14GB，那么上述程序执行完后，保存的文件长度仍是30GB。也就是说，在处理完成后还要再次通过内存映射文件的形式将文件恢复到实际大小，下面是实现此要求的主要代码：//创建另外一个文件内核对象hFile2=CreateFile("Recv.zip",GENERIC_WRITE|GENERIC_READ,FILE_SHARE_READ,NULL,CREATE_ALWAYS,FILE_FLAG_SEQUENTIAL_SCAN,NULL);//以实际数据长度创建另外一个文件映射内核对象hFileMapping2=CreateFileMapping(hFile2,NULL,PAGE_READWRITE,0,(DWORD)(qwFileOffset&0xFFFFFFFF),NULL);//关闭文件内核对象CloseHandle(hFile2);//将文件数据映射到进程的地址空间pbFile2=(PBYTE)MapViewOfFile(hFileMapping2,FILE_MAP_ALL_ACCESS,0,0,qwFileOffset);//将数据从原来的内存映射文件复制到此内存映射文件memcpy(pbFile2,pbFile,qwFileOffset);file://从进程的地址空间撤消文件数据映像UnmapViewOfFile(pbFile);UnmapViewOfFile(pbFile2);//关闭文件映射对象CloseHandle(hFileMapping);CloseHandle(hFileMapping2);//删除临时文件DeleteFile("Recv1.zip");并行处理：特点播报编辑只有部分应用程序在满足以下条件的情况下可利用并行处理：具有充足的能充分利用多处理机的应用程序；并行化目标应用程序或用户需进行新的编码来利用并行程序。传统上，多处理机专为“并行计算机”所设计，沿着这样的思路，当前Linux支持SMP奔腾系统，在该系统中多处理机共享单个计算机中的单个存储器和总线接口。每个运行Linux的机器组都有可能通过网络互相连接形成并行处理群。第三种选择是使用Linux系统作为“主机”，提供专门的相关并行处理机（attachedparallelprocessor）。第四种新选择是寄存器内SIMD并行，应用于多媒体扩展（MMX）[1]。并行处理所需要提供的典型硬件环境有：单处理机上的单个区；多处理机（SMP）中的单个区；多区配置一个处理机（MPP）中的各区；多处理机（SMP群）中的各区；逻辑数据库区（在AIX第1版的DB2并行版－DB2PE中也称之为多逻辑代码或MLN）并行计算机具有代表性的应用领域有：天气预报建摸、VLSI电路的计算机辅助设计、大型数据库管理、人工智能、犯罪控制和国防战略研究等，而且它的应用范围还在不断地扩大。并行处理技术主要是以算法为核心，并行语言为描述，软硬件作为实现工具的相互联系而又相互制约的一种结构技术。算法基本策略播报编辑在并行处理技术中所使用的算法主要遵循三种策略：1．分而治之法：也就是把多个任务分解到多个处理器或多个计算机中，然后再按照一定的拓扑结构来进行求解。2．重新排序法：分别采用静态或动态的指令词度方式。3．显式/隐式并行性结合：显式指的是并行语言通过编译形成并行程序，隐式指的是串行语言通过编译形成并行程序，显式/隐式并行性结合的关键就在于并行编译，而并行编译涉及到语句、程序段、进程以及各级程序的并行性。并行性描述定义播报编辑利用计算机语言进行并行性描述的时候主要有三种方案：1．语言扩展方案：也就是利用各种语言的库函数来进行并行性功能的扩展。2．编译制导法：也称为智能编译，它是隐式并行策略的体现，主要是由并行编译系统进行程序表示、控制流的分析、相关分析、优化分析和并行化划分，由相关分析得到方法库管理方案，由优化分析得到知识库管理方案，由并行化划分得到程序重构，从而形成并行程序。3．新的语言结构法：这是显式并行策略的体现。也就是建立一种全新的并行语言的体系，而这种并行语言通过编译就能直接形成并行程序[2]。并行软件播报编辑并行软件可分成并行系统软件和并行应用软件两大类，并行系统软件主要指并行编译系统和并行操作系统，并行应用软件主要指各种软件工具和应用软件包。在软件中所牵涉到的程序的并行性主要是指程序的相关性和网络互连两方面。1．程序的相关性：程序的相关性主要分为数据相关、控制相关和资源相关三类。数据相关说明的是语句之间的有序关系，主要有流相关、反相关、输出相关、I/O相关和求知相关等，这种关系在程序运行前就可以通过分析程序确定下来。数据相关是一种偏序关系，程序中并不是每一对语句的成员都是相关联的。可以通过分析程序的数据相关，把程序中一些不存在相关性的指令并行地执行，以提高程序运行的速度。控制相关指的是语句执行次序在运行前不能确定的情况。它一般是由转移指令引起的，只有在程序执行到一定的语句时才能判断出语句的相关性。控制相关常使正在开发的并行性中止，为了开发更多的并行性，必须用编译技术克服控制相关。而资源相关则与系统进行的工作无关，而与并行事件利用整数部件、浮点部件、寄存器和存储区等共享资源时发生的冲突有关。软件的并行性主要是由程序的控制相关和数据相关性决定的。在并行性开发时往往把程序划分成许多的程序段——颗粒。颗粒的规模也称为粒度，它是衡量软件进程所含计算量的尺度，一般用细、中、粗来描述。划分的粒度越细，各子系统间的通信时延也越低，并行性就越高，但系统开销也越大。因此，我们在进行程序组合优化的时候应该选择适当的粒度，并且把通讯时延尽可能放在程序段中进行，还可以通过软硬件适配和编译优化的手段来提高程序的并行度。2．网络互连：将计算机子系统互连在一起或构造多处理机或多计算机时可使用静态或动态拓扑结构的网络。静态网络由点一点直接相连而成，这种连接方式在程序执行过程中不会改变，常用来实现集中式系统的子系统之间或分布式系统的多个计算结点之间的固定连接。动态网络是用开关通道实现的，它可动态地改变结构，使之与用户程序中的通信要求匹配。动态网络包括总线、交叉开关和多级网络，常用于共享存储型多处理机中。在网络上的消息传递主要通过寻径来实现。常见的寻径方式有存储转发寻径和虫蚀寻径等。在存储转发网络中以长度固定的包作为信息流的基本单位，每个结点有一个包缓冲区，包从源结点经过一系列中间结点到达目的结点。存储转发网络的时延与源和目的之间的距离(段数)成正比。而在新型的计算机系统中采用虫蚀寻径，把包进一步分成一些固定长度的片，与结点相连的硬件寻径器中有片缓冲区。消息从源传送到目的结点要经过一系列寻径器。同一个包中所有的片以流水方式顺序传送，不同的包可交替地传送，但不同包的片不能交叉，以免被送到错误的目的地。虫蚀寻径的时延几乎与源和目的之间的距离无关。在寻径中产生的死锁问题可以由虚拟通道来解决。虚拟通道是两个结点间的逻辑链，它由源结点的片缓冲区、结点间的物理通道以及接收结点的片缓冲区组成。物理通道由所有的虚拟通道分时地共享。虚拟通道虽然可以避免死锁，但可能会使每个请求可用的有效通道频宽降低。因此，在确定虚拟通道数目时，需要对网络吞吐量和通信时延折衷考虑。硬件技术播报编辑硬件技术在硬件技术方面主要从处理机、存储器和流水线三个方面来实现并行。1．处理机：主要的处理机系列包括CISC、RISC、超标量、VL1W、超流水线、向量以及符号处理机。传统的处理机属于复杂指令系统计算(CISC)结构。指令系统大，指令格式可变，通用寄存器个数较少，基本上使用合一的指令与数据高速缓存，时钟频率较低，CPI较高，大多数利用ROM实现微码控制CPU，而当今的精简指令系统计算(RISC)处理机指令格式简单规范，面向寄存器堆，采用重叠寄存器窗口技术，具有多级Cache，多种流水线结构，强调编译优化技术，时钟频率快，CPI低，大多数用硬连线控制CPU。CISC或RISC标量处理机都可以采用超标量或向量结构来改善性能。标量处理机在每个周期内只发射一条指令并要求周期只完成从流水线来的一条指令。而在超标量处理机中，使用了多指令流水线，每个周期要发射多条指令并产生多个结果。由于希望程序中有许多的指令级并行性，因此超标量处理机更要依靠优化编译器去开发并行性。VL1W结构是将水平微码和超标量处理这两种普遍采用的概念结合起来产生的。典型的超长指令字VL1W机器指令字长度有数百位。在VLlW处理机中，多个功能部件是并发工作的，所有的功能部件共享使用公用大型寄存器堆，由功能部件同时执行的各种操作是用VL1W指令来同步的，每条指令可指定多个操作。VL1W指令译码比超标量指令容易，但在开发不同数量的并行性时总是需要不同的指令系统。VL1W主要是开发标量操作之间的并行性，它的成功与否很大程度取决于代码压缩的效率，其结构和任何传统的通用处理机完全不兼容。即使同一结构的不同实现也不大可能做到彼此二进制兼容。VL1W的主要优点在于它的硬件结构和指令系统简单，在科学应用领域可以发挥良好作用，但在一般应用场合可能并不很好用。向量处理机对数组执行向量指令，每条指令都包含一串重复的操作。它是专门设计用来完成向量运算的协处理机，通常用于多流水线超级计算机中。向量处理机可以利用循环级展开所得的并行性，它可以附属于任何标量处理机。专用的向量流水线可以在循环控制中消除某些软件开销，它的效果与优化编译器将顺序代码向量化的性能很有关系。从理论上说，向量机可以具有和超标量处理机同样的性能，因此可以说向量机的并行性与超标量机相同。符号处理机是为AI应用而研制的，已用于定理证明、模式识别、专家系统、知识工程、文本检索、科学以及机器智能等许多应用领域。在这些应用中，数据和知识表达式、原语操作、算法特性、存储器、I/0和通信以及专用的结构特性与数值计算是不一样的，符号处理机也称为逻辑程序设计语言处理机、表处理语言处理机或符号变换器。符号处理并不和数值数据打交道，它处理的是逻辑程序、符号表、对象、剧本、黑板、产生式系统、语义网络、框架以及人工神经网络等问题。这些操作需要专门的指令系统，通常不使用浮点操作。2．存储器：存储设备按容量和存取时间从低到高可分为寄存器、高速缓存、主存储器、磁盘设备和磁带机五个层次。较低层存储设备与较高层的相比，存取速度较快、容量较小，每字节成本较高、带宽较宽、传输单位较小。存放在存储器层次结构中的信息满足三个重要特性：包含性、一致性和局部性。所谓包含性，指的是一个信息字的复制品可以在比它高的所有层中找到，而如果在高层中丢失了一个信息，则在比它低的所有层中此信息也将丢失。CPU和高速缓存之间的信息传送是按字进行的，高速缓存和主存储器间用块作为数据传送的基本单位，主存和磁盘之间又是以页面为基本单位来传送信息的，而在磁盘和磁带机之间的数据传送则是按文件级处理的。所谓一致性要求的是同一个信息项与后继存储器层次上的副本是一致的。也就是说，如果在高速缓存中的一个字被修改过，那么在所有更高层上该字的副本也必须立即或最后加以修改。为了尽量减少存储器层次结构的有效存取时间，通常把频繁使用的信息放在较低层次。维护存储器层次结构一致性一般有两种策略，一种是写直达策略，也就是如果，则立即在所有高层存储器中进行同样的修改；另一种是写回策略，也就是在较低层中对信息进行修改后并不立即在高层存储器中进行相应的修改，而是等到该信息将被替换或将从低层中消失时才在所有高层存储器中进行同样的修改。甚至可以将写直达和写回策略的优点结合起来，形成写一次协议来维护存储器的一致性。存储器的层次结构是在一种程序行为——访问的局部性基础上开发出来的。主要有时间局部性、空间局部性和顺序局部性。时间局部性指的是最近的访问项很可能在不久的将来再次被访问。它往往会引起对最近使用区域的集中访问。空间局部性表示一种趋势，指的是一个进程访问的各项其地址彼此很近。顺序局部性指的是在典型程序中，除非是转移指令，一般指令都是顺序执行的。在多处理机系统中一般使用共享存储器。对共享存储器的组织一般采用低位交叉、高位交叉、高低位交叉三种方法。低位交叉又称并发存取，它是把相邻的地址放在相邻的存储器模块中，在访问时不容易产生冲突，并行性较好，但可靠性容错能力和扩展性均较差。高位交叉又称允许同时存取，它是把相邻地址分配到同一个存储器模块中，可靠性、容错能力和扩展性均较强，但访问时易产生冲突，带宽较窄，并行性较差。高低位交叉存取又称C—s存取，它是结合了高位交叉和低位交叉两种方法的优点，既解决了冲突问题，又能有效地提高容错能力和并行性，最适合于向量处理机结构。3．流水线：流水线技术主要有指令流水线技术和运算流水线技术两种。指令流水线技术主要目的是要提高计算机的运行效率和吞吐率。它主要通过设置预取指令缓冲区、设置多功能部件、进行内部数据定向、采取适当的指令调度策略来实现。指令调度的策略主要有静态和动态两种，静态词度是基于软件的，主要由编译器完成，动态词度是基于硬件的，主要是通过硬件技术进行。运算流水线主要有单功能流水线和多功能流水线两种。其中多功能流水线又可分为静态流水线和动态流水线。静态流水线技术只用来实现确定的功能，而动态流水线可以在不同时间重新组合，实现不同的功能，它除流线连接外，还允许前馈和反馈连接，因此也称为非线性流水线。这些前馈和反馈连接使得进入流水线的相继事件的词度变得很不简单。由于这些连接，流水线不一定从最后一段输出。根据不同的数据流动模式，人们可以用同一条流水线求得不同功能的值[1]。并行计算机发展简述播报编辑40年代开始的现代计算机发展历程可以分为两个明显的发展时代：串行计算时代、并行计算时代。每一个计算时代都从体系结构发展开始，接着是系统软件（特别是编译器与操作系统）、应用软件，最后随着问题求解环境的发展而达到顶峰。创建和使用并行计算机的主要原因是因为并行计算机是解决单处理器速度瓶颈的最好方法之一。并行计算机是由一组处理单元组成的，这组处理单元通过相互之间的通信与协作，以更快的速度共同完成一项大规模的计算任务。因此，并行计算机的两个最主要的组成部分是计算节点和节点间的通信与协作机制。并行计算机体系结构的发展也主要体现在计算节点性能的提高以及节点间通信技术的改进两方面。60年代初期，由于晶体管以及磁芯存储器的出现，处理单元变得越来越小，存储器也更加小巧和廉价。这些技术发展的结果导致了并行计算机的出现，这一时期的并行计算机多是规模不大的共享存储多处理器系统，即所谓大型主机（Mainframe）。IBM360是这一时期的典型代表。到了60年代末期，同一个处理器开始设置多个功能相同的功能单元，流水线技术也出现了。与单纯提高时钟频率相比，这些并行特性在处理器内部的应用大大提高了并行计算机系统的性能。伊利诺依大学和Burroughs公司此时开始实施IlliacIV计划，研制一台64个CPU的SIMD主机系统，它涉及到硬件技术、体系结构、I/O设备、操作系统、程序设计语言直至应用程序在内的众多研究课题。不过，当一台规模大大缩小了的16CPU系统终于在1975年面世时，整个计算机界已经发生了巨大变化。首先是存储系统概念的革新，提出虚拟存储和缓存的思想。IBM360/85系统与360/91是属于同一系列的两个机型，360/91的主频高于360/85，所选用的内存速度也较快，并且采用了动态调度的指令流水线；但是，360/85的整体性能却高于360/91，唯一的原因就是前者采用了缓存技术，而后者则没有。其次是半导体存储器开始代替磁芯存储器。最初，半导体存储器只是在某些机器被用作缓存，而CDC7600则率先全面采用这种体积更小、速度更快、可以直接寻址的半导体存储器，磁芯存储器从此退出了历史舞台。与此同时，集成电路也出现了，并迅速应用到了计算机中。元器件技术的这两大革命性突破，使得IlliacIV的设计者们在底层硬件以及并行体系结构方面提出的种种改进都大为逊色。1976年CRAY-1问世以后，向量计算机从此牢牢地控制着整个高性能计算机市场15年。CRAY-1对所使用的逻辑电路进行了精心的设计，采用了我们如今称为RISC的精简指令集，还引入了向量寄存器，以完成向量运算。这一系列全新技术手段的使用，使CRAY-1的主频达到了80MHz。微处理器随着机器的字长从4位、8位、16位一直增加到32位，其性能也随之显著提高。正是因为看到了微处理器的这种潜力，卡内基-梅隆大学开始在当时流行的DECPDP11小型计算机的基础上研制成功一台由16个PDP11/40处理机通过交叉开关与16个共享存储器模块相连接而成的共享存储多处理器系统C.mmp。从80年代开始，微处理器技术一直在高速前进。稍后又出现了非常适合于SMP方式的总线协议，而伯克利加州大学则对总线协议进行了扩展，提出了Cache一致性问题的处理方案。从此，C.mmp开创出的共享存储多处理器之路越走越宽；现在，这种体系结构已经基本上统治了服务器和桌面工作站市场。同一时期，基于消息传递机制的并行计算机也开始不断涌现。80年代中期，加州理工成功地将64个i8086/i8087处理器通过超立方体互连结构连结起来。此后，便先后出现了InteliPSC系列、INMOSTransputer系列，IntelParagon以及IBMSP的前身Vulcan等基于消息传递机制的并行计算机。80年代末到90年代初，共享存储器方式的大规模并行计算机又获得了新的发展。IBM将大量早期RISC微处理器通过蝶形互连网络连结起来。人们开始考虑如何才能在实现共享存储器缓存一致的同时，使系统具有一定的可扩展性（Scalability）。90年代初期，斯坦福大学提出了DASH计划，它通过维护一个保存有每一缓存块位置信息的目录结构来实现分布式共享存储器的缓存一致性。后来，IEEE在此基础上提出了缓存一致性协议的标准。90年代以来，主要的几种体系结构开始走向融合。属于数据并行类型的CM-5除大量采用商品化的微处理器以外，也允许用户层的程序传递一些简单的消息；CRAYT3D是一台NUMA结构的共享存储型并行计算机，但是它也提供了全局同步机制、消息队列机制，并采取了一些减少消息传递延迟的技术。随着商品化微处理器、网络设备的发展，以及MPI/PVM等并行编程标准的发布，机群架构的并行计算机出现。IBMSP2系列机群系统就是其中的典型代表。在这些系统中，各个节点采用的都是标准的商品化计算机，它们之间通过高速网络连接起来。越来越多的并行计算机系统采用商品化的微处理器加上商品化的互连网络构造，这种分布存储的并行计算机系统称为机群。国内几乎所有的高性能计算机厂商都生产这种具有极高性能价格比的高性能计算机，并行计算机就进入了一个新的时代，并行计算的应用达到了前所未有的广度和深度。并行计算机随着微处理芯片的发展，已经进入了一个新时代。并行计算机的性能已经突破20PFLOPS，正在向百亿亿次发展。我国并行计算机的研制已经走在世界前列。2003年由联想公司生产的深腾6800在2003年11月世界TOP500排名中位列第14名，2004年曙光公司生产的曙光4000A在2004年6月的世界TOP500排名中位列第10名，这是我国公开发布的高性能计算机在世界TOP500中首次进入前十名，这标志着我国在并行计算机系统的研制和生产中已经赶上了国际先进水平，为提高我国的科学研究水平奠定了物质基础。2013年国际超级计算机大会最新发布的世界超级计算机500强排名中，国防科技大学研制的天河二号超级计算机系统，以峰值计算速度每秒5.49亿亿次、持续计算速度每秒3.39亿亿次双精度浮点运算的优异性能位居榜首。从TOP500的前10名来看，美国仍然是超级计算机的最大拥有者。按照世界TOP500的统计数据来分析，美国在计算能力上占有近全世界的一半，在TOP500中的所有计算机中拥有的数量超过50%[3]。指令集：简介播报编辑在计算机中，指示计算机硬件执行某种运算、处理功能的命令称为指令。指令是计算机运行的最小的功能单位，而硬件的作用是完成每条指令规定的功能。一台计算机上全部指令的集合，就是这台计算机的指令系统。指令系统也称指令集，是这台计算机全部功能的体现。而人们设计计算机首要考虑的是它拥有的功能，也就是首先要按功能档次设计指令集，然后按指令集的要求在硬件上实现。指令系统不仅仅是指令的集合，还包括全部指令的指令格式、寻址方式和数据形式。所以，各计算机执行的指令系统不仅决定了机器所要求的能力，而且也决定了指令的格式和机器的结构。反过来说，不同结构的机器和不同的指令格式应该具有与之相匹配的指令系统。为此，设计指令系统时，要对指令格式、类型及操作功能给予应有的重视。软件是为了使用计算机而编写的各种系统和用户的程序，程序由一个序列的计算机指令组成。从这个角度上说，指令是用于设计程序的一种计算机语言单位[2]。计算机的指令系统是指一台计算机上全部指令的集合，也称计算机的指令集。指令系统包括指令格式、寻址方式和数据形式。一台计算机的指令系统反映了该计算机的全部功能，机器类型不同，其指令系统也不同，因而功能也不同。指令系统的设置和机器的硬件结构密切相关，一台计算机要有较好的性能，必须设计功能齐全、通用性强、内含丰富的指令系统，这就需要复杂的硬件结构来支持[2]。常见的指令集有：Intel的x86，EM64T，MMX，SSE，SSE2，SSE3，SSSE3(SuperSSE3)，SSE4A，SSE4.1，SSE4.2，AVX，AVX2，AVX-512，VMX等指令集；和AMD的x86，x86-64，3D-Now!指令集。类型播报编辑SSE指令集由于MMX指令并没有带来3D游戏性能的显著提升，1999年Intel公司在PentiumIIICPU产品中推出了数据流单指令序列扩展指令（SSE）。SSE兼容MMX指令，它可以通过SIMD（单指令多数据技术）和单时钟周期并行处理多个浮点来有效地提高浮点运算速度。在MMX指令集中,借用了浮点处理器的8个寄存器，这样导致了浮点运算速度降低。而在SSE指令集推出时，Intel公司在PentiumIIICPU中增加了8个128位的SSE指令专用寄存器。而且SSE指令寄存器可以全速运行，保证了与浮点运算的并行性。SSE2指令集在Pentium4CPU中，Intel公司开发了新指令集SSE2。这一次新开发的SSE2指令一共144条，包括浮点SIMD指令、整形SIMD指令、SIMD浮点和整形数据之间转换、数据在MMX寄存器中转换等几大部分。其中重要的改进包括引入新的数据格式，如：128位SIMD整数运算和64位双精度浮点运算等。为了更好地利用高速缓存。另外，在Pentium4中还新增加了几条缓存指令，允许程序员控制已经缓存过的数据。SSE3指令集相对于SSE2，SSE3又新增加了13条新指令，此前它们被统称为pni(prescottnewinstructions)。13条指令中，一条用于视频解码，两条用于线程同步，其余用于复杂的数学运算、浮点到整数转换和SIMD浮点运算。SSE4指令集SSE4又增加了50条新的增加性能的指令，这些指令有助于编译、媒体、字符/文本处理和程序指向加速。SSE4指令集将作为Intel公司未来“显著视频增强”平台的一部分。该平台的其他视频增强功能还有ClearVideo技术（CVT）和统一显示接口（UDI）支持等，其中前者是对ATiAVIVO技术的回应，支持高级解码、后处理和增强型3D功能。3DNow!扩展指令集3DNow!指令集是AMD公司1998年开发的多媒体扩展指令集，共有21条指令。针对MMX指令集没有加强浮点处理能力的弱点，重点提高了AMD公司K6系列CPU对3D图形的处理能力。由于指令有限，3DNow!指令集主要用于3D游戏，而对其他商业图形应用处理支持不足。3DNow!+指令集：在原有的指令集基础上，增加到52条指令，其中包含了部分SSE指令，该指令集主要用于新型的AMDCPU上。X86指令集要知道什么是指令集，要从X86架构的CPU说起。X86指令集是Intel为其第一块16位CPU(i8086)专门开发的，IBM1981年推出的世界第一台PC机中的CPU—i8088(i8086简化版)使用的也是X86指令，同时电脑中为提高浮点数据处理能力而增加的X87芯片系列数学协处理器则另外使用X87指令，图示以后就将X86指令集和X87指令集统称为X86指令集。虽然随着CPU技术的不断发展，Intel陆续研制出更新型的i80386、i80486，但为了保证电脑能继续运行以往开发的各类应用程序以保护和继承丰富的软件资源，所以Intel公司所生产的所有CPU仍然继续使用X86指令集，所以它的CPU仍属于X86系列。由于IntelX86系列及其兼容CPU都使用X86指令集，所以就形成了庞大的X86系列及兼容CPU阵容。EM64T指令集Intel公司的EM64T（ExtendedMemory64Technology）即64位内存扩展技术。该技术为服务器和工作站平台应用提供扩充的内存寻址能力，拥有更多的内存地址空间，可带来更大的应用灵活性，特别有利于提升音频视频编辑、CAD设计等复杂工程软件及游戏软件的应用。常说的64位指的是AMD公司出的64位CPU，而EM64T则是Intel公司按照自己的意思理解出来的64位，也就是和AMD公司的64位对应的另一种叫法。RISC指令集RISC指令集是以后高性能CPU的发展方向。它与传统的CISC(复杂指令集)相对。相比而言，RISC的指令格式统一，种类比较少，寻址方式也比复杂指令集少。使用RISC指令集的体系结构主要有ARM、MIPS。MIPS指令集是最早实现商用的精简指令集（RISC）之一，上个世纪80年代初由斯坦福大学的研究小组研发，并在1984年成立MIPS计算机公司[3]。随后MIPS成为上世纪90年代最流行的指令集，一度与x86和ARM指令集齐名。RISC具有设计更简单、设计周期更短等优点，并可以应用更多先进的技术，开发更快的下一代处理器。MIPS是出现最早的商业RISC架构芯片之一，新的架构集成了所有原来MIPS指令集，并增加了许多更强大的功能。随着移动互联网的兴起，MIPS指令集逐渐衰落，公司也多次辗转被收购。AVX指令集IntelAVX指令集在SIMD计算性能增强的同时也沿用了的MMX/SSE指令集。不过MMX/SSE的不同点在于增强的AVX指令，从指令的格式上就发生了很大的变化。x86(IA-32/Intel64)架构的基础上增加了prefix(Prefix)，所以实现了新的命令，也使更加复杂的指令得以实现，从而提升了x86CPU的性能。AVX并不是x86CPU的扩展指令集，可以实现更高的效率，同时和CPU硬件兼容性也好，并且也有着足够的扩展空间，这都和其全新的命令格式系统有关。更加流畅的架构就是AVX发展的方向，换言之，就是摆脱传统x86的不足，在SSE指令的基础上AVX也使SSE指令接口更加易用。针对AVX的最新的命令编码系统，Intel也给出了更加详细的介绍，其中包括了大幅度扩充指令集的可能性。比如SandyBridge所带来的融合了乘法的双指令支持。从而可以更加容易地实现512bits和1024bits的扩展。而在2008年末到2009年推出的meniikoaCPU“Larrabee(LARAB)”处理器，就会采用AVX指令集。从地位上来看AVX也开始了Intel处理器指令集的新篇章。AT指令集在移动卫星通信中的应用播报编辑AT命令处理器的实现架构AT命令集是由贺氏公司（Hayes）发明，贺氏公司起初是一家生产拨号调制解调器的公司，而AT命令集最初的用途正是为了控制拨号调制解调器，其控制协议采用文本格式，且每条指令以AT打头，AT指令集因此得名。随着技术的不断进步，低速的拨号调制解调器逐步开始满足不了高带宽、高速率的应用需求，因此逐步被市场所淘汰。贺氏公司也在这一技术升级换代的浪潮中所消失。但是AT指令却得以保存，其后，当时几家主要的移动电话生产商诺基亚、摩托罗拉、HP和爱立信基于贺氏AT指令加以延伸扩展，针对移动电话中的GSM模块控制，研制出了一套完整的AT指令。由此，之后GSM07.05标准、GSM07.07标准均将AT指令纳入其中。并且工业上常用PDU、GPRS控制等也均采用AT指令来进行实际的控制。因此，AT指令也成为了这些产品的事实标准。ATCoP，是ATCommandProcessor的缩写，它是负责软件实现AT指令的模块，我们对AT指令的新增和修改都是通过AT命令处理器来实现的。其具体流程为：当AT命令处理器接收到串口的AT命令，进行相应的解析工作，并根据具体的解析结果去AT命令表查找是否存在对应的处理选项，若找到对应的项，则继续执行相应的处理过程，并在处理结束后将得到的响应数据返回到串口，具体如图《AT命令处理器的实现架构》所示。SIO数据预处理模块的主要工作是将串口收到的AT命令先进行一个数据预处理，同时，将预处理所产生的非中断（null-terminated）命令行发送给AT命令解析模块。AT命令解析模块对传送来的非中断（null-terminated）命令行进行解析，并将每一个非中断命令行映射成一个token结构，并将此token结构放入到队列中，形成AT命令表，等待AT命令处理模块进行查找调用。AT命令处理模块处理AT命令时，对AT命令表中的token结构逐一进行查找，如果查找到匹配选项，则继续执行具体的处理函数，并将此token结构删除。AT命令响应产生模块主要是格式化解析AT命令产生的响应数据，并将此格式化的响应传送给数据终端设备（DataTerminalEquipment：数据终端设备）。AT命令处理器的容错机制为：一次只进行一条AT指令的处理，并且如果AT命令存在错误，在SIO数据预处理模块就会给出一个错误响应，并产生一个错误代码，不再对其进行处理。常规的卫星移动通信系统主要由卫星、卫星天线、功放及射频模块、信道模块以及用户组成。其中，地面站网络管理控制中心（NetworkControlCenter，NCC）负责对整个卫星网内的各卫星地面站设备进行入网、退网、建立卫星业务通道、各种业务流程等进行统一的管理控制。卫星地面站设备包括卫星控制信道、卫星业务信道、射频及功放设备、卫星收发天线等。它负担着整个卫星业务的业务流程控制，业务数据采集、调制解调等工作。卫星控制信道主要负责整个卫星地面站设备的入网、退网等控制信令的传输控制，卫星业务信道负责对需要发送的卫星业务数据或者卫星话音数据进行加密、调制解调成射频信号传输给射频设备，或者对接收到的射频信号进行调制解调、解密转变成卫星业务数据或话音数据。射频设备以及卫星收发天线主要负责对经过信道处理的卫星数据进行发送或者接收对端传输来的卫星射频信号。当卫星地面站设备1的卫星用户1想和卫星地面站设备N的用户N进行卫星通信时，用户1通过卫星电话终端或者卫星数据终端进行卫星业务发起，这时，卫星控制信道将对业务发起的控制信令进行处理，通过地面站网络管理控制中心，为两个卫星地面站设备建立空中链路业务通道，之后两个地面站的用户就可以进行需要的业务通信了。当通信结束时，一方用户进行挂机操作，卫星控制终端将会发起业务结束控制信令，拆除两个卫星地面站设备之间的卫星链路。通过前面的简介可以知道，在整个卫星移动通信过程中，由于卫星通信天生的时延等特性，要进行正常的卫星业务通信，对每个卫星地面站设备的入退网管控、话音或者卫星数据流程的发起、结束，卫星业务链路的建立、拆除等控制流程起着至关重要的作用，因此这里我们将简单可靠的AT指令集引入，作为卫星移动通信系统的控制协议。这里我们将卫星控制信道称之为AT命令解析器（ATCommandProcessor，AP），将卫星业务信道称之为信道处理器（ChannelProcessor，CP）在卫星控制信道中使用AT指令来进行具体对本地面站设备的的控制与解析、对卫星业务流程的发起管理与结束、以及对CP的设置与查询等指令。在CP中主要接收来自AP的一些参数的设置与查询命令，以及根据来自AP的AT指令进行业务通信的具体流程[4]。集成电路：综述播报编辑集成电路，英文为IntegratedCircuit，缩写为IC；顾名思义，就是把一定数量的常用电子元件，如电阻、电容、晶体管等，以及这些元件之间的连线，通过半导体工艺集成在一起的具有特定功能的电路。是20世纪50年代后期到60年代发展起来的一种新型半导体器件。它是经过氧化、光刻、扩散、外延、蒸铝等半导体制造工艺，把构成具有一定功能的电路所需的半导体、电阻、电容等元件及它们之间的连接导线全部集成在一小块硅片上，然后焊接封装在一个管壳内的电子器件。其封装外壳有圆壳式、扁平式或双列直插式等多种形式。集成电路技术包括芯片制造技术与设计技术，主要体现在加工设备，加工工艺，封装测试，批量生产及设计创新的能力上。为什么会产生集成电路？我们知道任何发明创造背后都是有驱动力的，而驱动力往往来源于问题。那么集成电路产生之前的问题是什么呢？我们看一下1946年在美国诞生的世界上第一台电子计算机，它是一个占地150平方米、重达30吨的庞然大物，里面的电路使用了17468只电子管、7200只电阻、10000只电容、50万条线，耗电量150千瓦[1]。显然，占用面积大、无法移动是它最直观和突出的问题；如果能把这些电子元件和连线集成在一小块载体上该有多好！我们相信，有很多人思考过这个问题，也提出过各种想法。典型的如英国雷达研究所的科学家达默，他在1952年的一次会议上提出：可以把电子线路中的分立元器件，集中制作在一块半导体晶片上，一小块晶片就是一个完整电路，这样一来，电子线路的体积就可大大缩小，可靠性大幅提高。这就是初期集成电路的构想，晶体管的发明使这种想法成为了可能，1947年在美国贝尔实验室制造出来了第一个晶体管，而在此之前要实现电流放大功能只能依靠体积大、耗电量大、结构脆弱的电子管。晶体管具有电子管的主要功能，并且克服了电子管的上述缺点，因此在晶体管发明后，很快就出现了基于半导体的集成电路的构想，也就很快发明出来了集成电路。杰克·基尔比（JackKilby）和罗伯特·诺伊斯（RobertNoyce）在1958~1959期间分别发明了锗集成电路和硅集成电路。现在，集成电路已经在各行各业中发挥着非常重要的作用，是现代信息社会的基石。集成电路的含义，已经远远超过了其刚诞生时的定义范围，但其最核心的部分，仍然没有改变，那就是“集成”，其所衍生出来的各种学科，大都是围绕着“集成什么”、“如何集成”、“如何处理集成带来的利弊”这三个问题来开展的。硅集成电路是主流，就是把实现某种功能的电路所需的各种元件都放在一块硅片上，所形成的整体被称作集成电路。对于“集成”，想象一下我们住过的房子可能比较容易理解：很多人小时候都住过农村的房子，那时房屋的主体也许就是三两间平房，发挥着卧室的功能，门口的小院子摆上一副桌椅，就充当客厅，旁边还有个炊烟袅袅的小矮屋，那是厨房，而具有独特功能的厕所，需要有一定的隔离，有可能在房屋的背后，要走上十几米……后来，到了城市里，或者乡村城镇化，大家都住进了楼房或者套房，一套房里面，有客厅、卧室、厨房、卫生间、阳台，也许只有几十平方米，却具有了原来占地几百平方米的农村房屋的各种功能，这就是集成。当然现如今的集成电路，其集成度远非一套房能比拟的，或许用一幢摩登大楼可以更好地类比：地面上有商铺、办公、食堂、酒店式公寓，地下有几层是停车场，停车场下面还有地基——这是集成电路的布局，模拟电路和数字电路分开，处理小信号的敏感电路与翻转频繁的控制逻辑分开，电源单独放在一角。每层楼的房间布局不一样，走廊也不一样，有回字形的、工字形的、几字形的——这是集成电路器件设计，低噪声电路中可以用折叠形状或“叉指”结构的晶体管来减小结面积和栅电阻。各楼层直接有高速电梯可达，为了效率和功能隔离，还可能有多部电梯，每部电梯能到的楼层不同——这是集成电路的布线，电源线、地线单独走线，负载大的线也宽；时钟与信号分开；每层之间布线垂直避免干扰；CPU与存储之间的高速总线，相当于电梯，各层之间的通孔相当于电梯间……特点播报编辑集成电路或称微电路（microcircuit）、微芯片（microchip）、芯片（chip）在电子学中是一种把电路（主要包括半导体装置，也包括被动元件等）小型化的方式，并通常制造在半导体晶圆表面上。前述将电路制造在半导体芯片表面上的集成电路又称薄膜（thin-film）集成电路。另有一种厚膜（thick-film）混成集成电路（hybridintegratedcircuit）是由独立半导体设备和被动元件，集成到衬底或线路板所构成的小型化电路。本文是关于单片（monolithic）集成电路，即薄膜集成电路。集成电路具有体积小，重量轻，引出线和焊接点少，寿命长，可靠性高，性能好等优点，同时成本低，便于大规模生产。它不仅在工、民用电子设备如收录机、电视机、计算机等方面得到广泛的应用，同时在军事、通讯、遥控等方面也得到广泛的应用。用集成电路来装配电子设备，其装配密度比晶体管可提高几十倍至几千倍，设备的稳定工作时间也可大大提高。分类播报编辑功能结构集成电路集成电路，又称为IC，按其功能、结构的不同，可以分为模拟集成电路、数字集成电路和数/模混合集成电路三大类。模拟集成电路又称线性电路,用来产生、放大和处理各种模拟信号（指幅度随时间变化的信号。例如半导体收音机的音频信号、录放机的磁带信号等），其输入信号和输出信号成比例关系。而数字集成电路用来产生、放大和处理各种数字信号（指在时间上和幅度上离散取值的信号。例如5G手机、数码相机、电脑CPU、数字电视的逻辑控制和重放的音频信号和视频信号）。制作工艺集成电路按制作工艺可分为半导体集成电路和膜集成电路。膜集成电路又分类厚膜集成电路和薄膜集成电路。集成度高低集成电路按集成度高低的不同可分为：SSIC小规模集成电路(SmallScaleIntegratedcircuits)MSIC中规模集成电路(MediumScaleIntegratedcircuits)LSIC大规模集成电路(LargeScaleIntegratedcircuits)VLSIC超大规模集成电路(VeryLargeScaleIntegratedcircuits)ULSIC特大规模集成电路(UltraLargeScaleIntegratedcircuits)GSIC巨大规模集成电路也被称作极大规模集成电路或超特大规模集成电路(GigaScaleIntegration)。导电类型不同集成电路按导电类型可分为双极型集成电路和单极型集成电路，他们都是数字集成电路。双极型集成电路的制作工艺复杂，功耗较大，代表集成电路有TTL、ECL、HTL、LST-TL、STTL等类型。单极型集成电路的制作工艺简单，功耗也较低，易于制成大规模集成电路，代表集成电路有CMOS、NMOS、PMOS等类型。按用途集成电路集成电路按用途可分为电视机用集成电路、音响用集成电路、影碟机用集成电路、录像机用集成电路、电脑（微机）用集成电路、电子琴用集成电路、通信用集成电路、照相机用集成电路、遥控集成电路、语言集成电路、报警器用集成电路及各种专用集成电路。1.电视机用集成电路包括行、场扫描集成电路、中放集成电路、伴音集成电路、彩色解码集成电路、AV/TV转换集成电路、开关电源集成电路、遥控集成电路、丽音解码集成电路、画中画处理集成电路、微处理器（CPU）集成电路、存储器集成电路等。2.音响用集成电路包括AM/FM高中频电路、立体声解码电路、音频前置放大电路、音频运算放大集成电路、音频功率放大集成电路、环绕声处理集成电路、电平驱动集成电路，电子音量控制集成电路、延时混响集成电路、电子开关集成电路等。3.影碟机用集成电路有系统控制集成电路、视频编码集成电路、MPEG解码集成电路、音频信号处理集成电路、音响效果集成电路、RF信号处理集成电路、数字信号处理集成电路、伺服集成电路、电动机驱动集成电路等。4.录像机用集成电路有系统控制集成电路、伺服集成电路、驱动集成电路、音频处理集成电路、视频处理集成电路。5.计算机集成电路，包括中央控制单元（CPU）、内存储器、外存储器、I/O控制电路等。6.通信集成电路7.专业控制集成电路按应用领域分集成电路按应用领域可分为标准通用集成电路和专用集成电路。按外形分集成电路按外形可分为圆形（金属外壳晶体管封装型，一般适合用于大功率）、扁平型（稳定性好，体积小）和双列直插型。简史播报编辑世界集成电路发展历史1947年：美国贝尔实验室的约翰·巴丁、布拉顿、肖克莱三人发明了晶体管，这是微电子技术发展中第一个里程碑；集成电路1950年：结型晶体管诞生1950年：ROhl和肖克莱发明了离子注入工艺1951年：场效应晶体管发明1956年：CSFuller发明了扩散工艺1958年：仙童公司RobertNoyce与德仪公司基尔比间隔数月分别发明了集成电路，开创了世界微电子学的历史；1960年：HHLoor和ECastellani发明了光刻工艺1962年：美国RCA公司研制出MOS场效应晶体管1963年：F.M.Wanlass和C.T.Sah首次提出CMOS技术，今天，95%以上的集成电路芯片都是基于CMOS工艺1964年：Intel摩尔提出摩尔定律，预测晶体管集成度将会每18个月增加1倍1966年：美国RCA公司研制出CMOS集成电路，并研制出第一块门阵列（50门），为现如今的大规模集成电路发展奠定了坚实基础，具有里程碑意义1967年：应用材料公司（AppliedMaterials）成立，现已成为全球最大的半导体设备制造公司1971年：Intel推出1kb动态随机存储器（DRAM），标志着大规模集成电路出现1971年：全球第一个微处理器4004由Intel公司推出，采用的是MOS工艺，这是一个里程碑式的发明1974年：RCA公司推出第一个CMOS微处理器18021976年：16kbDRAM和4kbSRAM问世1978年：64kb动态随机存储器诞生，不足0.5平方厘米的硅片上集成了14万个晶体管，标志着超大规模集成电路（VLSI）时代的来临1979年：Intel推出5MHz8088微处理器，之后，IBM基于8088推出全球第一台PC1981年：256kbDRAM和64kbCMOSSRAM问世1984年：日本宣布推出1MbDRAM和256kbSRAM1985年：80386微处理器问世，20MHz1988年：16MDRAM问世，1平方厘米大小的硅片上集成有3500万个晶体管，标志着进入超大规模集成电路（VLSI）阶段1989年：1MbDRAM进入市场1989年：486微处理器推出，25MHz，1μm工艺，后来50MHz芯片采用0.8μm工艺1992年：64M位随机存储器问世1993年：66MHz奔腾处理器推出，采用0.6μm工艺集成电路1995年：PentiumPro,133MHz，采用0.6-0.35μm工艺；1997年：300MHz奔腾Ⅱ问世，采用0.25μm工艺1999年：奔腾Ⅲ问世，450MHz，采用0.25μm工艺，后采用0.18μm工艺2000年：1GbRAM投放市场2000年：奔腾4问世，1.5GHz，采用0.18μm工艺2001年：Intel宣布2001年下半年采用0.13μm工艺。2003年：奔腾4E系列推出，采用90nm工艺。2005年：intel酷睿2系列上市，采用65nm工艺。2007年：基于全新45纳米High-K工艺的intel酷睿2E7/E8/E9上市。2009年：intel酷睿i系列全新推出，创纪录采用了领先的32纳米工艺，并且下一代22纳米工艺正在研发。我国集成电路发展历史我国集成电路产业诞生于六十年代，共经历了三个发展阶段：1965年-1978年：以计算机和军工配套为目标，以开发逻辑电路为主要产品，初步建立集成电路工业基础及相关设备、仪器、材料的配套条件1978年-1990年：主要引进美国二手设备，改善集成电路装备水平，在“治散治乱”的同时，以消费类整机作为配套重点，较好地解决了彩电集成电路的国产化1990年-2000年：以908工程、909工程为重点，以CAD为突破口，抓好科技攻关和北方科研开发基地的建设，为信息产业服务，集成电路行业取得了新的发展。集成电路产业是对集成电路产业链各环节市场销售额的总体描述，它不仅仅包含集成电路市场，也包括IP核市场、EDA市场、芯片代工市场、封测市场，甚至延伸至设备、材料市场。集成电路产业不再依赖CPU、存储器等单一器件发展，移动互联、三网融合、多屏互动、智能终端带来了多重市场空间，商业模式不断创新为市场注入新活力。目前我国集成电路产业已具备一定基础，多年来我国集成电路产业所聚集的技术创新活力、市场拓展能力、资源整合动力以及广阔的市场潜力，为产业在未来5年～10年实现快速发展、迈上新的台阶奠定了基础。检测常识1、检测前要了解集成电路及其相关电路的工作原理检查和修理集成电路前首先要熟悉所用集成电路的功能、内部电路、主要电气参数、各引脚的作用以及引脚的正常电压、波形与外围元件组成电路的工作原理。2、测试避免造成引脚间短路电压测量或用示波器探头测试波形时，避免造成引脚间短路，最好在与引脚直接连通的外围印刷电路上进行测量。任何瞬间的短路都容易损坏集成电路，尤其在测试扁平型封装的CMOS集成电路时更要加倍小心。3、严禁在无隔离变压器的情况下，用已接地的测试设备去接触底板带电的电视、音响、录像等设备严禁用外壳已接地的仪器设备直接测试无电源隔离变压器的电视、音响、录像等设备。虽然一般的收录机都具有电源变压器，当接触到较特殊的尤其是输出功率较大或对采用的电源性质不太了解的电视或音响设备时，首先要弄清该机底盘是否带电，否则极易与底板带电的电视、音响等设备造成电源短路，波及集成电路，造成故障的进一步扩大。4、要注意电烙铁的绝缘性能不允许带电使用烙铁焊接，要确认烙铁不带电，最好把烙铁的外壳接地，对MOS电路更应小心，能采用6~8V的低压电烙铁就更安全。5、要保证焊接质量焊接时确实焊牢，焊锡的堆积、气孔容易造成虚焊。焊接时间一般不超过3秒钟，烙铁的功率应用内热式25W左右。已焊接好的集成电路要仔细查看，最好用欧姆表测量各引脚间有否短路，确认无焊锡粘连现象再接通电源。6、不要轻易断定集成电路的损坏不要轻易地判断集成电路已损坏。因为集成电路绝大多数为直接耦合，一旦某一电路不正常，可能会导致多处电压变化，而这些变化不一定是集成电路损坏引起的，另外在有些情况下测得各引脚电压与正常值相符或接近时，也不一定都能说明集成电路就是好的。因为有些软故障不会引起直流电压的变化。7、测试仪表内阻要大测量集成电路引脚直流电压时，应选用表头内阻大于20KΩ/V的万用表，否则对某些引脚电压会有较大的测量误差。8、要注意功率集成电路的散热功率集成电路应散热良好，不允许不带散热器而处于大功率的状态下工作。9、引线要合理如需要加接外围元件代替集成电路内部已损坏部分，应选用小型元器件，且接线要合理以免造成不必要的寄生耦合，尤其是要处理好音频功放集成电路和前置放大电路之间的接地端。集成电路型号各部分的意义第0部分第一部分第二部分第三部分第四部分符号意义符合意义意义符号意义符合意义CC表示中国制造TTTL电路用数字表示器件的系列代号C0~70℃F多层陶瓷扁平HHTL电路G‐25~70℃B塑料扁平EECL电路L‐24~85℃H黑瓷扁平CCMOS电路E‐40~85℃D多层陶瓷双列直插M存储器R‐55~85℃J黑瓷双列直插&micro;微型机电路M‐55~125℃P塑料双列直插F线性放大器S塑料单列直插W稳定器K金属菱形B非线性电路T金属圆形J接口电路C陶瓷芯片载体ADA/D转换器E塑料芯片载体DAD/A转换器G网络针栅陈列D音响、电视电路SC通信专用电路SS敏感电路SW钟表电路例如：肖特基4输入与非门CT54S20MDC—符合国家标准T—TTL电路54S20—肖特基双4输入与非门M—‐55~125℃D—多层陶瓷双列直插封装1、BGA(ballgridarray)集成电路球形触点阵列，表面贴装型封装之一。在印刷基板的背面按阵列方式制作出球形凸点用以代替引脚，在印刷基板的正面装配LSI芯片，然后用模压树脂或灌封方法进行密封。也称为凸点阵列载体(PAC)。引脚可超过200，是多引脚LSI用的一种封装。封装本体也可做得比QFP(四侧引脚扁平封装)小。例如，引脚中心距为1.5mm的360引脚BGA仅为31mm见方；而引脚中心距为0.5mm的304引脚QFP为40mm见方。而且BGA不用担心QFP那样的引脚变形问题（见有图所示）。2、BQFP(quadflatpackagewithbumper)带缓冲垫的四侧引脚扁平封装。QFP封装之一，在封装本体的四个角设置突起(缓冲垫)以防止在运送过程中引脚发生弯曲变形。美国半导体厂家主要在微处理器和ASIC等电路中采用此封装。引脚中心距0.635mm，引脚数从84到196左右(见QFP)。3、C－(ceramic)表示陶瓷封装的记号。例如，CDIP表示的是陶瓷DIP。是在实际中经常使用的记号。4、Cerdip用玻璃密封的陶瓷双列直插式封装，用于ECLRAM，DSP(数字信号处理器)等电路。带有玻璃窗口的Cerdip用于紫外线擦除型EPROM以及内部带有EPROM的微机电路等。引脚中心距2.54mm，引脚数从8到42。在日本，此封装表示为DIP－G(G即玻璃密封的意思)。5、Cerquad集成电路表面贴装型封装之一，即用下密封的陶瓷QFP，用于封装DSP等的逻辑LSI电路。带有窗口的Cerquad用于封装EPROM电路。散热性比塑料QFP好，在自然空冷条件下可容许1.5～2W的功率。但封装成本比塑料QFP高3～5倍。引脚中心距有1.27mm、0.8mm、0.65mm、0.5mm、0.4mm等多种规格。引脚数从32到368。带引脚的陶瓷芯片载体，表面贴装型封装之一，引脚从封装的四个侧面引出，呈丁字形。带有窗口的用于封装紫外线擦除型EPROM以及带有EPROM的微机电路等。此封装也称为QFJ、QFJ－G(见QFJ)。6、COB(chiponboard)板上芯片封装，是裸芯片贴装技术之一，半导体芯片交接贴装在印刷线路板上，芯片与基板的电气连接用引线缝合方法实现，芯片与基板的电气连接用引线缝合方法实现，并用树脂覆盖以确保可靠性。虽然COB是最简单的裸芯片贴装技术，但它的封装密度远不如TAB和倒片焊技术。7、DFP(dualflatpackage)双侧引脚扁平封装。是SOP的别称(见SOP)。以前曾有此称法，80年代后期已基本上不用。8、DIC(dualin-lineceramicpackage)陶瓷DIP(含玻璃密封)的别称(见DIP).9、DIL(dualin-line)DIP的别称(见DIP)。欧洲半导体厂家多用此名称。10、DIP(dualin-linepackage)双列直插式封装。插装型封装之一，引脚从封装两侧引出，封装材料有塑料和陶瓷两种。DIP是最普及的插装型封装，应用范围包括标准逻辑IC，存贮器LSI，微机电路等。引脚中心距2.54mm，引脚数从6到64。封装宽度通常为15.2mm。有的把宽度为7.52mm和10.16mm的封装分别称为skinnyDIP和slimDIP(窄体型DIP)。但多数情况下并不加区分，只简单地统称为DIP。另外，用低熔点玻璃密封的陶瓷DIP也称为cerdip(见cerdip)。11、DSO(dualsmallout-lint)双侧引脚小外形封装。SOP的别称(见SOP)。部分半导体厂家采用此名称。12、DICP(dualtapecarrierpackage)集成电路双侧引脚带载封装。TCP(带载封装)之一。引脚制作在绝缘带上并从封装两侧引出。由于利用的是TAB(自动带载焊接)技术，封装外形非常薄。常用于液晶显示驱动LSI，但多数为定制品。另外，0.5mm厚的存储器LSI簿形封装正处于开发阶段。在日本，按照EIAJ(日本电子机械工业)会标准规定，将DICP命名为DTP。13、DIP(dualtapecarrierpackage)同上。日本电子机械工业会标准对DTCP的命名(见DTCP)。14、FP(flatpackage)扁平封装。表面贴装型封装之一。QFP或SOP(见QFP和SOP)的别称。部分半导体厂家采用此名称。15、flip-chip倒焊芯片。裸芯片封装技术之一，在LSI芯片的电极区制作好金属凸点，然后把金属凸点与印刷基板上的电极区进行压焊连接。封装的占有面积基本上与芯片尺寸相同。是所有封装技术中体积最小、最薄的一种。但如果基板的热膨胀系数与LSI芯片不同，就会在接合处产生反应，从而影响连接的可靠性。因此必须用树脂来加固LSI芯片，并使用热膨胀系数基本相同的基板材料。16、FQFP(finepitchquadflatpackage)小引脚中心距QFP。通常指引脚中心距小于0.65mm的QFP(见QFP)。部分导导体厂家采用此名称。17、CPAC(globetoppadarraycarrier)美国Motorola公司对BGA的别称(见BGA)。18、CQFP(quadfiatpackagewithguardring)带保护环的四侧引脚扁平封装。塑料QFP之一，引脚用树脂保护环掩蔽，以防止弯曲变形。在把LSI组装在印刷基板上之前，从保护环处切断引脚并使其成为海鸥翼状(L形状)。这种封装在美国Motorola公司已批量生产。引脚中心距0.5mm，引脚数最多为208左右。19、H-(withheatsink)表示带散热器的标记。例如，HSOP表示带散热器的SOP。20、pingridarray(surfacemounttype)集成电路表面贴装型PGA。通常PGA为插装型封装，引脚长约3.4mm。表面贴装型PGA在封装的底面有陈列状的引脚，其长度从1.5mm到2.0mm。贴装采用与印刷基板碰焊的方法，因而也称为碰焊PGA。因为引脚中心距只有1.27mm，比插装型PGA小一半，所以封装本体可制作得不怎么大，而引脚数比插装型多(250～528)，是大规模逻辑LSI用的封装。封装的基材有多层陶瓷基板和玻璃环氧树脂印刷基数。以多层陶瓷基材制作封装已经实用化。21、JLCC(J-leadedchipcarrier)J形引脚芯片载体。指带窗口CLCC和带窗口的陶瓷QFJ的别称(见CLCC和QFJ)。部分半导体厂家采用的名称。22、LCC(Leadlesschipcarrier)无引脚芯片载体。指陶瓷基板的四个侧面只有电极接触而无引脚的表面贴装型封装。是高速和高频IC用封装，也称为陶瓷QFN或QFN－C(见QFN)。23、LGA(landgridarray)触点陈列封装。即在底面制作有阵列状态坦电极触点的封装。装配时插入插座即可。现已实用的有227触点(1.27mm中心距)和447触点(2.54mm中心距)的陶瓷LGA，应用于高速逻辑LSI电路。LGA与QFP相比，能够以比较小的封装容纳更多的输入输出引脚。另外，由于引线的阻抗小，对于高速LSI是很适用的。但由于插座制作复杂，成本高，90年代基本上不怎么使用。预计今后对其需求会有所增加。24、LOC(leadonchip)芯片上引线封装。LSI封装技术之一，引线框架的前端处于芯片上方的一种结构，芯片的中心附近制作有凸焊点，用引线缝合进行电气连接。与原来把引线框架布置在芯片侧面附近的结构相比，在相同大小的封装中容纳的芯片达1mm左右宽度。25、LQFP(lowprofilequadflatpackage)薄型QFP。指封装本体厚度为1.4mm的QFP，是日本电子机械工业会根据制定的新QFP外形规格所用的名称。26、L－QUAD陶瓷QFP之一。封装基板用氮化铝，基导热率比氧化铝高7～8倍，具有较好的散热性。封装的框架用氧化铝，芯片用灌封法密封，从而抑制了成本。是为逻辑LSI开发的一种封装，在自然空冷条件下可容许W3的功率。现已开发出了208引脚(0.5mm中心距)和160引脚(0.65mm中心距)的LSI逻辑用封装，并于1993年10月开始投入批量生产。27、MCM(multi-chipmodule)多芯片组件。将多块半导体裸芯片组装在一块布线基板上的一种封装。根据基板材料可分为MCM－L，MCM－C和MCM－D三大类。MCM－L是使用通常的玻璃环氧树脂多层印刷基板的组件。布线密度不怎么高，成本较低。MCM－C是用厚膜技术形成多层布线，以陶瓷(氧化铝或玻璃陶瓷)作为基板的组件，与使用多层陶瓷基板的厚膜混合IC类似。两者无明显差别。布线密度高于MCM－L。MCM－D是用薄膜技术形成多层布线，以陶瓷(氧化铝或氮化铝)或Si、Al作为基板的组件。布线密谋在三种组件中是最高的，但成本也高。28、MFP(miniflatpackage)小形扁平封装。塑料SOP或SSOP的别称(见SOP和SSOP)。部分半导体厂家采用的名称。29、MQFP(metricquadflatpackage)按照JEDEC(美国联合电子设备委员会)标准对QFP进行的一种分类。指引脚中心距为0.65mm、本体厚度为3.8mm～2.0mm的标准QFP(见QFP)。30、MQUAD(metalquad)美国Olin公司开发的一种QFP封装。基板与封盖均采用铝材，用粘合剂密封。在自然空冷条件下可容许2.5W～2.8W的功率。日本新光电气工业公司于1993年获得特许开始生产。31、MSP(minisquarepackage)QFI的别称(见QFI)，在开发初期多称为MSP。QFI是日本电子机械工业会规定的名称。34、OPMAC(overmoldedpadarraycarrier)模压树脂密封凸点陈列载体。美国Motorola公司对模压树脂密封BGA采用的名称(见BGA)。32、P－(plastic)表示塑料封装的记号。如PDIP表示塑料DIP。33、PAC(padarraycarrier)凸点陈列载体，BGA的别称(见BGA)。34、PCLP(printedcircuitboardleadlesspackage)印刷电路板无引线封装。日本富士通公司对塑料QFN(塑料LCC)采用的名称(见QFN)。引脚中心距有0.55mm和0.4mm两种规格。35、PFPF(plasticflatpackage)塑料扁平封装。塑料QFP的别称(见QFP)。部分LSI厂家采用的名称。36、PGA(pingridarray)集成电路陈列引脚封装。插装型封装之一，其底面的垂直引脚呈陈列状排列。封装基材基本上都采用多层陶瓷基板。在未专门表示出材料名称的情况下，多数为陶瓷PGA，用于高速大规模逻辑LSI电路。成本较高。引脚中心距通常为2.54mm，引脚数从64到447左右。为了为降低成本，封装基材可用玻璃环氧树脂印刷基板代替。也有64～256引脚的塑料PGA。另外，还有一种引脚中心距为1.27mm的短引脚表面贴装型PGA(碰焊PGA)。(见表面贴装型PGA)。37、piggyback驮载封装。指配有插座的陶瓷封装，形关与DIP、QFP、QFN相似。在开发带有微机的设备时用于评价程序确认操作。例如，将EPROM插入插座进行调试。这种封装基本上都是定制品，市场上不怎么流通。38、PLCC(plasticleadedchipcarrier)带引线的塑料芯片载体。表面贴装型封装之一。引脚从封装的四个侧面引出，呈丁字形，是塑料制品。美国德克萨斯仪器公司首先在64k位DRAM和256kDRAM中采用，90年代已经普及用于逻辑LSI、DLD(或程逻辑器件电路。引脚中心距1.27mm，引脚数从18到84。J形引脚不易变形，比QFP容易操作，但焊接后的外观检查较为困难。PLCC与LCC(也称QFN)相似。以前，两者的区别仅在于前者用塑料，后者用陶瓷。但现在已经出现用陶瓷制作的J形引脚封装和用塑料制作的无引脚封装(标记为塑料LCC、PCLP、P－LCC等)，已经无法分辨。为此，日本电子机械工业会于1988年决定，把从四侧引出J形引脚的封装称为QFJ，把在四侧带有电极凸点的封装称为QFN(见QFJ和QFN)。39、P－LCC(plasticteadlesschipcarrier)(plasticleadedchipcurrier)有时候是塑料QFJ的别称，有时候是QFN(塑料LCC)的别称(见QFJ和QFN)。部分LSI厂家用PLCC表示带引线封装，用P－LCC表示无引线封装，以示区别。40、QFH(quadflathighpackage)四侧引脚厚体扁平封装。塑料QFP的一种，为了防止封装本体断裂，QFP本体制作得较厚(见QFP)。部分半导体厂家采用的名称。41、QFI(quadflatI-leadedpackgac)四侧I形引脚扁平封装。表面贴装型封装之一。引脚从封装四个侧面引出，向下呈I字。也称为MSP(见MSP)。贴装与印刷基板进行碰焊连接。由于引脚无突出部分，贴装占有面积小于QFP。日立制作所为视频模拟IC开发并使用了这种封装。此外，日本的Motorola公司的PLLIC也采用了此种封装。引脚中心距1.27mm，引脚数从18于68。42、QFJ(quadflatJ-leadedpackage)四侧J形引脚扁平封装。表面贴装封装之一。引脚从封装四个侧面引出，向下呈J字形。是日本电子机械工业会规定的名称。引脚中心距1.27mm。材料有塑料和陶瓷两种。塑料QFJ多数情况称为PLCC(见PLCC)，用于微机、门陈列、DRAM、ASSP、OTP等电路。引脚数从18至84。陶瓷QFJ也称为CLCC、JLCC(见CLCC)。带窗口的封装用于紫外线擦除型EPROM以及带有EPROM的微机芯片电路。引脚数从32至84。43、QFN(quadflatnon-leadedpackage)集成电路四侧无引脚扁平封装。表面贴装型封装之一。90年代后期多称为LCC。QFN是日本电子机械工业会规定的名称。封装四侧配置有电极触点，由于无引脚，贴装占有面积比QFP小，高度比QFP低。但是，当印刷基板与封装之间产生应力时，在电极接触处就不能得到缓解。因此电极触点难于作到QFP的引脚那样多，一般从14到100左右。材料有陶瓷和塑料两种。当有LCC标记时基本上都是陶瓷QFN。电极触点中心距1.27mm。塑料QFN是以玻璃环氧树脂印刷基板基材的一种低成本封装。电极触点中心距除1.27mm外，还有0.65mm和0.5mm两种。这种封装也称为塑料LCC、PCLC、P－LCC等。44、QFP(quadflatpackage)四侧引脚扁平封装。表面贴装型封装之一，引脚从四个侧面引出呈海鸥翼(L)型。基材有陶瓷、金属和塑料三种。从数量上看，塑料封装占绝大部分。当没有特别表示出材料时，多数情况为塑料QFP。塑料QFP是最普及的多引脚LSI封装。不仅用于微处理器，门陈列等数字逻辑LSI电路，而且也用于VTR信号处理、音响信号处理等模拟LSI电路。引脚中心距有1.0mm、0.8mm、0.65mm、0.5mm、0.4mm、0.3mm等多种规格。0.65mm中心距规格中最多引脚数为304。日本将引脚中心距小于0.65mm的QFP称为QFP(FP)。但2000年后日本电子机械工业会对QFP的外形规格进行了重新评价。在引脚中心距上不加区别，而是根据封装本体厚度分为QFP(2.0mm～3.6mm厚)、LQFP(1.4mm厚)和TQFP(1.0mm厚)三种。另外，有的LSI厂家把引脚中心距为0.5mm的QFP专门称为收缩型QFP或SQFP、VQFP。但有的厂家把引脚中心距为0.65mm及0.4mm的QFP也称为SQFP，至使名称稍有一些混乱。QFP的缺点是，当引脚中心距小于0.65mm时，引脚容易弯曲。为了防止引脚变形，现已出现了几种改进的QFP品种。如封装的四个角带有树指缓冲垫的BQFP(见BQFP)；带树脂保护环覆盖引脚前端的GQFP(见GQFP)；在封装本体里设置测试凸点、放在防止引脚变形的专用夹具里就可进行测试的TPQFP(见TPQFP)。在逻辑LSI方面，不少开发品和高可靠品都封装在多层陶瓷QFP里。引脚中心距最小为0.4mm、引脚数最多为348的产品也已问世。此外，也有用玻璃密封的陶瓷QFP(见Gerqad)。45、QFP(FP)(QFPfinepitch)小中心距QFP。日本电子机械工业会标准所规定的名称。指引脚中心距为0.55mm、0.4mm、0.3mm等小于0.65mm的QFP(见QFP)。46、QIC(quadin-lineceramicpackage)陶瓷QFP的别称。部分半导体厂家采用的名称(见QFP、Cerquad)。47、QIP(quadin-lineplasticpackage)塑料QFP的别称。部分半导体厂家采用的名称(见QFP)。48、QTCP(quadtapecarrierpackage)四侧引脚带载封装。TCP封装之一，在绝缘带上形成引脚并从封装四个侧面引出。是利用TAB技术的薄型封装(见TAB、TCP)。49、QTP(quadtapecarrierpackage)四侧引脚带载封装。日本电子机械工业会于1993年4月对QTCP所制定的外形规格所用的名称(见TCP)。50、QUIL(quadin-line)QUIP的别称(见QUIP)。51、QUIP(quadin-linepackage)四列引脚直插式封装。引脚从封装两个侧面引出，每隔一根交错向下弯曲成四列。引脚中心距1.27mm，当插入印刷基板时，插入中心距就变成2.5mm。因此可用于标准印刷线路板。是比标准DIP更小的一种封装。日本电气公司在台式计算机和家电产品等的微机芯片中采用了些种封装。材料有陶瓷和塑料两种。引脚数64。52、SDIP(shrinkdualin-linepackage)收缩型DIP。插装型封装之一，形状与DIP相同，但引脚中心距(1.778mm)小于DIP(2.54mm)，因而得此称呼。引脚数从14到90。也有称为SH－DIP的。材料有陶瓷和塑料两种。53、SH－DIP(shrinkdualin-linepackage)同SDIP。部分半导体厂家采用的名称。54、SIL(singlein-line)SIP的别称(见SIP)。欧洲半导体厂家多采用SIL这个名称。55、SIMM(singlein-linememorymodule)单列存贮器组件。只在印刷基板的一个侧面附近配有电极的存贮器组件。通常指插入插座的组件。标准SIMM有中心距为2.54mm的30电极和中心距为1.27mm的72电极两种规格。在印刷基板的单面或双面装有用SOJ封装的1兆位及4兆位DRAM的SIMM已经在个人计算机、工作站等设备中获得广泛应用。至少有30～40%的DRAM都装配在SIMM里。56、SIP(singlein-linepackage)单列直插式封装。引脚从封装一个侧面引出，排列成一条直线。当装配到印刷基板上时封装呈侧立状。引脚中心距通常为2.54mm，引脚数从2至23，多数为定制产品。封装的形状各异。也有的把形状与ZIP相同的封装称为SIP。57、SK－DIP(skinnydualin-linepackage)DIP的一种。指宽度为7.62mm、引脚中心距为2.54mm的窄体DIP。通常统称为DIP(见DIP)。58、SL－DIP(slimdualin-linepackage)DIP的一种。指宽度为10.16mm，引脚中心距为2.54mm的窄体DIP。通常统称为DIP。59、SMD(surfacemountdevices)表面贴装器件。偶而，有的半导体厂家把SOP归为SMD(见SOP)。SOP的别称。世界上很多半导体厂家都采用此别称。(见SOP)。60、SOI(smallout-lineI-leadedpackage)I形引脚小外型封装。表面贴装型封装之一。引脚从封装双侧引出向下呈I字形，中心距1.27mm。贴装占有面积小于SOP。日立公司在模拟IC(电机驱动用IC)中采用了此封装。引脚数26。61、SOIC(smallout-lineintegratedcircuit)SOP的别称(见SOP)。国外有许多半导体厂家采用此名称。62、SOJ(SmallOut-LineJ-LeadedPackage)J形引脚小外型封装。表面贴装型封装之一。引脚从封装两侧引出向下呈J字形，故此得名。通常为塑料制品，多数用于DRAM和SRAM等存储器LSI电路，但绝大部分是DRAM。用SOJ封装的DRAM器件很多都装配在SIMM上。引脚中心距1.27mm，引脚数从20至40(见SIMM)。63、SQL(SmallOut-LineL-leadedpackage)按照JEDEC(美国联合电子设备工程委员会)标准对SOP所采用的名称(见SOP)。64、SONF(SmallOut-LineNon-Fin)无散热片的SOP。与通常的SOP相同。为了在功率IC封装中表示无散热片的区别，有意增添了NF(non-fin)标记。部分半导体厂家采用的名称(见SOP)。65、SOP(smallOut-Linepackage)小外形封装。表面贴装型封装之一，引脚从封装两侧引出呈海鸥翼状(L字形)。材料有塑料和陶瓷两种。另外也叫SOL和DFP。SOP除了用于存储器LSI外，也广泛用于规模不太大的ASSP等电路。在输入输出端子不超过10～40的领域，SOP是普及最广的表面贴装封装。引脚中心距1.27mm，引脚数从8～44。另外，引脚中心距小于1.27mm的SOP也称为SSOP；装配高度不到1.27mm的SOP也称为TSOP(见SSOP、TSOP)。还有一种带有散热片的SOP。66、SOW(SmallOutlinePackage(Wide-Jype))宽体SOP。部分半导体厂家采用的名称。制造从1930年代开始，元素周期表中的化学元素中的半导体被研究者如贝尔实验室的WilliamShockley认为是固态真空管的最可能的原料。从氧化铜到锗，再到硅，原料在1940到1950年代被系统的研究。今天，尽管元素周期表的一些III-V价化合物如砷化镓应用于特殊用途如：发光二极管，激光，太阳能电池和最高速集成电路，单晶硅成为集成电路主流的基层。创造无缺陷晶体的方法用去了数十年的时间。半导体IC制程，包括以下步骤，并重复使用：黄光(微影)蚀刻薄膜扩散CMP使用单晶硅晶圆（或III-V族，如砷化镓）用作基层。然后使用微影、扩散、CMP等技术制成MOSFET或BJT等组件，然后利用微影、薄膜、和CMP技术制成导线，如此便完成芯片制作。因产品性能需求及成本考量，导线可分为铝制程和铜制程。IC由很多重叠的层组成，每层由图像技术定义，通常用不同的颜色表示。一些层标明在哪里不同的掺杂剂扩散进基层（成为扩散层），一些定义哪里额外的离子灌输（灌输层），一些定义导体（多晶硅或金属层），一些定义传导层之间的连接（过孔或接触层）。所有的组件由这些层的特定组合构成。在一个自排列（CMOS）过程中，所有门层（多晶硅或金属）穿过扩散层的地方形成晶体管。电阻结构，电阻结构的长宽比，结合表面电阻系数，决定电阻。电容结构，由于尺寸限制，在IC上只能产生很小的电容。更为少见的电感结构，可以制作芯片载电感或由回旋器模拟。因为CMOS设备只引导电流在逻辑门之间转换，CMOS设备比双级组件消耗的电流少很多。随机存取存储器（randomaccessmemory）是最常见类型的集成电路，所以密度最高的设备是存储器，但即使是微处理器上也有存储器。尽管结构非常复杂－几十年来芯片宽度一直减少－但集成电路的层依然比宽度薄很多。组件层的制作非常像照相过程。虽然可见光谱中的光波不能用来曝光组件层，因为他们太大了。高频光子（通常是紫外线）被用来创造每层的图案。因为每个特征都非常小，对于一个正在调试制造过程的过程工程师来说，电子显微镜是必要工具。在使用自动测试设备（ATE）包装前，每个设备都要进行测试。测试过程称为晶圆测试或晶圆探通。晶圆被切割成矩形块，每个被称为“die”。每个好的die被焊在“pads”上的铝线或金线，连接到封装内，pads通常在die的边上。封装之后，设备在晶圆探通中使用的相同或相似的ATE上进行终检。测试成本可以达到低成本产品的制造成本的25%，但是对于低产出，大型和/或高成本的设备，可以忽略不计。在2005年，一个制造厂（通常称为半导体工厂，常简称fab，指fabricationfacility）建设费用要超过10亿美金，因为大部分操作是自动化的。发展趋势2001年到2010年这10年间，我国集成电路产量的年均增长率超过25%，集成电路销售额的年均增长率则达到23%。2010年国内集成电路产量达到640亿块，销售额超过1430亿元，分别是2001年的10倍和8倍。中国集成电路产业规模已经由2001年不足世界集成电路产业总规模的2%提高到2010年的近9%。中国成为过去10年世界集成电路产业发展最快的地区之一。国内集成电路市场规模也由2001年的1140亿元扩大到2010年的7350亿元，扩大了6.5倍。国内集成电路产业规模与市场规模之比始终未超过20%。如扣除集成电路产业中接受境外委托代工的销售额，则中国集成电路市场的实际国内自给率还不足10%，国内市场所需的集成电路产品主要依靠进口。近几年国内集成电路进口规模迅速扩大，2010年已经达到创纪录的1570亿美元，集成电路已连续两年超过原油成为国内最大宗的进口商品。与巨大且快速增长的国内市场相比，中国集成电路产业虽发展迅速但仍难以满足内需要求。当前以移动互联网、三网融合、物联网、云计算、智能电网、新能源汽车为代表的战略性新兴产业快速发展，将成为继计算机、网络通信、消费电子之后，推动集成电路产业发展的新动力。工信部预计，国内集成电路市场规模到2015年将达到12000亿元。我国集成电路产业发展的生态环境亟待优化，设计、制造、封装测试以及专用设备、仪器、材料等产业链上下游协同性不足，芯片、软件、整机、系统、应用等各环节互动不紧密。“十二五”期间，中国将积极探索集成电路产业链上下游虚拟一体化模式，充分发挥市场机制作用，强化产业链上下游的合作与协同，共建价值链。培育和完善生态环境，加强集成电路产品设计与软件、整机、系统及服务的有机连接，实现各环节企业的群体跃升，增强电子信息大产业链的整体竞争优势。2023年，问天实验舱元器件与组件舱外通用试验装置将开展大规模集成电路、新型半导体器件的空间环境效应试验[6]。发展对策建议1.创新性效率超越传统的成本性静态效率从理论上讲，商务成本属于成本性的静态效率范畴，在产业发展的初级阶段作用显著。外部商务成本的上升实际上是产业升级、创新驱动的外部动力。作为高新技术产业的上海集成电路产业，需要积极利用产业链完备、内部结网度较高、与全球生产网络有机衔接等集群优势，实现企业之间的互动共生的高科技产业机体的生态关系，有效保障并促进产业创业、创新的步伐。事实表明，20世纪80年代，虽然硅谷的土地成本要远高于128公路地区，但在硅谷建立的半导体公司比美国其他地方的公司开发新产品的速度快60%，交运产品的速度快40%。具体而言，就是硅谷地区的硬件和软件制造商结成了紧密的联盟，能最大限度地降低从创意到制造出产品等相关过程的成本，即通过技术密集关联为基本的动态创业联盟，降低了创业成本，从而弥补了静态的商务成本劣势[2]。2.准确的产品与市场定位许多归国创业的设计人才认为，中国的消费者是世界上最好的衣食父母，与欧美发达国家相比，我们的消费者对新产品充满好奇，一般不退货，基本无赔偿。这些特点为设计企业的创业、创新与发展提供了良好的市场机遇。企业要善于去发现产品应用，寻找市场[2]。设计公司扩张主要是受限于人才与产品定位。由于在人才团队、市场和产品定义方面的不足，初创公司不可能做大项目，不适合于做集聚型大项目。现有的大多数设计企业还是适合于分散型市场，主动去支持系统厂商，提供大量的服务。人力密集型业务项目不适合欧美公司，更适合我们。例如，在国内市场上，如果一个产品能出货300万颗，那么公司就会去做，国外企业则不可能去做它[2]。3.打造国际精英人才的“新故乡”，充分发挥海归人才优势海归人才在国外做了很多超前的技术开发研究，并且在全球一些顶尖公司内有产业经验，回国后从事很有需求的产品开发应用，容易成功。集成电路产业的研发就怕方向性错误与低水平重复，海归人才知道如何去做才能够成功[2]。“归国人才团队+海外工作经验+优惠政策扶持+风险投资”式上海集成电路产业发展的典型模式，这在张江高科技园区尤为明显。然而，由于国际社区建设滞后、户籍政策限制、个人所得税政策缺乏国际竞争力等多方面原因综合作用，张江仍然没有成为海外高级人才的安家落户、长期扎根的开放性、国际性高科技园区。留学生短期打算、“做做看”的“候鸟”观望气氛浓厚，不利于全球高级人才的集聚。要充分发挥张江所处的区位优势以及浦东综合配套改革试点的政策优势，将单纯吸引留学生变为吸引留学生、国外精英等高层次人才。通过科学城建设以及个人所得税率的国际化调整、落户政策的优化，发挥上海“海派文化”传统，将张江建设成为世界各国人才汇集、安居乐业的新故乡，大幅提升张江在高层次人才争夺中的国际竞争力[2]。4.重在积累，克服急功近利设计业的复杂度很高，需要强大的稳定的团队、深厚的积累。积累是一个不可逾越的发展过程。中国集成电路产业的发展如同下围棋，不能只争一时之短长，要比谁的气长，而不是谁的空多。集成电力产业人才尤其是设计人才供给问题长期以来是舆论界关注的热点，许多高校在专业与设置、人才培养方面急功近利，片面追随所谓社会热点和学业对口，导致学生的基本综合素质和人文科学方面的素养不够高，知识面过窄。事实上，众多设计企业普遍反映，他们招聘人才的标准并非是单纯的所谓专业对口，而是更注重基础知识和综合素质，他们普遍反映高校的教育太急功近利了[2]。5.促进企业间合作，促进产业链合作国内企业之间的横向联系少，外包刚刚起步，基本上每个设计企业都有自己的芯片，都在进行全面发展。这些因素都限制了企业的快速发展。要充分运用华南一些企业为国外做的解决方案，这样终端客户就可以直接将公司产品运用到原有解决方案上去。此外，设计企业要与方案商、通路商、系统厂商形成紧密的战略合作伙伴关系[2]。6.摒弃理想化的产学研模式产学研一体化一直被各界视为促进高新技术产业发展的良方，但实地调研结果暴露出人们在此方面存在着不切实际的幻想。笔者所调研的众多设计企业对高校帮助做产品不抱任何指望。公司项目要求的进度快，存在合作的时间问题；高校一般不具备可以使工厂能更有效利用厂房空间，也适用于研发中心的使用。新开发的空冷系统减少了对外部设施的依赖，可在任意位置安装设置，同时继续支持符合STC标准的各种T2000模块，满足各种测试的需要[2]。其他信息播报编辑晶体管发明并大量生产之后，各式固态半导体组件如二极管、晶体管等大量使用，取代了真空管在电路中的功能与角色。到了20世纪中后期半导体制造技术进步，使得集成电路成为可能。相对于手工组装电路使用个别的分立电子组件，集成电路可以把很大数量的微晶体管集成到一个小芯片，是一个巨大的进步。集成电路的规模生产能力，可靠性，电路设计的模块化方法确保了快速采用标准化IC代替了设计使用离散晶体管。IC对于离散晶体管有两个主要优势：成本和性能。成本低是由于芯片把所有的组件通过照相平版技术，作为一个单位印刷，而不是在一个时间只制作一个晶体管。性能高是由于组件快速开关，消耗更低能量，因为组件很小且彼此靠近。2006年，芯片面积从几平方毫米到350mm²，每mm²可以达到一百万个晶体管。第一个集成电路雏形是由杰克·基尔比于1958年完成的，其中包括一个双极性晶体管，三个电阻和一个电容器。根据一个芯片上集成的微电子器件的数量，集成电路可以分为以下几类：1.小规模集成电路SSI英文全名为SmallScaleIntegration，逻辑门10个以下或晶体管100个以下。2.中规模集成电路MSI英文全名为MediumScaleIntegration，逻辑门11~100个或晶体管101~1k个。3.大规模集成电路LSI英文全名为LargeScaleIntegration，逻辑门101~1k个或晶体管1,001~10k个。4.超大规模集成电路VLSI英文全名为Verylargescaleintegration，逻辑门1,001~10k个或晶体管10,001~100k个。5.甚大规模集成电路ULSI英文全名为UltraLargeScaleIntegration，逻辑门10,001~1M个或晶体管100,001~10M个。GLSI英文全名为GigaScaleIntegration，逻辑门1,000,001个以上或晶体管10,000,001个以上。而根据处理信号的不同，可以分为模拟集成电路、数字集成电路、和兼具模拟与数字的混合信号集成电路。集成电路发展最先进的集成电路是微处理器或多核处理器的"核心(cores)",可以控制电脑到手机到数字微波炉的一切。存储器和ASIC是其他集成电路家族的例子，对于现代信息社会非常重要。虽然设计开发一个复杂集成电路的成本非常高，但是当分散到通常以百万计的产品上，每个IC的成本最小化。IC的性能很高，因为小尺寸带来短路径，使得低功率逻辑电路可以在快速开关速度应用。这些年来，IC持续向更小的外型尺寸发展，使得每个芯片可以封装更多的电路。这样增加了每单位面积容量，可以降低成本和增加功能－见摩尔定律，集成电路中的晶体管数量，每两年增加一倍。总之，随着外形尺寸缩小，几乎所有的指标改善了－单位成本和开关功率消耗下降，速度提高。但是，集成纳米级别设备的IC不是没有问题，主要是泄漏电流（leakagecurrent）。因此，对于最终用户的速度和功率消耗增加非常明显，制造商面临使用更好几何学的尖锐挑战。这个过程和在未来几年所期望的进步，在半导体国际技术路线图（ITRS）中有很好的描述。越来越多的电路以集成芯片的方式出现在设计师手里，使电子电路的开发趋向于小型化、高速化。越来越多的应用已经由复杂的模拟电路转化为简单的数字逻辑集成电路。2022年，关于促进我国集成电路全产业链可持续发展的提案:集成电路产业是国民经济和社会发展的战略性、基础性、先导性产业，其全产业链中的短板缺项成为制约我国数字经济高质量发展、影响综合国力提升的关键因素之一。现阶段我国集成电路产业高端受封锁压制、中低端产能紧缺情况愈演愈烈，仍存在一些亟需解决的问题。一是国内芯片企业能力不强与市场不足并存。二是美西方对我国集成电路产业先进工艺的高端装备全面封堵，形成新的产业壁垒。三是目前我国集成电路产业人才处于缺乏状态，同时工艺研发人员的培养缺乏“产线”的支撑。为此，建议：一是发挥新型举国体制优势，持续支持集成电路产业发展。延续和拓展国家科技重大专项，集中力量重点攻克核心难点。支持首台套应用，逐步实现国产替代。拓展新的应用领域。加大产业基金规模和延长投入周期。二是坚持产业长远布局，深化人才培养改革。既要“补短板”也要“加长板”。持续加大科研人员培养力度和对从事基础研究人员的投入保障力度，夯实人才基础。三是坚持高水平对外开放，拓展和营造新兴市场。积极探索未来和集成电路有关的新兴市场，支持我国集成电路企业走出去。[4]IC的普及仅仅在其开发后半个世纪，集成电路变得无处不在，电脑，手机和其他数字电器成为现代社会结构不可缺少的一部分。这是因为，现代计算，交流，制造和交通系统，包括互联网，全都依赖于集成电路的存在。甚至很多学者认为有集成电路带来的数字革命是人类历史中最重要的事件。IC的分类集成电路的分类方法很多，依照电路属模拟或数字，可以分为：模拟集成电路、数字集成电路和混合信号集成电路（模拟和数字在一个芯片上）。数字集成电路可以包含任何东西，在几平方毫米上有从几千到百万的逻辑门，触发器，多任务器和其他电路。这些电路的小尺寸使得与板级集成相比，有更高速度，更低功耗并降低了制造成本。这些数字IC，以微处理器，数字信号处理器（DSP）和单片机为代表，工作中使用二进制，处理1和0信号。模拟集成电路有,例如传感器，电源控制电路和运放，处理模拟信号。完成放大，滤波，解调，混频的功能等。通过使用专家所设计、具有良好特性的模拟集成电路，减轻了电路设计师的重担，不需凡事再由基础的一个个晶体管处设计起。IC可以把模拟和数字电路集成在一个单芯片上，以做出如模拟数字转换器（A/Dconverter）和数字模拟转换器（D/Aconverter）等器件。这种电路提供更小的尺寸和更低的成本，但是对于信号冲突必须小心。统计数据播报编辑《中华人民共和国2021年国民经济和社会发展统计公报》显示：2021年，集成电路产量3594.3亿块，增长37.5%。[3]2023年2月28日，国家统计局发布《中华人民共和国2022年国民经济和社会发展统计公报》，初步核算，2022年集成电路产量3241.9亿块，比上年增长-9.8%；集成电路出口量2734亿个，比上年增长-12.0%；集成电路进口量5384亿个，比上年增长-15.3%。[5]光盘存储：简介播报编辑光盘是存储信息的主要物理媒介，随着信息容量的急速增长，对信息的分类和快速提取非常重要。因此需要建立一套对光盘存储媒介的管理系统，来实现快速检索。美可达光盘档案归档管理系统播报编辑光盘档案随着光盘价格的急剧下降，光盘已成为价格最低的计算机数据存储介质，全世界百分之八十的光学头、百分之七十的光盘机小机芯在中国生产，中国已成为世界光盘产品产销大国。特别是2003年国际蓝光光盘标准的统一，单盘存储量可达50GB。越来越多的政府机构与公共事业部门、大中型企业、报刊出版社、电台和电视台、银行、学校，以及图书馆、档案馆（室）、资料室在线查询，将信息（计算机程序、数据、书刊）用光盘形式存储发行。光存储介质的物理特性决定了光盘对“恶意修改”、“病毒”和“黑客”入侵，先天“免疫”，特别是，在真实不可更改的档案保管中，光盘发挥着不可替代的作用。在绝对不可修改的数据，如身份证、驾驶证、银行票据、保险票据、建筑档案、国防科技重要资料等行业应用中，以及不可存储与复制的数据（如有版权的光盘）的归档和日常数据管理，光盘已成为各级档案部门的唯一性选择。光盘档案分发归档管理解决方案，是针对国家机关、企事业单位档案管理部门电子文件光盘或公文光盘的存储归档等诸多现实问题，本解决方案有效解决了电子档案的光盘存储、分类标识、上架管理和调档利用问题。该方案不但可大幅度降低部署和维护存储归档系统的管理成本，而且充分体现了电子文档系统与传统归档系统一样的权威性和安全性。本方案可把分布在硬盘、磁带、胶片以及挂接在INTERNET/INTRANET网络上所有数据资源，迁移到光盘后进行分类归档。也可对已归档的光盘档案进行再分类归档、上架。随着中华人民共和国《GB/T20530-2006文献档案资料数字化工作导则》国家标准的正式发布实施，奠定了光盘档案在存储与归档领域的未来法律地位主要功能1、光盘档案上架管理按照国家及行业相关标准，对每张上架光盘进行条码赋码，系统通过读取光盘外标识的条形码，为每张光盘分配上架的物理位置。2、光盘档案著录本方案可对每张光盘进行卷宗级、案卷级和文件级著录（建立文件索引），并可提取文件相关信息，真正做到“只需动手，无需动脑”。3、档案查询用户通过输入关键字等信息，可快速查询到目标文件光盘的具体位置。与智能光盘柜结合进行具体光盘档案查询。可采用多种模式快速定位所查光盘档案所属的物理位置。查询方式：卷宗级、案卷级、目录级查询途径：单一条件查询、组合条件查询、模糊查询4、光盘调档管理Rimage设备可自动为用户提供双备份或者批量备份数据等服务。依照调档工作管理规范完成审批调阅手续后，依次批量复制，及批量调档。5、系统管理可对用户权限进行分级设定和管理，支持组策略；系统初始化设置;日志管理等功能。光盘归档管理方式具有以下优点1、符合国家、行业对档案管理的相关标准要求；2、基于光盘建立的存储与归档系统具有操作便易性、高效性及实用性，安全性高、成本低廉、维护成本低；3、对光盘档案的容灾性强；4、检索和调档手段可选择性强，满足分级管理的需求；5、光盘档案与纸质档案、电子档案互为关联，系统管理具有包容性。应用领域档案馆、图书馆、医院、城建、测绘、电信、证券、保险、银行、广电、气象、地震、石油、地质勘探、音像出版等应用领域。微型计算机：简介播报编辑微型计算机简称微机，俗称电脑，其准确的称谓应该是微型计算机系统。它可以简单地定义为：在微型计算机硬件系统的基础上配置必要的外部设备和软件构成的实体[2]。组成播报编辑微型计算机系统从全局到局部存在三个层次：微型计算机系统、微型计算机、微处理器（CPU）。单纯的微处理器和单纯的微型计算机都不能独立工作，只有微型计算机系统才是完整的信息处理系统，才具有实用意义[2]。一个完整的微型计算机系统包括硬件系统和软件系统两大部分。硬件系统由运算器、控制器、存储器（含内存、外存和缓存）、各种输入输出设备组成，采用“指令驱动”方式工作[3]。微型计算机软件系统可分为系统软件和应用软件。系统软件是指管理、监控和维护计算机资源（包括硬件和软件）的软件。它主要包括：操作系统、各种语言处理程序、数据库管理系统以及各种工具软件等。其中操作系统是系统软件的核心，用户只有通过操作系统才能完成对计算机的各种操作。应用软件是为某种应用目的而编制的计算机程序，如文字处理软件、图形图像处理软件、网络通信软件、财务管理软件、CAD软件、各种程序包等[3]。特点播报编辑微型计算机的特点是体积小、灵活性大、价格便宜、使用方便。自1981年美国IBM公司推出第一代微型计算机IBM-PC以来，微型机以其执行结果精确、处理速度快捷、性价比高、轻便小巧等特点迅速进入社会各个领域，且技术不断更新、产品快速换代，从单纯的计算工具发展成为能够处理数字、符号、文字、语言、图形、图像、音频、视频等多种信息的强大多媒体工具。如今的微型机产品无论从运算速度、多媒体功能、软硬件支持还是易用性等方面都比早期产品有了很大飞跃[4]。分类播报编辑工作站工作站是一种高端的通用微型计算机，以个人计算机和分布式网络计算为基础，主要面向专业应用领域，具备强大的数据运算与图形、图像处理能力，是为满足工程设计、动画制作、科学研究、软件开发、金融管理、信息服务、模拟仿真等专业领域而设计开发的高性能计算机。它属于一种高档的计算机，一般拥有较大的屏幕显示器和大容量的内存和硬盘，也拥有较强的信息处理功能和高性能的图形、图像处理功能以及联网功能[4]。服务器服务器服务器专指某些高性能计算机，能通过网络对外提供服务。相对于普通计算机来说，稳定性、安全性、性能等方面都要求更高，因此在CPU、芯片组、内存、磁盘系统、网络等硬件和普通计算机有所不同。服务器是网络的结点，存储、处理网络上80%的数据和信息，在网络中起到举足轻重的作用。服务器是为客户端计算机提供各种服务的高性能的计算机，其高性能主要在高速度的运算能力、长时间的可靠运行、强大的外部数据吞吐能力等方面。服务器的构成与普通计算机类似，也有处理器、硬盘、内存、系统总线等，但因为它是针对具体的网络应用特别定制的，因而服务器与微型机在处理能力、稳定性、可靠性、安全性、可扩展性、可管理性等方面存在很大差异。服务器主要有网络服务器(DNS、DHCP)、打印服务器、终端服务器、磁盘服务器、邮件服务器、文件服务器等[4]。工业控制计算机工业控制计算机是一种采用总线结构，对生产过程及其机电设备、工艺装备进行检测与控制的计算机系统总称，简称控制机。它由计算机和过程输入/输出（I/O）两大部分组成。计算机由主机、输入/输出设备和外部磁盘机、磁带机等组成。在计算机外部又增加一部分过程输入/输出通道，用来将工业生产过程的检测数据送入计算机进行处理；另一方面，将计算机要行使对生产过程控制的命令、信息转换成工业控制对象的控制变量信号，再送往工业控制对象的控制器中。由控制器行使对生产设备的运行控制[4]。个人计算机①台式机：台式机是应用非常广泛的微型计算机，也叫桌面机，是一种独立分离的计算机，体积相对较大，主机、显示器等设备一般都是相对独立的，需要放置在电脑桌或者专门的工作台上，因此命名为台式机。台式机的机箱空间大、通风条件好，具有很好的散热性；独立的机箱方便用户进行硬件升级，如光驱、硬盘；台式机机箱的开关键、重启键、USB、音频接口都在机箱前置面板中，方便用户的使用[4]。②电脑一体机：电脑一体机是由一台显示器、一个键盘和一个鼠标组成的计算机。它的芯片、主板与显示器集成在一起，显示器就是一台计算机，因此只要将键盘和鼠标连接到显示器上，机器就能使用。随着无线技术的发展，电脑一体机的键盘、鼠标与显示器可实现无线连接，机器只有一根电源线，在很大程度上解决了一直为人诟病的台式机线缆多而杂的问题[4]。③笔记本式计算机：笔记本式计算机是一种小型、可携带的个人计算机，通常质量为1-3kg。它和台式机架构类似，但是它具有更好的便携性。笔记本式计算机除了键盘外，还提供了触控板（TouchPad）或触控点（PointingStick），提供了更好的定位和输入功能[4]。④掌上电脑（PDA）：PDA（PersonalDigitalAssistant），是个人数字助手的意思。顾名思义就是辅助个人工作的数字工具，主要提供记事、通讯录、名片交换及行程安排等功能。可以帮助人们在移动中工作、学习、娱乐等。按使用来分类，分为工业级PDA和消费品PDA。工业级PDA主要应用在工业领域，常见的有条形码扫描器、RFID读写器、POS机等；消费品PDA包括的比较多，比如智能手机、手持的游戏机等[4]。⑤平板电脑：平板电脑也叫平板式计算机（TabletPersonalComputer，简称TabletPc、FlatPc、Tablet、Slates），是一种小型、方便携带的个人计算机，以触摸屏作为基本的输入设备。它拥有的触摸屏（也称为数位板技术）允许用户通过触控笔或数字笔来进行作业而不是传统的键盘或鼠标。用户可以通过内置的手写识别、屏幕上的软键盘、语音识别或者一个真正的键盘（如果该机型配备的话）实现输入[4]。嵌入式计算机个人计算机(3张)嵌入式计算机即嵌入式系统，是一种以应用为中心、以微处理器为基础，软硬件可裁剪的，适应应用系统对功能、可靠性、成本、体积、功耗等综合性严格要求的专用计算机系统。它一般由嵌入式微处理器、外围硬件设备、嵌入式操作系统及用户的应用程序四个部分组成。它是计算机市场中增长最快的领域，也是种类繁多、形态多种多样的计算机系统。嵌入式系统几乎包括了生活中的所有电器设备，如计算器、电视机顶盒、手机、数字电视、多媒体播放器、汽车、微波炉、数字相机、家庭自动化系统、电梯、空调、安全系统、自动售货机、消费电子设备、工业自动化仪表与医疗仪器等[4]。发展阶段播报编辑1、4位和8位低档微处理器时代（1971~1973年）1971年1月，Intel公司的霍夫工程师研制成功世界上第1个字长为4位的微处理器芯片Intel4004，标志着第1代微处理器问世，微型计算机时代从此开始[5]。该阶段是4位和8位低档微处理器时代，通常称为第1代，其典型产品是Intel4004和Intel8008微处理器和分别由它们组成的MCS-4和MCS-8微机。该阶段产品的基本特点是采用PMOS工艺，集成度低，系统结构和指令系统都比较简单，主要采用机器语言或简单的汇编语言，指令数目较少，多用于家电和简单控制场合[5]。2、8位中高档微处理器时代（1974~1978年）该阶段通常称为第2代，典型产品有Intel公司的Intel8080/8085、Motorola公司的MC6800及美国Zilog公司的Z80等，以及各种8位单片机，如Inte公司的8048、Motorola公司的MC6801、Zilog公司的Z8等。该阶段产品的基本特点是采用NMOS工艺，集成度提高约4倍，运算速度提高约10~15倍，指令系统比较完善，具有典型的计算机体系结构和中断、DMA等控制功能。软件方面除了汇编语言外，还有BASIC、FORTRAN等高级语言和相应的解释程序和编译程序，在后期还出现了操作系统，如CP/M就是当时流行的操作系统[5]。3、16位微处理器时代（1978~1984年）该阶段通常称为第3代。1978年6月，Intel公司推出主频为4.77MHz的字长16位的微处理器芯片Intel8086。8086微处理器的诞生标志着第3代微处理器问世。该阶段的典型产品包括Intel公司的8086/8088、80286，Motorola公司的M68000，Zilog公司的Z8000等微处理器。其特点是采用HMOS工艺，集成度和运算速度都比第2代提高了一个数量级。指令系统更加丰富、完善，采用多级中断、多种寻址方式、段式存储结构、硬件乘除部件，并配置了软件系统[5]。这一时期的著名微机产品有IBM公司的个人计算机PC。1981年推出的IBM-PC机采用8088CPU。紧接着1982年又推出了扩展型的个人计算机IBM-PC/XT，它对内存进行了扩充，并增加了一个硬盘驱动器。1984年IBM推出了以80286处理器为核心组成的16位增强型个人计算机IBM-PC/AT。由于IBM公司在发展PC机时采用了技术开放的策略，使PC机风靡世界[5]。4、32位微处理器时代（1985~1992年）该阶段通常称为第4代。1985年10月，Intel公司推出了80386DX微处理器，标志着进入了字长为32位的数据总线时代。该阶段典型产品包括Intel公司的80386/80486，Motorola公司的M68030/68040等。其特点是采用HMOS或CMOS工艺，集成度高达100万晶体管/片，具有32位地址线和32位数据总线。每秒钟可完成600万条指令。微机的功能已经达到甚至超过超级小型计算机，完全可以胜任多任务、多用户的作业。同期，其他一些微处理器生产厂商(如AMD、TEXAS等)也推出了80386/80486系列的芯片[5]。5、Pentium系列微处理器时代（1993年以后）该阶段通常称为第5代。典型产品是Intel公司的奔腾系列芯片及与之兼容的AMD的K6系列微处理器芯片。该阶段产品内部采用了超标量指令流水线结构，并具有相互独立的指令和数据高速缓存。随着MMX（MultimediaeXtended）微处理器的出现，使微机的发展在网络化、多媒体化和智能化等方面跨上了更高的台阶。2000年3月，AMD与Intel分别推出了时钟频率达1GHz的Athlon和PentiumⅢ。2000年11月，Intel又推出了PentiumⅣ微处理器，集成度高达每片4200万个晶体管，主频1.5GHz，400MHz的前端总线，使用全新SSE2指令集。2002年11月，Intel推出的PentiumⅣ微处理器的时钟频率达到3.06GHz，而且微处理器还在不断地发展，性能也在不断提升[5]。2001年Intel公司发布第一款64位的产品Itanium（安腾）微处理器。2003年4月，AMD公司推出了基于64位运算的Opteron（皓龙）微处理器。2003年9月，AMD公司的Athlon（速龙）微处理器问世，标志着64位计算时代的到来[5]。技术指标播报编辑计算机的性能指标涉及体系结构、软硬件配置、指令系统等多种因素，一般说来主要有下列技术指标[6]。字长字长是指计算机运算部件一次能同时处理的二进制数据的位数。字长越长，如果用作存储数据，则计算机的运算精度就越高；如果用作存储指令，则计算机的处理能力就越强。通常字长总是8的整数倍，如8、16、32、64位等。Intel486机和Pentium4机均属32位机[6]。时钟主频时钟主频是指CPU的时钟频率，它的高低在一定程度上决定了计算机速度的高低。主频以兆赫兹（MHz）为单位，一般来说，主频越高，速度就越快。由于微处理器发展迅速，微机的主频也在不断提高[6]。运算速度计算机的运算速度通常是指每秒钟所能执行指令的数目，常用百万次/秒（MIPS，MillionInstructionsPerSecond）来表示。这个指标更能直观地反映机器的速度[6]。存储容量存储容量通常分内存容量和外存容量，这里主要指内存储器的容量。显然，内存容量越大，机器所能运行的程序就越大，处理能力就越强。尤其是当前多媒体PC应用多涉及图像信息处理，要求存储容量越来越大，甚至没有足够大的内存容量就无法运行某些软件。大多数微机的内存容量已达到4GB[6]。存取周期内存储器的存取周期也是影响整个计算机系统性能的主要指标之一。简单地讲，存取周期就是CPU从内存储器中存取数据所需的时间。内存的存取周期在7-70ns之间[7]。此外，计算机的可靠性、可维护性、平均无故障时间和性能价格比也都是计算机的技术指标[7]。系统总线：总线简介播报编辑系统总线上传送的信息包括数据信息、地址信息、控制信息，因此，系统总线包含有三种不同功能的总线，即数据总线DB（DataBus）、地址总线AB（AddressBus）和控制总线CB（ControlBus）。系统总线数据总线DB用于传送数据信息。数据总线是双向三态形式（双向是指可以两个方向传输，可以A->B也可以A<-B；三态指0，1和第三态（tri-state）。tri-state既不是一也不是零，三态门的闭合无输出高阻状态。）的总线，即他既可以把CPU的数据传送到存储器或I/O接口等其它部件，也可以将其它部件的数据传送到CPU。数据总线的位数是微型计算机的一个重要指标，通常与微处理的字长相一致。例如Intel8086微处理器字长16位，其数据总线宽度也是16位。需要指出的是，数据的含义是广义的，它可以是真正的数据，也可以指令代码或状态信息，有时甚至是一个控制信息，因此，在实际工作中，数据总线上传送的并不一定仅仅是真正意义上的数据。地址总线AB是专门用来传送地址的，由于地址只能从CPU传向外部存储器或I/O端口，所以地址总线总是单向三态的，这与数据总线不同。地址总线的位数决定了CPU可直接寻址的内存空间大小，比如8位微机的地址总线为16位，则其最大可寻址空间为2^16=64KB，16位微型机的地址总线为20位，其可寻址空间为2^20=1MB。一般来说，若地址总线为n位，则可寻址空间为2^n（2的n次方）个地址空间（存储单元）。举例来说：一个16位元宽度的位址总线（通常在1970年和1980年早期的8位元处理器中使用）可以寻址的内存空间为2的16次方=65536=64KB的地址，而一个32位元位址总线（通常在像现今2004年的PC处理器中）可以寻址的内存空间为4,294,967,296=4GB（前提：数据总线的宽度是8位）的位址。注释：位元=bit。上面提到的2^n=X=YGB中的B其实是bit，这个结果其实是乘以可寻址的位元8bit之后得到的。控制总线CB用来传送控制信号和时序信号。控制信号中，有的是微处理器送往存储器和I/O接口电路的，如读/写信号，片选信号、中断响应信号等；也有是其它部件反馈给CPU的，比如：中断申请信号、复位信号、总线请求信号、限备就绪信号等。因此，控制总线的传送方向由具体控制信号而定，一般是双向的，控制总线的位数要根据系统的实际控制需要而定。实际上控制总线的具体情况主要取决于CPU。工作原理播报编辑系统总线系统总线在微型计算机中的地位，如同人的神经中枢系统，CPU通过系统总线对存储器的内容进行读写，同样通过总线，实现将CPU内数据写入外设，或由外设读入CPU。微型计算机都采用总线结构。总线就是用来传送信息的一组通信线。微型计算机通过系统总线将各部件连接到一起，实现了微型计算机内部各部件间的信息交换。一般情况下，CPU提供的信号需经过总线形成电路形成系统总线。系统总线按照传递信息的功能来分，分为地址总线、数据总线和控制总线。这些总线提供了微处理器(CPU)与存储器、输入输出接口部件的连接线。可以认为，一台微型计算机就是以CPU为核心，其它部件全“挂接”在与CPU相连接的系统总线上。这种总线结构形式，为组成微型计算机提供了方便。人们可以根据自己的需要，将规模不一的内存和接口接到系统总线上，很容易形成各种规模的微型计算机。微型计算机实质上就是把CPU、存储器和输入/输出接口电路正确的连接到系统总线上，而计算机应用系统的硬件设计本质上是外部设备同系统总线之间的总线接口电路设计问题，这种总线结构设计是计算机硬件系统的一个特点。常用总线播报编辑ISA总线----ISA（industrialstandardarchitecture）总线标准是IBM公司1984年为推出PC/AT机而建立的系统总线标准，所以也叫AT总线。它是对XT总线的扩展，以适应8/16位数据总线要求。它在80286至80486时代应用非常广泛，以至于奔腾机中还保留有ISA总线插槽。ISA总线有98只引脚。EISA总线----EISA总线是1988年由Compaq等9家公司联合推出的总线标准。它是在ISA总线的基础上使用双层插座，在原来ISA总线的98条信号线上又增加了98条信号线，也就是在两条ISA信号线之间添加一条EISA信号线。在实用中，EISA总线完全兼容ISA总线信号。VESA总线系统总线----VESA（videoelectronicsstandardassociation）总线是1992年由60家附件卡制造商联合推出的一种局部总线，简称为VL(VESAlocalbus)总线。它的推出为微机系统总线体系结构的革新奠定了基础。该总线系统考虑到CPU与主存和Cache的直接相连，通常把这部分总线称为CPU总线或主总线，其他设备通过VL总线与CPU总线相连，所以VL总线被称为局部总线。它定义了32位数据线，且可通过扩展槽扩展到64位，使用33MHz时钟频率，最大传输率达132MB/s，可与CPU同步工作。是一种高速、高效的局部总线，可支持386SX、386DX、486SX、486DX及奔腾微处理器。PCI总线----PCI（peripheralcomponentinterconnect）总线是当前最流行的总线之一，它是由Intel公司推出的一种局部总线。它定义了32位数据总线，且可扩展为64位。PCI总线主板插槽的体积比原ISA总线插槽还小，其功能比VESA、ISA有极大的改善，支持突发读写操作，最大传输速率可达132MB/s，可同时支持多组外围设备。PCI局部总线不能兼容现有的ISA、EISA、MCA（microchannelarchitecture）总线，但它不受制于处理器，是基于奔腾等新一代微处理器而发展的总线。CompactPCI----以上所列举的几种系统总线一般都用于商用PC机中，在计算机系统总线中，还有另一大类为适应工业现场环境而设计的系统总线，比如STD总线、VME总线、PC/104总线等。这里仅介绍当前工业计算机的热门总线之一——CompactPCI。系统总线----CompactPCI的意思是“坚实的PCI”，是当今第一个采用无源总线底板结构的PCI系统，是PCI总线的电气和软件标准加欧式卡的工业组装标准，是当今最新的一种工业计算机标准。CompactPCI是在原来PCI总线基础上改造而来，它利用PCI的优点，提供满足工业环境应用要求的高性能核心系统，同时还考虑充分利用传统的总线产品，如ISA、STD、VME或PC/104来扩充系统的I/O和其他功能。----6.PCI-E总线----PCIExpress采用的也是业内流行这种点对点串行连接，比起PCI以及更早期的计算机总线的共享并行架构，每个设备都有自己的专用连接，不需要向整个总线请求带宽，而且可以把数据传输率提高到一个很高的频率，达到PCI所不能提供的高带宽。相对于传统PCI总线在单一时间周期内只能实现单向传输，PCIExpress的双单工连接能提供更高的传输速率和质量，它们之间的差异跟半双工和全双工类似。技术规范播报编辑系统总线是一类信号线的集合是模块间传输信息的公共通道，通过它，计算机各部件间可进行各种数据和命令的传送。为使不同供应商的产品间能够互换，给用户更多的选择，总线的技术规范要标准化。总线的标准制定要经周密考虑，要有严格的规定。系统总线标准（技术规范）包括：（1）机械结构规范：模块尺寸、总线插头、总线接插件以及安装尺寸均有统一规定。（2）功能规范：总线每条信号线（引脚的名称）、功能以及工作过程要有统一规定。（3）电气规范：总线每条信号线的有效电平、动态转换时间、负载能力等。技术指标播报编辑系统总线发展1、系统总线的带宽（总线数据传输速率）系统总线的带宽指的是单位时间内总线上传送的数据量，即每钞钟传送MB的最大稳态数据传输率。与总线密切相关的两个因素是总线的位宽和总线的工作频率，它们之间的关系：总线的带宽=总线的工作频率*总线的位宽/82、系统总线的位宽系统总线的位宽指的是总线能同时传送的二进制数据的位数，或数据总线的位数，即32位、64位等总线宽度的概念。总线的位宽越宽，每秒钟数据传输率越大，总线的带宽越宽。3、系统总线的工作频率总线的工作时钟频率以MHZ为单位，工作频率越高，总线工作速度越快，总线带宽越宽。[1]发展历程播报编辑计算机系统总线的详细发展历程，包括早期的PC总线和ISA总线、PCI/AGP总线、PCI-X总线以及主流的PCIExpress、HyperTransport高速串行总线。从PC总线到ISA、PCI总线，再由PCI进入PCIExpress和HyperTransport体系，计算机在这三次大转折中也完成三次飞跃式的提升。与这个过程相对应，计算机的处理速度、实现的功能和软件平台都在进行同样的进化，显然，没有总线技术的进步作为基础，计算机的快速发展就无从谈起。业界站在一个崭新的起点：PCIExpress和HyperTransport开创了一个近乎完美的总线架构。而业界对高速总线的渴求也是无休无止，PCIExpress4.0和HyperTransport4.0都已提上日程，它们将会再次带来效能提升。在计算机系统中，各个功能部件都是通过系统总线交换数据，总线的速度对系统性能有着极大的影响。而也正因为如此，总线被誉为是计算机系统的神经中枢。但相比CPU、显卡、内存、硬盘等功能部件，总线技术的提升步伐要缓慢得多。在PC发展的二十余年历史中，总线只进行三次更新换代，但它的每次变革都令计算机的面貌焕然一新。[1]总线复用：产品介绍播报编辑如8051单片机，地址空间是16bit，数据宽度8bit，而低位地址总线8bit是与数据8bit复用的。所以总共还是16根线。数据和地址的分离是通过外部电路来完成的，一般都用273锁存器，对地址信息进行锁存，通过ALE信号来控制。然后再传输数据信息。总线复用传送播报编辑所谓复用传送就是指多个用户共享公用信道的一种机制，最常见的主要有时分多路复用、频分多路复用和码分多路复用等,优点在于:为了各子系统的信息能有效及时的被传送，并且减少总线中信号线的数量，为了不至于彼此间的信号相互干扰和避免物理空间上过于拥挤复用传送又分三种(以下为介绍)时分多路复用（TDMA）时分复用是将信道按时间加以分割成多个时间段，不同来源的信号会要求在不同的时间段内得到响应，彼此信号的传输时间在时间坐标轴上是不会重叠。频分多路复用（FDMA）频分复用就是把信道的可用频带划分成若干互不交叠的频段，每路信号经过频率调制后的频谱占用其中的一个频段，以此来实现多路不同频率的信号在同一信道中传输。而当接收端接收到信号后将采用适当的带通滤波器和频率解调器等来恢复原来的信号。码分多路复用（CDMA）码分多路复用是所被传输的信号都会有各自特定的标识码或地址码，接收端将会根据不同的标识码或地址码来区分公共信道上的传输信息，只有标识码或地址码完全一致的情况下传输信息才会被接收。技术应用播报编辑IEEE以太网标准-Ethernet以太网（Ethernet）是一种计算机局域网组网技术。IEEE制定的IEEE802.3标准给出了以太网的技术标准。它规定了包括物理层的连线、电信号和介质访问层协议的内容。以太网是当前应用最普遍的局域网技术。以太网的标准拓扑结构为总线型拓扑，但快速以太网（100BASE-T、1000BASE-T标准）为了最大程度的减少冲突，最大程度的提高网络速度和使用效率，使用交换机（Switchhub）来进行网络连接和组织，这样，以太网的拓扑结构就成了星型，但在逻辑上，以太网仍然使用总线型拓扑和CSMA/CD（CarrierSenseMultipleAccess/CollisionDetect即带冲突检测的载波监听多路访问）的总线复用技术。数据寄存器：定义播报编辑内存资料寄存器是指用于存放欲写入存储体中的数据，或暂存从存储体中读出的数据，准备让处理器处理的寄存器，即用来暂时存放处理器计算过程中所用到的操作数、结果和信息。数据寄存器用来暂时存放由主存储器读出的一条指令或一个数据字；反之，当向主存存入一条指令或一个数据字时，也将它们暂时存放在数据寄存器中。在单累加器结构的运算器中，数据寄存器还可兼作操作数寄存器[1]。数据寄存器访问速度最快，完全能与CPU协调工作。类别播报编辑AX、BX、CX、DX可以称为数据寄存器，这4个16位寄存器又可分别分成高8位（AH、BH、CH、DH）和低8位（AL、BL、CL、DL）。因此它们既可作为4个16位数据寄存器使用，也可作为8个8位数据寄存器使用，在编程时可存放源操作数、目的操作数或运算结果。数据寄存器是存放操作数、运算结果和运算的中间结果，以减少访问存储器的次数，或者存放从存储器读取的数据以及写入存储器的数据的寄存器。AX（accumulator）累加器。作为累加器使用。是算术运算的主要寄存器。在乘、除等指令中指定用来存放操作数。以及所有的I/O指令都使用这一寄存器与外部设备传送信息。BX（base）基址。可以作为通用寄存器使用。此外在计算机存储地址时，它经常用作基址寄存器。CX（count）计数。可以作为通用寄存器使用。常用来保存计数值，如在循环、位移和串处理指令中作隐含计数器。DX（data）数据。可以作为通用寄存器使用。一般在作双字长运算时把DX和AX组合在一起存放一个双字长数，DX用来存放高位数。对于某些I/O操作，DX可用来存放I/O的端口地址。寄存器播报编辑寄存器，是集成电路中非常重要的一种存储单元，通常由触发器组成。在集成电路设计中，寄存器可分为电路内部使用的寄存器和充当内外部接口的寄存器这两类。内部寄存器不能被外部电路或软件访问，只是为内部电路的实现存储功能或满足电路的时序要求。而接口寄存器可以同时被内部电路和外部电路或软件访问，CPU中的寄存器就是其中一种，作为软硬件的接口，为广泛的通用编程用户所熟知。CPU中至少要有六类寄存器：指令寄存器（IR）、程序计数器（PC）、地址寄存器（AR）、数据寄存器（DR）、累加寄存器（AC）、程序状态字寄存器（PSW）。这些寄存器用来暂存一个计算机字，其数目可以根据需要进行扩充。指令寄存器指令寄存器（InstructionRegister，IR）用来保存当前正在执行的一条指令。当执行一条指令时，首先把该指令从主存读取到数据寄存器中，然后再传送至指令寄存器。指令包括操作码和地址码两个字段，为了执行指令，必须对操作码进行测试，识别出所要求的操作，指令译码器（InstructionDecoder，ID）就是完成这项工作的。指令译码器对指令寄存器的操作码部分进行译码，以产生指令所要求操作的控制电位，并将其送到微操作控制线路上，在时序部件定时信号的作用下，产生具体的操作控制信号。指令寄存器中操作码字段的输出就是指令译码器的输入。操作码一经译码，即可向操作控制器发出具体操作的特定信号。程序计数器程序计数器（ProgramCounter，PC）用来指出下一条指令在主存储器中的地址。在程序执行之前，首先必须将程序的首地址，即程序第一条指令所在主存单元的地址送入PC，因此PC的内容即是从主存提取的第一条指令的地址。当执行指令时，CPU能自动递增PC的内容，使其始终保存将要执行的下一条指令的主存地址，为取下一条指令做好准备。若为单字长指令，则(PC)+1àPC，若为双字长指令，则(PC)+2àPC，以此类推。但是，当遇到转移指令时，下一条指令的地址将由转移指令的地址码字段来指定，而不是像通常的那样通过顺序递增PC的内容来取得。因此，程序计数器的结构应当是具有寄存信息和计数两种功能的结构。地址寄存器地址寄存器（AddressRegister，AR）用来保存CPU当前所访问的主存单元的地址。由于在主存和CPU之间存在操作速度上的差异，所以必须使用地址寄存器来暂时保存主存的地址信息，直到主存的存取操作完成为止。当CPU和主存进行信息交换，即CPU向主存存入数据/指令或者从主存读出数据/指令时，都要使用地址寄存器和数据寄存器。如果我们把外围设备与主存单元进行统一编址，那么，当CPU和外围设备交换信息时，我们同样要使用地址寄存器和数据寄存器。累加寄存器累加寄存器通常简称累加器（Accumulator，AC），是一个通用寄存器。累加器的功能是：当运算器的算术逻辑单元ALU执行算术或逻辑运算时，为ALU提供一个工作区，可以为ALU暂时保存一个操作数或运算结果。显然，运算器中至少要有一个累加寄存器。程序状态字寄存器程序状态字（ProgramStatusWord，PSW）用来表征当前运算的状态及程序的工作方式。程序状态字寄存器用来保存由算术/逻辑指令运行或测试的结果所建立起来的各种条件码内容，如运算结果进/借位标志（C）、运算结果溢出标志（O）、运算结果为零标志（Z）、运算结果为负标志（N）、运算结果符号标志（S）等，这些标志位通常用1位触发器来保存。除此之外，程序状态字寄存器还用来保存中断和系统工作状态等信息，以便CPU和系统及时了解机器运行状态和程序运行状态。因此，程序状态字寄存器是一个保存各种状态条件标志的寄存器。主存储器播报编辑主存储器(简称内存或主存)是计算机系统中一个主要部件，用于保存进程运行时的程序和数据，也称可执行存储器，其容量对于当前的微机系统和大中型机，可能一般为数十MB到数GB，而且容量还在不断增加，而嵌入式计算机系统一般仅有几十KB到几MB。CPU的控制部件只能从主存储器中取得指令和数据，数据能够从主存储器读取并将它们装入到寄存器中，或者从寄存器存入到主存储器。CPU与外围设备交换的信息一般也依托于主存储器地址空间。由于主存储器的访问速度远低于CPU执行指令的速度，为缓和这一矛盾，在计算机系统中引入了寄存器和高速缓存。数据总线：共享与交换播报编辑数据总线(DataBus)。规范了一个大的集成应用系统中同构系统、异构系统等方面进行数据共享和交换实现方法，系统间数据交换标准。可用于微处理与内存，微处理器与输入输出接口之间传送信息。数据总线的宽度是决定计算机性能的一个重要指标。微型计算机的数据总线大多是32位或64位。1.业务实体数据交换：各个子系统在架构分层上都有业务实体层，数据交换机制在业务实体层建立了一层对所有应用系统透明的层。子系统之间，无论其实现的具体技术方案是什么，都可通过业务实体层进行共享和交互，这也就建立了可在子系统间进行持续集成和业务扩展的结构，从而实现一个可扩展的完整的一体化信息系统。[1]2.WebService数据交换：是一种Web服务标准，Web服务提供在异构系统间共享和交换数据的方案，也可用于在产品集成中使用统一的接口标准进行数据共享和交换。交换方式播报编辑原理图1.业务实体层的数据交换，这是同构子系统系统间最直接和最高效的交换方案。在同构子系统间通过定义数据对象接口层，通过DTO进行传输，或者直接在数据库中进行数据表的连接或访问，达到同构子系统间的数据共享和交换。例如征管系统内各个子系统间的数据共享和交换、业务系统和数据挖掘间的数据共享。2.WebService数据交换，在异构子系统间，同时存在数据不集中的情况下，必须使用有效的技术手段来保证异构的数据共享和交换。WebService是基于Web的标准服务，其不受传输协议或硬件的限制，也不受子系统具体实现技术的限制。而且较先进完备的应用系统或产品都提供了基于WebService的集成接口。这就解决了异构子系统间的数据共享和交换。WebService也可以解决跨网络和行业系统的数据交换，这需要对方接口单位同样具备WebService服务。3.格式化文件数据交换，它是与外部系统文件传输，业务上的内部系统和外部信息交换需求，要求提供相应的数据共享和交换技术机制。这类问题通常使用基于文件系统的技术方案解决，例如文件报送、文件交换等。可举例说明：税、库、银三者之间就存在实时和非实时的数据交换，这种交换优化的方案就是使用文件通过Socket进行交换。此类技术实现一般采用底层技术。连接器播报编辑连接器数据总线连接器(DBconnector)是一种用于连接串行和平行电缆到数据总线的连接器。数据总线连接器命名格式是DB-x，x代表连接器内电线的数量。每条线被连接到在连接器中的一个栓上，但是在很多情况下，不是所有的栓都被分配一个功能。数据总线连接器被各种EIA/TIA标准定义。是一类用于连接序列和平行电缆到一个数据总线的连接器。DB连接器在DB-x的格式下命名，其中x代表连接器内（线）的数量。每条线与连接器中的销钉相连，但是在许多情况下，不是所有的销钉都被分配功能。DB连接器有9,15,25,37和50销钉尺寸。DB连接器定义了连接器物理结构，而不是每条线的用途。例如，DB-9有9个销钉和被用于连接一个鼠标。DB-25有25个销钉和被用于连接一台打印机。技术指标播报编辑程序总线1、总线的带宽（总线数据传输速率）总线的带宽指的是单位时间内总线上传送的数据量，即每钞钟传送MB的最大稳态数据传输率。与总线密切相关的两个因素是总线的位宽和总线的工作频率，它们之间的关系：总线的带宽=总线的工作频率*总线的位宽/82、总线的位宽总线的位宽指的是总线能同时传送的二进制数据的位数，或数据总线的位数，即32位、64位等总线宽度的概念。总线的位宽越宽，每秒钟数据传输率越大，总线的带宽越宽。3、总线的工作频率总线的工作时钟频率以MHZ为单位，工作频率越高，总线工作速度越快，总线带宽越宽。操作播报编辑模型总线一个操作过程是完成两个模块之间传送信息，启动操作过程的是主模块，另外一个是从模块。某一时刻总线上只能有一个主模块占用总线。总线的操作步骤：主模块申请总线控制权，总线控制器进行裁决。数据传送的错误检查：主模块得到总线控制权后寻址从模块，从模块确认后进行数据传送。总线定时协议：定时协议可保证数据传输的双方操作同步，传输正确。定时协议有三种类型：同步总线定时：总线上的所有模块共用同一时钟脉冲进行操作过程的控制。各模块的所有动作的产生均在时钟周期的开始，多数动作在一个时钟周期中完成。异步总线定时：操作的发生由源或目的模块的特定信号来确定。总线上一个事件发生取决前一事件的发生，双方相互提供联络信号。总线定时协议半同步总线定时：总线上各操作的时间间隔可以不同，但必须是时钟周期的整数倍，信号的出现,采样与结束仍以公共时钟为基准。ISA总线采用此定时方法。数据传输类型：分单周方式和突发(burst)方式。单周期方式：一个总线周期只传送一个数据。突发方式：取得主线控制权后进行多个数据的传输。寻址时给出目的地首地址，访问第一个数据，数据2、3到数据n的地址在首地址基础上按一定规则自动寻址（如自动加1）。标准规范播报编辑标准系统结构总线总线是一类信号线的集合是模块间传输信息的公共通道，通过它，计算机各部件间可进行各种数据和命令的传送。为使不同供应商的产品间能够互换，给用户更多的选择，总线的技术规范要标准化。[2]总线的标准制定要经周密考虑，要有严格的规定。总线标准（技术规范）包括以下几部分：机械结构规范：模块尺寸、总线插头、总线接插件以及安装尺寸均有统一规定。功能规范：总线每条信号线（引脚的名称）、功能以及工作过程要有统一规定。电气规范：总线每条信号线的有效电平、动态转换时间、负载能力等。指令寄存器：属性描述播报编辑BSDL语言中有一个重要的描述，即指令寄存器（InstruclionRegister），它是由一些强制的、可选的和用户自定义的指令集合而成。关于这个指令寄存器的属性描述，必须包含5个要素：指令寄存器的长度、各种指令的名称、对应的操作码、指令寄存器的捕获操作码以及哪些指令是内部的[4]。取指过程播报编辑取指令阶段完成的任务是将现行指令从主存中取出来并送至指令寄存器中，具体的操作如下：[5]1、将程序计数器（PC）中的内容送至存储器地址寄存器（MAR），并送地址总线（AB）[5]。2、由控制单元（CU）经控制总线（CB）向存储器发读命令[5]。3、从主存中取出的指令通过数据总线（DB）送到存储器数据寄存器（MDR）[5]。4、将MDR的内容送至指令寄存器（R）中[5]。5、将PC的内容递增，为取下一条指令做好准备[5]。以上这些操作对任何一条指令来说都是必须要执行的操作，所以称为公共操作[5]。原理播报编辑指令寄存器可以在移入一条新的指令的同时，将当前指令保持在它的输出端口。可用这个寄存器来指定所要执行的操作和选择测试数据寄存器。当TAP接收到一条指令寄存器扫描指令时，对指令寄存器进行读取。在指令寄存器工作过程中，来自TAP的控制信号选择指令寄存器的输出驱动TDO管脚[6]。指令寄存器的功能由三部分构成：扫描移位寄存器、保持寄存器与译码逻辑。扫描移位寄存器从TDI端扫描移入当前指令代码；保持寄存器对当前指令代码进行保持；译码逻辑根据当前指令代码，产生相应的数据寄存器控制信号。三部分的运行控制信号均来自TAP控制器[6]。概念区分播报编辑IP是指令指针寄存器（InstructionPointer），它用来存放待要取出指令的地址偏移量。它只有与CS寄存器相结合，才能形成指向指令的真正物理地址[7]。操作系统：系统简介播报编辑在计算机中，操作系统是其最基本也是最为重要的基础性系统软件。从计算机用户的角度来说，计算机操作系统体现为其提供的各项服务；从程序员的角度来说，其主要是指用户登录的界面或者接口；如果从设计人员的角度来说，就是指各式各样模块和单元之间的联系。事实上，全新操作系统的设计和改良的关键工作就是对体系结构的设计，经过几十年以来的发展，计算机操作系统已经由一开始的简单控制循环体发展成为较为复杂的分布式操作系统，再加上计算机用户需求的愈发多样化，计算机操作系统已经成为既复杂而又庞大的计算机软件系统之一。[1]发展历史播报编辑纵观计算机之历史，操作系统与计算机硬件的发展息息相关。操作系统之本意原为提供简单的工作排序能力，后为辅助更新更复杂的硬件设施而渐渐演化。从最早的批量模式开始，分时机制也随之出现，在多处理器时代来临时，操作系统也随之添加多处理器协调功能，甚至是分布式系统的协调功能。其他方面的演变也类似于此。另一方面，个人计算机之操作系统因袭大型机的成长之路，在硬件越来越复杂、强大时，也逐步实现以往只有大型机才有的功能。从1946年诞生第一台电子计算机以来，它的每一代进化都以减少成本、缩小体积、降低功耗、增大容量和提高性能为目标，随着计算机硬件的发展，同时也加速了操作系统(简称OS)的形成和发展。[2]最初的电脑没有操作系统，人们通过各种按钮来控制计算机，后来出现了汇编语言，操作人员通过有孔的纸带将程序输入电脑进行编译。这些将语言内置的电脑只能由制作人员自己编写程序来运行，不利于程序、设备的共用。为了解决这种问题，就出现了操作系统，这样就很好实现了程序的共用，以及对计算机硬件资源的管理。[2]随着计算技术和大规模集成电路的发展，微型计算机迅速发展起来。从20世纪70年代中期开始出现了计算机操作系统。在美国1976年的时候就研制了DIGITALRESEARCH软件公司出8位的CP/M操作系统。这个系统允许用户通过控制台的键盘对系统进行控制和管理，其主要功能是对文件信息进行管理，以实现其他设备文件或硬盘文件的自动存取。此后出现的一些8位操作系统多采用CP/M结构。[2]2019年8月9日于东莞举行的华为开发者大会（HDC.2019）上正式发布的分布式操作系统。华为鸿蒙系统是一款全新的面向全场景的分布式操作系统，创造一个超级虚拟终端互联的世界，将人、设备、场景有机地联系在一起，将消费者在全场景生活中接触的多种智能终端，实现极速发现、极速连接、硬件互助、资源共享，用合适的设备提供场景体验。[16]2023年7月5日，“开放麒麟”操作系统1.0版本正式发布。[13]主要功能播报编辑计算的操作系统对于计算机可以说是十分重要的，从使用者角度来说，操作系统可以对计算机系统的各项资源板块开展调度工作，其中包括软硬件设备、数据信息等，运用计算机操作系统可以减少人工资源分配的工作强度，使用者对于计算的操作干预程度减少，计算机的智能化工作效率就可以得到很大的提升。其次在资源管理方面，如果由多个用户共同来管理一个计算机系统，那么可能就会有冲突矛盾存在于两个使用者的信息共享当中。为了更加合理的分配计算机的各个资源板块，协调计算机系统的各个组成部分，就需要充分发挥计算机操作系统的职能，对各个资源板块的使用效率和使用程度进行一个最优的调整，使得各个用户的需求都能够得到满足。最后，操作系统在计算机程序的辅助下，可以抽象处理计算系统资源提供的各项基础职能，以可视化的手段来向使用者展示操作系统功能，减低计算机的使用难度。[3]操作系统主要包括以下几个方面的功能：①进程管理，其工作主要是进程调度，在单用户单任务的情况下，处理器仅为一个用户的一个任务所独占，进程管理的工作十分简单。但在多道程序或多用户的情况下，组织多个作业或任务时，就要解决处理器的调度、分配和回收等问题。②存储管理分为几种功能：存储分配、存储共享、存储保护、存储扩张。③设备管理分有以下功能：设备分配、设备传输控制、设备独立性。④文件管理：文件存储空间的管理、目录管理、文件操作管理、文件保护。⑤作业管理是负责处理用户提交的任何要求。[2]用途分类播报编辑计算机的操作系统根据不同的用途分为不同的种类，从功能角度分析，分别有实时系统、批处理系统、分时系统、网络操作系统等。[4]实时系统主要是指系统可以快速的对外部命令进行响应，在对应的时间里处理问题，协调系统工作。[4]批处理系统出现于20世纪60年代，批处理系统能够提高资源的利用率和系统的吞吐量。[5]分时系统可以实现用户的人机交互需要，多个用户共同使用一个主机，很大程度上节约了资源成本。分时系统具有多路性、独立性、交互性、及时性的优点，能够将用户-系统-终端任务实现。[4]网络操作系统是一种能代替操作系统的软件程序，是网络的心脏和灵魂，是向网络计算机提供服务的特殊的操作系统。借由网络达到互相传递数据与各种消息，分为服务器及客户端。而服务器的主要功能是管理服务器和网络上的各种资源和网络设备的共用，加以统合并控管流量，避免有瘫痪的可能性，而客户端就是有着能接收服务器所传递的数据来运用的功能，好让客户端可以清楚的搜索所需的资源。体系结构播报编辑简单体系结构计算机操作系统诞生初期，其体系结构就属于简单体系结构，由于当时各式各样影响因素的作用，如硬件性能、平台、软件水平等方面的限制，使得当时的计算机操作系统结构呈现出一种混乱且结构模糊的状态，其操作系统的用户应用程序和其内核程序鱼龙混杂，甚至其运行的地址和空间都是一致的。这种操作系统实际上就是一系列过程和项目的简单组合，使用的模块方法也相对较为粗糙，因此导致其结构宏观上非常模糊。[1]单体内核结构随着科学技术的不断发展和进步，硬件及其平台的水平和性能得到了很大程度的提高，其数量和种类也与日俱增，操作系统的复杂性也逐渐加深，其具备的功能以及性能越来越多，在此背景下，单体内核结构的操作系统诞生并得到了应用，例如UNIX操作系统、windowsNT/XP等。一般情况下，单体内核结构的操作系统主要具备以下几种功能，分别是文件及内存管理、设备驱动、CPU调度以及网络协议处理等。由于内核的复杂性不断加深，相关的开发设计人员为了实现对其良好的控制，逐渐开始使用了一些较为成熟的模块化方法，并根据其不同的功能将其进行结构化，进而将其划分为诸多的模块，例如文件及内存管理模块、驱动模块、CPU调度模块及网络协议处理等。这些模块所使用的地址和空间与内核使用的完全一致，其以函数调用的方式构建了用于通讯的结构来实现各个模块之间的通讯。在使用模块化的方法以后，只要其通讯接口没有发生明显的变化，即使整个结构中的任何一个模块发生变化也不会对结构中的其他模块造成任何的影响，为其系统的维护和改良扩充提供了便利。虽然单体内核结构的计算机操作系统经过了模块化的处理，但是其中的全部模块仍然是在硬件之上、应用软件之下的操作系统核心中运转和工作。模块与模块之间活动的层次没有任何的差别。[1]层次式结构层次式结构的计算机操作系统是为了减少以往操作系统中各个模块之间由于联系紧密而带来的各种问题而诞生的，其可以最大程度的减少甚至是避免循环调用现象的发生，确保调用有序，为操作系统设计目标的实现奠定了坚实的基础。在层次式结构的计算机操作系统之中，其是由诸多系统分为若干个层次的，其最底层是硬件技术，其他每一个层级均是建立在其下一层级之上的。在设计其计算机操作系统内核时，主要采用与抽象数据类型十分类似的设计方法进行的，在系统中的每一个层级均包含着多种数据和操作，且每一个的数据和操作是其他层不可见的，在每一层当中都配备了用于其他层使用的一操作接口，同时每一层发生的访问行为只能针对其下层进行，不能访问其上层的数据和服务，严格遵守了调用规则，在很大程度上避免了其他层次对某一层次的干扰和破坏。对于理想的层次式计算机系统体系结构来说，其之间的联系不仅仅是单向依赖性的，同时各个层级之间也要具备相互的独立性，且只能对低层次的模块和功能进行调用，例如THE系统。但是这种理想的全序层次式计算机操作系统在现实中建成是较为困难的，其无法完全避免模块之间循环调用现象的出现，某个层级之间仍旧存在某种循环关系，这种层次式结构又被叫作半序层次式计算机操作系统，例如SUE操作系统。[1]微内核结构微内核计算机操作系统体系结构又可以被叫作客户机结构或者服务器结构，其实际上就是一种将系统中的代码转移到更高层次当中，尽可能地减少操作系统中的东西，仅仅保留一个小体积的内核，一般情况下其使用的主要方法就是通过用户进程来实现操作系统所具备的各项功能，具体来说就是用户进程可以将相关的请求和要求发送到服务器当中，然后由服务器完成相关的操作以后在通过某种渠道反馈到用户进程当中。在微内核结构中，操作系统的内核主要工作就是对客户端和服务器之间的通信进行处理，在系统中包括许多部分，每一个部分均具备某一方面的功能，例如文件服务、进程服务、终端服务等，这样的部分相对较小，相关的管理工作也较为便利。这种机构的服务的运行都是以用户进程的形式呈现的，既不在核心中运行，也不直接地对硬件进行访问，这样一来即使服务器发生错误或受到破坏也不会对系统造成影响，仅仅只是会造成相对应服务器的崩溃。[1]外核结构外核结构的计算机操作系统本质上就是为了获得更高的性能和灵活性而设计出来的，在系统中，操作系统接口处于硬件层，在内核中提出全部由以往操作系统带来的抽象，并将重点和关键放在了更多硬件资源的复用方面。在操作系统的外核结构中，内核负责的主要工作仅仅为简单的申请操作以及释放和复用硬件资源，其由以往操作系统提供的抽象全部在用户空间当中运行。[1]一般情况下，外核结构中的内核主要有三大方面的工作，分别是对资源的所有权进行跟踪、为操作系统的安全提供保护以及撤销对资源的访问行为。在核外，基本上所有的操作系统中的抽象都是以库的形式呈现出来的，而用户在访问硬件资源时也是通过库的调用来完成的。[1]安全加固播报编辑随着计算机网络与应用技术的不断发展，信息系统安全问题越来越引起人们的关注，信息系统一旦遭受破坏，用户及单位将受到重大的损失，对信息系统进行有效的保护，是必须面对和解决的迫切课题，而操作系统安全在计算机系统整体安全中至关重要，加强操作系统安全加固和优化服务是实现信息系统安全的关键环节。当前，操作系统安全构成威胁的问题主要有系统漏洞、脆弱的登录认证方式、访问控制形同虚设、计算机病毒、特洛伊木马、隐蔽通道、系统后门恶意程序和代码感染等，加强操作系统安全加固工作是整个信息系统安全的基础。[6]安全加固原理安全加固是指按照系统安全配置标准，结合用户信息系统实际情况，对信息系统涉及的终端主机、服务器、网络设备、数据库及应用中间件等软件系统进行安全配置加固、漏洞修复和安全设备调优。通过安全加固，可以合理加强信息系统安全性，提高其健壮性，增加攻击入侵的难度，可以使信息系统安全防范水平得到大幅提升。[6]安全加固方法安全加固主要通过人工对系统进行漏洞扫描，针对扫描结果使用打补丁、强化账号安全、修改安全配置、优化访问控制策略、增加安全机制等方法加固系统以及堵塞系统漏洞、“后门”，完成加固工作。[6]安全加固流程安全加固主要包含以下几个环节：（1）安全加固范围确定收集需要进行安全加固的信息系统所涉及的计算机设备、网络、数据库及应用中间件的设备情况。[6]（2）制订安全加固方案根据信息系统的安全等级划分和具体要求，利用网络安全经验和漏洞扫描技术和工具，对加固范围内的计算机操作系统、网络设备、数据库系统及应用中间件系统进行安全评估，从内、外部对信息系统进行全面的评估，检查这些系统目前安全状况，根据现状制定相应的安全加固措施，形成安全加固方案。[6]（3）安全加固方案实施根据制定的安全加固实施方案实施加固，完成后对加固后的系统进行全面的测试和检查，确保加固对系统业务无影响，并填写加固实施记录。[6]（4）安全加固报告输出根据安全加固实施记录，编写最终的安全加固实施报告，对加固工作进行总结，对已加固的项目、加固效果、遗留问题进行汇总统计。[6]系统虚拟化播报编辑操作系统虚拟化作为容器的核心技术支撑，得到了研究者的广泛关注。最近几年，无论是在以SOSP/OSDI为代表的计算机系统领域顶级学术会议上，还是以Google为代表的重要互联网企业中，都陆续出现了一批操作系统虚拟化的最新研究成果，并且成果数量呈现出逐年增加的总体趋势。[7]操作系统虚拟化技术允许多个应用在共享同一主机操作系统(HostOS)内核的环境下隔离运行，主机操作系统为应用提供一个个隔离的运行环境，即容器实例：操作系统虚拟化技术架构可以分为容器实例层、容器管理层和内核资源层。[7]操作系统虚拟化与传统虚拟化最本质的不同是传统虚拟化需要安装客户机操作系统(GuestOS)才能执行应用程序，而操作系统虚拟化通过共享的宿主机操作系统来取代GuestOS。[7]操作实例播报编辑嵌入式嵌入式系统使用非常广泛的系统（如VxWorks、eCos、SymbianOS及PalmOS）以及某些功能缩减版本的Linux或者其他操作系统。某些情况下，OS指称的是一个内置了固定应用软件的巨大泛用程序。在许多最简单的嵌入式系统中，所谓的OS就是指其上唯一的应用程序。iOS是由苹果公司开发的手持设备操作系统。苹果公司于2007年1月9日的Macworld大会上公布这个系统，以Darwin为基础，属于类Unix的商业操作系统。最初是设计给iPhone使用的，后来陆续套用到iPodtouch、iPad以及AppleTV等产品上。iOS与苹果的MacOSX操作系统一样，属于类Unix的商业操作系统。原本这个系统名为iPhoneOS，因为iPad，iPhone，iPodtouch都使用iPhoneOS，所以2010年WWDC大会上宣布改名为iOS（iOS为美国Cisco公司网络设备操作系统注册商标，苹果改名已获得Cisco公司授权）。Android是一种基于Linux的自由及开放源代码的操作系统。主要使用于移动设备，如智能手机和平板电脑，由Google公司和开放手机联盟领导及开发。尚未有统一中文名称，中国大陆地区较多人使用“安卓”。Android操作系统最初由AndyRubin开发，主要支持手机。2005年8月由Google收购注资。2007年11月，Google与84家硬件制造商、软件开发商及电信营运商组建开放手机联盟共同研发改良Android系统。随后Google以Apache开源许可证的授权方式，发布了Android的源代码。第一部Android智能手机发布于2008年10月。Android逐渐扩展到平板电脑及其他领域上，如电视、数码相机、游戏机、智能手表等。2011年第一季度，Android在全球的市场份额首次超过塞班系统，跃居全球第一。2013年的第四季度，Android平台手机的全球市场份额已经达到78.1%。2013年09月24日谷歌开发的操作系统Android在迎来了5岁生日，全世界采用这款系统的设备数量已经达到10亿台。openEuler是开放原子开源基金会（OpenAtomFoundation）孵化及运营的开源项目。[17]欧拉操作系统(openEuler，简称“欧拉”,“开源欧拉”)是面向数字基础设施的操作系统，支持服务器、云计算、边缘计算、嵌入式等应用场景，支持多样性计算，致力于提供安全、稳定、易用的操作系统。通过为应用提供确定性保障能力，支持OT领域应用及OT与ICT的融合。[17]类Unix主条目：类Unix所谓的类Unix家族指的是一族种类繁多的OS，此族包含了SystemV、BSD与Linux。由于Unix是TheOpenGroup的注册商标，特指遵守此公司定义的行为的操作系统。而类Unix通常指的是比原先的Unix包含更多特征的OS。类Unix系统可在非常多的处理器架构下运行，在服务器系统上有很高的使用率，例如大专院校或工程应用的工作站。1991年，芬兰学生林纳斯·托瓦兹根据类Unix系统Minix编写并发布了Linux操作系统内核，其后在理查德·斯托曼的建议下以GNU通用公共许可证发布，成为自由软件Unix变种.Linux近来越来越受欢迎，它们也在个人桌面计算机市场上大有斩获，例如Ubuntu系统。某些Unix变种，例如惠普的HP-UX以及IBM的AIX仅设计用于自家的硬件产品上，而SUN的Solaris可安装于自家的硬件或x86计算机上。苹果计算机的MacOSX是一个从NeXTSTEP、Mach以及FreeBSD共同派生出来的微内核BSD系统，此OS取代了苹果计算机早期非Unix家族的MacOS。经历数年的披荆斩棘，自由开源的Linux系统逐渐蚕食以往专利软件的专业领域，例如以往计算机动画运算巨擘──硅谷图形公司（SGI）的IRIX系统已被Linux家族及贝尔实验室研发小组设计的九号项目与Inferno系统取代，皆用于分散表达式环境。它们并不像其他Unix系统，而是选择内置图形用户界面。九号项目原先并不普及，因为它刚推出时并非自由软件。后来改在自由及开源软件许可证LucentPublicLicense发布后，便开始拥有广大的用户及社群。Inferno已被售予VitaNuova并以GPL/MIT许可证发布。当前，计算机按照计算能力排名世界500强中472台使用Linux，6台使用Windows，其余为各类BSD等Unix。MicrosoftWindows主条目：MicrosoftWindowsMicrosoftWindows系列操作系统是在微软给IBM机器设计的MS-DOS的基础上设计的图形操作系统。现在的Windows系统，如Windows2000、WindowsXP皆是创建于现代的WindowsNT内核。NT内核是由OS/2和OpenVMS等系统上借用来的。Windows可以在32位和64位的Intel和AMD的处理器上运行，但是早期的版本也可以在DECAlpha、MIPS与PowerPC架构上运行。虽然由于人们对于开放源代码操作系统兴趣的提升，Windows的市场占有率有所下降，但是到2004年为止，Windows操作系统在世界范围内占据了桌面操作系统90%的市场。Windows系统也被用在低级和中阶服务器上，并且支持网页服务的数据库服务等一些功能。最近微软花费了很大研究与开发的经费用于使Windows拥有能运行企业的大型程序的能力。WindowsXP在2001年10月25日发布，2004年8月24日发布服务包2（ServicePack2），2008年4月21日发布最新的服务包3（ServicePack3）。Windows7，是由微软公司（Microsoft）开发的操作系统，内核版本号为WindowsNT6.1。Windows7可供家庭及商业工作环境：笔记本电脑、多媒体中心等使用。和同为NT6成员的WindowsVista一脉相承，Windows7继承了包括Aero风格等多项功能，并且在此基础上增添了些许功能。Windows10是由美国微软公司开发的应用于计算机和平板电脑的操作系统，于2015年7月29日发布正式版。Windows10操作系统在易用性和安全性方面有了极大的提升，除了针对云服务、智能移动设备、自然人机交互等新技术进行融合外，还对固态硬盘、生物识别、高分辨率屏幕等硬件进行了优化完善与支持。截至2022年5月26日，Windows10正式版已更新至Windows1021H2版本。[10]微软的操作系统WindowsVista（开发代码为Longhorn）于2007年1月30日发售。WindowsVista增加了许多功能，尤其是系统的安全性和网上管理功能，并且其拥有接口华丽的AeroGlass。但是整体而言，其在全球市场上的口碑却并不是很好。其后继者Windows7则是于2009年10月22日发售，Windows7改善了WindowsVista为人诟病的性能问题，相较于WindowsVista，在同样的硬件环境下，Windows7的表现较WindowsVista为好。而Windows10则是于2015年7月29日发售。最新的系统为Windows11,于2021年6月25日的直播中公布并发售[9]MacOSX主条目：MacOS和MacOSXmacOS，前称“MacOSX”或“OSX”，是一套运行于苹果Macintosh系列计算机上的操作系统。MacOS是首个在商用领域成功的图形用户界面系统。Macintosh开发成员包括比尔·阿特金森（BillAtkinson）、杰夫·拉斯金（JefRaskin）和安迪·赫茨菲尔德（AndyHertzfeld）。从OSX10.8开始在名字中去掉Mac，仅保留OSX和版本号。2016年6月13日在WWDC2016上，苹果公司将OSX更名为macOS，现行的最新的系统版本是13.X，即macOSVentura。[11]GoogleChromeOS主条目：GoogleChromeOSGoogleChromeOS是一项Google的轻型的、基于网络的计算机操作系统计划，其基于Google的浏览器GoogleChrome的Linux内核。2021年6月，华为鸿蒙系统正式亮相，国产操作系统迈出市场化和商业化重要一步。9月30日，面向数字基础设施的开源操作系统欧拉（openEuler）全新发布，与鸿蒙实现内核技术共享。11月9日，华为携手社区全体伙伴共同将欧拉开源操作系统正式捐赠给开放原子开源基金会，以推动操作系统产业快速发展。从服务器操作系统，升级为数字基础设施的操作系统，欧拉能够支持IT、CT、OT等数字基础设施全场景，覆盖服务器、云、边、嵌入式等各种设备形态的需求，更好地满足千行百业数字化转型的需求。[8]HarmonyOS操作系统2019年8月9日华为于东莞举行的华为开发者大会（HDC.2019）上正式发布的分布式操作系统-华为鸿蒙系统（HUAWEIHarmonyOS）。国产操作系统迈出市场化和商业化重要一步。鸿蒙OS是华为公司开发的一款基于微内核、面向5G物联网、面向全场景的分布式操作系统。鸿蒙的英文名是HarmonyOS，意为和谐。[16]这个新的操作系统将打通手机、电脑、平板、电视、工业自动化控制、无人驾驶、车机设备、智能穿戴统一成一个操作系统，并且该系统是面向下一代技术而设计的，能兼容全部安卓应用的所有Web应用。若安卓应用重新编译，在鸿蒙OS上，运行性能提升超过60%。[18]鸿蒙OS架构中的内核会把之前的Linux内核、鸿蒙OS微内核与LiteOS合并为一个鸿蒙OS微内核。创造一个超级虚拟终端互联的世界，将人、设备、场景有机联系在一起。同时由于鸿蒙系统微内核的代码量只有Linux宏内核的千分之一，其受攻击几率也大幅降低。[19]分布式架构首次用于终端OS，实现跨终端无缝协同体验；确定时延引擎和高性能IPC技术实现系统天生流畅；基于微内核架构重塑终端设备可信安全；[20]对于消费者而言，HarmonyOS通过分布式技术，让8+N设备具备智慧交互的能力。在不同场景下，8+N配合华为手机提供满足人们不同需求的解决方案。对于智能硬件开发者，HarmonyOS可以实现硬件创新，并融入华为全场景的大生态。对于应用开发者，HarmonyOS让他们不用面对硬件复杂性，通过使用封装好的分布式技术APIs，以较小投入专注开发出各种全场景新体验。[21]在万物智联时代重要机遇期，鸿蒙系统结合移动生态发展的趋势，提出了三大技术理念：一次开发，多端部署；可分可合，自由流转；统一生态，原生智能。实时操作系统（RTOS）这类系统的最大特色是实时性，就是在接收数据、指令后尽快处理，得出处理结果后会在规定时间内执行。家庭用户购买的物联网设备都是安装的RTOS。RTOS的种类很多，一般用户常碰见的有：1、RT-Thread：一个免费、开源的系统，诞生于2006年，由一名叫熊谱翔的开发者创立，目前由国内的开源社区维护，是一个地道的国产操作系统，对硬件的要求很低。国内厂商出品的物联网设备，智能空调、共享充电宝、智能电热水器、智能手环、智能手表等等，大部分都运行着RT-Thread，是目前国内做得最成熟、也是装机量最大的物联网系统。2、FreeRTOS：也是免费、开源的系统，对硬件的要求很低，获得了亚马逊的支持。国外厂商的物联网设备大部分安装的是FreeRTOS。3、LiteOS：这是华为开发的开源系统，主要运行在支持华为智能家居服务的物联网设备上，还有华为的GT系列智能手表中。4、QNX：一个闭源的操作系统，而且授权费不低，目前归属于加拿大的黑莓公司。QNX是一个安全性、稳定性极高的操作系统，长期以来被用于核电站、风力发电站、太空飞船、战斗机、CT扫描机、核磁共振扫描机等设备上。家庭用户购买到QNX设备主要有两类：一类是汽车，由于QNX的高安全性、高稳定性，一直受到众多汽车厂商的青睐，比如宝马、保时捷、福特、小鹏汽车等等，QNX几乎占据车载系统市场60%的市场份额；另一类是扫地机器人，部分品牌的扫地机器人使用的是QNX系统，如iRobot。应用软件：基本概念播报编辑计算机软件分为系统软件和应用软件两大类。应用软件是为满足用户不同领域、不同问题的应用需求而提供的那部分软件。它可以拓宽计算机系统的应用领域，放大硬件的功能。应用软件（applicationsoftware）是用户可以使用的各种程序设计语言，以及用各种程序设计语言编制的应用程序的集合，分为应用软件包和用户程序。应用软件包是利用计算机解决某类问题而设计的程序的集合供多用户使用。系统软件播报编辑系统软件是指控制和协调计算机及外部设备,支持应用软件开发和运行的系统，是无需用户干预的各种程序的集合，主要功能是调度，监控和维护计算机系统；负责管理计算机系统中各种独立的硬件，使得它们可以协调工作。系统软件使得计算机使用者和其他软件将计算机当作一个整体而不需要顾及到底层每个硬件是如何工作的。用途播报编辑办公室软件文书试算表程式投影片报告数学程式创建编辑器绘图程式基础数据库档案管理系统文本编辑器。[2]互联网软件即时通讯软件电子邮件客户端网页浏览器客户端下载工具。[2]多媒体软件媒体播放器图像编辑软件音讯编辑软件视讯编辑软件计算机辅助设计计算机游戏桌面排版[2]分析软件计算机代数系统统计软件数字计算计算机辅助工程设计[2]协作软件协作产品开发[2]商务软件会计软件企业工作流程分析客户关系管理Backoffice企业资源规划供应链管理产品生命周期管理[2]高级语言：简介播报编辑计算机语言具有高级语言和低级语言之分。而高级语言又主要是相对于汇编语言而言的，它是较接近自然语言和数学公式的编程，基本脱离了机器的硬件系统，用人们更易理解的方式编写程序。编写的程序称之为源程序[2]。高级语言并不是特指的某一种具体的语言，而是包括很多编程语言，如流行的java，c，c++，C#，pascal，python，lisp，prolog，FoxPro，易语言，中文版的C语言等等，这些语言的语法、命令格式都不相同[3]。高级语言与计算机的硬件结构及指令系统无关，它有更强的表达能力，可方便地表示数据的运算和程序的控制结构，能更好的描述各种算法，而且容易学习掌握。但高级语言编译生成的程序代码一般比用汇编程序语言设计的程序代码要长，执行的速度也慢。所以汇编语言适合编写一些对速度和代码长度要求高的程序和直接控制硬件的程序。高级语言、汇编语言和机器语言都是用于编写计算机程序的语言[4]。高级语言程序“看不见”机器的硬件结构，不能用于编写直接访问机器硬件资源的系统软件或设备控制软件。为此，一些高级语言提供了与汇编语言之间的调用接口。用汇编语言编写的程序，可作为高级语言的一个外部过程或函数，利用堆栈来传递参数或参数的地址[5]。发展历程播报编辑在编程语言经历了机器语言，汇编语言等更新之后，人们发现了限制程序推广的关键因素——程序的可移植性。需要设计一个能够不依赖于计算机硬件，能够在不同机器上运行的程序。这样可以免去很多编程的重复过程，提高效率，同时这种语言又要接近于数学语言或人的自然语言。在计算机还很稀缺的50年代，诞生了第一个高级编程语言。当时计算机的造价不菲，但是每天的计算量有有限，如何有效的利用计算机有限的计算能力成为了当时人们面对的问题。同时，因为资源的稀缺，计算机的运行效率也成为了那个年代工程师追寻的目标。为了更高效的使用计算机，人们设计出了高级编程语言，来满足人们对于高效简的编程语言的追求。用高级编程语言编写的程序需要经过翻译，翻译成机器所能识别的二进制数才能由计算机去执行。虽然，高级编程语言编写的程序需要一些时间去翻译代码，从而降低了计算机的执行效率，但是实践证明，高级编程语言为工程师带来的便利远远大于降低的执行效率。经过各软件工程师和专家的不懈努力，1954年，第一个完全意义的高级编程语言FORTRAN问世了，他完全脱离了特定机器的局限性，是第一个通用性的编程语言。从第一个编程语言问世到现今，共有几百种高级编程语言出现，很多语言成为了编程语言发展道路上的里程碑，影响很大。比如：BASIC、JAVA、C、C++、python等。高级编程语言也从早期的控制信号变成了现在的有结构有格式的程序编写工具，C++等语言的出现更是开启了面向对象编程语言的新章。同时伴随着软件编写效率的提高，软件开发也逐渐变成了有规模、有产业的商业项目[6]。特点播报编辑因为明确的目标性以及理解容易，一个新手很容易去学习高级编程语言。同时高级编程语言因为发展的历史，拥有很多函数库，用户可以根据自身的需求在代码中加入头文件来调用这些函数来实现自己的功能，当然使用者也可以根据自己的喜好编写函数来在后续的代码中调用[6]。高级编程语言作为一种通用的编程语言，它的语言结构和计算机本身的硬件以及指令系统无关，它的可阅读性更强，能够方便的表达程序的功能，更好的描述使用的算法。同时，它更容易被初学者所掌握，很容易学习。而且容易学习掌握。但是高级编程语言因为是一种编译语言，所以他的运行速度比汇编程序要低，同时因为高级语言比较冗长，所以代码的执行速度也要慢一些[6]。高级编程语言，作为用户层面的编程工具，用户并不需要去了解硬件的结构，而是去用逻辑的语言去实现想要的目标，但是因为高级编程语言的架构高于汇编，所以不能编写直接访问硬件资源的系统程序，因此，高级编程语言必须要调用汇编语言编写的程序来访问硬件地址[6]。分类播报编辑1.命令式语言。这种语言的语义基础是模拟“数据存储/数据操作”的图灵机可计算模型，十分符合现代计算机体系结构的自然实现方式。其中产生操作的主要途径是依赖语句或命令产生的副作用。现代流行的大多数语言都是这一类型，比如Fortran、Pascal、Cobol、C、C++、Basic、Ada、Java、C#等，各种脚本语言也被看作是此种类型[7]。2.函数式语言。这种语言的语义基础是基于数学函数概念的值映射的λ算子可计算模型。这种语言非常适合于进行人工智能等工作的计算。典型的函数式语言如Lisp、Haskell、ML、Scheme、F#等[7]。3.逻辑式语言。这种语言的语义基础是基于一组已知规则的形式逻辑系统。这种语言主要用在专家系统的实现中。最著名的逻辑式语言是Prolog[7]。4.面向对象语言。现代语言中的大多数都提供面向对象的支持，但有些语言是直接建立在面向对象基本模型上的，语言的语法形式的语义就是基本对象操作。主要的纯面向对象语言是Smalltalk[7]。性能分析播报编辑接口分析接口主要指高级语言与汇编语言之间的联系性，Ada语言在应用的过程中可以访问汇编语言，访问情况的实现只需要程序功能，程序功能在使用的过程中破解所设定的环节，进行访问工作。对C语言而言，将汇编语言作为整体看成一个独立的部分，将独立的部分加入C的程序中，具有通讯功能。对于Macros的应用，可以应用在汇编语言中，借助编译器完成各种工作。语言的性能并没有改变，Java语言与汇编语言的关系可以将其作为一个代码，此代码具有移植性，直接移植便可以进行操作，操作的过程方面并没有过多复杂程序[8]。寻址分析Ada寻址情况主要借助的是SYSTEM实现，可以准确的寻址；C的寻址需要借助指针实现，可以精确的实现寻址，对于存储器寻址情况需要应用peek完成，Modula-2的寻址情况与Ada所借助的情况一致，可以吸纳绝对的寻址[8]。位操作分析对于不同语言具有不同的位情况，所表达的从句中可以明确指出Ada的位，会存在很多位的情况，将其组合，通过逻辑原理进行处理。C的主要功能是位操作，对于Modula-2主要借助BIYSTE，应用这样的方式可以准确进行位操作[8]。任务支持分析不同的语言任务功能不一样，对于Ada具有较多的任务，其支持性强，可以实现多种任务同时工作的情况。C与Ada相比不具有这样的优势，Modula-2与Ada相比并没有其完善性，需要借助机制实现。对于这样的优势是Ada，可以独立的完成[8]。控制程序分析系统的设定需要控制程序，对于高级语言会涵盖一定的控制结构，像Ada中具有控制能力，对于其分支可以完全掌控其运行。C中并没有完善的控制结构，主要是对分值方面使用灵活，并且简单易操作，在使用的过程中应严格按照其规定操作，避免人为原因造成问题出现。Modula-2的控制系统只是控制分支，转移需要应用FXIT，操作的过程中应严格审查操作环节，避免其操作的过程中造成出现问题，操作时应兢兢业业，因为这方面的人为操作易引起问题的形成[8]。高级语言的工作方式播报编辑高级语言设计的程序必须经过“翻译”以后才能被机器执行。“翻译”的方法有两种，一种是解释，一种是编译。解释是把源程序翻译一句，执行一句的过程，而编译是源程序翻译成机器指令形式的目标程序的过程，再用链接程序把目标程序链接成可执行程序后才能执行[9]。解释翻译过程。对高级语言程序进行解释并执行的程序称为解释程序（软件）。它的功能是读入源程序，按源程序动态逻辑顺序进行逐句分析、翻译，解释一句执行一句，不产生任何中间代码，最终得到程序的执行结果[9]。二级缓存：产品简介播报编辑L2缓存位于CPU与内存之间的临时存储器，它的容量比内存小但交换速度快。在缓存中的数据是内存中的一小部分，但这一小部分是短时间内CPU即将访问的，当CPU调用大量数据时，就可避开内存直接从缓存中调用，从而加快读取速度。由此可见，在CPU中加入缓存是一种高效的解决方案，这样整个内存储器（缓存+内存）就变成了既有缓存的高速度，又有内存的大容量的存储系统了。缓存对CPU的性能影响很大，主要是因为CPU的数据交换顺序和CPU与缓存间的带宽引起的。L2原理播报编辑缓存的工作原理是当CPU要读取一个数据时，首先从缓存中查找，如果找到就立即读取并送给CPU处理；如果没有找到，就用相对慢的速度从内存中读取并送给CPU处理，同时把这个数据所在的数据块调入缓存中，可以使得以后对整块数据的读取都从缓存中进行，不必再调用内存。正是这样的读取机制使CPU读取缓存的命中率非常高（大多数CPU可达90%左右），也就是说CPU下一次要读取的数据90%都在缓存中，只有大约10%需要从内存读取。这大大节省了CPU直接读取内存的时间，也使CPU读取数据时基本无需等待。总的来说，CPU读取数据的顺序是先缓存后内存。[1]L2发展历史播报编辑最早先的CPU缓存是个整体的，而且容量很低，英特尔公司从Pentium时代开始把缓存进行了分类。当时集成在CPU内核中的缓存已不足以满足CPU的需求，而制造工艺上的限制又不能大幅度提高缓存的容量。因此出现了集成在与CPU同一块电路板上或主板上的缓存，此时就把CPU内核集成的缓存称为一级缓存，而外部的称为二级缓存。一级缓存中还分数据缓存（D-Cache）和指令缓存（I-Cache）。二者分别用来存放数据和执行这些数据的指令，而且两者可以同时被CPU访问，减少了争用Cache所造成的冲突，提高了处理器效能。英特尔公司在推出Pentium4处理器时，还新增了一种一级追踪缓存，容量为12KB.发展过程随着CPU制造工艺的发展，二级缓存也能轻易的集成在CPU内核中，容量也在逐年提升。再用集成在CPU内部与否来定义一、二级缓存，已不确切。而且随着二级缓存被集成入CPU内核中，以往二级缓存与CPU大差距分频的情况也被改变，此时其以相同于主频的速度工作，可以为CPU提供更高的传输速度。二级缓存是CPU性能表现的关键之一，在CPU核心不变化的情况下，增加二级缓存容量能使性能大幅度提高。而同一核心的CPU高低端之分往往也是在二级缓存上有差异，由此可见二级缓存对于CPU的重要性。CPU在缓存中找到有用的数据被称为命中，当缓存中没有CPU所需的数据时（这时称为未命中），CPU才访问内存。从理论上讲，在一颗拥有二级缓存的CPU中，读取一级缓存的命中率为80%。也就是说CPU一级缓存中找到的有用数据占数据总量的80%，剩下的20%从二级缓存中读取。由于不能准确预测将要执行的数据，读取二级缓存的命中率也在80%左右（从二级缓存读到有用的数据占总数据的16%）。那么还有的数据就不得不从内存调用，但这已经是一个相当小的比例了。较高端的CPU中，还会带有三级缓存，它是为读取二级缓存后未命中的数据设计的—种缓存，在拥有三级缓存的CPU中，只有约5%的数据需要从内存中调用，这进一步提高了CPU的效率。为了保证CPU访问时有较高的命中率，缓存中的内容应该按一定的算法替换。一种较常用的算法是“最近最少使用算法”（LRU算法），它是将最近一段时间内最少被访问过的行淘汰出局。因此需要为每行设置一个计数器，LRU算法是把命中行的计数器清零，其他各行计数器加1。当需要替换时淘汰行计数器计数值最大的数据行出局。这是一种高效、科学的算法，其计数器清零过程可以把一些频繁调用后再不需要的数据淘汰出缓存，提高缓存的利用率。CPU产品中，一级缓存的容量基本在4KB到18KB之间，二级缓存的容量则分为128KB、256KB、512KB、1MB等。一级缓存容量各产品之间相差不大，而二级缓存容量则是提高CPU性能的关键。二级缓存容量的提升是由CPU制造工艺所决定的，容量增大必然导致CPU内部晶体管数的增加，要在有限的CPU面积上集成更大的缓存，对制造工艺的要求也就越高。[2]使用方法播报编辑双核心CPU的二级缓存比较特殊，和以前的单核心CPU相比，最重要的就是两个内核的缓存所保存的数据要保持一致，否则就会出现错误，为了解决这个问题不同的CPU使用了不同的办法：Intel双核心处理器的二级缓存Intel的双核心CPU主要有PentiumD、PentiumEE、CoreDuo三种，其中PentiumD、PentiumEE的二级缓存方式完全相同。PentiumD和PentiumEE的二级缓存都是CPU内部两个内核具有互相独立的二级缓存，其中，8xx系列的Smithfield核心CPU为每核心1MB，而9xx系列的Presler核心CPU为每核心2MB。这种CPU内部的两个内核之间的缓存数据同步是依靠位于主板北桥芯片上的仲裁单元通过前端总线在两个核心之间传输来实现的，所以其数据延迟问题比较严重，性能并不尽如人意。CoreDuo使用的核心为Yonah，它的二级缓存则是两个核心共享2MB的二级缓存，共享式的二级缓存配合Intel的“Smartcache”共享缓存技术，实现了真正意义上的缓存数据同步，大幅度降低了数据延迟，减少了对前端总线的占用，性能表现不错，是双核心处理器上最先进的二级缓存架构。今后Intel的双核心处理器的二级缓存都会采用这种两个内核共享二级缓存的“Smartcache”共享缓存技术。AMD双核心处理器的二级缓存Athlon64X2CPU的核心主要有Manchester和Toledo两种，他们的二级缓存都是CPU内部两个内核具有互相独立的二级缓存，其中，Manchester核心为每核心512KB，而Toledo核心为每核心1MB。处理器内部的两个内核之间的缓存数据同步是依靠CPU内置的SystemRequestInterface(系统请求接口，SRI)控制，传输在CPU内部即可实现。这样一来，不但CPU资源占用很小，而且不必占用内存总线资源，数据延迟也比Intel的Smithfield核心和Presler核心大为减少，协作效率明显胜过这两种核心。不过，由于这种方式仍然是两个内核的缓存相互独立，从架构上来看也明显不如以Yonah核心为代表的Intel的共享缓存技术SmartCache。小型计算机：简介播报编辑小型计算机是相对于[1]大型计算机而言，小型计算机的软件、硬件系统规模比较小，但价格低、可靠性高、操作灵活方便，便于维护和使用。为了有效发挥计算机资源的功能和提高性能-价格比而采取的方法有四种：1、根据不同用途采用不同字长，尽可能在满足应用要求的前提下用较短的字长，以压缩计算机规模，从而降低造价。在已有的小型机中,字长为16位者较为普遍,如美国的PDP-11系列、NOVA系列,中国的DJS100系列。2、采用微程序控制结构，结构规整，便于实现生产标准化。它又能灵活地实现各种控制功能，可根据不同应用编制相应的微程序，以获得良好的性能－价格比。3、按处理能力分档，研制小型机系列。同一系列中各档小型机的字长和指令系统往往相同，只是规模大小、处理能力不同。为各档小型机研制各种可供选择的功能部件和接口，而且使主存储器和外围设备等的配置规模也有一定的变化范围。这样，可以针对不同的应用规模选用系列中适当型号及其系统配置规模。4、研制各种软件，如实时操作系统、多用户分时操作系统、各种高级语言（包括专用语言）和各类应用程序包等，以获得解决各种应用问题的良好效果。微型化播报编辑小型机和超大规模集成电路技术的发展为微型计算机的诞生创造了条件。8位和8位以下的微型计算机、单板机和微处理器以及16位的单板机和微处理器的成本比小型机大大降低，也更便于维护和使用。在小型计算机应用领域，微型计算机与小型计算机相辅相成，得到广泛的应用。为了提高小型计算机的性能－价格比，不少厂家利用大规模集成电路技术实现小型计算机的微型化。因为体系逻辑结构是现成的，研制生产周期可以缩短，原先研制的软件也可以使用。超级小型计算机播报编辑为了向上扩大小型计算机的应用领域，已采用各种技术研制出[2]超级小型计算机。这些高性能小型计算机的处理能力达到或超过了低档大型计算机的能力。因此，小型计算机和大型计算机的界线也有了一定的交错。提高性能的技术措施主要有四个方面。1、字长增加到32位，以便提高运算精度和速度，增强指令功能，扩大寻址范围，使计算机的处理能力大大提高。2、采用大型计算机中的一些技术，如采用流水线结构、通用寄存器、超高速缓冲存储器、快速总线和通道等来提高系统的运算速度和吞吐率。3、采用各种大规模集成电路，用快速存储器、门阵列、程序逻辑阵列、大容量存储芯片和各种接口芯片等构成计算机系统，以缩小体积和减少功耗，提高性能和可靠性。4、研制功能更强的系统软件、工具软件、通信软件、数据库和应用程序包，以及能支持软件核心部分的硬件系统结构、指令系统和固件，软件、硬件结合起来构成用途广泛的高性能系统。解释器：执行方式播报编辑Python、TCL和各种Shell程序一般而言是使用解释器执行的。微软公司的Qbasic语言也是解释方式，它不能生成可执行程序（但QuickBasic和VisualBasic可以）；运用广泛的网络编程语言java则同时有解释和编译方式。在开始之前有必要再次强调：下面介绍的解释器是一个源代码解释器。也就是说，解释器在执行时，每次读入一条语句，并且根据这条语句执行特定的操作；然后再读入下一条语句，依次类推。这与伪代码解释器是有所区别的，例如早期的Java运行时系统。两者的区别在于：源代码解释器直接对程序的源代码解释执行；而伪代码解释器先将程序的源代码转化为某种与机器无关的中间代码，然后再执行中间代码。相比之下，源代码解释器更易于创建，并且不需要一个独立的编译过程。子系统播报编辑SmallBASIC解释器包括两个主要的子系统：一个是表达式解析器，负责处理数字表达式；另一个是解释器，负责程序的实际执行。对于前者，可采用本书第二章所介绍的表达式解析器。但是在这里做了某些改进，使得解析器能够解析包含在程序语句中的数字表达式，而不是只能解析孤立的表达式。解释器子系统和解析器子系统包含在同一个解释器类中，该类名为SBasic。尽管从理论上讲可以使用两个独立的类：一个包含解释器，另一个包含表达式解析器；但是将两者用同一个类来实现的代效率会更高，因为表达式解析器和解释器的代码是密不可分的。例如，两个子系统都操作保存着程序代码的同一个字符数组。如果将它们分别安排在两个类中，将会增加可观的额外开销，并导致性能上的损失和功能上的重复。此外，由于程序解释的任务繁重，而解析表达式只是其中的一部分，因此将整个解释机制包含在单个类中是很有意义的。解释器执行时，每次从程序的源代码中读入一个标识符。如果读入的是关键字，解释器就按照该关键字的要求执行规定的操作。举例来说，当解释器读入一个PRINT后，它将打印PRINT之后的字符；当读入一个GOSUB时，它就执行指定的子程序。在到达程序的结尾之前，这个过程将反复进行。可以看到，解释器只是简单地执行程序指定的动作。解释编译播报编辑解释器运行程序的方法有：1.直接运行高级编程语言（如Shell自带的解释器）2.转换高级编程语言码到一些有效率的字节码(Bytecode)，并运行这些字节码3.以解释器包含的编译器对高级语言编译，并指示处理器运行编译后的程序(例如:JIT)Perl，Python，MATLAB，与Ruby是属于第二种方法，而UCSDPascal则是属于第三种方式。在转译的过程中，这组高级语言所写成的程序仍然维持在源代码的格式（或某种中继语言的格式），而程序本身所指涉的动作或行为则由解释器来表现。使用解释器来运行程序会比直接运行编译过的机器码来得慢，但是相对的这个直译的行为会比编译再运行来得快。这在程序开发的雏型化阶段和只是撰写试验性的代码时尤其来得重要，因为这个“编辑-直译-除错”的循环通常比“编辑-编译-运行-除错”的循环来得省时许多。在解释器上运行程序比直接运行编译过的代码来得慢，是因为解释器每次都必须去分析并转译它所运行到的程序行，而编译过的程序就只是直接运行。这个在运行时的分析被称为"直译式的成本"。在解释器中，变量的访问也是比较慢的，因为每次要访问变量的时候它都必须找出该变量实际存储的位置，而不像编译过的程序在编译的时候就决定好了变量的位置了。在使用解释器来达到较快的开发速度和使用编译器来达到较快的运行进度之间是有许多妥协的。有些系统(例如有一些LISP)允许直译和编译的代码互相调用并共享变量。这意味着一旦一个子程序在解释器中被测试并除错过之后，它就可以被编译以获得较快的运行进度。许多解释器并不像其名称所说的那样运行原始代码，反而是把原始代码转换成更压缩的内部格式。举例来说，有些BASIC的解释器会把keywords取代成可以用来在jumptable中找出相对应指令的单一byte符号。解释器也可以使用如同编译器一般的文字分析器（lexicalanalyzer）和语法分析器（parser）然后再转译产生出来的抽象语法树（abstractsyntaxtree）。可携性佳，直译式程序相较于编译式程序有较佳的可携性，可以容易的在不同软硬件平台上运行。而编译式程序经过编译后的程序则只限定于运行在开发环境平台。字节解释播报编辑考量程序运行之前所需要分析的时间，存在了一个介于直译与编译之间的可能性。例如，用EmacsLisp所撰写的源代码会被编译成一种高度压缩且优化的另一种Lisp源代码格式，这就是一种字节码（bytecode），而它并不是机器码（因此不会被绑死在特定的硬件上）。这个"编译过的"码之后会被字节码直译器（使用C写成的）转译。在这种情况下，这个"编译过的"码可以被说成是虚拟机（不是真的硬件，而是一种字节码解释器）的机器码。这个方式被用在OpenFirmware系统所使用的Forth代码中:原始程序将会被编译成"Fcode"（一种字节码），然后被一个特定平台的虚拟机直译和运行。[1]指令预取：预取技术:具体方法就是在不命中时，当数据从主存储器中取出送往CPU的同时，把主存储器相邻几个单元中的数据（称为一个数据块）都取出来送入Cache中。机器周期：简介播报编辑时序是用定时单位来说明的。MCS-51的时序定时单位共有4个，从小到大依次是：节拍、状态、机器周期和指令周期。下面分别加以说明[2]。节拍与状态：把振荡脉冲的周期定义为节拍（用p表示）。振荡脉冲经过二分频后定义为状态。一个状态就包含两个节拍[2]。机器周期：MCS-51采用定时控制方式，有固定的机器周期，规定一个机器周期的宽度为6个状态，并依次表示为S1-S6。由于一个状态包括两个节拍，因此一个机器周期总共有12个节拍，分别记作S1P1、S1P2、……、S6P2。因此一个机器周期就由12个振荡脉冲周期组成[3]。显然，当振荡脉冲频率为12MHz时，一个机器周期为1μs，当振荡脉冲频率为6MHz时，一个机器周期为2μs[3]。指令周期：指令周期是最大的时序定时单位，执行一条指令所需要的时间称为指令周期。MCS-51的指令周期根据指令的不同，可分别包含有一、二、四个机器周期[3]。指令周期播报编辑CPU每取出一条指令并执行这条指令，都要完成一系列的操作，这一系列操作所需要的时间通常叫做一个指令周期。换言之指令周期是取出一条指令并执行这条指令的时间。由于各条指令的操作功能不同，因此各种指令的指令周期是不尽相同的。例如一条加法指令的指令周期同一条乘法指令的指令周期是不相同的[4]。指令周期常常用若干个CPU周期数来表示，CPU周期也称为机器周期。由于CPU内部的操作速度快，而CPU访问一次内存所花的时间较长，通常用内存中读取一个指令字的最短时间来规定CPU周期。这就是说，一条指令的取出阶段（通常称为取指）需要一个CPU周期时间。而一个CPU周期时间又包含有若干个时钟周期（通常称为节拍脉冲或T周期，它是处理操作的最基本单位）。这些时钟周期的总和，决定了一个CPU周期的时间宽度。由此可知，取出和执行任何一条指令所需的最短时间为两个CPU周期。对于复杂一些的指令，则需要更多的CPU周期[4]。总线周期播报编辑1、微处理器是在时钟信号CLK控制下按节拍工作的。8086/8088系统的时钟频率为4.77MHz，每个时钟周期约为200ns[5]。2、由于存贮器和I/O端口是挂接在总线上的，CPU对存贮器和I/O接口的访问，是通过总线实现的。我们通常把CPU通过总线对微处理器外部（存储器或I/O接口）进行一次访问所需时间，称为一个总线周期[5]。时钟周期播报编辑时钟周期T又称为振荡周期，由单片机片内振荡电路OSC产生，常定义为时钟脉冲频率的倒数，是时序中最小的时间单位。例如，若某单片机时钟频率为1MHz，则它的时钟周期T应为1μs。由于时钟脉冲是计算机的基本工作脉冲，它控制着计算机的工作节奏，使计算机的每一步工作都统一到它的步调上来。显然，对同一种机型的计算机，时钟频率越高，计算机的工作速度就越快。但是，由于不同的计算机硬件电路和器件的不完全相同，所以它们需要的时钟周期频率范围也不一定相同[6]。相互关系播报编辑1、指令周期由若干个机器周期组成，而机器周期又包含若干个时钟周期，基本总线周期由4个时钟周期组成[7]。2、机器周期和总线周期的关系：机器周期指的是完成一个基本操作的时间，基本操作有时可能包含总线读/写，因而包含总线周期，但是有时可能与总线读/写无关，所以，并无明确的相互包含关系[7]。总线接口：产品简介播报编辑总线接口：显示卡要插在主板上才能与主板互相交换数据。与主板连接的接口主要ISA、EISA、VESA、PCI、AGP等几种。ISA和EISA总线带宽窄、速度慢，VESA总线扩展能力差，这三种总线已经被市场淘汰。现在常见的是PCI和AGP接口。PCI接口是一种总线接口，以1/2或1/3的系统总线频率工作（通常为33MHz），如果要在处理图像数据的同时处理其它数据，那么流经PCI总线的全部数据就必须分别地进行处理，这样势必存在数据滞留现象，在数据量大时，PCI总线就显得很紧张。AGP接口是为了解决这个问题而设计的，它是一种专用的显示接口（就是说，可以在主板的PCI插槽中插上声卡、显示卡、视频捕捉卡等板卡，却不能在主板的AGP插槽中插上除了AGP显示卡以外的任何板卡），具有独占总线的特点，只有图像数据才能通过AGP端口。另外AGP使用了更高的总线频率（66MHz），这样极大地提高了数据传输率。目前的显示卡接口的发展趋势是AGP接口。要留意的是，AGP技术分AGP1×和AGP2×，后者的最大理论数据传输率是前者的2倍，将会出现支持AGP4×的显示卡（例如Savage4），它的最大理论数据传输率将达到1056MB/s。区分AGP接口和PCI接口很容易，前者的引线上下宽度错开，俗称“金手指”，后者的引线上下一般齐。总线接口种类播报编辑总线接口是成像板卡与计算机链接的接口，总线接口包括：ISA/EISA、AGP、VME、VL、PCI/PCI-X、PCMCIA、PMC、PCIEXPRESS等。在机器视觉领域中广泛使用的总线接口主要是基于PCI的各种总线：PCI、PCI-X、PCIEXPRESS。PCI总线是独立于CPU的系统总线，采用了独特的中间缓冲器设计，可将高速的外围设备直接挂在CPU总线上，打破了瓶颈，使得CPU的性能得到充分的发挥。图像采集卡利用PCI总线的优点，实现了高速图像数据传输和主控系统的对接。为了实现PCI总线数据传输速度的进一步提高，PCISIG组织在PCI标准协议的基础上指定了PCI-X、PCIEXPRESS等快速数据传输标准。同时为了适应嵌入式系统应用，PCISIG也推出了PC104、PC104Plus、PXI、CompactPCI等标准。PCIPCI(PeripheralComponentInterconnected)总线是PentiumPC机的组成部分，理论带宽可达到132MB/S,通常可达到95MB/s.PCI-XPCI是PC总线的一种扩展架构，它与PCI总线不同的是，PCI总线必须频繁地在目标设备和总线之间交换数据，而PCI-X则允许目标设备仅在单个PCI-X设备进行交换。PCI-X有三种不同的工作频率，66MHz、100MHz和133MHz，在66MHz时数据率为1GB/s.PCI-EPCIEXPRESS也称PCI-E,是下一代PCI总线，原名为“3GIO”是由英特尔提出的，它的最大特点是传输速率快，PCI-E有X1、X4、X8、X16，PCI-X1的传输速率可达到500MB/s，X16可达到8GB/s。PC104/PC104plus/PXI/CompactPCI以上均为专门为嵌入式控制而定义的总线指令解码：cpu运作原理CPU的主要运作原理，不论其外观，都是执行储存于被称为程式里的一系列指令。在此讨论的是遵循普遍的架构设计的装置。程式以一系列数字储存在电脑记忆体中。差不多所有的CPU的运作原理可分为四个阶段：提取（Fetch）、解码（Decode）、执行（Execute）和写回（Writeback）。第一阶段，提取，从程式记忆体中检索指令（为数值或一系列数值）。由程式计数器（ProgramCounter）指定程式记忆体的位置，程式计数器保存供识别程式位置的数值。换言之，程式计数器记录了CPU在程式里的踪迹。提取指令之后，程式计数器根据指令式长度增加记忆体单元。指令的提取常常必须从相对较慢的记忆体寻找，导致CPU等候指令的送入。这个问题主要被论及在现代处理器的快取和管线化架构（见下）。CPU根据从记忆体提取到的指令来决定其执行行为。在解码阶段，指令被拆解为有意义的片断。根据CPU的指令集架构（ISA）定义将数值解译为指令。一部分的指令数值为运算码（Opcode），其指示要进行哪些运算。其它的数值通常供给指令必要的资讯，诸如一个加法（Addition）运算的运算目标。这样的运算目标也许提供一个常数值（即立即值），或是一个空间的定址值：暂存器或记忆体位址，以定址模式决定。在旧的设计中，CPU里的指令解码部分是无法改变的硬体装置。不过在众多抽象且复杂的CPU和指令集架构中，一个微程式时常用来帮助转换指令为各种形态的讯号。这些微程式在已成品的CPU中往往可以重写，方便变更解码指令。在提取和解码阶段之后，接着进入执行阶段。该阶段中，连接到各种能够进行所需运算的CPU部件。例如，要求一个加法运算，算数逻辑单元（ALU，ArithmeticLogicUnit）将会连接到一组输入和一组输出。输入提供了要相加的数值，而且在输出将含有总和结果。ALU内含电路系统，以于输出端完成简单的普通运算和逻辑运算（比如加法和位元运算）。如果加法运算产生一个对该CPU处理而言过大的结果，在标志暂存器里，运算溢出（ArithmeticOverflow）标志可能会被设置（参见以下的数值精度探讨）。最终阶段，写回，以一定格式将执行阶段的结果简单的写回。运算结果经常被写进CPU内部的暂存器，以供随后指令快速存取。在其它案例中，运算结果可能写进速度较慢，但容量较大且较便宜的主记忆体。某些类型的指令会操作程式计数器，而不直接产生结果资料。这些一般称作“跳转”（Jumps）并在程式中带来循环行为、条件性执行（透过条件跳转）和函式。许多指令也会改变标志暂存器的状态位元。这些标志可用来影响程式行为，缘由于它们时常显出各种运算结果。例如，以一个“比较”指令判断两个值的大小，根据比较结果在标志暂存器上设置一个数值。这个标志可藉由随后的跳转指令来决定程式动向。在执行指令并写回结果资料之后，程式计数器的值会递增，反覆整个过程，下一个指令周期正常的提取下一个顺序指令。如果完成的是跳转指令，程式计数器将会修改成跳转到的指令位址，且程式继续正常执行。许多复杂的CPU可以一次提取多个指令、解码，并且同时执行。这个部分一般涉及“经典RISC管线”，那些实际上是在众多使用简单CPU的电子装置中快速普及（常称为微控制（Microcontrollers））。CPU：发展历史播报编辑CPU出现于大规模集成电路时代，处理器架构设计的迭代更新以及集成电路工艺的不断提升促使其不断发展完善。从最初专用于数学计算到广泛应用于通用计算，从4位到8位、16位、32位处理器，最后到64位处理器，从各厂商互不兼容到不同指令集架构规范的出现，CPU自诞生以来一直在飞速发展。[1]CPU发展已经有50多年的历史了。我们通常将其分成六个阶段。[3](1)第一阶段(1971年-1973年)。这是4位和8位低档微处理器时代，代表产品是Intel4004处理器。[3]1971年，Intel生产的4004微处理器将运算器和控制器集成在一个芯片上，标志着CPU的诞生；1978年，8086处理器的出现奠定了X86指令集架构，随后8086系列处理器被广泛应用于个人计算机终端、高性能服务器以及云服务器中。[1](2)第二阶段(1974年-1977年)。这是8位中高档微处理器时代，代表产品是Intel8080。此时指令系统已经比较完善了。[3](3)第三阶段(1978年-1984年)。这是16位微处理器的时代，代表产品是Intel8086。相对而言已经比较成熟了。[3](4)第四阶段(1985年-1992年)。这是32位微处理器时代，代表产品是Intel80386。已经可以胜任多任务、多用户的作业。[3]1989年发布的80486处理器实现了5级标量流水线，标志着CPU的初步成熟，也标志着传统处理器发展阶段的结束。[1](5)第五阶段(1993年-2005年)。这是奔腾系列微处理器的时代。[3]1995年11月，Intel发布了Pentium处理器，该处理器首次采用超标量指令流水结构，引入了指令的乱序执行和分支预测技术，大大提高了处理器的性能，因此，超标量指令流水线结构一直被后续出现的现代处理器，如AMD（AdvancedMicrodevices）的锐龙、Intel的酷睿系列等所采用。[1](6)第六阶段(2005年后)。处理器逐渐向更多核心，更高并行度发展。典型的代表有英特尔的酷睿系列处理器和AMD的锐龙系列处理器。[3]为了满足操作系统的上层工作需求，现代处理器进一步引入了诸如并行化、多核化、虚拟化以及远程管理系统等功能，不断推动着上层信息系统向前发展。[1]工作原理播报编辑冯诺依曼体系结构是现代计算机的基础。在该体系结构下，程序和数据统一存储，指令和数据需要从同一存储空间存取，经由同一总线传输，无法重叠执行。根据冯诺依曼体系，CPU的工作分为以下5个阶段：取指令阶段、指令译码阶段、执行指令阶段、访存取数和结果写回。[1]取指令（IF，instructionfetch），即将一条指令从主存储器中取到指令寄存器的过程。程序计数器中的数值，用来指示当前指令在主存中的位置。当一条指令被取出后，程序计数器（PC）中的数值将根据指令字长度自动递增。[1]指令译码阶段（ID，instructiondecode），取出指令后，指令译码器按照预定的指令格式，对取回的指令进行拆分和解释，识别区分出不同的指令类别以及各种获取操作数的方法。现代CISC处理器会将拆分已提高并行率和效率。[1]执行指令阶段（EX，execute），具体实现指令的功能。CPU的不同部分被连接起来，以执行所需的操作。访存取数阶段（MEM，memory），根据指令需要访问主存、读取操作数，CPU得到操作数在主存中的地址，并从主存中读取该操作数用于运算。部分指令不需要访问主存，则可以跳过该阶段。[1]结果写回阶段（WB，writeback），作为最后一个阶段，结果写回阶段把执行指令阶段的运行结果数据“写回”到某种存储形式。结果数据一般会被写到CPU的内部寄存器中，以便被后续的指令快速地存取；许多指令还会改变程序状态字寄存器中标志位的状态，这些标志位标识着不同的操作结果，可被用来影响程序的动作。[1]在指令执行完毕、结果数据写回之后，若无意外事件（如结果溢出等）发生，计算机就从程序计数器中取得下一条指令地址，开始新一轮的循环，下一个指令周期将顺序取出下一条指令。[1]许多复杂的CPU可以一次提取多个指令、解码，并且同时执行。简介播报编辑中央处理器（CPU），是电子计算机的主要设备之一，电脑中的核心配件。其功能主要是解释计算机指令以及处理计算机软件中的数据。CPU是计算机中负责读取指令，对指令译码并执行指令的核心部件。中央处理器主要包括两个部分，即控制器、运算器，其中还包括高速缓冲存储器及实现它们之间联系的数据、控制的总线。电子计算机三大核心部件就是CPU、内部存储器、输入/输出设备。中央处理器的功效主要为处理指令、执行操作、控制时间、处理数据。[2]在计算机体系结构中，CPU是对计算机的所有硬件资源（如存储器、输入输出单元）进行控制调配、执行通用运算的核心硬件单元。CPU是计算机的运算和控制核心。计算机系统中所有软件层的操作，最终都将通过指令集映射为CPU的操作。[1]性能结构播报编辑性能衡量指标对于CPU而言，影响其性能的指标主要有主频、CPU的位数、CPU的缓存指令集、CPU核心数和IPC（每周期指令数）。所谓CPU的主频，指的就是时钟频率，它直接的决定了CPU的性能，可以通过超频来提高CPU主频来获得更高性能。而CPU的位数指的就是处理器能够一次性计算的浮点数的位数，通常情况下，CPU的位数越高，CPU进行运算时候的速度就会变得越快。21世纪20年代后个人电脑使用的CPU一般均为64位，这是因为64位处理器可以处理范围更大的数据并原生支持更高的内存寻址容量，提高了人们的工作效率。而CPU的缓存指令集是存储在CPU内部的，主要指的是能够对CPU的运算进行指导以及优化的硬程序。一般来讲，CPU的缓存可以分为一级缓存、二级缓存和三级缓存，缓存性能直接影响CPU处理性能。部分特殊职能的CPU可能会配备四级缓存。[4]CPU结构通常来讲，CPU的结构可以大致分为运算逻辑部件、寄存器部件和控制部件等。所谓运算逻辑部件，主要能够进行相关的逻辑运算，如：可以执行移位操作以及逻辑操作，除此之外还可以执行定点或浮点算术运算操作以及地址运算和转换等命令，是一种多功能的运算单元。而寄存器部件则是用来暂存指令、数据和地址的。控制部件则是主要用来对指令进行分析并且能够发出相应的控制信号。对于中央处理器来说，可将其看作一个规模较大的集成电路，其主要任务是加工和处理各种数据。传统计算机的储存容量相对较小，其对大规模数据的处理过程中具有一定难度，且处理效果相对较低。随着我国信息技术水平的迅速发展，随之出现了高配置的处理器计算机，将高配置处理器作为控制中心，对提高计算机CPU的结构功能发挥重要作用。中央处理器中的核心部分就是控制器、运算器，其对提高计算机的整体功能起着重要作用，能够实现寄存控制、逻辑运算、信号收发等多项功能的扩散，为提升计算机的性能奠定良好基础。[2]集成电路在计算机内起到了调控信号的作用，根据用户操作指令执行不同的指令任务。中央处理器是一块超大规模的集成电路。它由运算器、控制器、寄存器等组成，如下图，关键操作在于对各类数据的加工和处理。[5]中央处理器结构[5]传统计算机存储容量较小，面对大规模数据集的操作效率偏低。新一代计算机采用高配置处理器作为控制中心，CPU在结构功能方面有了很大的提升空间。中央处理器以运算器、控制器为主要装置，逐渐扩散为逻辑运算、寄存控制、程序编码、信号收发等多项功能。这些都加快了CPU调控性能的优化升级。[5]CPU总线CPU总线是在计算机系统中最快的总线，同时也是芯片组与主板的核心。人们通常把和CPU直接相连的局部总线叫做CPU总线或者称之为内部总线，将那些和各种通用的扩展槽相接的局部总线叫做系统总线或者是外部总线。在内部结构比较单一的CPU中，往往只设置一组数据传送的总线即CPU内部总线，用来将CPU内部的寄存器和算数逻辑运算部件等连接起来，因此也可以将这一类的总线称之为ALU总线。而部件内的总线，通过使用一组总线将各个芯片连接到一起，因此可以将其称为部件内总线，一般会包含地址线以及数据线这两组线路。系统总线指的是将系统内部的各个组成部分连接在一起的线路，是将系统的整体连接到一起的基础；而系统外的总线，是将计算机和其他的设备连接到一起的基础线路。[4]核心部分播报编辑运算器运算器是指计算机中进行各种算术和逻辑运算操作的部件，其中算术逻辑单元是中央处理核心的部分。[2]（1）算术逻辑单元（ALU）。算术逻辑单元是指能实现多组算术运算与逻辑运算的组合逻辑电路，其是中央处理中的重要组成部分。算术逻辑单元的运算主要是进行二位元算术运算，如加法、减法、乘法。在运算过程中，算术逻辑单元主要是以计算机指令集中执行算术与逻辑操作，通常来说，ALU能够发挥直接读入读出的作用，具体体现在处理器控制器、内存及输入输出设备等方面，输入输出是建立在总线的基础上实施。输入指令包含一个指令字，其中包括操作码、格式码等。[2]（2）中间寄存器（IR）。其长度为128位，其通过操作数来决定实际长度。IR在“进栈并取数”指令中发挥重要作用，在执行该指令过程中，将ACC的内容发送于IR，之后将操作数取到ACC，后将IR内容进栈。[2]（3）运算累加器（ACC）。当前的寄存器一般都是单累加器，其长度为128位。对于ACC来说，可以将它看成可变长的累加器。在叙述指令过程中，ACC长度的表示一般都是将ACS的值作为依据，而ACS长度与ACC长度有着直接联系，ACS长度的加倍或减半也可以看作ACC长度加倍或减半。[2]（4）描述字寄存器（DR）。其主要应用于存放与修改描述字中。DR的长度为64位，为了简化数据结构处理，使用描述字发挥重要作用。[2]（5）B寄存器。其在指令的修改中发挥重要作用，B寄存器长度为32位，在修改地址过程中能保存地址修改量，主存地址只能用描述字进行修改。指向数组中的第一个元素就是描述字，因此，访问数组中的其它元素应当需要用修改量。对于数组成员来说，其是由大小一样的数据或者大小相同的元素组成的，且连续存储，常见的访问方式为向量描述字，因为向量描述字中的地址为字节地址，所以，在进行换算过程中，首先应当进行基本地址的相加。对于换算工作来说，主要是由硬件自动实现，在这个过程中尤其要注意对齐，以免越出数组界限。[2]控制器控制器是指按照预定顺序改变主电路或控制电路的接线和改变电路中电阻值来控制电动机的启动、调速、制动与反向的主令装置。控制器由程序状态寄存器PSR，系统状态寄存器SSR，程序计数器PC，指令寄存器等组成，其作为“决策机构”，主要任务就是发布命令，发挥着整个计算机系统操作的协调与指挥作用。控制的分类主要包括两种，分别为组合逻辑控制器、微程序控制器，两个部分都有各自的优点与不足。其中组合逻辑控制器结构相对较复杂，但优点是速度较快；微程序控制器设计的结构简单，但在修改一条机器指令功能中，需对微程序的全部重编。[2]品牌介绍播报编辑“龙芯”系列芯片“龙芯”系列芯片是由中国科学院中科技术有限公司设计研制的，采用MIPS体系结构，具有自主知识产权，产品现包括龙芯1号小CPU、龙芯2号中CPU和龙芯3号大CPU三个系列，此外还包括龙芯7A1000桥片。龙芯1号系列32/64位处理器专为嵌入式领域设计，主要应用于云终端、工业控制、数据采集、手持终端、网络安全、消费电子等领域，具有低功耗、高集成度及高性价比等特点。其中龙芯lA32位处理器和龙芯1C64位处理器稳定工作在266～300MHz，龙芯1B处理器是一款轻量级32位芯片。龙芯1D处理器是超声波热表、水表和气表的专用芯片。2015年，新一代北斗导航卫星搭载着我国自主研制的龙芯1E和1F芯片，这两颗芯片主要用于完成星间链路的数据处理任务一。[6]龙芯2号系列是面向桌面和高端嵌入式应用的64位高性能低功耗处理器。龙芯2号产品包括龙芯2E、2F、2H和2K1000等芯片。龙芯2E首次实现对外生产和销售授权。龙芯2F平均性能比龙芯2E高20%以上，可用于个人计算机、行业终端、工业控制、数据采集、网络安全等领域。龙芯2H于2012年推出正式产品，适用计算机、云终端、网络设备、消费类电子等领域需求，同时可作为HT或者PCI-e接口的全功能套片使用。2018年，龙芯推出龙芯2K1000处理器，它主要是面向网络安全领域及移动智能领域的双核处理芯片，主频可达1GHz，可满足工业物联网快速发展、自主可控工业安全体系的需求。[6]龙芯3号系列是面向高性能计算机、服务器和高端桌面应用的多核处理器，具有高带宽，高性能，低功耗的特征。龙芯3A3000/3B3000处理器采用自主微结构设计，主频可达到1.5GHz以上；计划2019年面向市场的龙芯3A4000为龙芯第三代产品的首款四核芯片，该芯片基于28nm工艺，采用新研发的GS464V64位高性能处理器核架构，并实现256位向量指令，同时优化片内互连和访存通路，集成64位DDR3/4内存控制器，集成片内安全机制，主频和性能将再次得到大幅提升。[6]龙芯7A1000桥片是龙芯的第一款专用桥片组产品，目标是替代AMDRS780+SB710桥片组，为龙芯处理器提供南北桥功能。它于2018年2月份发布，目前搭配龙芯3A3000以及紫光4GDDR3内存应用在一款高性能网络平台上。该方案整体性能相较于3A3000+780e平台有较大提升，具有高国产率、高性能、高可靠性等特点。[6]Intel根据Intel产品线规划，截止2021年Intel十一代消费级酷睿有六类产品：i9/i7/i5/i3/奔腾/赛扬。此外还有面向服务器的至强铂金/金牌/银牌/铜牌和面向HEDT平台的至强W系列。AMD根据AMD产品线规划，截至2021年AMD锐龙5000系列处理器有Ryzen9/Ryzen7/Ryzen5/Ryzen3四个消费级产品线。此外还有面向服务器市场的第三代霄龙EPYC处理器和面向HEDT平台的线程撕裂者系列。[7]上海兆芯上海兆芯集成电路有限公司是成立于2013年的国资控股公司，其生产的处理器采用x86架构，产品主要有开先ZX-A、ZX-c/ZX-C+、ZX-D、开先KX一5000和KX一6000；开胜ZX—C+、ZX—D、KH一20000等。其中开先KX一5000系列处理器采用28nm工艺，提供4核或8核两种版本，整体性能较上一代产品提升高达140%，达到国际主流通用处理器性能水准，能够全面满足党政桌面办公应用，以及包括4K超高清视频观影等多种娱乐应用需求。开胜KH-20000系列处理器是兆芯面向服务器等设备推出的CPU产品。开先KX-6000系列处理器主频高达3.0GHz，兼容全系列Windows操作系统及中科方德、中标麒麟、普华等国产自主可控操作系统，性能与Intel第七代的酷睿i5相当。[6]上海申威申威处理器简称“Sw处理器”，出自于DEC的Alpha21164，采用Alpha架构，具有完全自主知识产权，其产品有单核Sw-1、双核Sw-2、四核Sw-410、十六核SW-1600/SW-1610等。神威蓝光超级计算机使用了8704片SW一1600，搭载神威睿思操作系统，实现了软件和硬件全部国产化。而基于Sw-26010构建的“神威·太湖之光”超级计算机自2016年6月发布以来，已连续四次占据世界超级计算机TOP500榜单第一，“神威·太湖之光”上的两项千万核心整机应用包揽了2016、2017年度世界高性能计算应用领域最高奖“戈登·贝尔”奖。[6]分类播报编辑指令集的方式CPU的分类还可以按照指令集的方式将其分为精简指令集计算机(RISC)和复杂指令集计算机(CISC)。RISC指令长度和执行时间恒定，CISC指令长度和执行时间不一定。RISC指令的并行的执行程度更好，并且编译器的效率也较高。CISC指令则对不同的任务有着更好的优化，代价是电路复杂且较难提高并行度。典型的CISC指令集有x86微架构，典型的RISC指令集有ARM微架构。但在现代处理器架构中RISC和CISC指令均会在译码环节进行转换，拆分成CPU内部的类RISC指令[4]嵌入式系统CPU传统的嵌入式领域所指范畴非常广泛，是处理器除了服务器和PC领域之外的主要应用领域。所谓“嵌入式”是指在很多芯片中，其所包含的处理器就像嵌入在里面不为人知一样。[8]近年来随着各种新技术新领域的进一步发展，嵌入式领域本身也被发展成了几个不同的子领域而产生了分化。[8]首先是随着智能手机(MobileSmartPhone)和手持设备(MobileDevice)的发展，移动(Mobile)领域逐渐发展成了规模匹敌甚至超过PC领域的一个独立领域。由于Mobile领域的处理器需要加载Linux操作系统，同时涉及复杂的软件生态，因此，其具有和PC领域一样对软件生态的严重依赖。[8]其次是实时(RealTime)嵌入式领域。该领域相对而言没有那么严重的软件依赖性，因此没有形成绝对的垄断，但是由于ARM处理器IP商业推广的成功，目前仍然以ARM的处理器架构占大多数市场份额，其他处理器架构譬如SynopsysARC等也有不错的市场成绩。[8]最后是深嵌入式领域。该领域更像前面所指的传统嵌入式领域。该领域的需求量非常之大，但往往注重低功耗、低成本和高能效比，无须加载像Linux这样的大型应用操作系统，软件大多是需要定制的裸机程序或者简单的实时操作系统，因此对软件生态的依赖性相对比较低。[8]大型机CPU大型机，或者称大型主机。大型机使用专用的处理器指令集、操作系统和应用软件。大型机一词，最初是指装在非常大的带框铁盒子里的大型计算机系统，以用来同小一些的小型机和微型机有所区别。[9]减少大型机CPU消耗是个重要工作。节约每个CPU周期，不仅可以延缓硬件升级，还可以降低基于使用规模的软件授权费。大型机体系结构主要包括以下两点：高度虚拟化，系统资源全部共享。大型机可以整合大量的负载于一体，并实现资源利用率的最大化；异步I/O操作。即当执行I/O操作时CPU将I/O指令交给I/O子系统来完成，CPU自己被释放执行其它指令。因此主机在执行繁重的I/O任务的同时，还可以同时执行其它工作。[9]控制技术形式播报编辑中央处理器强大的数据处理功有效提升了计算机的工作效率，在数据加工操作时，并不仅仅只是一项简单的操作，中央处理器的操作是建立在计算机使用人员下达的指令任务基础上，在执行指令任务过程中，实现用户输入的控制指令与CPU的相对应。随着我国信息技术的快速发展，计算机在人们生活、工作以及企业办公自动化中得到广泛应用，其作为一种主控设备，为促进电子商务网络的发展起着促进作用，使CPU控制性能的升级进程得到很大提高。指令控制、实际控制、操作控制等就是计算机CPU技术应用作用表现。[2]（1）选择控制。集中处理模式的操作，是建立在具体程序指令的基础上实施，以此满足计算机使用者的需求，CPU在操作过程中可以根据实际情况进行选择，满足用户的数据流程需求。指令控制技术发挥的重要作用。根据用户的需求来拟定运算方式，使数据指令动作的有序制定得到良好维持。CPU在执行当中，程序各指令的实施是按照顺利完成，只有使其遵循一定顺序，才能保证计算机使用效果。CPU主要是展开数据集自动化处理，其是实现集中控制的关键，其核心就是指令控制操作。[2]（2）插入控制。CPU对于操作控制信号的产生，主要是通过指令的功能来实现的，通过将指令发给相应部件，达到控制这些部件的目的。实现一条指令功能，主要是通过计算机中的部件执行一序列的操作来完成。较多的小控制元件是构建集中处理模式的关键，目的是为了更好的完成CPU数据处理操作。[2]（3）时间控制。将时间定时应用于各种操作中，就是所谓的时间控制。在执行某一指令时，应当在规定的时间内完成，CPU的指令是从高速缓冲存储器或存储器中取出，之后再进行指令译码操作，主要是在指令寄存器中实施，在这个过程中，需要注意严格控制程序时间。[2]与GPU比较播报编辑GPUGPU即图像处理器，CPU和GPU的工作流程和物理结构大致是类似的，相比于CPU而言，GPU的工作更为单一。在大多数的个人计算机中，GPU仅仅是用来绘制图像的。如果CPU想画一个二维图形，只需要发个指令给GPU，GPU就可以迅速计算出该图形的所有像素，并且在显示器上指定位置画出相应的图形。由于GPU会产生大量的热量，所以通常显卡上都会有独立的散热装置。[3]设计结构CPU有强大的算术运算单元，可以在很少的时钟周期内完成算术计算。同时，有很大的缓存可以保存很多数据在里面。此外，还有复杂的逻辑控制单元，当程序有多个分支的时候，通过提供分支预测的能力来降低延时。GPU是基于大的吞吐量设计，有很多的算术运算单元和很少的缓存。同时GPU支持大量的线程同时运行，如果他们需要访问同一个数据，缓存会合并这些访问，自然会带来延时的问题。尽管有延时，但是因为其算术运算单元的数量庞大，因此能够达到一个非常大的吞吐量的效果。[3]使用场景显然，因为CPU有大量的缓存和复杂的逻辑控制单元，因此它非常擅长逻辑控制、串行的运算。相比较而言，GPU因为有大量的算术运算单元，因此可以同时执行大量的计算工作，它所擅长的是大规模的并发计算，计算量大但是没有什么技术含量，而且要重复很多次。这样一说，我们利用GPU来提高程序运算速度的方法就显而易见了。使用CPU来做复杂的逻辑控制，用GPU来做简单但是量大的算术运算，就能够大大地提高程序的运行速度。[3]安全问题播报编辑CPU蓬勃发展的同时也带来了许多的安全问题。1994年出现在Pentium处理器上的FDIVbug（奔腾浮点除错误）会导致浮点数除法出现错误；1997年Pentium处理器上的F00F异常指令可导致CPU死机；2011年Intel处理器可信执行技术(TXT，trustedexecutiontechnology)存在缓冲区溢出问题，可被攻击者用于权限提升；2017年Intel管理引擎(ME，managementengine)组件中的漏洞可导致远程非授权的任意代码执行；2018年，Meltdown和Spectre两个CPU漏洞几乎影响到过去20年制造的每一种计算设备，使得存储在数十亿设备上的隐私信息存在被泄露的风险。这些安全问题严重危害国家网络安全、关键基础设施安全及重要行业的信息安全，已经或者将要造成巨大损失。[1]未来发展播报编辑通用中央处理器(CPU)芯片是信息产业的基础部件，也是武器装备的核心器件。我国缺少具有自主知识产权的CPU技术和产业，不仅造成信息产业受制于人，而且国家安全也难以得到全面保障。“十五”期间，国家“863计划”开始支持自主研发CPU。“十一五”期间，“核心电子器件、高端通用芯片及基础软件产品”(“核高基”)重大专项将“863计划”中的CPU成果引入产业。从“十二五”开始，我国在多个领域进行自主研发CPU的应用和试点，在一定范围内形成了自主技术和产业体系，可满足武器装备、信息化等领域的应用需求。但国外CPU垄断已久，我国自主研发CPU产品和市场的成熟还需要一定时间。[10]片内总线：例如：现用2K*8位的静态RAM芯片构成8K*8位存储器，若CPU输出的地址信号为20位。片内地址总线就是11位(2Kb=211b)。计算机网络：定义分类播报编辑按广义计算机网络链接示意图计算机网络也称计算机通信网。关于计算机网络的最简单定义是：一些相互连接的、以共享资源为目的的、自治的计算机的集合。若按此定义，则早期的面向终端的网络都不能算是计算机网络，而只能称为联机系统（因为那时的许多终端不能算是自治的计算机）。但随着硬件价格的下降，许多终端都具有一定的智能，因而“终端”和“自治的计算机”逐渐失去了严格的界限。若用微型计算机作为终端使用，按上述定义，则早期的那种面向终端的网络也可称为计算机网络。[2]另外，从逻辑功能上看，计算机网络是以传输信息为基础目的，用通信线路将多个计算机连接起来的计算机系统的集合，一个计算机网络组成包括传输介质和通信设备。[2]从用户角度看，计算机网络是这样定义的：存在着一个能为用户自动管理的网络操作系统。由它调用完成用户所调用的资源，而整个网络像一个大的计算机系统一样，对用户是透明的。[2]一个比较通用的定义是：利用通信线路将地理上分散的、具有独立功能的计算机系统和通信设备按不同的形式连接起来，以功能完善的网络软件及协议实现资源共享和信息传递的系统。[2]从整体上来说计算机网络就是把分布在不同地理区域的计算机与专门的外部设备用通信线路互联成一个规模大、功能强的系统，从而使众多的计算机可以方便地互相传递信息，共享硬件、软件、数据信息等资源。简单来说，计算机网络就是由通信线路互相连接的许多自主工作的计算机构成的集合体。[2]最简单的计算机网络就只有两台计算机和连接它们的一条链路，即两个节点和一条链路。[2]按连接计算机网络就是通过线路互连起来的、自治的计算机集合，确切的说就是将分布在不同地理位置上的具有独立工作能力的计算机、终端及其附属设备用通信设备和通信线路连接起来，并配置网络软件，以实现计算机资源共享的系统。[2]按需求计算机网络（computernetworks）就是由大量独立的、但相互连接起来的计算机共同完成计算机任务的系统。[3]发展历程播报编辑自从计算机网络出现以后，它的发展速度与应用的广泛程度十分惊人。纵观计算机网络的发展，其大致经历了以下四个阶段：[2]诞生阶段20世纪60年代中期之前的第一代计算机网络是以单个计算机为中心的远程联机系统，典型应用是由一台计算机和全美范围内2000多个终端组成的飞机订票系统，终端是一台计算机的外围设备，包括显示器和键盘，无CPU和内存。随着远程终端的增多，在主机前增加了前端机(FEP)。当时，人们把计算机网络定义为“以传输信息为目的而连接起来，实现远程信息处理或进一步达到资源共享的系统”，这样的通信系统已具备网络的雏形。[2]形成阶段20世纪60年代中期至70年代的第二代计算机网络是以多个主机通过通信线路互联起来，为用户提供服务，兴起于60年代后期，典型代表是美国国防部高级研究计划局协助开发的ARPANET。主机之间不是直接用线路相连，而是由接口报文处理机(IMP)转接后互联的。IMP和它们之间互联的通信线路一起负责主机间的通信任务，构成了通信子网。通信子网互联的主机负责运行程序，提供资源共享，组成资源子网。这个时期，网络概念为“以能够相互共享资源为目的互联起来的具有独立功能的计算机之集合体”，形成了计算机网络的基本概念。[2]互联互通阶段20世纪70年代末至90年代的第三代计算机网络是具有统一的网络体系结构并遵守国际标准的开放式和标准化的网络。ARPANET兴起后，计算机网络发展迅猛，各大计算机公司相继推出自己的网络体系结构及实现这些结构的软硬件产品。由于没有统一的标准，不同厂商的产品之间互联很困难，人们迫切需要一种开放性的标准化实用网络环境，这样应运而生了两种国际通用的最重要的体系结构，即TCP/IP体系结构和国际标准化组织的OSI体系结构。[2]高速网络技术阶段20世纪90年代至今的第四代计算机网络，由于局域网技术发展成熟，出现光纤及高速网络技术，整个网络就像一个对用户透明的大的计算机系统，发展为以因特网(Internet)为代表的互联网。[2]组成播报编辑计算机网络的分类与一般的事物分类方法一样，可以按事物所具有的不同性质特点（即事物的属性）分类。计算机网络通俗地讲就是由多台计算机（或其它计算机网络设备）通过传输介质和软件物理（或逻辑）连接在一起组成的。总的来说计算机网络的组成基本上包括：计算机、网络操作系统、传输介质（可以是有形的，也可以是无形的，如无线网络的传输介质就是空间）以及相应的应用软件四部分。[3]功能播报编辑数据通信数据通信是计算机网络的最主要的功能之一。数据通信是依照一定的通信协议，利用数据传输技术在两个终端之间传递数据信息的一种通信方式和通信业务。它可实现计算机和计算机、计算机和终端以及终端与终端之间的数据信息传递，是继电报、电话业务之后的第三种最大的通信业务。数据通信中传递的信息均以二进制数据形式来表现，数据通信的另一个特点是总是与远程信息处理相联系，是包括科学计算、过程控制、信息检索等内容的广义的信息处理。[2]资源共享资源共享是人们建立计算机网络的主要目的之一。计算机资源包括硬件资源、软件资源和数据资源。硬件资源的共享可以提高设备的利用率，避免设备的重复投资，如利用计算机网络建立网络打印机；软件资源和数据资源的共享可以充分利用已有的信息资源，减少软件开发过程中的劳动，避免大型数据库的重复建设。[2]集中管理计算机网络技术的发展和应用，已使得现代的办公手段、经营管理等发生了变化。目前，已经有了许多管理信息系统、办公自动化系统等，通过这些系统可以实现日常工作的集中管理，提高工作效率，增加经济效益。[2]实现分布式处理网络技术的发展，使得分布式计算成为可能。对于大型的课题，可以分为许许多多小题目，由不同的计算机分别完成，然后再集中起来，解决问题。[2]负荷均衡负荷均衡是指工作被均匀的分配给网络上的各台计算机系统。网络控制中心负责分配和检测，当某台计算机负荷过重时，系统会自动转移负荷到较轻的计算机系统去处理。[2]由此可见，计算机网络可以大大扩展计算机系统的功能，扩大其应用范围，提高可靠性，为用户提供方便，同时也减少了费用，提高了性能价格比。[2]分类播报编辑虽然网络类型的划分标准各种各样，但是从地理范围划分是一种大家都认可的通用网络划分标准。按这种标准可以把各种网络类型划分为局域网、城域网、广域网和互联网四种。局域网一般来说只能是一个较小区域内，城域网是不同地区的网络互联，不过在此要说明的一点就是这里的网络划分并没有严格意义上地理范围的区分，只能是一个定性的概念。下面简要介绍这几种计算机网络。[4]局域网局域网（LocalAreaNetwork；LAN）通常我们常见的“LAN”就是指局域网，这是我们最常见、应用最广的一种网络。局域网随着整个计算机网络技术的发展和提高得到充分的应用和普及，几乎每个单位都有自己的局域网，有的甚至家庭中都有自己的小型局域网。很明显，所谓局域网，那就是在局部地区范围内的网络，它所覆盖的地区范围较小。局域网在计算机数量配置上没有太多的限制，少的可以只有两台，多的可达几百台。一般来说在企业局域网中，工作站的数量在几十到两百台次左右。在网络所涉及的地理距离上一般来说可以是几米至10公里以内。局域网一般位于一个建筑物或一个单位内，不存在寻径问题，不包括网络层的应用。[4]这种网络的特点就是：连接范围窄、用户数少、配置容易、连接速率高。目前局域网最快的速率要算现今的10G以太网了。IEEE的802标准委员会定义了多种主要的LAN网：以太网（Ethernet）、令牌环网（TokenRing）、光纤分布式接口网络（FDDI）、异步传输模式网（ATM）以及最新的无线局域网（WLAN）。这些都将在后面详细介绍。[4]城域网城域网示意图（MetropolitanAreaNetwork；MAN）这种网络一般来说是在一个城市，但不在同一地理小区范围内的计算机互联。这种网络的连接距离可以在10￣100公里，它采用的是IEEE802.6标准。MAN与LAN相比扩展的距离更长，连接的计算机数量更多，在地理范围上可以说是LAN网络的延伸。在一个大型城市或都市地区，一个MAN网络通常连接着多个LAN网。如连接政府机构的LAN、医院的LAN、电信的LAN、公司企业的LAN等等。由于光纤连接的引入，使MAN中高速的LAN互连成为可能。[4]城域网多采用ATM技术做骨干网。ATM是一个用于数据、语音、视频以及多媒体应用程序的高速网络传输方法。ATM包括一个接口和一个协议，该协议能够在一个常规的传输信道上，在比特率不变及变化的通信量之间进行切换。ATM也包括硬件、软件以及与ATM协议标准一致的介质。ATM提供一个可伸缩的主干基础设施，以便能够适应不同规模、速度以及寻址技术的网络。ATM的最大缺点就是成本太高，所以一般在政府城域网中应用，如邮政、银行、医院等。[4]广域网广域示意图（WideAreaNetwork，WAN）这种网络也称为远程网，所覆盖的范围比城域网（MAN）更广，它一般是在不同城市之间的LAN或者MAN网络互联，地理范围可从几百公里到几千公里。因为距离较远，信息衰减比较严重，所以这种网络一般是要租用专线，通过IMP（接口信息处理）协议和线路连接起来，构成网状结构，解决循径问题。这种城域网因为所连接的用户多，总出口带宽有限，所以用户的终端连接速率一般较低，通常为9.6Kbps-45Mbps如：邮电部的CHINANET，CHINAPAC，和CHINADDN网。[4]上面讲了网络的几种分类，其实在现实生活中我们真正遇得最多的还要算是局域网，因为它可大可小，无论在单位还是在家庭实现起来都比较容易，应用也是最广泛的一种网络，所以在下面我们有必要对局域网及局域网中的接入设备作一个进一步的认识。[4]无线网无线网随着笔记本电脑（notebookcomputer）和个人数字助理（PersonalDigitalAssistant，PDA）等便携式计算机的日益普及和发展，人们经常要在路途中接听电话、发送传真和电子邮件阅读网上信息以及登录到远程机器等。然而在汽车或飞机上是不可能通过有线介质与单位的网络相连接的，这时候可能会对无线网感兴趣了。虽然无线网与移动通信经常是联系在一起的，但这两个概念并不完全相同。例如当便携式计算机通过PCMCIA卡接入电话插口，它就变成有线网的一部分。另一方面，有些通过无线网连接起来的计算机的位置可能又是固定不变的，如在不便于通过有线电缆连接的大楼之间就可以通过无线网将两栋大楼内的计算机连接在一起。[4]无线网特别是无线局域网有很多优点，如易于安装和使用。但无线局域网也有许多不足之处：如它的数据传输率一般比较低，远低于有线局域网；另外无线局域网的误码率也比较高，而且站点之间相互干扰比较厉害。用户无线网的实现有不同的方法。国外的某些大学在它们的校园内安装许多天线，允许学生们坐在树底下查看图书馆的资料。这种情况是通过两个计算机之间直接通过无线局域网以数字方式进行通信实现的。另一种可能的方式是利用传统的模拟调制解调器通过蜂窝电话系统进行通信。在国外的许多城市已能提供蜂窝式数字信息分组数据（CellularDigitalPacketData，CDPD）的业务，因而可以通过CDPD系统直接建立无线局域网。无线网络是当前国内外的研究热点，无线网络的研究是由巨大的市场需求驱动的。无线网的特点是使用户可以在任何时间、任何地点接入计算机网络，而这一特性使其具有强大的应用前景。当前已经出现了许多基于无线网络的产品，如个人通信系统（PersonalCommunicationSystem，PCS）电话、无线数据终端、便携式可视电话、个人数字助理（PDA）等。无线网络的发展依赖于无线通信技术的支持。无线通信系统主要有：低功率的无绳电话系统、模拟蜂窝系统、数字蜂窝系统、移动卫星系统、无线LAN和无线WAN等。[4]性能播报编辑计算机网络的性能一般是指它的几个重要的性能指标。但除了这些重要的性能指标外，还有一些非性能特征，它们对计算机网络的性能也有很大的影响。[5]1．计算机网络的性能指标性能指标从不同的方面来度量计算机网络的性能。[5]（1）速率计算机发送出的信号都是数字形式的。比特是计算机中数据量的单位，也是信息论中使用的信息量的单位。英文字bit来源于binarydigit，意思是一个“二进制数字”，因此一个比特就是二进制数字中的一个1或0。网络技术中的速率指的是连接在计算机网络上的主机在数字信道上传送数据的速率，它也称为数据率（datarate）或比特率（bitrate）。速率是计算机网络中最重要的一个性能指标。速率的单位是bit/s（比特每秒）（即bitpersecond）。[5]（2）带宽“带宽”有以下两种不同的意义。[5]①带宽本来是指某个信号具有的频带宽度。信号的带宽是指该信号所包含的各种不同频率成分所占据的频率范围。例如，在传统的通信线路上传送的电话信号的标准带宽是3.1kHz（从300Hz到3.4kHz，即话音的主要成分的频率范围）。这种意义的带宽的单位是赫（或千赫，兆赫，吉赫等）。[5]②在计算机网络中，带宽用来表示网络的通信线路所能传送数据的能力，因此网络带宽表示在单位时间内从网络中的某一点到另一点所能通过的“最高数据率”。这里一般说到的“带宽”就是指这个意思。这种意义的带宽的单位是“比特每秒”，记为bit/s。[5]（3）吞吐量吞吐量表示在单位时间内通过某个网络（或信道、接口）的数据量。吞吐量更经常地用于对现实世界中的网络的一种测量，以便知道实际上到底有多少数据量能够通过网络。显然，吞吐量受网络的带宽或网络的额定速率的限制。例如，对于一个100Mbit/s的以太网，其额定速率是100Mbit/s，那么这个数值也是该以太网的吞吐量的绝对上限值。因此，对100Mbit/s的以太网，其典型的吞吐量可能也只有70Mbit/s。有时吞吐量还可用每秒传送的字节数或帧数来表示。[5]（4）时延时延是指数据（一个报文或分组，甚至比特）从网络（或链路）的一端传送到另一端所需的时间。时延是个很重要的性能指标，它有时也称为延迟或迟延。网络中的时延是由以下几个不同的部分组成的。[5]①发送时延。发送时延是主机或路由器发送数据帧所需要的时间，也就是从发送数据帧的第一个比特算起，到该帧的最后一个比特发送完毕所需的时间。[5]因此发送时延也叫做传输时延。发送时延的计算公式是：[5]发送时延=数据帧长度（bit/s）/信道带宽（bit/s）[5]由此可见，对于一定的网络，发送时延并非固定不变，而是与发送的帧长（单位是比特）成正比，与信道带宽成反比。[5]②传播时延。传播时延是电磁波在信道中传播一定的距离需要花费的时间。传播时延的计算公式是：[5]传播时延=信道长度（m）/电磁波在信道上的传播速率（m/s）[5]电磁波在自由空间的传播速率是光速，即300000km/s。电磁波在网络传输媒体中的传播速率比在自由空间要略低一些。[5]③处理时延。主机或路由器在收到分组时要花费一定的时间进行处理，例如分析分组的首部，从分组中提取数据部分，进行差错检验或查找适当的路由等，这就产生了处理时延。[5]④排队时延。分组在经过网络传输时，要经过许多的路由器。但分组在进入路由器后要先在输入队列中排队等待处理。在路由器确定了转发接口后，还要在输出队列中排队等待转发。这就产生了排队时延。[5]这样，数据在网络中经历的总时延就是以上四种时延之和：[5]总时延=发送时延+传播时延+处理时延+排队时延[5]（5）时延带宽积把以上讨论的网络性能的两个度量—传播时延和带宽相乘，就得到另一个很有用的度量：传播时延带宽积，即时延带宽积=传播时延×带宽。[5]（6）往返时间（RTT）在计算机网络中，往返时间也是一个重要的性能指标，它表示从发送方发送数据开始，到发送方收到来自接收方的确认（接受方收到数据后便立即发送确认）总共经历的时间。[5]当使用卫星通信时，往返时间（RTT）相对较长。[5]（7）利用率利用率有信道利用率和网络利用率两种。信道利用率指某信道有百分之几的时间是被利用的（有数据通过），完全空闲的信道的利用率是零。网络利用率是全网络的信道利用率的加权平均值。[5]2．计算机网络的非性能特征这些非性能特征与前面介绍的性能指标有很大的关系。[5]（1）费用即网络的价格（包括设计和实现的费用）。网络的性能与其价格密切相关。一般说来，网络的速率越高，其价格也越高。[5]（2）质量网络的质量取决于网络中所有构件的质量，以及这些构件是怎样组成网络的。网络的质量影响到很多方面，如网络的可靠性、网络管理的简易性，以及网络的一些性能。但网络的性能与网络的质量并不是一回事，例如，有些性能也还可以的网络，运行一段时间后就出现了故障，变得无法再继续工作，说明其质量不好。高质量的网络往往价格也较高。[5]（3）标准化网络的硬件和软件的设计既可以按照通用的国际标准，也可以遵循特定的专用网络标准。最好采用国际标准的设计，这样可以得到更好的互操作性，更易于升级换代和维修，也更容易得到技术上的支持。[5]（4）可靠性可靠性与网络的质量和性能都有密切关系。速率更高的网络，其可靠性不一定会更差。但速率更高的网络要可靠地运行，则往往更加困难，同时所需的费用也会较高。[5]（5）可扩展性和可升级性网络在构造时就应当考虑到今后可能会需要扩展（即规模扩大）和升级（即性能和版本的提高）。网络的性能越高，其扩展费用往往也越高，难度也会相应增加。[5]（6）易于管理和维护网络如果没有良好的管理和维护，就很难达到和保持所设计的性能。[5]相关应用播报编辑21世纪人类将全面进入信息时代。信息时代的重要特征就是数字化、网络化和信息化。要实现信息化就必须依靠完善的网络，因为网络可以非常迅速地传递信息。因此网络现在已经成为信息社会的命脉和发展知识经济的重要基础。网络对社会生活的很多方面以及对社会经济的发展已经产生了不可估量的影响。[3]这里所说的网络是指“三网”，即电信网络、有线电视网络和计算机网络。这三种网络向用户提供的服务不同。电信网络的用户可得到电话、电报以及传真等服务；有线电视网络的用户能够观看各种电视节目；计算机网络则可使用户能够迅速传送数据文件，以及从网络上查找并获取各种有用资料，包括图像和视频文件。这三种网络在信息化过程中都起到十分重要的作用，但其中发展最快的并起到核心作用的是计算机网络。随着技术的发展，电信网络和有线电视网络都逐渐融入了现代计算机网络（也称计算机通信网）的技术，这就产生了“网络融合”的概念。[3]自从20世纪90年代以后，以因特网（Internet）为代表的计算机网络得到了飞速的发展，已从最初的教育科研网络逐步发展成为商业网络，并已成为仅次于全球电话网的世界第二大网络。因特网正在改变着我们工作和生活的各个方面，它已经给很多国家带来了巨大的好处，并加速了全球信息革命的进程。因特网是人类自印刷术发明以来在通信方面最大的变革。现在，人们的生活、工作、学习和交往都已离不开因特网了。[3]计算机网络向用户提供的最重要的功能有两个，即连通性和共享。[3]为什么会建立这么多的计算机网络，主要还是因为计算机网络的运用受到个人和公司的青睐。[3]一、商业运用。1、主要是实现资源共享（resourcesharing）最终打破地理位置束缚（tyrannyofgeography）,主要运用客户-服务器模型（client-servermodel）。[3]2、提供强大的通信媒介（communicationmedium）。如：电子邮件（E-mail）、视频会议。[3]3、电子商务活动。如：各种不同供应商购买子系统，然后在将这些部件组装起来。[3]4、通过Internet与客户做各种交易。如：书店、音像在家里购买商品或者服务。[3]二、家庭运用1、访问远程信息。如：浏览Web页面获得艺术、商务、烹饪、政府、健康、历史、爱好、娱乐、科学、运动、旅游等等信息。[3]2、个人之间的通信。如：即时消息（instantmessaging）运用<QQ、MSN、YY>、聊天室、对等通信（peer-to-communication）<通过中心数据库共享，各大网盘，但是容易造成侵犯版权>。[3]3、交互式娱乐。如：视频点播、即时评论及参加活动<电视直播网络互动>、网络游戏。[3]4、广义的电子商务。如：电子方式支付账单、管理银行账户、处理投资。[3]三、移动用户以无线网络为基础。[3]1、可移动的计算机：笔记本计算机、PDA、3G手机。[3]2、军事：一场战争不可能靠局域网设备通信。[3]3、运货车队、出租车、快递专车等应用。[3]四、社会问题网络的广泛运用已经导致了新的社会、伦理和政治问题。[3]局域网：局域网简介播报编辑局域网自然就是局部地区形成的一个区域网络，其特点就是分布地区范围有限，可大可小，大到一栋建筑楼与相邻建筑之间的连接，小到可以是办公室之间的联系。局域网自身相对其他网络传输速度更快，性能更稳定，框架简易，并且是封闭性，这也是很多机构选择的原因所在。局域网自身的组成大体由计算机设备、网络连接设备、网络传输介质3大部分构成，其中，计算机设备又包括服务器与工作站，网络连接设备则包含了网卡、集线器、交换机，网络传输介质简单来说就是网线，由同轴电缆、双绞线及光缆3大原件构成。[2]局域网是一种私有网络，一般在一座建筑物内或建筑物附近，比如家庭、办公室或工厂。局域网络被广泛用来连接个人计算机和消费类电子设备，使它们能够共享资源和交换信息。当局域网被用于公司时，它们就称为企业网络。[3]局域网将一定区域内的各种计算机、外部设备和数据库连接起来形成计算机通信网，通过专用数据线路与其他地方的局域网或数据库连接，形成更大范围的信息处理系统。局域网通过网络传输介质将网络服务器、网络工作站、打印机等网络互联设备连接起来，实现系统管理文件，共享应用软件、办公设备，发送工作日程安排等通信服务。局域网为封闭型网络，在一定程度上能够防止信息泄露和外部网络病毒攻击，具有较高的安全性，但是一旦发生黑客攻击等事件，极有可能导致局域网整体出现瘫痪，网络内的所有工作无法进行，甚至泄露大量公司机密，对公司事业发展造成重创。2017年国家发布《中华人民共和国网络安全法》，6月1日正式施行，从法律角度对网络安全和信息安全做出了明确规定，对网络运营者、使用者都提出了相应的要求，以提高网络使用的安全性。[4]无线局域网播报编辑无线局域网，简称WLAN，是在几千米范围内的公司楼群或是商场内的计算机互相连接所组建的计算机网络，一个无线局域网能支持几台到几千台计算机的使用。现如今无线局域网的应用已经越来越多。现在的校园、商场、公司以及高铁都在应用。无线局域网的应用为我们的生活和工作都带来很大的帮助，不仅能够快速传输人们所需要的信息，还能让人们在到联网中的联系更加快捷方便。[5]无线局域网近来受到非常大的欢迎，尤其是家庭、旧办公楼、食堂和其他一些安装电缆太麻烦的场地。在这些系统中，每台计算机都有一个无线调制解调器和一个天线，用来与其他计算机通信。在大多数情况下，每台计算机与安装在天花板上的一个设备通信。这个设备，成为接入点、无线路由器或者基站，它主要负责中继无线计算机之间的数据包，还负责中继无线计算机和Internet之间的数据包。[3]无线局域网的一个标准称为IEEE802.11，俗称WIFI，已经非常广泛地使用。[3]局域网的组建组建目标无线局域网可以传输音频、视频、文字。现在很多公司和校园都在用无线局域网。不仅能够提高办公的效率，还能快速传递信息。无线局域网的组建、维护管理都非常简单，而且很少被干扰。而且还能够节省网络费用的开支。无线局域网的组建目标主要有两个标准：第一，灵活性和独立性较强。无线局域网的部件的和相关设备的摆放不受任何空间限制。用户在连接到无线局域网以后。可以用自己是手机或笔记本等设备与系统网络进行连接，也不会影响到无线局域网的正常使用。第二，扩展性和先进性好。无线局域网的组建结构是非常简单。它会随着现在科技信息技术的发展而进行更新，提升性能和升级系统，从而使得信息传输更加快速。[5]无线局域网应用在日常生活中的应用无线局域网的实现协议众多，当前最广泛使用的当属Wi-Fi，只需要一个路由器，即可以达到让所有具有无线功能的设备组成一个无线局域网，非常方便灵活。目前大多数无线局域网是基于IEEE802.11标准，在这个标准下的无线局域网大多使用的是2.4GHz或5GHz的射频。家庭一般只需要一个路由器就可以组建小型的无线局域网络，中等规模的企业通过多个路由器以及交换机，就能组建覆盖整个企业的中型无线局域网络，而大型企业则是需要通过一些中心化的无线控制器来组建强大的覆盖面广的大型无线局域网络。[6]在不同行业中的应用无线局域网在医院中的应用对于医疗工作有很大的帮助，医生在查房时，需要随时查看患者的病例，然后会看患者当时的病情在下医嘱。在使用无线网络以后，医生查房时可以携带能够连接无线网络的平板电脑，随时查看患者的病例，并记录患者当时的病情。无线局域网不仅能为医生和病人提供上网服务，在医院的病人家属和访客都能享受到无线网络的快捷和便利。利用无线网络的定位服务在医院的应用也非常有帮助，医生能够及时定位到患者的位置。当患者出现紧急状况时能够得到及时抢治疗。另外，利用无线定位还可以随时知道药品的具体位置，相关人员在管理药品的库存时更加精确和方便。[5]金融行业网点众多，建议采用AC+瘦AP的组网架构，以便于WLAN网络统一管理。前期布网可考虑与运营商进行合作，以减少建设投资。AP的布放需要结合实际环境，如面积、楼层等做具体的适应性调整，部署范围应覆盖电子银行服务区、营业大厅、客户等候区、VIP客户接待区、理财专区等所有客户有权到达的区域，同时将无线控制器AC部署在核心机房，无线控制器通过N*GE链路旁挂或者在线部署在运营商汇聚交换机或者核心设备上。[7]有线局域网播报编辑有线局域网使用了各种不同的传输技术。它们大多使用铜线作为传输介质，但也有一些使用光纤。局域网的大小受到限制，这意味着最坏情况下的传输时间也是有界的，并且事先可以知道。了解这些界限有助于网络协议的设计。通常情况下，有线局域网的运行速度在100Mbps到1Gbps之间，延迟很低（微秒或者纳秒级），而且很少发生错误。较新的局域网可以工作在高达10Gbps的速率。和无线网络相比，有线局域网在性能的所有方面都超过了它们。[3]许多有线局域网的拓扑结构是以点到点链路为基础的。俗称以太网的IEEE802.3是迄今为止最常见的一种有线局域网。在交换式以太网中每台计算机按照以太网协议规定的方式运行，通过一条点到点链路连接到一个盒子，这个盒子称为交换机，这就是交换式以太网名字的由来。[3]特点及分类播报编辑局域网一般为一个部门或单位所有，建网、维护以及扩展等较容易，系统灵活性高。其主要特点是：1.覆盖的地理范围较小，只在一个相对独立的局部范围内联，如一座或集中的建筑群内。2.使用专门铺设的传输介质进行联网，数据传输速率高（10Mb/s～10Gb/s）3.通信延迟时间短，可靠性较高4.局域网可以支持多种传输介质局域网的类型很多，若按网络使用的传输介质分类，可分为有线网和无线网；若按网络拓扑结构分类，可分为总线型、星型、环型、树型、混合型等；若按传输介质所使用的访问控制方法分类，又可分为以太网、令牌环网、FDDI网和无线局域网等。其中，以太网是当前应用最普遍的局域网技术。拓扑结构播报编辑局域网通常是分布在一个有限地理范围内的网络系统，一般所涉及的地理范围只有几公里。局域网专用性非常强，具有比较稳定和规范的拓扑结构。常见的局域网拓朴结构如下：星型星型结构这种结构的网络是各工作站以星形方式连接起来的，网中的每一个节点设备都以中心节为中心，通过连接线与中心节点相连，如果一个工作站需要传输数据，它首先必须通过中心节点。由于在这种结构的网络系统中，中心节点是控制中心，任意两个节点间的通信最多只需两步，所以，能够传输速度快，并且网络构形简单、建网容易、便于控制和管理。但这种网络系统，网络可靠性低，网络共享能力差，并且一旦中心节点出现故障则导致全网瘫痪。树型树形结构网络是天然的分级结构，又被称为分级的集中式网络。其特点是网络成本低，结构比较简单。在网络中，任意两个节点之间不产生回路，每个链路都支持双向传输，并且，网络中节点扩充方便、灵活，寻查链路路径比较简单。但在这种结构网络系统中，除叶节点及其相连的链路外，任何一个工作站或链路产生故障会影响整个网络系统的正常运行。总线型总线性结构总线形结构网络是将各个节点设备和一根总线相连。网络中所有的节点工作站都是通过总线进行信息传输的。作为总线的通信连线可以是同轴电缆、双绞线，也可以是扁平电缆。在总线结构中，作为数据通信必经的总线的负载能量是有限度的，这是由通信媒体本身的物理性能决定的。所以，总线结构网络中工作站节点的个数是有限制的，如果工作站节点的个数超出总线负载能量，就需要延长总线的长度，并加入相当数量的附加转接部件，使总线负载达到容量要求。总线形结构网络简单、灵活，可扩充性能好。所以，进行节点设备的插入与拆卸非常方便。另外，总线结构网络可靠性高、网络节点间响应速度快、共享资源能力强、设备投入量少、成本低、安装使用方便，当某个工作站节点出现故障时，对整个网络系统影响小。因此，总线结构网络是最普遍使用的一种网络。但是由于所有的工作站通信均通过一条共用的总线，所以，实时性较差。环型环形结构是网络中各节点通过一条首尾相连的通信链路连接起来的一个闭合环形结构网。环形结构网络的结构也比较简单，系统中各工作站地位相等。系统中通信设备和线路比较节省。在网中信息设有固定方向单向流动，两个工作站节点之间仅有一条通路，系统中无信道选择问题；某个结点的故障将导致物理瘫痪。环网中，由于环路是封闭的，所以不便于扩充，系统响应延时长，且信息传输效率相对较低。安全问题播报编辑服务器防护能力较弱局域网相较于其他网络，其信息的传播速度较快，传递方式也相对简单，如果局域网中的某一台计算机受到了病毒的入侵，病毒会通过局域网中的信息传播散播到所有计算机当中。虽然有一些局域网中会安装一些杀毒软件，但是因为软件补丁更新不到位，或者有一些计算机没有安装杀毒软件，病毒会利用防护软件的漏洞进行网络攻击，从而导致局域网系统运行瘫痪，造成用户信息泄露、窃取用户财产等问题。[8]网络边界接入存在风险在局域网网络边界所存在的接入风险主要包括路由的破坏、用户信息的窃听、未经授权的访问等网络设备攻击，以及某些病毒的传播等。对于局域网的运行当中，主要是拒绝服务攻击较多一些，以此造成主机死机、网络服务暂停等。而在大量的SYNFlood、ACKFlooding、UDPFlood等攻击后产生的大量垃圾数据包，使得被攻击方CPU满负荷运转或者是内存不足，造成业务服务器的关键设备业务中断或是服务质量下降。[8]用户的安全意识薄弱局域网用户在使用网络进行数据传输时，有时会使用到外部存储设备，但是用户没有对外部设备安全检测的习惯，而是直接连接网络进行使用。导致外部数据和病毒一起进入到局域网当中，通过局域网中信息的传播，使得病毒在局域网中进行扩散，从而造成了局域网病毒入侵的情况。另外，有一些用户在进行网站浏览的过程当中，不小心点击到一些弹出的窗口或者是下载了病毒伪装的软件，也会导致计算机中毒，造成用户的信息泄露，威胁到整个局域网的安全。[8]并行计算：定义播报编辑并行计算（ParallelComputing）是指同时使用多种计算资源解决计算问题的过程，是提高计算机系统计算速度和处理能力的一种有效手段。它的基本思想是用多个处理器来协同求解同一问题，即将被求解的问题分解成若干个部分，各部分均由一个独立的处理机来并行计算。并行计算系统既可以是专门设计的、含有多个处理器的超级计算机，也可以是以某种方式互连的若干台的独立计算机构成的集群。通过并行计算集群完成数据的处理，再将处理的结果返回给用户。并行计算可分为时间上的并行和空间上的并行。时间上的并行：是指流水线技术，比如说工厂生产食品的时候步骤分为：1．清洗：将食品冲洗干净。2．消毒：将食品进行消毒处理。3．切割：将食品切成小块。4．包装：将食品装入包装袋。如果不采用流水线，一个食品完成上述四个步骤后，下一个食品才进行处理，耗时且影响效率。但是采用流水线技术，就可以同时处理四个食品。这就是并行算法中的时间并行，在同一时间启动两个或两个以上的操作，大大提高计算性能。空间上的并行：是指多个处理机并发的执行计算，即通过网络将两个以上的处理机连接起来，达到同时计算同一个任务的不同部分，或者单个处理机无法解决的大型问题。比如小李准备在植树节种三棵树，如果小李1个人需要6个小时才能完成任务，植树节当天他叫来了好朋友小红、小王，三个人同时开始挖坑植树，2个小时后每个人都完成了一颗植树任务，这就是并行算法中的空间并行，将一个大任务分割成多个相同的子任务，来加快问题解决速度。特征播报编辑为利用并行计算，通常计算问题表现为以下特征：（1）将工作分离成离散部分，有助于同时解决；（2）随时并及时地执行多个程序指令；（3）多计算资源下解决问题的耗时要少于单个计算资源下的耗时。基本体系结构播报编辑并行计算科学中主要研究的是空间上的并行问题。从程序和算法设计人员的角度来看，并行计算又可分为数据并行和任务并行。一般来说，因为数据并行主要是将一个大任务化解成相同的各个子任务，比任务并行要容易处理。空间上的并行导致了两类并行机的产生，按照Flynn的说法分为：单指令流多数据流（SIMD）和多指令流多数据流（MIMD）。我们常用的串行机也叫做单指令流单数据流（SISD）。MIMD类的机器又可分为以下常见的五类：并行向量处理机（PVP）、对称多处理机（SMP）、大规模并行处理机（MPP）、工作站机群（COW）、分布式共享存储处理机（DSM）。访存模型并行计算机有以下五种访存模型：均匀访存模型（UMA）非均匀访存模型（NUMA）全高速缓存访存模型（COMA）一致性高速缓存非均匀存储访问模型（CC-NUMA）非远程存储访问模型（NORMA）。计算模型并行求解过程示意图不像串行计算机那样，全世界基本上都在使用冯·诺伊曼的计算模型；并行计算机没有一个统一的计算模型。不过，人们已经提出了几种有价值的参考模型：PRAM模型，BSP模型，LogP模型，C^3模型等。网络设置播报编辑并行计算机是靠网络将各个处理机或处理器连接起来的，一般来说有以下几种方式：处理单元间有着固定连接的一类网络，在程序执行期间，这种点到点的链接保持不变；典型的静态网络有一维线性阵列、二维网孔、树连接、超立方网络、立方环、洗牌交换网、蝶形网络等。静态连接动态连接播报编辑用交换开关构成的，可按应用程序的要求动态地改变连接组态；典型的动态网络包括总线、交叉开关和多级互连网络等。基本术语播报编辑节点度:射入或射出一个节点的边数。在单向网络中，入射和出射边之和称为节点度。网络直径:网络中任何两个节点之间的最长距离，即最大路径数。对剖宽度:对分网络各半所必须移去的最少边数。对剖带宽:每秒钟内，在最小的对剖平面上通过所有连线的最大信息位（或字节)。性能度量播报编辑基本指标执行时间工作负载存储性能加速比评测Amdahl定理Gastofson定理Sun-Ni定理可扩放性标准等效率标准等速度标准平均延迟标准并行计算与云计算云计算是在并行计算之后产生的概念，是由并行计算发展而来，两者在很多方面有着共性。学习并行计算对于理解云计算有很大的帮助。并行计算是学习云计算必须要学习的基础课程。但并行计算不等于云计算，云计算也不等同并行计算。两者区别如下。（1）云计算萌芽于并行计算云计算的萌芽应该从计算机的并行化开始，并行机的出现是人们不满足于CPU摩尔定率的增长速度，希望把多个计算机并联起来，从而获得更快的计算速度。这是一种很简单也很朴素的实现高速计算的方法，这种方法后来被证明是相当成功的。（2）并行计算、网格计算只用于特定的科学领域，专业的用户并行计算、网格计算的提出主要是为了满足科学和技术领域的专业需要，其应用领域也基本限于科学领域。传统并行计算机的使用是一个相当专业的工作，需要使用者有较高的专业素质，多数是命令行的操作，这是很多专业人士的噩梦，更不用说普通的业余级用户了。（3）并行计算追求的高性能在并行计算的时代，人们极力追求的是高速的计算、采用昂贵的服务器，各国不惜代价在计算速度上超越他国，因此，并行计算时代的高性能机群是一个“快速消费品”，世界TOP500高性能计算机地排名不断地在刷新，一台大型机群如果在3年左右不能得到有效的利用就远远的落后了，巨额投资无法收回。（4）云计算对于单节点的计算能力要求低而云计算时代我们并不去追求使用昂贵的服务器，我们也不用去考虑TOP500的排名，云中心的计算力和存储力可随着需要逐步增加，云计算的基础架构支持这一动态增加的方式，高性能计算将在云计算时代成为“耐用消费品”。超线程技术：基本简介播报编辑英特尔®超线程技术是一项硬件创新，允许在每个内核上运行多个线程。更多的线程意味着可以并行完成更多的工作。[6]超线程技术把多线程处理器内部的两个逻辑内核模拟成两个物理芯片，让单个处理器就能使用线程级的并行计算，进而兼容多线程操作系统和软件。超线程技术充分利用空闲CPU资源，在相同时间内完成更多工作。[2]虽然采用超线程技术能够同时执行两个线程，当两个线程同时需要某个资源时，其中一个线程必须让出资源暂时挂起，直到这些资源空闲以后才能继续。因此，超线程的性能并不等于两个CPU的性能。而且，超线程技术的CPU需要芯片组、操作系统和应用软件的支持，才能比较理想地发挥该项技术的优势。[2]运作方式播报编辑超线程如何工作？当英特尔®超线程技术处于激活状态时，CPU会在每个物理内核上公开两个执行上下文。这意味着，一个物理内核现在就像两个“逻辑内核”一样，可以处理不同的软件线程。[6]较之传统的单线程内核，两个逻辑内核可以更有效地完成任务。英特尔®超线程(HT)技术充分利用了内核以前在等待其他任务完成时的空闲时间，提高了CPU吞吐量。[6]每个单位时间内，一个单运行管线的CPU只能处理一个线程（操作系统：thread），以这样的单位进行，如果想要在一单位时间内处理超过一个线程是不可能的，除非是有两个CPU的实体单元。双核心技术是将两个一样的CPU放置于一个封装内（或直接将两个CPU做成一个芯片），而英特尔的多线程技术是在CPU内部仅复制必要的资源、让两个线程可同时运行；在一单位时间内处理两个线程的工作，模拟实体双核心、双线程运作。[3]Intel自Pentium开始引入超标量、乱序运行、大量的寄存器及寄存器重命名、多指令解码器、预测运行等特性；这些特性的原理是让CPU拥有大量资源，并可以预先运行及平行运行指令，以增加指令运行效率，可是在现实中这些资源经常闲置；为了有效利用这些资源，就干脆再增加一些资源来运行第二个线程，让这些闲置资源可执行另一个线程，而且CPU只要增加少数资源就可以模拟成两个线程运作。[3]P4处理器需多加一个LogicalCPUPointer（逻辑处理单元）。因此P4HT的die的面积比以往的P4增大了5%。而其余部分如ALU（整数运算单元）、FPU（浮点运算单元）、L2Cache（二级缓存）并未增加，且是共享的。[3]超线程的需求条件播报编辑并不是所有的处理器都支持超线程，支持超线程的台式机处理器有以下几种：[4]1、IntelPentium4B3.06GHz[4]2、IntelPentium4C2.4/2.6/2.8/3.0/3.2/3.4[4]3、IntelPentium4E2.8(800FSB)/3.0/3.2/3.4/3.6[4]4、IntelPentium4XE3.4/3.46/3.73[4]5、IntelPentium4520/530/53l/540/541/550/551/560/561/570/57l/630/640/650/660[4]6、IntelPentiumXE840(双核加NT)[4]超线程除了需要CPU的支持外还需要以下几个方面的支持：[4]1、需要主板BIOS的支持。主板厂商必须在BIOS中支持超线程才可以。个别的主板需要升级BIOS才能稳定支持。[4]2、需要操作系统支持。WindowsXP即支持此功能。[4]3、需要应用软件的支持。通常，只要支持多处理器的软件就能支持超线程技术，但是目前支持多处理器的软件并不多，当前支持超线程技术的应用软件主要有Office2000、OfficeXP及Linuxkernel2.4.x以后的版本。[4]优缺点播报编辑优点1.超线程技术的优势在于同时进行多任务批处理工作，尽管支持超线程技术的软件不多，也只有少数的软件可以享受到由超线程技术带来的性能提升，但是这符合今后软件等技术的发展方向，今后更多的软件将受益于超线程技术。[5]2.从性能来看，部分客户可以发觉在运行某些特定软件时，超线程技术让系统有了30%的性能提升，为超线程技术优化的软件都能够享受到超线程技术的好处。[5]3.客户同时运行两个以上的软件时候，将可以明显的感受到这两个软件的性能都得到提升相比关闭超线程技术的情况下都有很大的提升，超线程技术的效率优势只有在多任务操作时候才能得到发挥。[5]4.支持超线程技术的WindowsXP操作系统，其中的很多系统软件都已经针对超线程技术优化过，因此在使用Windows操作系统的时候可以很好的享受到超线程技术带来好处。[5]缺点1.因为超线程技术是对多任务处理有优势，因此当运行单线程运用软件时，超线程技术将会降低系统性能，尤其在多线程操作系统运行单线程软件时将容易出现此问题。[5]2.在打开超线程支持后，如果处理器以双处理器模式工作，那么处理器内部缓存就会被划分成几区域，互相共享内部资源。对于不支持多处理器工作的软件在双处理器上运行时出错的概率要比单处理器上高很多。[5]3.因为很多工作站软件为Windows2000操作系统进行过优化，但是采用Windows2000这样的操作系统的工作站无法完全利用超线程技术的优势，也带来不了高的工作效率[5]4.超线程技术只能提高40%左右的性能（测评时可以看成50%，即Corei3的执行效率为3核速率，Corei54核HT与Corei7的执行效率为6核速率）[5]与多核心区别播报编辑超线程技术与多核体系结构的区别如下：①超线程技术是通过延迟隐藏的方法，提高了处理器的性能，本质上，就是多个线程共享一个处理单元。因此，采用超线程技术所获得的性能并不是真正意义上的并行。从而采用超线程技术获得的性能提升，将会随着应用程序以及硬件平台的不同而参差不齐。②多核处理器是将两个甚至更多的独立执行单元，嵌入到一个处理器内部。每个指令序列（线程），都具有一个完整的硬件执行环境，所以各线程之间就实现了真正意义上的并行。[2]超线程技术与多核技术相结合可以给应用程序带来更大的优化空间，进而极大地提高系统的吞吐率。[2]辅助存储器：解释播报编辑PC机常见的外存储器有软盘存储器、硬盘存储器、光盘存储器等。磁盘有软磁盘和硬磁盘两种。光盘有只读型光盘CD-ROM、一次写入型光盘WORM和可重写型光盘MO三种。简介存储器的种类很多，按其用途可分为主存储器和辅助存储器，主存储器又称内存储器（简称内存），辅助存储器又称外存储器（简称外存）。内存储器最突出的特点是存取速度快，但是容量小、价格贵；外存储器的特点是容量大、价格低，但是存取速度慢。内存储器用于存放那些立即要用的程序和数据；外存储器用于存放暂时不用的程序和数据。内存储器和外存储器之间常常频繁地交换信息。[1]外存通常是磁性介质或光盘，像硬盘，软盘，磁带，CD等，能长期保存信息，并且不依赖于电来保存信息，但是由机械部件带动，速度与CPU相比就显得慢的多。软盘：软磁盘使用柔软的聚酯材料制成原型底片，在两个表面涂有磁性材料。常用软盘直径为3.5英寸，存储容量为1.44MB.软盘通过软盘驱动器来读取数据。U盘：U盘也被称为“闪盘”，可以通过计算机的USB口存储数据。与软盘相比，由于U盘的体积小、存储量大及携带方便等诸多优点，U盘已经取代软盘的地位。硬盘：硬磁盘是由涂有磁性材料额铝合金原盘组成的，每个硬盘都由若干个磁性圆盘组成。其中固态硬盘是以闪存为存储介质的半导体存储器，其相对于机械硬盘具备读写速度快、延迟低、抗震性好等优势，在全球硬盘市场上的出货量占比不断提高。[2]移动固态硬盘的普及，让习惯了移动机械硬盘的人们，背包重量大有减轻。而且固态和移动硬盘的结合，显然也符合移动存储产品耐碰撞、轻巧且无须等待即插即用这诸多的主要特性。[3]磁带存储器：磁带也被称为顺序存取存储器SAM。它存储容量很大，但查找速度很慢，一般仅用作数据后备存储。计算机系统使用的磁带机有3中类型：盘式磁带机、数据流磁带机及螺旋扫描磁带机。光盘存储器：光盘指的是利用光学方式进行信息存储的圆盘。它应用了光存储技术，即使用激光在某种介质上写入信息，然后再利用激光读出信息。光盘存储器可分为:CD-ROM、CD-R、CD-RW、和DVD-ROM等。[1]种类移动硬盘软盘、硬盘、光盘、U盘、磁带都是外部存储器。从冯.诺依曼的存储程序工作原理及计算机的组成来说，计算机分为运算器、控制器、存储器和输入/输出设备，这里的存储器就是指内存，而硬盘属于输入/输出设备。CPU运算所需要的程序代码和数据来自于内存，内存中的东西则来自于硬盘，所以硬盘并不直接与CPU打交道。硬盘相对于内存来说就是外部存储器。存储器是用来存储器数据的，内存有高速缓存和内存，计算机内部存储，外存就是类似U盘的外部存储。内存储器速度快价格贵，容量小，断电后内存内数据会丢失。（ROM断电不丢失）外存储器单位价格低、容量大、速度慢、断电后数据不会丢失。性能指标播报编辑硬盘●容量——通常所说的容量是指硬盘的总容量，一般硬盘厂商定义的单位1GB=1000MB，而系统定义的1GB=1024MB，所以会出现硬盘上的标称值大于格式化容量的情况，这算业界惯例，属于正常情况。●单碟容量就是指一张碟片所能存储的字节数，硬盘的单碟容量一般都在20GB以上。而随着硬盘单碟容量的增大，硬盘的总容量已经可以实现上百G甚至几TB了(商业购买的硬盘容量为1TB的，可能实际只有1000GB，而不是1024GB，真正意义上的1TB=1024GB)。●转速——转速是指硬盘内电机主轴的转动速度，单位是RPM(每分钟旋转次数)。转速是决定硬盘内部传输率的决定因素之一，它的快慢在很大程度上决定了硬盘的速度，同时也是区别硬盘档次的重要标目前一般的硬盘转速为5400转和7200转，最高的转速则可达到10000转每分以上。●最高内部传输速率——这是硬盘的外圈的传输速率，它是指磁头和高速数据缓存之间的最高数据传输速率，单位为MB/s。最高内部传输速率的性能与硬盘转速以及盘片存储密度(单碟容量)有直接的关系。●平均寻道时间平均寻道时间是指硬盘磁头移动到数据所在磁道时所用的时间，单位为毫秒(ms),硬盘的平均寻道时间一般低于9毫秒。平均寻道时间越短,硬盘的读取数据能力就越高。U盘●理论数据读取速度：18MB/s●理论数据写入速度：17MB/s●无需安装驱动程序(windows98除外)●无需额外电源，只从usb总线取电●容量大、品种多●带写保护开关，防止文件被抹掉，防病毒●led指示灯指示工作状态●体积小，重量轻：大约20g系统软件：基本概念播报编辑各种应用软件，虽然完成的工作各不相同，但它们都需要一些共同的基础操作，例如都要从输入设备取得数据，向输出设备送出数据，向外存写数据，从外存读数据，对数据的常规管理，等等。这些基础工作也要由一系列指令来完成。人们把这些指令集中组织在一起，形成专门的软件，用来支持应用软件的运行，这种软件称为系统软件。一般来讲，系统软件包括操作系统和一系列基本的工具（比如编译器，数据库管理，存储器格式化，文件系统管理，用户身份验证，驱动管理，网络连接等方面的工具），是支持计算机系统正常运行并实现用户操作的那部分软件。系统软件一般是在计算机系统购买时随机携带的，也可以根据需要另行安装。特点播报编辑系统软件的主要特征是：*与硬件有很强的交互性*能对资源共享进行调度管理*能解决并发操作处理中存在的协调问题*其中的数据结构复杂，外部接口多样化，便于用户反复使用主要类别播报编辑系统软件在为应用软件提供上述基本功能的同时，也进行着对硬件的管理，使在一台计算机上同时或先后运行的不同应用软件有条不紊地合用硬件设备。例如，两个应用软件都要向硬盘存入和修改数据，如果没有一个协调管理机构来为它们划定区域的话，必然形成互相破坏对方数据的局面。[1]有代表性的系统软件有：操作系统操作系统管理计算机的硬件设备，使应用软件能方便、高效地使用这些设备。在微机上常见的有：DOS、WINDOWS、UNIX、OS/2等。操作系统(5张)在计算机软件中最重要且最基本的就是操作系统（OS）。它是最底层的软件，它控制所有计算机运行的程序并管理整个计算机的资源，是计算机裸机与应用程序及用户之间的桥梁。没有它，用户也就无法使用某种软件或程序。操作系统是计算机系统的控制和管理中心，从资源角度来看，它具有处理机、存储器管理、设备管理、文件管理等4项功能。常用的系统有DOS操作系统、WINDOWS操作系统、UNIX操作系统和Linux、Netware等操作系统。[2]语言处理程序编译软件CPU执行每一条指令都只完成一项十分简单的操作，一个系统软件或应用软件，要由成千上万甚至上亿条指令组合而成。直接用基本指令来编写软件，是一件极其繁重而艰难的工作。计算机只能直接识别和执行机器语言，因此要计算机上运行高级语言程序就必须配备程序语言翻译程序，翻译程序本身是一组程序，不同的高级语言都有相应的翻译程序。语言处理程序如汇编语言汇编器，C语言编译、连接器等。为了提高效率，人们规定一套新的指令，称为高级语言，其中每一条指令完成一项操作，这种操作相对于软件总的功能而言是简单而基本的，而相对于CPU的一眇操作而言又是复杂的。用这种高级语言来编写程序（称为源程序）就象用预制板代替砖块来造房子，效率要高得多。但CPU并不能直接执行这些新的指令，需要编写一个软件，专门用来将源程序中的每条指令翻译成一系列CPU能接受的基本指令（也称机器语言）使源程序转化成能在计算机上运行的程序。完成这种翻译的软件称为高级语言编译软件，通常把它们归入系统软件。目前常用的高级语言有VB、C++、JAVA等，它们各有特点，分别适用于编写某一类型的程序，它们都有各自的编译软件。[1]数据库管理数据库管理系统有组织地、动态地存贮大量数据，使人们能方便、高效地使用这些数据。数据库管理系统是一种操纵和管理数据库的大型软件，用于建立、使用和维护数据库。Foxpro，Access，Oracle，Sybase，DB2和Informix则是数据库系统。辅助程序系统辅助处理程序也称为“软件研制开发工具”、“支持软件”、“软件工具”，主要有编辑程序、调试程序、装备和连接程序、调试程序。总线周期：总线周期的概念1.微处理器是在时钟信号CLK控制下按节拍工作的。8086/8088系统的时钟频率为4.77MHz，每个时钟周期约为200ns。2.由于存储器和I/O端口是挂接在总线上的，CPU对存储器和I/O接口的访问，是通过总线实现的。通常把CPU通过总线对微处理器外部（存储器或I/O接口）进行一次访问所需时间称为一个总线周期。一个总线周期一般包含4个时钟周期，这4个时钟周期分别称4个状态即T1状态、T2状态、T3状态和T4状态，必要时，可在T3、T4间插入一个至数个Tw。（1）T1状态——输出存储器地址或I/O地址。（2）T2状态——输出控制信号。（3）T3和Tw状态——总线操作持续，并检测READY以决定是否延长时序。（4）T4状态——完成数据传送。存储器地址寄存器：公布时间播报编辑1993年，经全国科学技术名词审定委员会审定发布。[1]出处播报编辑《电子学名词》第一版。算术逻辑部件：公布时间播报编辑2008年，经全国科学技术名词审定委员会审定发布。出处播报编辑《海峡两岸信息科学技术名词》。[1]实时系统：基本信息播报编辑时间约束实时系统的任务具有一定的时间约束（截止时间）。根据截止时间，实时系统的实时性分为“硬实时”和“软实时”。硬实时是指应用的时间需求能够得到完全满足，否则就造成重大安全事故，甚至造成重大的生命财产损失和生态破坏，如在航空航天、军事、核工业等一些关键领域中的应用。软实时是指某些应用虽然提出时间需求，但实时任务偶尔违反这种需求对系统运行及环境不会造成严重影响，如监控系统等和信息采集系统等。可预测性可预测性是指系统能够对实时任务的执行时间进行判断，确定是否能够满足任务的时限要求。由于实时系统对时间约束要求的严格性，使可预测性成为实时系统的一项重要性能要求。除了要求硬件延迟的可预测性以外，还要求软件系统的可预测性，包括应用程序的响应时间是可预测的，即在有限的时间内完成必须的工作；以及操作系统的可预测性，即实时原语、调度函数等运行开销应是有界的，以保证应用程序执行时间的有界性。可靠性大多数实时系统要求有较高的可靠性。在一些重要的实时应用中，任何不可靠因素和计算机的一个微小故障，或某些特定强实时任务（又叫关键任务）超过时限，都可能引起难以预测的严重后果。为此，系统需要采用静态分析和保留资源的方法及冗余配置，使系统在最坏情况下都能正常工作或避免损失。可靠性已成为衡量实时系统性能不可缺少的重要指标。交互作用实时系统通常运行在一定的环境下，外部环境是实时系统不可缺少的一个组成部分。计算机子系统一般是控制系统，它必须在规定的时间内对外部请求做出反应。外部物理环境往往是被控子系统，两者互相作用构成完整的实时系统。大多数控制子系统必须连续运转以保证子系统的正常工作或准备对任何异常行为采取行动。新特点播报编辑简述早期的实时系统功能简单，包括单板机、单片机，以及简单的嵌入式实时系统等，其调度过程相对简单。随着实时系统应用范围的不断扩大，系统复杂性不断提高，实时系统具有以下新特点：多任务类在实时系统中，不但包括周期任务、偶发任务、非周期任务，还包括非实时任务。实时任务要求要满足时限，而非实时任务要求要使其响应时间尽可能的短。多种类型任务的混合，使系统的可调度性分析更加困难。复杂性任务的约束包括时间约束、资源约束、执行顺序约束和性能约束。时间约束是任何实时系统都固有的约束。资源约束是指多个实时任务共享有限的资源时，必须按照一定的资源访问控制协议进行同步，以避免死锁和高优先级任务被低优先级任务堵塞的时间（即优先级倒置时间）不可预测。执行顺序约束是指各任务的启动和执行必须满足一定的时间和顺序约束。例如，在分布式端到端（end-to-end）实时系统很重，同一任务的各子任务之间存在前驱/后驱约束关系，需要执行同步协议来管理子任务的启动和控制子任务的执行，使它们满足时间约束和系统可调度要求。性能约束是指必须满足如可靠性、可用性、可预测性、服务质量（QualityofService,QoS）等性能指标。短暂超载在实时系统中，即使一个功能设计合理、资源充足的系统也可能由于一下原因超载：1）系统元件出现老化，外围设备错误或系统发生故障。随着系统运行时间的增长，系统元件出现老化，系统部件可能发生故障，导致系统可用资源降低，不能满足实时任务的时间约束要求。2）环境的动态变化。由于不能对未来的环境、系统状态进行正确有效地预测，因此不能从整体角度上对任务进行调度，可能导致系统超载。3）应用规模的扩大。原先满足实时任务时限要求的系统，随着应用规模的增大，可能出现不能满足任务时限要求的情况，而重新设计、重建系统在时间和经济上又不允许。调度范围播报编辑分析为了精确管理“时间”资源，已达到实时性和与预测性要求，并能够满足是实时系统的新要求，需用实时调度理论对任务进行调度和可调度性分析。任务调度技术包括调度策略和可调度性分析方法，两者是紧密结合的。任务调度技术研究的范围包括任务使用系统资源（包括处理机、内存、I/O、网络等资源）的策略和机制，以及提供判断系统性能是否可预测的方法和手段。例如，什么时候调度任务运行、在哪运行（当系统为多处理机系统或分布式系统时）、运行多长时间等等；以及判断分析用一定参数描述的实时任务能否被系统正确调度。给定一组实时任务和系统资源，确定每个任务何时何地执行的整个过程就是调度。在非实时系统中，调度的主要目的是缩短系统平均响应时间，提高系统资源利用率，或优化某一项指标；而实时系统中调度的目的则是要尽可能地保证每个任务满足他们的时间约束，及时对外部请求做出响应。实时调度技术通常有多种划分方法，常用以下两种。占式调度抢占式调度通常是优先级驱动的调度。每个任务都有优先级，任何时候具有最高优先级且已启动的任务先执行。一个正在执行的任务放弃处理器的条件为：自愿放弃处理器（等待资源或执行完毕）；有高优先级任务启动，该高优先级任务将抢占其执行。除了共享资源的临界段之外，高优先级任务一旦准备就绪，可在任何时候抢占低优先级任务的执行。抢占式调度的优点是实时性好、反应快，调度算法相对简单，可优先保证高优先级任务的时间约束，其缺点是上下文切换多。而非抢占式调度是指不允许任务在执行期间被中断，任务一旦占用处理器就必须执行完毕或自愿放弃。其优点是上下文切换少；缺点是在一般情况下，处理器有效资源利用率低，可调度性不好。驱动策略静态表驱动策略（StaticTable-DrivenScheduling）是一种离线调度策略，指在系统运行前根据各任务的时间约束及关联关系，采用某种搜索策略生成一张运行时刻表。这张运行时刻表与列车运行时刻表类似，指明了各任务的起始运行时刻及运行时间。运行时刻表一旦生成就不再发生变化了。在系统运行时，调度器只需根据这张时刻表启动相应的任务即可。由于所有调度策略在离线情况下指定，因此调度器的功能被弱化，只具有分派器（Dispatcher）的功能。优先级驱动策略指按照任务优先级的高低确定任务的高低确定任务的执行顺序。优先级驱动策略又分为静态优先级调度策略。静态优先级调度是指任务的优先级分配好之后，在任务的运行过程中，优先级不会发生改变。静态优先级调度又称为固态优先级调度。动态优先级调度是指任务的优先级可以随着时间或系统状态的变化而发生变化。分类播报编辑强实时强实时系统（HardReal-Time）：在航空航天、军事、核工业等一些关键领域中，应用时间需求应能够得到完全满足，否则就造成如飞机失事等重大地安全事故，造成重大地生命财产损失和生态破坏。因此，在这类系统的设计和实现过程中，应采用各种分析、模拟及形式化验证方法对系统进行严格的检验，以保证在各种情况下应用的时间需求和功能需求都能够得到满足。弱实时弱实时系统（SoftReal-Time）：某些应用虽然提出了时间需求，但实时任务偶尔违反这种需求对系统的运行以及环境不会造成严重影响，如视频点播（Video-On-Demand，VOD）系统、信息采集与检索系统就是典型的弱实时系统。在VOD系统中，系统只需保证绝大多数情况下视频数据能够及时传输给用户即可，偶尔的数据传输延迟对用户不会造成很大影响，也不会造成像飞机失事一样严重的后果。存储字：一个存储字可代表一个二进制数，也可代表一串字符，如存储字为0011011001111101，既可表示为由十六进制字符组成的367DH（ASCII码），又可代表16位的二进制数，此值对应十进制数为13949，还可代表两个ASCII码：“6”和“”。一个存储字还可代表一条指令。[1]运算器：简介播报编辑运算器由算术逻辑单元（ALU）、累加器、状态寄存器、通用寄存器组等组成。算术逻辑运算单元（ALU）的基本功能为加、减、乘、除四则运算，与、或、非、异或等逻辑操作，以及移位、求补等操作。计算机运行时，运算器的操作和操作种类由控制器决定。运算器处理的数据来自存储器；处理后的结果数据通常送回存储器，或暂时寄存在运算器中。与ControlUnit共同组成了CPU的核心部分。运算器是计算机中处理数据的功能部件。对数据处理主要包括数据的算术运算和逻辑数据的逻辑操作。因此,实现对数据的算术与逻辑运算是运算器的核心功能。[1]基本理论播报编辑数据运算器运算器的处理对象是数据，所以数据长度和计算机数据表示方法，对运算器的性能影响极大。70年代微处理器常以1个、4个、8个、16个二进制位作为处理数据的基本单位。大多数通用计算机则以16、32、64位作为运算器处理数据的长度。能对一个数据的所有位同时进行处理的运算器称为并行运算器。如果一次只处理一位，则称为串行运算器。有的运算器一次可处理几位（通常为6或8位），一个完整的数据分成若干段进行计算，称为串/并行运算器。运算器往往只处理一种长度的数据。有的也能处理几种不同长度的数据，如半字长运算、双倍字长运算、四倍字长运算等。有的数据长度可以在运算过程中指定，称为变字长运算。按照数据的不同表示方法，可以有二进制运算器、十进制运算器、十六进制运算器、定点整数运算器、定点小数运算器、浮点数运算器等。按照数据的性质，有地址运算器和字符运算器等。它的主要功能是进行算术运算和逻辑运算。操作运算器能执行多少种操作和操作速度，标志着运算器能力的强弱，甚至标志着计算机本身的能力。运算器最基本的操作是加法。一个数与零相加，等于简单地传送这个数。将一个数的代码求补，与另一个数相加，相当于从后一个数中减去前一个数。将两个数相减可以比较它们的大小。运算器左右移位是运算器的基本操作。在有符号的数中，符号不动而只移数据位，称为算术移位。若数据连同符号的所有位一齐移动，称为逻辑移位。若将数据的最高位与最低位链接进行逻辑移位，称为循环移位。运算器的逻辑操作可将两个数据按位进行与、或、异或，以及将一个数据的各位求非。有的运算器还能进行二值代码的16种逻辑操作。乘、除法操作较为复杂。很多计算机的运算器能直接完成这些操作。乘法操作是以加法操作为基础的，由乘数的一位或几位译码控制逐次产生部分积，部分积相加得乘积。除法则又常以乘法为基础，即选定若干因子乘以除数，使它近似为1，这些因子乘被除数则得商。没有执行乘法、除法硬件的计算机可用程序实现乘、除，但速度慢得多。有的运算器还能执行在一批数中寻求最大数，对一批数据连续执行同一种操作，求平方根等复杂操作。运算方法实现运算器的操作，特别是四则运算，必须选择合理的运算方法。它直接影响运算器的性能，也关系到运算器的结构和成本。另外，在进行数值计算时，结果的有效数位可能较长，必须截取一定的有效数位，由此而产生最低有效数位的舍入问题。选用的舍入规则也影响到计算结果的精确度。在选择计算机的数的表示方式时，应当全面考虑以下几个因素：要表示的数的类型（小数、整数、实数和复数）：决定表示方式，可能遇到的数值范围：确定存储、处理能力。数值精确度：处理能力相关；数据存储和处理所需要的硬件代价：造价高低。运算器两种常用格式：定点格式：定点格式容许的数值范围有限，但要求的处理硬件比较简单；浮点格式：容许的数值范围很大，但要求的处理硬件比较复杂。1、定点数表示法：定点指小数点的位置固定，为了处理方便，一般分为定点纯整数和纯小数。2、浮点数表示法：由于所需表示的数值取值范围相差十分悬殊，给存储和计算带来诸多不便，因此出现了浮点运算法。浮点表示法，即小数点的位置是浮动的。其思想来源于科学计数法。IEEE754的浮点数（比较特殊）浮点数的规格化：主要解决同一浮点数表示形式的不唯一性问题。规定，否则尾数要进行左移或右移。机器零的概念：尾数为0或是阶码值小于所能表示的最小数。3、十进制数串的表示方法：由于人们对十进制比较熟悉，因此在计算机中要增加对十进制运算的支持。两种方式：将十进制数变为二进制数运算，输出时再由二进制变为十进制。直接的十进制运算。直接运算的表示方法：字符串形式：用于非数值计算领域、压缩的十进制数串：分为定长和不定长两种。需要相应的十进制运算器和指令支持。4、自定义数据表示：标志符数据表示、描述符数据表示。区别：标志符与每个数据相连，二者合起来存放在一个存储单元，而描述符要和数据分开存放；描述符表示中，先访问描述符，后访问数据，至少增加一次访存；描述符是程序的一部分，而不是数据的一部分。原码：比较自然的表示法，最高位表示符号，0为正，1为负。优点：简单易懂。缺点：加减法运算复杂。补码：加减法运算方便，减法可以转换为加法。定点小数的补码。定点整数的补码，反码：为计算补码方便而引入。由反码求补码：符号位置1，各位取反，末位加1。移码：用于阶码的表示，两个移码容易比较大小，便于对阶。运算器ASCII码输入码：用于汉字输入；汉字的存储；字模码：用于汉字的显示。余数处理的两种方法：恢复余数法：运算步骤不确定，控制复杂，不适合计算机运算。加减交替法：不恢复余数，运算步骤确定，适合计算机操作。逻辑数概念：不带符号的二进制数。四种逻辑运算：逻辑非、逻辑加、逻辑乘、逻辑异。多功能算术/逻辑运算单元（ALU）并行进位，行波进位加/减法器存在的两个问题：运算时间长，行波进位加/减法器只能完成加法和减法，而不能完成逻辑操作，控制端M用来控制作算术运算还是逻辑运算，两种运算的区别在于是否对进位进行处理。M=0时，对进位无影响，为算术运算；M=1时，进位被封锁，为逻辑运算。正逻辑中，“1”用高电平表示，“0”用低电平表示，而负逻辑刚好相反。逻辑与负逻辑的关系为，正逻辑的“与”到负逻辑中变为“或”，即+·互换。内部总线，总线分类：内部总线、外部总线（系统总线）、通信总线。总线又可分为单向总线和双向总线。带锁存器的总线可实现总线的复用。运算器包括ALU、阵列乘除器件、寄存器、多路开关、三态缓冲器、数据总线等逻辑部件。运算器的设计，主要是围绕着ALU和寄存器同数据总线之间如何传送操作数和运算结果而进行的。运算器的三种结构形式：单总线结构的运算器：这种结构的主要缺点是操作进度较慢，但控制电路比较简单。双总线结构的运算器。三总线结构的运算器：三总线结构的运算器的特点是操作时间快。结构运算器运算器包括寄存器、执行部件和控制电路3个部分。在典型的运算器中有3个寄存器：接收并保存一个操作数的接收寄存器；保存另一个操作数和运算结果的累加寄存器；在进行乘、除运算时保存乘数或商数的乘商寄存器。执行部件包括一个加法器和各种类型的输入输出门电路。控制电路按照一定的时间顺序发出不同的控制信号，使数据经过相应的门电路进入寄存器或加法器，完成规定的操作。为了减少对存储器的访问，很多计算机的运算器设有较多的寄存器，存放中间计算结果，以便在后面的运算中直接用作操作数。为了提高运算速度，某些大型计算机有多个运算器。它们可以是不同类型的运算器，如定点加法器、浮点加法器、乘法器等，也可以是相同类型的运算器。运算器的组成决定于整机的设计思想和设计要求，采用不同的运算方法将导致不同的运算器组成。但由于运算器的基本功能是一样的，其算法也大致相同，因而不同机器的运算器是大同小异的。运算器主要由算术逻辑部件、通用寄存器组和状态寄存器组成。1、算术逻辑部件ALU。ALU主要完成对二进制信息的定点算术运算、逻辑运算和各种移位操作。算术运算主要包括定点加、减、乘和除运算。逻辑运算主要有逻辑与、逻辑或、逻辑异或和逻辑非操作。移位操作主要完成逻辑左移和右移、算术左移和右移及其他一些移位操作。某些机器中，ALU还要完成数值比较、变更数值符号、计算操作数在存储器中的地址等。可见，ALU是一种功能较强的组合逻辑电路，有时被称为多功能发生器，它是运算器组成中的核心部件。ALU能处理的数据位数（即字长）与机器有关。如Z80单板机中，ALU是8位；IBMPC/XT和AT机中，ALU为16位；386和486微机中，ALU是32位。ALU有两个数据输入端和一个数据输出端，输入输出的数据宽度（即位数）与ALU处理的数据宽度相同。2、通用寄存器组设计的机器的运算器都有一组通用寄存器。它主要用来保存参加运算的操作数和运算的结果。早期的机器只设计一个寄存器，用来存放操作数、操作结果和执行移位操作运算器，由于可用于存放重复累加的数据，所以常称为累加器。通用寄存器均可以作为累加器使用。通用寄存器的数据存取速度是非常快的，一般是十几个毫微秒（μs）。如果ALU的两个操作数都来自寄存器，则可以极大地提高运算速度。通用寄存器同时可以兼作专用寄存器，包括用于计算操作数的地址（用来提供操作数的形式地址，据此形成有效地址再去访问主存单元）。例如，可作为变址寄存器、程序计数器（PC）、堆栈指示器（SP）等。必须注意的是，不同的机器对这组寄存器使用的情况和设置的个数是不相同的。3、状态寄存器状态寄存器用来记录算术、逻辑运算或测试操作的结果状态。程序设计中，这些状态通常用作条件转移指令的判断条件，所以又称为条件码寄存器。一般均设置如下几种状态位：（1）零标志位（Z）：当运算结果为0时，Z位置“1”；非0时，置“0”；（2）负标志位（N）：当运算结果为负时，N位置“1”；为正时，置“0”；（3）溢出标志位（V）：当运算结果发生溢出时，V位置“1”；无溢出时，置“0”；（4）进位或借位标志（C）：在做加法时，如果运算结果最高有效位（对于有符号数来说，即符号位；对无符号数来说，即数值最高位）向前产生进位时，C位置“1”；无进位时，置“0”。在做减法时，如果不够减，最高有效位向前有借位（这时向前无进位产生）时，C位置“1”；无借位（即有进位产生）时，C位置“0”。除上述状态外，状态寄存器还常设有保存有关中断和机器工作状态（用户态或核心态）等信息的一些标志位（应当说明，不同的机器规定的内容和标志符号不完全相同），以便及时反映机器运行程序的工作状态，所以有的机器称它为“程序状态字”或“处理机状态字”（ProcessorStatusWord，PSW）。性能指标播报编辑1.机器字长，机器字长是指参与运算的数据的基本位数。它决定了寄存器、运算器和数据总线的位数，因而直接影响到硬件的价格。字长标志着计算精度。为协调精度与造价，并满足多方面的要求，许多计算机允许变字长计算，例如半字长、全字长和双倍字长等。由于数和指令代码都放在主存中，因而字长与指令码长度往往有一个对应关系，字长也就影响到指令系统功能的强弱。计算机字长从4位、8位、16位、32位到64位不等。机器字长可包含一个或多个字节。用于科学计算的机器，为了确保精度，需要较长的字长；用于数据处理、工业控制的机器，字长为16位或32位就能满足要求。运算器2.运算速度，它是计算机的主要指标之一。计算机执行不同的运算和操作所需的时间可能不同，因而对运算速度存在不同的计算方法。一般常用平均速度，即在单位时间内平均能执行的指令条数来表示，如某计算机运算速度为100万次/秒，就是指该机在一秒钟内能平均执行100万条指令（即1MIPS）。有时也采用加权平均法（即根据每种指令的执行时间以及该指令占全部操作的百分比进行计算）求得的等效速度表示。功能分类播报编辑运算器的基本功能是完成对各种数据的加工处理，例如算术四则运算，与、或、求反等逻辑运算，算术和逻辑移位操作，比较数值，变更符号，计算主存地址等。运算器中的寄存器用于临时保存参加运算的数据和运算的中间结果等。运算器中还要设置相应的部件，用来记录一次运算结果的特征情况，如是否溢出，结果的符号位，结果是否为零等。计算机所采用的运算器类型很多，从不同的角度分析，就有不同的分类方法。从小数点的表示形式可分为定点运算器和浮点运算器。定点运算器只能做定点数运算，特点是机器数所表示的范围较小，但结构较简单。浮点运算器功能较强，既能对浮点数，又能对定点数进行运算，其数的表示范围很大，但结构相当复杂。从进位制方面分为二进制运算器和十进制运算器。一般计算机都采用二进制运算器，随着计算机广泛应用于商业和数据处理，越来越多的机器都扩充十进制运算的功能，使运算器既能完成二进制的运算，也能完成十进制运算。计算机中运算器需要具有完成多种运算操作的功能，因而必须将各种算法综合起来，设计一个完整的运算部件。浮点运算器1、浮点运算器的一般结构浮点运算可用两个松散连接的定点运算部件来实现：即阶码部件和尾数部件，浮点运算器的一般结构尾数部件实质上就是一个通用的定点运算器，要求该运算器能实现加、减、乘、除四种基本算术运算。其中三个单字长寄存器用来存放操作数：AC为累加器，MQ为乘商寄存器，DR为数据寄存器。AC和MQ连起来还可组成左右移位的双字长寄存器AC－MQ。并行加法器用来完运算器成数据的加工处理，其输入来自AC和DR，而结果回送到AC。MQ寄存器在乘法时存放乘数，而除法时存放商数，所以称为乘商寄存器。DR用来存放被乘数或除数，而结果（乘积或商与余数）则存放在AC－MQ。在四则运算中，使用这些寄存器的典型方法如下：运算类别寄存器关系加法AC+DR→AC减法AC－DR→AC乘法DR×MQ→AC－MQ除法AC÷DR→AC－MQ对阶码部件来说，只要能进行阶码相加、相减和比较操作即可。在图2-21中，操作数的阶码部分放在寄存器E1和E2，它们与并行加法器相连以便计算。浮点加法和减法所需要的阶码比较是通过E1－E2来实现的，相减的结果放入计数器E中，然后按照E的符号为决定哪一个阶码较大。在尾数相加或相减之前，需要将一个尾数进行移位，这是由计数器E来控制的，目的是使E的值按顺序减到0。E每减一次1，相应的尾数则向右移1位。一旦尾数高速完毕，它们就可按通常的定点方法进行处理。运算结果的阶码值仍放到计数器E中。2、点协处理器，80x87是美国Intel公司为处理浮点数等数据的算术运算和多种函数计算而设计生产的专用算术运算处理器。由于它们的算术运算是配合80x86CPU进行的，所以又称为协处理器。我们以80x87为例来讨论浮点运算器部件的组成。浮点协处理器的主要功能如下：（1）可与配套的CPU芯片异步并行工作。80x87相当于386的一个I/O部件，本身有它自己的指令，但不能单独使用，它只能作为386主CPU的协处理器才能运算。因为真正的读写主存的工作不是80x87完成，而是由386执行的。如果386从主存读取的指令是80x87浮点运算指令，则它们以输出方式把该指令送到80x87，80x87接收后进行译码并执行浮点运算。在80x87进行运算期间，386可取下一条其他指令予以执行，因而实现了并行工作。如果在80x87执行浮点运算指令过程中386又取来一条80x87指令，则80x87以给出“忙”的标志信号加以拒绝，使386暂停向80x87发送命令。只有待80x87完成浮点运算而取消“忙”的标志信号以后，386才可以进行一次发送操作。（2）高性能的80位字长的内部结构，有8个80位字长的以堆栈方式管理的寄存器组。80x87从存储器取数和向存储器写数时，均用80位的临时实数和其他6种数据类型执行自动转换。全部数据在80x87中均以80位临时实数的形式表示。因此80x87具有80位的内部结构，并有八个80位字长以“先进后出”方式管理的寄存器组，又称寄存器堆栈。这些寄存器可以按堆栈方式工作，此时，栈顶被用作累加器；也可以按寄存器的编号直接访问任一个寄存器。（3）浮点数的格式，完全符合IEEE制定的国际标准。（4)能处理包括二进制浮点数、二进制整数和十进制数串三大类共7种数据。此7种数据类型在寄存器中表示如下：短整数（32位整数）S31位(二进制补码)长整数（64位整数）S63位（二进制补码）短实数（32位浮点数）S指数尾数（23位）长实数（64位浮点数）S指数尾数（52位）临时实数（80位浮点数）S指数尾数（64位）十进数串（十进制18位）S－－d17d16…d1d0。此处S为一位符号位，0代表正，1代表负。三种浮点数阶码的基值均为2。阶码值用移码表示，尾数用原码表示。尾数有32位、64位、80位三种。不仅仅是一个浮点运算器，还包括了执行数据运算所需要的全部控制线路，就运算部分讲，有处理浮点数指数部分的部件和处理尾数部分的部件，还有加速移位操作的移位器线路，它们通过指数总线和小数总线与八个80位字长的寄存器堆栈相连接。（5)内部的出错管理功能为了保证操作的正确执行，80x87内部还设置了三个各为16位字长的寄存器，即特征寄存器、控制字寄存器和状态寄存器。特征寄存器用每两位表示寄存器堆栈中每个寄存器的状态，即特征值为00－11四种组合时表明相应的寄存器有正确数据、数据为0、数据非法、无数据四种情况。控制字寄存器用于控制80x87的内部操作。其中PC为精度控制位域（2位）：00为24位，01为备用，10为53位，11为64位。RC为舍入控制位域（2位）：00为就近舍入，01朝－方向舍入，10朝+方向舍入，11朝0舍入。IC为无穷大控制位：该位为0时+与－作同值处理，该位为1时+与－不作同值处理。控制寄存器的低6位作异常中断屏蔽位：IM为非法处理，DM为非法操作数，ZM为0作除数，OM为上溢，UM为下溢，PM为精度下降。状态字寄存器用于表示80x87的结果处理情况，例如当“忙”标志为1时，表示正在执行一条浮点运算指令，为0则表示80x87空闲。状态寄存器的低6位指出异常错误的6种类型，与控制寄存器低6位相。当的控制寄存器位为0（未屏蔽）而状态寄存器位为1时，因发生某种异常错误而产生中断请求。3．CPU内的浮点运算器，奔腾CPU将浮点运算器包含在芯片内。浮点运算部件采用流水线设计。指令执行过程分为8段流水线。前4段为指令预取（DF）、指令译码(D1）、地址生成（D2）、取操作数（EX），在U，V流水线中完成；后4段为执行1(X1）、执行2(X2）、结果写回寄存器堆（WF）、错误报告(ER），在浮点运算器中完成。一般情况下，由V流水线完成一条浮点操作指令。浮点部件内有浮点专用的加法器、乘法器和除法器，有8个80位寄存器组成的寄存器堆，内部的数据总线为80位宽。因此浮点部件可支持IEEE754标准的单精度和双精度格式的浮点数。另外还使用一种称为临时实数的80位浮点数。对于浮点的取数、加法、乘法等操作，采用了新的算法并用硬件来实现，其执行速度是80486的10倍多。发展播报编辑公元前5世纪，中国人发明了算盘，广泛应用于商业贸易中，算盘被认为是最早的计算机，并一直使用至今。算盘在某些方面的运算能力要超过计算机，算盘的方面体现了中国人民的智慧。运算器直到17世纪，计算设备才有了第二次重要的进步。1642年，法国人BlaisePascal（1623-1662）发明了自动进位加法器，称为Pascalene。1694年，德国数学家GottfriedWilhemvonLeibniz（1646-1716）改进了Pascaline，使之可以计算乘法。后来，法国人CharlesXavierThomasdeColmar发明了可以进行四则运算的计算器。现代计算机的真正起源来自英国数学教授CharlesBabbage。CharlesBabbage发现通常的计算设备中有许多错误，在剑桥学习时，他认为可以利用蒸汽机进行运算。起先他设计差分机用于计算导航表，后来，他发现差分机只是专门用途的机器，于是放弃了原来的研究，开始设计包含现代计算机基本组成部分的分析机。（AnalyticalEngine）Babbage的蒸汽动力计算机虽然最终没有完成，以今天的标准看也是非常原始的，然而，它勾画出现代通用计算机的基本功能部分，在概念上是一个突破。在接下来的若干年中，许多工程师在另一些方面取得了重要的进步，美国人HermanHollerith（1860-1929），根据提花织布机的原理发明了穿孔片计算机，并带入商业领域建立公司。现代计算机发展历程第一代电子管计算机(1946-1957)1946年2月15日，标志现代计算机诞生的ENIAC（ElectronicNumericalIntegratorandComputer）在费城公诸于世。ENIAC代表了计算机发展史上的里程碑，它通过不同部分之间的重新接线编程，还拥有并行计算能力。ENIAC由美国政府和宾夕法尼亚大学合作开发，使用了18000个电子管，70000个电阻器，有5百万个焊接点，耗电160千瓦，其运算速度为每秒5000次。第一代计算机的特点是操作指令是为特定任务而编制的，每种机器有各自不同的机器语言，功能受到限制，速度也慢。另一个明显特征是使用真空电子管和磁鼓储存数据.第二代晶体管计算机(1957-1964)运算器1948年，晶体管发明代替了体积庞大电子管，电子设备的体积不断减小。1956年，晶体管在计算机中使用，晶体管和磁芯存储器导致了第二代计算机的产生。第二代计算机体积小、速度快、功耗低、性能更稳定。1960年，出现了一些成功地用在商业领域、大学和政府部门的第二代计算机。第二代计算机用晶体管代替电子管，还有现代计算机的一些部件：打印机、磁带、磁盘、内存、操作系统等。计算机中存储的程序使得计算机有很好的适应性，可以更有效地用于商业用途。在这一时期出现了更高级的COBOL和FORTRAN等语言，使计算机编程更容易。新的职业（程序员、分析员和计算机系统专家）和整个软件产业由此诞生。第三代集成电路计算机(1964-1972)1958年德州仪器的工程师JackKilby发明了集成电路（IC），将三种电子元件结合到一片小小的硅片上。更多的元件集成到单一的半导体芯片上，计算机变得更小，功耗更低，速度更快。这一时期的发展还包括使用了操作系统，使得计算机在中心程序的控制协调下可以同时运行许多不同的程序。第四代大规模集成电路计算机(1972-至今）大规模集成电路(LSI)可以在一个芯片上容纳几百个元件。到了80年代，超大规模集成电路(VLSI)在芯片上容纳了几十万个元件，后来的(ULSI)将数字扩充到百万级。可以在硬币大小的芯片上容纳如此数量的元件使得计算机的体积和价格不断下降，而功能和可靠性不断增强。70年代中期，计算机制造商开始将计算机带给普通消费者，这时的小型机带有友好界面的软件包，供非专业人员使用的程序和最受欢迎的字处理和电子表格程序。1981年，IBM推出个人计算机(PC)用于家庭、办公室和学校。80年代个人计算机的竞争使得价格不断下跌，微机的拥有量不断增加，计算机继续缩小体积。与IBMPC竞争的AppleMacintosh系列于1984年推出，Macintosh提供了友好的图形界面，用户可以用鼠标方便地操作。纪事年表播报编辑1666年，在英国SamuelMorland发明了一部可以计算加数及减数的机械计数机。1673年，GottfriedLeibniz制造了一部踏式（stepped）圆柱形转轮的计数机，叫“SteppedReckoner”，这部计算器可以把重复的数字相乘，并自动地加入加数器里。运算器1694年，德国数学家，GottfriedLeibniz，把巴斯卡的Pascalene改良，制造了一部可以计算乘数的机器，它仍然是用齿轮及刻度盘操作。1773年，Philipp-Matthaus制造及卖出了少量精确至12位的计算机器。1775年，ThethirdEarlofStanhope发明了一部与Leibniz相似的乘法计算器。1786年，J.H.Mueller设计了一部差分机，可惜没有拨款去制造。1801年，Joseph-MarieJacquard的织布机是用连接按序的打孔卡控制编织的样式。1854年，GeorgeBoole出版"AnInvestigationoftheLawsofThought”，是讲述符号及逻辑理由，它后来成为计算机设计的基本概念。1858年，一条电报线第一次跨越大西洋，并且提供了几日的服务。1861年，一条跨越大陆的电报线把大西洋和太平洋沿岸连接起来。1876年，AlexanderGrahamBell发明了电话并取得专利权。1876至1878年，BaronKelvin制造了一部泛音分析机及潮汐预测机。1882年，WilliamS.Burroughs辞去在银行文员的工作，并专注于加数器的发明。1889年，HermanHollerith的电动制表机在比赛中有出色的表现，并被用于1890中的人口调查。HermanHollerith采用了Jacquard织布机的概念用来计算，他用咭贮存资料，然后注入机器内编译结果。这机器使本来需要十年时间才能得到的人口调查结果，在短短六星期内做到。1893年，第一部四功能计算器被发明。1895年，GuglielmoMarconi传送广播讯号。1896年，Hollerith成立制表机器公司（TabulatingMachineCompany）。1901年，打孔键出现，之后的半个世纪只有很少的改变。1904年，JohnA.Fleming取得真空二极管的专利权，为无线电通讯建立基础。1906年，LeedeForedt加了一个第三活门在Felming的二极管，创制了三电极真空管。1907年，唱片音乐在纽约组成第一间正式的电台。1908年，英国科学家CampbellSwinton述了电子扫描方法及预示用阴极射线管制造电视。1911年，Hollerith的表机公司与其它两间公司合并，组成ComputerTabulatingRecordingCompany(C-T-R），制表及录制公司。但在1924年，改名为InternationalBusinessMachineCorporation（IBM）。1911年，荷兰物理学家KamerlinghOnnes在LeidenUnversity发现超导电。1931年，VanneverBush发明了一部可以解决差分程序的计数机，这机器可以解决一些令数学家，科学家头痛的复杂差分程序。1935年，IBM(InternationalBusinessMachineCorporation)引入"IBM601”，它是一部有算术部件及可在1秒钟内计算乘数的穿孔咭机器。它对科学及商业的计算起很大的作用。总共制造了1500部。1937年，AlanTuring想出了一个"通用机器（UniversalMachine）”的概念，可以执行任何的算法，形成了一个"可计算（computability）”的基本概念。Turing的概念比其它同类型的发明为好，因为他用了符号处理（symbolprocessing）的概念。1939年11月，JohnVincentAtannsoff与JohnBerry制造了一部16位加数器。它是第一部用真空管计算的机器。1939年，Zuse与Schreyer开鈶制造了"V2”[后来叫Z2]，这机器沿用Z1的机械贮存器，加上一个用断电器逻辑（RelayLogic）的新算术部件。但当Zuse完成草稿后，这计划被中断一年。运算器1939-40年，Schreyer完成了用真空管的10位加数器，以及用氖气灯（霓虹灯）的存贮器。1940年1月,在BellLabs,SamuelWilliams及Stibitz完成了一部可以计算复杂数字的机器，叫“复杂数字计数机（ComplexNumberCalculator）”，后来改称为“断电器计数机型号I（ModelIRelayCalculator）”。它用电话开关部份做逻辑部件：145个断电器，10个横杠开关。数字用“Plus3BCD”代表。在同年9月，电传打字etype安装在一个数学会议里，由NewHampshire连接去纽约。1940年，Zuse终于完成Z2，它比运作得更好，但不是太可靠。1941年夏季，Atanasoff及Berry完成了一部专为解决联立线性方程系统（systemofsimultaneouslinearequations)的计算器，后来叫做"ABC(Atanasoff-BerryComputer）”，它有60个50位的存贮器，以电容器（capacitories）的形式安装在2个旋转的鼓上，时钟速度是60Hz。1941年2月，Zuse完成"V3”（后来叫Z3），是第一部操作中可编写程序的计数机。它亦是用浮点操作，有7个位的指数，14位的尾数，以及一个正负号。存贮器可以贮存64个字，所以需要1400个断电器。它有多于1200个的算术及控制部件，而程序编写，输入，输出的与Z1相同。1943年1月HowardH.Aiken完成"ASCCMarkI”（自动按序控制计算器MarkI，AutomaticSequence--ControlledCalculatorMarkI），亦称“HawardMarkI”。这部机器有51尺长，重5顿，由750,000部份合并而成。它有72个累加器，每一个有自己的算术部件，及23位数的寄存器。1943年12月，TommyFlowers与他的队伍，完成第一部“Colossus”，它有2400个真空管用作逻辑部件，5个纸带圈读取器（reader），每个可以每秒工作5000字符。1943年，由JohnBrainered领导，ENIAC开始研究。而JohnMauchly及J.PresperEckert负责这计划的执行。1946v第一台电子数字积分计算器（ENIAC）在美国建造完成。1947年，美国计算器协会（ACM）成立。1947年，英国完成了第一个存储真空管O1948贝尔电话公司研制成半导体。1949年，英国建造完成"延迟存储电子自动计算器"(EDSAC)1950年，"自动化"一词第一次用于汽车工业。1951年，美国麻省理工学院制成磁心1952年，第一台"储存程序计算器"诞生。1952年，第一台大型计算机系统IBM701宣布建造完成。1952年，第一台符号语言翻译机发明成功。1954年，第一台半导体计算机由贝尔电话公司研制成功。1954年，第一台通用数据处理机IBM650诞生。1955年，第一台利用磁心的大型计算机IBM705建造完成。运算器1956年，IBM公司推出科学704计算机。1957年，程序设计语言FORTRAN问世。1959年，第一台小型科学计算器IBM620研制成功。1960年，数据处理系统IBM1401研制成功。1961年，程序设计语言COBOL问世。1961年，第一台分系统计算机由麻省理工学院设计完成。1963年，BASIC语言问世。1964年，第三代计算机IBM360系列制成。1965年，美国数字设备公司推出第一台小型机PDP-8。1969年，IBM公司研制成功90列卡片机和系统--3计算机系统。1970年，IBM系统1370计算机系列制成。1971年，伊利诺大学设计完成伊利阿克IV巨型计算机。1971年，第一台微处理机4004由英特尔公司研制成功。1972年，微处理机基片开始大量生产销售。运算器1973年，第一片软磁盘由IBM公司研制成功。1975年，ATARI--8800微电脑问世。1977年，柯莫道尔公司宣称全组合微电脑PET--2001研制成功。1977年，TRS--80微电脑诞生。1977年,苹果--II型微电脑诞生。1978年，超大规模集成电路开始应用。1978年，磁泡存储器第二次用于商用计算机。1979年，夏普公司宣布制成第一台手提式微电脑。1982年，微电脑开始普及，大量进入学校和家庭。1984年，日本计算机产业着手研制"第五代计算机"---具有人工智能的计算机控制器：主要分类播报编辑控制器分组合逻辑控制器和微程序控制器，两种控制器各有长处和短处。组合逻辑控制器设计麻烦，结构复杂，一旦设计完成，就不能再修改或扩充，但它的速度快。微程序控制器设计方便，结构简单，修改或扩充都方便，修改一条机器指令的功能，只需重编所对应的微程序；要增加一条机器指令，只需在控制存储器中增加一段微程序，但是，它是通过执行一段微程。具体对比如下：组合逻辑控制器又称硬布线控制器，由逻辑电路构成，完全靠硬件来实现指令的功能。工作原理播报编辑电磁吸盘控制器：交流电压380V经变压器降压后，经过整流器整流变成110V直流后经控制装置进入吸盘此时吸盘被充磁，退磁时通入反向电压线路，控制器达到退磁功能。门禁控制器：门禁控制器工作在两种模式之下。一种是巡检模式，另一种是识别模式。在巡检模式下，控制器不断向读卡器发送查询代码，并接收读卡器的回复命令。这种模式会一直保持下去，直至读卡器感应到卡片。当读卡器感应到卡片后，读卡器对控制器的巡检命令产生不同的回复，在这个回复命令中，读卡器将读到的感应卡内码数据传送到门禁控制器，使门禁控制器进入到识别模式。在门禁控制器的识别模式下，门禁控制器分析感应卡内码，同设备内存储的卡片数据进行比对，并实施后续动作。门禁控制器完成接收数据的动作后，会发送命令回复读卡器，使读卡器恢复状态，同时，门禁控制器重新回到巡检模式。常见种类播报编辑组合逻辑组合逻辑控制器由时序电路、指令译码电路和组合逻辑电路三部分组成。通过指令译码器确定当前执行的指令，结合时序电路产生的节拍，共同作为组合逻辑电路的输入结果输出相应的控制信号。组合逻辑控制器是由复杂组合逻辑门电路和触发器构成，执行速度快，因此在计算机结构比如RISC中得到广泛应用。[1]设计步骤：1、设计机器的指令系统：规定指令的种类、指令的条数以及每一条指令的格式和功能；2、初步的总体设计：如寄存器设置、总线安排、运算器设计、部件间的连接关系等；3、绘制指令流程图：标出每一条指令在什么时间、什么部件进行何种操作；4、编排操作时间表：即根据指令流程图分解各操作为微操作，按时间段列出机器应进行的微操作；5、列出微操作信号表达式，化简，电路实现。基本组成：1、指令寄存器用来存放正在执行的指令。指令分成两部分：操作码和地址码。操作码用来指示指令的操作性质，如加法、减法等；地址码给出本条指令的操作数地址或形成操作数地址的有关信息（这时通过地址形成电路来形成操作数地址）。有一种指令称为转移指令，它用来改变指令的正常执行顺序，这种指令的地址码部分给出的是要转去执行的指令的地址。2、操作码译码器：用来对指令的操作码进行译码，产生相应的控制电平，完成分析指令的功能。3、时序电路：用来产生时间标志信号。在微型计算机中，时间标志信号一般为三级：指令周期、总线周期和时钟周期。微操作命令产生电路产生完成指令规定操作的各种微操作命令。这些命令产生的主要依据是时间标志和指令的操作性质。该电路实际是各微操作控制信号表达式（如上面的A→L表达式）的电路实现，它是组合逻辑控制器中最为复杂的部分。4、指令计数器：用来形成下一条要执行的指令的地址。通常，指令是顺序执行的，而指令在存储器中是顺序存放的。所以，一般情况下下一条要执行的指令的地址可通过将现行地址加1形成，微操作命令“1”就用于这个目的。如果执行的是转移指令，则下一条要执行的指令的地址是要转移到的地址。该地址就在本转移指令的地址码字段，将其直接送往指令计数器。微程序控制器的提出是因为组合逻辑设计存在不便于设计、不灵活、不易修改和扩充等缺点。微程序微程序控制(简称微码控制)的基本思路是：用微指令产生微操作命令，一条指令的功能通过执行一系列基本操作来完成，这些基本操作称为微操作，每个微操作在相应控制信号的控制下执行，这些控制信号在微程序设计中称为微命令。微程序是一个微指令序列，对应于一条机器指令的功能，每条微指令是一个0/1序列，其中包含若干个微命令，它完成一个基本运算或传送功能，有时也将微指令字，称作控制字(controlword)[2]。微程序控制器的组成：1、控制存储器（ControlMemory）用来存放各机器指令对应的微程序。译码器用来形成机器指令对应的微程序的入口地址。当将一条机器指令对应的微程序的各条微指令逐条取出，并送到微指令寄存器时，其微操作命令也就按事先的设计发出，因而也就完成了一条机器指令的功能。对每一条机器指令都是如此。2、微指令的宽度直接决定了微程序控制器的宽度。为了简化控制存储器，可采取一些措施来缩短微指令的宽度。如采用字段译码法一级分段译码。显然，微指令的控制字段将大大缩短。，一些要同时产生的微操作命令不能安排在同一个字段中。为了进一步缩短控制字段，还可以将字段译码设计成两级或多级。CPU控制器是指挥计算机的各个部件按照指令的功能要求协调工作的部件，是计算机的神经中枢和指挥中心，由指令寄存器IR（InstructionRegister）、程序计数器PC（ProgramCounter）和操作控制器OC（OperationController）三个部件组成，对协调整个电脑有序工作极为重要。指令寄存器：用以保存当前执行或即将执行的指令的一种寄存器。指令内包含有确定操作类型的操作码和指出操作数来源或去向的地址。指令长度随不同计算机而异，指令寄存器的长度也随之而异。计算机的所有操作都是通过分析存放在指令寄存器中的指令后再执行的。指令寄存器的输人端接收来自存储器的指令，指令寄存器的输出端分为两部分。操作码部分送到译码电路进行分析，指出本指令该执行何种类型的操作;地址部分送到地址加法器生成有效地址后再送到存储器，作为取数或存数的地址。存储器可以指主存、高速缓存或寄存器栈等用来保存当前正在执行的一条指令。当执行一条指令时，先把它从内存取到数据寄存器（DR）中，然后再传送至IR。指令划分为操作码和地址码字段，由二进制数字组成。为了执行任何给定的指令，必须对操作码进行测试，以便识别所要求的操作。指令译码器就是做这项工作的。指令寄存器中操作码字段的输出就是指令译码器的输入。操作码一经译码后，即可向操作控制器发出具体操作的特定信号。程序计数器：指明程序中下一次要执行的指令地址的一种计数器，又称指令计数器。它兼有指令地址寄存器和计数器的功能。当一条指令执行完毕的时候，程序计数器作为指令地址寄存器，其内容必须已经改变成下一条指令的地址，从而使程序得以持续运行。为此可采取以下两种办法：第一种办法是在指令中包含了下一条指令的地址。在指令执行过程中将这个地址送人指令地址寄存器即可达到程序持续运行的目的。这个方法适用于早期以磁鼓、延迟线等串行装置作为主存储器的计算机。根据本条指令的执行时间恰当地决定下一条指令的地址就可以缩短读取下一条指令的等待时间，从而收到提高程序运行速度的效果。第二种办法是顺序执行指令。一个程序由若干个程序段组成，每个程序段的指令可以设计成顺序地存放在存储器之中，所以只要指令地址寄存器兼有计数功能，在执行指令的过程中进行计数，自动加一个增量，就可以形成下一条指令的地址，从而达到顺序执行指令的目的。这个办法适用于以随机存储器作为主存储器的计算机。当程序的运行需要从一个程序段转向另一个程序段时，可以利用转移指令来实现。转移指令中包含了即将转去的程序段入口指令的地址。执行转移指令时将这个地址送人程序计数器(此时只作为指令地址寄存器，不计数)作为下一条指令的地址，从而达到转移程序段的目的。子程序的调用、中断和陷阱的处理等都用类似的方法。在随机存取存储器普及以后，第二种办法的整体运行效果大大地优于第一种办法，因而顺序执行指令已经成为主流计算机普遍采用的办法，程序计数器就成为中央处理器不可或缺的一个控制部件。CPU内的每个功能部件都完成一定的特定功能。信息在各部件之间传送及数据的流动控制部件的实现。通常把许多数字部件之间传送信息的通路称为“数据通路”。信息从什么地方开始，中间经过哪个寄存器或多路开关，最后传到哪个寄存器，都要加以控制。在各寄存器之间建立数据通路的任务，是由称为“操作控制器”的部件来完成的。操作控制器的功能就是根据指令操作码和时序信号，产生各种操作控制信号，以便正确地建立数据通路，从而完成取指令和执行指令的控制。有两种由于设计方法不同因而结构也不同的控制器。微操作是指不可再分解的操作，进行微操作总是需要相应的控制信号(称为微操作控制信号或微操作命令)。一台数字计算机基本上可以划分为两大部分---控制部件和执行部件。控制器就是控制部件，而运算器、存储器、外围设备相对控制器来说就是执行部件。控制部件与执行部件的一种联系就是通过控制线。控制部件通过控制线向执行部件发出各种控制命令，通常这种控制命令叫做微命令，而执行部件接受微命令后所执行的操作就叫做微操作。控制部件与执行部件之间的另一种联系就是反馈信息。执行部件通过反馈线向控制部件反映操作情况，以便使得控制部件根据执行部件的状态来下达新的微命令，这也叫做“状态测试”。微操作在执行部件中是组基本的操作。由于数据通路的结构关系，微操作可分为相容性和相斥性两种。在机器的一个CPU周期中，一组实现一定操作功能的微命令的组合，构成一条微指令。一般的微指令格式由操作控制和顺序控制两部分构成。操作控制部分用来发出管理和指挥全机工作的控制信号。其顺序控制部分用来决定产生下一个微指令的地址。事实上一条机器指令的功能是由许多条微指令组成的序列来实现的。这个微指令序列通常叫做微程序。既然微程序是有微指令组成的，那么当执行当前的一条微指令的时候。必须指出后继微指令的地址，以便当前一条微指令执行完毕以后，取下一条微指令执行。LEDLED控制器(LEDcontroller)就是通过芯片处理控制LED灯电路中的各个位置的开关。低压型LED产品控制器：低压型LED产品一般设计电压12V-36V,每个回路LED数量3-6个串联，用电阻降压限流，每个回路电流20mA以下。一个LED产品由多个回路的LED组成，优点是低压，结构简单，容易设计；缺点是：产品规模大时电流很大，需要配置低压开关电源。由于产品的缺点所限，低压不可能远距离输电，都是局限于体积不大的产品上，如招牌文字、小图案等。根据这个特点，控制器设计规格：12V的选用75A/30VMOS功率管控制，输出电流8A/路；24-36V选用60A/50VMOS功率管控制，输出电流5A/路。用户可以根据以上规格选定控制器的路数，跳变的可以选购NE20低压系列、渐变的选购NE10低压系列控制器即可。注意LED的必须是共阳(+)极连接法，控制器控制阴(-)极，控制器不包括低压电源高压型LED产品控制器：高压型LED产品设计电压是交流/直流220V电压，每个回路LED数量36-48个串联，每个回路电流20mA以下，限流方式有两种，一种是电阻限流，这种方式电阻功耗较大，建议使用每4个LED串接一个1/4W金属模电阻，均匀分布散热，这种接法是最稳定可靠；另一种是电阻电容串联限流，这种接法大部分电压降在电容上，电阻功耗小，只能用在稳定的长亮状态，如果闪动电容储能，反而电压加倍，LED容易损坏。凡是使用控制器的LED必须使用电阻限流方式，LED一般每个回路一米，功率5W，三色功率每米15W。常用渐变控制器NE112K控制直流1200W，NE103D交流负载4500W直流负载1500W，如果灯管闪动单元多就使用NE112K，如果只需要整体闪动就使用NE103D。如果使用渐变方式，要注意负载匹配，霓虹灯和LED的发光分布特性不一样，同一回路不能混接不同类型的负载。低压串行控制器：低压型LED产品串行控制器的特点是控制路数多，利用串行信号传输达到控制的目的，一般512单元的控制只需要4条控制连线，串行LED控制器需要在LED的光源板配有寄存器，控制器可选用型号NE040S控制器，该控制器的最大容量达到4096KBit,如果负载512单元的LED可以最大实现8192桢画面。还有就是安全行业所使用的控制器，控制探测器在各工作区间内监测气体的一种设备。门禁门禁控制器就是门禁系统的核心，对出入口通道进行管制的系统大脑，它是在传统的门锁基础上发展而来的。门控制器是读卡和控制合二为一的门禁控制产品，有独立型的也有联网型的。简单而言，门禁控制器就是集门禁控制板、读卡器于一体的机器，高档点的还包括键盘跟显示屏，只需要接上电源就可以当完整的门禁系统使用了。门控制器的分类：1、按照门控制器和管理电脑的通讯方式分为：RS485联网型门控制器、TCP/IP网络型门控制器、不联网门控制器。（1）不联网门控制器，就是一个机子管理一个门，不能用电脑软件进行控制，也不能看到记录，直接通过控制器进行控制。特点是价格便宜，安装维护简单，不能查看记录，不适合人数量多于50或者人员经常流动（指经常有人入职和离职）的地方，也不适合门数量多于5的工程。（2）485联网门控制器，就是可以和电脑进行通讯的门禁类型，直接使用软件进行管理，包括卡和事件控制。所以有管理方便、控制集中、可以查看记录、对记录进行分析处理以用于其它目的。特点是价格比较高、安装维护难道加大，但培训简单，可以进行考勤等增值服务。适合人多、流动性大、门多的工程。（3）TCP/IP网络门控制器，也叫以太网联网门禁，也是可以联网的门禁系统，但是通过网络线把电脑和控制器进行联网。除具有485门禁联网的全部优点以外，还具有速度更快，安装更简单，联网数量更大，可以跨地域或者跨城联网。但存在设备价格高，需要有电脑网络知识。适合安装在大项目、人数量多、对速度有要求、跨地域的工程中。2、按照每台控制器控制的门的数量可以分为：单门控制器、双门控制器、四门控制器及多门控制器。3、控制器根据每个门可接读卡器的数量分为：单向控制器、双向控制器。注：如果一个门，进门刷卡，出门按按钮，控制器对于每个门只能接一个读卡器，叫单向控制器。如果一个门，进门刷卡，出门也刷卡（也可以接出门按钮），每个控制器对于每个门可以接两个读卡器，一个是进门读卡器，一个是出门读卡器，叫双向控制器。电动汽车电动汽车控制器是用来控制电动车电机的启动、运行、进退、速度、停止以及电动车的其它电子器件的核心控制器件，它就象是电动车的大脑，是电动车上重要的部件。电动车主要包括电动自行车、电动二轮摩托车、电动三轮车、电动三轮摩托车、电动四轮车、电瓶车等，电动车控制器也因为不同的车型而有不同的性能和特点。超静音设计技术：独特的电流控制算法，能适用于任何一款无刷电动车电机，并且具有相当的控制效果，提高了电动车控制器的普遍适应性，使电动车电机和控制器不再需要匹配。恒流控制技术：电动车控制器堵转电流和动态运行电流完全一致，保证了电池的寿命，并且提高了电动车电机的启动转矩。自动识别电机模式系统：自动识别电动车电机的换相角度、霍尔相位和电机输出相位，只要控制器的电源线、转把线和刹车线不接错，就能自动识别电机的输入及输出模式，可以省去无刷电动车电机接线的麻烦，大大降低了电动车控制器的使用要求。随动abs系统：具有反充电/汽车EABS刹车功能，引入了汽车级的EABS防抱死技术，达到了EABS刹车静音、柔和的效果，不管在任何车速下保证刹车的舒适性和稳定性，不会出现原来的abs在低速情况下刹车刹不住的现象，完全不损伤电机，减少机械制动力和机械刹车的压力，降低刹车噪音，大大增加了整车制动的安全性；并且刹车、减速或下坡滑行时将EABS产生的能量反馈给电池，起到反充电的效果，从而对电池进行维护，延长电池寿命，增加续行里程，用户可根据自己的骑行习惯自行调整EABS刹车深度。电机锁系统：在警戒状态下，报警时控制器将电机自动锁死，控制器几乎没有电力消耗，对电机没有特殊要求，在电池欠压或其他异常情况下对电动车正常推行无任何影响。自检功能：分动态自检和静态自检，控制器只要在上电状态，就会自动检测与之相关的接口状态，如转把，刹把或其它外部开关等等，一旦出现故障，控制器自动实施保护，充分保证骑行的安全，当故障排除后控制器的保护状态会自动恢复。反充电功能：刹车、减速或下坡滑行时将EABS产生的能量反馈给电池，起到反充电的效果，从而对电池进行维护，延长电池寿命，增加续行里程。堵转保护功能：自动判断电机在过流时是处于完全堵转状态还是在运行状态或电机短路状态，如果过流时是处于运行状态，控制器将限流值设定在固定值，以保持整车的驱动能力；如电机处于纯堵转状态，则控制器2秒后将限流值控制在10A以下，起到保护电机和电池，节省电能；如电机处于短路状态，控制器则使输出电流控制在2A以下，以确保控制器及电池的安全。动静态缺相保护：指在电机运行状态时，电动车电机任意一相发生断相故障时，控制器实行保护，避免造成电机烧毁，同时保护电动车电池、延长电池寿命。功率管动态保护功能：控制器在动态运行时，实时监测功率管的工作情况，一旦出现功率管损坏的情况，控制器马上实施保护，以防止由于连锁反应损坏其他的功率管后，出现推车比较费力的现象。防飞车功能：解决了无刷电动车控制器由于转把或线路故障引起的飞车现象，提高了系统的安全性。1+1助力功能：用户可自行调整采用自向助力或反向助力，实现了在骑行中辅以动力，让骑行者感觉更轻松。巡航功能：自动/手动巡航功能一体化，用户可根据需要自行选择，8秒进入巡航，稳定行驶速度，无须手柄控制。模式切换功能：用户可切换电动模式或助力模式。防盗报警功能：超静音设计，引入汽车级的遥控防盗理念，防盗的稳定性更高，在报警状态下可锁死电机，报警喇叭音效高达125dB以上，具有极强的威慑力。并具有自学习功能，遥控距离长达150米不会有误码产生。倒车功能：控制器增加了倒车功能，当用户在正常骑行时，倒车功能失效；当用户停车时，按下倒车功能键，可进行辅助倒车，并且倒车速度最高不超过10km/h。遥控功能：采用先进的遥控技术，长达256的加密算法，灵敏度多级可调，加密性能更好，并且绝无重码现象发生，极大地提高了系统的稳定性，并具有自学习功能，遥控距离长达150米不会有误码产生。高速控制：采用最新的为马达控制设计专用的单片机，加入全新的BLDC控制算法，适用于低于6000rpm高速、中速或低速电机控制。电机相位：60度120度电机自动兼容，不管是60度电机还是120度电机，都可以兼容，不需要修改任何设置。维修方法：1、当电动车有刷控制器没有输出时（1）将万用表设置在+20发（DC）档位，先测量闸把输出信号的高、低电位。（2）如捏闸把时，闸把信号有超过4V的电位变化，则可排除闸把故障。（3）然后按照有刷控制器常用世道上脚功能表，与测量出的主控世道民逻辑芯片的电压值进行电路分析，并检查各芯片外围器件（电阻、电容、二极管）的数值是否和元件表面的标识相一致。（4）最后检查外围器件或是集成电路出现故障，可以通过更换同型号的器件来排除故障。2、当电动车无刷控制器完全没有输出时（1）参照无刷电机控制器主相位检查测量图，用万用表直流电压+50V档，检测6路MOS管栅极电压是否与转把的转动角度呈对应关系。（2）如没有对，表示控制器里的PWM电路或MOS管驱动电路有故障。（3）参照无刷控制器主相位检查图，测量芯片的输入输出引脚的电压是否与转把转动角度有对应关系，可以判断哪些芯片有故障，更换同型号芯片即可排除故障。3、当电动车有刷控制器控制部件的电源不正常时不同种类的控制器(40张)（1）电动车控制器内部电源一般采用三端稳压集成电路，一般用7805、7806、7812、7815三端稳压集成电路，它们的输出电压分别是5V、6V、12V、15V。（2）将万用表设置在直流电压+20V(DC)档位，将万用表黑表笔与红表笔分别靠在转把的黑线和红线上，观察万用表读数是否与标称电压相符，它们的上下电压差不应超过0.2V。（3）否则说明控制器内部电源出现故障了，一般有刷控制器可以通过更换三端稳压集成电路排除故障。4、当电动车无刷控制器缺相时电动车无刷控制器电源与闸把的故障可以参考有刷控制器的故障排除方法先予排除，对无刷控制器而言，还有其特有故障现象，比如缺相。电动车无刷控制器缺相现象可以分为主相位缺相和霍耳缺相两种情况。（1）主相位缺相的检测方法可以参照电动车有刷控制器飞车故障排除法，检测MOS管是否击穿，无刷控制器MOS管击穿一般是某一个相位的上下两个一对MOS管同时击穿，更换时确保同时更换。检查测量点。（2）电动车无刷控制器的霍耳缺相表现为控制器不能识别电机霍耳信号。火灾报警火灾自动报警系统应有自动和手动两种触发装置。各种类型的火灾探测器是自动触发装置，而在防火分区疏散通道、楼梯口等处设置的手动火灾报警按钮是手动触发装置，它应具有应急情况下，人工手动通报火警的功能。火灾报警控制器是火灾自动报警系统心脏，具有下述功能：1、用来接受火灾信号并启动火灾警报装置。该设备也可用来指示着火部位和记录有关信息；2、能通过火警发送装置启动火灾报警信号或通过自动消防灭火控制装置启动自动灭火设备和消防联动控制器；3、自动地监视系统的正确运行和对特定故障给出声、光报警。火灾报警控制器种类繁多，根据不同的方法可分成不同的类别：1、按控制范围可分为：a、区域火灾报警控制器：直接连接火灾探测器，处理各种报警信息。b、集中火灾报警控制器：它一般不与火灾探测器相连，而与区域火灾报警控制器相连，处理区域级火灾报警控制器送来的报警信号，常使用在较大型系统中。c、控制中心火灾报警控制器：它兼有区域，集中两级或火灾报警控制器的特点，即可以作区域级使用，连接控制器；又可以作集中级使用，连接区域火灾报警控制器。2、按结构型式可分为：（1）壁挂式火灾报警控制器：连接的探测器回路相应少些，控制功能简单，区域报警控制器多才用这种型式；（2）台式火灾报警控制器：连接探测器回路数较多，联动控制较复杂，集中式报警器常采用这种方式；（3）框式火灾报警控制器：可实现多回路连接，具有复杂的联动控制。3、按系统布线方式分为：（1）多线制火灾报警控制器：探测器与控制器的连接采用一一对应方式；（2）总线制火灾报警控制器：控制器与探测器采用总线方式连接，探测器并联或串联在总线上。火灾报警控制器的功能：1、火灾报警：当收到探测器、手动报警开关、消火栓开关及输入模块所配接的设备所发来的火警信号时，均可在报警器中报警；2、故障报警：系统运行时控制器分时巡检，若有异常（设备故障）发出声、光报警信号，并显示故障类型及编码等；3、火警优先：在故障报警或已处理火警时，若发生火警则报火警，而当火警清除后又自动报原有的故障。pid所谓PID控制，就是在一个闭环控制系统中，使被控物理量能够迅速而准确地无限接近于控制目标的一种手段。PID控制功能是变频器应用技术的重要领域之一，也是变频器发挥其卓越效能的重要技术手段。变频调速产品的设计、运行、维护人员应该充分熟悉并掌握PID控制的基本理论。工业自动化水平已成为衡量各行各业现代化水平的一个重要标志。同时，控制理论的发展也经历了古典控制理论、现代控制理论和智能控制理论三个阶段。智能控制的典型实例是模糊全自动洗衣机等。自动控制系统可分为开环控制系统和闭环控制系统。一个控制系统包括控制器﹑传感器﹑变送器﹑执行机构﹑输入输出接口。控制器的输出经过输出接口﹑执行机构，加到被控系统上；控制系统的被控量，经过传感器﹐变送器﹐通过输入接口送到控制器。不同的控制系统﹐其传感器﹑变送器﹑执行机构是不一样的。比如压力控制系统要采用压力传感器。电加热控制系统的传感器是温度传感器。PID控制及其控制器或智能PID控制器（仪表）已经很多，产品已在工程实际中得到了广泛的应用，有各种各样的PID控制器产品，各大公司均开发了具有PID参数自整定功能的智能调节器（intelligentregulator），其中PID控制器参数的自动调整是通过智能化调整或自校正、自适应算法来实现。有利用PID控制实现的压力、温度、流量、液位控制器，能实现PID控制功能的可编程控制器（PLC），还有可实现PID控制的PC系统等等。可编程控制器（PLC）是利用其闭环控制模块来实现PID控制，而可编程控制器可以直接与ControlNet相连，还有可以实现PID控制功能的控制器。母联母联控制器主要用于自动控制切换带母线联络断路的两路电源的供电系统。控制模式有母联备自投，进线备自投两种。组成母联自动转换开关的有：母联控制器、三相交流过欠压断相保护器、空气断路器。适合多型号断路器，有电动操作机构就能与控制器连接。自动转换开关自动转换开关控制器是一种具有可编程，自动化测量，LCD显示，数字通讯等为一体的智能双电源切换系统。在与低压空气断路器配套后，特别适合于两路低压进线侧的自动转换和保护。自动转换开关控制器的执行部件是框架式空气断路器，两台断路器不用加装适配器，控制器直接对供应电源状态进行监测，自动控制完成常用电源与备用电源的切换。1、控制器为两路低压进线提供自动转换控制和保护；2、适合多型号的框架断路器；3、控制器的电气联锁，断路器的机械联锁，确保二台断路器不能同时合闸；4、具有手动，自动转换功能；5、控制器与断路器直接二次线连接，中间无需适配器；6、在控制器或监控中心汉显两路电源的电量参数，并能设定和更改控制器所有参数；7、供电方式可设定为一路优先，二路优先或无优先；8、具有自启动油机功能；9、具有RS-232C和RS-485通讯接口。运动运动控制器是运动控制系统的核心部件。国内的运动控制器大致可以分为3类：第1类是以单片机等微处理器作为控制核心的运动控制器。这类运动控制器速度较慢、精度不高、成本相对较低，只能在一些低速运行和对轨迹要求不高的轮廓运动控制场合应用。第2类是以专用芯片（ASIC）作为核心处理器的运动控制器，这类运动控制器结构比较简单，大多只能输出脉冲信号，工作于开环控制方式。由于这类控制器不能提供连续插补功能，也没有前馈功能，特别是对于大量的小线段连续运动的场合不能使用这类控制器。第3类是基于PC总线的以DSP或FPGA作为核心处理器的开放式运动控制器。这类开放式运动控制器以DSP芯片作为运动控制器的核心处理器，以PC机作为信息处理平台，运动控制器以插件形式嵌入PC机，即“PC+运动控制器”的模式。这样的运动控制器具有信息处理能力强，开放程度高，运动轨迹控制准确，通用性好的特点。但是这种方式存在以下缺点：运动控制卡需要插入计算机主板的PCI或者ISA插槽，因此每个具体应用都必须配置一台PC机作为上位机。这无疑对设备的体积、成本和运行环境都有一定的限制，难以独立运行和小型化。微型微控制器（MicroController）又可简称MCU或μC，也有人称为单芯片微控制器（SingleChipMicrocontroller），将ROM、RAM、CPU、I/O集合在同一个芯片中,为不同的应用场合做不同组合控制。微控制器在经过这几年不断地研究、发展，历经4位、8位，到如今的16位及32位，甚至64位。产品的成熟度，以及投入厂商之多、应用范围之广，真可谓之空前。在国外大厂因开发较早、产品线广，所以技术领先，而本土厂商则以多功能为产品导向取胜。基本功能播报编辑数据缓冲：由于I/O设备的速率较低而CPU和内存的速率却很高，故在控制器中必须设置一缓冲器。在输出时，用此缓冲器暂存由主机高速传来的数据，然后才以I/O设备所具有的速率将缓冲器中的数据传送给I/O设备；在输入时，缓冲器则用于暂存从I/O设备送来的数据，待接收到一批数据后，再将缓冲器中的数据高速地传送给主机。差错控制：设备控制器还兼管对由I/O设备传送来的数据进行差错检测。若发现传送中出现了错误，通常是将差错检测码置位，并向CPU报告，于是CPU将本次传送来的数据作废，并重新进行一次传送。这样便可保证数据输入的正确性。数据交换：这是指实现CPU与控制器之间、控制器与设备之间的数据交换。对于前者，是通过数据总线，由CPU并行地把数据写入控制器，或从控制器中并行地读出数据；对于后者，是设备将数据输入到控制器，或从控制器传送给设备。为此，在控制器中须设置数据寄存器。状态说明：标识和报告设备的状态控制器应记下设备的状态供CPU了解。例如，仅当该设备处于发送就绪状态时，CPU才能启动控制器从设备中读出数据。为此，在控制器中应设置一状态寄存器，用其中的每一位来反映设备的某一种状态。当CPU将该寄存器的内容读入后，便可了解该设备的状态。接收和识别命令：CPU可以向控制器发送多种不同的命令，设备控制器应能接收并识别这些命令。为此，在控制器中应具有相应的控制寄存器，用来存放接收的命令和参数，并对所接收的命令进行译码。例如，磁盘控制器可以接收CPU发来的Read、Write、Format等15条不同的命令，而且有些命令还带有参数；相应地，在磁盘控制器中有多个寄存器和命令译码器等。地址识别：就像内存中的每一个单元都有一个地址一样，系统中的每一个设备也都有一个地址，而设备控制器又必须能够识别它所控制的每个设备的地址。此外，为使CPU能向(或从)寄存器中写入(或读出)数据，这些寄存器都应具有唯一的地址。PC：释义Privateclub私人俱乐部；PaddingCondenser垫整[微调]电容器；Paperchromatography纸色谱法；PartsCatalog零件目录；PathControl通路控制；PeaceCorps和平队[美]；PercentageofCompletion完工百分率；PetersenCoil消弧线圈；Pharmaceuticalcompanies医药公司；PhosphatidylCholine磷酯胆碱；磷肌酸；Photocell光敏电阻；Photoconductor光敏电阻，光电导体；PhotoCredit照片来源/拍摄者PitchCircle(齿轮)节圆；Plano-convex平凸透镜；pokemoncenter《口袋妖怪》中的口袋妖怪中心（亦称神奇宝贝中心，日：ポケモンセンター）；PoliceConstable（香港、英国）警察；Polychloroprene聚丁二烯；PolymerConcrete聚合物混凝土；postalcode邮政编码；Postcrossing国际明信片交流；powercenter动力中心；precastconcrete混凝土预制件；PrestressedConcrete预应力混凝土；PricedCatalogue价目表；PrimeCost成本，原价；printedcircuit印刷电路；ProcessController过程控制器；productcarrier成品油轮；ProductionControl生产控制；ProgramController程序控，指希望一切事物和活动都通过代码来来实现以及控制的程序员；ProgramCounter程序计数器；ProgrammableController可编程控制器；ProportionalCounter正比计数器；PulseController脉冲控制器；PulseCounter脉冲计数器；PunchedCard穿孔卡片；pyrolyticcarbon热解碳；PolarizationController偏振控制器。perfectcombo完美连击（音游使用，也作ap，allperfect）MAR：剧情简介播报编辑故事讲述一个运动不行、成绩很差、严重近视的中学二年级学生虎水银太，在一次机缘巧合下被”小丑守门人“传唤而来到一直向往着的奇幻的异世界——MARHEAVEN。在这个世界上，人们使用着名为”ÄRM“的魔法银饰。银太遇到了活着的ÄRM“巴波“并结识了一群志同道合的队友，为打倒邪恶军团”Chess兵队“、守护异世界的和平而共同努力。[1]魔兵传奇动画制作播报编辑制作人员原作：安西信行原案协力：都筑伸一郎、林正人、宫坂保志监督：奥胁雅晴（1话~52话）、川口敬一郎（53话~102话）Supervisor：野村敦司、沢辺伸政、斎藤裕系列构成：武上纯希角色设定、总作画监督：小丸敏之ÄRM设计：虾名康哲（1话~51话）今野幸一（52话~102话）美术监督：梶原芳郎色彩设计：黑柳朋子摄影监督：ひろちけんじ编辑：小峰博美音响监督：渡边淳音乐：池田大介3DCG制作：小学馆音乐&数码娱乐制作人：笹村武史（1~10话），青木俊志（11~71话），岩田伸一、古市直彦（72~102话）线上制作人：下地志直（1〜26话）动画制作人：樱井凉介动画制作：SynergySP制作：东京电视台、小学馆集英社制片公司参考资料[2]角色配音角色日本配音台湾配音虎水银太熊井统子→（代役）比嘉久美子钱欣郁巴波银河万丈曹冀鲁白雪清水爱冯嘉德桃乐丝中岛沙树冯嘉德阿尔维斯保志总一朗吴文民杰克阪口大助冯嘉德那那西小野坂昌也曹冀鲁艾伦小杉十郎太、皆川纯子（孩童）黄天佑参考资料[3]剧集信息播报编辑话数标题（日/中）剧本分镜演出作画监督1开け!异世界の扉!!开启吧！异世界的大门！！武上纯希奥胁雅晴小高义规长森佳容2伝说のアーム!バッボ!!传说中的ARM！巴波！！のがみかずお齐藤和也3ジャック!バトルスコップ発动!!杰克！战斗银铲发动！！神户一彦千叶大辅植田秀仁千叶大辅冈辰也4ギンタ!バッボを取り返せ!!银太！把巴波抢回来！！早川正奥村吉昭李豪世5谜の美少年、アルヴィス谜之美少年，阿尔维斯植田浩二奥胁雅晴小林哲也江森真理子6氷の中の少女、スノウ冰中的少女，白雪松园公小高义规长森佳容7目覚めよ!もう一人のエド!!觉醒吧！另一个爱德！！早川正奥胁雅晴のがみかずお久保山英一田中薰8复活のナイト・ファントム复活的骑士・魅影神户一彦小林哲也千叶大辅冈辰也9修练の门、メリロとプモル修炼之门，梅莉露与布莫路武上纯希奥村吉昭李豪世10第二次メルヘヴン大戦第二次MARHEAVEN大战植田浩二奥胁雅晴小林哲也江森真理子11见せてやる!バッボ・バージョン（2）!!让你见识一下！巴波的第二形态！！早川正松园公福田贵之小丸敏之12ルベリアのボス、ナナシ!鲁贝利亚的首领，那那西！神户一彦奥胁雅晴おゆなむ江原康之13地底湖の戦い!ナナシVSオルコ!!地底湖之战！那那西VS欧路戈！！植田浩二植田秀仁千叶大辅冈辰也14バッボバージョン（3）!出て来いガーゴイル!!巴波变形系列三！出来吧，石翼魔！！武上纯希奥村吉昭李豪世157人目の仲间?ジョン・ピーチ!?第七名伙伴？约翰・皮奇？！植田浩二奥胁雅晴千叶大辅こひらかずと16ウォーゲーム开始!WARGAME开始！早川正奥村吉昭藤本义孝石川哲也171STバトル（1）!アルヴィスVSレノ!!第一回合战斗！阿尔维斯VS雷诺！！神户一彦松园公冈崎幸男江原康之登坂晋181STバトル（2）!ジャックVSパノ!!第一回合之二！杰克VS芭诺！！武上纯希小林哲也江森真理子19キャプテン・ギンタ!ガーゴイルVSガロン队长・银太！石翼魔VS盖隆神户一彦ヤマトナオミチ草刈大介20修练の门再び!ケンカのやり方教えます!!修炼之门再临！传授打架之道！！早川正奥胁雅晴福田贵之石川哲也21砂漠フィールド!闘うお姫様!!沙漠区！奋战的公主！！神户一彦奥村吉昭曾我笃史22ナナシVSロコ!呪いのワラ人形!!那那西VS洛可！诅咒稻草人！！武上纯希松园公冈崎幸男樱井木之实23恐るべき魔女!ドロシー!!惊人的魔女！桃乐丝！！神户一彦小林哲也江森真理子24ファントムの密やかな楽しみ魅影一个人独享的乐趣植田浩二奥胁雅晴畠山茂树草刈大介25遅れてきた男!アラン!!迟来的男人！艾伦！！武上纯希福田贵之宇中仁26男を见せるぜジャック!魔法のキノコ!!展现男子气概的杰克！魔法蘑菇！！神户一彦奥村吉昭曾我笃史27私、负けないよ!火山群のスノウ!!我决不会输的！火山群中的白雪！！早川正奥胁雅晴冈崎幸男樱井木之实28呪いのロウソク!ギンタVSカノッチ!!诅咒蜡烛！银太VS卡诺奇！！武上纯希植田秀仁小林哲也江森真理子29もうひとつのゾンビタトゥ!アルヴィスVSロラン!!另一个僵尸刺青！阿尔维斯VS罗兰！！植田浩二ヤマトナオミチ草刈大介30戦栗!ファントムとゾディアックのナイト!!战栗！魅影与13星座骑士！！武藏境考福田贵之槙田一章31シャドーバトル!ガーゴイルVSブラックガーゴイル!!影子对战！石翼魔VS黑影石翼魔！！武上纯希大关雅幸曾我笃史32静かなる闘志…アルヴィスの力…沉寂的斗志…阿尔维斯的力量…神户一彦大平直树冈崎幸男岛田贤志古谷田顺久33どうなるジャック!どうするドロシー!?杰克会怎样！桃乐丝怎么办？！静谷伊佐夫おおそ独犬山口美浩氏家嘉宏野道佳代34アクアとアッコちゃんとナナシ流!亚可亚，可可与那那西的作风！高桥奈津子奥胁雅晴菅井嘉浩植田理恵35逆袭のギロム!エゴラVSガーゴイル!!奇洛姆的反攻！艾克拉VS石翼魔植田浩二奥村吉昭福田贵之まきだかずあき36ドロシーVSラプンツェル、呗え。クレイジーキルト!!桃乐丝VS拉普洁唱吧，疯狂娃娃！！神户一彦大关雅幸曾我笃史37魔法の国、カルデアへ魔法王国，卡鲁帝亚武上纯希向中野义雄近藤优次38侵略者ファントム・ギンタ激闘の果てに…侵略者魅影・银太激战的结果植田浩二奥胁雅晴冈崎幸男岛田贤志39こども大好きナイト、アッシュ!!喜欢小孩的骑士，亚修！！静谷伊佐夫井草かほる山口美浩氏家嘉宏野道佳代40世界一ブサイク决定戦!?スノウVSエモキス!!世界第一丑选拔赛？！白雪VS爱摩奇丝！！高桥奈津子中村贤太郎小野田雄亮菅井嘉浩器田竹一41夺われた魔力!アルヴィスの危机!!魔力被夺走了！阿尔维斯的危机！！神户一彦奥田诚治福田贵之まきだかずあき42快感!石使いのナイト、キャンディス!!快感！石使者骑士，小甜甜！！植田浩二奥胁雅晴大关雅幸曾我笃史43死の戦场!サイコスペース!!死亡战场！惊魂空间！！武上纯希向中野义雄近藤优次44运命の死闘!ナナシVSガリアン!!命中注定的决斗！那那西VS卡里安！！植田浩二奥胁雅晴冈崎ゆきお岛田贤志45雷撃×雷撃!ナナシ、よみがえる记忆!!雷击×雷击！那那西苏醒的记忆！！山口美浩氏家嘉宏野道佳代46新生ナイト、复讐のイアン!新生骑士复仇的伊安！神户一彦井草かほる小野田雄亮岛村惠美子47伤だらけのアルヴィス遍体鳞伤的阿尔维斯静谷伊佐夫奥胁雅晴福田贵之まきだかずあき48怒りのドロシー!砂漠の塔愤怒的桃乐丝！沙漠之塔高桥奈津子大关雅幸曾我笃史49ゾンネンズ!狙われた修练の门!!黑星帮！被侵犯的修炼之门！！武上纯希向中野义雄近藤优次50アルヴィス×ナナシ!禁断のラビリンス!!阿尔维斯X那那西！禁止进入的迷宫！！植田浩二奥田诚治德本善信はっとりますみ51ドロシー×スノウ!诱惑のルージュ!!桃乐丝X白雪！魅惑唇膏！！神户一彦山口美浩氏家嘉宏野道佳代52届け!希望のシックスセンス!!传送吧！希望的第六感！！武上纯希井草かほる小野田雄亮岛村惠美子53ファントムを倒す打倒魅影静谷伊佐夫川口敬一郎甲藤元54アランのサブイボ起鸡皮疙瘩的艾伦高桥奈津子川口敬一郎大关雅幸曾我笃史55アルヴィスが许せない阿尔维斯不能原谅植田浩二山口美浩近藤优次56ドロシーが食べられた桃乐丝被吃掉了静谷伊佐夫阿久たすく佐野英敏阿部宗孝57スノウが笑った白雪笑了高桥奈津子篠崎康行高木信一郎58イアンが怒る伊安愤怒了植田浩二小野田雄亮岛村惠美子59ギンタ东京へ银太去东京武上纯希川口敬一郎まきだかずあき60ナナシの暴走失控的那那西川口敬一郎大关雅幸曾我笃史61深窓のドロシー深宅中的桃乐丝高桥奈津子山口美浩近藤优次62アランの名探侦艾伦的名侦探静谷伊佐夫武上纯希阿久たすく阿部宗孝63アルヴィスと少女阿尔维斯和少女植田浩二みくりや恭辅佐藤道雄雨宫英雄64小雪の仮面小雪的假面具武上纯希小野田雄亮岛村惠美子65不思议の国のリリス不可思议之国的莉莉丝川口敬一郎まきだかずあき66レギンレイヴ姫の秘密雷琴列城公主的秘密猪爪慎一佐野隆史大关雅幸曾我笃史67ロコと呪いの新ARM洛可与新的诅咒ARM山口美浩近藤优次68ラストバトル始まるッ最终决战开始濑藤健嗣阿部宗孝69ジャックと炎のガーディアン杰克与炎之守护者濑藤健嗣みくりや恭辅保田康治70再戦アルヴィス対ロラン再战阿尔维斯VS罗兰高桥奈津子川口敬一郎小野田雄亮岛村惠美子71永远の刹那永远的刹那川口敬一郎まきだかずあき72悲しみの花嫁(キメラ)悲伤的新娘川口敬一郎大関雅幸小林一三73アランの古伤(トラウマ)艾伦的旧伤静谷伊佐夫大关雅幸山口美浩近藤优次74さらば旧友(ハロウィン)别了老友朝日燃阿部宗孝75ルベリアの誓い鲁贝利亚的誓言植田浩二佐野隆史みくりや恭辅保田康治76真红の爪(ガーネットクロウ)真红之爪小野田雄亮岛村惠美子77ギンタ対ファントム银太VS魅影武上纯希川口敬一郎まきだかずあき78最凶猫ガーディアン最强猫咪守护者川口敬一郎浅见松雄小林一三79决着ッ决战山口美浩近藤优次80かわいい来客可爱来客高桥奈津子濑藤健嗣朝日燃阿部宗孝81バッボ割れる巴波碎裂植田浩二佐野隆史みくりや恭辅保田康治82复活の咆哮复活的咆哮小野田雄亮岛村惠美子83イアンと花嫁伊安和新娘猪爪慎一川口敬一郎小丸敏之84スノウ夺还夺回公主植田浩二大关雅幸小林一三85爱の岚ゼピュロスブルーム爱之风暴西风的扫帚猪爪慎一川口敬一郎山口美浩近藤优次86时间の轮舞(ロンド)时间轮舞武上纯希阿久たすく阿部宗孝87城塞都市パルトガイン要塞都市塔鲁特盖猪爪慎一东海林真一みくりや恭辅佐藤道雄88ファントムの梦魅影的梦想高桥奈津子川口敬一郎小野田雄亮服部宪知89覚醒のゾンビタトゥ觉醒的僵尸刺青植田浩二高山功名仓智史90忘却のクラヴィーア忘却的葛拉维亚武上纯希高柳哲司大关雅幸小林一三91アルヴィスよ瞑れ阿尔维斯安息吧猪爪慎一川口敬一郎山口美浩近藤优次92ミスティキャッスル密西缇城堡武上纯希阿久たすく阿部宗孝93冥界のアナリーゼ冥界的风暴植田浩二山崎たかし桥口洋介藤崎贤二94蔷薇は散りてなお染まり蔷薇未被染红却已凋谢高桥奈津子川口敬一郎小野田雄亮服部宪知95スノウの真実白雪的真相猪爪慎一小高义规高山功名仓智史96伪りの平和虚伪的和平武上纯希佐野隆史大关雅幸小林一三97炎に散り水に眠る在火焰中散去在水中长眠猪爪慎一山崎たかし山口美浩近藤优次98さらば心优しきチェス永别了善良的的CHESS兵队植田浩二猪爪慎一濑藤健嗣藤崎贤二99アルヴィスの光阿尔维斯之光猪爪慎一佐野隆史小野田雄亮服部宪知100哀の岚ゼピュロスブルーム哀伤的风暴西风的扫帚高桥奈津子川口敬一郎高山功名仓智史101ギンタ対ダンナ银太VS主人武上纯希大关雅幸小林一三102ワクワクは止まらない最终回兴奋不已川口敬一郎近藤优次参考资料[4]动画音乐播报编辑片头曲序号集数曲名演唱作词作曲编曲OP11~26君の思い描いた梦集メルHEAVEN（汇集你所思所想之梦的天堂）GARNETCROWAZUKI七中村由利古井弘人OP227~51晴れ时计（晴朗的指示钟）OP352~77梦・花火（梦・烟花）OP478~102风とRAINBOW（风与彩虹）片尾曲序号集数曲名演唱作词作曲编曲ED11~13Ijustwannaholdyoutight（我只想抱紧你）小松未步小松未步小松未步小林哲ED214~26不机嫌になる私（不要追问我）岩田小百合小松未步小松未步MissTyED327~39毎日アドベンチャー（每日冒险）Sparkling☆PointSparkling☆Point三好诚大贺好修ED440~51桜色（樱色）竹井诗织里AZUKI七桂花小林哲ED552~64MIRACLE（奇迹）爱内里菜爱内里菜大野爱果叶山武ED665~77今宵エデンの片隅で（今宵伊甸园的一角）GARNETCROWAZUKI七中村由利古井弘人ED778~90もう心摇れたりしないで（不要再让内心动摇了）北原爱子北原爱子北原爱子古井弘人ED891~101この手を伸ばせば（若是伸出这双手）GARNETCROWAZUKI七中村由利古井弘人注：第102集（最终话）片尾曲采用OP1《君の思い描いた梦集メルHEAVEN》。参考资料[5]关联游戏播报编辑标题游戏平台发行日期MARHEAVENKNOCKIN'ONHEAVEN'SDOOR（打开天堂之门）GBA2005年6月30日MARHEAVENÄRMFIGHTDREAMPS22005年11月3日MARHEAVEN卡尔迪亚的恶魔NDS2006年3月30日MARHEAVEN忘却的古拉维亚2006年9月7日参考资料[6]定点数：基本简介播报编辑1.定点数表示法(fixed-point)所谓定点格式，即约定机器中所有数据的小数点位置是固定不变的。在计算机中通常采用两种简单的约定：将小数点的位置固定在数据的最高位之前，或者是固定在最低位之后。一般常称前者为定点小数，后者为定点整数。定点小数是纯小数，约定的小数点位置在符号位之后、有效数值部分最高位之前。若数据x的形式为x=x0.x1x2…xn(其中x0为符号位，x1～xn是数值的有效部分，也称为尾数，x1为最高有效位)，则在计算机中的表示形式为：一般说来，如果最末位xn=1，前面各位都为0，则数的绝对值最小，即|x|min=2^(-n)。如果各位均为1，则数的绝对值最大，即|x|max=1-2^(-n)。所以定点小数的表示范围是：2^(-n)≤|x|≤1-2^(-n)表示方法播报编辑任何一个定点小数都可以被写成：N=NS.N-1N-2…N-M如果在计算机中用m+1个二进制位表示上述小数，则可以用最高(最左)一个二进制位表示符号(如用0表示正号，则1就表示负号)，而用后面的m个二进制位表示该小数的数值。小数点不用明确表示出来，因为它总是固定在符号位与最高数值位之间。定点小数的取值范围很小,对用m+1个二进制位的小数来说,其值的范围为：|N|≤1-2^(-m)，即小于1的纯小数。这对用户算题是十分不方便的，因为在算题前，必须把要用的数，通过合适的"比例因子"化成绝对值小于1的小数，并保证运算的中间和最终结果的绝对值也都小于1，在输出真正结果时，还要把计算的结果按相应比例加以扩大。定点小数表示法，主要用在早期的计算机中，它最节省硬件。随着计算机硬件成本的大幅度降低，现代的通用计算机都被设计成能处理与计算多种类型数值的计算机。我们将主要通过定点小数讨论数值数据的不同编码方案，而且，定点小数也被用来表示浮点数的尾数部分。浮点数：简介播报编辑浮点计算浮点计算是指浮点数参与的运算，这种运算通常伴随着因为无法精确表示而进行的近似或舍入。一个浮点数a由两个数m和e来表示：a=m×b^e。在任意一个这样的系统中，我们选择一个基数b（记数系统的基）和精度p（即使用多少位来存储）。m（即尾数）是形如±d.ddd...ddd的p位数（每一位是一个介于0到b-1之间的整数，包括0和b-1)。如果m的第一位是非0整数,m称作规格化的。有一些描述使用一个单独的符号位(s代表+或者-）来表示正负，这样m必须是正的。e是指数。结构由此可以看出，在计算机中表示一个浮点数，其结构如下：尾数部分（定点小数）阶码部分（定点整数）阶符±阶码e数符±尾数m这种设计可以在某个固定长度的存储空间内表示定点数无法表示的更大范围的数。浮点加法减法运算设有两个浮点数x和y,它们分别为x=Mx*2^Exy=My*2^Ey其中Ex和Ey分别为数x和y的阶码,Mx和My为数x和y的尾数。两浮点数进行加法和减法的运算规则是设Ex小于等于Ey，则x±y=(Mx*2^(Ex－Ey)±My)*2^Ey,完成浮点加减运算的操作过程大体分为四步：1.0操作数的检查；2.比较阶码大小并完成对阶；3.尾数进行加或减运算；4.结果规格化并进行舍入处理。⑴0操作数检查浮点加减运算过程比定点运算过程复杂。如果判知两个操作数x或y中有一个数为0,即可得知运算结果而没有必要再进行后续的一系列操作以节省运算时间。0操作数检查步骤则用来完成这一功能。⑵比较阶码大小并完成对阶两浮点数进行加减，首先要看两数的阶码是否相同，即小数点位置是否对齐。若二数阶码相同，表示小数点是对齐的，就可以进行尾数的加减运算。反之，若二数阶码不同，表示小数点位置没有对齐，此时必须使二数阶码相同，这个过程叫作对阶。要对阶，首先应求出两数阶码Ex和Ey之差，即△E=Ex－Ey若△E=0,表示两数阶码相等，即Ex=Ey；若△E>0,表示Ex>Ey；若△E<0,表示Ex<Ey。当Ex≠Ey时，要通过尾数的移动以改变Ex或Ey,使之相等。原则上，既可以通过Mx移位以改变Ex来达到Ex=Ey,也可以通过My移位以改变Ey来实现Ex=Ey。但是，由于浮点表示的数多是规格化的，尾数左移会引起最高有效位的丢失，造成很大误差。尾数右移虽引起最低有效位的丢失，但造成误差较小。因此，对阶操作规定使尾数右移，尾数右移后阶码作相应增加，其数值保持不变。显然，一个增加后的阶码与另一个阶码相等，增加的阶码的一定是小阶。因此在对阶时，总是使小阶向大阶看齐，即小阶的尾数向右移位（⑶尾数求和运算对阶结束后，即可进行尾数的求和运算。不论加法运算还是减法运算，都按加法进行操作，其方法与定点加减法运算完全一样。⑷结果规格化在浮点加减运算时，尾数求和的结果也可以得到01.ф…ф或10.ф…ф，即两符号位不等，这在定点加减法运算中称为溢出，是不允许的。但在浮点运算中，它表明尾数求和结果的绝对值大于1,向左破坏了规格化。此时将运算结果右移以实现规格化表示，称为向右规格化。规则是：尾数右移1位，阶码加1。当尾数不是1.M时需向左规格化。⑸舍入处理在对阶或向右规格化时，尾数要向右移位，这样，被右移的尾数的低位部分会被丢掉，从而造成一定误差，因此要进行舍入处理。简单的舍入方法有两种：一种是"0舍1入"法，即如果右移时被丢掉数位的最高位为0则舍去，为1则将尾数的末位加"1"。另一种是"恒置一"法，即只要数位被移掉，就在尾数的末尾恒置"1"。在IEEE754标准中，舍入处理提供了四种可选方法：就近舍入其实质就是通常所说的"四舍五入"。例如，尾数超出规定的23位的多余位数字是10010,多余位的值超过规定的最低有效位值的一半，故最低有效位应增1。若多余的5位是01111,则简单的截尾即可。对多余的5位10000这种特殊情况：若最低有效位现为0,则截尾；若最低有效位现为1,则向上进一位使其变为0。朝0舍入即朝数轴原点方向舍入，就是简单的截尾。无论尾数是正数还是负数，截尾都使取值的绝对值比原值的绝对值小。这种方法容易导致误差积累。朝+∞舍入对正数来说，只要多余位不全为0则向最低有效位进1；对负数来说则是简单的截尾。朝－∞舍入处理方法正好与朝+∞舍入情况相反。对正数来说,只要多余位不全为0则简单截尾；对负数来说，向最低有效位进1。⑹溢出处理浮点数的溢出是以其阶码溢出表现出来的。在加\减运算过程中要检查是否产生了溢出：若阶码正常，加（减）运算正常结束；若阶码溢出，则要进行相应处理。另外对尾数的溢出也需要处理。阶码上溢超过了阶码可能表示的最大值的正指数值，一般将其认为是+∞和－∞。阶码下溢超过了阶码可能表示的最小值的负指数值，一般将其认为是0。尾数上溢两个同符号尾数相加产生了最高位向上的进位，将尾数右移，阶码增1来重新对齐。尾数下溢在将尾数右移时，尾数的最低有效位从尾数域右端流出，要进行舍入处理。实例播报编辑题目例如，一个指数范围为±4的4位十进制浮点数可以用来表示43210,4.321或0.0004321,但是没有足够的精度来表示432.123和43212.3（必须近似为432.1和43210)。当然，实际使用的位数通常远大于4。特别数值此外，浮点数表示法通常还包括一些特别的数值：+∞和−∞（正负无穷大）以及NaN（'NotaNumber'）。无穷大用于数太大而无法表示的时候,NaN则指示非法操作或者无法定义的结果。二进制表示众所周知，计算机中的所有数据都是以二进制表示的，浮点数也不例外。然而浮点数的二进制表示法却不像定点数那么简单了。浮点数概念先澄清一个概念，浮点数并不一定等于小数，定点数也并不一定就是整数。所谓浮点数就是小数点在逻辑上是不固定的，而定点数只能表示小数点固定的数值，具用浮点数或定点数表示某哪一种数要看用户赋予了这个数的意义是什么。C++中的浮点数有6种，分别是：float：单精度,32位unsignedfloat：单精度无符号,32位double：双精度,64位longdouble：高双精度,80位下面仅以float（带符号，单精度,32位）类型的浮点数说明C++中的浮点数是如何在内存中表示的。先讲一下基础知识，纯小数的二进制表示。纯小数要想用二进制表示，必须先进行规格化，即化为1.xxxxx*(2^n)的形式（“^”代表乘方,2^n表示2的n次方）。对于一个纯小数D,求n的公式如下：n=1+log2(D);//纯小数求得的n必为负数再用D/(2^n)就可以得到规格化后的小数了。接下来就是十进制到二进制的转化问题，为了更好的理解，先来看一下10进制的纯小数是怎么表示的，假设有纯小数D,它小数点后的每一位数字按顺序形成一个数列：{k1,k2,k3,...,kn}那么D又可以这样表示：D=k1/(10^1)+k2/(10^2)+k3/(10^3)+...+kn/(10^n)推广到二进制中，纯小数的表示法即为：D=b1/(2^1)+b2/(2^2)+b3/(2^3)+...+bn/(2^n)现在问题就是怎样求得b1,b2,b3,……,bn。算法描述起来比较复杂，还是用数字来说话吧。声明一下,1/(2^n）这个数比较特殊，我称之为位阶值。例二例如0.456,第1位,0.456小于位阶值0.5故为0；第2位,0.456大于位阶值0.25,该位为1,并将0.456减去0.25得0.206进下一位；第3位,0.206大于位阶值0.125,该位为1,并将0.206减去0.125得0.081进下一位；第4位,0.081大于0.0625,为1,并将0.081减去0.0625得0.0185进下一位；第5位0.0185小于0.03125……最后把计算得到的足够多的1和0按位顺序组合起来，就得到了一个比较精确的用二进制表示的纯小数了，同时精度问题也就由此产生，许多数都是无法在有限的n内完全精确的表示出来的，我们只能利用更大的n值来更精确的表示这个数，这就是为什么在许多领域，程序员都更喜欢用double而不是float。float的内存结构，我用一个带位域的结构体描述如下：structMYFLOAT{boolbSign:1;//符号，表示正负,1位charcExponent:8;//指数,8位unsignedlongulMantissa:32;//尾数,32位};符号就不用多说了,1表示负,0表示正指数是以2为底的，范围是-128到127,实际数据中的指数是原始指数加上127得到的，如果超过了127,则从-128开始计，其行为和X86架构的CPU处理加减法的溢出是一样的。比如：127+2=-127；-127-2=127尾数都省去了第1位的1,所以在还原时要先在第一位加上1。它可能包含整数和纯小数两部分，也可能只包含其中一部分，视数字大小而定。对于带有整数部分的浮点数，其整数的表示法有两种，当整数大于十进制的16777215时使用的是科学计数法，如果小于或等于则直接采用一般的二进制表示法。科学计数法和小数的表示法是一样的。小数部分则是直接使用科学计数法，但形式不是X*(10^n），而是X*（0000000000000000000000000000000符号位指数位尾数位--------------------------------------------------------------------------------例三判断两个浮点数是否相等。在这个例子中我们以C++代码来判别两个浮点数是否相等。由于浮点数在存储中无法精确表示，所以fp1==fp2无法准确的判断float型变量fp1与fp2是否相等。应该使用（fp1-fl2）<0.0000001来进行判断。示例：boolequal(floatfp1,floatfp2){if(abs(fp1-fp2)<0.00000001)returntrue;elsereturnfalse;}--------------------------------------------------------------------------------导数字分布播报编辑简介作者：concreteHAM什么是浮点数，不用我多说，这里我们要讨论的是规格化的任意进制浮点数的前导数字的概率分布。在《计算机程序设计艺术》第二卷中做了非常深入的讨论，这里我从中精炼出要点。实例例如：浮点数2.345E67这是一个十进制规格化浮点数，前导数字就是2。就只有一个“随机”的浮点数而言，讨论其分布式没有意义的，我们要讨论的是充分多个“随机”数进行的一系列运算后产生的浮点结果的前导数字分布。假设现在有一巨大的浮点数集，依此对数集中每个浮点数都乘以2,其中有一个十进制浮点数F,它的前导数字是1,那么它底数可能的值范围就是1.000…～1.999…，乘以一个数字2,那么它的底数就变成2.000…～3.999…，很明显乘以2以前前导数字是1的浮点个数与现在前导数字是2、3的浮点个数相同。以此我们接下来分析。对于一个b进制的浮点数，它的前导数字x范围就是0<x<b,设f(x)是上述数集的前导数字的概率密度函数（注：是密度函数），那么它在前导数字u和v之间(0<u<v<b)的概率就是：∫[u,v]f(x)dx⑴由前面所述的，对于一个充分小增量Δx,f(x)必须满足这样一个公式：f⑴Δx=x*f(x)Δx⑵因为：f⑴Δx是f⑴微分段内的概率，根据前面所述,f⑴Δx概率等于f(1*x)*(x*Δx)很明显：f(x)=f⑴/x⑶两边在[1,b]之间进行积分，等号左边必定为1,右边等于f⑴ln(b)：1=f⑴ln(b)⑷得：f⑴=1/ln(b)带入⑶中：f(x)=1/(x*ln(b))那么利用⑴式得：∫[u,v]1/(x*ln(b))dx=ln(v/u)/ln(b)⑸这就是求前导数字的概率分布函数。例如b=10进制时，前导数字为1的概率就是：=ln((1+1)/1)/ln⑽≈0.301前导数字为9的概率就是：=ln((9+1)/9)/ln⑽≈0.0458以下是一个测试程序（Mathematica软件）：T[n_,b_]:=Block[{res={},ran,i,a},For[i=1,i<b,i++;res=Append[res,0]];For[i=0,i<n,i++;ran=Random[]*Random[]*Random[];充分打乱浮点数ran=Log[b,ran];a=Floor[b^(ran-Floor[ran])];取出前导数字res[[a]]++对前导数字个数统计];Return[res]]执行T[100000,10],以10进制测试100000个浮点数，得到一个分布：{30149,18821,13317,9674,7688,6256,5306,4655,4134}和理论值相当接近。逻辑运算：简介播报编辑布尔运算是数字符号化的逻辑推演法，包括联合、相交、相减。在图形处理操作中引用了这种逻辑运算方法以使简单的基本图形组合产生新的形体，并由二维布尔运算发展到三维图形的布尔运算。由于布尔在符号逻辑运算中的特殊贡献，很多计算机语言中将逻辑运算称为布尔运算，将其结果称为布尔值。数学布尔运算播报编辑产生逻辑运算又称布尔运算布尔用数学方法研究逻辑问题，成功地建立了逻辑演算。他用等式表示判断，把推理看作等式的变换。这种变换的有效性不依赖人们对符号的解释，只依赖于符号的组合规律。这一逻辑理论人们常称它为布尔代数。20世纪30年代，逻辑代数在电路系统上获得应用，随后，由于电子技术与计算机的发展，出现各种复杂的大系统，它们的变换规律也遵守布尔所揭示的规律。表示方法"∨"表示"或""∧"表示"与"."┐"表示"非"."="表示"等价".1和0表示"真"和"假"(还有一种表示,"+"表示"或","·"表示"与"）计算机编程布尔运算播报编辑逻辑运算(logicaloperators)通常用来测试真假值。最常见到的逻辑运算就是循环的处理，用来判断是否该离开循环或继续执行循环内的指令。各种编程语言中的逻辑运算符作用CPascal等于===不等于!=<>小于<<大于>>小于等于<=<=大于等于>=>=与&&and或||or非!not异或^xor运算规则组合\结果\运算符.....And.......Or.........Xor0......0.......................0..........0............01......0.......................0..........1............10......1.......................0..........1............11......1.......................1..........1............0简单的说And:同为真时为真Or:同为假时为假Xor:相同为假三维图形布尔运算播报编辑作用Boolean（布尔运算）通过对两个以上的物体进行并集、差集、交集的运算，从而得到新的物体形态。系统提供了4种布尔运算方式：Union（并集）、Intersection（交集）和Subtraction（差集，包括A-B和B-A两种）[1]。效果物体在进行布尔运算后随时可以对两个运算对象进行修改操作，布尔运算的方式、效果也可以编辑修改，布尔运算修改的过程可以记录为动画，表现神奇的切割效果。组成部分布尔运算练习模型:骰子Boolean（布尔运算）的参数面板可分成三部分。PickBoolean（拾取布尔运算对象）卷展栏该卷展栏用来拾取运算对象B。在布尔运算中，两个原始对象被称为运算对象，一个叫运算对象A，另一个叫运算对象B。在建立布尔运算前，首先要在视图中选择一个原始对象，这时Boolean按钮才可以使用。进入布尔运算命令面板后，单击PickOperandB命令按钮来选择第二个运算对象。·PickOperandB（拾取运算对象B）：单击该按钮，在场景中选择另一个物体完成布尔合成。其下的4个选项用来控制运算对象B的属性，它们要在拾取运算对象B之前确定。·Reference（参考）：将原始对象的参考复制品作为运算对象B，以后改变原始对象，也会同时改变布尔物体中的运算对象B，但改变运算对象B，不会改变原始对象。·Copy（复制）：将原始对象复制一个作为运算对象B，而不改变原始对象。当原始对象还要作其他之用时选用该方式。·Move（移动）：将原始对象直接作为运算对象B，它本身将不再存在。当原始对象无其他用途时选该用方式。该方式为默认方式。·Instance（关联）：将原始对象的关联复制品作为运算对象B，以后对两者中之一进行修改时都会同时影响另一个。Parameters（参数）卷展栏该卷展栏参数可分为三个区域。Operands（操作对象）选项组该组参数用来显示所有的运算对象的名称，并可对它们作相关的操作。OperandsList（操作对象列表）：该列表框中列出所有的运算对象，供编辑操作时选择使用。Name（名称）：显示列表框中选中的操作对象的名称。可对其进行编辑。ExtractOperand（提取运算对象）：它将当前指定的运算对象重新提取到场景中，作为一个新的可用对象，包括Instance（关联）和Copy（拷贝）两种属性。这样进入了布尔运算的物体仍可以被释放到场景中。只有从其上方的列表框中选择一个操作对象后才能激活该按钮。注意：该按钮只有在修改面板中才可用。当创建面板处于激活状态时，不能从布尔物体中提取出操作对象。联想到前面所述的变形对象，在进入了变形预备物体中后，却无法再返回到场景中。不过对此还有一个可行的方法，就是利用Snapshot（快照）工具，在变形的关键帧快照克隆出一个新的造型。Operation（运算方式）选项组该组参数提供了4种运算方式可供选择。·Union（并集）：用来将两个造型合并，相交的部分将被删除，运算完成后两个物体将成为一个物体。·Intersection（交集）：用来将两个造型相交的部分保留下来，删除不相交的部分。·Subtraction（A-B）（A-B部分）：在A物体中减去与B物体重合的部分。·Subtraction（B-A）（B-A部分）：在B物体中减去与A物体重合的部分。·Cut（切除）：用B物体切除A物体，但不在A物体上添加B物体的任何部分。当Cut（切除）单选按钮被选中时，它将激活其下方的4个单选按钮让用户选择不同的切除类型。·Refine（细化）：在A物体上沿着B物体与A物体相交的面增加顶点和边数以细化A物体的表面。也就是说，根据B物体的外形将A物体的表面重新细分。·Split（劈裂）：其工作方法与Refine（细化）类似。只不过在B物体切割A物体部分的边缘多加了一排顶点。利用这种方法可以根据其他物体的外形将一个物体分成两部分。·RemoveInside（移除内部）：删除A物体中所有在B物体内部的片段面。其工作方法和Subtraction（A-B）（A-B部分）类似，只是同时也切除了B物体的表面。·RemoveOutside（移除外部）：删除A物体中所有在B物体外部的片段面。其工作方法和Intersection（交集）类似，只是同时也切除了B物体的表面。Display（显示）/Update（更新）卷展栏该卷展栏参数用来控制是否在视图中显示运算结果以及每次修改后何时进行重新计算，更新视图。Display（显示）选项组该组参数用来决定是否在视图中显示布尔运算的结果，包含三个选项。·Result（结果）：显示每项布尔运算的计算结果。·Operands（操作对象）：只显示布尔合成物体而不显示运算结果。这样可以加快显示速度。·Result+HiddenOps（结果+隐藏物体）：在实体着色的实体内以线框方式显示出隐藏的运算对象，主要用于动态布尔运算的编辑操作。Update（更新）选项组该组参数用来决定何时进行重新计算并显示布尔效果。·Always（总是）：每一次操作后都立即显示布尔结果。·WhenRendering（渲染时）：只有在最后渲染时才重新计算更新效果。·Manually（手动）：选择此选项，下面的Update（更新）按钮可用，它提供手动的更新控制。·Update（更新）：需要观看更新效果时，按下此按钮，系统进行重新计算。CISC：产品介绍播报编辑计算机处理器包含有实现各种功能的指令或微指令，指令集越丰富，为微处理器编写程序就越容易，但是丰富的微指令集会影响其性能。复杂指令集计算机（CISC）体系结构的设计策略是使用大量的指令，包括复杂指令。与其他设计相比，在CISC中进行程序设计要比在其他设计中容易，因为每一项简单或复杂的任务都有一条对应的指令。程序设计者不需要写一大堆指令去完成一项复杂的任务。但指令集的复杂性使得CPU和控制单元的电路非常复杂。[1]CISC包括一个丰富的微指令集，这些微指令简化了在处理器上运行的程序的创建。指令由汇编语言所组成，把一些原来由软件实现的常用的功能改用硬件的指令系统实现，编程者的工作因而减少许多，在每个指令期同时处理一些低阶的操作或运算，以提高计算机的执行速度，这种系统就被称为复杂指令系统。在CISC指令集的各种指令中，其使用频率却相差悬殊，大约有20%的指令会被反复使用，占整个程序代码的80%。而余下的80%的指令却不经常使用，在程序设计中只占20%。与RISC对比播报编辑[1]RISC(精简指令集计算机)设计方案，如它的名字所蕴涵的那样，有一个简化的指令集，该指令集提高处理器的效率但是需要有更复杂的外部程序。RISC结构优先选取使用频最高的简单指令，避免复杂指令；将指令长度固定，指令格式和寻地方式种类减少；以控制逻辑为主，不用或少用微码控制等措施来提高运算速度。RISC设计方案是根据JohnCocke在IBM所做的工作形成的。JohnCocke发现大约20%的计算机指令完成大约80%的工作。因此，基于RISC的系统通常比CISC系统速度快。它的80/20规则促进了RISC体系结构的发展。当然，和CISC架构相比较，尽管RISC架构有上述的优点，但不能认为RISC架构就可以取代CISC架构，事实上，RISC和CISC各有优势，而且界限并不那么明显。现代的CPU往往采用CISC的外围，内部加入了RISC的特性，如超长指令集CPU就是融合了RISC和CISC的优势，成为未来的CPU发展方向之一。RISC：释义RNA诱导沉默复合体（RNA-inducedsilencingcomplex，RISC）：一种由siRNA与Argonaute蛋白和Dicer酶复合形成的复合物。在RNAi中，利用siRNA的反义链切割靶mRNA，达到基因沉默。[2]RISC由Dicer酶、Argonaute蛋白、siRNA等多种生物大分子装配而成。RISC的组装是RNAi和miRNA途径的中心环节，包括smallRNA的形成，smallRNA进入RISC装载复合体（RISCloadingcomplex，RLC）并进而转变为有沉默目标mRNA活性的RISC[1]。研究表明，RISC中的Dicer具有RNaseIII结构域，在RNAi的起始阶段负责催化siRNA的产生，在RISC装配过程中起稳定RISC中间体结构和功能的作用；Argonaute蛋白是RISC中的核心蛋白，有PAZ和PIWI两个主要的结构域，前者为siRNA的传递提供结合位点,后者是RISC中的酶切割活性中心；siRNA是RISC完成特异性切割作用的向导，在成熟的RISC中虽然只包含siRNA的一条链，但siRNA在RISC形成过程中的双链结构是保证RNAi效应的决定因素[3]。计算机组成：概念播报编辑计算机组成的任务是在指令集系统结构确定分配给硬件系统的功能和概念结构之后，研究各组成部分的内部构造和相互联系，以实现机器指令集的各种功能和特性。这种联系包括各功能部件的内部和相互作用。计算机组成要解决的问题是在所希望达到的性能和价格下，怎样最佳，最合理地把各个设备和部件组成成计算机，已实现所确定的ISA。计算机组成设计要确定的方面应包括：(1)数据通路宽度：数据总线上一次并行传送的信息位数。(2)专用部件的设置：是否设置乘除法、浮点运算、字符处理、地址运算等专用部件，设置的数量与机器要达到的速度、价格及专用部件的使用频度等有关。(3)各种操作对部件的共享程度：分时共享使用程度高，虽限制了速度，但价格便宜。设置部件多降低共享程度，因操作并行度提高，可提高速度，但价格也会提高。(4)功能部件的并行度：是用顺序串行，还是用重叠、流水或分布式控制和处理。(5)控制机构的组成方式：用硬联还是微程序控制，是单机处理还是多机或功能分布处理。(6)缓冲和排队技术：部件间如何设置及设置多大容量的缓冲器来协调它们的速度差；用随机、先进先出、先进后出、优先级，还是循环方式来安排事件处理的顺序。(7)预估、预判技术：为优化性能用什么原则预测未来行为。(8)可靠性技术：用什么冗余和容错技术来提高可靠性。硬件组成部分播报编辑主要分为五个部分：1.控制器(controlunit)：是整个计算机的中枢神经，其功能是对程序规定的控制信息进行解释，根据其要求进行控制，调度程序、数据、地址，协调计算机各部分工作及内存与外设的访问等。2.运算器(arithmeticlogicunit)：运算器的功能是对数据进行各种算术运算和逻辑运算，即对数据进行加工处理。3.存储器(memory)：存储器的功能是存储程序、数据和各种信号、命令等信息，并在需要时提供这些信息。4.输入(input)：输入设备是计算机的重要组成部分，输入设备与输出设备合称为外部设备，简称外设，输入设备的作用是将程序、原始数据、文字、字符、控制命令或现场采集的数据等信息输入到计算机。常见的输入设备有键盘、鼠标器、光电输入机、磁带机、磁盘机、光盘机等。5.输出(output)：输出设备与输入设备同样是计算机的重要组成部分，它把计算机的中间结果或最后结果、机内的各种数据符号及文字或各种控制信号等信息输出出来。微机常用的输出设备有显示终端CRT、打印机、激光印字机、绘图仪及磁带、光盘机等。CPU=控制器+运算器主板=I/O总线，输入输出系统存储器=内存+硬盘I/O设备：键盘、鼠标、扫描仪、显示器、数字化仪，读卡机、纸带等。键盘数字化仪扫描仪鼠标软件播报编辑软件概述计算机软件(computersoftware)是指计算机系统中的程序及其文档。程序是计算任务的处理对象和处理规则的描述；文档是为了便于了解程序所需的阐述性资料。程序必须装入机器内部才能工作，文档一般是给人看的，不一定装入机器。软件是用户与硬件之间的接口界面。用户主要是通过软件与计算机进行交流。软件是计算机系统设计的重要依据。为了方便用户，为了使计算机系统具有较高的总体效用，在设计计算机系统时，必须通盘考虑软件与硬件的结合，以及用户的要求和软件的要求。软件的正确含义应该是:(1)运行时，能够提供所要求功能和性能的指令或计算机程序集合。(2)程序能够满意地处理信息的数据结构。(3)描述程序功能需求以及程序如何操作和使用所要求的文档。软件具有与硬件不同的特点:(1)表现形式不同硬件有形，有色，有味，看得见，摸得着，闻得到。而软件无形，无色，无味，看不见，摸不着，闻不到。软件大多存在人们的脑袋里或纸面上，它的正确与否，是好是坏，一直要到程序在机器上运行才能知道。这就给设计、生产和管理带来许多困难。(2)生产方式不同软件是开发，是人的智力的高度发挥，不是传统意义上的硬件制造。尽管软件开发与硬件制造之间有许多共同点，但这两种活动是根本不同的。(3)要求不同硬件产品允许有误差，而软件产品却不允许有误差。(4)维护不同硬件是要用旧用坏的，在理论上，软件是不会用旧用坏的，但在实际上，软件也会变旧变坏。因为在软件的整个生存期中，一直处于改变维护状态。计算机软件分为系统软件和应用软件，如果把计算机比喻为一个人的话，那么硬件就表示人的身躯。而软件则表示人的思想、灵魂。一台没有安装任何软件的计算机称之为“裸机”。系统软件系统软件是指控制和协调计算机及外部设备,支持应用软件开发和运行的系统，是无需用户干预的各种程序的集合，主要功能是调度，监控和维护计算机系统；负责管理计算机系统中各种独立的硬件，使得它们可以协调工作。系统软件使得计算机使用者和其他软件将计算机当作一个整体而不需要顾及到底层每个硬件是如何工作的。（如Windows、Linux、DOS、Unix等操作系统都属于系统软件。）应用软件应用软件（applicationsoftware）是用户可以使用的各种程序设计语言，以及用各种程序设计语言编制的应用程序的集合，分为应用软件包和用户程序。应用软件包是利用计算机解决某类问题而设计的程序的集合，供多用户使用。计算机软件分为系统软件和应用软件两大类。应用软件是为满足用户不同领域、不同问题的应用需求而提供的那部分软件。它可以拓宽计算机系统的应用领域，放大硬件的功能。（如Word、Excel、QQ等都属于应用软件）I/O设备：功能介绍播报编辑输入/输出设备模型输入/输出（Input/Output,简称I/O），指的是一切操作、程序或设备与计算机之间发生的数据传输过程。输入/输出系统(Input/OutputSystem)，指控制计算机数据流动的体制，包括程序、硬件。输入/输出设备，就是指可以与计算机进行数据传输的硬件。最常见的I/O设备有打印机、硬盘、键盘和鼠标。从严格意义上来讲，它们中有一些只能算是输入设备（比如说键盘和鼠标）；有一些只是输出设备（如打印机）。所有储存器也可以算是输入/输出设备。如硬盘、软盘、光盘等。I/O设备分类播报编辑现代计算机系统中配置了大量的外围设备，即I/O设备。依据它们的工作方式的不同，通常进行如下分类：（1）字符设备（characterdevice），又叫做人机交互设备。用户通过这些设备实现与计算机系统的通信。它们大多是以字符为单位发送和接受数据的，数据通信的速度比较慢。例如，键盘和显示器为一体的字符终端、打印机、扫描仪、包括鼠标等，还有早期的卡片和纸带输入和输出机。含有显卡的图形显示器的速度相对较快，可以用来进行图像处理中的复杂图形的显示。（2）块设备（blockdevice），又叫外部存储器，用户通过这些设备实现程序和数据的长期保存。与字符设备相比，它们是以块为单位进行传输的，如磁盘、磁带和光盘等。块的常见尺寸为512~32768B之间。（3）网络通信设备。这类设备主要有网卡、调制解调器等，主要用于与远程设备的通信。这类设备的传输速度比字符设备高，但比外部存储器低。这种分类的方法并不完备，有些设备并没有包括。例如，时钟既不是按块访问，也不是按字符访问，它所做的是按照预先规定好的时间间隔产生中断。但是这种分类足以使操作系统构造出处理I/O设备的软件，使它们独立于具体的设备。I/O设备故障播报编辑计算机中的I/O设备故障[1]表现主要有以下三个方面：1.I/O设备就无法正常使用了，包括各类外接接口、笔记本的键盘打不出字、触控屏不灵等现象。2.电脑维修工具：主板诊断卡插在主板上进行跑码会显示FF代码、00代码、DD代码或无代码及反复跑C1~C5代码的现象。3.I/O设备短路等故障还会导致计算机连接外部设备的时候可能会受到静电的冲击或干扰以至于损坏其他电容、二极管等元器件。从而导致设备无法开机的严重后果。防范I/O设备故障：I/O设备设备属于精密的电子产品，使用过程中对环境要求严格，切莫在高温，潮湿的环境下使用。寻址方式：简介播报编辑在存储器中，操作数或指令字写入或读出的方式，有地址指定方式、相联存储方式和堆栈存取方式。几乎所有的计算机，在内存中都采用地址指定方式。当采用地址指定方式时，形成操作数或指令地址的方式称为寻址方式。寻址方式分为两类，即指令寻址方式和数据寻址方式，前者比较简单，后者比较复杂。值得注意的是，在传统方式设计的计算机中，内存中指令的寻址与数据的寻址是交替进行的。[2]寻址模式的数量播报编辑不同的计算机体系结构在硬件中提供的寻址模式数量上有很大差异。消除复杂寻址模式并仅使用一个或几个更简单的寻址模式有一些好处，即使它需要一些额外的指令，也许还需要一个额外的寄存器。如果只有一些简单的寻址模式，那么设计管流水线CPU将变得更为简单。大多数RISC架构只有大约五种简单的寻址模式，而DECCAX等CISC架构有十几种寻址模式，其中一些非常复杂。IBMSystem/360架构只有三种寻址模式，System/390又添加了一些。当只有少数寻址模式时，所需的特定寻址模式通常在指令代码中编码（例如IBMSystem/360和后继者，还有大多数RISC）。但是当存在许多寻址模式时，通常在指令中留出特定字段来指定寻址模式。DECVAX允许几乎所有指令有多个存储器操作数，因此保留每个操作数说明符的前几位以指示该特定操作数的寻址模式。保持寻址模式指定符位与操作码操作位分离产生正交指令集。即使在具有许多寻址模式的计算机上，实际程序的测量表明下面列出的简单寻址模式占所有寻址模式的约90％或更多。由于大多数此类测量基于编译器从高级语言生成的代码，因此这在某种程度上反映了所使用的编译器的局限性。指令寻址播报编辑指令的寻址方式有以下两种。顺序寻址方式由于指令地址在内存中按顺序安排，当执行一段程序时，通常是一条指令接一条指令地顺序进行。也就是说，从存储器取出第1条指令，然后执行这条指令；接着从存储器取出第2条指令，再执行第二条指令；接着再取出第3条指令。[2]这种程序顺序执行的过程，称为指令的顺序寻址方式。为此，必须使用程序计数器（又称指令计数器）PC来计数指令的顺序号，该顺序号就是指令在内存中的地址。跳跃寻址方式当程序转移执行的顺序时，指令的寻址就采取跳跃寻址方式。所谓跳跃，是指下条指令的地址码不是由程序计数器给出，而是由本条指令给出。注意，程序跳跃后，按新的指令地址开始顺序执行。因此，程序计数器的内容也必须相应改变，以便及时跟踪新的指令地址。采用指令跳跃寻址方式，可以实现程序转移或构成循环程序，从而能缩短程序长度，或将某些程序作为公共程序引用。指令系统中的各种条件转移或无条件转移指令，就是为了实现指令的跳跃寻址而设置的。[2]注意是否跳跃可能受到状态寄存器的操作数的控制，而跳跃到的地址分为绝对地址（由标记符直接得到）和相对地址（对于当前指令地址的偏移量），跳跃的结果是当前指令修改PC程序计数器的值，所以下一条指令仍是通过程序计数器PC给出。操作数寻址播报编辑形成操作数的有效地址的方法称为操作数的寻址方式。由于大型机、小型机、微型机和单片机结构不同，从而形成了各种不同的操作数寻址方式。下面介绍一些比较典型又常用的操作数寻址方式。[2]隐含寻址这种类型的指令，不是明显地给出操作数的地址。而是在指令中隐含着操作数的地址。例如，单地址的指令格式，就不明显地在地址字段中指出第2操作数的地址，而是规定累加寄存器AC作为第2操作数地址。指令格式明显指出的仅是第1操作数的地址D。因此，累加寄存器AC对单地址指令格式来说是隐含地址。[2]如：DAA；立即寻址指令的地址字段指出的不是操作数的地址，而是操作数本身，这种寻址方式称为立即寻址。立即寻址方式的特点是指令执行时间很短，因为它不需要访问内存取数，从而节省了访问内存的时间。[2]如：MOVAX,#5678H注意：立即数只能作为源操作数，不能作为目的操作数。直接寻址直接寻址是一种基本的寻址方法，其特点是：在指令格式的地址的字段中直接指出操作数在内存的地址。由于操作数的地址直接给出而不需要经过某种变换，所以称这种寻址方式为直接寻址方式。在指令中直接给出参与运算的操作数及运算结果所存放的主存地址，即在指令中直接给出有效地址[2]间接寻址间接寻址是相对直接寻址而言的，在间接寻址的情况下，指令地址字段中的形式地址不是操作数的真正地址，而是操作数地址的指示器，或者说此形式地址单元的内容才是操作数的有效地址。[2]寄存器寻址方式当操作数不放在内存中，而是放在CPU的通用寄存器中时，可采用寄存器寻址方式。显然，此时指令中给出的操作数地址不是内存的地址单元号，而是通用寄存器的编号（可以是8位也可以是16位（AX，BX，CX，DX））。指令结构中的RR型指令，就是采用寄存器寻址方式的例子。如：MOVDS，AX寄存器间接寻址方式与寄存器寻址方式的区别在于：指令格式中的寄存器内容不是操作数，而是操作数的地址，该地址指明的操作数在内存中。[2]相对寻址方式相对寻址是把程序计数器PC的内容加上指令格式中的形式地址D而形成操作数的有效地址。程序计数器的内容就是当前指令的地址。“相对”寻址，就是相对于当前的指令地址而言。采用相对寻址方式的好处是程序员无须用指令的绝对地址编程，因而所编程序可以放在内存的任何地方。[2]指令格式：MOVAX，[BX+1200H]操作数物理地址PA=(DS/SS)*16H+EAEA=(BX/BP/SI/DI)+(6/8)位偏移量Disp对于BX，SI，DI寄存器来说段寄存器默认为DS，对于BP来说，段寄存器默认为SS[3]基址寻址方式在基址寻址方式中将CPU中的基址寄存器的内容，加上变址寄存器的内容而形成操作数的有效地址。基址寻址的优点是可以扩大寻址能力，因为与形式地址相比，基址寄存器的位数可以设置得很长，从而可以在较大的存储空间中寻址。[2]变址寻址方式变址寻址方式与基址寻址方式计算有效地址的方法很相似，它把CPU中某个变址寄存器的内容与偏移量D相加来形成操作数有效地址。但使用变址寻址方式的目的不在于扩大寻址空间，而在于实现程序块的规律变化。为此，必须使变址寄存器的内容实现有规律的变化（如自增1、自减1、乘比例系数）而不改变指令本身，从而使有效地址按变址寄存器的内容实现有规律的变化。[2]块寻址方式块寻址方式经常用在输入输出指令中，以实现外存储器或外围设备同内存之间的数据块传送。块寻址方式在内存中还可用于数据块移动。[2]多核处理器：技术发展播报编辑256线程的CPU英特尔工程师们开发了多核芯片，使之满足“横向扩展”（而非“纵向扩充”）方法，从而提高性能。该架构实现了“分治法”战略。通过划分任务，线程应用能够充分利用多个执行内核，并可在特定的时间内执行更多任务。多核处理器是单枚芯片（也称为“硅核”），能够直接插入单一的处理器插槽中，但操作系统会利用所有相关的资源，将每个执行内核作为分立的逻辑处理器。通过在两个执行内核之间划分任务，多核处理器可在特定的时钟周期内执行更多任务。多核架构能够使软件更出色地运行，并创建一个促进未来的软件编写更趋完善的架构。尽管认真的软件厂商还在探索全新的软件并发处理模式，但是，随着向多核处理器的移植，现有软件无需被修改就可支持多核平台。操作系统专为充分利用多个处理器而设计，且无需修改就可运行。为了充分利用多核技术，应用开发人员需要在程序设计中融入更多思路，但设计流程与对称多处理(SMP)系统的设计流程相同，并且现有的单线程应用也将继续运行。得益于线程技术的应用在多核处理器上运行时将显示出卓越的性能可扩充性。此类软件包括多媒体应用（内容创建、编辑，以及本地和数据流回放）、工程和其他技术计算应用以及诸如应用服务器和数据库等中间层与后层服务器应用。多核技术能够使服务器并行处理任务，而在以前，这可能需要使用多个处理器，多核系统更易于扩充，并且能够在更纤巧的外形中融入更强大的处理性能，这种外形所用的功耗更低、计算功耗产生的热量更少。多核技术是处理器发展的必然。推动微处理器性能不断提高的因素主要有两个：半导体工艺技术的飞速进步和体系结构的不断发展。半导体工艺技术的每一次进步都为微处理器体系结构的研究提出了新的问题，开辟了新的领域；体系结构的进展又在半导体工艺技术发展的基础上进一步提高了微处理器的性能。这两个因素是相互影响，相互促进的。一般说来，工艺和电路技术的发展使得处理器性能提高约20倍，体系结构的发展使得处理器性能提高约4倍，编译技术的发展使得处理器性能提高约1.4倍。但是今天，这种规律性的东西却很难维持。多核的出现是技术发展和应用需求的必然产物。发展历程播报编辑1971年，英特尔推出的全球第一颗通用型微处理器4004，由2300个晶体管构成。当时，公司的联合创始人之一戈登摩尔(GordonMoore)，就提出后来被业界奉为信条的“摩尔定律”——每过18个月，芯片上可以集成的晶体管数目将增加一倍。在一块芯片上集成的晶体管数目越多，意味着运算速度即主频就更快。今天英特尔的奔腾(Pentium)四至尊版840处理器，晶体管数量已经增加至2.5亿个，相比当年的4004增加了10万倍。其主频也从最初的740kHz(每秒钟可进行74万次运算)，增长到3.9GHz(每秒钟运算39亿次)以上。当然，CPU主频的提高，或许在一定程度上也要归功于1975年进入这个领域的AMD公司的挑战。正是这样的“双雄会”，使得众多计算机用户有机会享受不断上演的“速度与激情”。一些仍不满足的发烧友甚至选择了自己超频，因为在玩很多游戏时，更快的速度可以带来额外的饕餮享受。但到了2005年，当主频接近4GHz时，英特尔和AMD发现，速度也会遇到自己的极限：那就是单纯的主频提升，已经无法明显提升系统整体性能。以英特尔发布的采用NetBurst架构的奔腾四CPU为例，它包括Willamette、Northwood和Prescott等三种采用不同核心的产品。利用冗长的运算流水线，即增加每个时钟周期同时执行的运算个数，就达到较高的主频。这三种处理器的最高频率，分别达到了2.0G、3.4G和3.8G。按照当时的预测，奔腾四在该架构下，最终可以把主频提高到10GHz。但由于流水线过长，使得单位频率效能低下，加上由于缓存的增加和漏电流控制不利造成功耗大幅度增加，3.6GHz奔腾四芯片在性能上反而还不如早些时推出的3.4GHz产品。所以，Prescott产品系列只达到3.8G，就戛然而止。英特尔上海公司一位工程师在接受记者采访时表示，Netburst微架构的好处在于方便提升频率，可以让产品的主频非常高。但性能提升并不明显，频率提高50%，性能提升可能微不足道。因为Netburst微架构的效率较低，CPU计算资源未被充分利用，就像开车时“边踩刹车边踩油门”。此外，随着功率增大，散热问题也越来越成为一个无法逾越的障碍。据测算，主频每增加1G，功耗将上升25瓦，而在芯片功耗超过150瓦后，现有的风冷散热系统将无法满足散热的需要。3.4GHz的奔腾四至尊版，晶体管达1.78亿个，最高功耗已达135瓦。实际上，在奔腾四推出后不久，就在批评家那里获得了“电炉”的美称。更有好事者用它来玩煎蛋的游戏。很显然，当晶体管数量增加导致功耗增长超过性能增长速度后，处理器的可靠性就会受到致命性的影响。就连戈登摩尔本人似乎也依稀看到了“主频为王”这条路的尽头——2005年4月，他曾公开表示，引领半导体市场接近40年的“摩尔定律”，在未来10年至20年内可能失效。多核心CPU解决方案(多核)的出现，似乎给人带来了新的希望。早在上世纪90年代末，就有众多业界人士呼吁用CMP(单芯片多处理器)技术来替代复杂性较高的单线程CPU。IBM、惠普、Sun等高端服务器厂商，更是相继推出了多核服务器CPU。不过，由于服务器价格高、应用面窄，并未引起大众广泛的注意。直到AMD抢先手推出64位处理器后，英特尔才想起利用“多核”这一武器进行“帝国反击战”。2005年4月，英特尔仓促推出简单封装双核的奔腾D和奔腾四至尊版840。AMD在之后也发布了双核皓龙(Opteron)和速龙(Athlon)64X2和处理器。但真正的“双核元年”，则被认为是2006年。这一年的7月23日，英特尔基于酷睿(Core)架构的处理器正式发布。2006年11月，又推出面向服务器、工作站和高端个人电脑的至强(Xeon)5300和酷睿双核和四核至尊版系列处理器。与上一代台式机处理器相比，酷睿2双核处理器在性能方面提高40%，功耗反而降低40%。作为回应，7月24日，AMD也宣布对旗下的双核Athlon64X2处理器进行大降价。由于功耗已成为用户在性能之外所考虑的首要因素，两大处理器巨头都在宣传多核处理器时，强调其“节能”效果。英特尔发布了功耗仅为50瓦的低电压版四核至强处理器。而AMD的“Barcelona”四核处理器的功耗没有超过95瓦。在英特尔高级副总裁帕特基辛格(PatGelsinger)看来，从单核到双核，再到多核的发展，证明了摩尔定律还是非常正确的，因为“从单核到双核，再到多核的发展，可能是摩尔定律问世以来，在芯片发展历史上速度最快的性能提升过程”。技术优势播报编辑从应用需求上去看，越来越多的用户在使用过程中都会涉及到多任务应用环境，日常应用中用到的非常典型的有两种应用模式。一种应用模式是一个程序采用了线程级并行编程，那么这个程序在运行时可以把并行的线程同时交付给两个核心分别处理，因而程序运行速度得到极大提高。这类程序有的是为多路工作站或服务器设计的专业程序，例如专业图像处理程序、非线视频编缉程序、动画制作程序或科学计算程序等。对于这类程序，两个物理核心和两颗处理器基本上是等价的，所以，这些程序往往可以不作任何改动就直接运行在双核电脑上。还有一些更常见的日常应用程序，例如Office、IE等，同样也是采用线程级并行编程，可以在运行时同时调用多个线程协同工作，所以在双核处理器上的运行速度也会得到较大提升。例如，打开IE浏览器上网。看似简单的一个操作，实际上浏览器进程会调用代码解析、Flash播放、多媒体播放、Java、脚本解析等一系列线程，这些线程可以并行地被双核处理器处理，因而运行速度大大加快（实际上IE浏览器的运行还涉及到许多进程级的交互通信，这里不再详述）。由此可见，对于已经采用并行编程的软件，不管是专业软件，还是日常应用软件，在多核处理器上的运行速度都会大大提高。日常应用中的另一种模式是同时运行多个程序。许多程序没有采用并行编程，例如一些文件压缩软件、部分游戏软件等等。对于这些单线程的程序，单独运行在多核处理器上与单独运行在同样参数的单核处理器上没有明显的差别。但是，由于日常使用的最最基本的程序——操作系统——是支持并行处理的，所以，当在多核处理器上同时运行多个单线程程序的时候，操作系统会把多个程序的指令分别发送给多个核心，从而使得同时完成多个程序的速度大大加快。另外，虽然单一的单线程程序无法体现出多核处理器的优势，但是多核处理器依然为程序设计者提供了一个很好的平台，使得他们可以通过对原有的单线程序进行并行设计优化，以实现更好的程序运行效果。上面介绍了多核心处理器在软件上面的应用，但游戏其实也是软件的一种，作为一种特殊的软件，对PC发展作出了较大的贡献。一些多线程游戏已经能够发挥出多核处理器的优势，对于单线程游戏，相信游戏厂商也将会改变编程策略，例如，一些游戏厂商正在对原来的一些单线程游戏进行优化，采用并行编程使得游戏运行得更快。有的游戏可以使用一个线程实现人物动画，而使用另一个线程来载入地图信息。或者使用一个线程来实现图像渲染中的矩阵运算，而使用另一个来实现更高的人工智能运算。如今，大量的支持多核心的游戏涌现出来，从而使得多核处理器的优势能得到进一步的发挥。技术瓶颈播报编辑布赖恩特直言不讳地指出，要想让多核完全发挥效力，需要硬件业和软件业更多革命性的更新。其中，可编程性是多核处理器面临的最大问题。一旦核心多过八个，就需要执行程序能够并行处理。尽管在并行计算上，人类已经探索了超过40年，但编写、调试、优化并行处理程序的能力还非常弱。易观国际分析师李也认为，“出于技术的挑战，双核甚至多核处理器被强加给了产业，而产业却并没有事先做好准备”。或许正是出于对这种失衡的担心，中国国家智能计算机中心主任孙凝辉告诉《财经》记者，“十年以后，多核这条道路可能就到头了”。在他看来，一味增加并行的处理单元是行不通的。并行计算机的发展历史表明，并行粒度超过100以后，程序就很难写，能做到128个以上的应用程序很少。CPU到了100个核以上后，并行计算机系统遇到的问题，在CPU一样会存在。“如果解决不了主流应用并行化的问题，主流CPU发展到100个核就到头了。还不知道什么样的革命性的进展能解决这些问题。”孙补充说。实际上，市场研究公司In-Stat分析师吉姆克雷格(JimMcGregor)就承认，虽然英特尔已向外界展示了80核处理器原型，但尴尬的是，还没有能够利用这一处理器的操作系统。中科院软件所并行计算实验室副主任张云泉也持类似的观点。他对《财经》记者表示，这个问题实际一直就存在，但原来在超级计算机上才会遇到，所以，讨论也多局限在学术界。所有用户都要面对这样的问题。多核心技术在应用上的优势有两个方面：为用户带来更强大的计算性能；更重要的，则是可满足用户同时进行多任务处理和多任务计算环境的要求。两大巨头都给消费者描绘出了使用多核处理器在执行多项任务时的美妙前景：同时可以检查邮件、刻录CD、修改照片、剪辑视频，并且同时可以运行杀毒软件。或者利用同一台电脑，父亲在查看财务报表，女儿在打游戏，母亲在给远方的朋友打网络电话。但并不是所有家庭只有一台电脑，也不是所有用户都要用电脑一下子做那么多事，更何况大部分应用程序还并不能自动分割成多任务，分别交给多个核心去执行。所以，对于大多数用户来说，多核所带来的实际益处，很可能并不明显。而多核所带来的挑战，或者说麻烦，却是实实在在的。美国卡内基梅隆大学计算机系教授朗道布赖恩特(RandalEBryant)在接受《财经》记者采访时就坦称，“这给软件业制造了巨大的问题”。技术原理播报编辑多核CPU就是基板上集成有多个单核CPU，早期PD双核需要北桥来控制分配任务，核心之间存在抢二级缓存的情况，后期酷睿自己集成了任务分配系统，再搭配操作系统就能真正同时开工，2个核心同时处理2“份”任务，速度快了，万一1个核心死机，起码另一个U还可以继续处理关机、关闭软件等任务。技术关键播报编辑与单核处理器相比，多核处理器在体系结构、软件、功耗和安全性设计等方面面临着巨大的挑战，但也蕴含着巨大的潜能。多核处理器CMP和SMT一样，致力于发掘计算的粗粒度并行性。CMP可以看做是随着大规模集成电路技术的发展，在芯片容量足够大时，就可以将大规模并行处理机结构中的SMP（对称多处理机）或DSM（分布共享处理机）节点集成到同一芯片内，各个处理器并行执行不同的线程或进程。在基于SMP结构的单芯片多处理机中，处理器之间通过片外Cache或者是片外的共享存储器来进行通信。而基于DSM结构的单芯片多处理器中，处理器间通过连接分布式存储器的片内高速交叉开关网络进行通信。由于SMP和DSM已经是非常成熟的技术了，CMP结构设计比较容易，只是后端设计和芯片制造工艺的要求较高而已。正因为这样，CMP成为了最先被应用于商用CPU的“未来”高性能处理器结构。虽然多核能利用集成度提高带来的诸多好处，让芯片的性能成倍地增加，但很明显的是原来系统级的一些问题便引入到了处理器内部。核结构研究同构还是异构CMP的构成分成同构和异构两类，同构是指内部核的结构是相同的，而异构是指内部的核结构是不同的。为此，面对不同的应用研究核结构的实现对未来微处理器的性能至关重要。核本身的结构，关系到整个芯片的面积、功耗和性能。怎样继承和发展传统处理器的成果，直接影响多核的性能和实现周期。同时，根据Amdahl定理，程序的加速比决定于串行部分的性能，所以，从理论上来看似乎异构微处理器的结构具有更好的性能。核所用的指令系统对系统的实现也是很重要的，多核之间采用相同的指令系统还是不同的指令系统，能否运行操作系统等，也将是研究的内容之一。程序执行模型处理器设计的首要问题是选择程序执行模型。程序执行模型的适用性决定多核处理器能否以最低的代价提供最高的性能。程序执行模型是编译器设计人员与系统实现人员之间的接口。编译器设计人员决定如何将一种高级语言程序按一种程序执行模型转换成一种目标机器语言程序;系统实现人员则决定该程序执行模型在具体目标机器上的有效实现。当目标机器是多核体系结构时，产生的问题是:多核体系结构如何支持重要的程序执行模型？是否有其他的程序执行模型更适于多核的体系结构？这些程序执行模型能多大程度上满足应用的需要并为用户所接受？Cache设计多级Cache设计与一致性问题处理器和主存间的速度差距对CMP来说是个突出的矛盾，因此必须使用多级Cache来缓解。有共享一级Cache的CMP、共享二级Cache的CMP以及共享主存的CMP。通常，CMP采用共享二级Cache的CMP结构，即每个处理器核心拥有私有的一级Cache，且所有处理器核心共享二级Cache。Cache自身的体系结构设计也直接关系到系统整体性能。但是在CMP结构中，共享Cache或独有Cache孰优孰劣、需不需要在一块芯片上建立多级Cache，以及建立几级Cache等等，由于对整个芯片的尺寸、功耗、布局、性能以及运行效率等都有很大的影响，因而这些都是需要认真研究和探讨的问题。另一方面，多级Cache又引发一致性问题。采用何种Cache一致性模型和机制都将对CMP整体性能产生重要影响。在传统多处理器系统结构中广泛采用的Cache一致性模型有:顺序一致性模型、弱一致性模型、释放一致性模型等。与之相关的Cache一致性机制主要有总线的侦听协议和基于目录的目录协议。CMP系统大多采用基于总线的侦听协议。核间通信技术CMP处理器的各CPU核心执行的程序之间有时需要进行数据共享与同步，因此其硬件结构必须支持核间通信。高效的通信机制是CMP处理器高性能的重要保障，比较主流的片上高效通信机制有两种，一种是基于总线共享的Cache结构，一种是基于片上的互连结构。总线共享Cache结构是指每个CPU内核拥有共享的二级或三级Cache，用于保存比较常用的数据，并通过连接核心的总线进行通信。这种系统的优点是结构简单，通信速度高，缺点是基于总线的结构可扩展性较差。基于片上互连的结构是指每个CPU核心具有独立的处理单元和Cache，各个CPU核心通过交叉开关或片上网络等方式连接在一起。各个CPU核心间通过消息通信。这种结构的优点是可扩展性好，数据带宽有保证;缺点是硬件结构复杂，且软件改动较大。也许这两者的竞争结果不是互相取代而是互相合作，例如在全局范围采用片上网络而局部采用总线方式，来达到性能与复杂性的平衡。总线设计传统微处理器中，Cache不命中或访存事件都会对CPU的执行效率产生负面影响，而总线接口单元（BIU）的工作效率会决定此影响的程度。当多个CPU核心同时要求访问内存或多个CPU核心内私有Cache同时出现Cache不命中事件时，BIU对这多个访问请求的仲裁机制以及对外存储访问的转换机制的效率决定了CMP系统的整体性能。因此寻找高效的多端口总线接口单元（BIU）结构，将多核心对主存的单字访问转为更为高效的猝发（burst）访问;同时寻找对CMP处理器整体效率最佳的一次Burst访问字的数量模型以及高效多端口BIU访问的仲裁机制将是CMP处理器研究的重要内容，Inter推出了最新的英特尔智能互连技术(QPI)技术总线，更大程度发掘了多核处理器的实力。操作系统设计任务调度、中断处理、同步互斥对于多核CPU，优化操作系统任务调度算法是保证效率的关键。一般任务调度算法有全局队列调度和局部队列调度。前者是指操作系统维护一个全局的任务等待队列，当系统中有一个CPU核心空闲时，操作系统就从全局任务等待队列中选取就绪任务开始在此核心上执行。这种方法的优点是CPU核心利用率较高。后者是指操作系统为每个CPU内核维护一个局部的任务等待队列，当系统中有一个CPU内核空闲时，便从该核心的任务等待队列中选取恰当的任务执行，这种方法的优点是任务基本上无需在多个CPU核心间切换，有利于提高CPU核心局部Cache命中率。多数多核CPU操作系统采用的是基于全局队列的任务调度算法。多核的中断处理和单核有很大不同。多核的各处理器之间需要通过中断方式进行通信，所以多个处理器之间的本地中断控制器和负责仲裁各核之间中断分配的全局中断控制器也需要封装在芯片内部。另外,多核CPU是一个多任务系统。由于不同任务会竞争共享资源，因此需要系统提供同步与互斥机制。而传统的用于单核的解决机制并不能满足多核，需要利用硬件提供的“读－修改－写”的原子操作或其他同步互斥机制来保证。低功耗设计半导体工艺的迅速发展使微处理器的集成度越来越高，同时处理器表面温度也变得越来越高并呈指数级增长，每三年处理器的功耗密度就能翻一番。低功耗和热优化设计已经成为微处理器研究中的核心问题。CMP的多核心结构决定了其相关的功耗研究是一个至关重要的课题。低功耗设计是一个多层次问题，需要同时在操作系统级、算法级、结构级、电路级等多个层次上进行研究。每个层次的低功耗设计方法实现的效果不同——抽象层次越高，功耗和温度降低的效果越明显。当前Intel的CPU的功耗相对较低，得益于先进的英特尔构架和45纳米、32纳米制程工艺，同时Intel还专门为CPU开发了不少节能技术，比如C6深度节能技、英特尔智能功效管理和主动管理技术等等，Intel在移动CPU市场，更是凭借超低电压处理器（ULV）和凌动（Atom）系列处理器，遥遥领先于对手。存储器墙为了使芯片内核充分地工作，最起码的要求是芯片能提供与芯片性能相匹配的存储器带宽，虽然内部Cache的容量能解决一些问题，但随着性能的进一步提高，必须有其他一些手段来提高存储器接口的带宽，如增加单个管脚带宽的DDR、DDR2、QDR、XDR等。同样，系统也必须有能提供高带宽的存储器。所以，芯片对封装的要求也越来越高，虽然封装的管脚数每年以20%的数目提升，但还不能完全解决问题，而且还带来了成本提高的问题，为此，怎样提供一个高带宽，低延迟的接口带宽，是必须解决的一个重要问题。可靠性及安全性设计随着技术革新的发展，处理器的应用渗透到现代社会的各个层面，但是在安全性方面却存在着很大的隐患。一方面，处理器结构自身的可靠性低下，由于超微细化与时钟设计的高速化、低电源电压化，设计上的安全系数越来越难以保证，故障的发生率逐渐走高。另一方面，来自第三方的恶意攻击越来越多，手段越来越先进，已成为具有普遍性的社会问题。可靠性与安全性的提高在计算机体系结构研究领域备受注目。今后，CMP这类处理器芯片内有多个进程同时执行的结构将成为主流，再加上硬件复杂性、设计时的失误增加，使得处理器芯片内部也未必是安全的，因此，安全与可靠性设计任重而道远。技术意义播报编辑多核处理器代表了计算技术的一次创新。由于数字数据和互联网的全球化，商业和消费者开始要求多核处理器带来性能改进，这个重要创新就开始了；因为多核处理器比单核处理器具有性能和效率优势，多核处理器将会成为被广泛采用的计算模型。在驱动pc安全性和虚拟化技术的重大进程过程中，多核处理器扮演着中心作用，这些安全性和虚拟化技术的开发用于为商业计算市场提供更大的安全性、更好的资源利用率、创造更大价值。普通消费者用户也期望得到前所未有的性能，这将极大地扩展其家庭pc和数字媒体计算系统的使用。多核处理器具有不增加功耗而提高性能的好处，实现更大的性能/能耗比。在一个处理器中放入两个或多个功能强大的计算核产生了一个重大的可能性。由于多核处理器能提供比单核处理器更好的性能和效率，下一代的软件应用程序很有可能是基于多核处理器而开发的。不管这些应用是帮助专业的电影公司以更少的投入和更少的时间完成更真实的电影，还是以更彻底的方法使得pc更自然和直观，多核处理器技术将永远改变计算世界。多核处理器表达了amd了解顾客需求并且开发最能满足客户要求产品的意愿。微软多核计算的主管DanReed称，整个世界上很缺乏那些并行计算的研究人员，而一个间接的原因就是学院里对于并行计算的关注度不够，而这些学院正是下一代软件开发人员诞生的地方。越来越高的时钟频率导致应用程序的代码运行的越来越快，而对于当前多核处理器来讲这一规则虽然成立，但却有所不同。而这种不同可以做一个形象的比喻，那就是一部跑车和一辆学校的巴士。当跑车能够以很快的速度飞奔时，巴士虽然比较慢，但它可以载着更多的人前行。问题就是，简单地在计算机CPU上增加多个核并不能增加传统应用程序代码的运行速度，这一结果是根据一项来自于Forrester研究公司的报告得出的。换句话说，复杂的工作需要拆分来填充这辆巴士上的空座位。Forrester的报告还谈到：同时，当前四核处理器会激发更多的多处理器设计的思想，我们期待着2009年x86的服务器使用64个处理器核，并且2012年台式机也可以实现这一梦想。使得芯片的制造商以及主要的板级应用的软件厂商意识到多核编程的机遇和挑战。[1]技术种类播报编辑单芯片多处理器(CMP)与同时多线程处理器(SimultaneousMultithreading，SMT)，这两种体系结构可以充分利用这些应用的指令级并行性和线程级并行性，从而显著提高了这些应用的性能。从体系结构的角度看，SMT比CMP对处理器资源利用率要高，在克服线延迟影响方面更具优势。CMP相对SMT的最大优势还在于其模块化设计的简洁性。复制简单设计非常容易，指令调度也更加简单。同时SMT中多个线程对共享资源的争用也会影响其性能，而CMP对共享资源的争用要少得多，因此当应用的线程级并行性较高时，CMP性能一般要优于SMT。此外在设计上，更短的芯片连线使CMP比长导线集中式设计的SMT更容易提高芯片的运行频率，从而在一定程度上起到性能优化的效果。总之，单芯片多处理器通过在一个芯片上集成多个微处理器核心来提高程序的并行性。每个微处理器核心实质上都是一个相对简单的单线程微处理器或者比较简单的多线程微处理器，这样多个微处理器核心就可以并行地执行程序代码，因而具有了较高的线程级并行性。由于CMP采用了相对简单的微处理器作为处理器核心，使得CMP具有高主频、设计和验证周期短、控制逻辑简单、扩展性好、易于实现、功耗低、通信延迟低等优点。此外，CMP还能充分利用不同应用的指令级并行和线程级并行，具有较高线程级并行性的应用如商业应用等可以很好地利用这种结构来提高性能。技术应用播报编辑并行计算技术是云计算的核心技术，也是最具挑战性的技术之一。多核处理器的出现增加了并行的层次性能使得并行程序的开发比以往更难。而当前业内并无有效的并行计算解决方案，无论是编程模型、开发语言还是开发工具，距离开发者的期望都有很大的差距。自动的并行化解决方案在过去的30年间已经被证明基本是死胡同，但传统的手工式的并行程序开发方式又难以为普通的程序员所掌握。Intel、微软、SUN、Cray等业内巨头正投入大量人力物力进行相关的研究，但真正成熟的产品在短期内很难出现。可扩展性是云计算时代并行计算的主要考量点之一，应用性能必须能随着用户的请求、系统规模的增大有效的扩展。当前大部分并行应用在超过一千个的处理器(核)上都难以获得有效的加速性能，未来的许多并行应用必须能有效扩展到成千上万个处理器上。这对开发者是巨大的挑战。[2]产品应用播报编辑从Power、UltraSPARCT1、安腾到双核Opteron、至强Xeon，各个领域都显示出，多核处理器计算平台势必成为服务器的主流或者说是强势计算平台，但这只是上游硬件厂商的乐观预计。并不是所有的操作系统和应用软件都做好了迎接多核平台的准备，尤其是在数十年来均为单一线程开发应用的x86服务器领域。微软软件架构师HerbSutter曾指出:软件开发者对多核处理器时代的来临准备不足。他说，软件开发社区认识到处理器厂商被迫采用多核设计以应对处理器速度提升带来的发热问题，但却没有清楚地了解这样的设计为软件开发带来多少额外的工作。在过去一段长时间里，x86系统上软件的性能随着来自Intel和AMD处理器速度越来越快而不断提高，开发者只需对现有软件程序作轻微改动就能坐观其性能在随着硬件性能的上升而不断提升。不过，多核设计概念的出现迫使软件世界不得不直面并行性(将单个任务拆分成多个小块以便分别处理之后再重新组合的能力)问题。当然，为服务器设计软件的开发者已经解决了一些此类难题，因为多核处理器和多路系统在服务器市场已经存在多年(在传统的Unix领域)，一些运行在RISC架构多核多路系统上的应用程序已经被设计成多线程以利用系统的并行处理能力。但是，在x86领域，应用程序开发者多年来一直停留在单线程世界，生产所谓的“顺序软件”。情况是软件开发者必须找出新的开发软件的方法，面向对象编程的兴起增加了汇编语言的复杂性，并行编程也需要新的抽象层次。另一方面，处理器设计厂商在设计产品时也应该将软件开发者考虑在内，“处理器的首要着眼点应该是可编程性，而不是速度。”Sutter说。多核处理器要想发挥出威力，关键在于并行化软件支持，多核设计带动并行化计算的推进，而给软件带来的影响更是革命性的。Intel很早就通过超线程技术实现了逻辑上的双处理器系统，可以并行计算，但这不过是对处理器闲置资源的一种充分利用而已，并且这种充分利用只有在特定的条件下，尤其是针对流水线比较长且两种运算并不相互交叉的时候，才会有较高的效率，如编码解码、长期重复某种矩阵运算以及一些没有经过仔细编写的软件等。即使IBM的Power5架构，也需要跟最新的操作系统进行融合，加上运行在其上的软件，才有可能利用并发多线程。虚拟化技术在一定程度上能够处理一些因为多核带来的问题，可以让应用软件和操作系统在透明的环境下对处理器资源进行分配和管理。在对称多处理器方面，操作系统对资源的分配和管理并没有本质的改变，多以对称的方式进行平均分配。也就是说，在操作系统层面，当一个任务到来时，剥离成为两个并行的线程，因为线程之间需要交流以及操作系统监管，它导致的效率损失要比硬件层面大得多。并且，多数软件并没有充分考虑到双核乃至多核的运行情况，导致线程的平均分配时间以及线程之间的沟通时间都会大大增加，尤其是当线程需要反复访问内存的时候。多数操作系统还没有完全实现自由的资源分配，如IBM是通过AIX5.3L来支持Power5上的虚拟化功能，才实现了资源的动态调配和划分的。从长远来看，需要使用虚拟化技术才可能实现操作系统对任务的具体划分，这很可能改变一些通用的编程模式。[3]英特尔播报编辑2009年9月6日下午，英特尔在北京发布了业界首款专为多路(MP)服务器设计的四核英特尔&reg;至强&reg;7300系列服务器处理器。与英特尔前代双核产品相比，此次发布的六款全新四核至强&reg;7300系列处理器的性能和性能功耗比分别提升了两倍和三倍之多。而随着这些产品的发布，英特尔在不到15个月的时间内完成了向创新和高能效的英特尔&reg;酷睿™微体系架构的快速切换。据了解，此次推出的至强&reg;7300系列产品包括主频高达2.93GHz处理器(功耗为130瓦)，几款80瓦处理器，和一款针对四插槽刀片式服务器和高密度机架式服务器优化的50瓦版处理器(主频为1.86GHz)。具备数据流量优化(DataTrafficOptimizations)特性的英特尔&reg;7300芯片组采用平衡的平台设计，具有多项全新技术，以改善数据在处理器、内存和I/O之间的传输能力。此外，英特尔还发布了一款50瓦(每内核12.5瓦)的处理器，以推动四插槽刀片式服务器和高密度机架式服务器等高能效超密度部署产品的发展。在芯片设计方面，除内核数量增加一倍之外，相对于前代英特尔多路平台，至强&reg;7300系列处理器和英特尔&reg;7300芯片组所支持的内存容量是原来的4倍，并能支持非常高的整合比例，以减少空间、降低功耗和运营成本。预计今后将有超过50家的系统制造商发售基于英特尔&reg;至强&reg;7300系列处理器的服务器，其中包括戴尔、Egenera、富士通、富士通-西门子、日立、惠普、IBM、NEC、Sun、超微和优利等。针对需要基于全新英特尔&reg;至强&reg;7300系列处理器的完整平台的渠道客户，英特尔特别为其提供了英特尔&reg;S7000FC4UR服务器平台。该款平台可提供强劲的可扩展性能、业经验证的企业级可靠性，用于基础设施的虚拟化和整合。许多软件厂商也为基于英特尔&reg;至强&reg;7300系列处理器的平台提供了创新性的支持虚拟化和性能扩展的解决方案，如BEA、微软、甲骨文、SAP和VMware等。此外，Solaris操作系统和其上运行的数千款应用能够充分利用英特尔&reg;至强&reg;7300系列处理器平台的领先性能优势，为英特尔&reg;至强&reg;服务器用户提供企业级、支持关键任务的UNIX操作系统环境。这些全新四核处理器的定价根据主频、特性和客户定购数量的不同，其千枚单价从856美元至2,301美元不等。总线事务：名词定义：总线裁决：决定哪个主控设备使用总线。寻址阶段：主控设备送出要访问设备的地址，同时送出有关命令（读或写等），启动从设备。数据传输阶段：主、从设备间进行数据交换。结束阶段：有关信息在总线上撤销，让出总线使用权。总线控制：特点播报编辑控制总线CB（ControlBus）特点是：在单向、双向、双态等种形态，是总线中最复杂、最灵活、功能最强的，其数量、种类、定义随机型不同而不同。分类播报编辑控制总线就是各种信号线的集合，是计算机各部件之间传送数据、地址和控制信息的公共通道。⒈按相对于CPU与其芯片的位置来分：⑴片内总线：指在CPU内部各寄存器、算术逻辑部件ALU，控制部件以及内部高速缓冲存储器之间传输数据所用的总线，即芯片内部总线。⑵片外总线：通常所说的总线（BUS）指的外总线，是CPU与内存RAM、ROM和输入输出输入输出设备接口之间进行通讯的数据通道，CPU通过总线实现程序存取命令，内存/外设的数据交换在CPU与外设一定的情况下，总线速度是限制计算机整体性能的最大因数。⒉按总线功能分：⑴地址总线：（AB）用来传递地址信息。⑵数据总线：（DB）用来传递数据信息。⑶控制总线：（CB）用来传送各种控制信号。⒊按总线的层次结构分：⑴CPU总线：包括CPU地址线（CAB），CPU数据线（CDB）和CPU控制线（CCB），其用来连接CPU和控制芯片。CS31通讯总线⑵存储器总线：包括存储器地址线（MAB）、存储器数据线（MDB）和存储器控制线（MCD），用来连接内存控制器（北桥）和内存。⑶系统总线：（I/O扩展总线）也称为I/O通道总线或I/O扩展总线，包括系统地址线（SAB），系统数据线（SDB）和系统控制线（SCD），用来与I/O扩展槽上的各种扩展卡相连接。⑷外部总线：（外围芯片总线）用来连接各种外设控制芯片，如主板上的I/O控制器（如硬盘接口控制器、软盘驱动控制器、串行/并行接口控制器等），和键盘控制器，包括外部地址线（XAB）、外部数据线（XMB）和外部控制线（XCB）。⒋系统总线（输入输出）扩展总线）又分为ISA、PCI、AGP等多种标准⑴ISA(Industrystandardarchitecture,工业标准结构）是IBM公司为286AT电脑制定的总线工业标准，也称为AT标准。⑵PCI(peripheralcomponentinterconnet,外部设备互连）是SIG（spelialinterestgroup）集团推出的总线结构。⑶AGP(acceleratedgraphicsport，加速图形端口）是一种为了提高视频带宽而设计的总线规范，因为它是点对点连接，即连接控制芯片和AGP显卡，因此严格说来，AGP也是一种接口标准。ISA插槽播报编辑1、地址总线：SA0~SA19(I/O）和LA17~LA23(I/O)LⅪ测试总线技术2、数据总线：SD0~SD7(I/O）和SD8~SD15(I/O)3、控制总线：BALE(0)---USAddresslatchenable：系统地址锁存允许4、SYSCLK(0)---SYSTEMCLOCK系统时钟信号5、IR23~7,9~12,15(Z)---这是用于I/O设备通过中断控制器向CPU发送的中断请求(interruptrequest)信号6、SMEMR#和SMEMW#(0)---这是命令内存将数据送至数据总线的信号7、MEMR#和MEMW#(I/O)---内存读（MEMR）或内存写（MEMW#)信号8、DRQ0~3,5~7⑵---这是DMA请求（DMARequesc）信号9、DACK0#~3,5~7(0)---(DMAAcknowledge,DMA响应）这是对DRQ0~3,5~7的响应信号10、AEN(0)---地址允许（Addressenable）信号11、REFRESH#(I/O)---内存刷新(DRAMrefresh)信号12、SBHE(I/O)---系统总线字节允许（systembushighenable）信号13、MASTER⑵---主控信号14、MEMCS16#⑵---存储器16位片选(Memory16bitchipselect)信号15、ZOCS16#⑵---I/O16位片选(I/O16bitchipselect)信号16、OWS⑵---零等待状态(ZeroWaitState)信号技术指标播报编辑1、总线的带宽（总线数据传输速率）程序总线总线的带宽指的是单位时间内总线上传送的数据量，即每钞钟传送MB的最大稳态数据传输率。与总线密切相关的两个因素是总线的位宽和总线的工作频率，它们之间的关系：总线的带宽=总线的工作频率*总线的位宽/82、总线的位宽总线的位宽指的是总线能同时传送的二进制数据的位数，或数据总线的位数，即32位、64位等总线宽度的概念。总线的位宽越宽，每秒钟数据传输率越大，总线的带宽越宽。3、总线的工作频率总线的工作时钟频率以MHZ为单位，工作频率越高，总线工作速度越快，总线带宽越宽。操作播报编辑总线一个操作过程是完成两个模块之间传送信息，启动操作过程的是主模块，另外一个是从模块。某一时刻总线上只能有一个主模块占用总线。[2]控制总线总线的操作步骤：主模块申请总线控制权，总线控制器进行裁决。数据传送的错误检查：主模块得到总线控制权后寻址从模块，从模块确认后进行数据传送。总线定时协议：定时协议可保证数据传输的双方操作同步，传输正确。定时协议有三种类型：同步总线定时：总线上的所有模块共用同一时钟脉冲进行操作过程的控制。各模块的所有动作的产生均在时钟周期的开始，多数动作在一个时钟周期中完成。异步总线定时：操作的发生由源或目的模块的特定信号来确定。总线上一个事件发生取决前一事件的发生，双方相互提供联络信号。控制总线模型总线定时协议半同步总线定时：总线上各操作的时间间隔可以不同，但必须是时钟周期的整数倍，信号的出现，采样与结束仍以公共时钟为基准。ISA总线采用此定时方法。数据传输类型：分单周方式和突发（burst）方式。单周期方式：一个总线周期只传送一个数据。数据传输类型：突发方式：取得主线控制权后进行多个数据的传输。寻址时给出目的地首地址，访问第一个数据，数据2、3到数据n的地址在首地址基础上按一定规则自动寻址（如自动加1）。标准规范播报编辑总线是一类信号线的集合是模块间传输信息的公共通道，通过它，计算机各部件间可进行各种数据和命令的传送。为使不同供应商的产品间能够互换，给用户更多的选择，总线的技术规范要标准化。总线的标准制定要经周密考虑，要有严格的规定。总线标准（技术规范）包括以下几部分：机械结构规范：模块尺寸、总线插头、总线接插件以及安装尺寸均有统一规定。功能规范：总线每条信号线（引脚的名称）、功能以及工作过程要有统一规定。电气规范：总线每条信号线的有效电平、动态转换时间、负载能力等。串行传输：简介播报编辑串行通信技术，是指通信双方按位进行，遵守时序的一种通信方式。串行通信中，将数据按位依次传输，每位数据占据固定的时间长度，即可使用少数几条通信线路就可以完成系统间交换信息，特别适用于计算机与计算机、计算机与外设之间的远距离通信。串行通信多用于系统间通信（多主控制系统）、设备间（主控设备与附属设备）、器件间（主控CPU与功能芯片）之间数据的串行传送，实现数据的传输与共享。[2]串行总线通信过程的显著特点是：通信线路少，布线简便易行，施工方便，结构灵活，系统间协商协议，自由度及灵活度较高，因此在电子电路设计、信息传递等诸多方面的应用越来越多。[2]串行通信是指计算机主机与外设之间以及主机系统与主机系统之间数据的串行传送。使用一条数据线，将数据一位一位地依次传输，每一位数据占据一个固定的时间长度。其只需要少数几条线就可以在系统间交换信息，特别适用于计算机与计算机、计算机与外设之间的远距离通信。分类播报编辑同步通信同步通信是一种连续串行传送数据的通信方式，一次通信只传送一帧信息。这里的信息帧与异步通信中的字符帧不同，通常含有若干个数据字符。它们均由同步字符、数据字符和校验字符（CRC）组成。其中同步字符位于帧开头，用于确认数据字符的开始。数据字符在同步字符之后，个数没有限制，由所需传输的数据块长度来决定；校验字符有1到2个，用于接收端对接收到的字符序列进行正确性的校验。同步通信的缺点是要求发送时钟和接收时钟保持严格的同步。异步通信异步通信中，在异步通信中有两个比较重要的指标：字符帧格式和波特率。数据通常以字符或者字节为单位组成字符帧传送。字符帧由发送端逐帧发送，通过传输线被接收设备逐帧接收。发送端和接收端可以由各自的时钟来控制数据的发送和接收，这两个时钟源彼此独立，互不同步。接收端检测到传输线上发送过来的低电平逻辑"0"（即字符帧起始位）时，确定发送端已开始发送数据，每当接收端收到字符帧中的停止位时，就知道一帧字符已经发送完毕。特点播报编辑数据在单条一位宽的传输线上，一比特接一比特地按顺序传送的方式称为串行通信。在并行通信中，一个字节（8位）数据是在8条并行传输线上同时由源传到目的地；而在串行通信方式中，数据是在单条1位宽的传输线上一位接一位地顺序传送。这样一个字节的数据要分8次由低位到高位按顺序一位位地传送。由此可见，串行通信的特点如下：1、节省传输线，这是显而易见的。尤其是在远程通信时，此特点尤为重要。这也是串行通信的主要优点。2、数据传送效率低。与并行通信比，这也这是显而易见的。这也是串行通信的主要缺点。例如：传送一个字节，如果并行通信所需时间为1T，则串行通信所需时间至少为8T。由此可见，串行通信适合于远距离传送，可以从几米到数千公里。对于长距离、低速率的通信，串行通信往往是唯一的选择。并行通信适合于短距离、高速率的数据传送，通常传输距离小于30米。特别值得一提的是，现成的公共电话网是通用的长距离通信介质，它虽然是为传输声音信号设计的，但利用调制解调技术，可使现成的公共电话网系统为串行数据通信提供方便、实用的通信线路。串行通信干扰源播报编辑串行通信工作场所多处于强电/户外等复杂环境，并且通信各方间距离一般较长，因此易受干扰。串行通信，波特率一定时，数据位的传输时间相对较短，由于串行通信的数据位采样/获取特点，位信息受干扰，整个字节数据就是错误信息。[3]现实中，容易带入串行通信干扰的因素包括：（1）环境电磁干扰在串行通信工作设备附近，无可避免的存在强电设备、功率发射台等。这些设备发射/感应的强电磁场感应区内，环境电磁干扰强。串行通信设备工作在这种环境下，由于噪声(干扰)在信号电平上的叠加，引发了通信双方数据错误。[3]（2）系统噪声串行通信依赖于串行通信芯片。由于芯片的设计工艺与制作水平，对输出电平的噪声控制参差不齐。产生输出电平的噪声包括数字逻辑中供电电源和器件自身的稳定性。通信中，供电电源的纹波无可避免的会加载到通信线路中。纹波较大时，容易引发串行通信的错误。[3]（3）码率误差串行通信双方事先约定了固定的波特率作为数据传输的步调。波特率的一致性是串行通信数据稳定可靠的基础。由于通信双方的波特率由各自本地产生，存在误差率的波特率导致通信双方存在码率误差。波特率误差越大，通信数据错误的几率就越大。[3]（4）地回路与参考地电位通信双方共地应用中，由于系统间参考地信号的高低电平不一致，导致传输的信号对地电压存在一定的误差。低电压供电应用系统中，两侧参考地电位误差过大，会引发串行通信的数据错误。以上干扰源，在通信线屏蔽、线路隔离、校准波特率等不同的硬件优化措施下，可以减弱或消除部分干扰，但仍存在数据错误的可能性。因此，在硬件抗干扰的保障之外，加入软件侦错机制，不可忽略，尤为必要。[3]串行通信隔离方法播报编辑隔离的现实需要串行通信由于其工作特点（按位传输易受干扰、远距离信息交换）、应用场合（恶劣环境的工业控制、户外等）、器件间电平匹配（两侧器件的工作电平不一致等），需要做相应的隔离防护。通过隔离，达到以下目的。（1）器件保护，防护隔离在电子器件高速发展的今天，低功耗、高封装的芯片应用广泛。微处理器的低电压工作条件和外围器件的高电压工作环境，其发展进程不一。当前微处理器芯片电平多以1.8V、3.3V、5.0V等低电压器件为主，而且随着不同工作电压的数字IC的不断涌现，逻辑电平转换的必要性更加突出。例如STM32控制器的3.3V输入输出I/O与传统串行通信接口芯环境，其发展进程不一。因此，为了实现控制器与通信接口芯片间的电平匹配，保护控制器引脚因过高或者过低的工作电压而受损，加入隔离器件尤其必要。[2]（2）屏蔽干扰，线路隔离由于较多串行通信设备工作在工业现场的恶劣环境或配电系统的远距离传输等条件下，因此在长线通讯中线路上往往会感应出明显的干扰信号，造成通信过程的偶发性错误，进而影响整个系统的可靠运行。引入干扰信号的来源包括空间辐射、串扰、系统噪声等。例如RS－232C通信中由于其采用单端信号传输模式，当通信双方的不同地线之间的地电位不一致时，就会引入共模干扰电压，造成通信的不稳定。[2]串行通信中，通过通信线路屏蔽可以减少辐射干扰的影响，通过差分方式信号传输方式可以减少共模干扰电压的影响，但为应对器件保护而进行的电平变换和为减少干扰而设计的线路隔离，仍必不可少。[2]隔离的方法应用（1）分立器件隔离技术在隔离设计需要中，器件间电平变换隔离方法可采用单纯的分立器件完成。电平变换的最终目的就是实现工作单元两侧的电平根据各自需要而定。分立器件隔离方法主要利用的就是电阻与晶体管的合理搭配，使得输入/输出间的电平实现匹配。利用MOS管的开关作用，实现双侧电平变换，是常规有效的方法。此种隔离方法，一般为共地隔离，仅完成电平变换，做到保护器件功能，非系统间电气隔离。[2]（2）光电耦合器隔离技术光电耦合器，简称光耦，是一种以光为媒介来实现电信号传输的一类器件。其工作原理是把发光器（发光器件）与感光器（光敏器件）封装在芯片内部，通过外加在输入端的电信号控制发光器发光，感光器在内部光照的情况下，产生电信号，驱动输出端，实现了“电—光—电”转换。由于光耦两侧的电信号完全隔离，内部以光为传输媒介，因此，光耦输入/输出之间绝缘，可以完成单向信号的隔离传输，在数字电路中应用广泛。普通光耦（TLP521）在隔离电路中的应用，受限于器件特点，其传输特性低频效果较好，高频信号传输失真严重。实际电路测试中，115kbp的串行通信频率，通过电路器件参数匹配和电路结构优化，可基本适应。从东芝半导体公司光耦产品系中可知，其通信速率涵盖了20kbps～50Mbps，因此在高速通信传输时，应根据设计需要选用高速光耦。[2]（3）新型隔离技术在产品日新月异的时下，新器件层出不穷。主流芯片商德州仪器（TI）、亚诺德半导体（ADI）和芯科科技（SiliconLabs）分别研发了电容隔离、磁耦隔离、射频隔离等不同类型的数字隔离器。[2]电容隔离电容隔离，利用了电容极板间填充材料为绝缘物质为隔离层，通过内部电场的变化来完成信号的传输。TI公司的ISO72x系列为典型电容隔离技术的应用。在电容隔离功能中，信号传输通道分为“低频通道”与“高频通道”。低频信号通过内置振荡器产生的高频载波与PWM调制，通过差分方式进行调制传输。输出端低通滤波去除高频载波。高频信号则不经过调制编码，差分变换后直接通过隔离层传输，输出端通过时间关系进行逻辑决策，从而控制输出多路选择器正确输出。[2]磁耦隔离磁耦隔离，利用了变压器原理，使用变压器初级线圈与次级线圈两者之间通过磁耦合方式进行信号传递，从而实现隔离效果。ADI公司的iCoupler专利技术，就是基于芯片内空芯变压器的磁隔离技术。ADUM系列为典型磁耦隔离技术的应用。[2]iCoupler磁隔离技术，通过芯片内部特征尺寸上实现的空芯变压器初级与次级线圈间的磁耦合实现信号隔离。信号传输采用了特定短脉冲组合方式来表示高低电平。两个连续的短脉冲表示高电平，单个短脉冲表示低电平。输出端根据检测脉冲的个数来确定输出电平状态。刷新器电路与看门狗电路提供了输入端电平状态与输出端故障安全状态方面的保障。[2]射频隔离射频隔离，利用了无线射频传输原理。在发送端，完成基于高频信号的原始信号调制，通过发射天线发送。在接收端，通过解调器完成已调信号的解调，恢复原始信号。通过这样的调制与解调，实现隔离的效果。SiliconLabs公司的RF隔离即射频隔离，Si84xx系列为典型射频隔离技术的应用。[2]RF隔离采用ISOpro型RF射频隔离原理。芯片由半导体RF射频发射器、接收器和两者间的差动电容式隔离隔栅组成。工作中，使用基本的ON/OFF按键（OOK功能），输入数据为高电压时，发射器产生RF射频调制信号；输入数据为低电平时，发生器无RF射频调制信号。调制信号经过隔离隔栅送到接收器。接收器检测到同频带调制信号时，经解调器解调，输出高电平；无调制信号时，输出低电平。[2]IR：关系介绍播报编辑含义具体而言，投资者关系管理(IRM：InvestorRelationshipManagement)是指运用财经传播和营销的原理，通过管理公司同财经界和其他各界进行信息沟通的内容和渠道，以实现相关利益者价值最大化并如期获得投资者的广泛认同，规范资本市场运作、实现外部对公司经营约束的激励机制、实现股东价值最大化和保护投资者利益，以及缓解监管机构压力等。IRM还经常被通俗理解为公共关系管理(PRM：PublicRelationManagement)。在中国，IRM也经常被人称为财经公关。IRIRM投资者关系（IR，InvestorsRelation）与“投资者关系管理”（IRM,InvestorsRelationManagement）在西方成熟资本市场上已有三十多年的历史。然而，在发展中国家，这一概念还不广为证券市场参与各方所知，也并不是所有上市公司管理层都能充分理解IRM对公司长远发展的重要意义。国内学者田书华曾对投资者关系管理进行过深入系统的研究。五大对象播报编辑排序值得一提的是投资者关系五大对象按重要程度排序依次是：基金经理，买方分析师，卖方分析师，财经媒体和高净资产个人（散户）。机构投资者一般都有自己的分析师团队，并有着各自不同的投资策略和偏好，对其进行有效的沟通需要专业的资本市场知识和经验，而仅仅运用公关和大众传播的思维方式效果是有限的。财经媒体的作用更多的是影响散户，所以重要程度排在买方和卖方之后。实务就实务方面而言，美国上市公司投资者关系发展较为成熟的（包括在美国上市的非美国公司），通常会委任专业的投资者关系顾问公司协助日常及项目型工作。常年的日常工作包括投资者关系策略制定，公司资本市场定位，投资亮点及故事包装，业绩发布电话会议支持，重大事件披露新闻稿的编撰润色，路演支持，投资者关系网站和投资者数据库的维护，以及接受投资者问询并对危机管理提供咨询建议。项目型服务包括详尽的股东组成结构分析，投资者反馈调查（包括常规的和特定议题如兼并收购），以及潜在机构投资者锁定及拓展计划。通常，对于新上市的公司尤其中小股本公司，为了更好的吸引资本市场的兴趣，一般会采用投资者关系顾问公司的最佳实践标准的（BestPractice），积极性的专业服务，以提高其资本市场的竞争力；对于上市多年的公司尤其是行业龙头的大型股本公司，内部投资者关系团队比较成熟，可以独立处理大部分日常工作，所以一般采用专业顾问公司的项目型服务。专业顾问公司的多年积累的数据库和成熟的研究方法可以提供更精准的调查，分析和建议。半导体存储器：简介播报编辑半导体集成存储器semiconductormemory每个存储单元有两个不同的表征态“0”和“1”，用以存储不同的信息。半导体存储器是构成计算机的重要部件。同磁性存储器相比，半导体存储器具有存取速度快、存储容量大、体积小等优点，并且存储单元阵列和主要外围逻辑电路兼容，可制作在同一芯片上，使输入输出接口大为简化。因此，在计算机高速存储方面，半导体存储器已全部替代过去的磁性存储器。主要优点播报编辑这种存储器的主要优点是：①存储单元阵列和主要外围逻辑电路制作在同一个硅芯片上，输出和输入电平可以做到同片外的电路兼容和匹配。这可使计算机的运算和控制与存储两大部分之间的接口大为简化；②数据的存入和读取速度比磁性存储器约快三个数量级，可大大提高计算机运算速度；③利用大容量半导体存储器使存储体的体积和成本大大缩小和下降。因此，在计算机高速存储方面，半导体存储器已全部替代了过去的磁性存储器。用作大规模集成电路的半导体存储器，是1970年前后开始生产的1千位动态随机存储器。随着工艺技术的改进，到1984年这类产品已达到每片1兆位的存储容量。分类播报编辑按功能的不同，半导体存储器可分为随机存储器（RAM）、只读存储器（ROM）和串行存储器三大类。随着半导体集成电路工艺技术的发展，半导体存储器容量增长非常快，单片存储容量已进入兆位级水平，如16兆动态随机存储器（DRAM）已商品化，64兆、256兆DRAM在研制中。随机存储器对于任意一个地址，以相同速度高速地、随机地读出和写入数据的存储器（写入速度和读出速度可以不同）。存储单元的内部结构一般是组成二维方矩阵形式，即一位一个地址的形式(如64k×1位)。但有时也有编排成便于多位输出的形式（如8k×8位）。随机存储器主要用于组成计算机主存储器等要求快速存储的系统。按工作方式不同，随机存储器又可分为静态和动态两类。静态随机存储器的单元电路是触发器。可规定A或B两个晶体管中的一个导通时，代表“1”或代表“0”。触发器只要电源足够高，导通状态便不会改变。因此，存入每一单元的信息，如不“强迫”改写，只要有足够高的电源电压存在便不会改变，不需要任何刷新（见金属-氧化物-半导体静态随机存储器）。这种存储器的速度快，使用方便。动态随机存储器的单元由一个MOS电容和一个MOS晶体管构成，数据以电荷形式存放在电容之中，一般以无电荷代表“0”，有电荷代表“1”，反之亦可。单元中的MOS晶体管是一个开关，它控制存储电容器中电荷的存入和取出。通常，MOS电容及与其相联接的PN结有微弱的漏电，电荷随时间而变少，直至漏完，存入的数据便会丢失。因此动态随机存储器需要每隔2～4毫秒对单元电路存储的信息重写一次，这称为刷新。这种存储器的特点是单元器件数量少，集成度高，应用最为广泛（见金属-氧化物-半导体动态随机存储器）。只读存储器用来存储长期固定的数据或信息，如各种函数表、字符和固定程序等。其单元只有一个二极管或三极管。一般规定，当器件接通时为“1”，断开时为“0”，反之亦可。若在设计只读存储器掩模版时，就将数据编写在掩模版图形中，光刻时便转移到硅芯片上。这样制备成的称为掩模只读存储器。这种存储器装成整机后，用户只能读取已存入的数据，而不能再编写数据。其优点是适合于大量生产。但是，整机在调试阶段，往往需要修改只读存储器的内容，比较费时、费事，很不灵活（见半导体只读存储器）。串行存储器它的单元排列成一维结构，犹如磁带。首尾部分的读取时间相隔很长，因为要按顺序通过整条磁带。半导体串行存储器中单元也是一维排列，数据按每列顺序读取，如移位寄存器和电荷耦合存储器等。按制造工艺技术的不同，半导体存储器可分成MOS型存储器和双极型存储器两类。70年代以来，NMOS电路(见N沟道金属-氧化物-半导体集成电路）和CMOS电路(见互补金属-氧化物-半导体集成电路)发展最快，用这两者都可做成极高集成度的各种半导体集成存储器。砷化镓半导体存储器如1024位静态随机存储器的读取时间已达2毫秒，预计在超高速领域将有所发展。指令流水线：原理播报编辑举个例子：例如一条指令要执行要经过3个阶段：取指令、译码、执行，每个阶段都要花费一个机器周期，如果没有采用流水线技术，那么这条指令执行需要3个机器周期；如果采用了指令流水线技术，那么当这条指令完成“取指”后进入“译码”的同时，下一条指令就可以进行“取指”了，这样就提高了指令的执行效率。步骤播报编辑指令步骤的并行。常见的六级流水线将指令流的处理过程划分为取指(FI)、译码(DI)、计算操作数地址(CO)、取操作数(FO)、执行指令(EI)、写操作数(WO)等几个并行处理的过程段。这就是指令6级流水时序。在这个流水线中，处理器有六个操作部件，同时对这六条指令进行加工，加快了程序的执行速度。几乎所有的高性能计算机都采用了指令流水线。总线结构：总线结构优点播报编辑（1）组网费用低：从示意图可以看到这样的结构根本不需要另外的互联设备，是直接通过一条总线进行连接，所以组网费用较低；（2）这种网络因为各节点是共用总线带宽的，所以在传输速度上会随着接入网络的用户的增多而下降；（3）网络用户扩展较灵活：需要扩展用户时只需要添加一个接线器即可，但所能连接的用户数量有限；（4）维护较容易：单个节点失效不影响整个网络的正常通信。但是如果总线一断，则整个网络或者相应主干网段就断了。总线结构缺点播报编辑所有的数据都需经过总线传送，总线若出现故障则整个网络就会瘫痪。而且一次仅能一个端用户发送数据，其它端用户必须等待到获得发送权。在EAI中和星型结构相对。总线标准：为了使计算机产品成为全国范围内即插即用的工业化组装件，近几十年来计算机工业界制定了许多工业标准总线。优点明显：确保外设能与任一新计算机相联。定义：1、何谓标准：a、机械结构、尺寸、引脚的分布位置；b、数据线、地址线的宽度，传送规模；c、总线主设备数；d、定时控制方式，同步，异步，半同步。2、常用工业标准总线a、PC总线－－标准的总线IBMPC/-XT20位地址线，8位数据线；IBMPC-AT总线，EISA16位；b、IPI－－IntelligentPeripheralInterface智能外围接口；c、Smallcomputersysteminterface(SCSI)；d、PCI总线(peripheralcomponetInterconnect)由标准化组织制定或行业、大公司提出，而成为行业标准。微机总线发展：ISA（IndustryStandardArchitecture）EISA(ExtendedIndustryStandardArchilecture)内存分配：DOS内存播报编辑基本内存计算机主板上640KB以下的存储空间。DOS的系统程序和用户的应用程序都要使用这片空间。扩展内存(Extended)计算机主板上640KB以上的存储空间。这部分空间DOS不能直接管理，而是要通过扩展内存管理程序HIMEM.SYS来使用这部分内存。扩充内存(Expanded)插在计算机主板的扩充槽中的内存扩充板上的那部分存储器，它们是通过EMS.SYS程序来管理的。保留内存(Reserved)这是给计算机留做存储I/O系统数据及各种接口驱动程序使用的存储器，也称适配器内存。C++的内存分配：根据C++的语法规范，定义数组时数组长度必须用常量而不能用变量表示，此时可以使用动态内存分配解决这一问题。动态内存分配是指在程序运行时为程序中的变量分配内存空间，它完全由应用程序自己进行内存的分配和回收。程序运行时，特别要注意的是内存的分配。有以下六个地方都可以保存数据。存储区域播报编辑寄存器这是最快的保存区域，因为它位于和其他所有保存方式不同的地方：处理器内部。然而，寄存器的数量十分有限，所以寄存器是根据需要由编译器分配。我们对此没有直接的控制权，也不可能在自己的程序里找到寄存器存在的任何踪迹。[1]堆栈驻留于常规RAM（随机访问存储器）区域，但可通过它的“堆栈指针”获得处理的直接支持。堆栈指针若向下移，会创建新的内存；若向上移，则会释放那些内存。这是一种特别快、特别有效的数据保存方式，仅次于寄存器。创建程序时，Java编译器必须准确地知道堆栈内保存的所有数据的“长度”以及“存在时间”。这是由于它必须生成相应的代码，以便向上和向下移动指针。这一限制无疑影响了程序的灵活性，所以尽管有些Java数据要保存在堆栈里——特别是对象句柄，但Java对象并不放到其中。[1]堆一种常规用途的内存池（也在RAM区域），其中保存了Java对象。和堆栈不同，“内存堆”或“堆”（Heap）最吸引人的地方在于编译器不必知道要从堆里分配多少存储空间，也不必知道存储的数据要在堆里停留多长的时间。因此，用堆保存数据时会得到更大的灵活性。要求创建一个对象时，只需用new命令编制相关的代码即可。执行这些代码时，会在堆里自动进行数据的保存。当然，为达到这种灵活性，必然会付出一定的代价：在堆里分配存储空间时会花掉更长的时间！[1]存储方式播报编辑静态存储这儿的“静态”（Static）是指“位于固定位置”（尽管也在RAM里）。程序运行期间，静态存储的数据将随时等候调用。可用static关键字指出一个对象的特定元素是静态的。但Java对象本身永远都不会置入静态存储空间。[1]常数存储常数值通常直接置于程序代码内部。这样做是安全的，因为它们永远都不会改变。有的常数需要严格地保护，所以可考虑将它们置入只读存储器（ROM）。[1]非RAM存储若数据完全独立于一个程序之外，则程序不运行时仍可存在，并在程序的控制范围之外。其中两个最主要的例子便是“流式对象”和“固定对象”。对于流式对象，对象会变成字节流，通常会发给另一台机器。而对于固定对象，对象保存在磁盘中。即使程序中止运行，它们仍可保持自己的状态不变。对于这些类型的数据存储，一个特别有用的技巧就是它们能存在于其他媒体中。一旦需要，甚至能将它们恢复成普通的、基于RAM的对象。[1]控制总线：特点播报编辑控制总线CB（ControlBus）特点是：在单向、双向、双态等种形态，是总线中最复杂、最灵活、功能最强的，其数量、种类、定义随机型不同而不同。分类播报编辑控制总线就是各种信号线的集合，是计算机各部件之间传送数据、地址和控制信息的公共通道。⒈按相对于CPU与其芯片的位置来分：⑴片内总线：指在CPU内部各寄存器、算术逻辑部件ALU，控制部件以及内部高速缓冲存储器之间传输数据所用的总线，即芯片内部总线。⑵片外总线：通常所说的总线（BUS）指的外总线，是CPU与内存RAM、ROM和输入输出输入输出设备接口之间进行通讯的数据通道，CPU通过总线实现程序存取命令，内存/外设的数据交换在CPU与外设一定的情况下，总线速度是限制计算机整体性能的最大因数。⒉按总线功能分：⑴地址总线：（AB）用来传递地址信息。⑵数据总线：（DB）用来传递数据信息。⑶控制总线：（CB）用来传送各种控制信号。⒊按总线的层次结构分：⑴CPU总线：包括CPU地址线（CAB），CPU数据线（CDB）和CPU控制线（CCB），其用来连接CPU和控制芯片。CS31通讯总线⑵存储器总线：包括存储器地址线（MAB）、存储器数据线（MDB）和存储器控制线（MCD），用来连接内存控制器（北桥）和内存。⑶系统总线：（I/O扩展总线）也称为I/O通道总线或I/O扩展总线，包括系统地址线（SAB），系统数据线（SDB）和系统控制线（SCD），用来与I/O扩展槽上的各种扩展卡相连接。⑷外部总线：（外围芯片总线）用来连接各种外设控制芯片，如主板上的I/O控制器（如硬盘接口控制器、软盘驱动控制器、串行/并行接口控制器等），和键盘控制器，包括外部地址线（XAB）、外部数据线（XMB）和外部控制线（XCB）。⒋系统总线（输入输出）扩展总线）又分为ISA、PCI、AGP等多种标准⑴ISA(Industrystandardarchitecture,工业标准结构）是IBM公司为286AT电脑制定的总线工业标准，也称为AT标准。⑵PCI(peripheralcomponentinterconnet,外部设备互连）是SIG（spelialinterestgroup）集团推出的总线结构。⑶AGP(acceleratedgraphicsport，加速图形端口）是一种为了提高视频带宽而设计的总线规范，因为它是点对点连接，即连接控制芯片和AGP显卡，因此严格说来，AGP也是一种接口标准。ISA插槽播报编辑1、地址总线：SA0~SA19(I/O）和LA17~LA23(I/O)LⅪ测试总线技术2、数据总线：SD0~SD7(I/O）和SD8~SD15(I/O)3、控制总线：BALE(0)---USAddresslatchenable：系统地址锁存允许4、SYSCLK(0)---SYSTEMCLOCK系统时钟信号5、IR23~7,9~12,15(Z)---这是用于I/O设备通过中断控制器向CPU发送的中断请求(interruptrequest)信号6、SMEMR#和SMEMW#(0)---这是命令内存将数据送至数据总线的信号7、MEMR#和MEMW#(I/O)---内存读（MEMR）或内存写（MEMW#)信号8、DRQ0~3,5~7⑵---这是DMA请求（DMARequesc）信号9、DACK0#~3,5~7(0)---(DMAAcknowledge,DMA响应）这是对DRQ0~3,5~7的响应信号10、AEN(0)---地址允许（Addressenable）信号11、REFRESH#(I/O)---内存刷新(DRAMrefresh)信号12、SBHE(I/O)---系统总线字节允许（systembushighenable）信号13、MASTER⑵---主控信号14、MEMCS16#⑵---存储器16位片选(Memory16bitchipselect)信号15、ZOCS16#⑵---I/O16位片选(I/O16bitchipselect)信号16、OWS⑵---零等待状态(ZeroWaitState)信号技术指标播报编辑1、总线的带宽（总线数据传输速率）程序总线总线的带宽指的是单位时间内总线上传送的数据量，即每钞钟传送MB的最大稳态数据传输率。与总线密切相关的两个因素是总线的位宽和总线的工作频率，它们之间的关系：总线的带宽=总线的工作频率*总线的位宽/82、总线的位宽总线的位宽指的是总线能同时传送的二进制数据的位数，或数据总线的位数，即32位、64位等总线宽度的概念。总线的位宽越宽，每秒钟数据传输率越大，总线的带宽越宽。3、总线的工作频率总线的工作时钟频率以MHZ为单位，工作频率越高，总线工作速度越快，总线带宽越宽。操作播报编辑总线一个操作过程是完成两个模块之间传送信息，启动操作过程的是主模块，另外一个是从模块。某一时刻总线上只能有一个主模块占用总线。[2]控制总线总线的操作步骤：主模块申请总线控制权，总线控制器进行裁决。数据传送的错误检查：主模块得到总线控制权后寻址从模块，从模块确认后进行数据传送。总线定时协议：定时协议可保证数据传输的双方操作同步，传输正确。定时协议有三种类型：同步总线定时：总线上的所有模块共用同一时钟脉冲进行操作过程的控制。各模块的所有动作的产生均在时钟周期的开始，多数动作在一个时钟周期中完成。异步总线定时：操作的发生由源或目的模块的特定信号来确定。总线上一个事件发生取决前一事件的发生，双方相互提供联络信号。控制总线模型总线定时协议半同步总线定时：总线上各操作的时间间隔可以不同，但必须是时钟周期的整数倍，信号的出现，采样与结束仍以公共时钟为基准。ISA总线采用此定时方法。数据传输类型：分单周方式和突发（burst）方式。单周期方式：一个总线周期只传送一个数据。数据传输类型：突发方式：取得主线控制权后进行多个数据的传输。寻址时给出目的地首地址，访问第一个数据，数据2、3到数据n的地址在首地址基础上按一定规则自动寻址（如自动加1）。标准规范播报编辑总线是一类信号线的集合是模块间传输信息的公共通道，通过它，计算机各部件间可进行各种数据和命令的传送。为使不同供应商的产品间能够互换，给用户更多的选择，总线的技术规范要标准化。总线的标准制定要经周密考虑，要有严格的规定。总线标准（技术规范）包括以下几部分：机械结构规范：模块尺寸、总线插头、总线接插件以及安装尺寸均有统一规定。功能规范：总线每条信号线（引脚的名称）、功能以及工作过程要有统一规定。电气规范：总线每条信号线的有效电平、动态转换时间、负载能力等。指令：汉语词语播报编辑详细解释1.指示命令。唐韩愈《魏博节度使沂国公先庙碑铭》：“号登元和，大圣载营。风挥日舒，咸顺指令。”元柳贯《浦阳十咏·昭灵仙迹》：“真仙帝遣司风雨，唤起渊龙听指令。”陈世旭《小镇上的将军》：“立刻就传来了上面的指令，将军的遗体就地火葬。”孔羽《睢县文史资料·袁氏陆园》：“袁家山（袁可立别业），……1949年，睢县人民政府指令于此处集存各种文物，并派有专人看守。”朱长超《月亮上的足迹》：地面站停止对他们发出指令，以免干扰他们的好梦。2.下行公文的一种。对下级机关有所指示时用之。《新华日报》1943.9.18：“在次长的办公桌上，有电话机，来往的公事信。一切的指令、计划、方案与文件。”3.指定电子计算机实现某种控制或运算的代码。包括操作功能和操作对象等内容。(1)∶指导;号令(2)∶旧时公文的一种,是上级对下级呈请的批示(3)∶能被计算机识别并执行的二进制代码，它规定了计算机能完成的某一操作。告诉计算机从事某一特殊运算的代码合算:指令种类：数据传送指令、算术运算指令、位运算指令、程序流程控制指令、串操作指令、处理器控制指令。4.指令，指基金管理人在管理基金资产时，向基金托管人发出的资金划拨及实物券调拨等指令。信息技术名词播报编辑基本概念告诉计算机从事某一特殊运算的代码。计算机程序发给计算机处理器的命令就是“指令（instruction）”。最低级的指令是一串0和1，表示一项实体作业操作要运行（如“Add”）。根据指令类型，某个具体的存储领域被称作“寄存器（register）”，里面包含了可用于调出指令的数据或数据存储位置。计算机的汇编语言（assembler）中，每种语言一般只响应单一的处理器指令。而高级语言的每种语言经过程序编辑后能响应多个处理器指令。在汇编语言中，宏指令（macroinstruction）在汇编程序处理过程中会扩展为多个指令（以编码过的源宏定义为基础）。[1]组成形式指令是指示计算机执行某种操作的命令。它由一串二进制数码组成。一条指令通常由两个部分组成：操作码+地址码。操作码：指明该指令要完成的操作的类型或性质，如取数、做加法或输出数据等。地址码：指明操作对象的内容或所在的存储单元地址。宏指令:宏指令是汇编语言程序中的一种伪指令它的格式为[宏指令名]MACRO[形式参数]……代码段……ENDM使用了“形式参数“，它们引用宏指令时被给出的一些名字或数值(实在参数)所替换。使用形式参数给宏指令带来了很大的灵活性。宏调用格式[宏指令名][实际参数]实参数项将对应替换宏指令中形式参数。如果形式参数为标号时，则在宏调用中，实参也应为标号，且要求实参是唯一的。如果宏定义中有自己的标号，则在宏调用时，汇编程序自动地把标号变成唯一的标号.相关词语播报编辑伪指令:伪指令(伪操作)不像机器指令那样是在程序运行期间由计算机来执行的,它是在汇编程序对源程序汇编期间由汇编程序处理的操作.它可以完成如处理器选择,定义程序模式,定义数据,分配存储区,指示程序结束等功能.伪指令在编译的时候并不生成代码．伪指令在编译之后就不存在了搜索引擎指令播报编辑inurl命令用inurl搜索命令可以帮你搜索到在URL当中出现你搜索的关键词，很有针对性。使用格式：inurl:（+你需要搜索的内容）filetype命令在搜索引擎里面用filetype命令是可以帮助你打到相关的文档的，精确，特别是在百度推出了文库后，这个命令就更加好用啦site命令site命令用得多的一般是一些站长，他们用这个命令可以来查询某个域名被搜索引擎收录的情况，这样有利于自己对自身网站的了解和网站对搜索引擎的友好度等等使用格式：site:+域名intitle命令intitle命令顾名思义就是搜索标题的意思，在这里也对，我们有时搜索一个关键词时有上千万的内容，用这个命令就可以帮我们把跟我们搜索相关的网页排到前面。使用格式：intitle:+搜索内容[2]数据：定义播报编辑数据是指对客观事件进行记录并可以鉴别的符号，是对客观事物的性质、状态以及相互关系等进行记载的物理符号或这些物理符号的组合。它是可识别的、抽象的符号。它不仅指狭义上的数字，还可以是具有一定意义的文字、字母、数字符号的组合、图形、图像、视频、音频等，也是客观事物的属性、数量、位置及其相互关系的抽象表示。例如，“0、1、2…”、“阴、雨、下降、气温”、“学生的档案记录、货物的运输情况”等都是数据。数据经过加工后就成为信息。在计算机科学中，数据是所有能输入计算机并被计算机程序处理的符号的介质的总称，是用于输入电子计算机进行处理，具有一定意义的数字、字母、符号和模拟量等的通称。计算机存储和处理的对象十分广泛，表示这些对象的数据也随之变得越来越复杂。[1]信息信息与数据既有联系，又有区别。数据是信息的表现形式和载体，可以是符号、文字、数字、语音、图像、视频等。而信息是数据的内涵，信息是加载于数据之上，对数据作具有含义的解释。数据和信息是不可分离的，信息依赖数据来表达，数据则生动具体表达出信息。数据是符号，是物理性的，信息是对数据进行加工处理之后所得到的并对决策产生影响的数据，是逻辑性和观念性的；数据是信息的表现形式，信息是数据有意义的表示。数据是信息的表达、载体，信息是数据的内涵，是形与质的关系。数据本身没有意义，数据只有对实体行为产生影响时才成为信息。[2]数据的语义播报编辑数据的表现形式还不能完全表达其内容，需要经过解释，数据和关于数据的解释是不可分的。例如，93是一个数据，可以是一个同学某门课的成绩，也可以是某个人的体重，还可以是计算机系2013级的学生人数。数据的解释是指对数据含义的说明，数据的含义称为数据的语义，数据与其语义是不可分的。分类播报编辑按性质分为①定位的，如各种坐标数据；②定性的，如表示事物属性的数据（居民地、河流、道路等）；③定量的，反映事物数量特征的数据，如长度、面积、体积等几何量或重量、速度等物理量；④定时的，反映事物时间特性的数据，如年、月、日、时、分、秒等。按表现形式分为①数字数据，如各种统计或量测数据。数字数据在某个区间内是离散的值[3]；②模拟数据，由连续函数组成，是指在某个区间连续变化的物理量，又可以分为图形数据（如点、线、面）、符号数据、文字数据和图像数据等，如声音的大小和温度的变化等。按记录方式分为地图、表格、影像、磁带、纸带。按数字化方式分为矢量数据、格网数据等。在地理信息系统中，数据的选择、类型、数量、采集方法、详细程度、可信度等，取决于系统应用目标、功能、结构和数据处理、管理与分析的要求。现状与发展播报编辑大数据经济即将进入数据资本时代。数据成为与土地、劳动力、资本、技术等传统要素并列的生产要素，加快培育数据要素市场势在必行。同时，在大数据技术推动下，个人信息的应用已经由商业和经济领域，逐步扩大到政治、社会治理和公共政策等领域，并给公民的政治生活和国家的网络安全与主权等带来越来越大的影响。目前，我国已经初步建立了与国际基本接轨的个人信息保护法律体系，有些行政区域业已开始了数据要素市场的实践，意在形成系列创新安排。[4]中国前瞻产业研究院2020年8月发布的《2020年中国数字经济发展报告》显示，自2015年提出“国家大数据战略”以来，我国的数字经济市场规模迅速扩大，截至2019年末，数字经济的总体规模达到了35.8亿元，占GDP的36.2%。[5]2021年上海数据交易所成立，其面向全球开展大数据综合交易，这“可能是第4次工业革命的变革性事件之一”。[4]数据知识产权播报编辑2022年11月17日，北京市、上海市、江苏省、浙江省、福建省、山东省、广东省、深圳市等8个地方被国家知识产权局办公室确定为开展数据知识产权工作的试点地方，试点工作期限为2022年11月至2023年12月[6]。参考书籍播报编辑数据赋能书名：数据赋能作者：宋星出版社：电子工业出版社出版时间：2021-01-01开本：16开GPRs：介绍播报编辑移动通信技术从第一代的模拟通信系统发展到第二代的数字通信系统，以及之后的3G、4G、5G，正以突飞猛进的速度发展。在第二代移动通信技术中，GSM的应用最广泛。但是GSM系统只能进行电路域的数据交换，且最高传输速率为9.6kbit/s，难以满足数据业务的需求。因此，欧洲电信标准委员会（ETSI）推出了GPRS（GeneralPacketRadioService，通用分组无线业务）。分组交换技术是计算机网络上一项重要的数据传输技术。为了实现从传统语音业务到新兴数据业务的支持，GPRS在原GSM网络的基础上叠加了支持高速分组数据的网络，向用户提供WAP浏览（浏览因特网页面）、E-mail等功能，推动了移动数据业务的初次飞跃发展，实现了移动通信技术和数据通信技术（尤其是Internet技术）的完美结合。GPRS是介于2G和3G之间的技术，也被称为2.5G。它后面还有个弟弟EDGE，被称为2.75G。它们为实现从GSM向3G的平滑过渡奠定了基础。GPRS的功能GPRS主要是在移动用户和远端的数据网络(如支持TCP/IP、X.25等网络)之间提供一种连接，从而给移动用户提供高速无线IP和无线X.25业务，它将使得通讯速率从56kbPs一直上升到114kbPs，以GPRs为技术支撑，可为实现电子邮件、电子商务、移动办公、网上聊天、基于认钱P的信息浏览、互动游戏、FLASH画面、多和弦铃声、PDA终端接入、综合定位技术等，并且支持计算机和移动用户的持续连接[l]。较高的数据吞吐能力使得可以使用手持设备和笔记本电脑电脑进行电视会议和多媒体页面以及类似的应用。GPRS可以让多个用户共享某些固定的信道资源，数据速率最高可达164kb/8。具有人类特性的PDA，边打电话边在网上冲浪;(2)GPRSB类手机如果MS能同时侦听两个系统的寻呼信息，MS可以同时附着在GSM系统和GPRS系统;(3)GPRSC类手机MS要么附着在GSM网络，要么附着在GPRS网络。它只能通过人工的方式进行切换，没有办法同时进行两种操作。[2]GPRS的网络结构播报编辑GPRS是在GSM网络的基础上增加新的网络实体来实现分组数据业务，网络结构如图1所示。图2GPRS网络结构图图1图2GPRS新增的网络实体：1）GSN（GPRSSupportNode，GPRS支持节点）GSN是GPRS网络中最重要的网络部件，有SGSN何GGSN两种类型。SGSN（ServingGPRSSupportNode，服务GPRS支持节点）SGSN的主要作用是记录MS的当前位置信息，提供移动性管理和路由选择等服务，并且在MS和GGSN之间完成移动分组数据的发送和接收。GGSN（GatewayGPRSSupportNode，GPRS网关支持节点）GGSN起网关作用，把GSM网络中的分组数据包进行协议转换，之后发送到TCP/IP或X.25网络中。2）PCU（PacketControlUnit，分组控制单元）PCU位于BSS，用于处理数据业务，并将数据业务从GSM语音业务中分离出来。PCU增加了分组功能，可控制无线链路，并允许多用户占用同一无线资源。3）BG（BorderGateways，边界网关）BG用于PLMN间GPRS骨干网的互连，主要完成分属不同GPRS网络的SGSN、GGSN之间的路由功能，以及安全性管理功能，此外还可以根据运营商之间的漫游协定增加相关功能。4）CG（ChargingGateway，计费网关）CG主要完成从各GSN的话单收集、合并、预处理工作，并用作GPRS与计费中心之间的通信接口。5）DNS（DomainNameServer，域名服务器）GPRS网络中存在两种DNS。一种是GGSN同外部网络之间的DNS，主要功能是对外部网络的域名进行解析，作用等同于因特网上的普通DNS。另一种是GPRS骨干网上的DNS，主要功能是在PDP上下文激活过程中根据确定的APN（AccessPointName，接入点名称）解析出GGSN的IP地址，并且在SGSN间的路由区更新过程中，根据原路由区号码，解析出原SGSN的IP地址。[3]GPRS的关键指标播报编辑1）容量指标①PDCH分配成功率PDCH分配成功率=（1-分配失败次数/分配尝试次数）×100%该指标反映了信道的拥塞情况，用来反映当符合信道分配条件，PCU将TCH用做PDCH的成功率。②每兆字节PDCH被清空次数每兆字节PDCH被清空次数=使用状态下的PDCH被清空次数/忙时流量该指标反映了全部信道（TCH、PDCH）的拥塞情况。③PCU资源拥塞率PCU资源拥塞率=PCU资源不足造成的信道分配失败次数/分配尝试次数×100%该指标反映了PCU的公共设备资源是否存在不足。④忙时平均激活PDCH数该指标反映了小区或BSC内PDCH数量，与TCH资源相比可以反映出PDCH占用无线资源的比例。⑤忙时数据总流量分为上行流量和下行流量，下行流量更能反映业务量的情况。⑥忙时每PDCH负荷忙时每PDCH负荷=忙时数据总流量/忙时平均激活PDCH数该指标反映了每个PDCH单位时间承载的数据量。这个指标要控制在4kbit/s以下。2）干扰指标①C/I②下行BLER③上行BLER3）移动性能指标①每兆字节小区重选次数=小区重选次数/忙时流量②短时间重选率=短时间小区重选次数/小区重选总次数×100%③乒乓重选率=乒乓重选次数/小区重选总次数×100%特点播报编辑应用上的特点手机上网还显得有些不尽人意。因此，全面的解决方法GPRS也就这样应运而生了，这项全新技术可以令您在任何时间、任何地点都能快速方便地实现连接，同时费用又很合理。简单地说：速度上去了，内容丰富了，应用增加了，而费用却更加合理。(1)高速数据传输gprs远程集中抄表系统速度10倍于GSM，还可以稳定地传送大容量的高质量音频与视频文件，可谓不一般的巨大进步。(2)永远在线由于建立新的连接几乎无需任何时间(即无需为每次数据的访问建立呼叫连接)，因而您随时都可与网络保持联系，举个例子，若无GPRS的支持，当您正在网上漫游，而此时恰有电话接入，大部分情况下您不得不断线后接通来电，通话完毕后重新拨号上网。这对大多数人来说，的确是件非常令人恼火的事。而有了GPRS，您就能轻而易举地解决这个冲突。(3)仅按数据流量计费即根据您传输的数据量(如：网上下载信息时)来计费，而不是按上网时间计费也就是说，只要不进行数据传输，哪怕您一直“在线”，也无需付费。做个“打电话”的比方，在使用GSM+WAP手机上网时，就好比电话接通便开始计费；而使用GPRS+WAP上网则要合理得多，就像电话接通并不收费，只有对话时才计算费用。总之，它真正体现了少用少付费的原则。技术上的特点数据实现分组发送和接收，按流量计费；56~115Kbps的传输速度.GPRS的应用，迟些还会配合Bluetooth(蓝牙技术)的发展。到时，数码相机加了bluetooth，就可以马上通过手机，把像片传送到遥远的地方，也不过一刻钟的时间，够酷吧，这个日子将距离我们不远了。GPRS是基本分组无线业务，采用分组交换的方式，数据速率最高可达164kbit/s，它可以给GSM用户提供移动环境下的高速数据业务，还可以提供收发Email、Internet创览等功能。[4]在连接建立时间方面，GSM需要10-30秒，而GPRS只需要极短的时间就可以访问到相关请求；而对于费用而言，GSM是按连接时间计费的，而GPRS只需要按数据流量计费；GPRS对于网络资源的利用率而相对远远高于GSM。对应的范围1.移动办公2.移动商务3.移动信息服务4.移动互联网5.多媒体业务技术优势播报编辑（1）相对低廉的连接费用GPRS节水灌溉测控终端资源利用率高在GSM网络中，GPRS首先引入了分组交换的传输模式，使得原来采用电路交换模式的GSM传输数据方式发生了根本性的变化，这在无线资源稀缺的情况下显得尤为重要。按电路交换模式来说，在整个连接期内，用户无论是否传送数据都将独自占有无线信道。在会话期间，许多应用往往有不少的空闲时段，如上Internet浏览、收发E-mail等等。对于分组交换模式，用户只有在发送或接收数据期间才占用资源，这意味着多个用户可高效率地共享同一无线信道，从而提高了资源的利用率。GPRS用户的计费以通信的数据量为主要依据，体现了“得到多少、支付多少”的原则。实际上，GPRS用户的连接时间可能长达数小时，却只需支付相对低廉的连接费用。（2）传输速率高GPRS可提供高达115kbps的传输速率（最高值为171.2kbps，不包括FEC）。这意味着在数年内，通过便携式电脑，GPRS用户能和ISDN用户一样快速地上网浏览，同时也使一些对传输速率敏感的移动多媒体应用成为可能。（3）接入时间短分组交换接入时间缩短为少于1GPRS是一种新的GSM数据业务，它可以给移动用户提供无线分组数据接入股务。数据速率最高可达164kb/8.GSM空中接口的信道资源既可以被话音占用，也可以被GPRS数据业务占用。当然在信道充足的条件下，可以把一些信道定义为GPRS专用信道。要实现GPRS网络，需要在传统的GSM网络中引入新的网络接口和通信协议。GPRS网络引入GSN（GPRSSurportingNode）节点。移动台则必须是GPRS移动台或GPRS/GSM双模移动台。服务播报编辑GPRS提升GSM的数据服务性能:GPRS点到点(P2P)服务:连接(IPprotocols)IP网络andX.25网络。多播(P2MP)服务:一点到多点的组播和多方通话。短信服务(SMS):发送SMS。多媒体短信(MMS):发送携带语音和图像信息的短消息。因特网服务提供商服务:提供互联网内容服务。邮件服务通过POP3或者IMAP协议检查阅读发送电子邮件匿名服务:匿名访问预定服务未来功能:灵活加入新的功能，例如更大容量，更多用户，新的资源和无线网络。业务介绍播报编辑入门指南GPRS即“通用分组无线业务”（GeneralPacketRadioService的英文简称），是在现有GSM网络上开通的一种新型的分组数据传输技术。相对于原来GSM以拨号接入的电路交换数据传送方式，GPRS是分组交换技术，具有“永远在线”、“自如切换”、“高速传输”等优点，它能全面提升移动数据通信服务，使“移动梦网”服务更丰富、功能更强大，给您的生活和工作带来更多便捷与实惠。以GPRS为技术支撑，可为您实现诸如：电子邮件、电子商务、移动办公、网上聊天、基于WAP的信息浏览、互动游戏、FLASH画面、多和弦铃声、PDA终端接入、综合定位技术等，从而带您进入一个动感而彩色的移动世界，引领您尽快迈向3G时代。GPRS将是通向3G的一个重要里程碑。迄今为止,移动通信的发展还是围绕话音(话音质量和漫游范围)进行的。对非话音通信的需求仍处于初期阶段,但正稳步上升,短消息(SMS)业务量的迅速增长正说明了这一点。与此同时,国际互联网的迅猛增长,为基于网页内容的服务拓展了机遇,且很可能在下一代网络中占据支配地位。新型无线数据服务的预期需求令GSM运营商对运营环境中的重大变革充满期望。[5]业务优势广域覆盖：GPRS在全国31个省240多个城市均有良好覆盖，基本上在手机可以打电话的地方都可以通过GPRS无线上网；永远在线：只要激活GPRS应用后，将一直保持在线，类似于无线专线网络服务。按量计费：GPRS服务虽然保持一直在线，但您不必担心费用问题；因为只有产生通信流量时才计费。高速传输：GPRS可支持53.6Kbps的峰值传输速率，理论峰值传输可达100余Kbps。业务丰富：彩信、WAP掌上资讯、金融交易、游戏百宝箱，丰富多彩的业务应用涉及人们生活的各个领域。（注：与手机支持情况和网络情况有关）设置全攻略市场上具有GPRS功能的手机品种相当丰富，而且多数GPRS手机具备“一键上网”功能，您无需进行设置，即可轻松使用，希望您在购买时选择带有GPRS“一键上网”功能的手机。如果您的GPRS手机不具备“一键上网”功能，可按照下述步骤进行设置，操作同样非常简单：APN的含义APN(AccessPointName)，即“接入点名称”，用来标识GPRS的业务种类，分为两大类：CMWAP(通过GPRS访问WAP业务)、CMNET（除了WAP以外的服务都用CMNET,比如连接因特网等）。连接配置选择GPRS方式连接：连接1：接入点名称为CMNET，用户名、密码均为空――主要用于访问因特网或java下载等；连接2：接入点名称为CMWAP，用户名、密码均为空――主要用于访问“移动梦网”WAP。其他通用配置在手机或PC中的进行其他参数配置，如：对于连接因特网需要在PC端配置、电子邮件要配置自己的POP和SMTP、WAP配置与其他WAP手机的配置一样。设置举例NOKIA6610、6100、7200、7250选择进入“服务”菜单，选择“设置”――>选择“修改服务设置”：进入修改服务设置屏幕，分别输入相关信息：“设置组名称”设为“移动梦网GPRS”“连接类型”设为“持续连接”“安全保护”设为“关”“传输方式”设为“GPRS”“GPRS接入点”设为“CMWAP”“IP地址”设为“10.0.0.172”“鉴权类型”设为“普通”“登录类型”设为“自动”“用户名”和“密码”不用设置输入完毕按返回退到待机状态在待机状态下，按“功能表”选择“服务”并进入“主页”后即可登录移动梦网主页玩转GPRSGPRS全面支持随e行业务，随时随处实现移动办公：将带有GPRS功能的SIM卡插入GPRS无线网卡中，再与移动终端（笔记本电脑或PDA）相连接，就可实现无线上网，并可以收发短信。当然也可将GPRS手机通过数据线与笔记本电脑串口相连（或经过USB、红外等端口相连接）通过GPRS访问因特网。GPRS可支持50多K的峰值传输速率，广域覆盖、随时在线等特点的发挥可使您感受随时随处的移动办公。通过GPRS使用手机WAP服务GPRS可大大提升原有WAP服务的品质，访问速度大大提升，费用更加经济，可实现新闻浏览、随身理财、移动办公、更可支持多种彩色、动感的图片、游戏等服务（需要手机支持）。收发彩信，乐趣无穷：拿出您的彩信手机通过GPRS可享受丰富多彩的彩信服务：卡通、明星、漫画、游戏等多姿多彩的彩信壁纸，还有动感十足的彩信动画任您下载。用带有摄像头的彩信手机拍下生活中的精彩画面通过GPRS发送给亲友，更是乐趣无穷！下载“移动百宝箱”中的精彩内容：使用支持JAVA功能的手机，通过GPRS方式进入“移动百宝箱”，方便地下载娱乐、生活、商务、游戏等方面的精彩内容。如下载各种棋牌游戏、电子书籍、股票证券信息、天气预报、聊天交友等。企业和行业应用：专线接入GPRS网络，实现高服务质量等级的专有服务。遥感、监测、定位等信息通过GPRS，方便的进行无线接入和传输。业务办理使用条件（1）手机支持GPRS功能。（2）全球通客户已申请开通GPRS功能。（3）在手机上正确设置GPRS参数。（4）处在GPRS网络覆盖范围内。业务办理全球通移动电话客户可以拨打客户服务热线10086或持有效身份证件到号码归属地移动各营业厅及合作厅办理开通、取消、变更GPRS业务。也可登陆号码归属地移动网站进行网上办理。漫游服务国内漫游：注：GPRS已实现北京全市覆盖，另支持国内31省240多个市的漫游服务附录：GPRS支持的漫游城市举例北京、上海、天津、重庆、沈阳、大连、济南、青岛、石家庄、郑州、武汉、南京、杭州、宁波、温州、成都、南宁、广州、深圳、福州、厦门、海口、三亚、合肥、长沙、西安、兰州、乌鲁木齐、西宁、昆明、银川、呼和浩特、贵阳、南昌、太原、拉萨、哈尔滨、长春国际漫游GPRS已实现美国、法国、新加坡、台湾、香港、澳门等地的国际漫游。部分漫游国家和地区运营商及资费列表（资费仅供参考，以当地运营商公布最新资费为准）页面置换算法：常见的置换算法播报编辑最佳置换算法（OPT）这是一种理想情况下的页面置换算法，但实际上是不可能实现的。该算法的基本思想是：发生缺页时，有些页面在内存中，其中有一页将很快被访问（也包含紧接着的下一条指令的那页），而其他页面则可能要到10、100或者1000条指令后才会被访问，每个页面都可[1]以用在该页面首次被访问前所要执行的指令数进行标记。最佳页面置换算法只是简单地规定：标记最大的页应该被置换。这个算法唯一的一个问题就是它无法实现。当缺页发生时，操作系统无法知道各个页面下一次是在什么时候被访问。虽然这个算法不可能实现，但是最佳页面置换算法可以用于对可实现算法的性能进行衡量比较。[1]先进先出置换算法（FIFO）最简单的页面置换算法是先入先出（FIFO）法。这种算法的实质是，总是选择在主存中停留时间最长（即最老）的一页置换，即先进入内存的页，先退出内存。理由是：最早调入内存的页，其不再被使用的可能性比刚调入内存的可能性大。建立一个FIFO队列，收容所有在内存中的页。被置换页面总是在队列头上进行。当一个页面被放入内存时，就把它插在队尾上。[1]这种算法只是在按线性顺序访问地址空间[1]时才是理想的，否则效率不高。因为那些常被访问的页，往往在主存中也停留得最久，结果它们因变“老”而不得不被置换出去。FIFO的另一个缺点是，它有一种异常现象，即在增加存储块的情况下，反而使缺页中断率增加了。当然，导致这种异常现象的页面走向实际上是很少见的。[1]最近最久未使用（LRU）算法FIFO算法和OPT算法之间的主要差别是，FIFO算法利用页面进入内存后的时间长短作为置换依据，而OPT算法的依据是将来使用页面的时间。如果以最近的过去作为不久将来的近似，那么就可以把过去最长一段时间里不曾被使用的页面置换掉。它的实质是，当需要置换一页时，选择在之前一段时间里最久没有使用过的页面予以置换。这种算法就称为最久未使用算法（LeastRecentlyUsed，LRU）。[1]LRU算法是与每个页面最后使用的时间有关的。当必须置换一个页面时，LRU算法选择过去一段时间里最久未被使用的页面。[1]LRU算法是经常采用的页面置换算法，并被认为是相当好的，但是存在如何实现它的问题。LRU算法需要实际硬件的支持。其问题是怎么确定最后使用时间的顺序，对此有两种可行的办法：[1]1.计数器。最简单的情况是使每个页表项对应一个使用时间字段，并给CPU增加一个逻辑时钟或计数器。每次存储访问，该时钟都加1。每当访问一个页面时，时钟寄存器的内容就被复制到相应页表项的使用时间字段中。这样我们就可以始终保留着每个页面最后访问的“时间”。在置换页面时，选择该时间值最小的页面。这样做，[1]不仅要查页表，而且当页表改变时（因CPU调度）要[1]维护这个页表中的时间，还要考虑到时钟值溢出的问题。2.栈。用一个栈保留页号。每当访问一个页面时，就把它从栈中取出放在栈顶上。这样一来，栈顶总是放有目前使用最多的页，而栈底放着目前最少使用的页。由于要从栈的中间移走一项，所以要用具有头尾指针的双向链连起来。在最坏的情况下，移走一页并把它放在栈顶上需要改动6个指针。每次修改都要有开销，但需要置换哪个页面却可直接得到，用不着查找，因为尾指针指向栈底，其中有被置换页。[1]因实现LRU算法必须有大量硬件支持，还需要一定的软件开销。所以实际实现的都是一种简单有效的LRU近似算法。[1]一种LRU近似算法是最近未使用算法（NotRecentlyUsed，NRU）。它在存储分块表的每一表项中增加一个引用位，操作系统定期地将它们置为0。当某一页被访问时，由硬件将该位置1。过一段时间后，通过检查这些位可以确定哪些页使用过，哪些页自上次置0后还未使用过。就可把该位是0的页淘汰出去，因为在之前最近一段时间里它未被访问过。[1]Clock置换算法采用Clock算法时,只需为每个页面设置一位访问位，再将内存中的所有页面都通过链接指针链接成一个循环队列。当某页被访问时,就将其访问位被置为1。置换算法在选择一页淘汰时，只检查页的访问位。如果改位是0,就选择该页换出;如果是1,则重新将它置0,暂不换出，而给该页第二次驻留内存的机会,再按照FIFO算法检查下一个页面。当检查到队列中的最后一个页面时，若其访问位仍为1,则再返回到队首去检查第一个页面。由于该算法是循环地检查各页面的使用情况,故称为Clock算法。[3]最少使用（LFU）置换算法在采用最少使用置换算法时，应为在内存中的每个页面设置一个移位寄存器，用来记录该页面被访问的频率。该置换算法选择在之前时期使用最少的页面作为淘汰页。由于存储器具有较高的访问速度，例如100ns，在1ms时间内可能对某页面连续访[1]问成千上万次，因此，通常不能直接利用计数器来记录某页被访问的次数，而是采用移位寄存器方式。每次访问某页时，便将该移位寄存器的最高位置1，再每隔一定时间(例如100ns)右移一次。这样，在最近一段时间使用最少的页面将是∑Ri最小的页。[1][3]LFU置换算法的页面访问图与LRU置换算法的访问图完全相同；或者说，利用这样一套硬件既可实现LRU算法，又可实现LFU算法。应该指出，LFU算法并不能真正反映出页面的使用情况，因为在每一时间间隔内，只是用寄存器的一位来记录页的使用情况，因此，访问一次和访问10000次是等效的。[3]6）工作集算法[1]7）工作集时钟算法8）老化算法（非常类似LRU的有效算法）[1]9）NRU(最近未使用）算法10）第二次机会算法第二次机会算法的基本思想是与FIFO相同的，但是有所改进，避免把经常使用的页面置换出去。当选择置换页面时，检查它的访问位。如果是[1]0，就淘汰这页；如果访问位是1，就给它第二次机会，并选择下一个FIFO页面。当一个页面得到第二次机会时，它的访问位就清为0，它的到达时间就置为当前时间。如果该页在此期间被访问过，则访问位置1。这样给了第二次机会的页面将不被淘汰，直至所有其他页面被淘汰过（或者也给了第二次机会）。因此，如果一个页面经常使用，它的访问位总保持为1，它就从来不会被淘汰出去。[1]第二次机会算法可视为一个环形队列。用一个指针指示哪一页是下面要淘汰的。当需要一个[1]存储块时，指针就前进，直至找到访问位是0的页。随着指针的前进，把访问位就清为0。在最坏的情况下，所有的访问位都是1，指针要通过整个队列一周，每个页都给第二次机会。这时就退化成FIFO算法了。[1]操作系统页面置换算法代码播报编辑#include<stdio.h>[2]#include<stdlib.h>#include<unistd.h>#defineTRUE1#defineFALSE0#defineINVALID-1#defineNUL0#definetotal_instruction320/*指令流长*/#definetotal_vp32/*虚页长*/#defineclear_period50/*清零周期*/typedefstruct{/*页面结构*/intpn,pfn,counter,time;}pl_type;pl_typepl[total_vp];/*页面结构数组*/structpfc_struct{/*页面控制结构*/intpn,pfn;structpfc_struct*next;};typedefstructpfc_structpfc_type;pfc_typepfc[total_vp],*freepf_head,*busypf_head,*busypf_tail;intdiseffect,a[total_instruction];intpage[total_instruction],offset[total_instruction];voidinitialize(int);voidFIFO(int);voidLRU(int);voidNUR(int);intmain(){intS,i;srand((int)getpid());S=(int)rand()%390;for(i=0;i<total_instruction;i+=1)/*产生指令队列*/{a[i]=S;/*任选一指令访问点*/a[i+1]=a[i]+1;/*顺序执行一条指令*/a[i+2]=(int)rand()%390;/*执行前地址指令m’*/a[i+3]=a[i+2]+1;/*执行后地址指令*/S=(int)rand()%390;}for(i=0;i<total_instruction;i++)/*将指令序列变换成页地址流*/{page[i]=a[i]/10;offset[i]=a[i]%10;}for(i=4;i<=32;i++)/*用户内存工作区从4个页面到32个页面*/{printf("%2dpageframes",i);FIFO(i);LRU(i);NUR(i);printf("\n");}return0;}voidFIFO(inttotal_pf)/*FIFO(FirstinFirstout)ALGORITHM*//*用户进程的内存页面数*/{inti;pfc_type*p,*t;initialize(total_pf);/*初始化相关页面控制用数据结构*/busypf_head=busypf_tail=NUL;/*忙页面队列头，对列尾链接*/for(i=0;i<total_instruction;i++){if(pl[page[i]].pfn==INVALID)/*页面失效*/{diseffect+=1;/*失效次数*/if(freepf_head==NUL)/*无空33闲页面*/{p=busypf_head->next;pl[busypf_head->pn].pfn=INVALID;/*释放忙页面队列中的第一个页面*/freepf_head=busypf_head;freepf_head->next=NUL;busypf_head=p;}p=freepf_head->next;/*按方式调新页面入内存页面*/freepf_head->next=NUL;freepf_head->pn=page[i];pl[page[i]].pfn=freepf_head->pfn;if(busypf_tail==NUL)busypf_head=busypf_tail=freepf_head;else{busypf_tail->next=freepf_head;busypf_tail=freepf_head;}freepf_head=p;}}printf("FIFO:%6.4F",1-(float)diseffect/320);}voidLRU(inttotal_pf){intmin,minj,i,j,present_time;initialize(total_pf);present_time=0;for(i=0;i<total_instruction;i++){if(pl[page[i]].pfn==INVALID)/*页面失效*/{diseffect++;if(freepf_head==NUL)/*无空闲2页面*/{min=32767;for(j=0;j<total_vp;j++)if(min>pl[j].time&&pl[j].pfn!=INVALID){min=pl[j].time;minj=j;}freepf_head=&pfc[pl[minj].pfn];pl[minj].pfn=INVALID;pl[minj].time=-1;freepf_head->next=NUL;}pl[page[i]].pfn=freepf_head->pfn;pl[page[i]].time=present_time;freepf_head=freepf_head->next;}elsepl[page[i]].time=present_time;present_time++;}printf("LRU:%6.4f",1-(float)diseffect/320);}voidNUR(inttotal_pf){inti,j,dp,cont_flag,old_dp;pfc_type*t;initialize(total_pf);dp=0;for(i=0;i<total_instruction;i++){if(pl[page[i]].pfn==INVALID)/*页面失效*/{diseffect++;if(freepf_head==NUL)/*无空闲1页面*/{cont_flag=TRUE;old_dp=dp;while(cont_flag)if(pl[dp].counter==0&&pl[dp].pfn!=INVALID)cont_flag=FALSE;else{dp++;if(dp==total_vp)dp=0;if(dp==old_dp)for(j=0;j<total_vp;j++)pl[j].counter=0;}freepf_head=&pfc[pl[dp].pfn];pl[dp].pfn=INVALID;freepf_head->next=NUL;}pl[page[i]].pfn=freepf_head->pfn;freepf_head=freepf_head->next;}elsepl[page[i]].counter=1;if(i%clear_period==0)for(j=0;j<total_vp;j++)pl[j].counter=0;}printf("NUR:%6.4f",1-(float)diseffect/320);}voidinitialize(inttotal_pf)/*初始化相关数据结构*//*用户进程的内存页面数*/{inti;diseffect=0;for(i=0;i<total_vp;i++){pl[i].pn=i;pl[i].pfn=INVALID;/*置页面控制结构中的页号，页面为空*/pl[i].counter=0;pl[i].time=-1;/*页面控制结构中的访问次数为0，时间为-1*/}for(i=1;i<total_pf;i++){pfc[i-1].next=&pfc[i];pfc[i-1].pfn=i-1;/*建立pfc[i-1]和pfc[i]之间的连接*/}pfc[total_pf-1].next=NUL;pfc[total_pf-1].pfn=total_pf-1;freepf_head=&pfc[0];/*页面队列的头指针为pfc[0]*/}/*说明：本程序在Linux的gcc下和c-free下编译运行通过*/地址总线：基本信息播报编辑地址总线（AddressBus）是一种计算机总线，是CPU或有DMA能力的单元，用来沟通这些单元想要访问（读取/写入）计算机内存组件/地方的物理地址。[1]数据总线的宽度，随可寻址的内存组件大小而变，决定有多少的内存可以被访问。举例来说：一个16位元宽度的位址总线(通常在1970年和1980年早期的8位元处理器中使用)到达2的16次方=65536=64KB的内存位址，而一个32位单元位址总线(通常在像现今2004年的PC处理器中)可以寻址到4,294,967,296=4GB的位址。但现在很多计算机内存已经大于4G（windowsXPx32位系统最大只能识别3.29G，所以要使用4G以上大内存就要用windowsx64位系统）。所以主流的计算机都是64位的处理器也就是说可以寻址到2^64=16X10^18=16EB的位址，在很长一段时间内这个数字是用不完的。在大多数的微电脑(微计算机)中，可寻址的元件都是8位元的"字节"(所以"K"在这情况像相等于"KB"或kilobyte)，有很多的电脑例子是以更大的资料区块当作他们实体上最小的可寻址元件，像是大型主机、超级电脑、以及某些工作站的CPU。[1]地址总线AB是专门用来传送地址的，由于地址只能从CPU传向外部存储器或I/O端口，所以地址总线总是单向三态的，这与数据总线不同。地址总线的位数决定了CPU可直接寻址的内存空间大小，比如8位微机的地址总线为16位，则其最大可寻址空间为2^16=64KB，16位微型机的地址总线为20位，其可寻址空间为2^20=1MB。一般来说，若地址总线为n位，则可寻址空间为2^n位。[1]技术指标播报编辑地址总线(图2)1、总线的带宽（总线数据传输速率）[1]总线的带宽指的是单位时间内总线上传送的数据量，即每钞钟传送MB的最大稳态数据传输率。与总线密切相关的两个因素是总线的位宽和总线的工作频率，它们之间的关系：[1]2、总线的位宽总线的位宽指的是总线能同时传送的二进制数据的位数，或数据总线的位数，即32位、64位等总线宽度的概念。总线的位宽越宽，每秒钟数据传输率越大，总线的带宽越宽。[1]3、总线的工作频率总线的工作时钟频率以MHZ为单位，工作频率越高，总线工作速度越快，总线带宽越宽。总线带宽的计算方法：总线的带宽=总线的工作频率*总线的位宽/8。[1]例如：对于64位、800MHz的前端总线，它的数据传输率就等于6.4GB/s=64bit×800MHz÷8(Byte)；32位、33MHzPCI总线的数据传输率就是132MB/s=32bit×33MHz÷8(Byte)，等等[1]操作过程播报编辑第一代32位处理器地址总线一个操作过程是完成两个模块之间传送信息，启动操作过程的是主模块，另外一个是从模块。某一时刻总线上只能有一个主模块占用总线。[1]总线的操作步骤：主模块申请总线控制权，总线控制器进行裁决。数据传送的错误检查：主模块得到总线控制权后寻址从模块，从模块确认后进行数据传送。[1]总线定时协议：定时协议可保证数据传输的双方操作同步，传输正确。定时协议有三种类型：[1]同步总线定时：总线上的所有模块共用同一时钟脉冲进行操作过程的控制。各模块的所有动作的产生均在时钟周期的开始，多数动作在一个时钟周期中完成。[1]异步总线定时：操作的发生由源或目的模块的特定信号来确定。总线上一个事件发生取决前一事件的发生，双方相互提供联络信号。[1]总线定时协议半同步总线定时：总线上各操作的时间间隔可以不同，但必须是时钟周期的整数倍，信号的出现，采样与结束仍以公共时钟为基准。ISA总线采用此定时方法。[1]数据传输类型：分单周方式和突发（burst）方式。单周期方式：一个总线周期只传送一个数据。数据传输类型：突发方式：取得主线控制权后进行多个数据的传输。寻址时给出目的地首地址，访问第一个数据，数据2、3到数据n的地址在首地址基础上按一定规则自动寻址（如自动加1）。[1]技术规范播报编辑地址总线(图2)地址总线是一类信号线的集合是模块间传输信息的公共通道，通过它，计算机各部件间可进行各种数据和命令的传送。为使不同供应商的产品间能够互换，给用户更多的选择，总线的技术规范要标准化。[1]总线的标准制定要经周密考虑，要有严格的规定。总线标准（技术规范）包括以下几部分：机械结构规范：模块尺寸、总线插头、总线接插件以及安装尺寸均有统一规定。功能规范：总线每条信号线（引脚的名称）、功能以及工作过程要有统一规定。电气规范：总线每条信号线的有效电平、动态转换时间、负载能力等。标准分类播报编辑ISA总线ISA技术ISA（IndustrialStandardArchitecture）总线标准是IBM公司1984年为推出PC/AT机而建立的系统总线标准，所以也叫AT总线。它是对XT总线的扩展，以适应8/16位数据总线要求。它在80286至80486时代应用非常广泛，以至于奔腾机中还保留有ISA总线插槽。ISA总线有98只引脚。[1]EISA总线EISA总线是1988年由Compaq等9家公司联合推出的总线标准。它是在ISA总线的基础上使用双层插座，在原来ISA总线的98条信号线上又增加了98条信号线，也就是在两条ISA信号线之间添加一条EISA信号线。在实用中，EISA总线完全兼容ISA总线信号。[1]VESA总线VESA（VideoElectronicsStandardAssociation）总线是1992年由60家附件卡制造商联合推出的一种局部总线，简称为VL（VESALocalbus）总线。它的推出为微机系统总线体系结构的革新奠定了基础。该总线系统考虑到CPU与主存和Cache的直接相连，通常把这部分总线称为CPU总线或主总线，其他设备通过VL总线与CPU总线相连，所以VL总线被称为局部总线。[1]PCI总线PCI（PeripheralComponentInterconnect）总线是当前最流行的总线之一，它是由Intel公司推出的一种局部总线。它定义了32位数据总线，且可扩展为64位。PCI总线主板插槽的体积比原ISA总线插槽还小，其功能比VESA、ISA有极大的改善，支持突发读写操作，最大传输速率可达132MB/s，可同时支持多组外围设备。[1]CompactPCI“以上所列举的几种系统总线一般都用于商用PC机中，在计算机系统总线中，还有另一大类为适应工业现场环境而设计的系统总线，比如STD总线、VME总线、PC/104总线等。这里仅介绍当前工业计算机的热门总线之一：CompactPCI。”[1]发展历程播报编辑地址总线的详细发展历程，包括早期的PC总线和ISA总线、PCI/AGP总线、PCI-X总线以及主流的PCIExpress、HyperTransport高速串行总线。从PC总线到ISA、PCI总线，再由PCI进入PCIExpress和HyperTransport体系，计算机在这三次大转折中也完成三次飞跃式的提升。与这个过程相对应，计算机的处理速度、实现的功能和软件平台都在进行同样的进化，显然，没有总线技术的进步作为基础，计算机的快速发展就无从谈起。业界站在一个崭新的起点：PCIExpress和HyperTransport开创了一个近乎完美的总线架构。而业界对高速总线的渴求也是无休无止，PCIExpress2.0和HyperTransport3.0都将提上日程，它们将会再次带来效能提升。在计算机系统中，各个功能部件都是通过地址总线寻址，总线的速度对系统性能有着极大的影响。而也正因为如此，总线被誉为是计算机系统的神经中枢。但相比CPU、显卡、内存、硬盘等功能部件，总线技术的提升步伐要缓慢得多。在PC发展的二十余年历史中，总线只进行三次更新换代，但它的每次变革都令计算机的面貌焕然一新。[1]软件：定义播报编辑软件，拼音为ruǎnjiàn，国标中对软件的定义为：与计算机系统操作有关的计算机程序、规程、规则，以及可能有的文件、文档及数据。其它定义：1．运行时，能够提供所要求功能和性能的指令或计算机程序集合。2．程序能够满意地处理信息的数据结构。3．描述程序功能需求以及程序如何操作和使用所要求的文档。以开发语言作为描述语言，可以认为：软件=程序+数据+文档特点播报编辑1、无形的，没有物理形态，只能通过运行状况来了解功能、特性和质量2、软件渗透了大量的脑力劳动，人的逻辑思维、智能活动和技术水平是软件产品的关键3、软件不会像硬件一样老化磨损，但存在缺陷维护和技术更新4、软件的开发和运行必须依赖于特定的计算机系统环境，对于硬件有依赖性，为了减少依赖，开发中提出了软件的可移植性5、软件具有可复用性，软件开发出来很容易被复制，从而形成多个副本分类播报编辑应用类别按应用范围划分，一般来讲软件被划分为系统软件、应用软件和介于这两者之间的中间件。系统软件系统软件为计算机使用提供最基本的功能，可分为操作系统和支撑软件，其中操作系统是最基本的软件。系统软件是负责管理计算机系统中各种独立的硬件，使得它们可以协调工作。系统软件使得计算机使用者和其他软件将计算机当作一个整体而不需要顾及到底层每个硬件是如何工作的。1．操作系统是一管理计算机硬件与软件资源的程序，同时也是计算机系统的内核与基石。操作系统身负诸如管理与配置内存、决定系统资源供需的优先次序、控制输入与输出设备、操作网络与管理文件系统等基本事务。操作系统也提供一个让使用者与系统交互的操作接口。2．支撑软件是支撑各种软件的开发与维护的软件，又称为软件开发环境（SDE）。它主要包括环境数据库、各种接口软件和工具组。著名的软件开发环境有IBM公司的WebSphere,微软公司的等。包括一系列基本的工具（比如编译器、数据库管理、存储器格式化、文件系统管理、用户身份验证、驱动管理、网络连接等方面的工具）。应用软件系统软件并不针对某一特定应用领域，而应用软件则相反，不同的应用软件根据用户和所服务的领域提供不同的功能。应用软件是为了某种特定的用途而被开发的软件。它可以是一个特定的程序，比如一个图像浏览器。也可以是一组功能联系紧密，可以互相协作的程序的集合，比如微软的Office软件。也可以是一个由众多独立程序组成的庞大的软件系统，比如数据库管理系统。如今智能手机得到了极大的普及，运行在手机上的应用软件简称手机软件。所谓手机软件就是可以安装在手机上的软件，完善原始系统的不足与个性化。随着科技的发展，手机的功能也越来越多，越来越强大。不是像过去的那么简单死板,发展到了可以和掌上电脑相媲美。手机软件与电脑一样，下载手机软件时还要考虑你购买这一款手机所安装的系统来决定要下相对应的软件。手机主流系统有以下：WindowsPhone、Symbian、iOS、Android。授权类别不同的软件一般都有对应的软件授权，软件的用户必须在同意所使用软件的许可证的情况下才能够合法的使用软件。从另一方面来讲，特定软件的许可条款也不能够与法律相违背。依据许可方式的不同，大致可将软件区分为几类：专属软件：此类授权通常不允许用户随意的复制、研究、修改或散布该软件。违反此类授权通常会有严重的法律责任。传统的商业软件公司会采用此类授权，例如微软的Windows和办公软件。专属软件的源码通常被公司视为私有财产而予以严密的保护。自由软件：此类授权正好与专属软件相反，赋予用户复制、研究、修改和散布该软件的权利，并提供源码供用户自由使用，仅给予些许的其它限制。以Linux、Firefox和OpenOffice可做为此类软件的代表。共享软件：通常可免费的取得并使用其试用版，但在功能或使用期间上受到限制。开发者会鼓励用户付费以取得功能完整的商业版本。根据共享软件作者的授权，用户可以从各种渠道免费得到它的拷贝，也可以自由传播它。免费软件：可免费取得和转载，但并不提供源码，也无法修改。公共软件：原作者已放弃权利，著作权过期，或作者已经不可考究的软件。使用上无任何限制。相关概念播报编辑开发流程软件开发是根据用户要求建造出软件系统或者系统中的软件部分的过程。软件开发是一项包括需求捕捉，需求分析，设计，实现和测试的系统工程。软件一般是用某种程序设计语言来实现的。通常采用软件开发工具可以进行开发。软件开发流程即Softwaredevelopmentprocess。软件设计思路和方法的一般过程，包括设计软件的功能和实现的算法和方法、软件的总体结构设计和模块设计、编程和调试、程序联调和测试以及编写、提交程序。1相关系统分析员和用户初步了解需求，然后列出要开发的系统的大功能模块，每个大功能模块有哪些小功能模块，对于有些需求比较明确相关的界面时，在这一步里面可以初步定义好少量的界面。2系统分析员深入了解和分析需求，根据自己的经验和需求做出一份文档系统的功能需求文档。这次的文档会清楚例用系统大致的大功能模块，大功能模块有哪些小功能模块，并且还例出相关的界面和界面功能。3系统分析员和用户再次确认需求。4系统分析员根据确认的需求文档所例用的界面和功能需求，用迭代的方式对每个界面或功能做系统的概要设计。5系统分析员把写好的概要设计文档给程序员，程序员根据所例出的功能一个一个的编写。6测试编写好的系统。交给用户使用，用户使用后一个一个的确认每个功能，然后验收。软件工程师一般指从事软件开发职业的人。软件工程师10余年来一直占据高薪职业排行榜的前列，作为高科技行业的代表，技术含量很高，职位的争夺也异常激烈。软件开发是一个系统的过程，需要经过市场需求分析、软件代码编写、软件测试、软件维护等程序。软件开发工程师在整个过程中扮演着非常重要的角色，主要从事根据需求开发项目软件工作。法律保护计算机软件作为一种知识产品，其要获得法律保护，必须具备以下必要条件：（一）原创性。即软件应该是开发者独立设计、独立编制的编码组合。（二）可感知性。受保护的软件须固定在某种有形物体上，通过客观手段表达出来并为人们所知悉。（三）可再现性。即把软件转载在有形物体上的可能性。著作权归属根据《计算机软件保护条例》第10条的规定，计算机软件著作权归属软件开发者。因此，确定计算机著作权归属的一般原则是“谁开发谁享有著作权”。软件开发者指实际组织进行开发工作，提供工作条件完成软件开发，并对软件承担责任的法人或者非法人单位，以及依靠自己具有的条件完成软件开发，并对软件承担责任的公民。载体软件的载体可以是硬盘、光盘、U盘、软盘等数据存储设备。使用许可不同的软件一般都有对应的软件授权，软件的使用者必须在同意所使用软件的许可证的情况下才能够合法的使用软件。依据许可方式的不同，大致可将软件区分为几类：专属软件、自由软件、共享软件、免费软件、公共软件。生命周期播报编辑软件生命周期是指从软件定义、开发、使用、维护到报废为止的整个过程，一般包括问题定义、可行性分析、需求分析、总体设计、详细设计、编码、测试和维护。问题定义就是确定开发任务到底“要解决的问题是什么”，系统分析员通过对用户的访问调查，最后得出一份双方都满意的关于问题性质、工程目标和规模的书面报告。可行性分析就是分析上一个阶段所确定的问题到底“可行吗”，系统分析员对系统要进行更进一步的分析，更准确、更具体地确定工程规模与目标，论证在经济上和技术上是否可行，从而在理解工作范围和代价的基础上，做出软件计划。需求分析即使对用户要求进行具体分析，明确“目标系统要做什么”，把用户对软件系统的全部要求以需求说明书的形式表达出来。总体设计就是把软件的功能转化为所需要的体系结构，也就是决定系统的模块结构，并给出模块的相互调用关系、模块间传达的数据及每个模块的功能说明。详细设计就是决定模块内部的算法与数据结构，也是明确“怎么样具体实现这个系统”。编码就是选取适合的程序设计语言对每个模板进行编码，并进行模块调试。测试就是通过各种类型的测试使软件达到预定的要求。维护就是软件交付给用户使用后，对软件不断查错、纠错和修改，使系统持久地满足用户的需求。软件的生命周期也可以分为3个大的阶段，分别是计划阶段、开发阶段和维护阶段。软件过程模型软件生命周期模型也称为软件过程模型，反映软件生存周期各个阶段的工作如何组织、衔接，常用的有瀑布模型、原型模型、螺旋模型、增量模型、喷泉模型，还有建造-修补模型、MSF过程模型、快速原型模型。[1]常见的模型瀑布模型有时也称为V模型，它是一种线型顺序模型，是项目自始至终按照一定顺序的步骤从需求分析进展到系统测试直到提交用户使用，它提供了一种结构化的、自顶向下的软件开发方法，每阶段主要工作成果从一个阶段传递到下一个阶段，必须经过严格的评审或测试，以判定是否可以开始下一阶段工作，各阶段相互独立、不重叠。瀑布模型是所有软件生命周期模型的基础。[1]原型+瀑布模型原型模型本身是一个迭代的模型，是为了解决在产品开发的早期阶段存在的不确定性、二义性和不完整性等问题，通过建立原型使开发者进一步确定其应开发的产品，使开发者的想象更具体化，也更易于被客户所理解。原型只是真实系统的一部分或一个模型，完全可能不完成任何有用的事情，通常包括抛弃型和进化型两种，抛弃型指原型建立、分析之后要扔掉，整个系统重新分析和设计；进化型则是对需求的定义较清楚的情形，原型建立之后要保留，作为系逐渐增加的基础，采用进化型一定要重视软件设计的系统性和完整性，并且在质量要求方面没有捷径，因此，对于描述相同的功能，建立进化型原型比建立抛弃型原型所花的时间要多。原型建立确认需求之后采用瀑布模型的方式完成项目开发。[1]增量模型与建造大厦相同，软件也是一步一步建造起来的。在增量模型中，软件被作为一系列的增量构件来设计、实现、集成和测试，每一个构件是由多种相互作用的模块所形成的提供特定功能的代码片段构成。增量模型在各个阶段并不交付一个可运行的完整产品，而是交付满足客户需求的一个子集的可运行产品。整个产品被分解成若干个构件，开发人员逐个构件地交付产品，这样做的好处是软件开发可以较好地适应变化，客户可以不断地看到所开发的软件，从而降低开发风险。一些大型系统往往需要很多年才能完成或者客户急于实现系统，各子系统往往采用增量开发的模式，先实现核心的产品，即实现基本的需求，但很多补充的特性(其中一些是已知的，另外一些是未知的)在下一期发布。增量模型强调每一个增量均发布一个可操作产品，每个增量构建仍然遵循设计-编码-测试的瀑布模型。[1]迭代模型早在20世纪50年代末期，软件领域中就出现了迭代模型。最早的迭代过程可能被描述为“分段模型”。迭代，包括产生产品发布（稳定、可执行的产品版本）的全部开发活动和要使用该发布必需的所有其他外围元素。所以，在某种程度上，开发迭代是一次完整地经过所有工作流程的过程：（至少包括）需求工作流程、分析设计工作流程、实施工作流程和测试工作流程。实质上，它类似小型的瀑布式项目。所有的阶段（需求及其它）都可以细分为迭代。每一次的迭代都会产生一个可以发布的产品，这个产品是最终产品的一个子集。[1]开发语言播报编辑O语言O语言是一款中文计算机语言（或称套装：O汇编语言、O中间语言、O高级语言）Java语言作为跨平台的语言，可以运行在Windows和Unix/Linux下面，长期成为用户的首选。自JDK6.0以来，整体性能得到了极大的提高，市场使用率超过20%。可能已经达到了其鼎盛时期了，不知道后面能维持多长时间。易语言（E语言）易语言是一个自主开发，适合国情，不同层次不同专业的人员易学易用的汉语编程语言。易语言降低了广大电脑用户编程的门槛，尤其是根本不懂英文或者英文了解很少的用户，可以通过使用本语言极其快速地进入Windows程序编写的大门。[2]C/C++语言以上2个作为传统的语言，一直在效率第一的领域发挥着极大的影响力。像Java这类的语言，其核心都是用C/C++写的。在高并发和实时处理，工控等领域更是首选。习语言习语言即中文版的C语言Basic美国计算机科学家约翰·凯梅尼和托马斯·库尔茨于1959年研制的一种“初学者通用符号指令代码”，简称BASIC。由于BASIC语言易学易用，它很快就成为流行的计算机语言之一。PHP同样是跨平台的脚本语言，在网站编程上成为了大家的首选，支持PHP的主机非常便宜，PHP+Linux+MySQL+Apache的组合简单有效。Perl脚本语言的先驱，其优秀的文本处理能力，特别是正则表达式，成为了以后许多基于网站开发语言(比如PHP,Java,C#)的这方面的基础。PythonPython是一种面向对象的解释性的计算机程序设计语言，也是一种功能强大而完善的通用型语言，已经具有十多年的发展历史，成熟且稳定。Python具有脚本语言中最丰富和强大的类库，足以支持绝大多数日常应用。这种语言具有非常简捷而清晰的语法特点，适合完成各种高层任务，几乎可以在所有的操作系统中运行。基于这种语言的相关技术正在飞速的发展，用户数量急剧扩大，相关的资源非常多。C#C#是微软公司发布的一种面向对象的、运行于NETFramework之上的高级程序设计语言，并定于在微软职业开发者论坛(PDC)上登台亮相。C#是微软公司研究员AndersHejlsberg的最新成果。C#看起来与Java有着惊人的相似；它包括了诸如单一继承、界面，与Java几乎同样的语法，和编译成中间代码再运行的过程。但是C#与Java有着明显的不同，它借鉴了Delphi的一个特点，与COM(组件对象模型)是直接集成的，而且它是微软公司.NETWindows网络框架的主角。JavaScriptJavaScript是一种由Netscape的LiveScript发展而来的脚本语言，主要目的是为了解决服务器终端语言，比如Perl，遗留的速度问题。当时服务端需要对数据进行验证，由于网络速度相当缓慢，只有28.8kbps，验证步骤浪费的时间太多。于是Netscape的浏览器Navigator加入了Javascript，提供了数据验证的基本功能。Ruby一种为简单快捷面向对象编程（面向对象程序设计）而创的脚本语言，由日本人松本行弘（まつもとゆきひろ，英译：YukihiroMatsumoto，外号matz）开发，遵守GPL协议和RubyLicense。Ruby的作者认为Ruby>(Smalltalk+Perl)/2，表示Ruby是一个语法像Smalltalk一样完全面向对象、脚本执行、又有Perl强大的文字处理功能的编程语言。Fortran在科学计算软件领域，Fortran曾经是最主要的编程语言。比较有代表性的有Fortran77、WatcomFortran、NDPFortran等。ObjectiveC这是一种运行在苹果公司的MacOSX，iOS操作系统上的语言。这两种操作系统的上层图形环境，应用程序编程框架都是使用该语言实现的。随著iPhone,iPad的流行，这种语言也开始在全世界流行。PascalPascal是一种计算机通用的高级程序设计语言。Pascal的取名是为了纪念十七世纪法国著名哲学家和数学家BlaisePascal。它由瑞士NiklausWirth教授于六十年代末设计并创立。Pascal语言语法严谨，层次分明，程序易写，具有很强的可读性，是第一个结构化的编程语言。SwiftSwift，苹果于2014年WWDC（苹果开发者大会）发布的新开发语言，可与Objective-C共同运行于MacOS和iOS平台，用于搭建基于苹果平台的应用程序。统计数据播报编辑《中华人民共和国2021年国民经济和社会发展统计公报》显示：2021年，全年软件和信息技术服务业完成软件业务收入94994亿元，按可比口径计算，比上年增长17.7%。[3]产业技术问题播报编辑2022年6月27日，在第二十四届中国科协年会闭幕式上，中国科协隆重发布10个对产业发展具有引领作用的产业技术问题，其中包括“如何发展自主可控的工业设计软件”。[4]奇偶校验：基本介绍播报编辑工作方式奇偶校验是在通信过程中确保节点之间准确数据传输的过程。奇偶校验位附加到原始数据位以创建偶数或奇数位。内存中最小的单位是比特，也称为“位”，位只有两种状态分别以1和0来标示，每8个连续的比特叫做一个字节（byte）。不带奇偶校验的内存每个字节只有8位，如果其某一位存储了错误的值，就会导致其存储的相应数据发生变化，进而导致应用程序发生错误。而奇偶校验就是在每一字节（8位）之外又增加了一位作为错误检测位。在某字节中存储数据之后，在其8个位上存储的数据是固定的，因为位只能有两种状态1或0，假设存储的数据用位标示为1、1、1、0、0、1、0、1，那么把每个位相加（1+1+1+0+0+1+0+1=5），结果是奇数。对于偶校验，校验位就定义为1；对于奇校验，则相反。当CPU读取存储的数据时，它会再次把前8位中存储的数据相加，计算结果是否与校验位相一致。从而一定程度上能检测出内存错误，奇偶校验只能检测出错误而无法对其进行修正，同时虽然双位同时发生错误的概率相当低，但奇偶校验却无法检测出双位错误。优缺点奇偶校验有两种类型：奇校验和偶校验。奇偶校验位是一个表示给定位数的二进制数中1的个数是奇数或者偶数的二进制数，奇偶校验位是最简单的错误检测码。如果传输过程中包括校验位在内的奇数个数据位发生改变，那么奇偶校验位将出错表示传输过程有错误发生。因此，奇偶校验位是一种错误检测码，但是由于没有办法确定哪一位出错，所以它不能进行错误校正。发生错误时必须扔掉全部的数据，然后从头开始传输数据。在噪声很多的媒介上成功传输数据可能要花费很长的时间，甚至根本无法实现。但是奇偶校验位也有它的优点，它是使用一位数据能够达到的最好的校验码，并且它仅仅需要一些异或门就能够生成。奇偶校验被广泛应用。[1]监督码播报编辑奇偶监督码是一种增加二进制传输系统最小距离的简单和广泛采用的方法。例如，单个的奇偶监督将使码的最小距离由一增加到二。一个二进码字，如果它的码元有奇数个1，就称为具有奇性。例如，码字“1011010111”有七个1，因此，这个码字具有奇性。同样，偶性码字具有偶数个1。注意奇性检测等效于所有码元的模二加，并能够由所有码元的异或运算来确定。对于一个n位字，奇性由式(8-1)给出：奇性=a0⊕a1⊕a2⊕…⊕an(8-1)很明显，用同样的方式，我们也能够根据每一个码字的零的个数来构成奇偶监督。单个的奇偶监督码可描述为：给每一个码字加一个监督位，用它来构成奇性或偶性监督。例如，在图8-2中，对于二进码就是这样做的。可以看出，附加码元d2，是简单地选来使每个字成为偶性的。因此，若有一个码元是错的，就可以分辨得出，因为奇偶监督将成为奇性。在一个典型系统里，在传输以前，由奇偶发生器把奇偶监督位加到每个字中。原有信息中的数字在接收机中被检测，如果没有出现正确的奇、偶性，这个信息标定为错误的，这个系统将把错误的字抛掉或者请求重发。注意，用单个的奇偶监督码仅能检出奇数个码元的错误。例如考虑图8-4里的奇性监督码。把奇、偶监督位加到一个8-4-2-1BCD码，使之能够进行奇监督（将所有监督位反过来将产生偶监督码）。可以看到，如果将任何码字里的奇数个码元反过来，那么将成为偶性码，因而，无效的字是可以分辨出来的。然而，如果有两个或四个码元反过来，那末奇偶监督将仍然是奇性码，并且这个字被认为是正确的。只当一个给定的字里同时出现两个错误的概率被忽略不计时，单个的奇偶监督才是有效的，实际上，奇监督码比偶监督码可取，因为它排除了传输全0的情况。单向校验播报编辑概述单向奇偶校验(RowParity)由于一次只采用单个校验位，因此又称为单个位奇偶校验(SingleBitParity)。发送器在数据祯每个字符的信号位后添一个奇偶校验位，接收器对该奇偶校验位进行检查。典型的例子是面向ASCII码的数据信号祯的传输，由于ASCII码是七位码，因此用第八个位码作为奇偶校验位。单向奇偶校验又分为奇校验(OddParity)和偶校验(EvenParity)，发送器通过校验位对所传输信号值的校验方法如下：奇校验保证所传输每个字符的8个位中1的总数为奇数；偶校验则保证每个字符的8个位中1的总数为偶数。显然，如果被传输字符的7个信号位中同时有奇数个(例如1、3、5、7)位出现错误，均可以被检测出来；但如果同时有偶数个(例如2、4、6)位出现错误，单向奇偶校验是检查不出来的。一般在同步传输方式中常采用奇校验，而在异步传输方式中常采用偶校验。校验方法奇校验：就是让原有数据序列中（包括你要加上的一位）1的个数为奇数1000110（0）你必须添0这样原来有3个1已经是奇数了所以你添上0之后1的个数还是奇数个。偶校验：就是让原有数据序列中（包括你要加上的一位）1的个数为偶数，偶校验实际上是循环冗余校验的一个特例，通过多项式x+1得到1位CRC。1000110（1）你就必须加1了这样原来有3个1要想1的个数为偶数就只能添1了。[1]双向校验播报编辑为了提高奇偶校验的检错能力，可采用双向奇偶校验(RowandColumnParity)，也可称为双向冗余校验(VerticalandLongitudinalRedundancyChecks)。双向奇偶校验，又称“方块校验”或“垂直水平”校验。例：1010101×1010111×1110100×0101110×1101001×0011010××××××××“×”表示奇偶校验所采用的奇校验或偶校验的校验码。如此，对于每个数的关注就由以前的1×7次增加到了7×7次。因此，比单项校验的校验能力更强。简单的校验数据的正确性，在计算机里都是010101二进制表示，每个字节有八位二进制，最后一位为校验码，奇校验测算前七位里1的个数合的奇偶性，偶校验测算前七位里0的个数的奇偶性。当数据里其中一位变了，得到的奇偶性就变了，接收数据方就会要求发送方重新传数据。奇偶校验只可以简单判断数据的正确性，从原理上可看出当一位出错，可以准确判断，如同时两个1变成两个0就校验不出来了，只是两位或更多位及校验码在传输过程中出错的概率比较低，奇偶校验可以用的要求比较低的应用下。范例播报编辑串行数据在传输过程中，由于干扰可能引起信息的出错，例如，传输字符‘E’，其各位为：0100，0101=45HD7D0由于干扰，可能使位变为1，（为什么不变0？）这种情况，我们称为出现了“误码”。我们把如何发现传输中的错误，叫“检错”。发现错误后，如何消除错误，叫“纠错”。最简单的检错方法是“奇偶校验”，即在传送字符的各位之外，再传送1位奇/偶校验位。奇校验：所有传送的数位（含字符的各数位和校验位）中，“1”的个数为奇数，如：10110，010100110，0101偶校验：所有传送的数位（含字符的各数位和校验位）中，“1”的个数为偶数，如：10100，010100100，0101如果传输过程中包括校验位在内的奇数个数据位发生改变，那么奇偶校验位出错将表示传输过程有错误发生。但是如果传输过程中包括校验位在内的偶数个数据位发生改变，将无法检出收到的数据是否有错误。只能让发送方重新发送。输入设备：基本概念播报编辑原理图“输出设备”的对称，向计算机输入数据和信息的设备。是计算机与用户或其他设备通信的桥梁。输入设备是用户和计算机系统之间进行信息交换的主要装置之一.键盘，鼠标，摄像头,扫描仪,光笔，手写输入板，游戏杆，语音输入装置等都属于输入设备输入设备（InputDevice）是人或外部与计算机进行交互的一种装置，用于把原始数据和处理这些数据的程序输入到计算机中。把待输入信息转换成能为计算机处理的数据形式的设备。计算机输入的信息有数字、模拟量、文字符号、语声和图形图像等形式。对于这些信息形式，计算机往往无法直接处理，必须把它们转换成相应的数字编码后才能处理。输入信息的传输率变化也很大，它们与计算机的工作速率不相匹配。输入设备的一个作用是使这二方面协调起来，提高计算机工作效率。输入设备的种类很多，除文字及数字输入设备外，模拟信号的输入设备有数-模、模-数转换设备；图形、图像的输入设备有模式信息输入输出设备；脱机输入信息用的数据准备装置有数据准备设备等。现在的计算机能够接收各种各样的数据，既可以是数值型的数据，也可以是各种非数值型的数据，如图形、图像、声音等都可以通过不同类型的输入设备输入到计算机中，进行存储、处理和输出。计算机的输入设备按功能可分为下列几类：字符输入设备：键盘；光学阅读设备：光学标记阅读机，光学字符阅读机；图形输入设备：鼠标器、操纵杆、光笔；图像输入设备：摄像机、扫描仪、传真机；输入模型模拟输入设备：语言模数转换识别系统。输出设备：将计算机中的数据或信息输出给用户。输出设备（OutputDevice）是人与计算机交互的一种部件，用于数据的输出。它把各种计算结果数据或信息以数字、字符、图像、声音等形式表示出来。常见的有显示器、打印机、绘图仪、影像输出系统、语音输出系统、磁记录设备等。既是输入设备又是输出设备：存储设备有内存储器和外存储器，软盘、硬盘、光盘、U盘、移动硬盘等是外存储器，内存储器又分为RAM和ROM，RAM为随机存储器，ROM是只读存储器，内存条是RAM，ROM指的是主板上的存储BIOS的芯片。技术及原理播报编辑信息输入时要说明信息的具体内容、信息的形式和时间。信息输入按信息的来源（称目标系统）和处理系统之间连接的不同可分为间接连接、半直接连接和直接连接。间接连接把目标系统的信息记录在数据载体上，再通过输入设备输入处理系统。常用的载体有穿孔卡片、穿孔带、磁带、磁盘等。半直接连接利用处理系统能够处理的原始文件连接目标系统和处理系统。常用的原始文件有标记文件、磁墨水字符文件、印刷体光学字符文件和手写体光学字符文件等。直接连接通过键盘、光笔、记录设备、传感器等将信息直接输入处理系统。信息输入按照采集系统和处理系统之间控制的不同又可分为脱机输入和联机输入。脱机时输入，信息采集系统与处理系统之间通过二次数据载体相连接。联机输入时，信息采集系统将信息直接输入处理系统。信息输入还可按输入设备的智能程度分为非智能输入和智能输入。非智能输入的信息为数据，输入设备单纯地把数据转换成处理系统能够识别的代码输入。智能输入不仅能进行数据转换，还能进行运算或直接输入声音、图像、文字标记等信息。常用的输入方式有穿孔卡片、穿孔带、磁带、磁盘和字符阅读等多种方式。输入方式播报编辑穿孔卡片输入穿孔卡片输入穿孔卡片是在预定位置处穿孔的组合表示数据。最常用的卡片宽82.6毫米，长187.3毫米，厚1.78毫米。它有80个垂直的列，每列有12个穿孔位置。在一列上穿1、2或3个孔表示一个字符。每张卡片可记载一件事务、一笔帐目或一个记录。穿孔卡片在初期的电子数据处理系统中，曾被广泛地使用。卡片输入是脱机输入，先用键盘穿孔机将数据记录在卡片上，然后通过读卡机送入处理系统。读卡机把卡片上孔眼组合转换成二进制代码送入处理系统，典型的输入速率为每秒2000个字符。穿孔带输入穿孔卡片派生出的穿孔纸带穿孔带由纸、塑料或金属制成，在带上穿圆孔来记载数据。按带的宽度分为8单位带、7单位带和5单位带。在带的横向一排穿孔位置上孔眼的组合代表一个5～8位的字符代码。穿孔带输入是脱机输入，先用穿孔机将数据记录在穿孔带上，然后由穿孔带阅读机将数据送入处理系统。穿孔带也可在许多事务处理机（例如电传打字机、现金收入记录机等）上作为正常业务操作的直接副产品而得到。穿孔带阅读机把穿孔带上的孔眼组合转换成二进制代码送入处理系统。典型的输入速率为每秒1000个字符。磁带输入磁带利用表面磁层的磁化方向来记录信息。它具有密度高、经济性好、易于擦掉再用等优点，是电子数据处理系统中使用最多的输入输出载体。常用的磁带12.7毫米（1/2英寸）宽，每盘61米（2400英寸）长，盘径266.7毫米（10.5英寸）。在横向上记录一个字符，称为一帧，每帧含有7个或9个二进制位（比特）。磁带的存储密度为246帧/毫米，每秒可读写125万个字符。在电子数据处理系统中使用的磁带机能在几毫秒内启动或停止，并能保证磁带高速平稳地通过磁头（5088毫米/秒）。磁头上有一线圈，它将磁带表面记录的信息转换成电信号输入处理系统。小型电子数据处理系统常用盒式磁带机，盒式磁带使用方便、经济。典型读写速度为10～2000字符/秒。磁盘输入带孔磁盘用不导磁的圆盘作基体，表面上涂有磁性层来记载数据，安装在一根垂直的轴上，以2400～3600转/分的速度旋转。磁盘是一种最重要的数据载体。典型的磁盘组由1～12个磁盘组成，盘径为356、254、203毫米（14、10、8英寸）不等。读写磁头安装在梳状存取机构上，可在盘径方向水平移动。磁盘组的读写速率为每秒156000～885000个字符，存储容量为7.25～200兆个字符。小型电子数据处理系统广泛使用软磁盘。它的基体由塑料制成，盘径76毫米、127毫米或203毫米（3英寸、5英寸或8英寸），装在黑色的塑料封套中。磁盘旋转时，封套保持不动。软磁盘可以随时从驱动器上取下更换，使用方便，价格低廉。字符阅读它是直接联机输入，直接读出由打印机、打字机、现金收入记录机和印刷票据上的字符，将它转换成处理系统可读的代码。有光学字符识别（OCR）和磁性墨水字符识别（MICR）。光学字符识别器利用光学原理可以识别两种标准字体（OCR-A和OCR-B）。磁性墨水字符识别器利用检测磁性标记可以识别用专门的磁性墨水打印的字符，它不会因非磁性的脏物或铅笔记号等发生识别错误，比光学字符识别器更为可靠。字符阅读机还可读入条形码表示的信息。条形码是60年代开始为铁路所采用。条形码最常用在标志盒装食品或罐头的种类和价格上。它由一连串黑白相间的条子组成，一般被称为国际产品码。超级市场的收款员只要将商品贴有条形码的一面轻轻擦过条形码扫描器的“窗口”，有关商品的信息就会输入到与之相连的微型计算机中。计算机迅速算出总价格。条形码已广泛用于库存管理、医院病例、书籍定价、图书馆流通管理以及工厂装配线等方面。字符阅读机促进了人机通信的进展。人们所能认识的图形可以自动地转换成机器能够识别的图形。许多原始文件（数据清单，票据等）可直接输入计算机而无需再作介质转换，从而省掉了大量的穿孔按键等准备数据的劳动，大大提高了计算机的使用效率。现代汉字识别和手写体识别技术也取得了一定成功。CRT终端它有一个类似于打字机的输入键盘和一个阴极射线管的显示屏。信息直接从键盘输入，输入的数据首先在屏幕上显示，如果发现错误，可以立即删除或修改，然后送入处理系统。也可用光笔输入信息，光笔是形状像笔的光检测装置，由操作员掌握，用它指定屏幕上的某一点，即可对此点的信息进行修改、增添或删除。光笔在屏幕上移动可以画出相应的图形。CRT终端是使用最广泛的输入输出设备。汉字输入手写笔直接把汉字转换成处理系统能够识别的代码输入。汉字输入系统是中文信息处理系统的重要组成部分。图形输入把复杂图形如指纹、航测图、卫星遥感图片等通过摄像装置或传真机送入系统并加以识别，经过压缩、处理，转换成处理系统能够识别的代码。语音输入直接把声音、语言转换成处理系统能够识别的代码输入。模拟量输入利用模数转换器可把从传感器上收集到的连续变化的信息（模拟量）转换成处理系统能够接受的数字。把模拟量转化为数字分四步进行：取样、保持、量化、编码。输入设备类型播报编辑1.定点输入设备：（鼠标，游戏杆，触摸屏，光笔，数字转换器，数码相机，数字摄影机等）键盘输入设备键盘（Keyboard）是常用的输入设备，它是由一组开关矩阵组成，包括数字键、字母键、符号键、功能键及控制键等。每一个按键在计算机中都有它的惟一代码。当按下某个键时，键盘接口将该键的二进制代码送入计算机主机中，并将按键字符显示在显示器上。当快速大量输入字符，主机来不及处理时，先将这些字符的代码送往内存的键盘缓冲区，然后再从该缓冲区中取出进行分析处理。键盘接口电路多采用单片微处理器，由它控制整个键盘的工作，如上电时对键盘的自检、键盘扫描、按键代码的产生、发送及与主机的通讯等。鼠标器鼠标器（Mouse）是一种手持式屏幕坐标定位设备，它是适应菜单操作的软件和图形处理环境而出现的一种输入设备，特别是在现今流行的Windows图形操作系统环境下应用鼠标器方便快捷。常用的鼠标器有两种，一种是机械式的，另一种是光电式的。鼠标机械式鼠标器的底座上装有一个可以滚动的金属球，当鼠标器在桌面上移动时，金属球与桌面摩擦，发生转动。金属球与四个方向的电位器接触，可测量出上下左右四个方向的位移量，用以控制屏幕上光标的移动。光标和鼠标器的移动方向是一致的，而且移动的距离成比例。光电式鼠标器的底部装有两个平行放置的小光源。这种鼠标器在反射板上移动，光源发出的光经反射板反射后，由鼠标器接收，并转换为电移动信号送入计算机，使屏幕的光标随之移动。其他方面与机械式鼠标器一样。鼠标器上有两个键的，也有三个键的。最左边的键是拾取键，最右边的键为消除键，中间的键是菜单的选择键。由于鼠标器所配的软件系统不同，对上述三个键的定义有所不同。一般情况下，鼠标器左键可在屏幕上确定某一位置，该位置在字符输入状态下是当前输入字符的显示点；在图形状态下是绘图的参考点。在菜单选择中，左键（拾取键）可选择菜单项，也可以选择绘图工具和命令。当作出选择后系统会自动执行所选择的命令。鼠标器能够移动光标，选择各种操作和命令，并可方便地对图形进行编辑和修改，但却不能输入字符和数字。2.扫描输入设备（图像扫描仪，传真机，条形码阅读器，字符和标记识别设备等）手持扫描仪光学标记阅读机是一种用光电原理读取纸上标记的输入设备，常用的有条码读入器和计算机自动评卷记分的输入设备等。图形（图像）扫描仪是利用光电扫描将图形（图像）转换成像素数据输入到计算机中的输入设备。目前一些部门已开始把图像输入用于图像资料库的建设中。如人事档案中的照片输入，公安系统案件资料管理，数字化图书馆的建设，工程设计和管理部门的工程图管理系统，都使用了各种类型的图形（图像）扫描仪。现在人们正在研究使计算机具有人的“听觉”和“视觉”，即让计算机能听懂人说的话，看懂人写的字，从而能以人们接收信息的方式接收信息。为此，人们开辟了新的研究方向，其中包括模式识别、人工智能、信号与图像处理等，并在这些研究方向的基础上产生了语言识别、文字识别、自然语言解与机器视觉等研究方向。3.语音输入设备（麦克风，声卡和语音输入软件系统组成）缓存：简介播报编辑缓存的工作原理缓存是指可以进行高速数据交换的存储器，它先于内存与CPU交换数据，因此速率很快。L1Cache（一级缓存）是CPU第一层高速缓存。内置的L1高速缓存的容量和结构对CPU的性能影响较大，不过高速缓冲存储器均由静态RAM组成，结构较复杂，在CPU管芯面积不能太大的情况下，L1级高速缓存的容量不可能做得太大。一般L1缓存的容量通常在32—256KB。L2Cache（二级缓存）是CPU的第二层高速缓存，分内部和外部两种芯片。内部的芯片二级缓存运行速率与主频相同，而外部的二级缓存则只有主频的一半。L2高速缓存容量也会影响CPU的性能，原则是越大越好，普通台式机CPU的L2缓存一般为128KB到2MB或者更高，笔记本、服务器和工作站上用CPU的L2高速缓存最高可达1MB-3MB。由于高速缓存的速度越高价格也越贵，故有的计算机系统中设置了两级或多级高速缓存。紧靠CPU的一级高速缓存的速度最高，而容量最小，二级高速缓存的容量稍大，速度也稍低[1]。缓存只是内存中少部分数据的复制品，所以CPU到缓存中寻找数据时，也会出现找不到的情况（因为这些数据没有从内存复制到缓存中去），这时CPU还是会到内存中去找数据，这样系统的速率就慢下来了，不过CPU会把这些数据复制到缓存中去，以便下一次不要再到内存中去取。随着时间的变化，被访问得最频繁的数据不是一成不变的，也就是说，刚才还不频繁的数据，此时已经需要被频繁的访问，刚才还是最频繁的数据，又不频繁了，所以说缓存中的数据要经常按照一定的算法来更换，这样才能保证缓存中的数据是被访问最频繁的。工作原理播报编辑缓存工作原理缓存的工作原理是当CPU要读取一个数据时，首先从CPU缓存中查找，找到就立即读取并送给CPU处理；没有找到，就从速率相对较慢的内存中读取并送给CPU处理，同时把这个数据所在的数据块调入缓存中，可以使得以后对整块数据的读取都从缓存中进行，不必再调用内存。正是这样的读取机制使CPU读取缓存的命中率非常高（大多数CPU可达90%左右），也就是说CPU下一次要读取的数据90%都在CPU缓存中，只有大约10%需要从内存读取。这大大节省了CPU直接读取内存的时间，也使CPU读取数据时基本无需等待。总的来说，CPU读取数据的顺序是先缓存后内存。RAM(Random-AccessMemory)和ROM(Read-OnlyMemory)相对的，RAM是掉电以后，其中的信息就消失那一种，ROM在掉电以后信息也不会消失那一种。RAM又分两种，一种是静态RAM，SRAM(StaticRAM)；一种是动态RAM，DRAM(DynamicRAM)。前者的存储速率要比后者快得多，使用的内存一般都是动态RAM。为了增加系统的速率，把缓存扩大就行了，扩的越大，缓存的数据越多，系统就越快了，缓存通常都是静态RAM，速率是非常的快，但是静态RAM集成度低（存储相同的数据，静态RAM的体积是动态RAM的6倍），价格高（同容量的静态RAM是动态RAM的四倍），由此可见，扩大静态RAM作为缓存是一个非常愚蠢的行为，但是为了提高系统的性能和速率，必须要扩大缓存，这样就有了一个折中的方法，不扩大原来的静态RAM缓存，而是增加一些高速动态RAM做为缓存，这些高速动态RAM速率要比常规动态RAM快，但比原来的静态RAM缓存慢，把原来的静态RAM缓存叫一级缓存，而把后来增加的动态RAM叫二级缓存。功能作用播报编辑硬盘的缓存主要起三种作用：预读取数据缓存当硬盘受到CPU指令控制开始读取数据时，硬盘上的控制芯片会控制磁头把正在读取的簇的下一个或者几个簇中的数据读到缓存中（由于硬盘上数据存储时是比较连续的，所以读取命中率较高），当需要读取下一个或者几个簇中的数据的时候，硬盘则不需要再次读取数据，直接把缓存中的数据传输到内存中就可以了，由于缓存的速率远远高于磁头读写的速率，所以能够达到明显改善性能的目的。写入缓存(16张)当硬盘接到写入数据的指令之后，并不会马上将数据写入到盘片上，而是先暂时存储在缓存里，然后发送一个“数据已写入”的信号给系统，这时系统就会认为数据已经写入，并继续执行下面的工作，而硬盘则在空闲（不进行读取或写入的时候）时再将缓存中的数据写入到盘片上。虽然对于写入数据的性能有一定提升，但也不可避免地带来了安全隐患——数据还在缓存里的时候突然掉电，那么这些数据就会丢失。对于这个问题，硬盘厂商们自然也有解决办法：掉电时，磁头会借助惯性将缓存中的数据写入零磁道以外的暂存区域，等到下次启动时再将这些数据写入目的地。临时存储有时候，某些数据是会经常需要访问的，像硬盘内部的缓存（暂存器的一种）会将读取比较频繁的一些数据存储在缓存中，再次读取时就可以直接从缓存中直接传输。缓存就像是一台计算机的内存一样，在硬盘读写数据时，负责数据的存储、寄放等功能。这样一来，不仅可以大大减少数据读写的时间以提高硬盘的使用效率。同时利用缓存还可以让硬盘减少频繁的读写，让硬盘更加安静，更加省电。更大的硬盘缓存，你将读取游戏时更快，拷贝文件时候更快，在系统启动中更为领先。硬盘缓存缓存容量的大小不同品牌、不同型号的产品各不相同，早期的硬盘缓存基本都很小，只有几百KB，已无法满足用户的需求。16MB和32MB缓存是现今主流硬盘所采用，而在服务器或特殊应用领域中还有缓存容量更大的产品，甚至达到了64MB、128MB等。大容量的缓存虽然可以在硬盘进行读写工作状态下，让更多的数据存储在缓存中，以提高硬盘的访问速率，但并不意味着缓存越大就越出众。缓存的应用存在一个算法的问题，即便缓存容量很大，而没有一个高效率的算法，那将导致应用中缓存数据的命中率偏低，无法有效发挥出大容量缓存的优势。算法是和缓存容量相辅相成，大容量的缓存需要更为有效率的算法，否则性能会大大折扣，从技术角度上说，高容量缓存的算法是直接影响到硬盘性能发挥的重要因素。更大容量缓存是未来硬盘发展的必然趋势。技术发展播报编辑缓存集群的配置最早先的CPU缓存是个整体的，而且容量很低，英特尔公司从Pentium时代开始把缓存进行了分类。当时集成在CPU内核中的缓存已不足以满足CPU的需求，而制造工艺上的限制又不能大幅度提高缓存的容量。因此出现了集成在与CPU同一块电路板上或主板上的缓存，此时就把CPU内核集成的缓存称为一级缓存，而外部的称为二级缓存。一级缓存中还分数据缓存（DataCache，D-Cache）和指令缓存（InstructionCache，I-Cache）。二者分别用来存放数据和执行这些数据的指令，而且两者可以同时被CPU访问，减少了争用Cache所造成的冲突，提高了处理器效能。英特尔公司在推出Pentium4处理器时，用新增的一种一级追踪缓存替代指令缓存，容量为12KμOps，表示能存储12K条微指令。随着CPU制造工艺的发展，二级缓存也能轻易的集成在CPU内核中，容量也在逐年提升。再用集成在CPU内部与否来定义一、二级缓存，已不确切。而且随着二级缓存被集成入CPU内核中，以往二级缓存与CPU大差距分频的情况也被改变，此时其以相同于主频的速率工作，可以为CPU提供更高的传输速率。二级缓存是CPU性能表现的关键之一，在CPU核心不变化的情况下，增加二级缓存容量能使性能大幅度提高。而同一核心的CPU高低端之分往往也是在二级缓存上有差异，由此可见二级缓存对于CPU的重要性。CPU在缓存中找到有用的数据被称为命中，当缓存中没有CPU所需的数据时（这时称为未命中），CPU才访问内存。从理论上讲，在一颗拥有二级缓存的CPU中，读取一级缓存的命中率为80%。也就是说CPU一级缓存中找到的有用数据占数据总量的80%，剩下的20%从二级缓存中读取。由于不能准确预测将要执行的数据，读取二级缓存的命中率也在80%左右（从二级缓存读到有用的数据占总数据的16%）。那么还有的数据就不得不从内存调用，但这已经是一个相当小的比例了。较高端的CPU中，还会带有三级缓存，它是为读取二级缓存后未命中的数据设计的—种缓存，在拥有三级缓存的CPU中，只有约5%的数据需要从内存中调用[5]，这进一步提高了CPU的效率。为了保证CPU访问时有较高的命中率，缓存中的内容应该按一定的算法替换。一种较常用的算法是“最近最少使用算法”（LRU算法），它是将最近一段时间内最少被访问过的行淘汰出局。因此需要为每行设置一个计数器，LRU算法是把命中行的计数器清零，其他各行计数器加1。当需要替换时淘汰行计数器计数值最大的数据行出局。这是一种高效、科学的算法，其计数器清零过程可以把一些频繁调用后再不需要的数据淘汰出缓存，提高缓存的利用率。CPU产品中，一级缓存的容量基本在4KB到64KB之间，二级缓存的容量则分为128KB、256KB、512KB、1MB、2MB、4MB等。一级缓存容量各产品之间相差不大，而二级缓存容量则是提高CPU性能的关键。二级缓存容量的提升是由CPU制造工艺所决定的，容量增大必然导致CPU内部晶体管数的增加，要在有限的CPU面积上集成更大的缓存，对制造工艺的要求也就越高。主流的CPU二级缓存都在2MB左右，其中英特尔公司07年相继推出了台式机用的4MB、6MB二级缓存的高性能CPU，不过价格也是相对比较高的，对于对配置要求不是太高的朋友，一般的2MB二级缓存的双核CPU基本也可以满足日常上网需要了。2022年，新一代的奔腾处理器采用了与12代酷睿一样的Intel7工艺，但没有大小核架构。参数方面，奔腾G7400为2核4线程，3.7GHz，6MB三级缓存，46WTDP，支持DDR4-3200内存和DDR5-4800内存。核显为UHD710，16EU1.35GHz。[4]主要意义播报编辑缓存的工作方式缓存工作的原则，就是“引用的局部性”，这可以分为时间局部性和空间局部性。空间局部性是指CPU在某一时刻需要某个数据，那么很可能下一步就需要其附近的数据；时间局部性是指当某个数据被访问过一次之后，过不了多久时间就会被再一次访问。对于应用程序而言，不管是指令流还是数据流都会出现引用的局部性现象。举个简单的例子，比如在播放DVD影片的时候，DVD数据由一系列字节组成，这个时候CPU会依次从头处理到尾地调用DVD数据，如果CPU这次读取DVD数据为1分30秒，那么下次读取的时候就会从1分31秒开始，因此这种情况下有序排列的数据都是依次被读入CPU进行处理。从数据上来看，对于Word一类的应用程序通常都有着较好的空间局部性。用户在使用中不会一次打开7、8个文档，不会在其中某一个文档中打上几个词就换另一个。大多数用户都是打开一两个文档，然后就是长时间对它们进行处理而不会做其他事情。这样在内存中的数据都会集中在一个区域中，也就可以被CPU集中处理。从程序代码上来考虑，设计者通常也会尽量避免出现程序的跳跃和分支，让CPU可以不中断地处理大块连续数据。游戏、模拟和多媒体处理程序通常都是这方面的代表，以小段代码连续处理大块数据。不过在办公运用程序中，情况就不一样了。改动字体，改变格式，保存文档，都需要程序代码不同部分起作用，而用到的指令通常都不会在一个连续的区域中。于是CPU就不得不在内存中不断跳来跳去寻找需要的代码。这也就意味着对于办公程序而言，需要较大的缓存来读入大多数经常使用的代码，把它们放在一个连续的区域中。如果缓存不够，就需要内存中的数据，而如果缓存足够大的话，所有的代码都可以放入，也就可以获得最高的效率。同理，高端的数据应用以及游戏应用则需要更高容量的缓存。CPU缓存播报编辑CPU缓存CPU缓存（CacheMemory）是位于CPU与内存之间的临时存储器，它的容量比内存小的多但是交换速率却比内存要快得多。缓存的出现主要是为了解决CPU运算速率与内存读写速率不匹配的矛盾，因为CPU运算速率要比内存读写速率快很多，这样会使CPU花费很长时间等待数据到来或把数据写入内存。在缓存中的数据是内存中的一小部分，但这一小部分是短时间内CPU即将访问的，当CPU调用大量数据时，就可避开内存直接从缓存中调用，从而加快读取速率。由此可见，在CPU中加入缓存是一种高效的解决方案，这样整个内存储器（缓存+内存）就变成了既有缓存的高速率，又有内存的大容量的存储系统了。缓存对CPU的性能影响很大，主要是因为CPU的数据交换顺序和CPU与缓存间的带宽引起的。缓存基本上都是采用SRAM存储器，SRAM是英文StaticRAM的缩写，它是一种具有静态存取功能的存储器，不需要刷新电路即能保存它内部存储的数据。不像DRAM内存那样需要刷新电路，每隔一段时间，固定要对DRAM刷新充电一次，否则内部的数据即会消失，因此SRAM具有较高的性能，但是SRAM也有它的缺点，即它的集成度较低，相同容量的DRAM内存可以设计为较小的体积，但是SRAM却需要很大的体积，这也是不能将缓存容量做得太大的重要原因。它的特点归纳如下：优点是节能、速率快、不必配合内存刷新电路、可提高整体的工作效率，缺点是集成度低、相同的容量体积较大、而且价格较高，只能少量用于关键性系统以提高效率。工作原理1、读取顺序CPU要读取一个数据时，首先从Cache中查找，如果找到就立即读取并送给CPU处理；如果没有找到，就用相对慢的速度从内存中读取并送给CPU处理，同时把这个数据所在的数据块调入Cache中，可以使得以后对整块数据的读取都从Cache中进行，不必再调用内存。正是这样的读取机制使CPU读取Cache的命中率非常高（大多数CPU可达90%左右），也就是说CPU下一次要读取的数据90%都在Cache中，只有大约10%需要从内存读取。这大大节省了CPU直接读取内存的时间，也使CPU读取数据时基本无需等待。总的来说，CPU读取数据的顺序是先Cache后内存。2、缓存分类Intel从Pentium开始将Cache分开，通常分为一级高速缓存L1和二级高速缓存L2。在以往的观念中，L1Cache是集成在CPU中的，被称为片内Cache。在L1中还分数据Cache（D-Cache）和指令Cache（I-Cache）。它们分别用来存放数据和执行这些数据的指令，而且两个Cache可以同时被CPU访问，减少了争用Cache所造成的冲突，提高了处理器效能。3、读取命中率CPU在Cache中找到有用的数据被称为命中，当Cache中没有CPU所需的数据时（这时称为未命中），CPU才访问内存。从理论上讲，在一颗拥有2级Cache的CPU中，读取L1Cache的命中率为80%。也就是说CPU从L1Cache中找到的有用数据占数据总量的80%，剩下的20%从L2Cache读取。由于不能准确预测将要执行的数据，读取L2的命中率也在80%左右（从L2读到有用的数据占总数据的16%）。那么还有的数据就不得不从内存调用，但这已经是一个相当小的比例了。在一些高端领域的CPU（像Intel的Itanium）中，我们常听到L3Cache，它是为读取L2Cache后未命中的数据设计的—种Cache，在拥有L3Cache的CPU中，只有约5%的数据需要从内存中调用，这进一步提高了CPU的效率。一级缓存播报编辑一级缓存（Level1Cache）简称L1Cache，位于CPU内核的旁边，是与CPU结合最为紧密的CPU缓存，也是历史上最早出现的CPU缓存。由于一级缓存的技术难度和制造成本最高，提高容量所带来的技术难度增加和成本增加非常大，所带来的性能提升却不明显，性价比很低，而且现有的一级缓存的命中率已经很高，所以一级缓存是所有缓存中容量最小的，比二级缓存要小得多。一级缓存可以分为一级数据缓存（DataCache，D-Cache）和一级指令缓存（InstructionCache，I-Cache）。二者分别用来存放数据以及对执行这些数据的指令进行即时解码，而且两者可以同时被CPU访问，减少了争用Cache所造成的冲突，提高了处理器效能。大多数CPU的一级数据缓存和一级指令缓存具有相同的容量，例如AMD的AthlonXP就具有64KB的一级数据缓存和64KB的一级指令缓存，其一级缓存就以64KB+64KB来表示，其余的CPU的一级缓存表示方法以此类推。Intel的采用NetBurst架构的CPU（最典型的就是Pentium4）的一级缓存有点特殊，使用了新增加的一种一级追踪缓存（ExecutionTraceCache，T-Cache或ETC）来替代一级指令缓存，容量为12KμOps，表示能存储12K条即12000条解码后的微指令。一级追踪缓存与一级指令缓存的运行机制是不相同的，一级指令缓存只是对指令作即时的解码而并不会储存这些指令，而一级追踪缓存同样会将一些指令作解码，这些指令称为微指令（micro-ops），而这些微指令能储存在一级追踪缓存之内，无需每一次都作出解码的程序，因此一级追踪缓存能有效地增加在高工作频率下对指令的解码能力，而μOps就是micro-ops，也就是微型操作的意思。它以很高的速率将μops提供给处理器核心。IntelNetBurst微型架构使用执行跟踪缓存，将解码器从执行循环中分离出来。这个跟踪缓存以很高的带宽将uops提供给核心，从本质上适于充分利用软件中的指令级并行机制。Intel并没有公布一级追踪缓存的实际容量,只知道一级追踪缓存能储存12000条微指令（micro-ops）。所以，不能简单地用微指令的数目来比较指令缓存的大小。实际上，单核心的NetBurst架构CPU使用8Kμops的缓存已经基本上够用了，多出的4kμops可以大大提高缓存命中率。而要使用超线程技术的话，12KμOps就会有些不够用，这就是为什么有时候Intel处理器在使用超线程技术时会导致性能下降的重要原因。例如Northwood核心的一级缓存为8KB+12KμOps，就表示其一级数据缓存为8KB，一级追踪缓存为12KμOps；而Prescott核心的一级缓存为16KB+12KμOps，就表示其一级数据缓存为16KB，一级追踪缓存为12KμOps。在这里12KμOps绝对不等于12KB，单位都不同，一个是μOps，一个是Byte（字节），而且二者的运行机制完全不同。所以那些把Intel的CPU一级缓存简单相加，例如把Northwood核心说成是20KB一级缓存，把Prescott核心说成是28KB一级缓存，并且据此认为Intel处理器的一级缓存容量远远低于AMD处理器128KB的一级缓存容量的看法是完全错误的，二者不具有可比性。在架构有一定区别的CPU对比中，很多缓存已经难以找到对应的东西，即使类似名称的缓存在设计思路和功能定义上也有区别了，此时不能用简单的算术加法来进行对比；而在架构极为近似的CPU对比中，分别对比各种功能缓存大小才有一定的意义。二级缓存播报编辑二级缓存结构剖析二级缓存（Level2cache），它是处理器内部的一些缓冲存储器，其作用跟内存一样。上溯到上个世纪80年代，由于处理器的运行速率越来越快，慢慢地，处理器需要从内存中读取数据的速率需求就越来越高了。然而内存的速率提升速率却很缓慢，而能高速读写数据的内存价格又非常高昂，不能大量采用。从性能价格比的角度出发，英特尔等处理器设计生产公司想到一个办法，就是用少量的高速内存和大量的低速内存结合使用，共同为处理器提供数据。这样就兼顾了性能和使用成本的最优。而那些高速的内存因为是处于cpu和内存之间的位置，又是临时存放数据的地方，所以就叫做缓冲存储器了，简称“缓存”。它的作用就像仓库中临时堆放货物的地方一样，货物从运输车辆上放下时临时堆放在缓存区中，然后再搬到内部存储区中长时间存放。货物在这段区域中存放的时间很短，就是一个临时货场。最初缓存只有一级，后来处理器速率又提升了，一级缓存不够用了，于是就添加了二级缓存。二级缓存是比一级缓存速率更慢，容量更大的内存，主要就是做一级缓存和内存之间数据临时交换的地方用。为了适应速率更快的处理器p4ee，已经出现了三级缓存了，它的容量更大，速率相对二级缓存也要慢一些，但是比内存可快多了。缓存的出现使得cpu处理器的运行效率得到了大幅度的提升，这个区域中存放的都是cpu频繁要使用的数据，所以缓存越大处理器效率就越高，同时由于缓存的物理结构比内存复杂很多，所以其成本也很高。大量使用二级缓存带来的结果是处理器运行效率的提升和成本价格的大幅度不等比提升。举个例子，服务器上用的至强处理器和普通的p4处理器其内核基本上是一样的，就是二级缓存不同。至强的二级缓存是2mb～16mb，p4的二级缓存是512kb，于是最便宜的至强也比最贵的p4贵，原因就在二级缓存不同。即l2cache。由于l1级高速缓存容量的限制，为了再次提高cpu的运算速率，在cpu外部放置一高速存储器，即二级缓存。工作主频比较灵活，可与cpu同频，也可不同。cpu在读取数据时，先在l1中寻找，再从l2寻找，然后是内存，在后是外存储器。所以l2对系统的影响也不容忽视。最早先的cpu缓存是个整体的，而且容量很低，英特尔公司从pentium时代开始把缓存进行了分类。当时集成在cpu内核中的缓存已不足以满足cpu的需求，而制造工艺上的限制又不能大幅度提高缓存的容量。因此出现了集成在与cpu同一块电路板上或主板上的缓存，此时就把cpu内核集成的缓存称为一级缓存，而外部的称为二级缓存。随着cpu制造工艺的发展，二级缓存也能轻易的集成在cpu内核中，容量也在逐年提升。再用集成在cpu内部与否来定义一、二级缓存，已不确切。而且随着二级缓存被集成入cpu内核中，以往二级缓存与cpu大差距分频的情况也被改变，此时其以相同于主频的速率工作，可以为cpu提供更高的传输速率。三级缓存播报编辑L3Cache(三级缓存)，分为两种，早期的是外置，逐渐都变为内置的。而它的实际作用即是，L3缓存的应用可以进一步降低内存延迟，同时提升大数据量计算时处理器的性能。降低内存延迟和提升大数据量计算能力对游戏都很有帮助。而在服务器领域增加L3缓存在性能方面仍然有显著的提升。比方具有较大L3缓存的配置利用物理内存会更有效，故它比较慢的磁盘I/O子系统可以处理更多的数据请求。具有较大L3缓存的处理器提供更有效的文件系统缓存行为及较短消息和处理器队列长度。其实最早的L3缓存被应用在AMD发布的K6-III处理器上，当时的L3缓存受限于制造工艺，并没有被集成进芯片内部，而是集成在主板上。在只能够和系统总线频率同步的L3缓存同主内存其实差不了多少。后来使用L3缓存的是英特尔为服务器市场所推出的Itanium处理器。接着就是P4EE和至强MP。Intel还打算推出一款9MBL3缓存的Itanium2处理器，和以后24MBL3缓存的双核心Itanium2处理器。但基本上L3缓存对处理器的性能提高显得不是很重要，比方配备1MBL3缓存的XeonMP处理器却仍然不是Opteron的对手，由此可见前端总线的增加，要比缓存增加带来更有效的性能提升。超级缓存播报编辑SuperCache，也就是超级缓存，计算机的速度瓶颈主要在于机械硬盘的读写速度，SuperCache就是给硬盘的读写用高速内存来做缓存，是大内存机器的提速首选，服务器的必备利器。工作原理：对于SuperCache而言，硬盘上没有文件的概念，只是用户指定大小的一个一个小格子，例如32k，硬盘上某个小格子里面的内容被读取了，则被缓存在内存里面，下次还读这个小格子的时候，直接从内存读取，硬盘没有任何动作，从而达到了加速的目的。有两种缓存模式，1、MFU模式，每个小格子被读取的时候，做一个简单的计数，当缓存满的时候，计数值小的先被清出缓存；2、MRU模式，简单的队列，先进先出。系统缓存播报编辑缓存设计将CPU比作一个城里的家具厂，而将存储系统比作郊区的木料厂，那么实际情况就是木料厂离家具厂越来越远，即使使用更大的卡车来运送木料，家具厂也得停工来等待木料送来。在这样的情况下，一种解决方法是在市区建立一个小型仓库，在里面放置一些家具厂最常用到的木料。这个仓库实际上就是家具厂的“Cache”，家具厂就可以从仓库不停的及时运送需要的木料。当然，仓库越大，存放的木料越多，效果就越好，因为这样即使是些不常用的东西也可以在仓库里找到。需要的木料仓库里没有，就要从城外的木料厂里继续找，而家具厂就得等着了。仓库就相对于L1缓存，可以由CPU及时快速的读写，所以存储的是CPU最常用代码和数据（后面会介绍一下如何挑选“最常用”）。L1缓存的速率比系统内存快的多是因为使用的是SRAM，这种内存单晶元使用四到六个晶体管。这也使得SRAM的造价相当的高，所以不能拿来用在整个存储系统上。在大多数CPU上，L1缓存和核心一起在一块芯片上。在家具厂的例子中，就好比工厂和仓库在同一条街上。这样的设计使CPU可以从最近最快的地方得到数据，但是也使得“城外的木料厂”到“仓库”和到“家具厂”的距离差不多远。这样CPU需要的数据不在L1缓存中，也就是“CacheMiss”，从存储设备取数据就要很长时间了。处理器速率越快，两者之间的差距就越大。使用Pentium4那样的高频率处理器，从内存中取得数据就相当于“木料厂”位于另一个国家。其实，缓存是CPU的一部分，它存在于CPU中CPU存取数据的速率非常的快，一秒钟能够存取、处理十亿条指令和数据（术语：CPU主频1G），而内存就慢很多，快的内存能够达到几十兆就不错了，可见两者的速率差异是多么的大缓存是为了解决CPU速率和内存速率的速率差异问题内存中被CPU访问最频繁的数据和指令被复制入CPU中的缓存，这样CPU就可以不经常到象“蜗牛”一样慢的内存中去取数据了，CPU只要到缓存中去取就行了，而缓存的速率要比内存快很多。这里要特别指出的是：1因为缓存只是内存中少部分数据的复制品，所以CPU到缓存中寻找数据时，也会出现找不到的情况（因为这些数据没有从内存复制到缓存中去），这时CPU还是会到内存中去找数据，这样系统的速率就慢下来了，不过CPU会把这些数据复制到缓存中去，以便下一次不要再到内存中去取。2因为随着时间的变化，被访问得最频繁的数据不是一成不变的，也就是说，刚才还不频繁的数据，此时已经需要被频繁的访问，刚才还是最频繁的数据，后来又不频繁了，所以说缓存中的数据要经常按照一定的算法来更换，这样才能保证缓存中的数据是被访问最频繁的。3关于一级缓存和二级缓存为了分清这两个概念，我们先了解一下RAMram和ROM相对的，RAM是掉电以后，其中信息才消失的那一种，ROM是在掉电以后信息也不会消失的那一种。RAM又分两种：一种是静态RAM、SRAM；一种是动态RAM、DRAM。磁盘缓存播报编辑磁盘缓存磁盘缓存分为读缓存和写缓存。读缓存是指，操作系统为已读取的文件数据，在内存较空闲的情况下留在内存空间中（这个内存空间被称之为“内存池”），当下次软件或用户再次读取同一文件时就不必重新从磁盘上读取，从而提高速率。写缓存实际上就是将要写入磁盘的数据先保存于系统为写缓存分配的内存空间中，当保存到内存池中的数据达到一个程度时，便将数据保存到硬盘中。这样可以减少实际的磁盘操作，有效的保护磁盘免于重复的读写操作而导致的损坏，也能减少写入所需的时间。根据写入方式的不同，有写通式和回写式两种。写通式在读硬盘数据时，系统先检查请求指令，看看所要的数据是否在缓存中，在的话就由缓存送出响应的数据，这个过程称为命中。这样系统就不必访问硬盘中的数据，由于SDRAM的速率比磁介质快很多，因此也就加快了数据传输的速率。回写式就是在写入硬盘数据时也在缓存中找，找到就由缓存就数据写入盘中，多数硬盘都是采用的回写式缓存，这样就大大提高了性能。缓存英文名为Cache。CPU缓存也是内存的一种，其数据交换速率快且运算频率高。磁盘缓存则是操作系统为磁盘输入输出而在普通物理内存中分配的一块内存区域。硬盘的缓冲区，硬盘的缓冲区是硬盘与外部总线交换数据的场所。硬盘的读数据的过程是将磁信号转化为电信号后，通过缓冲区一次次地填充与清空，再填充，再清空，一步步按照PCI总线的周期送出，可见，缓冲区的作用是相当重要的。它的作用也是提高性能，但是它与缓存的不同之处在于：一它是容量固定的硬件，而不像缓存是可以由操作系统在内存中动态分配的。二它对性能的影响大大超过磁盘缓存对性能的影响，因为没有缓冲区，就会要求每传一个字（通常是4字节）就需要读一次磁盘或写一次磁盘。缓存映射播报编辑高速缓存可以被分为直接映射缓存，组相联缓存和全相联缓存。直接映射缓存缓存的映射这种缓存中，每个组只有一行，E=1，结构很简单，整个缓存就相当于关于组的一维数组。不命中时的行替换也很简单，就一个行嘛，哪不命中替换哪。为了适应容量小的情况，第n+1层存储器中的某个数据块，你只能被替换到上一层（也就是第n层）存储器中的某个位置的子集中。假设一个直接映射的高速缓存，（S，E，B，m)=(4,1,2,4)，也就是说，地址是4位（16个），有四个组，每个组一行，每个块两个字节。由于有16个地址，表征16个字节，所以总共有8个块，但只有4个组，也就是4行。只能把多个块映射到相同的缓存组，比如0和4都映射到组1，1和5都映射到组2，等等。这下问题就来了，比如先读块0，此时块0的数据被cache到组0。然后我再读块4，因为块4也是被映射到组0的，组0又只有一行，那就只有把以前块0的数据覆盖了，要是之后我又读块0，就数据丢失了，只能到下级的存储器去找。实际的循环程序中，很容易引起这种情况，称其为抖动。这种情况的存在，自然大大影响了性能。所以，需要更好的映射方案。组相联缓存在组相联缓存里，E大于1，就是说一个组里面有多个cacheline。E等于多少，就叫有多少路，所以叫E路组相联。组相联的行匹配就要复杂一些了，因为要检查多个行的标记位和有效位。如果最终找到了，还好。当然，找不到会从下一级存储器中取出包含所需求数据的行来替换，但一个组里面这么多行，替换哪个行。如果有一个空行，自然就是替换空行，如果没有空行，那就引发了一些其他的替换策略了。除了刚才介绍过的随机策略，还有最不常使用策略，最近最少使用策略。这些策略本身是需要一定开销的，但要知道，不命中的开销是很大的，所以为了保证命中率，采取一些相对复杂的策略是值得的。全相联缓存所谓全相联，就是由一个包含所有缓存行的组组成的缓存（块可以放在高速缓存中的任意位置）[2]。由于只有一个组，所以组选择特别简单，此时地址就没有组索引了，只有标记和偏移，也就是t部分和b部分。其他的步骤，行匹配和数据选择，和组相联原理是一样的，只是规模大得多了。如果说上面关于这三种映射方法的描述非常抽象，为了能理解得更加透彻，把存储器比作一家大超市，超市里面的东西就是一个个字节或者数据。为了让好吃好玩受欢迎的东西能够容易被看到，超市可以将这些东西集中在一块放在一个专门的推荐柜台中，这个柜台就是缓存。如果仅仅是把这些货物放在柜台中即完事，那么这种就是完全关联的方式。可是如果想寻找自己想要的东西，还得在这些推荐货物中寻找，而且由于位置不定，甚至可能把整个推荐柜台寻找个遍，这样的效率无疑还是不高的。于是超市老总决定采用另一种方式，即将所有推荐货物分为许多类别，如“果酱饼干”，“巧克力饼干”，“核桃牛奶”等，柜台的每一层存放一种货物。这就是直接关联的访问原理。这样的好处是容易让顾客有的放矢，寻找更快捷，更有效。但这种方法还是有其缺点，那就是如果需要果酱饼干的顾客很多，需要巧克力饼干的顾客相对较少，显然对果酱饼干的需求量会远多于对巧克力饼干的需求量，可是放置两种饼干的空间是一样大的，于是可能出现这种情况：存放的果酱饼干的空间远不能满足市场需求的数量，而巧克力饼干的存放空间却被闲置。为了克服这个弊病，老板决定改进存货方法：还是将货物分类存放，不过分类方法有所变化，按“饼干”，“牛奶”，“果汁”等类别存货，也就是说，无论是什么饼干都能存入“饼干”所用空间中，这种方法显然提高了空间利用的充分性，让存储以及查找方法更有弹性。技术指标播报编辑CPU缓存CPU产品中，一级缓存的容量基本在4kb到64kb之间，二级缓存的容量则分为128kb、256kb、512kb、1mb、2mb等。一级缓存容量各产品之间相差不大，而二级缓存容量则是提高cpu性能的关键。二级缓存容量的提升是由cpu制造工艺所决定的，容量增大必然导致cpu内部晶体管数的增加，要在有限的cpu面积上集成更大的缓存，对制造工艺的要求也就越高缓存(cache)大小是CPU的重要指标之一，其结构与大小对CPU速率的影响非常大。简单地讲，缓存就是用来存储一些常用或即将用到的数据或指令，当需要这些数据或指令的时候直接从缓存中读取，这样比到内存甚至硬盘中读取要快得多，能够大幅度提升cpu的处理速率。所谓处理器缓存，通常指的是二级高速缓存，或外部高速缓存。即高速缓冲存储器，是位于CPU和主存储器dram(dynamicram)之间的规模较小的但速率很高的存储器，通常由sram（静态随机存储器）组成。用来存放那些被cpu频繁使用的数据，以便使cpu不必依赖于速率较慢的dram（动态随机存储器）。l2高速缓存一直都属于速率极快而价格也相当昂贵的一类内存，称为sram(静态ram)，sram(staticram)是静态存储器的英文缩写。由于sram采用了与制作cpu相同的半导体工艺，因此与动态存储器dram比较，sram的存取速率快，但体积较大，价格很高。处理器缓存的基本思想是用少量的sram作为cpu与dram存储系统之间的缓冲区，即cache系统。80486以及更高档微处理器的一个显著特点是处理器芯片内集成了sram作为cache，由于这些cache装在芯片内，因此称为片内cache。486芯片内cache的容量通常为8k。高档芯片如pentium为16kb，powerpc可达32kb。pentium微处理器进一步改进片内cache，采用数据和双通道cache技术，相对而言，片内cache的容量不大，但是非常灵活、方便，极大地提高了微处理器的性能。片内cache也称为一级cache。由于486，586等高档处理器的时钟频率很高，一旦出现一级cache未命中的情况，性能将明显恶化。在这种情况下采用的办法是在处理器芯片之外再加cache，称为二级cache。二级cache实际上是cpu和主存之间的真正缓冲。由于系统板上的响应时间远低于cpu的速率，没有二级cache就不可能达到486，586等高档处理器的理想速率。二级cache的容量通常应比一级cache大一个数量级以上。在系统设置中，常要求用户确定二级cache是否安装及尺寸大小等。二级cache的大小一般为128kb、256kb或512kb。在486以上档次的微机中，普遍采用256kb或512kb同步cache。所谓同步是指cache和cpu采用了相同的时钟周期，以相同的速率同步工作。相对于异步cache，性能可提高30%以上。pc及其服务器系统的发展趋势之一是cpu主频越做越高，系统架构越做越先进，而主存dram的结构和存取时间改进较慢。因此，缓存（cache）技术愈显重要，在pc系统中cache越做越大。广大用户已把cache做为评价和选购pc系统的一个重要指标。光驱缓存播报编辑光存储驱动器都带有内部缓冲器或高速缓存存储器。这些缓冲器是实际的存储芯片，安装在驱动器的电路板上，它在发送数据给PC之前可能准备或存储更大的数据段。CD/DVD典型的缓冲器大小为128KB，不过具体的驱动器可大可小（通常越多越好）。可刻录CD或DVD驱动器一般具有2MB-4MB以上的大容量缓冲器，用于防止缓存欠载（bufferunderrun）错误，同时可以使刻录工作平稳、恒定的写入。一般来说，驱动器越快，就有更多的缓冲存储器，以处理更高的传输速率。CD/DVD驱动器带有缓冲或高速缓存具有很多好处。缓冲可以保证PC以固定速率接收数据。当一个应用程序从驱动器请求数据时，数据可能位于分散在光盘上不同地方。因为驱动器的访问速率相对较慢，在数据读取时会使驱动器不得不间隔性向PC发送数据。驱动器的缓冲在软件的控制下可以预先读取并准备光盘的内容目录，从而加速第一次数据请求。光驱读取数据的规律是首先在缓存里寻找，如果在缓存中没有找到才会去光盘上寻找，大容量的缓存可以预先读取的数据越多，但在实际应用中CD-ROM、DVD-ROM等读取操作时，读取重复信息的机会是相对较少的，大部分的光盘更多的时候是一次读取数量较多的文件内容，因此在CD-ROM、DVD-ROM驱动器上缓存重要性得不到体现，因此大多此类产品采用较小的缓存容量。CD-ROM一般有128KB、256KB、512KB几种；而DVD一般有128KB、256KB、512KB，只有个别的外置式DVD光驱采用了较大容量的缓存。在刻录机或COMMBO产品上，缓存就变得十分重要了。在刻录光盘时，系统会把需要刻录的数据预先读取到缓存中，然后再从缓存读取数据进行刻录，缓存就是数据和刻录盘之间的桥梁。系统在传输数据到缓存的过程中，不可避免的会发生传输的停顿，如在刻录大量小容量文件时，硬盘读取的速率很可能会跟不上刻录的速率，就会造成缓存内的数据输入输出不成比例，如果这种状态持续一段时间，就会导致缓存内的数据被全部输出，而得不到输入，此时就会造成缓存欠载错误，这样就会导致刻录光盘失败。因此刻录机和COMMBO产品都会采用较大容量的缓存容量，再配合防刻死技术，就能把刻坏盘的几率降到最低。同时缓存还能协调数据传输速率，保证数据传输的稳定性和可靠性。刻录机产品一般有2MB、4MB、8MB，COMBO产品一般有2MB、4MB、8MB的缓存容量，受制造成本的限制，缓存不可能制作到足够大，但适量的缓存容量还是选择光储需要考虑的关键之一。网络缓存播报编辑概念WWW是互联网上最受欢迎的应用之一，其快速增长造成网络拥塞和服务器超载，导致客户访问延迟增大，WWW服务质量日益显现出来。缓存技术被认为是减轻服务器负载、降低网络拥塞、增强WWW可扩展性的有效途径之一，其基本思想是利用客户访问的时间局部性（TemproralLocality）原理，将客户访问过的内容在Cache中存放一个副本，当该内容下次被访问时，不必连接到驻留网站，而是由Cache中保留的副本提供。Web内容可以缓存在客户端、代理服务器以及服务器端。研究表明，缓存技术可以显著地提高WWW性能，它可以带来以下好处：（1）减少网络流量，从而减轻拥塞。（2）降低客户访问延迟，其主要原因有：①缓存在代理服务器中的内容，客户可以直接从代理获取而不是从远程服务器获取，从而减小了传输延迟；②没有被缓存的内容由于网络拥塞及服务器负载的减轻而可以较快地被客户获取。（3）由于客户的部分请求内容可以从代理处获取，从而减轻了远程服务器负载。（4）如果由于远程服务器故障或者网络故障造成远程服务器无法响应客户的请求，客户可以从代理中获取缓存的内容副本，使得WWW服务的鲁棒性得到了加强。Web缓存系统也会带来以下问题：（1）客户通过代理获取的可能是过时的内容。（2）如果发生缓存失效，客户的访问延迟由于额外的代理处理开销而增加。因此在设计Web缓存系统时，应力求做到Cache命中率最大化和失效代价最小化。（3）代理可能成为瓶颈。因此应为一个代理设定一个服务客户数量上限及一个服务效率下限，使得一个代理系统的效率至少同客户直接和远程服务器相连的效率一样。影响Internet访问速率访问网站的过程是通过建立在TCP/IP协议之上的HTTP协议来完成的。从客户端发出一个HTTP请求开始，用户所经历的等待时间主要决定于DNS和网站的响应时间。网站域名首先必须被DNS服务器解析为IP地址，HTTP的延时则由在客户端和服务器间的若干个往返时间所决定。往返时间是指客户端等待每次请求的响应时间，平均往返时间取决于三个方面：网站服务器的延时网站服务器造成的延时在往返时间中占主要比例。当某个服务器收到多个并发HTTP请求时，会产生排队延时。由于响应一个HTTP请求，往往需要多次访问本地硬盘，所以即使是一台负载并不大的服务器，也可能产生几十或几百微秒的延时。由路由器、网关、代理服务器和防火墙引入的延时通常在客户端和服务器之间的路径上会存在多个网络设备，如路由器、网关、代理和防火墙等。它们对经过的IP包都要做存储/转发的操作，于是会引入排队延时和处理延时。在网络拥塞时，这些设备甚至会丢包，此时会寄希望于客户端和服务器通过端到端的协议来恢复通信。不同通信链路上的数据传输速率在广域网中，从一个网络设备到另一个网络设备间的数据传输速率是决定往返时间的一个重要因素。但基本带宽的作用并不是像人们想象的那么重要，一项测试表明，当网站采用T3速率接入Internet时，也仅有2%的网页或对象能以64kbps的速率提供给客户端，这显然表明，带宽在网络性能上不是最关键的因素。Internet在向世界的每一个角落延伸，用户向一个服务器发出的请求可能会经过8000公里到1.6万公里的距离，光速带来的延时和网络设备的延时是网络如此缓慢的最根本原因。网络缓存解决根本问题既然影响网络速率的原因是由距离和光速引起，那么加速Web访问的唯一途径就是缩短客户端与网站之间的距离。通过将用户频繁访问的页面和对象存放在离用户更近的地方，才能减少光速引入的延时，同时由于减少了路由中的环节，也相应地减少了路由器、防火墙和代理等引入的延时。传统的解决办法是建立镜像服务器来达到缩短距离的目的。但这个办法存在很大的不足，对于某个站点而言，不可能在离每个用户群较近的地方都建立镜像站点，若对大多数网站都用这样的办法就更不经济，同时管理和维护镜像站点是一项非常困难的工作。网络缓存是一种降低Internet流量和提高终端用户响应时间的新兴网络技术。它的观念来自于计算机和网络的其他领域，如流行的Intel架构的CPU中就存在缓存，用于提高内存存取的速率；各种操作系统在进行磁盘存取时也会利用缓存来提高速率；分布式文件系统通常也通过缓存来提高客户机和服务器之间的速率。类型静态页面的缓存可能有2种形式：其实主要区别就是CMS是否自己负责关联内容的缓存更新管理。1静态缓存：是在新内容发布的同时就立刻生成相应内容的静态页面，比如：2003年3月22日，管理员通过后台内容管理界面录入一篇文章后，并同步更新相关索引页上的链接。2动态缓存：是在新内容发布以后，并不预先生成相应的静态页面，直到对相应内容发出请求时，如果前台缓存服务器找不到相应缓存，就向后台内容管理服务器发出请求，后台系统会生成相应内容的静态页面，用户第一次访问页面时可能会慢一点，但是以后就是直接访问缓存了。静态缓存的缺点：网络缓存系统结构图复杂的触发更新机制：这两种机制在内容管理系统比较简单的时候都是非常适用的。但对于一个关系比较网络缓存系统结构图复杂的网站来说，页面之间的逻辑引用关系就成为一个非常非常复杂的问题。最典型的例子就是一条新闻要同时在新闻首页和相关的3个新闻专题中出现，在静态缓存模式中，每发一篇新文章，除了这篇新闻内容本身的页面外，还需要系统通过触发器生成多个新的相关静态页面，这些相关逻辑的触发也往往就会成为内容管理系统中最复杂的部分之一。旧内容的批量更新：通过静态缓存发布的内容，对于以前生成的静态页面的内容很难修改，这样用户访问旧页面时，新的模板根本无法生效。在动态缓存模式中，每个动态页面只需要关心，而相关的其他页面能自动更新，从而大大减少了设计相关页面更新触发器的需要。网络缓存可以在客户端，也可以在网络上，由此我们将缓存分为两类：浏览器缓存和代理缓存。几乎所有的浏览器都有一个内置的缓存，它们通常利用客户端本地的内存和硬盘来完成缓存工作，同时允许用户对缓存的内容大小作控制。浏览器缓存是网络缓存的一个极端的情况，因为缓存设在客户机本地。通常一个客户端只有一个用户或几个共享计算机用户，浏览器缓存要求的硬盘空间通常在5MB到50MB的范围内。但是浏览器缓存在用户之间难以共享，不同客户端的缓存无法实现交流，因而缓存的内容与效果相当有限。代理缓存则是一种独立的应用层网络服务,它更像E－mail、Web、DNS等服务。许多用户不仅可以共享缓存，而且可以同时访问缓存中的内容。企业级代理缓存一般需要配置高端的处理器和存储系统，采用专用的软件，要求的硬盘空间在5MB到50GB左右，内存为64MB到512MB。代理处于客户端与网站服务器之间,在某些情况下，这种连接是不允许的，如网站在防火墙内,这时客户端必须与代理建立TCP连接，然后由代理建立与网站服务器的TCP连接。代理在服务器和客户端之间起到了数据接力的作用。代理发出的HTTP请求与一般的HTTP请求有细小的不同，主要在于它包含了完整的URL，而不只是URL的路径。代理缓存的工作原理当代理缓存收到客户端的请求时，它首先检查所请求的内容是否已经被缓存。如果没有找到，缓存必须以客户端的名义转发请求，并在收到服务器发出的文件时，将它以一定的形式保存在本地硬盘，并将其发送给客户端。如果客户端请求的内容已被缓存，还存在两种可能：其一，缓存的内容已经过时，即缓存中保存的内容超过了预先设定的时限，或网站服务器的网页已经更新，这时缓存会要求原服务器验证缓存中的内容，要么更新内容，要么返回“未修改”的消息；其二，缓存的内容是新的，即与原网站的内容保持同步，此时称为缓存命中，这时缓存会立即将已保存的内容送给客户端。在客户端的请求没有命中时，反而增加了缓存存储和转发的处理时间。在这种情况下，代理缓存是否仍有意义呢？实际上，代理缓存能够同时与网站服务器建立多个并发的TCP/IP连接，并行获取网站上的内容。缓存的存在从整体上降低了对网站访问的次数，也就降低了单位时间内服务器端的排队数目，因而这时并发连接的排队延时要小得多。优秀的缓存甚至能实现对网页内相关链接内容的预取以加快连接的速率。代理缓存的策略当原服务器的文件修改或被删除后，缓存又如何知道它保存的拷贝已经作废呢？HTTP协议为缓存服务提供了基本的支持，它使缓存能向原服务器查询，某个文件是否更改,如果缓存的拷贝过时则进行有条件下载。仅当原服务器文件超过指定的日期时，才会发出新的文件。但是这些询问操作对网络服务器造成的负载几乎和获取该文件差不多,因此不可能在客户端向缓存发起请求时都执行这样的操作。HTTP协议使得服务器可以有选择地为每个文档指定生存时间,即清楚地指出某个文件的有效生命周期，生存时间很短即意味着“不要对其缓存”。拷贝的保留时间可以是固定的，也可以是通过这个文件的大小、来源、生存时间或内容计算出来的。[3]分布缓存播报编辑分布式缓存系统是为了解决数据库服务器和web服务器之间的瓶颈。如果一个网站的流量很大，这个瓶颈将会非常明显，每次数据库查询耗费的时间将会非常可观。对于更新速度不是很快的网站，我们可以用静态化来避免过多的数据库查询。对于更新速度以秒计的网站，静态化也不会太理想，可以用缓存系统来构建。如果只是单台服务器用作缓存，问题不会太复杂，如果有多台服务器用作缓存，就要考虑缓存服务器的负载均衡。使用Memcached分布式缓存服务来达到保存用户的会话数据，而达到各个功能模块都能够跨省份、跨服务器共享本次会话中的私有数据的目的。每个省份使用一台服务器来做为Memcached服务器来存储用话的会话中的数据，当然也可以多台服务器，但必须确保每个省份的做Memcached服务器数量必须一致，这样才能够保证Memcached客户端操作的是同一份数据，保证数据的一致性。会话数据的添加、删除、修改Memcached客户端，添加、删除和、修改会话信息数据时，不仅要添加、删除、修改本省的Memcached服务器数据，而且同时要对其它省份的Memcahed服务器做同样的操作，这样用户访问其它省份的服务器的功能模块进也能读取到相同的会话数据。Memcached客户端服务器的列表使用局域网的内网IP（如：192.168.1.179）操作本省的Memcahed服务器，使用公网的IP（（如：202.183.62.210））操作其它省份的Memcahe服务器。会话数据的读取系统所有模块读取会话数据的Memcached客户端服务器列表都设为本省Memcached服务器地址的内网IP来向Memcahed服务器中读取会话数据。同一会话的确认使用Cookie来保持客户与服务端的联系。每一次会话开始就生成一个GUID作为SessionID，保存在客户端的Cookie中，作用域是顶级域名，这样二级、三级域名就可以共享到这个Cookie，系统中就使用这个SessionID来确认它是否是同一个会话。会话数据的唯一ID会话数据存储在Memcached服务器上的唯一键Key也就是会话数据数据的唯一ID定义为：SessionID_Name,SessionID就是保存在客户端Cookie中的SessionID,Name就是会话数据的名称，同一次会话中各个会话数据的Name必须是唯一的，否则新的会话数据将覆盖旧的会话数据。会话的失效时间会话的失效通过控制Cookie的有效时间来实现，会话的时间设为SessionID或Cookie中的有效时间，且每一次访问SessionID时都要重新设置一下Cookie的有效时间，这样就达到的会话的有效时间就是两次间访问Cookie中SessionID值的的最长时间，如果两次访问的间隔时间超过用效时间，保存在SessionID的Cookie将会失效，并生成新的SessionID存放在Cookie中,SessionID改变啦，会话就结束啦。Memcached服务器中会话数据的失效，每一次向Memcache服务器中添加会话数据时，都把有效时间设为一天也就是24小时，让Memcached服务使用它内部的机制去清除，不必在程序中特别做会话数据的删除操作。数据在Memcache服务器中有有效时间只是逻辑上的，就算是过了24小时，如果分配给Memcached服务的内存还够用的话，数据还是保存在内存当中的，只是Memcache客户端读取不到而已。只有到了分配给Memcached服务的内存不够用时，它才会清理没用或者比较旧的数据，也就是懒性清除。增加缓存的方法播报编辑CPU的缓存CPU的缓存分二级：L1（一级缓存）和L2（二级缓存），当处理器要读取数据时，首先要在L1缓存中查找，其次才是L2缓存，最后才是系统内存。如果有一天你发觉自己的电脑慢了很多，进入到Windows桌面也要几分钟，这时候就要检查一下CPU的一、二级缓存有没有打开。在BIOS设置中的StandardCMOSSetup（标准CMOS设定）有两项是用来打开或关闭缓存的：CPUInternalCache设为Enable时开启CPU内部的一级缓冲区，若设置为Disabl则为关闭，这时系统性能将大大降低；ExternalCache选项是控制主板上二级缓冲区，如果主板上有二级缓存则应设成Enable。硬盘的缓存点击电脑桌面上的“开始”/“运行”，键入“Msconfig”启动“系统配置实用程序”，跟着选中“system．ini”标签下的“Vcache”项，就可以根据系统的实际情况来调节硬盘的缓存了。在该选项中一般会有三行内容：ChunkSize=1024、MaxFileCache=10240和MinFileCache=10240；其中第一行是缓冲区读写单元值，第二、三行是硬盘的最大和最小缓冲值，等号后的数值都是可以修改的，只要右键单击选中任一行就可以进行修改了。如果你的内存是128MB的话，上面这三行的取值就比较合理了，当然也可以自定。如果不知道该如何设置合适的缓冲值，请“Windows优化大师”帮忙吧，这个软件中有一个“磁盘缓存优化”项，用鼠标就可以方便地设置好缓存；又或者让“Windows优化大师”自动帮你进行优化设置。当硬盘的缓存值足够大时，硬盘就不用频繁地读写磁盘，一来可以延长硬盘的寿命，二来也可以提高数据的传输速度。另外，将硬盘的“文件系统缓存”设置为“网络服务器”，可以加快系统对硬盘的访问速度，因为文件系统缓存里存放了硬盘最近被访问过的文件名和路径，缓存越大所能储存的内容也就越多。如果点击“控制面板”/“系统”/“性能”/“文件系统”/“硬盘”，将“此计算机的主要用途”由“台式机”改为“网络服务器”，可以将原来10K左右的缓存增加至近50K左右。软驱和光驱的缓存一般来说，软驱读写数据的速度都比较慢，这是因为盘片的转速不能太高，但是，我们可以提高软驱的读写缓存，让软驱一次读写更多的数据。方法是：在桌面上的“开始”/“运行”框中键入“Regedit”运行注册表编辑器，依次进入HKEY－LOCAL－MACHINE\System\CurrentControlSet\Services\Class\FDC\0000，新建一个为ForeFifo的“DWORD值”，将其值设为“0”，这样就对软驱进行了软提速。很多人都知道右键单击桌面“我的电脑”图标，选“属性”/“性能”/“文件系统”/“CD－ROM”，将最佳的访问方式设为“四倍速或更高速”，将追加的高速缓存大小滑块拖到最大处，可以明显提高光驱的读盘速度。除了这种方式，我们还可以在注册表中设置缓冲值，方法是：进入到注册表，在HKEY－LOCAL－MACHINE\System\CurrentControlSet\Control\FileSystem\CDFS下，将CacheSize（缓存值的大小）和Prefetch（预读文件大小）两项进行手工调整，只要右键单击要选的项就可以进行修改了。[3]编译器：定义播报编辑编译程序词组可以有两种认识。一、编译程序是一种动作，是根据编译原理技术，由高级程序设计语言编译器翻译成机器语言二进制代码行为。二、编译程序是动名词，特指生成编译器的软件程序。[1]简介播报编辑编译程序编译程序compiler编译程序的实现算法较为复杂。这是因为它所翻译的语句与目标语言的指令不是一一对应关系,而是一多对应关系;同时也因为它要处理递归调用、动态存储分配、多种数据类型，以及语句间的紧密依赖关系。但是，由于高级程序设计语言书写的程序具有易读、易移植和表达能力强等特点，编译程序广泛地用于翻译规模较大、复杂性较高、且需要高效运行的高级语言书写的源程序。功能播报编辑编译程序编译程序的基本功能是把源程序（高级语言）翻译成目标程序。但是,作为一个具有实际应用价值的编译系统,除了基本功能之外，还应具备语法检查、调试措施、修改手段、覆盖处理、目标程序优化、不同语言合用以及人-机联系等重要功能。①语法检查:检查源程序是否合乎语法。如果不符合语法，编译程序要指出语法错误的部位、性质和有关信息。编译程序应使用户一次上机，能够尽可能多地查出错误。②调试措施：检查源程序是否合乎设计者的意图。为此，要求编译程序在编译出的目标程序中安置一些输出指令，以便在目标程序运行时能输出程序动态执行情况的信息，如变量值的更改、程序执行时所经历的线路等。这些信息有助于用户核实和验证源程序是否表达了算法要求。③修改手段：为用户提供简便的修改源程序的手段。编译程序通常要提供批量修改手段（用于修改数量较大或临时不易修改的错误）和现场修改手段（用于运行时修改数量较少、临时易改的错误）。④覆盖处理：主要是为处理程序长、数据量大的大型问题程序而设置的。基本思想是让一些程序段和数据公用某些存储区，其中只存放当前要用的程序或数据；其余暂时不用的程序和数据，先存放在磁盘等辅助存储器中，待需要时动态地调入。⑤目标程序优化：提高目标程序的质量,即占用的存储空间少,程序的运行时间短。依据优化目标的不同，编译程序可选择实现表达式优化、循环优化或程序全局优化。目标程序优化有的在源程序级上进行，有的在目标程序级上进行。⑥不同语言合用：其功能有助于用户利用多种程序设计语言编写应用程序或套用已有的不同语言书写的程序模块。最为常见的是高级语言和汇编语言的合用。这不但可以弥补高级语言难于表达某些非数值加工操作或直接控制、访问外围设备和硬件寄存器之不足，而且还有利于用汇编语言编写核心部分程序,以提高运行效率。⑦人-机联系：确定编译程序实现方案时达到精心设计的功能。目的是便于用户在编译和运行阶段及时了解内部工作情况，有效地监督、控制系统的运行。早期编译程序的实现方案，是把上述各项功能完全收纳在编译程序之中。然而，习惯做法是在操作系统的支持下，配置调试程序、编辑程序和连接装配程序，用以协助实现程序的调试、修改、覆盖处理，以及不同语言合用功能。但在设计编译程序时，仍须精心考虑如何与这些子系统衔接等问题。[2]编译程序书籍特点播报编辑编译程序必须分析源程序，然后综合成目标程序。首先，检查源程序的正确性，并把它分解成若干基本成分；其次，再根据这些基本成分建立相应等价的目标程序部分。为了完成这些工作，编译程序要在分析阶段建立一些表格，改造源程序为中间语言形式，以便在分析和综合时易于引用和加工。数据结构分析和综合时所用的主要数据结构，包括符号表、常数表和中间语言程序。符号表由源程序中所用的标识符连同它们的属性组成，其中属性包括种类（如变量、数组、结构、函数、过程等）、类型（如整型、实型、字符串、复型、标号等），以及目标程序所需的其他信息。常数表由源程序中用的常数组成，其中包括常数的机内表示，以及分配给它们的目标程序地址。中间语言程序是将源程序翻译为目标程序前引入的一种中间形式的程序，其表示形式的选择取决于编译程序以后如何使用和加工它。常用的中间语言形式有波兰表示、三元组、四元组以及间接三元组等。分析部分源程序的分析是经过词法分析、语法分析和语义分析三个步骤实现的。词法分析由词法分析程序（又称为扫描程序）完成，其任务是识别单词（即标识符、常数、保留字，以及各种运算符、标点符号等）、造符号表和常数表，以及将源程序换码为编译程序易于分析和加工的内部形式。语法分析程序是编译程序的核心部分，其主要任务是根据语言的语法规则，检查源程序是否合乎语法。如不合乎语法，则输出语法出错信息；如合乎语法，则分解源程序的语法结构，构造中间语言形式的内部程序。语法分析的目的是掌握单词是怎样组成语句的，以及语句又是如何组成程序的。语义分析程序是进一步检查合法程序结构的语义正确性，其目的是保证标识符和常数的正确使用，把必要的信息收集和保存到符号表或中间语言程序中，并进行相应的语义处理。工作过程播报编辑编译程序也叫编译系统，是把用高级语言编写的面向过程的源程序翻译成目标程序的语言处理程序。编译程序把一个源程序翻译成目标程序的工作过程分为五个阶段：词法分析；语法分析；中间代码生成；代码优化；目标代码生成。主要是进行词法分析和语法分析，又称为源程序分析，分析过程中发现有语法错误，给出提示信息。（1）词法分析词法分析的任务是对由字符组成的单词进行处理，从左至右逐个字符地对源程序进行扫描，产生一个个的单词符号，把作为字符串的源程序改造成为单词符号串的中间程序。执行词法分析的程序称为词法分析程序或扫描器。源程序中的单词符号经扫描器分析，一般产生二元式：单词种别；单词自身的值。单词种别通常用整数编码，如果一个种别只含一个单词符号，那么对这个单词符号，种别编码就完全代表它自身的值了。若一个种别含有许多个单词符号，那么，对于它的每个单词符号，除了给出种别编码以外，还应给出自身的值。词法分析器一般来说有两种方法构造：手工构造和自动生成。手工构造可使用状态图进行工作，自动生成使用确定的有限自动机来实现。（2）语法分析编译程序的语法分析器以单词符号作为输入，分析单词符号串是否形成符合语法规则的语法单位，如表达式、赋值、循环等，最后看是否构成一个符合要求的程序，按该语言使用的语法规则分析检查每条语句是否有正确的逻辑结构，程序是最终的一个语法单位。编译程序的语法规则可用上下文无关文法来刻画。语法分析的方法分为两种：自上而下分析法和自下而上分析法。自上而下就是从文法的开始符号出发，向下推导，推出句子。而自下而上分析法采用的是移进归约法，基本思想是：用一个寄存符号的先进后出栈，把输入符号一个一个地移进栈里，当栈顶形成某个产生式的一个候选式时，即把栈顶的这一部分归约成该产生式的左邻符号。（3）中间代码生成中间代码是源程序的一种内部表示，或称中间语言。中间代码的作用是可使编译程序的结构在逻辑上更为简单明确，特别是可使目标代码的优化比较容易实现。中间代码即为中间语言程序，中间语言的复杂性介于源程序语言和机器语言之间。中间语言有多种形式，常见的有逆波兰记号、四元式、三元式和树。（4）代码优化代码优化是指对程序进行多种等价变换，使得从变换后的程序出发，能生成更有效的目标代码。所谓等价，是指不改变程序的运行结果。所谓有效，主要指目标代码运行时间较短，以及占用的存储空间较小。这种变换称为优化。有两类优化：一类是对语法分析后的中间代码进行优化，它不依赖于具体的计算机；另一类是在生成目标代码时进行的，它在很大程度上依赖于具体的计算机。对于前一类优化，根据它所涉及的程序范围可分为局部优化、循环优化和全局优化三个不同的级别。（5）目标代码生成目标代码生成是编译的最后一个阶段。目标代码生成器把语法分析后或优化后的中间代码变换成目标代码。目标代码有三种形式：①可以立即执行的机器语言代码，所有地址都重定位；②待装配的机器语言模块，当需要执行时，由连接装入程序把它们和某些运行程序连接起来，转换成能执行的机器语言代码；③汇编语言代码，须经过汇编程序汇编后，成为可执行的机器语言代码。目标代码生成阶段应考虑直接影响到目标代码速度的三个问题：一是如何生成较短的目标代码；二是如何充分利用计算机中的寄存器，减少目标代码访问存储单元的次数；三是如何充分利用计算机指令系统的特点，以提高目标代码的质量。[3]综合部分播报编辑综合阶段必须根据符号表和中间语言程序产生出目标程序，其主要工作包括代码优化、存储分配和代码生成。代码优化是通过重排和改变程序中的某些操作，以产生更加有效的目标程序。存储分配的任务是为程序和数据分配运行时的存储单元。代码生成的主要任务是产生与中间语言程序符等价的目标程序，顺序加工中间语言程序，并利用符号表和常数表中的信息生成一系列的汇编语言或机器语言指令。结构编译过程分为分析和综合两个部分，并进一步划分为词法分析、语法分析、语义分析、代码优化、存储分配和代码生成等六个相继的逻辑步骤。这六个步骤只表示编译程序各部分之间的逻辑联系，而不是时间关系。编译过程既可以按照这六个逻辑步骤顺序地执行，也可以按照平行互锁方式去执行。在确定编译程序的具体结构时，常常分若干遍实现。对于源程序或中间语言程序，从头到尾扫视一次并实现所规定的工作称作一遍。每一遍可以完成一个或相连几个逻辑步骤的工作。例如，可以把词法分析作为第一遍；语法分析和语义分析作为第二遍；代码优化和存储分配作为第三遍；代码生成作为第四遍。反之，为了适应较小的存储空间或提高目标程序质量，也可以把一个逻辑步骤的工作分为几遍去执行。例如，代码优化可划分为代码优化准备工作和实际代码优化两遍进行。一个编译程序是否分遍,以及如何分遍,根据具体情况而定。其判别标准可以是存储容量的大小、源语言的繁简、解题范围的宽窄，以及设计、编制人员的多少等。分遍的好处是各遍功能独立单纯、相互联系简单、逻辑结构清晰、优化准备工作充分。缺点是各遍之中不可避免地要有些重复的部分，而且遍和遍之间要有交接工作，因之增加了编译程序的长度和编译时间。一遍编译程序是一种极端情况，整个编译程序同时驻留在内存,彼此之间采用调用转接方式连接在一起(图2)。当语法分析程序需要新符号时，它就调用词法分析程序；当它识别出某一语法结构时，它就调用语义分析程序。语义分析程序对识别出的结构进行语义检查，并调用“存储分配”和“代码生成”程序生成相应的目标语言指令。随着程序设计语言在形式化、结构化、直观化和智能化等方面的发展，作为实现相应语言功能的编译程序，也正向自动程序设计的目标发展，以便提供理想的程序设计工具。参考书目陈火旺、钱家骅、孙永强编：《编译原理》，国防工业出版社，北京，1980。A.V.Aho,PrinciplesofCompilerDesign,AddisonWes-ley,Reading,Massachusetts,1977.动态20世纪80年代以后，程序设计语言在形式化、结构化、直观化和智能化等方面有了长足的进步和发展，主要表现两个方面：①随着程序设计理论和方法的发展，相继推出了一系列新型程序设计语言，如结构化程序设计语言、并发程序设计语言、分布式程序设计语言、函数式程序设计语言、智能化程序设计语言、面向对象程序设计语言等；②基于语法、语义和语用方面的研究成果，从不同的角度和层次上深刻地揭示了程序设计语言的内在规律和外在表现形式。与此相应地，作为实现程序设计语言重要手段之一的编译程序，在体系结构、设计思想、实现技术和处理内容等方面均有不同程度的发展、变化和扩充。另外，编译程序已作为实现编程的重要软件工具，被纳入到软件支援环境的基本层软件工具之中。因此，规划编译程序实现方案时，应从所处的具体软件支援环境出发，既要遵循整个环境的全局性要求和规定，又要精心考虑与其他诸层软件工具之间的相互支援、配合和衔接关系。累加器：简介播报编辑在中央处理器中，累加器(accumulator)是一种寄存器，用来储存计算产生的中间结果。如果没有像累加器这样的寄存器，那么在每次计算(加法，乘法，移位等等)后就必须要把结果写回到内存，也许马上就得读回来。然而存取主存的速度是比从算术逻辑单元到有直接路径的累加器存取更慢。标准的例子就是把一列的数字加起来。一开始累加器设定为零，每个数字依序地被加到累加器中，当所有的数字都被加入后，结果才写回到主存中。现今的CPU通常有很多寄存器，所有或多数都可以被用来当作累加器。因为这个原因，"累加器"这名词就显得有些老旧。这个名词已经几乎不在微处理器寄存器中使用，例如，运算寄存器的名称中的符号以"A"开头的表示是从"accumulator"这个历史因素得来的(有时候认为并非"arithmetic")。也可能混淆的是寄存器的名字前置"A"也表示"address"，比如说像是Motorola68000家族。早期的4位、8位微处理器，典型具有单个累加器。8051微控制器有两个累加器：主累加器与从累加器，其中的从累加器只用于乘法（MULAB）与除法（DIVAB）。乘法的16位结果放入两个8位累加器中。除法时，商放入主累加器，余数放入从累加器。8008的直接后继产品——8080与8086，开创了x86指令集体系结构，仍然使用两个累加器：主累加器EAX与从累加器EDX用于乘法与除法的大数运算。例如，MULECX将把两个32位寄存器ECX与EAX相乘，64位结果放入EAX与EDX。但是MUL与DIV之外的其他算术——逻辑指令（ADD、SUB、CMP、AND、OR、XOR、TEST）可以使用8个寄存器：EAX、ECX、EDX、EBX、ESP、EBP、ESI、EDI作为目的操作数（即存储结果的位置）。[1]中央处理器播报编辑中央处理器（英语：CentralProcessingUnit，缩写：CPU），是计算机的主要设备之一，功能主要是解释计算机指令以及处理计算机软件中的数据。计算机的可编程性主要是指对中央处理器的编程。中央处理器、内部存储器和输入/输出设备是现代电脑的三大核心部件。1970年代以前，中央处理器由多个独立单元构成，后来发展出由集成电路制造的中央处理器，这些高度收缩的组件就是所谓的微处理器，其中分出的中央处理器最为复杂的电路可以做成单一微小功能强大的单元。中央处理器广义上指一系列可以执行复杂的计算机程序的逻辑机器。这个空泛的定义很容易地将在“CPU”这个名称被普遍使用之前的早期计算机也包括在内。无论如何，至少从1960年代早期开始(Weik1961)，这个名称及其缩写已开始在电子计算机产业中得到广泛应用。尽管与早期相比，“中央处理器”在物理形态、设计制造和具体任务的执行上有了极大的发展，但是其基本的操作原理一直没有改变。早期的中央处理器通常是为大型及特定应用的计算机而定制。但是，这种昂贵的为特定应用定制CPU的方法很大程度上已经让位于开发便宜、标准化、适用于一个或多个目的的处理器类。这个标准化趋势始于由单个晶体管组成的大型机和微机年代，随着集成电路的出现而加速。IC使得更为复杂的中央处理器可以在很小的空间中设计和制造（在微米的数量级）。中央处理器的标准化和小型化都使得这一类数字设备和电子零件在现代生活中的出现频率远远超过有限应用专用的计算机。现代微处理器出现在包括从汽车到手机到儿童玩具在内的各种物品中。运算器：算术、逻辑（部件：算术逻辑单元、累加器、寄存器组、路径转换器、数据总线）；控制器：复位、使能（部件：计数器、指令寄存器、指令解码器、状态寄存器、时钟发生器、微操作信号发生器）。[2]计算机存储器播报编辑计算机存储器（英语：Computermemory）是一种利用半导体技术制成的存储数据的电子设备。其电子电路中的数据以二进制方式存储，存储器的每一个存储单元称做记忆元。记忆体又称内存，是CPU能直接寻址的存储空间，由半导体器件制成。内存的特点是访问速率快。内存是电脑中的主要部件，它是相对于外存而言的。我们平常使用的程序，如Windows操作系统、打字软件、游戏软件等，一般都是安装在硬盘等外存上的，但仅此是不能使用其功能的，必须把它们调入内存中运行，才能真正使用其功能，我们平时输入一段文字，或玩一个游戏，其实都是在内存中进行的。就好比在一个书房里，存放书籍的书架和书柜相当于电脑的外存，而我们工作的办公桌就是内存。通常我们把要永久保存的、大量的数据存储在外存上，而把一些临时的或少量的数据和程序放在内存上，当然内存的好坏会直接影响电脑的运行速度。[3]算术逻辑单元播报编辑算术逻辑单元（英语：ArithmeticLogicUnit,ALU）是中央处理器的执行单元，是所有中央处理器的核心组成部分，由及闸和或闸构成的算数逻辑单元，主要功能是进行二进制的算术运算，如加减乘(不包括整数除法)。基本上，在所有现代CPU体系结构中，二进制都以二补数的形式来表示。[4]参见播报编辑虚拟内存存储器层次结构同步总线：定义播报编辑利用时钟信号采样数据的总线。出处播报编辑《计算机科学技术名词》第三版。[1]控制单元：定义播报编辑控制单元，英文ControlUnit（CU），是CPU部件之一，有时也安装与CPU外部。其基本功能是从内存取指令、分析指令和执行指令。控制单元是实现一种或多种控制规律的控制仪表或控制部件。如：多路传输控制单元、代理设置控制单元。种类播报编辑无论哪一个种类的控制单元，原理均为通过控制单元发出的控制信号对CPU各个部分加以控制。控制单元大体可以分为以下两类。微程序式，由微程序读取和发出控制信号。通过被称为微型定序器的简单数字通路（微型电脑）对微程序加以执行。[1]硬件型控制单元。由数字通路直接发出控制信号。由于集成电路的规模化及设计技术的进步，此种控制单元已成为可能。功能播报编辑它根据用户预先编好的程序，依次从存储器中取出各条指令，放在指令寄存器IR中，通过指令译码(分析)确定应该进行什么操作，然后通过操作控制器OC，按确定的时序，向相应的部件发出微操作控制信号。操作控制器OC中主要包括节拍脉冲发生器、控制矩阵、时钟脉冲发生器、复位电路和启停电路等控制逻辑。微程序控制器：定义播报编辑采用微程序控制方式的控制器称为微程序控制器。所谓微程序控制方式是指微命令不是由组合逻辑电路产生的，而是由微指令译码产生。一条机器指令往往分成几步执行，将每一步操作所需的若干位命令以代码形式编写在一条微指令中，若干条微指令组成一段微程序，对应一条机器指令。在设计CPU时，根据指令系统的需要，事先编制好各段微程序，且将它们存入一个专用存储器（称为控制存储器）中。微程序控制器由指令寄存器IR、程序计数器PC、程序状态字寄存器PSW、时序系统、控制存储器CM、微指令寄存器以及微地址形成电路、微地址寄存器等部件组成。执行指令时，从控制存储器中找到相应的微程序段，逐次取出微指令，送入微指令寄存器，译码后产生所需微命令，控制各步操作完成。基本概念播报编辑微命令和微操作微命令：控制部件通过控制线向执行部件发出的各种控制命令。它构成控制信号的最小单元[1]。微操作：执行部件接受微命令后所进行的操作。它是由微命令实现的最基本操作[1]。控制部件与执行部件通过控制线和反馈信息进行联系。微指令和微程序微指令，在机器的一个CPU周期中，一组实现一定操作功能的微命令的组合。微程序，实现一条机器指令功能的许多条微指令组成的序列。控制部件与执行部件通过控制线和反馈信息进行联系。CPU周期与微指令周期的关系在串行方式的微程序控制器中:微指令周期=读出微指令的时间+执行该条微指令的时间一个CPU周期为0.8μs，它包含四个等间隔的节拍脉冲T1—T4，每个脉冲宽度为200ns。用T4作为读取微指令的时间，用T1+T2+T3时间作为执行微指令的时间。例如，在前600ns时间内运算器进行运算，在600ns时间的末尾运算器已经运算完毕，可用T4上升沿将运算结果打入某个寄存器。与此同时可用T4间隔读取下条微指令，经200ns时间延迟，下条微指令又从只读存储器读出，并用T1上升沿打入到微指令寄存器。如忽略触发器的翻转延迟，那么下条微指令的微命令信号就从T1上升沿起就开始有效，直到下一条微指令读出后打入微指令寄存器为止。因此一条微指令的保持时间恰好是0.8μs，也就是一个CPU周期的时间。[2]组成播报编辑微程序控制器主要由控制存储器、微指令寄存器和地址转移逻辑三大部分组成。控制存储器控制存储器用来存放实现全部指令系统的微程序，它是一种只读存储器。若指令系统中有多少条机器指令，就有多少微程序。一旦微程序固化，机器运行时则只读不写。其工作过程是：每读出一条微指令，则执行这条微指令；接着又读出下一条微指令，又执行这一条微指令……。读出一条微指令并执行微指令的时间总和称为一个微指令周期。通常，在串行方式的微程序控制器中，微指令周期就是只读存储器的工作周期。控制存储器的字长就是微指令字的长度，其存储容量视机器指令系统而定，即取决于微程序的数量。对控制存储器的要求是速度快，读出周期要短。[3]微指令寄存器微指令寄存器用来存放由控制存储器读出的一条微指令信息。其中微地址寄存器决定将要访问的下一条微指令的地址，而微命令寄存器则保存一条微指令的操作控制字段和判别测试字段的信息。[3]地址转移逻辑在一般情况下，微指令由控制存储器读出后直接给出下一条微指令的地址，通常我们简称微地址，这个微地址信息就存放在微地址寄存器中。如果微程序不出现分支，那么下一条微指令的地址就直接由微地址寄存器给出。当微程序出现分支时，意味着微程序出现条件转移。在这种情况下，通过判别测试字段P和执行部件的“状态条件”反馈信息，去修改微地址寄存器的内容，并按改好的内容去读下一条微指令。地址转移逻辑就承担自动完成修改微地址的任务。[3]控制原理播报编辑微程序控制的基本思想，就是仿照通常的解题程序的方法，把操作控制信号编成所谓的“微指令”，存放到一个只读存储器里．当机器运行时，一条又一条地读出这些微指令，从而产生全机所需要的各种操作控制信号，使相应部件执行所规定的操作。微程序控制的基本原理是：（1）将机器指令分解为基本的微命令序列，在制造CPU时固化在控制存储器CM中，执行一条机器指令时，CPU依次从CM中取出微指令产生微命令。（2）一条微指令包含的微命令控制实现一步（一个节拍）操作，若干条微指令组成一小段微程序解释执行一条机器指令。[1]执行过程播报编辑（1）根据计算机给出的第一条微指令的地址，从控制存储器中取出第一条微指令。（2）微指令由操作控制部分和顺序控制部分组成。操作控制部分产生微操作控制信号，控制执行部分完成规定的操作。顺序控制部分中的直接顺序控制部分放入微地址寄存器，顺序控制部分的P字段和执行部件反馈的状态条件信息决定修改微地址寄存器中的值。（3）按地址寄存器中的值从控制存储器中取出下一条微指令，继续第二步，如此循环，直到全部指令执行完毕。设计步骤播报编辑微程序控制器的设计步骤如下：（1）根据CPU的结构图描述出每条指令的微操作流程图并综合成总的流程图；（2）用混合控制法对微命令进行编码；（3）选择合适的控制和时序；（4）选用微程序的顺序控制方式为微指令安排微地址；（5）画出微程序控制器组成框图。[4]组合逻辑控制器和微程序控制器的比较播报编辑组合逻辑控制器和微程序控制器，除了操作控制信号的形成方法和原理有差别外，其余的组成部分上没有本质的区别。最显著的差别可归纳为如下两点：实现方式微程序控制器的控制功能是在存放微程序的控制存储器和存放当前正在执行的微指令的寄存器直接控制下实现的，而组合逻辑控制器由逻辑电路实现。前者电路比较规整，各条指令控制信号的差别反映在控制存储器的内容上，因此无论是增加或修改（包括纠正设计中的错误或升级）指令，只要增加或者修改内容即可。组合逻辑控制器先用逻辑表达式列出，精简化后用逻辑门电路实现，因而显得零乱复杂，当需要增加或修改指令时很麻烦甚至不可能，因此微程序控制器得到了广泛应用，尤其是指令系统复杂的计算机，一般都采用微程序控制器。[1]性能在同样的工艺条件下，微程序控制的速度比组合逻辑电路速度低，因为执行每条微指令都要从控制存储器（CM）中读取一次，影响了速度，而组合逻辑电路的速度主要取决于电路延迟，因而在高速或超高速计算机中，对影响速度的关键部分如CPU，往往采用组合逻辑电路。近年来，一些新的计算机系统如RISC（精简指令计算机），选用了组合逻辑控制器。[1]程序查询方式：一旦某一外设被选中并启动后，主机将查询这个外设的某些状态位，看其是否准备就绪？若外设未准备就绪，主机将再次查询；若外设已准备就绪，则执行一次I/O操作。这种方式控制简单，但外设和主机不能同时工作，各外设之间也不能同时工作，系统效率很低，因此，仅适用于外设的数目不多，对I/O处理的实时要求不那么高，CPU的操作任务比较单一，并不很忙的情况。单个设备：多个设备工作流程如下程序查询方式中断：术语解释播报编辑指处理机处理程序运行中出现的紧急事件的整个过程.程序运行过程中，系统外部、系统内部或者现行程序本身若出现紧急事件，处理机立即中止现行程序的运行，自动转入相应的处理程序(中断服务程序)，待处理完后，再返回原来的程序运行，这整个过程称为程序中断;当处理机接受中断时，只需暂停一个或几个周期而不执行处理程序的中断，称为简单中断.中断又可分为屏蔽中断和非屏蔽中断两类.可由程序控制其屏蔽的中断称为屏蔽中断或可屏蔽中断.屏蔽时，处理机将不接受中断.反之，不能由程序控制其屏蔽，处理机一定要立即处理的中断称为非屏蔽中断或不可屏蔽中断.非屏蔽中断主要用于断电、电源故障等必须立即处理的情况.处理机响应中断时，不需执行查询程序.由被响应中断源向CPU发向量地址的中断称为向量中断，反之为非向量中断.向量中断可以提高中断响应速度。[2]分类播报编辑硬件中断（HardwareInterrupt）[3]：可屏蔽中断（maskableinterrupt）。硬件中断的一类，可通过在中断屏蔽寄存器中设定位掩码来关闭。非可屏蔽中断（non-maskableinterrupt，NMI）。硬件中断的一类，无法通过在中断屏蔽寄存器中设定位掩码来关闭。典型例子是时钟中断（一个硬件时钟以恒定频率—如50Hz—发出的中断）。处理器间中断（interprocessorinterrupt）。一种特殊的硬件中断。由处理器发出，被其它处理器接收。仅见于多处理器系统，以便于处理器间通信或同步。伪中断（spuriousinterrupt）。一类不希望被产生的硬件中断。发生的原因有很多种，如中断线路上电气信号异常，或是中断请求设备本身有问题。软件中断（SoftwareInterrupt）[3]：软件中断。是一条CPU指令，用以自陷一个中断。由于软中断指令通常要运行一个切换CPU至内核态（KernelMode/Ring0）的子例程，它常被用作实现系统调用（Systemcall）。防止方法播报编辑要防止中断冲突，其实就是要知道什么设备容易产生中断冲突，只要知道了这点，在使用这些设备时稍微注意一下就可以了。下面我列出一些容易冲突的设备，希望对读者有用。1、声卡：一些早期的ISA型声卡，系统很有可能不认，就需要用户手动设置（一般为5）2、内置调制解调器和鼠标：一般鼠标用COM1，内置调制解调器使用COM2的中断（一般为3），这时要注意此时COM2上不应有其它设备3、网卡和鼠标：此问题一般发生在鼠标在COM1口，使用中断为3，这时要注意通常网卡的默认中断为3，两者极有可能发成冲突。4、打印机和EPP扫描仪：在安装扫描仪驱动程序时应将打印机打开，因为两个设备中串联，所以为了防止以后扫描仪驱动程序设置有误，一定要将打印机打开再安装扫描仪驱动程序。5、操作系统和BIOS：如果计算机使用了“即插即用”操作系统（例如win98），应将BIOS中PNPOSInstalled设置为Yes这样可让操作系统重新设置中断。6、PS/2鼠标和BIOS：在使用PS/2鼠标时应将BIOS中PS/2MouseFunctionControl打开或设置为Auto，只有这样BIOS才能将IRQ12分配给PS/2鼠标用。功能播报编辑现代计算机中采用中断系统的主要目的是[4]：①提高计算机系统效率。计算机系统中处理机的工作速度远高于外围设备的工作速度。通过中断可以协调它们之间的工作。当外围设备需要与处理机交换信息时，由外围设备向处理机发出中断请求，处理机及时响应并作相应处理。不交换信息时，处理机和外围设备处于各自独立的并行工作状态。②维持系统可靠正常工作。现代计算机中，程序员不能直接干预和操纵机器，必须通过中断系统向操作系统发出请求，由操作系统来实现人为干预。主存储器中往往有多道程序和各自的存储空间。在程序运行过程中，如出现越界访问，有可能引起程序混乱或相互破坏信息。为避免这类事件的发生，由存储管理部件进行监测，一旦发生越界访问，向处理机发出中断请求，处理机立即采取保护措施。③满足实时处理要求。在实时系统中，各种监测和控制装置随机地向处理机发出中断请求，处理机随时响应并进行处理。④提供故障现场处理手段。处理机中设有各种故障检测和错误诊断的部件，一旦发现故障或错误，立即发出中断请求，进行故障现场记录和隔离，为进一步处理提供必要的依据。中断优先权播报编辑在某一时刻有几个中断源同时发出中断请求时，处理器只响应其中优先权最高的中断源。当处理机正在运行某个中断服务程序期间出现另一个中断源的请求时，如果后者的优先权低于前者，处理机不予理睬，反之，处理机立即响应后者，进入所谓的“嵌套中断”。中断优先权的排序按其性质、重要性以及处理的方便性决定，由硬件的优先权仲裁逻辑或软件的顺序询问程序来实现[4]。中断过程播报编辑按照事件发生的顺序，中断过程包括[4]：①中断源发出中断请求;②判断当前处理机是否允许中断和该中断源是否被屏蔽;③优先权排队;④处理机执行完当前指令或当前指令无法执行完，则立即停止当前程序，保护断点地址和处理机当前状态，转入相应的中断服务程序;⑤执行中断服务程序;⑥恢复被保护的状态，执行“中断返回”指令回到被中断的程序或转入其他程序。上述过程中前四项操作是由硬件完成的，后两项是由软件完成的。向量中断播报编辑对应每个中断源设置一个向量。这些向量顺序存在主存储器的特定存储区。向量的内容是相应中断服务程序的起始地址和处理机状态字。在响应中断时，由中断系统硬件提供向量地址，处理机根据该地址取得向量，并转入相应的中断服务程序[4]。程序中断方式：当主机启动外设后，无需等待查询，而是继续执行原来的程序，外设在做好输入输出准备时，向主机发出中断请求，主机接到请求后就暂时中止原来执行的程序，转去执行中断服务程序对外部请求进行处理，在中断处理完毕后返回原来的程序继续执行。显然，程序中断不仅适用于外部设备的输入输出操作，也适用于对外界发生的随机事件的处理。程序中断在信息交换方式中处理最重要的地位，它不仅允许主机和外设同时并行工作，并且允许一台主机管理多台外设，使它们同时工作。但是完成一次程序中断还需要许多辅助操作，当外设数目较多时，中断请求过分频繁，可能使CPU应接不暇；另外，对于一些高速外设，由于信息交换是成批的，如果处理不及时，可能会造成信息丢失，因此，它主要适用于中、低速外设。程序中断与调用子程序的区别子程序的执行是由程序员实现安排好的，而中断服务程序的执行则是由随机的中断事件引起的；子程序的执行受到主程序或上层子程序的控制，而中断服务程序一般与被中断的现行程序毫无关系；不存在同时调用多个子程序的情况，而有可能发生多个外设同时请求cpu为自己服务的情况。DMA：简介播报编辑通常会指定一个内存部分用于直接内存访问。在ISA总线标准中，高达16兆字节的内存可用于DMA。EISA和微通道架构标准允许访问全套内存地址（假设他们可以用32位寻址）。外围设备互连通过使用一个总线主控器来完成直接内存访问。直接内存访问的另一个选择是程控输入输出（PIO）接口。在程控输入输出接口中，设备之间所有的数据传输都要通过处理器。ATA/IDE接口的新协议是UltraDMA，它提供的突发数据传输速率可达33兆字节每秒。具有UltraDMA/33的硬盘驱动器也支持PIO模式1、3、4和多字DMA模式2（每秒16.6兆字节）。[1]原理播报编辑外设与存储器之间以及存储器与存储器之间的数据传输，通常采用程序中断方式、程序查询方式和DMA控制方式。程序中断方式和程序查询方式都需要CPU发出输入/输出（In/Out，I/O）的指令，然后等待I/O设备完成操作之后返回，期间CPU需要等待I/O设备完成操作。DMA在传输存储器和I/O设备的数据时，无须CPU来控制数据的传输，直接通过DMA控制器（directmemoryaccesscontroller，DMAC）完成外设与存储器之间以及存储器与存储器之间的数据高速传输。[3]DMA传输原理一个完整的DMA传输包括DMA请求、DMA响应、DMA传输和DMA结束4个步骤。DMA传输原理如图1所示，图中I/O设备为源端设备，由I/O设备向目的端设备（存储器）传输数据，其DMA的基本传输过程如下：①CPU对总线控制器进行初始化，制定工作内存空间，读取DMAC中的寄存器信息，了解DMAC的传输状态[1]；②I/O设备向DMAC发送DMA请求（DMArequest，DREQ），DMAC收到此信号后，向CPU发出总线保持信号（HOLD）；③CPU当前总线周期执行结束后发出总线响应信号保持确认（holdacknowledgment，HLDA）；④DMAC收到总线授权后，向I/O设备发送DMA响应信号DMA确认（DMAacknowledgment，DACK），表示允许I/O设备进行DMA传送；⑤开始传输时，DMAC首先从源地址读取数据并存入内部缓存中，再写入目的地址，完成总线数据从源地址到目的地址的传输[1]；⑥DMA传输完成后，DMAC向CPU发出结束信号，释放总线，使CPU重新获得总线控制权。一次DMA传输只需要执行一个DMA周期，相当于一个总线读/写周期，因而能够满足外设数据高速传输的需要。[3]DMA是所有现代电脑的重要特色，它允许不同速度的硬件设备来沟通，而不需要依于中央处理器的大量中断负载。否则，中央处理器需要从来源把每一片段的数据复制到寄存器，然后把它们再次写回到新的地方。在这个时间中，中央处理器对于其他的工作来说就无法使用。DMA传输常使用在将一个内存区从一个设备复制到另外一个。当中央处理器初始化这个传输动作，传输动作本身是由DMA控制器来实行和完成。典型的例子就是移动一个外部内存的区块到芯片内部更快的内存去。像是这样的操作并没有让处理器工作拖延，使其可以被重新调度去处理其他的工作。DMA传输对于高性能嵌入式系统算法和网络是很重要的。举个例子，个人电脑的ISADMA控制器拥有8个DMA通道，其中的7个通道是可以让计算机的中央处理器所利用。每一个DMA通道有一个16位地址寄存器和一个16位计数寄存器。要初始化数据传输时，设备驱动程序一起设置DMA通道的地址和计数寄存器，以及数据传输的方向，读取或写入。然后指示DMA硬件开始这个传输动作。当传输结束的时候，设备就会以中断的方式通知中央处理器。"分散-收集"（Scatter-gather）DMA允许在一次单一的DMA处理中传输数据到多个内存区域。相当于把多个简单的DMA要求串在一起。同样，这样做的目的是要减轻中央处理器的多次输出输入中断和数据复制任务。DRQ意为DMA要求；DACK意为DMA确认。这些符号一般在有DMA功能的电脑系统硬件概要上可以看到。它们表示了介于中央处理器和DMA控制器之间的电子信号传输线路。[1]缓存一致性问题播报编辑DMA会导致缓存一致性问题。想像中央处理器带有缓存与外部内存的情况，DMA的运作则是去访问外部内存，当中央处理器访问外部内存某个地址的时候，暂时先将新的值写入缓存中，但并未将外部内存的数据更新，若在缓存中的数据尚未更新到外部内存前发生了DMA，则DMA过程将会读取到未更新的数据。相同的，如果外部设备写入新的值到外部内存内，则中央处理器若访问缓存时则会访问到尚未更新的数据。这些问题可以用两种方法来解决：1.缓存同调系统（Cache-coherentsystem）：以硬件方法来完成，当外部设备写入内存时以一个信号来通知缓存控制器某内存地址的值已经过期或是应该更新数据。2.非同调系统（Non-coherentsystem）：以软件方法来完成，操作系统必须确认缓存读取时，DMA程序已经开始或是禁止DMA发生。第二种的方法会造成DMA的系统负担。[2]DMA引擎播报编辑除了与硬件交互相关外，DMA也可为昂贵的内存耗费减负。比如大型的拷贝行为或scatter-gather操作，从中央处理器到专用的DMA引擎。Intel的高端服务器包含这种引擎，它被称为I/O加速技术（IOAT）。[2]RDMA播报编辑在电脑运算领域，远程直接内存访问（英语：remotedirectmemoryaccess，RDMA）是一种直接存储器访问技术，它将数据直接从一台计算机的内存传输到另一台计算机，无需双方操作系统的介入。这允许高通量、低延迟的网络通信，尤其适合在大规模并行计算机集群中使用。RDMA支持零复制网络传输，通过使网络适配器直接在应用程序内存间传输数据，不再需要在应用程序内存与操作系统缓冲区之间复制数据。这种传输不需要中央处理器、CPU缓存或上下文交换参与，并且传输可与其他系统操作并行。当应用程序执行RDMA读取或写入请求时，应用程序数据直接传输到网络，从而减少延迟并实现快速的消息传输。但是，这种策略也表现出目标节点不会收到请求完成的通知（单向通信）等相关的若干问题。[2]指令格式：指令格式是描述计算机内部电路中运行高低电平的组合，这些组合用0和1在纸张上描述。不同的组合都有一定的涵义，这些高低电平的源头就是机器语言的指令格式的各个字段。指令格式包括操作码和地址码，操作数的地址，操作结果的存储地址和下一条指令的地址。只读存储器：基本结构播报编辑ROM基本结构图右图给出ROM的基本结构，ROM主要由地址译码器、存储体、读出线及读出放大器等部分组成。ROM是按地址寻址的存储器，由CPU给出要访问的存储单元地址ROM的地址译码器是与门的组合，输出是全部地址输入的最小项（全译码）。n位地址码经译码后2n种结果，驱动选择2n个字,即W=2n。存储体是由熔丝、二极管或晶体管等元件排成W*m的二维阵列（字位结构），共W个字，每个字m位。存储体实际上是或门的组合，ROM的输出线位数就是或门的个数。由于它工作时只是读出信息，因此可以不必设置写入电路，这使得其存储单元与读出线路也比较简单。[2]工作过程播报编辑ROM的工作过程右图给出ROM的工作过程，CPU经地址总线送来要访问的存储单元地址，地址译码器根据输入地址码选择某条字线，然后由它驱动该字线的各位线，读出该字的各存储位元所存储的二进制代码，送入读出线输出，再经数据线送至CPU。[1]特点播报编辑只读存储器的特点是只能读出而不能写入信息，通常在电脑主板的ROM里面固化一个基本输入/输出系统，称为BIOS（基本输入输出系统）。其主要作用是完成对系统的加电自检、系统中各功能模块的初始化、系统的基本输入/输出的驱动程序及引导操作系统。[4]种类播报编辑ROM有多种类型，且每种只读存储器都有各自的特性和适用范围。从其制造工艺和功能上分，ROM有五种类型，即掩膜编程的只读存储器MROM（Mask-programmedROM）、可编程的只读存储器PROM（ProgrammableROM）、可擦除可编程的只读存储器EPROM（ErasableProgrammableROM）、可电擦除可编程的只读存储器EEPROM（ElecricallyErasableProgrammableROM）和快擦除读写存储器（FlashMemory）。[2]掩膜编程的只读存储器CDROM掩膜只读存储器（MaskROM）中存储的信息由生产厂家在掩膜工艺过程中“写入”。在制造过程中，将资料以一特制光罩（Mask）烧录于线路中，有时又称为“光罩式只读内存”（MaskROM），此内存的制造成本较低，常用于电脑中的开机启动。其行线和列线的交点处都设置了MOS管，在制造时的最后一道掩膜工艺，按照规定的编码布局来控制MOS管是否与行线、列线相连。相连者定为1（或0），未连者为0（或1），这种存储器一旦由生产厂家制造完毕，用户就无法修改。[1]MROM的主要优点是存储内容固定，掉电后信息仍然存在,可靠性高。缺点是信息一次写入（制造）后就不能修改，很不灵活且生产周期长，用户与生产厂家之间的依赖性大。[2]可编程只读存储器PROM可编程只读存储器（ProgrammableROM，PROM）允许用户通过专用的设备（编程器）一次性写入自己所需要的信息，其一般可编程一次，PROM存储器出厂时各个存储单元皆为1，或皆为0。用户使用时，再使用编程的方法使PROM存储所需要的数据。[2]PROM的种类很多，需要用电和光照的方法来编写与存放的程序和信息。但仅仅只能编写一次，第一次写入的信息就被永久性地保存起来。例如，双极性PROM有两种结构：一种是熔丝烧断型，一种是PN结击穿型。它们只能进行一次性改写，一旦编程完毕，其内容便是永久性的。由于可靠性差，又是一次性编程，较少使用。PROM中的程序和数据是由用户利用专用设备自行写入，一经写入无法更改，永久保存。PROM具有一定的灵活性，适合小批量生产，常用于工业控制机或电器中。[1]可编程可擦除只读存储器EPROM可编程可擦除只读存储器（ErasableProgrammableReadOnlyMemory，EPROM）可多次编程，是一种以读为主的可写可读的存储器。是一种便于用户根据需要来写入，并能把已写入的内容擦去后再改写的ROM。其存储的信息可以由用户自行加电编写，也可以利用紫外线光源或脉冲电流等方法先将原存的信息擦除，然后用写入器重新写入新的信息。EPROM比MROM和PROM更方便、灵活、经济实惠。但是EPROM采用MOS管，速度较慢。[2]擦除远存储内容的方法可以采用以下方法：电的方法（称电可改写ROM）或用紫外线照射的方法（称光可改写ROM）。光可改写ROM可利用高电压将资料编程写入，抹除时将线路曝光于紫外线下，则资料可被清空，并且可重复使用，通常在封装外壳上会预留一个石英透明窗以方便曝光。[2]电可擦除可编程只读存储器电可擦可编程序只读存储器（ElectricallyErasableProgrammableRead-OnlyMemory，EEPROM）是一种随时可写入而无须擦除原先内容的存储器，其写操作比读操作时间要长得多，EEPROM把不易丢失数据和修改灵活的优点组合起来，修改时只需使用普通的控制、地址和数据总线。EEPROM运作原理类似EPROM，但抹除的方式是使用高电场来完成，因此不需要透明窗。EEPROM比EPROM贵，集成度低，成本较高，一般用于保存系统设置的参数、IC卡上存储信息、电视机或空调中的控制器。但由于其可以在线修改，所以可靠性不如EPROM。[2]快擦除读写存储器快闪存储器快擦除读写存储器(FlashMemory)是英特尔公司90年代中期发明的一种高密度、非易失性的读/写半导体存储器它既有EEPROM的特点，又有RAM的特点，是一种全新的存储结构，俗称快闪存储器。它在20世纪80年代中后期首次推出，快闪存储器的价格和功能介于EPROM和EEPROM之间。与EEPROM一样，快闪存储器使用电可擦技术，整个快闪存储器可以在一秒钟至几秒内被擦除，速度比EPROM快得多。另外，它能擦除存储器中的某些块，而不是整块芯片。然而快闪存储器不提供字节级的擦除，与EPROM一样，快闪存储器每位只使用一个晶体管，因此能获得与EPROM一样的高密度(与EEPROM相比较)。“闪存”芯片采用单一电源（3V或者5V）供电，擦除和编程所需的特殊电压由芯片内部产生，因此可以在线系统擦除与编程。“闪存”也是典型的非易失性存储器，在正常使用情况下，其浮置栅中所存电子可保存100年而不丢失。[3]目前，闪存已广泛用于制作各种移动存储器，如U盘及数码相机/摄像机所用的存储卡等。[3]一次编程只读内存一次编程只读内存（OneTimeProgrammableReadOnlyMemory，OTPROM）之写入原理同EPROM，但是为了节省成本，编程写入之后就不再抹除，因此不设置透明窗。[1]使用范围播报编辑由于ROM具有断电后信息不丢失的特性，因而可用于计算机启动用的BIOS芯片。EPROM、EEPROM和FlashROM(NORFlash和NANDFlash)，性能同ROM，但可改写，一般读比写快，写需要比读高的电压，（读5V写12V）但Flash可以在相同电压下读写，且容量大成本低，如U盘MP3中使用广泛。在计算机系统里，RAM一般用作内存，ROM一般作为固件，用来存放一些硬件的驱动程序。[3]制作原理播报编辑ROM内部结构图ROM的地址译码器是与门的组合，其输出是全部地址输入的最小项。可以把译码器表示成右图所示的与阵列，图中与阵列水平线和垂直线交叉处标的“点”表示有“与”的联系。存储单元体实际上是或门的组合，ROM的输出数即或门的个数。译码器的每个最小项都可能是或门的输入，但是，某个最小项能否成为或门的输入取决于存储信息，因此存储单元体可看成是一个或阵列。由上分析，可以从另一角度来看ROM的结构：它由两个阵列组成——“与”门阵列和“或”门阵列，其中“或”的内容是由用户设置的，因而它是可编程的，而与阵列是用来形成全部最小项的，因而是不可编程的。[1]全相联映射：定义播报编辑两个不同存储器的地址空间之间的一种映射关系，一个存储器中的任意一块（页）可以映像到另外一个存储器中的任意一块（页）中。[1]出处播报编辑《计算机科学技术名词》第三版公布时间播报编辑2018年，经全国科学技术名词审定委员会审定发布。存储器：工作原理播报编辑存储器是许多存储单元的集合，按单元号顺序排列。每个单元由若干二进制位构成，以表示存储单元中存放的数值，这种结构和数组的结构非常相似，故在VHDL语言中，通常由数组描述存储器[1]。存储器是用来存储程序和各种数据信息的记忆部件。存储器可分为主存储器（简称主存或内存）和辅助存储器（简称辅存或外存）两大类。和CPU直接交换信息的是主存。[2]主存的工作方式是按存储单元的地址存放或读取各类信息，统称访问存储器。主存中汇集存储单元的载体称为存储体，存储体中每个单元能够存放一串二进制码表示的信息，该信息的总位数称为一个存储单元的字长。存储单元的地址与存储在其中的信息是一一对应的，单元地址只有一个，固定不变，而存储在其中的信息是可以更换的。[2]指示每个单元的二进制编码称为地址码。寻找某个单元时，先要给出它的地址码。暂存这个地址码的寄存器叫存储器地址寄存器(MAR)。为可存放从主存的存储单元内取出的信息或准备存入某存储单元的信息，还要设置一个存储器数据寄存器(MDR)。[2]特点播报编辑计算机的存储器可分成内存储器和外存储器。内存储器在程序执行期间被计算机频繁地使用，并且在一个指令周期期间是可直接访问的。外存储器要求计算机从一个外贮藏装置例如磁带或磁盘中读取信息。这与学生在课堂上做笔记相类似。如果学生没有看笔记就知道内容，信息就被存储在“内存储器”中。如果学生必须查阅笔记，那么信息就在“外存储器”中。[3]内存储器有很多类型。随机存取存储器（RAM）在计算期间被用作高速暂存记忆区。数据可以在RAM中存储、读取和用新的数据代替。当计算机在运行时RAM是可得到的。它包含了放置在计算机此刻所处理的问题处的信息。大多数RAM是“不稳定的”，这意味着当关闭计算机时信息将会丢失。只读存储器（ROM）是稳定的。它被用于存储计算机在必要时需要的指令集。存储在ROM内的信息是硬接线的”（即，它是电子元件的一个物理组成部分），且不能被计算机改变（因此称为“只读”）。可变的ROM，称为可编程只读存储器（PROM），可以将其暴露在一个外部电器设备或光学器件（如激光）中来改变。[3]数字成像设备中的内存储器必须足够大以存放至少一幅数字图像。一幅512x512x8位的图像需要1/4兆字节。因此，一台处理几幅这样的图像的成像设备需要几兆字节的内存。[3]外存储器用来储存不是实时成像任务中获取的图像，其与计算机有不同的分离层面。已经作出诊断的图像通常因为法律目的而存储多年。这些图像被称为“归档”（如磁带），它们必须在计算机上重新安装才能取回信息．硬盘驱动器中的图像被物理地安装在计算机上，且能在几毫秒内被访问。磁存储器中单个位被记录为磁畴，“北极向上”可能意味着1，“北极向下”可能意味着0。[3]最常用的外存储器设备以两种方式之一来存储信息。磁带，以大的盘式装置的形式在20世纪70年代作为计算机存储的一大支柱，现在则以小而封闭的盒式磁带的形式成为一种相对便宜的“离线”存储选择。尽管它在加载现代录音磁带和寻找到感兴趣数据的存储位置时可能花费几秒甚至几分钟，但购买和维修这一存储媒质的长期花费是较低的。[3]存储器各种光学存储器装置也是可得到的。在光学存储器装置中存取一串特定数据所需的时间，可能与在（磁）硬盘存取数据所需的时间一样短。在光盘某一平滑镜面上存在着微小的缺陷。在光盘表面烧一个孔洞表示二进制数1，没有烧孔洞则表示0。烧制而成的光盘是“写一次，读多次”（WORM）光盘的实例。这个特征使得它们适合于长期的档案存储，且保持较高的存取速率。直径是12cm的盘已经成为音乐录制和常规PC使用的标准。这些磁盘被称为“高密度盘”或CDROM。与CDROM具有相同大小，但能存储足够的数字信息来支持几小时的高质量视频的高容量盘，被称为数字视频盘（DVD）。DVD正变得流行。有时候根据要求利用机械装置从一大批光盘中提取和安装盘。这些装置被称为是“自动唱片点唱机”。[3]存储器(17张)分类播报编辑构成存储器的存储介质主要采用半导体器件和磁性材料。存储器中最小的存储单位就是一个双稳态半导体电路或一个CMOS晶体管或磁性材料的存储元，它可存储一个二进制代码。由若干个存储元组成一个存储单元，然后再由许多存储单元组成一个存储器。[4]根据存储材料的性能及使用方法的不同，存储器有几种不同的分类方法。[4]1．按存储介质分类半导体存储器：用半导体器件组成的存储器。[4]磁表面存储器：用磁性材料做成的存储器。[4]2．按存储方式分类随机存储器：任何存储单元的内容都能被随机存取，且存取时间和存储单元的物理位置无关。[4]顺序存储器：只能按某种顺序来存取，存取时间与存储单元的物理位置有关。[4]3．按存储器的读写功能分类只读存储器（ROM）：存储的内容是固定不变的，只能读出而不能写入的半导体存储器。[4]随机读写存储器（RAM）：既能读出又能写入的半导体存储器。[4]4．按信息的可保存性分类非永久记忆的存储器：断电后信息即消失的存储器。[4]永久记忆性存储器：断电后仍能保存信息的存储器。[4]5．按在计算机系统中的作用分类主存储器（内存）：用于存放活动的程序和数据，其速度高、容量较小、每位价位高。[4]辅助存储器（外存储器）：主要用于存放当前不活跃的程序和数据，其速度慢、容量大、每位价位低。[4]缓冲存储器：主要在两个不同工作速度的部件起缓冲作用。[4]存储系统的分级结构结构播报编辑存储器结构在MCS-51系列单片机中，程序存储器和数据存储器互相独立，物理结构也不相同。程序存储器为只读存储器，数据存储器为随机存取存储器。从物理地址空间看，共有4个存储地址空间，即片内程序存储器、片外程序存储器、片内数据存储器和片外数据存储器，I/O接口与外部数据存储器统一编址。[5]存储系统的层次结构播报编辑为提高存储器的性能，通常把各种不同存储容量、存取速度和价格的存储器按层次结构组成多层存储器，并通过管理软件和辅助硬件有机组合成统一的整体，使所存放的程序和数据按层次分布在各存储器中。[6]主要采用三级层次结构来构成存储系统，由高速缓冲存储器Cache、主存储器和辅助存储器组成。图中自上向下容量逐渐增大，速度逐级降低，成本则逐次减少。[6]整个结构可看成主存一辅存和Cache-主存两个层次。在辅助硬件和计算机操作系统的管理下，可把主存一辅存作为一个存储整体，形成的可寻址存储空间比主存储器空间大得多。由于辅存容量大，价格低，使得存储系统的整体平均价格降低。Cache-主存层次可以缩小主存和CPU之间的速度差距，从整体上提高存储器系统的存取速度。[6]一个较大的存储系统由各种不同类型的存储设备构成，形成具有多级层次结构的存储系统。该系统既有与CPU相近的速度，又有极大的容量，而价格又是较低的。可见，采用多级层次结构的存储器系统可有效地解决存储器的速度、容量和价格之间的矛盾。[6]存储器储存器的扩展播报编辑任何存储芯片的存储容量都是有限的。要构成一定容量的内存，单个芯片往往不能满足字长或存储单元个数的要求，甚至字长和存储单元数都不能满足要求。这时，就需要用多个存储芯片进行组合，以满足对存储容量的需求，这种组合就称为存储器的扩展。存储器扩展时要解决的问题主要包括位扩展、字扩展和字位扩展。[7]异步SRAM的接口是一种非常典型的半导体存储芯片接口，掌握了它的接口设计方法就意味着掌握了一系列半导体存储芯片接口的设计方法（包括NoRFlash、E2PROM等），同时也为学习其他半导体存储芯片的接口设计打下了基础。本节以异步SRAM的接口为例，介绍半导体存储芯片接口设计的基本方法与原则。[7]存储器组织播报编辑Flash存储控制器功能包括存储器组织、启动选择、IAP、ISP、片上Flash编程及校验和计算。在存储器组织中介绍了Flash存储控制器映射和系统存储器映射。Flash存储控制器包含片上Flash和Bootloader片上存储器是可编程的，包括APRON、LDROM、数据Flash和用户配置区。地址映射包括Flash存储映射和5个地址映射：支持IAP功能的LDROM，不支持IAP功能的LDROM，支持IAP功能的APRON，不支持IAP功能的APROM，以及支持IAP功能的Bootloader。[8]存储器芯片存储管理的目的播报编辑存储管理要实现的目的是为用户提供方便、安全和充分大的存储空间。[9]方便是指将逻辑地址和物理地址分开，用户只在各自的逻辑地址空间编写程序，不必过问物理空间和物理地址的细节，地址的转换由操作系统自动完成；安全是指同时驻留在内存的多个用户进程相互之间不会发生干扰，也不会访问操作系统所占有的空间；充分大的存储空间是指利用虚拟存储技术，从逻辑上对内存空间进行扩充，从而可以使用户在较小的内存里运行较大的程序。[9]存储器层次框图存储器阵列播报编辑如何增加磁盘的存取速度，如何防止数据因磁盘的故障而丢失及如何有效地利用磁盘空间，一直是电脑专业人员和用户的困扰；而大容量磁盘的价格非常昂贵，对用户形成很大的负担。磁盘阵列技术的产生一举解决了这些问题。[10]过去十多年来，CPU的处理速度几乎是呈几何级数的跃升，内存（memory）的存取速度亦大幅增加，而数据储存装置主要是在与磁盘（harddisk）的存取速度相较之下，较为缓慢。整个I/O吞吐量不能和系统匹配，形成电脑系统的瓶颈，拉低了电脑系统的整体性能。若不能有效地提升磁盘的存取速度，CPU、内存及磁盘问的不平衡将使CPU及内存的改进形成浪费。[10]目前改进磁盘存取速度的方式主要有两种。[10]一是磁盘快取控制（diskcachecontroller），它将从磁盘读取的数据存在快取内存（cachememory）中以减少磁盘存取的次数，数据的读写都在快取内存中进行，大幅增加存取的速度，如要读取的数据不在快取内存中，或要写数据到磁盘时，才做磁盘的存取动作。这种方式在单工期环境（single-taskingenvironment)如DOS之下，对大量数据的存取有很好的性能（量小且频繁的存取则不然），但在多工（multi-tasking）环境之下（因为要不停地做数据交换的动作）或数据库的存取（因每一记录都很小）就不能显示其性能。这种方式没有任何安全保障。[10]二是使用磁盘阵列的技术。磁盘阵列是把多个磁盘组成一个阵列，当作单一磁盘使用，它将数据以分段(striping)的方式储存在不同的磁盘中，存取数据时，阵列中的相关磁盘一起动作，大幅减低数据的存取时间，同时有更佳的空间利用率。磁盘阵列所利用的不同的技术，称为RAIDlevel，不同的level针对不同的系统及应用，以解决数据安全的问题。[10]一般高性能的磁盘阵列都是以硬件的形式来达成，进一步把磁盘快取控制及磁盘阵列结合在一个控制器（RAIDcontroller）或控制卡上，针对不同的用户解决人们对磁盘输出/输入系统的四大要求：(1)增加存取速度；(2)容错（faulttolerance），即安全性；(3)有效利用磁盘空间；(4)尽量平衡CPU、内存及磁盘的性能差异，提高电脑的整体工作性能。[10]关于磁盘阵列技术的阵列原理，1987年，加州伯克利大学的一位人员发表了名为“磁盘阵列研究”的论文，正式提到了RAID也就是磁盘阵列，论文提出廉价的5.25〞及3.5〞的硬盘也能如大机器上的8”盘一样能提供大容量、高性能和数据的一致性，并详述了RAID的技术。[10]磁盘阵列针对不同的应用，使用不同技术，称为RAIDlevel。RAID是RedundantArrayofInexpensiveDisks的缩写，每-level代表一种技术。目前业界公认的标准是RAIDO-RAID5。这个level并不代表技术的高低，leve15并不高于leve13，levell也不低于level4，至于要选择哪一种RAIDlevel的产品，视用户的操作环境（operatingenvironment）及应用（application）而定，与level的高低没有必然的关系。RAIDO没有安全的保障，但其快速，所以适合高速I/O的系统；RAID1适用于需安全性又要兼顾速度的系统，RAID2及RAID3适用于大型电脑及影像、CAD/CAM等处理；RAID5多用于OLTP，因有金融机构及大型数据处理中心的迫切需要，故使用较多而较有名气，但也因此形成很多人对磁盘阵列的误解，以为磁盘阵列非要RAID5不可。RAID4较少使用，和RAID5有其共同之处，但RAID4适合大量数据的存取。其他如RAID6、RAID7，乃至RAID10、RAID50、RAID100等，都是厂商各做各的，并无一致的标准，在此不作说明。[10]外部EPROM扩展原理(7张)总而言之，RAIDO及RAID1最适合PC服务器及图形工作站的用户，提供最佳的性能及最便宜的价格，以低成本符合市场的需求。RAID2及RAID3适用于大档案且输入/输出需求不频繁的应用如影像处理及CAD/CAM等；而RAID5则适用于银行、金融、股市、数据库等大型数据处理中心的OLTP应用；RAID4与RAID5有相同的特性及应用方式，但其较适用于大型文件的读取。[10]未来趋势播报编辑存储器是计算机中数据存放的主要介质。随着近年来的发展,存储器的变化日新月异,各种新型存储器进入市场,普及针对新型存储器的维护方法已经迫在眉睫。[11]从PCRAM和MRAM到RRAM等更多技术，一系列全新的存储技术正不断涌向晶圆厂。而推动这一进程的正是游戏和移动产品领域的技术进步，以及云计算的发展。这些应用都非常重要，它们正在不断扩展当今主流存储技术的能力。例如，游戏应用需要速度极快的主存储器和高容量的辅助（存储类）存储器，从而在用户浑然不觉的情况下处理数据,快速管理海量的图形数据。毕竟，没人希望在游戏玩到关键时刻，突然遇到意外的卡顿。对于云计算，其最大的优势在于能够通过网络访问海量数据，而无需将这些数据直接存储在我们的个人设备上。同样，速度也至关重要，因为除非必要，没人愿意多等待哪怕一纳秒。[12]半导体存储器随着数据存储技术的迅猛发展，用户对存储性价比的要求也越来越高，而云存储技术无需硬件设备的支持，这就大大增加了存储的安全性能，用户也无需对硬件设施进行维护，减少了投入成本，提升存储效率。[13]扩展总线：扩展总线简介播报编辑总线就是在模块与模块之间或设备与设备之间的一组进行互连和传输信息的信号线，信息包括指令、数据和地址。计算机的总线都是具有一定的含义的。对于连接到总线上的多个设备而言，任何一个设备发出的信号可以被连接到总线上的所有其他设备接收。如果两个以上的设备同时在总线上发出自己的信号，则会发生信号混乱。因此，在同一时间内，连接到总线是哪个的多个设备中只能有一个设备主动进行信号的传输，其他设备只能处于被动接收的状态。在20世纪70年代后期，以AppleΙΙ为代表的个人计算机逐步风靡全球。各种计算机的主板都有两个问题要解决，一是如何与外围高速交换数据，二是如何扩展计算机功能，解决问题的方法是采用各种类型的扩展总线。个人计算机的发展是与扩展总线的不断改进、不断更新分不开的。总线标准的制定，以及各种总线对市场的争夺，市场主流的不断更迭，始终是和个人计算机不断发展的步伐紧密配合的。扩展总线类型播报编辑PC/XT总线系统80年代初期，IBMPC/XT的出现，它所用的8位扩展总线代表了当时的一种新型总线标准。这种机型很快就使AppleΙΙ相形见绌。随着外部设备性能、主存储器速度和16位中央处理器性能的提高，8位总线已不能适应新的技术，IBM使用Intel公司推出了全新的16位微处理器80286开发PC/AT个人计算机，采用了全新的16位扩展总线，由PC/XT扩展总线增加地址信号、数据信号线及控制信号线而成，这两种总线在同一块底板上并存了较长一段时间。ISA总线系统PC/AT的扩展总线系统也就是后来在市场上使用了很长时间的工业标准体系结构总线（ISA）。这种16位的扩展总线系统在相当长时间内一直是市场上主板制造商使用的主流，有人试图另立标准，但都被市场所淘汰（这种情况一直延续到32位微处理器芯片出现之后）。[1]SRAM：基本简介播报编辑SRAM不需要刷新电路即能保存它内部存储的数据。而DRAM（DynamicRandomAccessMemory）每隔一段时间，要刷新充电一次，否则内部的数据即会消失，因此SRAM具有较高的性能，但是SRAM也有它的缺点，即它的集成度较低，功耗较DRAM大[1]，相同容量的DRAM内存可以设计为较小的体积，但是SRAM却需要很大的体积。同样面积的硅片可以做出更大容量的DRAM，因此SRAM显得更贵。[2]主要规格播报编辑一种是置于cpu与主存间的高速缓存，它有两种规格：一种是固定在主板上的高速缓存（CacheMemory）；另一种是插在卡槽上的COAST（CacheOnAStick）扩充用的高速缓存，另外在CMOS芯片1468l8的电路里，它的内部也有较小容量的128字节SRAM，存储所设置的配置数据。还有为了加速CPU内部数据的传送，自80486CPU起，在CPU的内部也设计有高速缓存，故在PentiumCPU就有所谓的L1Cache（一级高速缓存）和L2Cache（二级高速缓存）的名词，一般L1Cache是建在CPU的内部，L2Cache是设计在CPU的外部，但是PentiumPro把L1和L2Cache同时设计在CPU的内部，故PentiumPro的体积较大。PentiumⅡ又把L2Cache移至CPU内核之外的黑盒子里。SRAM显然速度快，不需要刷新操作，但是也有另外的缺点，就是价格高，体积大，所以在主板上还不能作为用量较大的主存。[2]主要用途播报编辑图1SRAMSRAM主要用于二级高速缓存（Level2Cache）。它利用晶体管来存储数据。与DRAM相比，SRAM的速度快，但在相同面积中SRAM的容量要比其他类型的内存小。SRAM的速度快但昂贵，一般用小容量的SRAM作为更高速CPU和较低速DRAM之间的缓存（cache）。SRAM也有许多种，如AsyncSRAM（AsynchronousSRAM，异步SRAM）、SyncSRAM（SynchronousSRAM，同步SRAM）、PBSRAM（PipelinedBurstSRAM，流水式突发SRAM），还有INTEL没有公布细节的CSRAM等。基本的SRAM的架构如图1所示，SRAM一般可分为五大部分：存储单元阵列（corecellsarray），行/列地址译码器（decode），灵敏放大器（SenseAmplifier），控制电路（controlcircuit），缓冲/驱动电路（FFIO）。SRAM是静态存储方式，以双稳态电路作为存储单元，SRAM不像DRAM一样需要不断刷新，而且工作速度较快，但由于存储单元器件较多，集成度不太高，功耗也较大。[2]工作原理播报编辑图2六管单元电路图SRAM的工作原理：假设准备往图2的6T存储单元写入“1”，先将某一组地址值输入到行、列译码器中，选中特定的单元，然后使写使能信号WE有效，将要写入的数据“1”通过写入电路变成“1”和“0”后分别加到选中单元的两条位线BL,BLB上，此时选中单元的WL=1，晶体管N0,N5打开，把BL,BLB上的信号分别送到Q,QB点，从而使Q=1，QB=0，这样数据“1”就被锁存在晶体管P2,P3,N3,N4构成的锁存器中。写入数据“0”的过程类似。SRAM的读过程以读“1”为例，通过译码器选中某列位线对BL,BLB进行预充电到电源电压VDD，预充电结束后，再通过行译码器选中某行，则某一存储单元被选中，由于其中存放的是“1”，则WL=1、Q=1、QB=0。晶体管N4、N5导通，有电流经N4、N5到地，从而使BLB电位下降，BL、BLB间电位产生电压差，当电压差达到一定值后打开灵敏度放大器，对电压进行放大，再送到输出电路，读出数据。[2]类型播报编辑1.非挥发性SRAM非挥发性SRAM（Non-volatileSRAM，nvSRAM）具有SRAM的标准功能，但在失去电源供电时可以保住其数据。非挥发性SRAM用于网络、航天、医疗等需要关键场合—保住数据是关键的而且不可能用上电池。2.异步SRAM异步SRAM（AsynchronousSRAM）的容量从4Kb到64Mb。SRAM的快速访问使得异步SRAM适用于小型的cache很小的嵌入式处理器的主内存，这种处理器广泛用于工业电子设备、测量设备、硬盘、网络设备等等。根据晶体管类型分类双极性结型晶体管（用于TTL与ECL）—非常快速但是功耗巨大MOSFET（用于CMOS）—本文详细介绍的类型，低功耗，应用广泛。根据功能分类异步—独立的时钟频率，读写受控于地址线与控制使能信号。同步—所有工作是时钟脉冲边沿开始，地址线、数据线、控制线均与时钟脉冲配合。根据特性分类零总线翻转（Zerobusturnaround，ZBT）—SRAM总线从写到读以及从读到写所需要的时钟周期是0同步突发SRAM（synchronous-burstSRAM，syncBurstSRAM）—DDRSRAM—同步、单口读/写，双数据率I/OQDRSRAM（QuadDataRate(QDR)SRAM）—同步，分开的读/写口，同时读写4个字（word）。根据触发类型二进制SRAM三进制计算机SRAM[2]结构原理播报编辑SRAM（StaticRAM），即静态RAM，它也由晶体管组成。接通代表1，断开表示0，并且状态会保持到接收了一个改变信号为止。这些晶体管不需要刷新，但停机或断电时，它们同DRAM一样，会丢掉信息。SRAM的速度非常快，通常能以20ns或更快的速度工作。一个DRAM存储单元仅需一个晶体管和一个小电容。而每个SRAM单元需要四到六个晶体管和其他零件。所以，除了价格较贵外，SRAM芯片在外形上也较大，与DRAM相比要占用更多的空间。由于外形和电气上的差别，SRAM和DRAM是不能互换的。SRAM的高速和静态特性使它们通常被用来作为Cache存储器。计算机的主板上都有Cache插座。图3SRAM如图3所示的是一个SRAM的结构框图。由图3看出SRAM一般由五大部分组成，即存储单元阵列、地址译码器（包括行译码器和列译码器）、灵敏放大器、控制电路和缓冲/驱动电路。在图3中，A0-Am-1为地址输入端，CSB，WEB和OEB为控制端，控制读写操作，为低电平有效，1100-11ON-1为数据输入输出端。存储阵列中的每个存储单元都与其它单元在行和列上共享电学连接，其中水平方向的连线称为“字线”，而垂直方向的数据流入和流出存储单元的连线称为“位线”。通过输入的地址可选择特定的字线和位线，字线和位线的交叉处就是被选中的存储单元，每一个存储单元都是按这种方法被唯一选中，然后再对其进行读写操作。有的存储器设计成多位数据如4位或8位等同时输入和输出，这样的话，就会同时有4个或8个存储单元按上述方法被选中进行读写操作。在SRAM中，排成矩阵形式的存储单元阵列的周围是译码器和与外部信号的接口电路。存储单元阵列通常采用正方形或矩阵的形式，以减少整个芯片面积并有利于数据的存取。以一个存储容量为4K位的SRAM为例，共需12条地址线来保证每一个存储单元都能被选中（=4096）。如果存储单元阵列被排列成只包含一列的长条形，则需要一个12/4K位的译码器，但如果排列成包含64行和64列的正方形，这时则只需一个6/64位的行译码器和一个6/64位的列译码器，行、列译码器可分别排列在存储单元阵列的两边，64行和64列共有4096个交叉点，每一个点就对应一个存储位。因此，将存储单元排列成正方形比排列成一列的长条形要大大地减少整个芯片地面积。存储单元排列成长条形除了形状奇异和面积大以外，还有一个缺点，那就是单排在列的上部的存储单元与数据输入/输出端的连线就会变得很长，特别是对于容量比较大得存储器来说，情况就更为严重，而连线的延迟至少是与它的长度成线性关系，连线越长，线上的延迟就越大，所以就会导致读写速度的降低和不同存储元连线延迟的不一致性，这些都是在设计中需要避免的。[3]应用与使用播报编辑特性SRAM是比DRAM更为昂贵，但更为快速、低功耗（仅空闲状态）。因此SRAM首选用于带宽要求高。SRAM比起DRAM更为容易控制，也更是随机访问。由于复杂的内部结构，SRAM比DRAM的占用面积更大，因而不适合用于更高储存密度低成本的应用，如PC内存。时钟频率与功耗SRAM功耗取决于它的访问频率。如果用高频率访问SRAM，其功耗比DRAM大得多。有的SRAM在全带宽时功耗达到几个瓦特量级。另一方面，SRAM如果用于温和的时钟频率的微处理器，其功耗将非常小，在空闲状态时功耗可以忽略不计—几个微瓦特级别。SRAM用于：通用的产品asynchronous界面，例如28针32Kx8的chip（通常命名为XXC256），以及类似的产品最多16Mbit每片synchronous界面，通常用做高速缓存（cache）以及其它要求突发传输的应用，最多18Mbit（256Kx72）每片集成于芯片内作为微控制器的RAM或者cache（通常从32bytes到128kilobytes）作为强大的微处理器的主caches，如x86系列与许多其它CPU（从8kiB到几百万字节的量级）作为寄存器（参见寄存器堆）用于特定的ICs或ASIC（通常在几千字节量级）用于FPGA与CPLD嵌入式应用工业与科学用的很多子系统，汽车电子等等都用到了SRAM。现代设备中很多都嵌入了几千字节的SRAM。实际上几乎所有实现了电子用户界面的现代设备都可能用上了SRAM，如玩具。数码相机、手机、音响合成器等往往用了几兆字节的SRAM。实时信号处理电路往往使用双口（dual-ported）的SRAM。用于计算机SRAM用于PC、工作站、路由器以及外设：内部的CPU高速缓存，外部的突发模式使用的SRAM缓存，硬盘缓冲区，路由器缓冲区，等等。LCD显示器或者打印机也通常用SRAM来缓存数据。SRAM做的小型缓冲区也常见于CDROM与CDRW的驱动器中，通常为256KiB或者更多，用来缓冲音轨数据。线缆调制解调器及类似的连接于计算机的设备也使用了SRAM。爱好者搭建自己的处理器的业余爱好者更愿意选用SRAM，这是由于其易用性的工作界面。没有DRAM所需的刷新周期；地址总线与数据总线直接访问而不是像DRAM那样多工分别访问。SRAM通常只需3个控制信号：ChipEnable(CE),WriteEnable(WE)与OutputEnable（OE）。对于同步SRAM,还需要时钟信号（Clock，CLK）。[4]参见播报编辑DRAM,包括PSRAM(pseudo-staticRAM)闪存晶体管总线：工作原理播报编辑如果说主板（MotherBoard）是一座城市，那么总线就像是城市里的公共汽车（bus），能按照固定行车路线，传输来回不停运作的比特（bit）。一条线路在同一时间内都仅能负责传输一个比特。因此，必须同时采用多条线路才能传送更多数据，而总线可同时传输的数据数就称为宽度（width），以比特为单位，总线宽度愈大，传输性能就愈佳。总线的带宽（即单位时间内可以传输的总数据数）为：总线带宽=频率x宽度/8（Bytes/sec）[3]。当总线空闲（其他器件都以高阻态形式连接在总线上）且一个器件要与目的器件通信时，发起通信的器件驱动总线，发出地址和数据。其他以高阻态形式连接在总线上的器件如果收到（或能够收到）与自己相符的地址信息后，即接收总线上的数据。发送器件完成通信，将总线让出（输出变为高阻态）。在计算机中用于连接各种功能部件并在它们之间传送数据的公用线路或通路。在计算机系统中按其所连接的对象，总线可分为：片总线，又称器件级总线，它是中央处理器芯片内部的总线。内总线，又称系统总线或板级总线，它是计算机各功能部件之间的传输通路，微型计算机总线通常称为内总线。外总线，又称通信总线，它是计算机系统之间，或者是计算机主机与外围设备之间的传输通路[1]。总线是一种共享型的数据传送设备。虽然总线上可联接多个设备，但任一时刻通常只能有一对设备参与数据传输。按信息传输的形式，总线可分为并行总线和串行总线两种。并行总线对n位二进制信息用n条传输线同时传送，其特点是传输速度快，但系统结构较复杂，它用于计算机系统内的各部件之间的连接；串行总线对多位二进制信息共用一条传输线，多位二进制信息按时间先后顺序通过总线，它的特点是结构简单，但其传输速度较慢。总线必须有明确的规范：总线定时协议，即在总线上传送信息时必须遵守一定的定时规则，例如同步总线定时，异步总线定时，半同步总线定时等。总线的物理特性，包括信号、电源、地址的电气特性，以及连线、接插件的机械特性。总线带宽，它是总线所能达到的最高传输率，其单位是MB/S。总线特性播报编辑由于总线是连接各个部件的一组信号线。通过信号线上的信号表示信息，通过约定不同信号的先后次序即可约定操作如何实现。总线的特性如下（1）物理特性：物理特性又称为机械特性，指总线上部件在物理连接时表现出的一些特性，如插头与插座的几何尺寸、形状、引脚个数及排列顺序等。（2）功能特性：功能特性是指每一根信号线的功能，如地址总线用来表示地址码。数据总线用来表示传输的数据，控制总线表示总线上操作的命令、状态等。（3）电气特性：电气特性是指每一根信号线上的信号方向及表示信号有效的电平范围，通常，由主设备（如CPU）发出的信号称为输出信号（OUT），送入主设备的信号称为输入信号（IN）。通常数据信号和地址信号定义高电平为逻辑1、低电平为逻辑0，控制信号则没有俗成的约定，如WE表示低电平有效、Ready表示高电平有效。不同总线高电平、低电平的电平范围也无统一的规定，通常与TTL是相符的。（4）时间特性：时间特性又称为逻辑特性，指在总线操作过程中每一根信号线上信号什么时候有效，通过这种信号有效的时序关系约定，确保了总线操作的正确进行。为了提高计算机的可拓展性，以及部件及设备的通用性，除了片内总线外，各个部件或设备都采用标准化的形式连接到总线上，并按标准化的方式实现总线上的信息传输。而总线的这些标准化的连接形式及操作方式，统称为总线标准。如ISA、PCI、USB总线标准等，相应的，采用这些标准的总线为ISA总线、PCI总线、USB总线等。总线分类播报编辑总线按功能和规范可分为五大类型:数据总线（DataBus）：在CPU与RAM之间来回传送需要处理或是需要储存的数据。地址总线（AddressBus）：用来指定在RAM（RandomAccessMemory）之中储存的数据的地址。控制总线（ControlBus）：将微处理器控制单元（ControlUnit）的信号，传送到周边设备。扩展总线（ExpansionBus）：外部设备和计算机主机进行数据通信的总线，例如ISA总线，PCI总线。局部总线（LocalBus）：取代更高速数据传输的扩展总线。三类总线在微机系统中的地位和关系其中的数据总线DB（DataBus）、地址总线AB（AddressBus）和控制总线CB（ControlBus），也统称为系统总线，即通常意义上所说的总线。有的系统中，数据总线和地址总线是复用的，即总线在某些时刻出现的信号表示数据而另一些时刻表示地址；而有的系统是分开的。51系列单片机的地址总线和数据总线是复用的，而一般PC中的总线则是分开的。“数据总线DB”用于传送数据信息。数据总线是双向三态形式的总线，即他既可以把CPU的数据传送到存储器或I/O接口等其它部件，也可以将其它部件的数据传送到CPU。数据总线的位数是微型计算机的一个重要指标，通常与微处理的字长相一致。例如Intel8086微处理器字长16位，其数据总线宽度也是16位。需要指出的是，数据的含义是广义的，它可以是真正的数据，也可以是指令代码或状态信息，有时甚至是一个控制信息，因此，在实际工作中，数据总线上传送的并不一定仅仅是真正意义上的数据。常见的数据总线为ISA（ISA总线）、EISA、VESA、PCI等。“地址总线AB”是专门用来传送地址的，由于地址只能从CPU传向外部存储器或I/O端口，所以地址总线总是单向三态的，这与数据总线不同。地址总线的位数决定了CPU可直接寻址的内存空间大小，比如8位微机的地址总线为16位，则其最大可寻址空间为2^16=64KB，16位微型机（x位处理器指一个时钟周期内微处理器能处理的位数[1、0]多少，即字长大小）的地址总线为20位，其可寻址空间为2^20=1MB。一般来说，若地址总线为n位，则可寻址空间为2^n字节。“控制总线CB”用来传送控制信号和时序信号。控制信号中，有的是微处理器送往存储器和I/O接口电路的，如读/写信号，片选信号、中断响应信号等；也有是其它部件反馈给CPU的，比如：中断申请信号、复位信号、总线请求信号、设备就绪信号等。因此，控制总线的传送方向由具体控制信号而定，(信息)一般是双向的，控制总线的位数要根据系统的实际控制需要而定。实际上控制总线的具体情况主要取决于CPU。按照传输数据的方式划分，可以分为串行总线和并行总线。串行总线中，二进制数据逐位通过一根数据线发送到目的器件；并行总线的数据线通常超过2根。常见的串行总线有SPI、I2C、USB及RS232等。按照时钟信号是否独立，可以分为同步总线和异步总线。同步总线的时钟信号独立于数据，而异步总线的时钟信号是从数据中提取出来的。SPI、I2C是同步串行总线，RS232采用异步串行总线。内部总线播报编辑并发CAMAC，用于仪表检测系统工业标准架构总线（ISA）扩展ISA（EISA）LowPinCount（LPC）微通道（MCA）MBus多总线（Multibus），用于工业生产系统NuBus，或称IEEE1196OPTi本地总线，用于早期Intel80486主板外围部件互联总线（PCI）S-100总线（S-100bus），或称IEEE696，用于Altair或类似微处理器SBus或称IEEE1496VESA本地总线（VLB，VL-bus）VERSAmoduleEurocardbus（VME总线）STD总线（STDbus），用于八位或十六位微处理器系统UnibusQ-BusPC/104PC/104PlusPC/104ExpressPCI-104PCIe-104串行1-WireHyperTransportI²C串行PCI（PCIe）串行外围接口总线（SPI总线）火线i.Link（IEEE1394）外部总线播报编辑外部总线指缆线和连接器系统，用来传输I/O路径技术指定的数据和控制信号，另外还包括一个总线终结电阻或电路，这个终结电阻用来减弱电缆上的信号反射干扰。并发ATA：磁盘/磁带周边附件总线，也称PATA、IDE、EIDE、ATAPI等等。(theoriginalATAisparallel,butseealsotherecentserialATA)HIPPI（HIghPerformanceParallelInterface）：高速平行接口。IEEE-488：也称GPIB（General-PurposeInstrumentationBus）或HPIB（Hewlett-PackardInstrumentationBus）。PCcard：前身为知名的PCMCIA，常用于笔记本电脑和其它便携式设备，但自从引入USB以及嵌入式网络后，这个总线就慢慢不再使用了。SCSI（SmallComputerSystemInterface）：小型电脑系统接口，磁盘/磁带周边附件总线。串行USBUniversalSerialBus,大量外部设备均采用此总线SerialAttachedSCSIandotherserialSCSIbusesSerialATAControllerAreaNetwork("CAN总线")EIA-485FireWireThunderbolt计算机总线播报编辑计算机总线是一组能为多个部件分时共享的信息传送线，用来连接多个部件并为之提供信息交换通路。总线不仅是一组信号线，从广义上讲，总线是一组传送线路及相关的总线协议。a.主板的总线在计算机科学技术中，人们常常以MHz表示的速度来描述总线频率。计算机总线的种类很多，前端总线的英文名字是FrontSideBus，通常用FSB表示，是将CPU连接到北桥芯片的总线。计算机的前端总线频率是由CPU和北桥芯片共同决定的。b.硬盘的总线总线一般有SCSI、ATA、SATA等几种。SATA是串行ATA的缩写，为什么要使用串行ATA就要从PATA——并行ATA的缺点说起。我们知道ATA或者说普通IDE硬盘的数据线最初就是40根的排线，这40根线里面有数据线、时钟线、控制线、地线，其中32根数据线是并行传输的（一个时钟周期可以同时传输4个字节的数据），因此对同步性的要求很高。这就是为什么从PATA-66（就是常说的DMA66）接口开始必须使用80根的硬盘数据线，其实增加的这40根全是屏蔽用的地线，而且只在主板一边接地（千万不要接反了，反了的话屏蔽作用大大降低），有了良好的屏蔽硬盘的传输速度才能达到66MB/s、100MB/s和最高的133MB/s。但是在PATA-133之后，并行传输速度已经到了极限，而且PATA的三大缺点暴露无遗：信号线长度无法延长、信号同步性难以保持、5V信号线耗电较大。那为什么SCSI-320接口的数据线能达到320MB/s的高速、而且线缆可以很长呢？你有没有注意到SCSI的高速数据线是“花线”？这可不是为了好看，那“花”的部分实际上就是一组组的差分信号线两两扭合而成，这成本可不是普通电脑系统愿意承担的。c.其他的总线计算机中其他的总线还有：通用串行总线USB（UniversalSerialBus）、IEEE1394、PCI等等。技术指标播报编辑1、总线的带宽（总线数据传输速率）总线的带宽指的是单位时间内总线上传送的数据量，即每秒钟传送MB的最大稳态数据传输率[2]。与总线密切相关的两个因素是总线的位宽和总线的工作频率，它们之间的关系：总线的带宽=总线的工作频率*总线的位宽/8或者总线的带宽=（总线的位宽/8）/总线周期2、总线的位宽总线的位宽指的是总线能同时传送的二进制数据的位数，或数据总线的位数，即32位、64位等总线宽度的概念。总线的位宽越宽，每秒钟数据传输率越大，总线的带宽越宽。3、总线的工作频率总线的工作时钟频率以MHZ为单位，工作频率越高，总线工作速度越快，总线带宽越宽。合理搭配播报编辑总线主板北桥芯片负责联系内存、显卡等数据吞吐量最大的部件，并和南桥芯片连接。CPU就是通过前端总线（FSB）连接到北桥芯片，进而通过北桥芯片和内存、显卡交换数据。前端总线是CPU和外界交换数据的最主要通道，因此前端总线的数据传输能力对计算机整体性能作用很大，如果没足够快的前端总线，再强的CPU也不能明显提高计算机整体速度。数据传输最大带宽取决于所有同时传输的数据的宽度和传输频率，即数据带宽=（总线频率×数据位宽）÷8。PC机上所能达到的前端总线频率有266MHz、333MHz、400MHz、533MHz、800MHz几种，前端总线频率越大，代表着CPU与北桥芯片之间的数据传输能力越大，更能充分发挥出CPU的功能。CPU技术发展很快，运算速度提高很快，而足够大的前端总线可以保障有足够的数据供给给CPU，较低的前端总线将无法供给足够的数据给CPU，这样就限制了CPU性能得发挥，成为系统瓶颈。总线操作播报编辑总线一个操作过程是完成两个模块之间传送信息，启动操作过程的是主模块，另外一个是从模块。某一时刻总线上只能有一个主模块占用总线。总线的操作步骤：主模块申请总线控制权，总线控制器进行裁决。总线的操作步骤：主模块得到总线控制权后寻址从模块，从模块确认后进行数据传送。数据传送的错误检查。总线定时协议：定时协议可保证数据传输的双方操作同步，传输正确。定时协议有三种类型：同步总线定时：总线上的所有模块共用同一时钟脉冲进行操作过程的控制。各模块的所有动作的产生均在时钟周期的开始，多数动作在一个时钟周期中完成。异步总线定时：操作的发生由源或目的模块的特定信号来确定。总线上一个事件发生取决前一事件的发生，双方相互提供联络信号。总线定时协议半同步总线定时：总线上各操作的时间间隔可以不同，但必须是时钟周期的整数倍，信号的出现,采样与结束仍以公共时钟为基准。ISA总线采用此定时方法。数据传输类型：分单周期方式和突发(burst)方式。单周期方式：一个总线周期只传送一个数据。突发方式：取得主线控制权后进行多个数据的传输。寻址时给出目的地首地址，访问第一个数据，数据2、3到数据n的地址在首地址基础上按一定规则自动寻址（如自动加1）。总线标准播报编辑为什么要制定总线标准?便于机器的扩充和新设备的添加，有了总线标准，不同厂商可以按照同样的标准和规范生产各种不同功能的芯片、模块和整机，用户可以根据功能需求去选择不同厂家生产的、基于同种总线标准的模块和设备，甚至可以按照标准，自行设计功能特殊的专用模块和设备，以组成自己所需的应用系统。这样可使芯片级、模块级、设备级等各级别的产品都具有兼容性和互换性，以使整个计算机系统的可维护性和可扩充性得到充分保证。总线标准的技术规范？机械结构规范：模块尺寸、总线插头、总线接插件以及安装尺寸均有统一规定。功能规范：总线每条信号线（引脚的名称）、功能以及工作过程要有统一规定。电气规范：总线每条信号线的有效电平、动态转换时间、负载能力等。哪种总线是标准的？主板上的处理器-主存总线经常是特定的专用总线，而用于连接各种I/O模块的I/O总线和底板式总线则通常可在不同计算机中互用。实际上，底板式总线和I/O总线通常是标准总线，可被许多由不同公司制造的不同计算机使用。总线标准-ISAISA（IndustrialStandardArchitecture）总线是IBM公司1984年为推出PC/AT机而建立的系统总线标准。所以也叫AT总线。主要特点:(1)支持64KI/O地址空间、16M主存地址空间的寻址，支持15级硬中断、7级DMA通道。(2)是一种简单的多主控总线。除了CPU外，DMA控制器、DRAM刷新控制器和带处理器的智能接口控制卡都可成为总线主控设备。(3)支持8种总线事务类型：存储器读、存储器写、I/O读、I/O写、中断响应、DMA响应、存储器刷新、总线仲裁。它的时钟频率为8MHz，共有98根信号线。数据线和地址线分离，数据线宽度为16位，可以进行8位或16位数据的传送，所以最大数据传输率为16MB/s。总线标准-EISAEISA(ExtendedIndustrialStanderdArchitecture)总线是一种在ISA总线基础上扩充的开放总线标准。支持多总线主控和突发传输方式。时钟频率为8.33MHz。共有198根信号线，在原ISA总线的98根线的基础上扩充了100根线，与原ISA总线完全兼容。具有分立的数据线和地址线。数据线宽度为32位，具有8位、16位、32位数据传输能力，所以最大数据传输率为33MB/s。地址线的宽度为32位，所以寻址能力达232。即：CPU或DMA控制器等这些主控设备能够对4G范围的主存地址空间进行访问。总线标准-PCIPCI（PeripheralComponentInterconnect）总线是一种高性能的32位局部总线。它由Intel公司于1991年底提出，后来又联合IBM、DEC等100多家PC业界主要厂家，于1992年成立PCI集团，称为PCISIG，进行统筹和推广PCI标准的工作。用于高速外设的I/O接口和主机相连。采用自身33MHz的总线频率，数据线宽度为32位，可扩充到64位，所以数据传输率可达132MB/s～264MB/s。速度快、支持无限突发传输方式、支持并发工作（PCI桥提供数据缓冲,并使总线独立于CPU），可在主板上和其他系统总线（如：ISA、EISA或MCA）相连接，系统中的高速设备挂接在PCI总线上，而低速设备仍然通过ISA、EISA等这些低速I/O总线支持。支持基于微处理器的配置，可用在单处理器系统中，也可用于多处理器系统。优点与缺点播报编辑采用总线结构的主要优点1、面向存储器的双总线结构信息传送效率较高，这是它的主要优点。但CPU与I/O接口都要访问存储器时，仍会产生冲突。2、CPU与高速的局部存储器和局部I/O接口通过高传输速率的局部总线连接，速度较慢的全局存储器和全局I/O接口与较慢的全局总线连接，从而兼顾了高速设备和慢速设备，使它们之间不互相牵扯。3、简化了硬件的设计。便于采用模块化结构设计方法，面向总线的微型计算机设计只要按照这些规定制作cpu插件、存储器插件以及I/O插件等，将它们连入总线就可工作，而不必考虑总线的详细操作。4、简化了系统结构。整个系统结构清晰。连线少，底板连线可以印制化。5、系统扩充性好。一是规模扩充，规模扩充仅仅需要多插一些同类型的插件。二是功能扩充，功能扩充仅仅需要按照总线标准设计新插件，插件插入机器的位置往往没有严格的限制。6、系统更新性能好。因为cpu、存储器、I/O接口等都是按总线规约挂到总线上的，因而只要总线设计恰当，可以随时随着处理器的芯片以及其他有关芯片的进展设计新的插件，新的插件插到底板上对系统进行更新，其他插件和底板连线一般不需要改。7、便于故障诊断和维修。用主板测试卡可以很方便找到出现故障的部位，以及总线类型。采用总线结构的缺点由于在CPU与主存储器之间、CPU与I/O设备之间分别设置了总线，从而提高了微机系统信息传送的速率和效率。但是由于外部设备与主存储器之间没有直接的通路，它们之间的信息交换必须通过CPU才能进行中转，从而降低了CPU的工作效率（或增加了CPU的占用率。一般来说，外设工作时要求CPU干预越少越好。CPU干预越少，这个设备的CPU占用率就越低，说明设备的智能化程度越高），这是面向CPU的双总线结构的主要缺点。同时还包括：1、利用总线传送具有分时性。当有多个主设备同时申请总线的使用是必须进行总线的仲裁。2、总线的带宽有限，如果连接到总线上的某个硬件设备没有资源调控机制容易造成信息的延时（这在某些即时性强的地方是致命的）。3、连到总线上的设备必须有信息的筛选机制，要判断该信息是否是传给自己的。相关信息播报编辑任何一个微处理器都要与一定数量的部件和外围设备连接，但如果将各部件和每一种外围设备都分别用一组线路与CPU直接连接，那么连线将会错综复杂，甚至难以实现。为了简化硬件电路设计、简化系统结构，常用一组线路，配置以适当的接口电路，与各部件和外围设备连接，这组共用的连接线路被称为总线。采用总线结构便于部件和设备的扩充，尤其制定了统一的总线标准则容易使不同设备间实现互连。微机中总线一般有内部总线、系统总线和外部总线。内部总线是微机内部各外围芯片与处理器之间的总线，用于芯片一级的互连；而系统总线是微机中各插件板与系统板之间的总线，用于插件板一级的互连；外部总线则是微机和外部设备之间的总线，微机作为一种设备，通过该总线和其他设备进行信息与数据交换，它用于设备一级的互连。另外，从广义上说，计算机通信方式可以分为并行通信和串行通信，相应的通信总线被称为并行总线和串行总线。并行通信速度快、实时性好，但由于占用的口线多，不适于小型化产品；而串行通信速率虽低，但在数据通信吞吐量不是很大的微处理电路中则显得更加简易、方便、灵活。串行通信一般可分为异步模式和同步模式。---随着微电子技术和计算机技术的发展，总线技术也在不断地发展和完善，而使计算机总线技术种类繁多，各具特色。总线的发展史播报编辑ISA总线（IndustryStandardArchitecture）最早的PC总线是IBM公司1981年在PC/XT电脑采用的系统总线，它基于8bit的8088处理器，被称为PC总线或者PC/XT总线。1984年，IBM推出基于16-bitIntel80286处理器的PC/AT电脑，系统总线也相应地扩展为16bit，并被称呼为PC/AT总线。而为了开发与IBMPC兼容的外围设备，行业内便逐渐确立了以IBMPC总线规范为基础的ISA（工业标准架构：IndustryStandardArchitecture）总线。PCI总线（PeripheralComponentInterconnect）由于ISA/EISA总线速度缓慢，一度出现CPU的速度甚至还高过总线的速度，造成硬盘、显示卡还有其它的外围设备只能通过慢速并且狭窄的瓶颈来发送和接受数据，使得整机的性能受到严重的影响。为了解决这个问题，1992年Intel在发布486处理器的时候，也同时提出了32-bit的PCI（周边组件互连）总线。AGP总线（AcceleratedGraphicsPort）PCI总线是独立于CPU的系统总线，可将显示卡、声卡、网卡、硬盘控制器等高速的外围设备直接挂在CPU总线上，打破了瓶颈，使得CPU的性能得到充分的发挥。可惜的是，由于PCI总线只有133MB/s的带宽，对付声卡、网卡、视频卡等绝大多数输入/输出设备也许显得绰绰有余，但对于胃口越来越大的3D显卡却力不从心，并成为了制约显示子系统和整机性能的瓶颈。因此，PCI总线的补充——AGP总线就应运而生了。PCI-Express在经历了长达10年的修修补补，PCI总线已经无法满足电脑性能提升的要求，必须由带宽更大、适应性更广、发展潜力更深的新一代总线取而代之，这就是PCI-Express总线。相对于PCI总线来讲，PCI-Express总线能够提供极高的带宽，来满足系统的需求。PCIExpress总线2.0标准的带宽如下表所示：PCI-E2.0标准带宽经历着这么三代半（AGP总线只是一种增强型的PCI总线）的发展，PC的外部总线终于发展到PCI-E4.0，提供了比以往总线大得多的带宽。至于今后总线发展的方向，相信会随着人们对带宽需要的不断增加，而很快来出现。专业术语播报编辑1.intermediatedistributionbus中间分布总线2.VESAlocalbus(VL-bus)VESA局域总线3.analysis,busbounce总线跳动分析4.analogsummingbus模拟加法总线5.architecture,micro-channelbus(MCA)微通道总线（体系）结构6.arbitrationbus判优总线7.arbiter,bus总线判优器8.backplanebus基架总线9.back-off,bus总线退出10.basebus基底总线11.bus-timingemulation总线时序仿真12.bus-intensive总线密集13.bus-controlunit总线控制单元14.bus,utility公用程序总线15.bus,summing加法总线16.bus,realtimesystemintegration(RTSIBus)即时系统综合总线17.bus,peripheralinterface外设接口总线18.bus,multisystemextensioninterface(MXIbus)多系统延伸接口总线19.bus,multidropparallel分支平行总线20.bus,micro-channel微通道总线总线带宽：概念简介播报编辑从电子电路角度出发，带宽（Bandwidth）本意指的是电子电路中存在一个固有通频带，各类复杂的电子电路无一例外都存在电感、电容或相当功能的储能元件，即使没有采用现成的电感线圈或电容，导线自身就是一个电感，而导线与导线之间、导线与地之间便可以组成电容——这就是通常所说的杂散电容或分布电容；不管是哪种类型的电容、电感，都会对信号起着阻滞作用从而消耗信号能量，严重的话会影响信号品质。这种效应与交流电信号的频率成正比关系，当频率高到一定程度、令信号难以保持稳定时，整个电子电路自然就无法正常工作。为此，电子学上就提出了带宽的概念，它指的是电路可以保持稳定工作的频率范围。而属于该体系的有显示器带宽、通讯/网络中的带宽等等。而第二种带宽的概念指的其实是数据传输率，譬如内存带宽、总线带宽、网络带宽等等，都是以字节/秒为单位。对于电子电路中的带宽，决定因素在于电路设计。它主要是由高频放大部分元件的特性决定，而高频电路的设计是比较困难的部分，成本也比普通电路要高很多。这部分内容涉及到电路设计的知识，对此我们就不做深入的分析。而对于总线、内存中的带宽，决定其数值的主要因素在于工作频率和位宽，在这两个领域，带宽等于工作频率与位宽的乘积，因此带宽和工作频率、位宽两个指标成正比。不过工作频率或位宽并不能无限制提高，它们受到很多因素的制约[1]。总线带宽简介播报编辑在计算机系统中，总线的作用就好比是人体中的神经系统，它承担的是所有数据传输的职责，而各个子系统间都必须藉由总线才能通讯，例如，CPU和北桥间有前端总线、北桥与显卡间为AGP总线、芯片组间有南北桥总线，各类扩展设备通过PCI、PCI-X总线与系统连接；主机与外部设备的连接也是通过总线进行，如流行的USB2.0、IEEE1394总线等等，一句话，在一部计算机系统内，所有数据交换的需求都必须通过总线来实现！按照工作模式不同，总线可分为两种类型，一种是并行总线，它在同一时刻可以传输多位数据，好比是一条允许多辆车并排开的宽敞道路，而且它还有双向单向之分；另一种为串行总线，它在同一时刻只能传输一个数据，好比只容许一辆车行走的狭窄道路，数据必须一个接一个传输、看起来仿佛一个长长的数据串，故称为“串行”。并行总线和串行总线的描述参数存在一定差别。对并行总线来说，描述的性能参数有以下三个：总线宽度、时钟频率、数据传输频率。其中，总线宽度就是该总线可同时传输数据的位数，好比是车道容许并排行走的车辆的数量；例如，16位总线在同一时刻传输的数据为16位，也就是2个字节；而32位总线可同时传输4个字节，64位总线可以同时传输8个字节......显然，总线的宽度越大，它在同一时刻就能够传输更多的数据。不过总线的位宽无法无限制增加。总线的带宽指的是这条总线在单位时间内可以传输的数据总量，它等于总线位宽与工作频率的乘积。例如，对于64位、800MHz的前端总线，它的数据传输率就等于64bit×800MHz÷8(Byte)=6.4GB/s；32位、33MHzPCI总线的数据传输率就是32bit×33MHz÷8=132MB/s，等等，这项法则可以用于所有并行总线上面——看到这里，读者应该明白我们所说的总线带宽指的就是它的数据传输率。对串行总线来说，带宽和工作频率的概念与并行总线完全相同，只是它改变了传统意义上的总线位宽的概念。在频率相同的情况下，并行总线比串行总线快得多，那么，为什么各类并行总线反而要被串行总线接替呢？原因在于并行总线虽然一次可以传输多位数据，但它存在并行传输信号间的干扰现象，频率越高、位宽越大，干扰就越严重，因此要大幅提高现有并行总线的带宽是非常困难的；而串行总线不存在这个问题，总线频率可以大幅向上提升，这样串行总线就可以凭借高频率的优势获得高带宽。而为了弥补一次只能传送一位数据的不足，串行总线常常采用多条管线（或通道）的做法实现更高的速度——管线之间各自独立，多条管线组成一条总线系统，从表面看来它和并行总线很类似，但在内部它是以串行原理运作的。对这类总线，带宽的计算公式就等于“总线频率×管线数”，这方面的例子有PCIExpress和HyperTransport，前者有×1、×2、×4、×8、×16和×32多个版本，在第一代PCIExpress技术当中，单通道的单向信号频率可达2.5GHz，我们以×16举例，这里的16就代表16对双向总线，一共64条线路，每4条线路组成一个通道，二条接收，二条发送。这样可以换算出其总线的带宽为2.5GHz×16/10=4GB/s（单向）。除10是因为每字节采用10位编码。内存带宽播报编辑除总线之外，内存也存在类似的带宽概念。其实所谓的内存带宽，指的也就是内存总线所能提供的数据传输能力，但它决定于内存芯片和内存模组而非纯粹的总线设计，加上地位重要，往往作为单独的对象讨论。SDRAM、DDR和DDRⅡ的总线位宽为64位，RDRAM的位宽为16位。而这两者在结构上有很大区别：SDRAM、DDR和DDRⅡ的64位总线必须由多枚芯片共同实现，计算方法如下：内存模组位宽=内存芯片位宽×单面芯片数量（假定为单面单物理BANK）；如果内存芯片的位宽为8位，那么模组中必须、也只能有8颗芯片，多一枚、少一枚都是不允许的；如果芯片的位宽为4位，模组就必须有16颗芯片才行，显然，为实现更高的模组容量，采用高位宽的芯片是一个好办法。而对RDRAM来说就不是如此，它的内存总线为串联架构，总线位宽就等于内存芯片的位宽。和并行总线一样，内存的带宽等于位宽与数据传输频率的乘积，例如，DDR400内存的数据传输频率为400MHz，那么单条模组就拥有64bit×400MHz÷8(Byte)=3.2GB/s的带宽；PC800标准RDRAM的频率达到800MHz，单条模组带宽为16bit×800MHz÷8=1.6GB/s。为了实现更高的带宽，在内存控制器中使用双通道技术是一个理想的办法，所谓双通道就是让两组内存并行运作，内存的总位宽提高一倍，带宽也随之提高了一倍！带宽可以说是内存性能最主要的标志，业界也以内存带宽作为主要的分类标准，但它并非决定性能的要素，在实际应用中，内存延迟的影响并不亚于带宽。如果延迟时间太长的话相当不利，此时即便带宽再高也无济于事[2]。带宽匹配播报编辑计算机系统中存在形形色色的总线，这不可避免带来总线速度匹配问题，其中最常出问题的地方在于前端总线和内存、南北桥总线和PCI总线。前端总线与内存匹配与否对整套系统影响最大，最理想的情况是前端总线带宽与内存带宽相等，而且内存延迟要尽可能低。在Pentium4刚推出的时候，Intel采用RDRAM内存以达到同前端总线匹配，但RDRAM成本昂贵，严重影响推广工作，Intel曾推出搭配PC133SDRAM的845芯片组，但SDRAM仅能提供1.06GB/s的带宽，仅相当于400MHz前端总线带宽的1/3，严重不匹配导致系统性能大幅度下降；后来，Intel推出支持DDR266的845D才勉强好转，但仍未实现与前端总线匹配；接着，Intel将P4前端总线提升到533MHz、带宽增长至4.26GB/s，虽然配套芯片组可支持DDR333内存，可也仅能满足2/3而已；P4的前端总线提升到800MHz，而配套的865/875P芯片组可支持双通道DDR400——这个时候才实现匹配的理想状态，当然，这个时候继续提高内存带宽意义就不是特别大，因为它超出了前端总线的接收能力。南北桥总线带宽曾是一个尖锐的问题，早期的芯片组都是通过PCI总线来连接南北桥，而它所能提供的带宽仅仅只有133MB/s，若南桥连接两个ATA-100硬盘、100M网络、IEEE1394接口......区区133MB/s带宽势必形成严重的瓶颈，为此，各芯片组厂商都发展出不同的南北桥总线方案，如Intel的Hub-Link、VIA的V-Link、SiS的MuTIOL，还有AMD的HyperTransport等等，它们的带宽都大大超过了133MB/s，最高纪录已超过1GB/s，瓶颈效应已不复存在。PCI总线带宽不足还是比较大的矛盾，PC上使用的PCI总线均为32位、33MHz类型，带宽133MB/s，而这区区133MB/s必须满足网络、硬盘控制卡（如果有的话）之类的扩展需要，一旦使用千兆网络，瓶颈马上出现，业界打算自2004年开始以PCIExpress总线来全面取代PCI总线，届时PCI带宽不足的问题将成为历史。显示器播报编辑以上我们所说的“带宽”指的都是速度概念，但对CRT显示器来说，它所指的带宽则是频率概念、属于电路范畴，更符合“带宽”本来的含义。要了解显示器带宽的真正含义，必须简单介绍一下CRT显示器的工作原理——由灯丝、阴极、控制栅组成的电子枪，向外发射电子流，这些电子流被拥有高电压的加速器加速后获得很高的速度，接着这些高速电子流经过透镜聚焦成极细的电子束打在屏幕的荧光粉层上，而被电子束击中的地方就会产生一个光点；光点的位置由偏转线圈产生的磁场控制，而通过控制电子束的强弱和通断状态就可以在屏幕上形成不同颜色、不同灰度的光点——在某一个特定的时刻，整个屏幕上其实只有一个点可以被电子束击中并发光。为了实现满屏幕显示，这些电子束必须从左到右、从上到下一个一个象素点进行扫描，若要完成800×600分辨率的画面显示，电子枪必须完成800×600=480000个点的顺序扫描。由于荧光粉受到电子束击打后发光的时间很短，电子束在扫描完一个屏幕后必须立刻再从头开始——这个过程其实十分短暂，在一秒钟时间电子束往往都能完成超过85个完整画面的扫描、屏幕画面更新85次，人眼无法感知到如此小的时间差异会“误以为”屏幕处于始终发亮的状态。而每秒钟屏幕画面刷新的次数就叫场频，或称为屏幕的垂直扫描频率、以Hz（赫兹）为单位，也就是我们俗称的“刷新率”。以800×600分辨率、85Hz刷新率计算，电子枪在一秒钟至少要扫描800×600×85=40800000个点的显示；如果将分辨率提高到1024×768，将刷新率提高到100Hz，电子枪要扫描的点数将大幅提高。按照业界公认的计算方法，显示器带宽指的就是显示器的电子枪在一秒钟内可扫描的最高点数总和，它等于“水平分辨率×垂直分辨率×场频（画面刷新次数）”，单位为MHz(兆赫)；由于显像管电子束的扫描过程是非线性的，为避免信号在扫描边缘出现衰减影响效果、保证图像的清晰度，总是将边缘扫描部分忽略掉，但在电路中它们依然是存在的。因此，我们在计算显示器带宽的时候还应该除一个取值为0.6~0.8的“有效扫描系数”，故得出带宽计算公式如下：“带宽=水平像素（行数）×垂直像素（列数）×场频（刷新频率）÷扫描系数”。扫描系数一般取为0.744。例如，要获得分辨率1024×768、刷新率85Hz的画面，所需要的带宽应该等于：1024×768×85÷0.744，结果大约是90MHz。不过，这个定义并不符合带宽的原意，称之为“像素扫描频率”似乎更为贴切。带宽的最初概念确实也是电路中的问题——简单点说就是：在“带宽”这个频率宽度之内，放大器可以处于良好的工作状态，如果超出带宽范围，信号会很快出现衰减失真现象。从本质上说，显示器的带宽描述的也是控制电路的频率范围，带宽高低直接决定显示器所能达到的性能等级。由于前文描述的“像素扫描频率”与控制电路的“带宽”基本是成正比关系，显示器厂商就干脆把它当作显示器的“带宽”——这种做法当然没有什么错，只是容易让人产生认识上的误区。当然，从用户的角度考虑没必要追究这么多，毕竟以“像素扫描频率”作为“带宽”是很合乎人们习惯的，大家可方便使用公式计算出达到某种显示状态需要的最低带宽数值。但是反过来说，“带宽数值完全决定着屏幕的显示状态”是否也成立呢？答案是不完全成立，因为屏幕的显示状态除了与带宽有关系之外，还与一个重要的概念相关——它就是“行频”。行频又称为“水平扫描频率”，它指的是电子枪每秒在荧光屏上扫描过的水平线数量，计算公式为：“行频=垂直分辨率×场频（画面刷新率）×1.07”，其中1.07为校正参数，因为显示屏上下方都存在我们看不到的区域。可见，行频是一个综合分辨率和刷新率的参数，行频越大，显示器就可以提供越高的分辨率或者刷新率。例如，1台17寸显示器要在1600×1200分辨率下达到75Hz的刷新率，那么带宽值至少需要221MHz，行频则需要96KHz，两项条件缺一不可；要达到这么高的带宽相对容易，而要达到如此高的行频就相当困难，后者成为主要的制约因素，而出于商业因素考虑，显示器厂商会突出带宽而忽略行频，这种宣传其实是一种误导。通讯带宽播报编辑在通讯和网络领域，带宽的含义又与上述定义存在差异，它指的是网络信号可使用的最高频率与最低频率之差、或者说是“频带的宽度”，也就是所谓的“Bandwidth”、“信道带宽”——这也是最严谨的技术定义。在100M以太网之类的铜介质布线系统中，双绞线的信道带宽通常用MHz为单位，它指的是信噪比恒定的情况下允许的信道频率范围，不过，网络的信道带宽与它的数据传输能力（单位Byte/s）存在一个稳定的基本关系。我们也可以用高速公路来作比喻：在高速路上，它所能承受的最大交通流量就相当于网络的数据运输能力，而这条高速路允许形成的宽度就相当于网络的带宽。显然，带宽越高、数据传输可利用的资源就越多，因而能达到越高的速度；除此之外，我们还可以通过改善信号质量和消除瓶颈效应实现更高的传输速度。网络带宽与数据传输能力的正比关系最早是由贝尔实验室的工程师ClaudeShannon所发现，因此这一规律也被称为Shannon定律。而通俗起见普遍也将网络的数据传输能力与“网络带宽”完全等同起来，这样“网络带宽”表面上看与“总线带宽”形成概念上的统一，但这两者本质上就不是一个意思、相差甚远。总结播报编辑对总线和内存来说，带宽高低对系统性能有着举足轻重的影响——倘若总线、内存的带宽不够高的话，处理器的工作频率再高也无济于事，因此带宽可谓是与频率并立的两大性能决定要素。而对CRT显示器而言，带宽越高，往往可以获得更高的分辨率、显示精度越高，不过CRT显示器的带宽都能够满足标准分辨率下85Hz刷新率或以上的显示需要（相信没有太多的朋友喜欢用非常高的分辨率去运行程序或者游戏），这样带宽高低就不是一个太敏感的参数了，当然，如果你追求高显示品质那是另一回事了[3]。通用寄存器：简介播报编辑通用寄存器可用于传送和暂存数据，也可参与算术逻辑运算，并保存运算结果。除此之外，它们还各自具有一些特殊功能。通用寄存器的长度取决于机器字长，汇编语言程序员必须熟悉每个寄存器的一般用途和特殊用途，只有这样，才能在程序中做到正确、合理地使用它们。16位cpu通用寄存器共有8个：AX,BX,CX,DX,BP,SP,SI,DI.八个寄存器都可以作为普通的数据寄存器使用。但有的有特殊的用途：AX为累加器，CX为计数器，BX，BP为基址寄存器，SI,DI为变址寄存器，BP还可以是基指针，SP为堆栈指针。32位cpu通用寄存器共有8个：EAX,EBX,ECX,EDX,EBP,ESP,ESI,EDI功能和上面差不多分类播报编辑数据寄存器数据寄存器主要用来保存操作数和运算结果等信息，从而节省读取操作数所需占用总线和访问存储器的时间。[1]32位CPU有4个32位的通用寄存器EAX、EBX、ECX和EDX。对低16位数据的存取，不会影响高16位的数据。这些低16位寄存器分别命名为：AX、BX、CX和DX，它和先前的CPU中的寄存器相一致。[1]4个16位寄存器又可分割成8个独立的8位寄存器(AX：AH-AL、BX：BH-BL、CX：CH-CL、DX：DH-DL)，每个寄存器都有自己的名称，可独立存取。程序员可利用数据寄存器的这种“可分可合”的特性，灵活地处理字/字节的信息。[1]寄存器AX和AL通常称为累加器(Accumulator)，用累加器进行的操作可能需要更少时间。累加器可用于乘、除、输入/输出等操作，它们的使用频率很高；寄存器BX称为基地址寄存器(BaseRegister)。它可作为存储器指针来使用；寄存器CX称为计数寄存器(CountRegister)。在循环和字符串操作时，要用它来控制循环次数；在位操作中，当移多位时，要用CL来指明移位的位数；寄存器DX称为数据寄存器(DataRegister)。在进行乘、除运算时，它可作为默认的操作数参与运算，也可用于存放I/O的端口地址。[1]在16位CPU中，AX、BX、CX和DX不能作为基址和变址寄存器来存放存储单元的地址，但在32位CPU中，其32位寄存器EAX、EBX、ECX和EDX不仅可传送数据、暂存数据保存算术逻辑运算结果，而且也可作为指针寄存器，所以，这些32位寄存器更具有通用性。详细内容请见第3.8节——32位地址的寻址方式。[1]变址寄存器32位CPU有2个32位通用寄存器ESI和EDI。其低16位对应先前CPU中的SI和DI，对低16位数据的存取，不影响高16位的数据。[1]寄存器ESI、EDI、SI和DI称为变址寄存器(IndexRegister)，它们主要用于存放存储单元在段内的偏移量，用它们可实现多种存储器操作数的寻址方式(在第3章有详细介绍)，为以不同的地址形式访问存储单元提供方便。变址寄存器不可分割成8位寄存器。作为通用寄存器，也可存储算术逻辑运算的操作数和运算结果。[1]它们可作一般的存储器指针使用。在字符串操作指令的执行过程中，对它们有特定的要求，而且还具有特殊的功能。[1]指针寄存器32位CPU有2个32位通用寄存器EBP和ESP。其低16位对应先前CPU中的SBP和SP，对低16位数据的存取，不影响高16位的数据。寄存器EBP、ESP、BP和SP称为指针寄存器(PointerRegister)，主要用于存放堆栈内存储单元的偏移量，用它们可实现多种存储器操作数的寻址方式(在第3章有详细介绍)，为以不同的地址形式访问存储单元提供方便。指针寄存器不可分割成8位寄存器。作为通用寄存器，也可存储算术逻辑运算的操作数和运算结果。[1]段寄存器段寄存器是根据内存分段的管理模式而设置的。内存单元的物理地址由段寄存器的值和一个偏移量组合而成的，这样可用两个较少位数的值组合成一个可访问较大物理空间的内存地址。[1]指令指针寄存器32位CPU把指令指针扩展到32位，并记作EIP，EIP的低16位与先前CPU中的IP作用相同。指令指针EIP、IP(InstructionPointer)是存放下次将要执行的指令在代码段的偏移量。在具有预取指令功能的系统中，下次要执行的指令通常已被预取到指令队列中，除非发生转移情况。所以，在理解它们的功能时，不考虑存在指令队列的情况。在实方式下，由于每个段的最大范围为64K，所以，EIP中的高16位肯定都为0，此时，相当于只用其低16位的IP来反映程序中指令的执行次序。[1]主要用途播报编辑通用寄存器数据寄存器AX乘、除运算，字的输入输出，中间结果的缓存AL字节的乘、除运算，字节的输入输出，十进制算术运算AH字节的乘、除运算，存放中断的功能号BX存储器指针CX串操作、循环控制的计数器CL移位操作的计数器DX字的乘、除运算，间接的输入输出变址寄存器SI存储器指针、串指令中的源操作数指针DI存储器指针、串指令中的目的操作数指针分类示意图变址寄存器BP存储器指针、存取堆栈的指针SP堆栈的栈顶指针指令指针IP/EIP标志位寄存器Flag/EFlag32位CPU的段寄存器16位CPU的段寄存器ES附加段寄存器CS代码段寄存器SS堆栈段寄存器DS数据段寄存器新增加的段寄存器FS附加段寄存器GS附加段寄存器相关信息播报编辑运算器结构寄存器是CPU内部重要的数据存储资源，用来暂存数据和地址，是汇编程序员能直接使用的硬件资源之一。由于寄存器的存取速度比内存快，所以，在用汇编语言编写程序时，要尽可能充分利用寄存器的存储功能。寄存器一般用来保存程序的中间结果，为随后的指令快速提供操作数，从而避免把中间结果存入内存，再读取内存的操作。在高级语言(如：C/C++语言)中，也有定义变量为寄存器类型的，这就是提高寄存器利用率的一种可行的方法。另外，由于寄存器的个数和容量都有限，不可能把所有中间结果都存储在寄存器中，所以，要对寄存器进行适当的调度。根据指令的要求，如何安排适当的寄存器，避免操作数过多的传送操作是一项细致而又周密的工作。字长：概念播报编辑计算机采用二进制编码方式表示数、字符、指令和其它控制信息。[1]计算机在存储、传送或操作时，作为一个单元的一组二进制码称为字，一个字中的二进制位的位数称为字长。[2]通常称处理字长为8位数据的CPU叫8位CPU，32位CPU就是在同一时间内处理字长为32位的二进制数据。二进制的每一个0或1是组成二进制的最小单位，称为位（bit）。常用的字长为8位、16位、32位和64位。字长为8位的编码称为字节，是计算机中的基本编码单位。[3]字长与计算机的功能和用途有很大的关系，是计算机的一个重要技术指标。字长直接反映了一台计算机的计算精度，为适应不同的要求及协调运算精度和硬件造价间的关系，大多数计算机均支持变字长运算，即机内可实现半字长、全字长（或单字长）和双倍字长运算。在其他指标相同时，字长越大计算机的处理数据的速度就越快。早期的微机字长一般是8位和16位，386以及更高的处理器大多是32位。市面上的计算机的处理器大部分已达到64位。字长由微处理器对外数据通路的数据总线条数决定。[3]通俗含义播报编辑字长是CPU的主要技术指标之一，指的是CPU一次能并行处理的二进制位数，通常PC机的字长为16位（早期），32位，64位。[4]PC机可以通过编程的方法来处理任意大小的数字，但数字越大，PC机就要花越长的时间来计算。PC机在一次操作中能处理的最大数字是由PC机的字长确定的。[5]我们先来看一下人脑是如何进行计算的，例如5×6则立即可以得到答案是30，但对于55×66，就不可能立即得到正确的答案，这就是说55或66已走出了人脑的“字长”，这是为了得出结果，就必须把复杂的问题（如55×66）分解成易于处理的问题（如55×66可分解为50×60，50×6，5×60，5×6），然后再综合起来，得出结果。[5]字长同样PC机也是这样处理问题的，一台16位字长的PC机，可以直接处理2的16次方（65536）之内的数字，对于超过65536的数字就需要分解的方法来处理。32位pc机比16位机优越的原因就在于它在一次操作中能处理的数字大，32位字长的PC机能直接处理的数字高达40亿（2的32次方），能处理的的数字越大，则操作的次数就越少，从而系统的效率也就越高。[5]CPU大多是64位的，但大多都以32位字长运行，都没能展示它的字长的优越性，因为它必须与64位软件（如64位的操作系统等）相辅相成，也就是说，字长受软件系统的制约，例如，在32位软件系统中64位字长的CPU只能当32位用。[4]固定字长与可变字长播报编辑每一个储存位置都可以由其地址找到。但是每一储存位置的长度(length)尚未指定。[6]在某些计算机中，每一储存位置是由固定的位数所组成的。每当计算机涉及到某一个储存位置时，即表示它要引用此一固定长度的位置，亦称为一个“字”(word)。像此种型态的组织，我们称之为固定字长(fixedwordlength)或可定址字(word-address-able)。例如典型的迷你计算机，一个字长为16个位。[6]可定址位元组另一些计算机，它的每个地址所引用是一个位元组或一个字。这种计算机，我们称之为可定址字(character-ddressable)或可定址位元组(byte-addresable)。右图所示即为此种储存体，因为这10个位元组的每一个位元组，皆可个别设定一个位址。[6]至于可定址字元的计算机，经常被称为可变字长(variablewordlength)的机器。[6]我们之所以称之“可变字长”，乃是因为只要利用一个计算机已有的指令(如"add"或"move")，它就可以去处理字数目为可变的字。但对固定字长的计算机而言，它所处理的字数目是由指合本身所指定的。[6]可定址字元右图所示为固定字长与可变字长储存体组织的比较。图a所示为每字可存4个字元的固定字长组织。注意此种组织中，虽然是每4个字元形成一组，且可赋予一个地址，但是每个个别的字元却不能赋予位址。在图b的可定址字元或可变字长的组织中，计算机可将其中每一个字赋予一个位址。[6]在图b中，假设要取出其中前5个字(即字母SANTA)时，需要分别引用5个位址。但实际上，并不需要如此。因为有一种可变字长指令，可让你一次就取出一组的字。在指令中，你只要第一个字元的位址，然后再指定一共要取出几个字元即可。例如，在图b，一个读取字母SANTA的指令，只要指定第一个字元的位址(001)及所要读取的字数(5)，则此5个字元即可被读出。[6]可变字长组织其主要优点为储存体的使用效率高；即，只需使用与字数一样的位置即可储存该组字(注：如果想储存SANTA这一组字，只需使用5个位置即可)。然而，固定字长的组织可能会有浪费内存空间的现象。例如图a中的第三个字(位址为003)仅被利用一半，而其另一半则未被使用。[6]双倍字长播报编辑双倍字长是指计算机内部参与运算的数的位数。它决定着计算机内部寄存器、ALU和数据总线的位数，直接影响着机器的硬件规模和造价。双倍字长直接反映了一台计算机的计算精度，为适应不同的要求及协调运算精度和硬件造价间的关系，大多数计算机均支持变字长运算，即机内可实现半字长、全字长（或单字长）和双倍字长运算。[7]微型机的字长通常为4位、8位、16位和32位，64位字长的高性能微型计算机也已推出。[7]双倍字长对计算机计算精度的影响：[7]4位字长：2^4=16；16位字长：2^16=65536=64K32位字长：2^32=4,294,967,296=4G；64位字长：2^64≈1.8445×10^19数据总线DB用于传送数据信息。数据总线是双向三态形式的总线，即他既可以把CPU的数据传送到存储器或I/O接口等其它部件，也可以将其它部件的数据传送到CPU。数据总线的位数是微型计算机的一个重要指标，通常与微处理的字长相一致。例如Intel8086微处理器字长16位，其数据总线宽度也是16位。需要指出的是，数据的含义是广义的，它可以是真正的数据，也可以指令代码或状态信息，有时甚至是一个控制信息，因此，在实际工作中，数据总线上传送的并不一定仅仅是真正意义上的数据。[7]地址总线AB是专门用来传送地址的，由于地址只能从CPU传向外部存储器或I/O端口，所以地址总线总是单向三态的，这与数据总线不同。地址总线的位数决定了CPU可直接寻址的内存空间大小，比如8位微机的地址总线为16位，则其最大可寻址空间为2^16=64KB，16位微型机的地址总线为20位，其可寻址空间为2^20=1MB。一般来说，若地址总线为n位，则可寻址空间为2^（n-10）千字节。[7]控制总线CB用来传送控制信号和时序信号。控制信号中，有的是微处理器送往存储器和I/O接口电路的，如读/写信号，片选信号、中断响应信号等；也有是其它部件反馈给CPU的，比如：中断申请信号、复位信号、总线请求信号、限备就绪信号等。因此，控制总线的传送方向由具体控制信号而定，一般是双向的，控制总线的位数要根据系统的实际控制需要而定。实际上控制总线的具体情况主要取决于CPU。[7]字长的选择播报编辑在设计计算机时，字长的选择是非常重要的。设计上的考虑倾向于为特定的用途（如地址）设定特定的位长。然而，出于经济的考虑，又应该仅使用一种尺寸，或者很少的几种与基本尺寸成倍数或分数（约数）关系的尺寸。这个首选的基本尺寸就成为该构架的字长。[8]字符的尺寸对于字长的选择也有影响。20世纪60年代中期以前，字符大部分以6位存储；这样最多允许64个字符，因此不能又大写字符。由于将字长定义成字符尺寸的倍数在处理时间和存储空间上都比较划算，所以这个时期字长也就被定义为6位（在二进制机器上）的倍数。通常的选择是36位字长，这也是适合于浮点数格式的一个长度。[8]随着IBM360系统的引入——该系统使用8位字符，并支持大小写字母——标准的字符（确切地说：字节）尺寸也转变成为8位。从那以后，字长也自然变成了8的倍数，16、32、64位字长被广泛使用。[8]各种字长的架构早期的计算机设计中包括所谓的“可变字长”设计。（原文：Earlymachinedesignsincludedsomethatusedwhatisoftentermedavariablewordlength.——译者）。在这类设计中，数字操作数没有固定的长度，它们通过检查某个特殊字符来判断是否结束。这样的机器使用BCD编码表示数字，例如IBM702、IBM705、IBM7080、IBM7010、UNIVAC1050、IBM1401和IBM1620。[8]大部分这样的机器一次处理一个存储单元，因为每条指令和数据占用的数个单元，所以指令将使用数个周期来读取存储器。这类机器经常因为这个原因变得非常慢。例如，在IBM1620ModelI上，取指令需要8个周期，只是为了读取12个数字（ModelII降低到6个周期，不过如果指令不需要取其中的一个1个地址域的话，可以只需要4个周期；如果两个都不需要，则只需要1个周期）。[8]字和字节编址字长对计算机构架的存储器模式有很大的影响。特别是：通常选择字作为存储器的编址方案，所谓存储器编址方案就是地址码能够指定的最小存储单位。编号相邻的存储器字组，其地址编号相差一。在计算机中这样很自然，因为它通常总是要处理以字为单位的数据（或者是以字的倍数）。并且具有让指令可以使用最小的长度来指定一个地址的优点，这样，就可以减少指令长度或者可以定义更多的指令条数。[8]当计算机很大的工作量是用来处理字节时，通常定义字节作为地址编址单位要比字更好。这样做字符串中的单个字符可以通过地址直接指定。当然，一个字仍然可以被地址访问，但是比起字编址方案，它的地址将使用更多的位数。在这种组织结构中，字长需要被定义为字符长度的整数倍。这种编址方案在IBM360中被使用，此后即变成计算机设计中最普遍的方案。[8]2的幂数据常常要占用不同大小的存储空间，例如，有些数值比其他的数值要求有更高的精度。通常使用的长度是编址单位（以字为单位编址或以字节为单位编址）的倍数，这个倍数常常是的2的幂。这样做是比较便利的，因为这样的话，将一个处理对象在数组中的索引值转化为这个处理对象的地址只需要进行一个移位操作（这在硬件上只需要进行布线的变化）而不需要进行乘操作。某些时候这样的做法还可以避免除操作。因此，一些现代计算机设计使用的字长（或者其他的操作数）是2的幂乘以字节尺寸。[8]字长表播报编辑年份计算机架构字长整数长度浮点数长度长度指令编址单位字符长度1941ZuseZ322b–w8bw–1942ABC50bw––––1944HarvardMarkI23dw–24b––1946（1948）{1953}ENIAC（w/Panel#16）{w/Panel#26}10dw,2w（w）{w}––（2d,4d,6d,8d）––{w}–1951UNIVACI12dw–½ww1d1952IASmachine40bw–½ww5b1952IBM70136b½w,w–½w½w,w6b1952UNIVAC60nd1d,...10d–––2d,3d1953IBM702nd0d,...511d–5dd1d1953UNIVAC120nd1d,...10d–––2d,3d1954（1955）IBM650（w/IBM653）10dw–（w）ww2d1954IBM70436bwwww6b1954IBM705nd0d,...255d–5dd1d1954IBMNORC16dww,2www–1956IBM305nd1d,...100d–10dd1d1958UNIVACII12dw–½ww1d1958SAGE32b½w–ww6b1958AutoneticsRecompII40bw,79b,8d,15d2w½w½w,w5b1959IBM1401nd1d,...–d,2d,4d,5d,7d,8dd1d1959（TBD）IBM1620nd2d,...–（4d,...102d）12dd2d1960LARC12dw,2ww,2www2d1960IBM1410nd1d,...–d,2d,6d,7d,11d,12dd1d1960IBM707010dwwww,d2d1960PDP-118bw–ww6b1961IBM7030（Stretch）64b1b,...64b,1d,...16dw½w,wb,½w,w1b,...8b1961IBM7080nd0d,...255d–5dd1d1962UNIVACIII25b,6dw,2w,3w,4w–ww6b1962UNIVAC110736b/6w,⅓w,½w,wwww6b1962IBM7010nd1d,...–d,2d,6d,7d,11d,12dd1d1962IBM709436bww,2www6b1963GeminiGuidanceComputer39b26b–13b13b,26b–1963（1966）ApolloGuidanceComputer15bw–w,2ww–1964CDC660060bww¼w,½ww6b1965IBM36032b½w,w,1d,...16dw,2w½w,w,1½w8b8b1965UNIVAC110836b/6w,¼w,⅓w,½w,w,2ww,2www6b,9b1965PDP-812bw–ww8b1970PDP-1116bw2w,4ww,2w,3w8b8b1971Intel40044bw,d–2w,4ww–1972Intel80088bw,2d–w,2w,3ww8b1972Calcomp9009bw–w,2ww8b1974Intel80808bw,2w,2d–w,2w,3ww8b1975Cray-164b24b,ww¼w,½ww8b1975Motorola68008bw,2d–w,2w,3ww8b1975MOSTech.6501MOSTech.65028bw,2d–w,2w,3ww8b1976ZilogZ808bw,2w,2d–w,2w,3w,4w,5ww8b1978（1980）Intel8086（w/Intel8087）16b½w,w,2d（w,2w,4w）–（2w,4w,5w,17d）½w,w,...7w8b8b1978VAX-11/78032b¼w,½w,w,1d,...31d,1b,...32bw,2w¼w,...14¼w8b8b1979Motorola6800032b¼w,½w,w,2d–½w,w,...7½w8b8b1982（1983）Motorola68020（w/Motorola68881）32b¼w,½w,w,2d–（w,2w,2½w）½w,w,...7½w8b8b1985ARM132bw–w8b8b1985MIPS32b¼w,½w,ww,2ww8b8b1989Intel8048616b½w,w,2dw,2w,4w2w,4w,5w,17d½w,w,...7w8b8b1989Motorola6804032b¼w,½w,w,2dw,2w,2½w½w,w,...7½w8b8b1991PowerPC32b¼w,½w,ww,2ww8b8b2000IA-6464b8b,¼w,½w,w½w,w41b8b8b2002XScale32bww,2w½w,w8b8b说明：b:位,d:10进制数,w:该构架的字长,n:变量长度（variablesize）有关术语播报编辑字在计算机中，一串数码作为一个整体来处理或运算的，称为一个计算机字，简称字，字反映计算机一次并行处理的一组二进制数。字通常分为若干个字节(每个字节一般是8位)。在存储器中，通常每个单元存储一个字，因此每个字都是可以寻址的。字的长度用位数来表示。[9]在计算机的运算器、控制器中，通常都是以字为单位进行传送的。字在不同的地址出现，其含义是不相同。例如，送往控制器去的字是指令，而送往运算器去的字就是一个数。[9]字节字节是指一小组相邻的二进制数码。通常是8位作为一个字节。它是构成信息的一个小单位，并作为一个整体来参加操作，比字小，是构成字的单位。在微型计算机中，通常用多少字节来表示存储器的存储容量。[9]RAM：简介播报编辑存储器是数字系统中用以存储大量信息的设备或部件，是计算机和数字设备中的重要组成部分。存储器可分为随机存取存储器（RAM）和只读存储器（ROM）两大类。随机存取存储器（RAM）既可向指定单元存入信息又可从指定单元读出信息。任何RAM中存储的信息在断电后均会丢失，所以RAM是易失性存储器。ROM为只读存储器，除了固定存储数据、表格、固化程序外，在组合逻辑电路中也有着广泛用途。[2]特点播报编辑随机存取静态随机存取存储器所谓“随机存取”，指的是当存储器中的数据被读取或写入时，所需要的时间与这段信息所在的位置或所写入的位置无关。相对的，读取或写入顺序访问（SequentialAccess）存储设备中的信息时，其所需要的时间与位置就会有关系。它主要用来存放操作系统、各种应用程序、数据等。[3]当RAM处于正常工作时，可以从RAM中读出数据，也可以往RAM中写入数据。与ROM相比较，RAM的优点是读/写方便、使用灵活，特别适用于经常快速更换数据的场合。[4]易失性当电源关闭时，RAM不能保留数据。如果需要保存数据，就必须把它们写入一个长期的存储设备中（例如硬盘）。[3]RAM的工作特点是通电后，随时可在任意位置单元存取数据信息，断电后内部信息也随之消失。[5]对静电敏感正如其他精细的集成电路，随机存取存储器对环境的静电荷非常敏感。静电会干扰存储器内电容器的电荷，引致数据流失，甚至烧坏电路。故此触碰随机存取存储器前，应先用手触摸金属接地。[3]访问速度现代的随机存取存储器几乎是所有访问设备中写入和读取速度最快的，存取延迟和其他涉及机械运作的存储设备相比，也显得微不足道。[3]需要刷新现代的随机存取存储器依赖电容器存储数据。电容器充满电后代表1（二进制），未充电的代表0。由于电容器或多或少有漏电的情形，若不作特别处理，数据会渐渐随时间流失。刷新是指定期读取电容器的状态，然后按照原来的状态重新为电容器充电，弥补流失了的电荷。需要刷新正好解释了随机存取存储器的易失性。[3]组成播报编辑RAM工作原理RAM由存储矩阵、地址译码器、读/写控制器、输入/输出、片选控制等几部分组成。[6]（1）存储矩阵。如图所示，RAM的核心部分是一个寄存器矩阵，用来存储信息，称为存储矩阵。[6]（2）地址译码器。地址译码器的作用是将寄存器地址所对应的二进制数译成有效的行选信号和列选信号，从而选中该存储单元。[6]（3）读/写控制器。访问RAM时，对被选中的寄存器进行读操作还是进行写操作，是通过读写信号来进行控制的。读操作时，被选中单元的数据经数据线、输入/输出线传送给CPU（中央处理单元）；写操作时，CPU将数据经输入/输岀线、数据线存入被选中单元。[6]（4）输入/输出。RAM通过输入/输岀端与计算机的CPU交换数据，读出时它是输岀端，写入时它是输入端，一线两用。由读/写控制线控制。输入/输出端数据线的条数，与一个地址中所对应的寄存器位数相同，也有的RAM芯片的输入/输出端是分开的。通常RAM的输出端都具有集电极开路或三态输出结构。[6]（5）片选控制。由于受RAM的集成度限制。一台计算机的存储器系统往往由许多RAM组合而成。CPU访问存储器时，一次只能访问RAM中的某一片（或几片），即存储器中只有一片（或几片）RAM中的一个地址接受CPU访问，与其交换信息，而其他片RAM与CPU不发生联系，片选就是用来实现这种控制的。通常一片RAM有一根或几根片选线，当某一片的片选线接入有效电平时，该片被选中，地址译码器的输出信号控制该片某个地址的寄存器与CPU接通；当片选线接入无效电平时，则该片与CPU之间处于断开状态。[6]类别播报编辑根据存储单元的工作原理不同，RAM分为静态RAM和动态RAM。[7]静态随机存储器静态存储单元是在静态触发器的基础上附加门控管而构成的。因此，它是靠触发器的自保功能存储数据的。SRAM存放的信息在不停电的情况下能长时间保留，状态稳定，不需外加刷新电路，从而简化了外部电路设计。但由于SRAM的基本存储电路中所含晶体管较多，故集成度较低，且功耗较大。[7]SRAM特点如下：●存储原理：由触发器存储数据。[8]●单元结构：六管NMOS或OS构成。[8]●优点：速度快、使用简单、不需刷新、静态功耗极低；常用作Cache。[8]●缺点：元件数多、集成度低、运行功耗大。[8]●常用的SRAM集成芯片：6116（2K×8位），6264（8K×8位），62256（32K×8位），2114（1K×4位）。[8]动态随机存储器DRAM利用电容存储电荷的原理保存信息，电路简单，集成度高。由于任何电容都存在漏电，因此，当电容存储有电荷时，过一段时间由于电容放电会导致电荷流失，使保存信息丢失。解决的办法是每隔一定时间（一般为2ms）须对DRAM进行读出和再写入，使原处于逻辑电平“l”的电容上所泄放的电荷又得到补充，原处于电平“0”的电容仍保持“0”，这个过程叫DRAM的刷新。[7]DRAM的刷新操作不同于存储器读/写操作，主要表现在以下几点：（1）刷新地址由刷新地址计数器产生，不是由地址总线提供。[7]（2）DRAM基本存储电路可按行同时刷新，所以刷新只需要行地址，不需要列地址。[7]（3）刷新操作时存储器芯片的数据线呈高阻状态，即片内数据线与外部数据线完全隔离。[7]DRAM与SRAM相比具有集成度高、功耗低、价格便宜等优点，所以在大容量存储器中普遍采用。DRAM的缺点是需要刷新逻辑电路，且刷新操作时不能进行正常读，写操作。[7]DRAM特点如下：●存储原理：利用MOS管栅极电容可以存储电荷的原理，需刷新（早期：三管基本单元；之后：单管基本单元）。[8]●刷新（再生）：为及时补充漏掉的电荷以避免存储的信息丢失，必须定时给栅极电容补充电荷的操作。[8]●刷新时间：定期进行刷新操作的时间。该时间必须小于栅极电容自然保持信息的时间（小于2ms）。[8]●优点：集成度远高于SRAM、功耗低，价格也低。[8]●缺点：因需刷新而使外围电路复杂；刷新也使存取速度较SRAM慢，所以在计算机中，DRAM常用于作主存储器。[8]尽管如此，由于DRAM存储单元的结构简单，所用元件少，集成度高，功耗低，所以已成为大容量RAM的主流产品。[8]相关概念播报编辑与只读存储器区别动态随机存取存储器在计算机中，RAM、ROM都是数据存储器。RAM是随机存取存储器，它的特点是易挥发性，即掉电失忆。ROM通常指固化存储器（一次写入，反复读取），它的特点与RAM相反。举个例子来说也就是，如果突然停电或者没有保存就关闭了文件，那么ROM可以随机保存之前没有储存的文件但是RAM会使之前没有保存的文件消失。[8]与内存之间的关系笔记本电脑内存在计算机的组成结构中，有一个很重要的部分，就是存储器。存储器是用来存储程序和数据的部件，对于计算机来说，有了存储器，才有记忆功能，才能保证正常工作。存储器的种类很多，按其用途可分为主存储器和辅助存储器，主存储器又称内存储器（简称内存），辅助存储器又称外存储器（简称外存）。外存通常是磁性介质或光盘，像硬盘，软盘，磁带，CD等，能长期保存信息，并且不依赖于电来保存信息，但是由机械部件带动，速度与CPU相比就显得慢的多。内存指的就是主板上的存储部件，是CPU直接与之沟通，并用其存储数据的部件，存放当前正在使用（即执行中）的数据和程序，它的物理实质就是一组或多组具备数据输入输出和数据存储功能的集成电路，内存只用于暂时存放程序和数据，一旦关闭电源或发生断电，其中的程序和数据就会丢失。[8]快速周期随机存取存储器从一有计算机开始，就有内存。内存发展到今天也经历了很多次的技术改进，从最早的DRAM一直到FPMDRAM、EDODRAM、SDRAM等，内存的速度一直在提高且容量也在不断的增加。今天，服务器主要使用的是什么样的内存？IA架构的服务器普遍使用的是RegisteredECCSDRAM。[8]既然内存是用来存放当前正在使用的（即执行中）的数据和程序，那么它是怎么工作的？我们平常所提到的计算机的内存指的是动态内存（即DRAM），动态内存中所谓的“动态”，指的是当我们将数据写入DRAM后，经过一段时间，数据会丢失，因此需要额外设一个电路进行内存刷新操作。[8]指令周期：基本概念播报编辑指令周期，读取－执行周期（fetch-and-executecycle）是指CPU要执行指令经过的步骤。计算机之所以能自动地工作，是因为CPU能从存放程序的内存里取出一条指令并执行这条指令；紧接着又是取指令，执行指令，如此周而复始，构成了一个封闭的循环。除非遇到停机指令，否则这个循环将一直继续下去。指令周期:CPU从内存取出一条指令并执行这条指令的时间总和。CPU周期:又称机器周期，CPU访问一次内存所花的时间较长，因此用从内存读取一条指令字的最短时间来定义。时钟周期:通常称为节拍脉冲或T周期。一个CPU周期包含若干个时钟周期。[1]类别播报编辑非访内指令CLA是一条非访内指令，它需要两个CPU周期，其中取指令阶段需要一个CPU周期，执行指令阶段需要一个CPU周期。1、取指令阶段(1)程序计数器PC的内容20(八进制)被装入地址寄存器AR；(2)程序计数器内容加1，变成21，为取下一条指令做好准备；(3)地址寄存器的内容被放到地址总线上；(4)所选存储器单元20的内容经过数据总线，传送到数据缓冲寄存器DR；(5)缓冲寄存器的内容传送到指令寄存器IR；(6)指令寄存器中的操作码被译码或测试；(7)CPU识别出是指令CLA，至此，取指令阶段即告结束。2、执行指令阶段(1)操作控制器送一控制信号给算术逻辑运算单元ALU；(2)ALU响应该控制信号，将累加寄存器AC的内容全部清零，从而执行了CLA指令。[1]取数指令1.送操作数地址第二个CPU周期主要完成送操作数地址。在此阶段，CPU的动作只有一个，那就是把指令寄存器中的地址码部分(30)装入地址寄存器，其中30为内存中存放操作数的地址。2.两操作数相加第三个CPU周期主要完成取操作数并执行加法操作中。在此阶段，CPU完成如下动作：(1)把地址寄存器中的操作数的地址发送到地址总线上。(2)由存储器单元30中读出操作数，并经过数据总线传送到缓冲寄存器。(3)执行加操作：由数据缓冲寄存器来的操作数可送往ALU的一个输入端，已等候在累加器内的另一个操作数(因为CLA指令执行结束后累加器内容为零)送往ALU的另一输入端，于是ALU将两数相加，产生运算结果为0+6=6。这个结果放回累加器，替换了累加器中原先的数0。[1]存数指令STA指令的指令周期由三个CPU周期组成。1.送操作数地址在执行阶段的第一个CPU周期中，CPU完成的动作是把指令寄存器中地址码部分的形式地址40装到地址寄存器。其中数字40是操作数地址。2.存储和数执行阶段的第二个CPU周期中，累加寄存器的内容传送到缓冲寄存器，然后再存入到所选定的存储单元(40)中。CPU完成如下动作：(1)累加器的内容被传送到数据缓冲寄存器DR；(2)把地址寄存器的内容发送到地址总线上，即为将要存入的数据6的内存单元号；(3)把缓冲寄存器的内容发送到数据总线上；(4)数据总线上的数写入到所选中的存储器单元中，即将数6写入到存储器40号单元中。注意在这个操作之后，累加器中仍然保留和数6，而存储器40号单元中原先的内容被冲掉。[1]空操作指令第四条指令即“NOP”指令，这是一条空操作指令。其中第一个CPU周期中取指令，CPU把23号单元的“NOP”指令取出放到指令寄存器，第二个CPU周期中执行该指令。因译码器译出是“NOP”指令，第二个CPU周期中操作控制器不发出任何控制信号。NOP指令可用来调机之用。1.第一个CPU周期（取指令阶段）CPU把24号单元的“JMP21”指令取出放至指令寄存器，同时程序计数器内容加1，变为25，从而取下一条指令做好准备。2.第二个CPU周期（执行阶段）CPU把指令寄存器中地址码部分21送到程序计数器，从而用新内容21代替PC原先的内容25。这样，下一条指令将不从25单元读出，而是从内存21单元开始读出并执行，从而改变了程序原先的执行顺序。注意执行“JMP21”指令时，我们此处所给的四条指令组成的程序进入了死循环，除非人为停机，否则这个程序将无休止地运行下去，因而内存单元40中的和数将一直不断地发生变化。当然，我们此处所举的转移地址21是随意的，仅仅用来说明转移指令能够改变程序的执行顺序而已。[1]特点介绍播报编辑指令不同，所需的机器周期数也不同。对于一些简单的的单字节指令，在取指令周期中，指令取出到指令寄存器后，立即译码执行，不再需要其它的机器周期。对于一些比较复杂的指令，例如转移指令、乘法指令，则需要两个或者两个以上的机器周期。[2]从指令的执行速度看，单字节和双字节指令一般为单机器周期和双机器周期，三字节指令都是双机器周期，只有乘、除指令占用4个机器周期。因此在进行编程时，在完成相同工作的情况下，选用占用机器周期少的命令会提高程序的执行速率，尤其是在编写大型程序程序的时候，其效果更加明显。[2]位宽：简介播报编辑显存位宽是显存在一个时钟周期内所能传送数据的位数，位数越大则瞬间所能传输的数据量越大，这是显存的重要参数之一。显存带宽=显存频率X显存位宽/8，那么在显存频率相当的情况下，显存位宽将决定显存带宽的大小。同样显存频率为500MHz的128位和256位显存，那么它俩的显存带宽将分别为：128位=500MHz*128∕8=8GiB/s，而256位=500MHz*256∕8=16GiB/s，是128位的2倍，可见显存位宽在显存数据中的重要性。显卡的显存是由一块块的显存芯片构成的，显存总位宽同样也是由显存颗粒的位宽组成，显存位宽=显存颗粒位宽×显存颗粒数。显存颗粒上都带有相关厂家的内存编号，可以去网上查找其编号，就能了解其位宽，再乘以显存颗粒数，就能得到显卡的位宽。[1]分类播报编辑市场上的常见显存位宽有128位、192位、256位、384位、512位和1024位六种，人们习惯上叫的128位、256位显卡、384位显卡、512位显卡和1024位显卡就是指其相应的显存位宽。显存位宽越高，性能越好价格也就越高，因此中高位宽的显存更多应用于高端显卡，而普通显卡基本都采用128位显宽，而1024位显卡属于顶级了。鉴别播报编辑有一个较为简便的方法，但只适应于一般情况，存在一些特殊情况，在大部分情况下能适用。显存的封装形式主要有TSOP和BGA两种，一般情况下BGA封装的显存是32位/颗的，而TSOP封装的颗粒是16位/颗的。如果显卡采用了四颗BGA封装的显存，那么它的位宽是128位的，而如果是八颗TSOP封装颗粒，那么位宽也是128位的，但如果显卡只采用了四颗TSOP封装颗粒，那么显存位宽就只有64位。这只是一个一般情况下的技巧，不一定符合所有的情况，要做到最为准确的判断，还是查看显存编号！SDRAM：演变播报编辑SDRAM从发展到现在已经经历了五代，分别是：第一代SDRSDRAM，第二代DDRSDRAM，第三代DDR2SDRAM，第四代DDR3SDRAM，第五代，DDR4SDRAM。第一代SDRAM采用单端（Single-Ended）时钟信号,第二代、第三代与第四代由于工作频率比较快，所以采用可降低干扰的差分时钟信号作为同步时钟。SDRSDRAM的时钟频率就是数据存储的频率，第一代内存用时钟频率命名，如pc100，pc133则表明时钟信号为100或133MHz，数据读写速率也为100或133MHz。之后的第二，三，四代DDR（DoubleDataRate）内存则采用数据读写速率作为命名标准，并且在前面加上表示其DDR代数的符号，PC-即DDR，PC2=DDR2，PC3=DDR3。如PC2700是DDR333，其工作频率是333/2=166MHz，2700表示带宽为2.7G。DDR的读写频率从DDR200到DDR400，DDR2从DDR2-400到DDR2-800，DDR3从DDR3-800到DDR3-1600。很多人将SDRAM错误的理解为第一代也就是SDRSDRAM，并且作为名词解释，皆属误导。SDR不等于SDRAM。Pin:模组或芯片与外部电路连接用的金属引脚，而模组的pin就是常说的“金手指”。SIMM：SingleIn-lineMemoryModule,单列内存模组。内存模组就是我们常说的内存条，所谓单列是指模组电路板与主板插槽的接口只有一列引脚（虽然两侧都有金手指）。DIMM：DoubleIn-lineMemoryModule，双列内存模组。是我们常见的模组类型，所谓双列是指模组电路板与主板插槽的接口有两列引脚，模组电路板两侧的金手指对应一列引脚。RIMM：registeredDIMM，带寄存器的双线内存模块，这种内存槽只能插DDR或Rambus内存。SO-DIMM:笔记本常用的内存模组。工作电压：SDR：3.3VDDR：2.5VDDR2：1.8VDDR3：1.5VDDR4：1.2VSDRSDRAM内存条的金手指通常是168线，而DDRSDRAM内存条的金手指通常是184线的。几代产品金手指的缺口数及缺口位置也不同有效防止反插与错插，SDRSDRAM有两个缺口，DDR只有一个缺口。关系播报编辑结构、时序与性能的关系一、影响性能的主要时序参数所谓的影响性能是并不是指SDRAM的带宽，频率与位宽固定后，带宽也就不可更改了。但这是理想的情况，在内存的工作周期内，不可能总处于数据传输的状态，因为要有命令、寻址等必要的过程。但这些操作占用的时间越短，内存工作的效率越高，性能也就越好。非数据传输时间的主要组成部分就是各种延迟与潜伏期。通过上文的讲述，大家应该很明显看出有三个参数对内存的性能影响至关重要，它们是tRCD、CL和tRP。每条正规的内存模组都会在标识上注明这三个参数值，可见它们对性能的敏感性。以内存最主要的操作——读取为例。tRCD决定了行寻址（有效）至列寻址（读/写命令）之间的间隔，CL决定了列寻址到数据进行真正被读取所花费的时间，tRP则决定了相同L-Bank中不同工作行转换的速度。现在可以想象一下读取时可能遇到的几种情况（分析写入操作时不用考虑CL即可）：1．要寻址的行与L-Bank是空闲的。也就是说该L-Bank的所有行是关闭的，此时可直接发送行有效命令，数据读取前的总耗时为tRCD+CL，这种情况我们称之为页命中（PH，PageHit）。2．要寻址的行正好是前一个操作的工作行，也就是说要寻址的行已经处于选通有效状态，此时可直接发送列寻址命令，数据读取前的总耗时仅为CL，这就是所谓的背靠背（BacktoBack）寻址，我们称之为页快速命中（PFH，PageFastHit）或页直接命中（PDH，PageDirectHit）。3．要寻址的行所在的L-Bank中已经有一个行处于活动状态（未关闭），这种现象就被称作寻址冲突，此时就必须要进行预充电来关闭工作行，再对新行发送行有效命令。结果，总耗时就是tRP+tRCD+CL，这种情况我们称之为页错失（PM，PageMiss）。显然，PFH是最理想的寻址情况，PM则是最糟糕的寻址情况。上述三种情况发生的机率各自简称为PHR——PHRate、PFHR——PFHRate、PMR——PMRate。因此，系统设计人员（包括内存与北桥芯片）都尽量想提高PHR与PFHR，同时减少PMR，以达到提高内存工作效率的目的。二、增加PHR的方法显然，这与预充电管理策略有着直接的关系，目前有两种方法来尽量提高PHR。自动预充电技术就是其中之一，它自动的在每次行操作之后进行预充电，从而减少了日后对同一L-Bank不同行寻址时发生冲突的可能性。但是，如果要在当前行工作完成后马上打开同一L-Bank的另一行工作时，仍然存在tRP的延迟。怎么办？此时就需要L-Bank交错预充电了。VIA的4路交错式内存控制就是在一个L-Bank工作时，对下一个要工作的L-Bank进行预充电。这样，预充电与数据的传输交错执行，当访问下一个L-Bank时，tRP已过，就可以直接进入行有效状态了。目前VIA声称可以跨P-Bank进行16路内存交错，并以LRU算法进行预充电管理。有关L-Bank交错预充电（存取）的具体执行在本刊2001年第2期已有详细介绍，这里就不再重复了。L-Bank交错自动预充电/读取时序图（可点击放大）：L-Bank0与L-Bank3实现了无间隔交错读取，避免了tRP对性能的影响。三、增加PFHR的方法无论是自动预充电还是交错工作的方法都无法消除tRCD所带来的延迟。要解决这个问题，就要尽量让一个工作行在进行预充电前尽可能多的接收多个工作命令，以达到背靠背的效果，此时就只剩下CL所造成的读取延迟了（写入时没有延迟）。如何做到这一点呢？这就是北桥芯片的责任了。在上文的时序图有一个参数tRAS（ActivetoPrechargeCommand，行有效至预充电命令间隔周期）。它有一个范围，对于PC133标准，一般是预充电命令至少要在行有效命令5个时钟周期之后发出，最长间隔视芯片而异（基本在120000ns左右），否则工作行的数据将有丢失的危险。那么这也就意味着一个工作行从有效（选通）开始，可以有120000ns的持续工作时间而不用进行预充电。显然，只要北桥芯片不发出预充电（包括允许自动预充电）的命令，行打开的状态就会一直保持。在此期间的对该行的任何读写操作也就不会有tRCD的延迟。可见，如果北桥芯片在能同时打开的行（页）越多，那么PFHR也就越大。需要强调的是，这里的同时打开不是指对多行同时寻址（那是不可能的），而是指多行同时处于选通状态。我们可以看到一些SDRAM芯片组的资料中会指出可以同时打开多少个页的指标，这可以说是决定其内存性能的一个重要因素。Intel845芯片组MCH的资料：其中表明它可以支持24个页面同时处于打开状态但是，可同时打开的页数也是有限制的。从SDRAM的寻址原理讲，同一L-Bank中不可能有两个打开的行（S-AMP只能为一行服务），这就限制了可同时打开的页面总数。以SDRAM有4个L-Bank，北桥最多支持8个P-Bank为例，理论上最多只能有32个页面能同时处于打开的状态。而如果只有一个P-Bank，那么就只剩下4个页面，因为有几个L-Bank才能有同时打开几个行而互不干扰。Intel845的MHC虽然可以支持24个打开的页面，那也是指6个P-Bank的情况下（845MCH只支持6个P-Bank）。可见845已经将同时打开页数发挥到了极致。不过，同时打开页数多了，也对存取策略提出了一定的要求。理论上，要尽量多地使用已打开的页来保证最短的延迟周期，只有在数据不存在（读取时）或页存满了（写入时）再考虑打开新的指定页，这也就是变向的连续读/写。而打开新页时就必须要关闭一个打开的页，如果此时打开的页面已是北桥所支持的最大值但还不到理论极限的话，就需要一个替换策略，一般都是用LRU算法来进行，这与VIA的交错控制大同小异。规格播报编辑芯片和模块标准名称内存时脉周期I/O总线时脉数据速率传输方式模组名称极限传输率DDR-200100MHz10ns100MHz200Million并列传输PC-16001600MB/sDDR-266133MHz7.5ns133MHz266Million并列传输PC-21002100MB/sDDR-333166MHz6ns166MHz333Million并列传输PC-27002700MB/sDDR-400200MHz5ns200MHz400Million并列传输PC-32003200MB/s记忆芯片DDR-200：DDR-SDRAM记忆芯片在100MHz下运行DDR-266：DDR-SDRAM记忆芯片在133MHz下运行DDR-333：DDR-SDRAM记忆芯片在166MHz下运行DDR-400：DDR-SDRAM记忆芯片在200MHz下运行（JEDEC制定的DDR最高规格）DDR-500：DDR-SDRAM记忆芯片在250MHz下运行（非JEDEC制定的DDR规格）DDR-600：DDR-SDRAM记忆芯片在300MHz下运行（非JEDEC制定的DDR规格）DDR-700：DDR-SDRAM记忆芯片在350MHz下运行（非JEDEC制定的DDR规格）芯片模块PC-1600内存模块指工作在100MHz下的DDR-200内存芯片，其拥有1.600GB/s的带宽PC-2100内存模块指工作在133MHz下的DDR-266内存芯片，其拥有2.133GB/s的带宽PC-2700内存模块指工作在166MHz下的DDR-333内存芯片，其拥有2.667GB/s的带宽PC-3200内存模块指工作在200MHz下的DDR-400内存芯片，其拥有3.200GB/s的带宽公式播报编辑利用下列公式，就可以计算出DDRSDRAM时脉。DDRI/II内存运作时脉：实际时脉*2。（由于两边数据同时传输，200MHz内存的时脉会以400MHz运作。）内存带宽=内存速度*内存位宽标准公式：内存除频系数=时脉/200→*速算法：外频*（除频频率/同步频率）（使用此公式将会导致4%的误差）取址播报编辑（1）bank块地址---定位逻辑块（2）行地址和列地址---定位存储单元容量定义播报编辑容量定义：地址数*位宽*Bank（存储块）。引脚介绍播报编辑SDRAM在读写数据时重点注意以下信号：（1）CLK：时钟信号，为输入信号。SDRAM所有输入信号的逻辑状态都需要通过CLK的上升沿采样确定。（2）CKE：时钟使能信号，为输入信号，高电平有效。CKE信号的用途有两个：一、关闭时钟以进入省电模式；二、进入自刷新状态。CKE无效时，SDRAM内部所有与输入相关的功能模块停止工作。（3）CS#：片选信号，为输入信号，低电平有效。只有当片选信号有效后，SDRAM才能识别控制器发送来的命令。设计时注意上拉。（4）RAS#：行地址选通信号，为输入信号，低电平有效。（5）CAS#：列地址选通信号，为输入信号，低电平有效。（6）WE#：写使能信号，为输入信号，低电平有效。当然还包括bank[…]地址信号，这个需要根据不同的型号来确定，同样为输入信号；地址信号A[…]，为输入信号；数据信号DQ[…]，为输入/输出双向信号；数据掩码信号DQM，为输入输出双向信号，方向与数据流方向一致，高电平有效。当其有效时，数据总线上出现的对应数据字节被接收端屏蔽。当今主流播报编辑DDR3内存。它属于SDRAM家族的内存产品，提供了相较于DDR2SDRAM更高的运行效能与更低的电压，是DDR2SDRAM（四倍资料率同步动态随机存取内存）的后继者（增加至八倍），也是现时流行的内存产品。DDR3SDRAM为了更省电、传输效率更快，使用了SSTL15的I/O接口，运作I/O电压是1.5V，采用CSP、FBGA封装方式包装，除了延续DDR2SDRAM的ODT、OCD、PostedCAS、AL控制方式外，另外新增了更为精进进的CWD、Reset、ZQ、SRT、PASR功能。CWD是作为写入延迟之用，Reset提供了超省电功能的命令，可以让DDR3SDRAM内存颗粒电路停止运作、进入超省电待命模式，ZQ则是一个新增的终端电阻校准功能，新增这个线路脚位提供了ODCE（OnDieCalibrationEngline）用来校准ODT（OnDieTermination）内部中断电阻，新增了SRT（Self-ReflashTemperature）可编程化温度控制内存时脉功能，SRT的加入让内存颗粒在温度、时脉和电源管理上进行优化，可以说在内存内，就做了电源管理的功能，同时让内存颗粒的稳定度也大为提升，确保内存颗粒不致于工作时脉过高导致烧毁的状况，同时DDR3SDRAM还加入PASR（PartialArraySelf-Refresh）局部Bank刷新的功能，可以说针对整个内存Bank做更有效的资料读写以达到省电功效。工作原理播报编辑SDRAM之所以成为DRAM就是因为它要不断进行刷新（Refresh）才能保留住数据，因为刷新（Refresh）是DRAM最重要的操作。那么要隔多长时间重复一次刷新，目前公认的标准是，存储体中电容的数据有效保存期上限是64ms（毫秒，1/1000秒），也就是说每一行刷新的循环周期是64ms。这样刷新速度就是：64ms/行数量。我们在看内存规格时，经常会看到4096RefreshCycles/64ms或8192RefreshCycles/64ms的标识，这里的4096与8192就代表这个芯片中每个Bank的行数。刷新命令一次对一行有效，发送间隔也是随总行数而变化，4096行时为15.625μs（微秒，1/1000毫秒），8192行时就为7.8125μs。HY57V561620为8192refreshcycles/64ms。SDRAM是多Bank结构，例如在一个具有两个Bank的SDRAM的模组中，其中一个Bank在进行预充电期间，另一个Bank却马上可以被读取，这样当进行一次读取后，又马上去读取已经预充电Bank的数据时，就无需等待而是可以直接读取了，这也就大大提高了存储器的访问速度。为了实现这个功能，SDRAM需要增加对多个Bank的管理，实现控制其中的Bank进行预充电。在一个具有2个以上Bank的SDRAM中，一般会多一根叫做BAn的引脚，用来实现在多个Bank之间的选择。SDRAM具有多种工作模式，内部操作是一个复杂的状态机。SDRAM器件的引脚分为以下几类。（1）控制信号：包括片选、时钟、时钟使能、行列地址选择、读写有效及数据有效。（2）地址信号：时分复用引脚，根据行列地址选择引脚，控制输入的地址为行地址或列地址。。（3）数据信号：双向引脚，受数据有效控制。SDRAM的所有操作都同步于时钟。根据时钟上升沿控制管脚和地址输入的状态，可以产生多种输入命令。模式寄存器设置命令。激活命令。预充命令。读命令。写命令。带预充的读命令。带预充的写命令。自动刷新命令。自我刷新命令。突发停命令。空操作命令。根据输入命令，SDRAM状态在内部状态间转移。内部状态包括模式寄存器设置状态、激活状态、预充状态、写状态、读状态、预充读状态、预充写状态、自动刷新状态及自我刷新状态。SDRAM支持的操作命令有初始化配置、预充电、行激活、读操作、写操作、自动刷新、自刷新等。所有的操作命令通过控制线CS#、RAS#、CAS#、WE#和地址线、体选地址BA输入。1、行激活行激活命令选择处于空闲状态存储体的任意一个行，使之进入准备读/写状态。从体激活到允许输入读/写命令的间隔时钟节拍数取决于内部特征延时和时钟频率。HY57V561620内部有4个体，为了减少器件门数，4个体之间的部分电路是公用的，因此它们不能同时被激活，而且从一个体的激活过渡到另一个体的激活也必须保证有一定的时间间隔。2、预充电预充电命令用于对已激活的行进行预充电即结束活动状态。预充电命令可以作用于单个体，也可以同时作用于所有体（通过所有体预充电命令）。对于突发写操作必须保证在写入预充电命令前写操作已经完成，并使用DQM禁止继续写入数据。预充电结束后回到空闲状态，也可以再次被激活，此时也可以输入进入低功耗、自动刷新、自刷新和模式设置等操作命令。预充电中重写的操作与刷新操作一样，只不过预充电不是定期的，而只是在读操作以后执行的。因为读取操作会破坏内存中的电荷。因此，内存不但要每64ms刷新一次，而且每次读操作之后还要刷新一次。3、自动预充电如果在突发读或突发写命令中，A10/AP位置为“1”，在读写操作完成后自动附加一个预充电动作。操作行结束活动状态，但在内部状态机回到空闲态之前不能给器件发送新的操作命令。4、突发读突发读命令允许某个体中的一行被激活后，连续读出若干个数据。第一个数据在经过指定的CAS延时节拍后呈现在数据线上，以后每个时钟节拍都会读出一个新的数据。突发读操作可以被同体或不同体的新的突发读/写命令或同一体的预充电命令及突发停止命令中止。5、突发写突发写命令与突发读命令类似，允许某个体中的一行被激活后，连续写入若干个数据。第一个写数据与突发写命令同时在数据线上给出，以后每个时钟节拍给出一个新的数据，输入缓冲在突发数据量满足要求后停止接受数据。突发写操作可以被突发读/写命令或DQM数据输入屏蔽命令和预充电命令或突发停止命令中止。6、自动刷新由于动态存储器存储单元存在漏电现象，为了保持每个存储单元数据的正确性，HY57V561620必须保证在64ms内对所有的存储单元刷新一遍。一个自动刷新周期只能刷新存储单元的一个行，每次刷新操作后内部刷新地址计数器自动加“1”。只有在所有体都空闲（因为4个体的对应行同时刷新）并且未处于低功耗模式时才能启动自动刷新操作，刷新操作执行期间只能输入空操作，刷新操作执行完毕后所有体都进入空闲状态。该器件可以每间隔7.8μs执行一次自动刷新命令，也可以在64ms内的某个时间段对所有单元集中刷新一遍。7、自刷新自刷新是动态存储器的另一种刷新方式，通常用于在低功耗模式下保持SDRAM的数据。在自刷新方式下，SDRAM禁止所有的内部时钟和输入缓冲（CKE除外）。为了降低功耗，刷新地址和刷新时间全部由器件内部产生。一旦进入自刷新方式只有通过CKE变低才能激活，其他的任何输入都将不起作用。给出退出自刷新方式命令后必须保持一定节拍的空操作输入，以保证器件完成从自刷新方式的退出。如果在正常工作期间采用集中式自动刷新方式，则在退出自刷新模式后必须进行一遍（对于HY57V561620来说，8192个）集中的自动刷新操作。8、时钟和时钟屏蔽时钟信号是所有操作的同步信号，上升沿有效。时钟屏蔽信号CKE决定是否把时钟输入施加到内部电路。在读写操作期间，CKE变低后的下一个节拍冻结输出状态和突发地址，直到CKE变高为止。在所有的体都处于空闲状态时，CKE变低后的下一个节拍SDRAM进入低功耗模式并一直保持到CKE变高为止。9、DQM操作DQM用于屏蔽输入输出操作，对于输出相当于开门信号，对于输入禁止把总线上的数据写入存储单元。对读操作DQM延迟2个时钟周期开始起作用，对写操作则是当拍有效。[1]DMA：简介播报编辑通常会指定一个内存部分用于直接内存访问。在ISA总线标准中，高达16兆字节的内存可用于DMA。EISA和微通道架构标准允许访问全套内存地址（假设他们可以用32位寻址）。外围设备互连通过使用一个总线主控器来完成直接内存访问。直接内存访问的另一个选择是程控输入输出（PIO）接口。在程控输入输出接口中，设备之间所有的数据传输都要通过处理器。ATA/IDE接口的新协议是UltraDMA，它提供的突发数据传输速率可达33兆字节每秒。具有UltraDMA/33的硬盘驱动器也支持PIO模式1、3、4和多字DMA模式2（每秒16.6兆字节）。[1]原理播报编辑外设与存储器之间以及存储器与存储器之间的数据传输，通常采用程序中断方式、程序查询方式和DMA控制方式。程序中断方式和程序查询方式都需要CPU发出输入/输出（In/Out，I/O）的指令，然后等待I/O设备完成操作之后返回，期间CPU需要等待I/O设备完成操作。DMA在传输存储器和I/O设备的数据时，无须CPU来控制数据的传输，直接通过DMA控制器（directmemoryaccesscontroller，DMAC）完成外设与存储器之间以及存储器与存储器之间的数据高速传输。[3]DMA传输原理一个完整的DMA传输包括DMA请求、DMA响应、DMA传输和DMA结束4个步骤。DMA传输原理如图1所示，图中I/O设备为源端设备，由I/O设备向目的端设备（存储器）传输数据，其DMA的基本传输过程如下：①CPU对总线控制器进行初始化，制定工作内存空间，读取DMAC中的寄存器信息，了解DMAC的传输状态[1]；②I/O设备向DMAC发送DMA请求（DMArequest，DREQ），DMAC收到此信号后，向CPU发出总线保持信号（HOLD）；③CPU当前总线周期执行结束后发出总线响应信号保持确认（holdacknowledgment，HLDA）；④DMAC收到总线授权后，向I/O设备发送DMA响应信号DMA确认（DMAacknowledgment，DACK），表示允许I/O设备进行DMA传送；⑤开始传输时，DMAC首先从源地址读取数据并存入内部缓存中，再写入目的地址，完成总线数据从源地址到目的地址的传输[1]；⑥DMA传输完成后，DMAC向CPU发出结束信号，释放总线，使CPU重新获得总线控制权。一次DMA传输只需要执行一个DMA周期，相当于一个总线读/写周期，因而能够满足外设数据高速传输的需要。[3]DMA是所有现代电脑的重要特色，它允许不同速度的硬件设备来沟通，而不需要依于中央处理器的大量中断负载。否则，中央处理器需要从来源把每一片段的数据复制到寄存器，然后把它们再次写回到新的地方。在这个时间中，中央处理器对于其他的工作来说就无法使用。DMA传输常使用在将一个内存区从一个设备复制到另外一个。当中央处理器初始化这个传输动作，传输动作本身是由DMA控制器来实行和完成。典型的例子就是移动一个外部内存的区块到芯片内部更快的内存去。像是这样的操作并没有让处理器工作拖延，使其可以被重新调度去处理其他的工作。DMA传输对于高性能嵌入式系统算法和网络是很重要的。举个例子，个人电脑的ISADMA控制器拥有8个DMA通道，其中的7个通道是可以让计算机的中央处理器所利用。每一个DMA通道有一个16位地址寄存器和一个16位计数寄存器。要初始化数据传输时，设备驱动程序一起设置DMA通道的地址和计数寄存器，以及数据传输的方向，读取或写入。然后指示DMA硬件开始这个传输动作。当传输结束的时候，设备就会以中断的方式通知中央处理器。"分散-收集"（Scatter-gather）DMA允许在一次单一的DMA处理中传输数据到多个内存区域。相当于把多个简单的DMA要求串在一起。同样，这样做的目的是要减轻中央处理器的多次输出输入中断和数据复制任务。DRQ意为DMA要求；DACK意为DMA确认。这些符号一般在有DMA功能的电脑系统硬件概要上可以看到。它们表示了介于中央处理器和DMA控制器之间的电子信号传输线路。[1]缓存一致性问题播报编辑DMA会导致缓存一致性问题。想像中央处理器带有缓存与外部内存的情况，DMA的运作则是去访问外部内存，当中央处理器访问外部内存某个地址的时候，暂时先将新的值写入缓存中，但并未将外部内存的数据更新，若在缓存中的数据尚未更新到外部内存前发生了DMA，则DMA过程将会读取到未更新的数据。相同的，如果外部设备写入新的值到外部内存内，则中央处理器若访问缓存时则会访问到尚未更新的数据。这些问题可以用两种方法来解决：1.缓存同调系统（Cache-coherentsystem）：以硬件方法来完成，当外部设备写入内存时以一个信号来通知缓存控制器某内存地址的值已经过期或是应该更新数据。2.非同调系统（Non-coherentsystem）：以软件方法来完成，操作系统必须确认缓存读取时，DMA程序已经开始或是禁止DMA发生。第二种的方法会造成DMA的系统负担。[2]DMA引擎播报编辑除了与硬件交互相关外，DMA也可为昂贵的内存耗费减负。比如大型的拷贝行为或scatter-gather操作，从中央处理器到专用的DMA引擎。Intel的高端服务器包含这种引擎，它被称为I/O加速技术（IOAT）。[2]RDMA播报编辑在电脑运算领域，远程直接内存访问（英语：remotedirectmemoryaccess，RDMA）是一种直接存储器访问技术，它将数据直接从一台计算机的内存传输到另一台计算机，无需双方操作系统的介入。这允许高通量、低延迟的网络通信，尤其适合在大规模并行计算机集群中使用。RDMA支持零复制网络传输，通过使网络适配器直接在应用程序内存间传输数据，不再需要在应用程序内存与操作系统缓冲区之间复制数据。这种传输不需要中央处理器、CPU缓存或上下文交换参与，并且传输可与其他系统操作并行。当应用程序执行RDMA读取或写入请求时，应用程序数据直接传输到网络，从而减少延迟并实现快速的消息传输。但是，这种策略也表现出目标节点不会收到请求完成的通知（单向通信）等相关的若干问题。[2]非易失性内存：类型播报编辑非易失性存储器主要有以下类型：ROM（Read-onlymemory，只读内存）PROM（Programmableread-onlymemory，可编程只读内存）EAROM（Electricallyalterablereadonlymemory，电可改写只读内存）EPROM（Erasableprogrammablereadonlymemory，可擦可编程只读内存）EEPROM（Electricallyerasableprogrammablereadonlymemory，电可擦可编程只读内存）Flashmemory（闪存）[1]只读存储器播报编辑只读存储器（Read-OnlyMemory，ROM）是一种半导体存储器，其特性是一旦存储数据就无法再将之改变或删除，且内容不会因为电源关闭而消失。在电子或电脑系统中，通常用以存储不需经常变更的程序或数据，例如早期的家用电脑如AppleII的监督程序、BASIC语言解释器、与硬件点阵字体，个人电脑IBMPC/XT/AT的BIOS（基本输入输出系统）与IBMPC/XT的BASIC解释器，与其他各种微电脑系统中的固件（Firmware），均存储在ROM内。PROM主条目：PROM可编程只读存储器（ProgrammableROM，PROM）其内部有行列式的镕丝，可依用户（厂商）的需要，利用电流将其烧断，以写入所需的数据及程序，镕丝一经烧断便无法再恢复，亦即数据无法再更改。EPROM主条目：EPROM可抹除可编程只读存储器（ErasableProgrammableReadOnlyMemory，EPROM）可利用高电压将数据编程写入，但抹除时需将线路曝光于紫外线下一段时间，数据始可被清空，再供重复使用。因此，在封装外壳上会预留一个石英玻璃所制的透明窗以便进行紫外线曝光。写入程序后通常会用贴纸遮盖透明窗，以防日久不慎曝光过量影响数据。OTPROM一次编程只读存储器（OneTimeProgrammableReadOnlyMemory，OTPROM）内部所用的芯片与写入原理同EPROM，但是为了节省成本，封装上不设置透明窗，因此编程写入之后就不能再抹除改写。EEPROM主条目：EEPROM电子抹除式可复写只读存储器（ElectricallyErasableProgrammableReadOnlyMemory，EEPROM）之运作原理类似EPROM，但是抹除的方式是使用高电场来完成，因此不需要透明窗。[1]闪存播报编辑快闪存储器（英语：flashmemory），是一种电子式可清除程序化只读存储器的形式，允许在操作中被多次擦或写的存储器。这种科技主要用于一般性数据存储，以及在电脑与其他数字产品间交换传输数据，如储存卡与U盘。闪存是一种特殊的、以宏块抹写的EEPROM。早期的闪存进行一次抹除，就会清除掉整颗芯片上的数据。闪存的成本远较可以字节为单位写入的EEPROM来的低，也因此成为非易失性固态存储最重要也最广为采纳的技术。像是PDA、笔记本电脑、数字随身听、数码相机与手机上均可见到闪存。此外，闪存在游戏主机上的采用也日渐增加，藉以取代存储游戏数据用的EEPROM或带有电池的SRAM。闪存是非易失性的内存。这表示单就保存数据而言，它是不需要消耗电力的。与硬盘相比，闪存也有更佳的动态抗震性。这些特性正是闪存被移动设备广泛采用的原因。闪存还有一项特性：当它被制成储存卡时非常可靠──即使浸在水中也足以抵抗高压与极端的温度。闪存的写入速度往往明显慢于读取速度。虽然闪存在技术上属于EEPROM，但是“EEPROM”这个字眼通常特指非快闪式、以小区块为清除单位的EEPROM。它们典型的清除单位是字节。因为老式的EEPROM抹除循环相当缓慢，相形之下快闪记体较大的抹除区块在写入大量数据时带给其显著的速度优势。闪存最常见的封装方式是TSOP48和BGA，在逻辑接口上的标准则由于厂商阵营而区分为两种：ONFI和Toggle。手机上的闪存常常以eMMC的方式存在。[2]闪存的限制播报编辑区块抹除闪存的一种限制在于即使它可以单一字节的方式读或写入，但是抹除一定是一整个区块。一般来说都是设置某一区中的所有比特为“1”，刚开始区块内的所有部分都可以写入，然而当有任何一个比特被设为“0”时，就只能借由清除整个区块来恢复“1”的状态。换句话说闪存（特别是NORFlash）能提供随机读取与写入操作，却无法提供任意的随机改写。不过其上的区块可以写入与既存的“0”值一样长的消息（新值的0比特是旧值的0比特的超集）。例如：有一小区块的值已抹除为1111，然后写入1110的消息。接下来这个区块还可以依序写入1010、0010，最后则是0000。可是实际上少有算法可以从这种连续写入兼容性得到好处，一般来说还是整块抹除再重写。尽管闪存的数据结构不能完全以一般的方式做更新，但这允许它以“标记为不可用”的方式删除消息。这种技巧在每单元存储大于1比特数据的MLC设备中必须稍微做点修改。记忆耗损另一项闪存的限制是它有抹写循环的次数限制（大多商业性SLC闪存保证“0”区有十万次的抹写能力，但其他区块不保证）。这个结果部分地被某些固件或文件系统为了在相异区块间分散写入操作而进行的计算写入次数与动态重对映所抵销；这种技巧称为耗损平衡（wearleveling）。另一种处理方法称为坏区管理（BadBlockManagement,BBM）。这种方法是在写入时做验证并进行动态重测，如果有验证失败的区块就加以剔除。对多数移动设备而言，这些磨损管理技术可以延长其内部闪存的寿命（甚至超出这些设备的使用年限）。此外，丢失部分数据在这些设备上或许是可接受的。至于会进行大量数据读写循环的高可靠性数据存储应用则不建议使用闪存。不过这种限制不适用于路由器与瘦客户端（Thinclients）等只读式应用，这些设备往往在使用年限内也只会写入一次或少数几次而已。读取干扰所使用的闪存读取方式随着时间的推移会导致在同一区块中相近的记忆单元内容改变（变成写入动作）。这即是所谓的读取干扰。会导致读取干扰现象的读取次数门槛介于区块被抹除间，通常为100,000次。假如连续从一个记忆单元读取，此记忆单元将不会受损，而受损却是接下来被读取的周围记忆单元。为避免读取干扰问题，闪存控制器通常会计算从上次抹除动作后的区块读取动作总次数。当计数值超过所设置的目标值门槛时，受影响的区块会被复制到一个新的区块，然后将原区块抹除后释放到区块回收区中。原区块在抹除动作后就会像新的一样。若是闪存控制器没有即时介入时，读取干扰错误就会发生，如果错误太多而无法被ECC机制修复时就会伴随着可能的数据丢失。写入（编程）干扰写入干扰（编程干扰）是指当对页（page）进行写入时，由于阈值电压接近的关系，相邻的位（bit）也被升高，从而造成相邻的位出错。闪存电荷非常不稳定，相邻存储电荷的悬浮门间会相互干扰，造成相邻悬浮门间的bit错误，MLC由于存在4组接近的电压，与SLC相比更容易受到干扰。[3]存储单元：介绍播报编辑存储单元存储单元：在存储器中有大量的存储元，把它们按相同的位划分为组，组内所有的存储元同时进行读出或写入操作，这样的一组存储元称为一个存储单元。一个存储单元通常可以存放一个字节；存储单元是CPU访问存储器的基本单位。[1-2]存储单元播报编辑地址上存储单元的过程在计算机中最小的信息单位是bit，也就是一个二进制位，8个bit组成一个Byte，也就是字节。一个存储单元可以存储一个字节，也就是8个二进制位。计算机的存储器容量是以字节为最小单位来计算的，对于一个有128个存储单元的存储器，可以说它的容量为128字节。如果有一个1KB的存储器则它有1024个存储单元，它的编号为从0－1023。存储器被划分成了若干个存储单元，每个存储单元都是从0开始顺序编号，如一个存储器有128个存储单元，则它的编号就是从0-127。存储地址一般用十六进制数表示，而每一个存储器地址中又存放着一组二进制（或十六进制）表示的数，通常称为该地址的内容。值得注意的是，存储单元的地址和地址中的内容两者是不一样的。前者是存储单元的编号，表示存储器中的一个位置，而后者表示这个位置里存放的数据。正如一个是房间号码，一个是房间里住的人一样。存放一个机器字的存储单元，通常称为字存储单元，相应的单元地址叫字地址。而存放一个字节的单元，称为字节存储单元，相应的地址称为字节地址。如果计算机中可以编址的最小单元是字存储单元，则该计算机称为按字寻址的计算机。如果计算机中可编址的最小单位是字节，则该计算机称为按字节寻址的计算机。如果机器字长等于存储器单元的位数，一个机器字可以包含数个字节，所以一个存储单元也可以包含数个能够单独编址的字节地址。例如一个16位二进制的字存储单元可存放两个字节，可以按字地址寻址，也可以按字节地址寻址。当用字节地址寻址时，16位的存储单元占两个字节地址。最小静态存储单元播报编辑世界上最小的静态存储单元2008年8月18日，美国IBM公司、AMD以及纽约州立大学Albany分校的纳米科学与工程学院（CNSE）等机构共同宣布，世界上首个22纳米节点有效静态随机存储器（SRAM）研制成功。这也是全世界首次宣布在300毫米研究设备环境下，制造出有效存储单元。SRAM芯片是更复杂的设备，比如微处理器的“先驱”。SRAM单元的尺寸更是半导体产业中的关键技术指标。最新的SRAM单元利用传统的六晶体管设计，仅占0.1平方微米，打破了此前的SRAM尺度缩小障碍。新的研究工作是在纽约州立大学Albany分校的纳米科学与工程学院（CNSE）完成的，IBM及其他伙伴的许多顶尖的半导体研究都在这里进行。IBM科技研发部副总裁T.C.Chen博士称，“我们正在可能性的终极边缘进行研究，朝着先进的下一代半导体技术前进。新的研究成果对于不断驱动微电子设备小型化的追求，可以说至关重要。”22纳米是芯片制造的下两代，而下一代是32纳米。在这方面，IBM及合作伙伴正在发展它们无与伦比的32纳米高K金属栅极工艺（high-Kmetalgatetechnology）。从传统上而言，SRAM芯片通过缩小基本构建单元，来制造得更加紧密。IBM联盟的研究人员优化了SRAM单元的设计和电路图，从而提升了稳定性，此外，为了制造新型SRAM单元，他们还开发出几种新的制作工艺流程。研究人员利用高NA浸没式光刻（high-NAimmersionlithography）技术刻出了模式维度和密度，并且在先进的300毫米半导体研究环境中制作了相关部件。与SRAM单元相关的关键技术包括：边带高K金属栅极、<25纳米栅极长度晶体管、超薄隔离结构（spacer）、共同掺杂、先进激活技术、极薄硅化物膜以及嵌入式铜触点等。据悉，在2008年12月15至17日美国旧金山将要举行的IEEE国际电子设备（IEDM）年会上，还会有专门的报告来介绍最新成果的细节。相关应用播报编辑在计算机中，由控制器解释，运算器执行的指令集是一个精心定义的数目十分有限的简单指令集合。一般可以分为四类：1）、数据移动（如：将一个数值从存储单元A拷贝到存储单元B）2）、数逻运算（如：计算存储单元A与存储单元B之和，结果返回存储单元C）3）、条件验证（如：如果存储单元A内数值为100，则下一条指令地址为存储单元F）4）、指令序列改易（如：下一条指令地址为存储单元F）[1]中断：术语解释播报编辑指处理机处理程序运行中出现的紧急事件的整个过程.程序运行过程中，系统外部、系统内部或者现行程序本身若出现紧急事件，处理机立即中止现行程序的运行，自动转入相应的处理程序(中断服务程序)，待处理完后，再返回原来的程序运行，这整个过程称为程序中断;当处理机接受中断时，只需暂停一个或几个周期而不执行处理程序的中断，称为简单中断.中断又可分为屏蔽中断和非屏蔽中断两类.可由程序控制其屏蔽的中断称为屏蔽中断或可屏蔽中断.屏蔽时，处理机将不接受中断.反之，不能由程序控制其屏蔽，处理机一定要立即处理的中断称为非屏蔽中断或不可屏蔽中断.非屏蔽中断主要用于断电、电源故障等必须立即处理的情况.处理机响应中断时，不需执行查询程序.由被响应中断源向CPU发向量地址的中断称为向量中断，反之为非向量中断.向量中断可以提高中断响应速度。[2]分类播报编辑硬件中断（HardwareInterrupt）[3]：可屏蔽中断（maskableinterrupt）。硬件中断的一类，可通过在中断屏蔽寄存器中设定位掩码来关闭。非可屏蔽中断（non-maskableinterrupt，NMI）。硬件中断的一类，无法通过在中断屏蔽寄存器中设定位掩码来关闭。典型例子是时钟中断（一个硬件时钟以恒定频率—如50Hz—发出的中断）。处理器间中断（interprocessorinterrupt）。一种特殊的硬件中断。由处理器发出，被其它处理器接收。仅见于多处理器系统，以便于处理器间通信或同步。伪中断（spuriousinterrupt）。一类不希望被产生的硬件中断。发生的原因有很多种，如中断线路上电气信号异常，或是中断请求设备本身有问题。软件中断（SoftwareInterrupt）[3]：软件中断。是一条CPU指令，用以自陷一个中断。由于软中断指令通常要运行一个切换CPU至内核态（KernelMode/Ring0）的子例程，它常被用作实现系统调用（Systemcall）。防止方法播报编辑要防止中断冲突，其实就是要知道什么设备容易产生中断冲突，只要知道了这点，在使用这些设备时稍微注意一下就可以了。下面我列出一些容易冲突的设备，希望对读者有用。1、声卡：一些早期的ISA型声卡，系统很有可能不认，就需要用户手动设置（一般为5）2、内置调制解调器和鼠标：一般鼠标用COM1，内置调制解调器使用COM2的中断（一般为3），这时要注意此时COM2上不应有其它设备3、网卡和鼠标：此问题一般发生在鼠标在COM1口，使用中断为3，这时要注意通常网卡的默认中断为3，两者极有可能发成冲突。4、打印机和EPP扫描仪：在安装扫描仪驱动程序时应将打印机打开，因为两个设备中串联，所以为了防止以后扫描仪驱动程序设置有误，一定要将打印机打开再安装扫描仪驱动程序。5、操作系统和BIOS：如果计算机使用了“即插即用”操作系统（例如win98），应将BIOS中PNPOSInstalled设置为Yes这样可让操作系统重新设置中断。6、PS/2鼠标和BIOS：在使用PS/2鼠标时应将BIOS中PS/2MouseFunctionControl打开或设置为Auto，只有这样BIOS才能将IRQ12分配给PS/2鼠标用。功能播报编辑现代计算机中采用中断系统的主要目的是[4]：①提高计算机系统效率。计算机系统中处理机的工作速度远高于外围设备的工作速度。通过中断可以协调它们之间的工作。当外围设备需要与处理机交换信息时，由外围设备向处理机发出中断请求，处理机及时响应并作相应处理。不交换信息时，处理机和外围设备处于各自独立的并行工作状态。②维持系统可靠正常工作。现代计算机中，程序员不能直接干预和操纵机器，必须通过中断系统向操作系统发出请求，由操作系统来实现人为干预。主存储器中往往有多道程序和各自的存储空间。在程序运行过程中，如出现越界访问，有可能引起程序混乱或相互破坏信息。为避免这类事件的发生，由存储管理部件进行监测，一旦发生越界访问，向处理机发出中断请求，处理机立即采取保护措施。③满足实时处理要求。在实时系统中，各种监测和控制装置随机地向处理机发出中断请求，处理机随时响应并进行处理。④提供故障现场处理手段。处理机中设有各种故障检测和错误诊断的部件，一旦发现故障或错误，立即发出中断请求，进行故障现场记录和隔离，为进一步处理提供必要的依据。中断优先权播报编辑在某一时刻有几个中断源同时发出中断请求时，处理器只响应其中优先权最高的中断源。当处理机正在运行某个中断服务程序期间出现另一个中断源的请求时，如果后者的优先权低于前者，处理机不予理睬，反之，处理机立即响应后者，进入所谓的“嵌套中断”。中断优先权的排序按其性质、重要性以及处理的方便性决定，由硬件的优先权仲裁逻辑或软件的顺序询问程序来实现[4]。中断过程播报编辑按照事件发生的顺序，中断过程包括[4]：①中断源发出中断请求;②判断当前处理机是否允许中断和该中断源是否被屏蔽;③优先权排队;④处理机执行完当前指令或当前指令无法执行完，则立即停止当前程序，保护断点地址和处理机当前状态，转入相应的中断服务程序;⑤执行中断服务程序;⑥恢复被保护的状态，执行“中断返回”指令回到被中断的程序或转入其他程序。上述过程中前四项操作是由硬件完成的，后两项是由软件完成的。向量中断播报编辑对应每个中断源设置一个向量。这些向量顺序存在主存储器的特定存储区。向量的内容是相应中断服务程序的起始地址和处理机状态字。在响应中断时，由中断系统硬件提供向量地址，处理机根据该地址取得向量，并转入相应的中断服务程序[4]。超标量技术：超标量CPU不可能再进一步调高性能了，这是由于指令的并行度ILP所决定的，即使编译器可以使用诸如循环展开优化技术，超标量CPU对性能的改善也很有限。算术逻辑单元：简介播报编辑算术逻辑单元算术逻辑单元（Arithmetic&logicalUnit）是中央处理器(CPU)的执行单元，是所有中央处理器的核心组成部分，由"AndGate"（与门）和"OrGate"（或门）构成的算术逻辑单元，主要功能是进行二位元的算术运算，如加减乘(不包括整数除法)。基本上，在所有现代CPU体系结构中，二进制都以补码的形式来表示。发展播报编辑算术逻辑单元算术逻辑单元（arithmeticlogicunit，缩写ALU）是进行整数运算的结构。现阶段是用电路来实现，应用在电脑芯片中。在计算机中，算术逻辑单元（ALU）是专门执行算术和逻辑运算的数字电路。ALU是计算机中央处理器的最重要组成部分，甚至连最小的微处理器也包含ALU作计数功能。在现代CPU和GPU处理器中已含有功能强大和复杂的ALU；一个单一的元件也可能含有ALU。1945年数学家冯诺伊曼在一篇介绍被称为EDVAC的一种新型电脑的基础构成的报告中提出ALU的概念。早期发展1946年，冯诺伊曼与同事合作为普林斯顿高等学习学院(IAS)设计计算机。随后IAS计算机成为后来计算机的原形。在论文中，冯诺伊曼提到他所相信的计算机中所需的部件，而其中包括ALU。冯诺伊曼写到，ALU是计算机的必备组成部分，因为已确定计算机一定要完成基本的数学运算，包括加减乘除。于是他相信「（计算机）应该含有专门完成此类运算的部件。」数字系统ALU必须与数字电路的其他部分使用同样的格式来进行数字处理。对现代处理器而言，数值一律使用二进制补码表示。早期的计算机曾使用过很多种数字系统，包括反码、符号数值码，甚至是十进制码，每一位用十个管子。以上这每一种数字系统所对应的ALU都有不同的设计，而这也影响了当前对二进制补码的优先选择，因为二进制补码能简化ALU加法和减法的运算。一个简单的能进行与或非和加运算的2位ALU。可行性分析绝大部分计算机指令都是由ALU执行的。ALU从寄存器中取出数据。数据经过处理将运算结果存入ALU输出寄存器中。其他部件负责在寄存器与内存间传送数据。控制单元控制着ALU，通过控制电路来告诉ALU该执行什么操作。[1]简单运算大部分ALU都可以完成以下运算∶整数算术运算（加、减，有时还包括乘和除，不过成本较高）位逻辑运算（与、或、非、异或）移位运算（将一个字向左或向右移位或浮动特定位，而无符号延伸），移位可被认为是乘以2或除以2。复杂运算工程师可设计能完成任何运算的ALU，不论运算有多复杂；问题在于运算越复杂，ALU成本越高，在处理器中占用的空间越大，消耗的电能越多。于是，工程师们经常计算一个折中的方案，提供给处理器（或其他电路）一个能使其运算高速的ALU，但同时又避免ALU设计的太复杂而价格昂贵。设想你需要计算一个数的平方根，数字工程师将评估以下的选项来完成此操作∶设计一个极度复杂的ALU，它能够一步完成对任意数字的平方根运算。这被称为单时钟脉冲计算。设计一个非常复杂的ALU，它能够分几步完成一个数字的平方根运算。不过，这里有个诀窍，中间结果经过一连串电路，就像是工厂里的生产线。这甚至使得ALU能够在完成前一次运算前就接受新的数字。这使得ALU能够以与单时钟脉冲同样的速度产生数字，虽然从ALU输出的结果有一个初始延迟。这被称为计算流水线。设计一个复杂的ALU，它能够计算分几步计算一个数字的平方根。这被称为互动计算，经常依赖于带有嵌入式微码的复杂控制单元。在处理器中设计一个简单的ALU，去掉一个昂贵的专门用于此运算的处理器，再选择以上三个选项之一。这被称为协处理器。告诉编程人员没有协处理器和仿真设备，于是他们必须自己写出算法来用软件计算平方根。这是由软件库完成的。对协处理器进行仿真，也就是说，只要一个程序想要进行平方根的计算，就让处理器检查当前有没有协处理器。如果有的话就使用其进行计算，如果没有的话，中断程序进程并调用操作系统通过软件算法来完成平方根的计算。这被称为软件仿真。以上给出的选项按最快和最贵到最慢和最经济排列。于是，虽然甚至是最简单的计算机也能计算最复杂的公式，但是最简单的计算机经常需要耗费大量时间，通过若干步才能完成。强大的处理器，比如英特尔酷睿和AMD64系列对一些简单的运算采用1号选项，对最常见的复杂运算采用2号选项，对极为复杂的运算采用3号选项。这是具有在处理器中构造非常复杂的ALU的能力为前提的。输入和输出ALU的输入是要进行操作的数据（称为操作数）以及来自控制单元的指令代码，用来指示进行哪种运算。它的输出即为运算结果。在许多设计中ALU也接收或发出输入或输出条件代码到（或来自）状态寄存器。这些代码用来指示一些情况，比如进位或借位、溢出、除数为零等。ALU与FPU浮点单元也对两个数值进行算术运算，但是这种运算已浮点数表示，比在ALU中一般使用的补码表示方式复杂的多。为了完成此类运算，FPU里嵌入了多个复杂电路，包括一些内部ALU。工程师一般认为ALU是处理整数型（比如补码和BCD码）算术运算的的电路，而对更为复杂的格式（比如浮点型、复数型）进行计算的电路则拥有一个更加匹配的称谓。[2]特点播报编辑ALU用以计算机指令集中的执行算术与逻辑操作;某些处理器中，将ALU切分为两部分，即算术单元（AU）与逻辑单元（LU）。某些处理器包含一个以上的AU，如，一个用来进行定点操作，另一个进行浮点操作。（个人计算机中，浮点操作有时由被称为数字协处理器的浮点单元完成）。通常而言，ALU具有对处理器控制器、内存及输入输出设备的直接读入读出权限。输入输出是通过总线进行的。输入指令包含一个指令字，有时被称为机器指令字，其中包括操作码，单个或多个操作数，有时还会有格式码；操作码指示ALU机要执行什么操作，在此操作中要执行多少个操作数。比如，两个操作数可以进行比较，也可以进行加法操作。格式码可与操作码结合，告知这是一个定点还是浮点指令；输出包括存放在存储寄存器中的结果及显示操作是否成功的设置。如操作失败，则在机器状态字中会有相应的状态显示。通常，输入操作数、操作数、累加和以及转换结果的存储位置都在ALU中。在算术单元中，乘除操作是通过一系列的加减运算得到的。在机器码中有多种方式用以表示负数。在逻辑单元中，每次执行16个可能的逻辑运算中的一个。ALU的设计是处理器设计中的关键部分。仍在不断研究如何提高指令的处理速度。[3]逻辑单元播报编辑逻辑单元(LU)是进入IBM系统网络体系结构(SNA)的网络端口，通过它用户可以访问网络资源，或一个程序员与另一个程序员通信。[4]并行传输：概念播报编辑并行传输指的是数据以成组的方式，在多条并行信道上同时进行传输。常用的是将构成一个字符的几位二进制码同时分别在几个并行的信道上传输。另外加一条控制信号即“选通”脉冲，它在数据信号发出之后传送，用以通知接收设备所有位已经发送完毕，可对各条信道上的信号进行取样了。这类传输比较简单，对8位微处理器来说，8位的数据一次同时传送。微处理器本身处理的数据就是并行处理，所以这就不需要对数据进行格式的变化。因此实现这类传输的接口电路也比较简单。[1]基本原理播报编辑并行传输的编码一个编了码的字符通常是由若干位二进制数表示,如用ASCII码编码的符号是由8位二进制数表示的,则并行传输ASCII编码符号就需要8个传输信道,使表示一个符号的所有数据位能同时沿着各自的信道并排的传输.并行传输时，一次可以传一个字符，收发双方不存在同步的问题。而且速度快、控制方式简单。但是，并行传输需要多个物理通道。所以并行传输只适合于短距离、要求传输速度快的场合使用。这类的接口电路必须具有缓冲寄存器，以便使数据在接口中停留足够的时间以适应外部设备的动作时间，或者是供微处理器在适当的时候来去数。另外还应该有一些控制电路；地址译码选择电路；用于在MPU查询时应答的状态标志电路和由关控制；寄存MPU发来的控制命令的寄存器以及中断逻辑控制电路等等。[2]并行传输的实现一个采用8单位二进制码构成了一个字符进行并行传输，系统采用8个信道并行传输，一次传送一个字符，因此收、发双方不存在字符同步的问题，不需要额外的措施来实现收发双方的字符同步，这是并行传输的主要优点。但是并行传输必须有多条并行信道，成本比较高，不易远距离传输。这类总线传输速度快，但适用于短距离传送。典型的有S-100总线、MUI.TIBUS总线、标准总线、IEEE-488总线等。并行标准总线通常是用于插件板之间的连接。只有IEEE-488是用于系统和系统之间的连接。[3]磁盘：发展历史播报编辑在过去的50年中，磁盘驱动器走过了很长的一段路。请跟随我们走过这段历史，回首我们按年度列出的磁盘驱动器发展史上50件具有里程碑意义的事件——从最早推出的产品到各种新技术以及在这中间的一切。1956年：IBM向客户交付第一台磁盘驱动器RAMAC305，可存储5MB数据，每MB成本为10000美元。它有2个冰箱那样大，使用50个24英寸盘片。1961年：IBM发明在空气垫上或“空气支撑物”上“悬浮”的磁盘驱动器磁头。1963年：IBM推出第一个活动磁盘驱动器1311，拥有6个14英寸盘片，可存储2.6MB数据。1966年：IBM推出第一个使用缠绕线圈铁氧记录磁头的驱动器。1970年：通用数据公司(1971年更名为西部数据公司)在加州成立。1973年：IBM宣布推出第一个现代“温彻斯特”磁盘驱动器3340，使用了密封组件、润滑主轴和小质量磁头。1978年：第一个RAID(冗余阵列)驱动器诞生。1979：磁盘制造商希捷科技公司于1979年由AlShugart挑头创立。1979：IBM的3370使用了7个直径为14英寸的盘片，存储容量可达571MB。3370也是首款使用薄胶片磁头的磁盘，1979：IBM的“Piccolo”电脑磁盘使用了6个直径为8英寸的盘片，存储容量可达64MB。1979：希捷科技公司研发出最早的磁盘接口——ST-506，之后便广泛用于微型计算机中。1980：IBM发布了当时首个存储容量以GB为单位的磁盘，其大小和一台电冰箱大小差不多，重量为250kg，出售价格为40000美元。1980：希捷科技公司发布首个大小为5.25英寸的磁盘。1981：ShugartAssociates联手NCR共同研发出一个智能磁盘接口，命名为ShugartAssociatesSystemsInterface(SASI)，该接口是SCSI(SmallComputerSystemInterface，小型计算机系统接口)的前辈。1982：WesternDigital宣布推出了首个单芯片“温彻斯特”磁盘控制器——WD1010。1983：Rodime宣布推出了当时首个3.5英寸的磁盘——RO352，它包括有两个盘片，存储容量可达10MB。1984：WesternDigital为IBMPC/AT制造出首个“温彻斯特”磁盘控制卡，并成为了当时的一种工业标准。1985：ControlData、CompaqComputer和WesternDigital共同合作，并研发出40-pin的IDE接口。IDE是IntelligentDriveElectronics(智慧电子驱动器)的缩写。1985：磁盘控制器首次整合到磁盘驱动当中。1985：Quantum(昆腾)发布了PlusHardcard磁盘，它在无需一个可用的插槽，或单独控制卡的情况下，可再多配置一个磁盘。1985：WesternDigital宣布推出了首款ESDI(EnhancedSmallDeviceInterface，增强型小型设备接口)控制板，它允许容量更大、速度更快的磁盘用于电脑当中。1986：官方的SCSI规格发布，而苹果电脑公司的MacPlus也是首台使用该规格的电脑之一。1988：PrairieTek宣布推出了220磁盘，这是首个2.5英寸的磁盘，主要是针对初生的笔记本电脑市场推出的。220磁盘使用了两个盘片，存储容量可达20MB。1988：Connor发布了首个高为1英寸的3.5英寸磁盘，还有磁盘沿袭了这种设计。1988：WesternDigital成功收购Tandon公司，转型为专业的磁盘制造商。1990：WesternDigital发布了其首个3.5英寸的Caviar(鱼子酱)IDE磁盘。1991：IBM向外界宣布推出了0663Corsair，这是首款采用感应式薄胶片磁阻(MR)磁头的磁盘。它设计有8个直径为3.5英寸的盘片，存储容量可达1GB。(MR磁头早在1984年就用于IBM的磁盘驱动器。)1991：IntegralPeripherals推出了使用一个直径为1.8英寸的盘片，存储容量可达21MB的1820Mustang磁盘。1992：希捷科技公司首次向外界展示了其2.5英寸的磁盘，在当时给了人们极大的震撼。1992：希捷科技公司成功的推出了存储容量为2.1GB的Barracuda(酷鱼)，这是首个采用7200r/min转速马达的磁盘。1992：惠普推出了C3013AKittyHawk磁盘，使用了两个直径为1.3英寸的盘片，存储容量可达2.1GB。1994：WesternDigital成功研发出EnhancedIDE，这是一个改良版的磁盘接口，并打破了当时528MB存储容量上限的束缚。EIDE同样也允许配置光驱和磁盘驱动器。1996：IBM成功研发出在1个盘片上可存储100亿比特/英寸的磁盘技术。1996：希捷科技公司宣布推出了其Cheetah(捷豹)系列磁盘，这是首个采用10000r/min转速马达的磁盘。1997：IBM宣布推出了首个采用巨磁阻磁头(GMR)的磁盘——Deskstar16GPTitan，在三个直径为3.5英寸的盘片上可装配16.8GB的存储容量。1998：IBM宣布推出了Microdrive(微磁盘)，这是当时世界上最小的磁盘，一个单一的1英寸盘片的容量可达340MB。2000：Maxtor(迈拓)成功收购了其竞争对手Quantum的磁盘业务。就当时的情况而言，Quantum是世界上第二大磁盘制造商，仅仅位于希捷技术公司之后。而成功收购了Quantum以后，Maxtor便一举成为世界上最大的磁盘制造商。2000：希捷科技公司发布了首款采用15000r/min转速马达的磁盘——CheetahX15。2002：希捷科技公司在磁盘历史又获得了一个第一的称号，这都是因为它发布了BarracudaATAVSerialATA磁盘。2002：希捷科技公司向外界演示了垂直磁性记录技术，每英寸的密度可达100GB。2002：其实，在2002年有很多技术值得我们去记住，但希捷科技公司成功演示的Heat-AssistedMagneticRecording(热辅助磁记录，HAMR)技术却格外耀眼，HAMR磁性记录技术采用了激光热辅助设计。2003：IBM宣布把其数据存储部门出售给日立，IBM由此也结束了在磁盘领域的辉煌历程。2003：WesternDigital推出了首个10000r/min的SATA磁盘——Raptor(猛禽)，存储容量为37GB。该款产品主要是为企业设计的，但是游戏玩家很快就发现，其实把该磁盘用于双磁盘RAID配置中，使得台式电脑的性能会有很大的提升。2004：东芝宣布推出了世界上首款0.85英寸的磁盘——MK2001MTN，在一个单一的盘片上，存储容量可达2GB。2005：东芝宣布推出了MK4007GAL，该磁盘采用了直径为1.8英寸的盘片设计，存储容量为40GB。同时，MK4007GAL也是首款采用垂直磁性记录设计的磁盘。2006：希捷科技公司成功收购了Maxtor，使得其在磁盘制造工业的竞争对手再度缩小。2006：希捷科技公司宣布推出了Momentus5400.3笔记本电脑磁盘，这是首款采用垂直磁性记录设计的2.5英寸磁盘型号，其存储容量也达到160GB。2006：希捷科技公司发布了当今世界上存储容量最大的磁盘——Barracuda7200.10，存储容量达到了750GB。2006：WesternDigital宣布推出了10000r/minRaptorXSATA磁盘，其存储容量达到了150GB。不仅如此，RaptorX还采用了透明的外观设计，用户可以看到它运作时内部的情况。2006：Cornice和希捷技术这两家公司都在2006年宣布推出了1英寸磁盘，存储容量为12GB。磁盘结构播报编辑盘片一个磁盘（如一个1T的机械硬盘）由多个盘片叠加而成。盘片的表面涂有磁性物质，这些磁性物质用来记录二进制数据。因为正反两面都可涂上磁性物质，故一个盘片可能会有两个盘面。磁道、扇区每个盘片被划分为一个个磁道，每个磁道又划分为一个个扇区。其中，最内侧磁道上的扇区面积最小，因此数据密度最大。柱面每个盘面对应一个磁头。所有的磁头都是连在同一个磁臂上的，因此所有磁头只能“共进退”。所有盘面中相对位置相同的磁道组成柱面。技术指标播报编辑磁盘存储器的主要技术指标存储密度、存储容量、存取时间及数据传输率。存储密度分为道密度、位密度和面密度。道密度是沿磁盘半径方向单位长度上的磁道数，单位为道/英寸。位密度是磁道单位长度上能记录的二进制代码位数，单位为位/英寸。面密度是位密度和道密度的乘积，单位为位/平方英寸。存储容量一个磁盘存储器所能存储的字节总数。存取时间存取时间由三种时间构成：寻道时间、等待时间、数据传送时间。寻道时间磁盘定位到指定磁道上所需要的时间等待时间寻道完成后至磁道上需要访问的信息到达磁头下的时间数据传送时间传送数据所需要的时间数据传输率磁盘存储器在单位时间内向主机传送数据的字节数闪存：概念播报编辑运用闪存的数码产品闪存是一种非易失性存储器，即断电数据也不会丢失。因为闪存不像RAM（随机存取存储器）一样以字节为单位改写数据，因此不能取代RAM。闪存卡（FlashCard）是利用闪存（FlashMemory）技术达到存储电子信息的存储器，一般应用在数码相机，掌上电脑，MP3等小型数码产品中作为存储介质，所以样子小巧，有如一张卡片，所以称之为闪存卡。根据不同的生产厂商和不同的应用，闪存卡大概有SmartMedia（SM卡）、CompactFlash（CF卡）、MultiMediaCard（MMC卡）、SecureDigital（SD卡）、MemoryStick（记忆棒）、XD-PictureCard（XD卡）和微硬盘（MICRODRIVE）这些闪存卡虽然外观、规格不同，但是技术原理都是相同的。技术特点播报编辑单片机闪存NOR型与NAND型闪存的区别很大，打个比方说，NOR型闪存更像内存，有独立的地址线和数据线，但价格比较贵，容量比较小；而NAND型更像硬盘，地址线和数据线是共用的I/O线，类似硬盘的所有信息都通过一条硬盘线传送一般，而且NAND型与NOR型闪存相比，成本要低一些，而容量大得多。因此，NOR型闪存比较适合频繁随机读写的场合，通常用于存储程序代码并直接在闪存内运行，手机就是使用NOR型闪存的大户，所以手机的“内存”容量通常不大；NAND型闪存主要用来存储资料，我们常用的闪存产品，如闪存盘、数码存储卡都是用NAND型闪存。这里我们还需要端正一个概念，那就是闪存的速度其实很有限，它本身操作速度、频率就比内存低得多，而且NAND型闪存类似硬盘的操作方式效率也比内存的直接访问方式慢得多。因此，不要以为闪存盘的性能瓶颈是在接口，甚至想当然地认为闪存盘采用USB2.0接口之后会获得巨大的性能提升。前面提到NAND型闪存的操作方式效率低，这和它的架构设计和接口设计有关，它操作起来确实挺像硬盘（其实NAND型闪存在设计之初确实考虑了与硬盘的兼容性），它的性能特点也很像硬盘：小数据块操作速度很慢，而大数据块速度就很快，这种差异远比其他存储介质大的多。这种性能特点非常值得我们留意。闪存存取比较快速，无噪音，散热小。用户空间容量需求量小的，打算购置的话可以不考虑太多，同样存储空间买闪存。如果需要容量空间大的（如500G），就买硬盘，较为便宜，也可以满足用户应用的需求。分类播报编辑按种类分U盘、CF卡、SM卡、SD/MMC卡、记忆棒、XD卡、MS卡、TF卡、PCIe闪存卡按品牌分矽统（SIS）、金士顿、索尼、LSI、闪迪、Kingmax、鹰泰、创见、爱国者、纽曼、威刚、联想、台电、微星、SSK、三星、海力士Sandisk【NAND型闪存】内存和NOR型闪存的基本存储单元是bit，用户可以随机访问任何一个bit的信息。而NAND型闪存的基本存储单元是页（Page）（可以看到，NAND型闪存的页就类似硬盘的扇区，硬盘的一个扇区也为512字节）。每一页的有效容量是512字节的倍数。所谓的有效容量是指用于数据存储的部分，实际上还要加上16字节的校验信息，因此我们可以在闪存厂商的技术资料当中看到“（512+16）Byte”的表示方式。2Gb以下容量的NAND型闪存绝大多数是（512+16）字节的页面容量，2Gb以上容量的NAND型闪存则将页容量扩大到（2048+64）字节。NAND型闪存以块（sector）为单位进行擦除操作。闪存的写入操作必须在空白区域进行，如果目标区域已经有数据，必须先擦除后写入，因此擦除操作是闪存的基本操作。一般每个块包含32个512字节的页（page），容量16KB；而大容量闪存采用2KB页时，则每个块包含64个页，容量128KB。每颗NAND型闪存的I/O接口一般是8条，每条数据线每次传输（512+16）bit信息，8条就是（512+16）×8bit，也就是前面说的512字节。但较大容量的NAND型闪存也越来越多地采用16条I/O线的设计，如三星编号K9K1G16U0A的芯片就是64M×16bit的NAND型闪存，容量1Gb，基本数据单位是（256+8）×16bit，还是512字节。寻址时，NAND型闪存通过8条I/O接口数据线传输地址信息包，每包传送8位地址信息。由于闪存芯片容量比较大，一组8位地址只够寻址256个页，显然是不够的，因此通常一次地址传送需要分若干组，占用若干个时钟周期。NAND的地址信息包括列地址（页面中的起始操作地址）、块地址和相应的页面地址，传送时分别分组，至少需要三次，占用三个周期。随着容量的增大，地址信息会更多，需要占用更多的时钟周期传输，因此NAND型闪存的一个重要特点就是容量越大，寻址时间越长。而且，由于传送地址周期比其他存储介质长，因此NAND型闪存比其他存储介质更不适合大量的小容量读写请求。闪存[1]而比我们平常用的U盘存储量更大，速度更快的闪存产品要属PCIe闪存卡了，它采用低功耗，高性能的闪存存储芯片，以提高应用程序性能。由于它们直接插到服务器中，数据位置接近服务器的处理器，相比其它通过基于磁盘的存储网络路径来获取信息大大节省了时间。企业正在转向这种技术以解决存储密集型工作负载，比如事务处理应用。在PCIe闪存卡方面，LSI公司新的Nytro产品，扩大其基于闪存的应用加速技术到各种规模的企业。LSI推出了三款产品，到一个正变得越来越拥挤的PCIe闪存适配器卡市场。LSINytro产品战略中的一部分，LSI公司的WarpDrive卡上，采用闪存存储、LSI的SAS集成控制器和来自公司收购的闪存控制器制造商SandForce的技术。其第二代基于PCIe的应用加速卡容量从200GB到3.2TB不等。NytroXD应用加速存储解决方案的软件和硬件的组合。它集成了WarpDrive卡与NytroXD智能高速缓存软件，以提高在存储区域网络(SAN)和直接附加存储(DAS)实现中的I/O速度。最后，还有NytroMegaRAID应用加速卡，它结合了MegaRAID控制器与板载闪存和缓存软件，LSI公司将NytroMegaRAID的定位面向低端，针对串行连接SCSI(SAS)DAS环境的性能增强解决方案。微软的SQLServer产品管理主管ClaudeLorenson，看好LSI的闪存产品在微软服务器环境中的未来。因为LSI的闪存产品NytroMegaRAID可以帮助微软SQL实现了每秒交易的10倍增长，[1]“闪存存储技术，如LSI的Nytro应用加速产品组合，可以用来加速关键业务应用，如SQLServer2012”，Lorenson在一份公司的声明中表示“随着微软将在WindowsServer8中提供的增强，这些技术的重要性将继续增长。”存储原理播报编辑要讲解闪存的存储原理，还是要从EPROM和EEPROM说起。EPROM是指其中的内容可以通过特殊手段擦去，然后重新写入。其基本单元电路（存储细胞），常采用浮空栅雪崩注入式MOS电路，简称为FAMOS。它与MOS电路相似，是在N型基片上生长出两个高浓度的P型区，通过欧姆接触分别引出源极S和漏极D。在源极和漏极之间有一个多晶硅栅极浮空在SiO2绝缘层中，与四周无直接电气联接。这种电路以浮空栅极是否带电来表示存1或者0，浮空栅极带电后（譬如负电荷），就在其下面，源极和漏极之间感应出正的导电沟道，使MOS管导通，即表示存入0。若浮空栅极不带电，则不形成导电沟道，MOS管不导通，即存入1。EEPROM基本存储单元电路的工作原理如下图所示。与EPROM相似，它是在EPROM基本单元电路的浮空栅的上面再生成一个浮空栅，前者称为第一级浮空栅，后者称为第二级浮空栅。可给第二级浮空栅引出一个电极，使第二级浮空栅极接某一电压VG。若VG为正电压，第一浮空栅极与漏极之间产生隧道效应，使电子注入第一浮空栅极，即编程写入。若使VG为负电压，强使第一级浮空栅极的电子散失，即擦除。擦除后可重新写入。闪存的基本单元电路，与EEPROM类似，也是由双层浮空栅MOS管组成。但是第一层栅介质很薄，作为隧道氧化层。写入方法与EEPROM相同，在第二级浮空栅加以正电压，使电子进入第一级浮空栅。读出方法与EPROM相同。擦除方法是在源极加正电压利用第一级浮空栅与源极之间的隧道效应，把注入至浮空栅的负电荷吸引到源极。由于利用源极加正电压擦除，因此各单元的源极联在一起，这样，快擦存储器不能按字节擦除，而是全片或分块擦除。到后来，随着半导体技术的改进，闪存也实现了单晶体管（1T）的设计，主要就是在原有的晶体管上加入了浮动栅和选择栅，在源极和漏极之间电流单向传导的半导体上形成贮存电子的浮动棚。浮动栅包裹着一层硅氧化膜绝缘体。它的上面是在源极和漏极之间控制传导电流的选择/控制栅。数据是0或1取决于在硅底板上形成的浮动栅中是否有电子。有电子为0，无电子为1。闪存就如同其名字一样，写入前删除数据进行初始化。具体说就是从所有浮动栅中导出电子。即将有所数据归“1”。写入时只有数据为0时才进行写入，数据为1时则什么也不做。写入0时，向栅电极和漏极施加高电压，增加在源极和漏极之间传导的电子能量。这样一来，电子就会突破氧化膜绝缘体，进入浮动栅。读取数据时，向栅电极施加一定的电压，电流大为1，电流小则定为0。浮动栅没有电子的状态（数据为1）下，在栅电极施加电压的状态时向漏极施加电压，源极和漏极之间由于大量电子的移动，就会产生电流。而在浮动栅有电子的状态（数据为0）下，沟道中传导的电子就会减少。因为施加在栅电极的电压被浮动栅电子吸收后，很难对沟道产生影响。应用前景播报编辑闪存卡“优盘”是闪存走进日常生活的最明显写照，其实早在U盘之前，闪存已经出现在许多电子产品之中。传统的存储数据方式是采用RAM的易失存储，电池没电了数据就会丢失。采用闪存的产品，克服了这一毛病，使得数据存储更为可靠。除了闪存盘，闪存还被应用在计算机中的BIOS、PDA、数码相机、录音笔、手机、数字电视、游戏机等电子产品中。追溯到1998年，优盘进入市场。接口由USB1.0发展到2.0再到最新的USB3.0，速度逐渐提高。U盘的盛行还间接促进了USB接口的推广。为什么U盘这么受到人们欢迎呢？闪存盘可用来在电脑之间交换数据。从容量上讲，闪存盘的容量从16MB到64GB可选，突破了软驱1.44MB的局限性。从读写速度上讲，闪存盘采用USB接口，读写速度比软盘高许多。从稳定性上讲，闪存盘没有机械读写装置，避免了移动硬盘容易碰伤、跌落等原因造成的损坏。部分款式闪存盘具有加密等功能，令用户使用更具个性化。闪存盘外形小巧，更易于携带。且采用支持热插拔的USB接口，使用非常方便。闪存正朝大容量、低功耗、低成本的方向发展。与传统硬盘相比，闪存的读写速度高、功耗较低，市场上已经出现了闪存硬盘，也就是SSD硬盘，该硬盘的性价比进一步提升。随着制造工艺的提高、成本的降低，闪存将更多地出现在日常生活之中。决定因素播报编辑页数量前面已经提到，越大容量闪存的页越多、页越大，寻址时间越长。但这个时间的延长不是线性关系，而是一个一个的台阶变化的。譬如128、256Mb的芯片需要3个周期传送地址信号，512Mb、1Gb的需要4个周期，而2、4Gb的需要5个周期。页容量每一页的容量决定了一次可以传输的数据量，因此大容量的页有更好的性能。前面提到大容量闪存（4Gb）提高了页的容量，从512字节提高到2KB。页容量的提高不但易于提高容量，更可以提高传输性能。我们可以举例子说明。以三星K9K1G08U0M和K9K4G08U0M为例，前者为1Gb，512字节页容量，随机读（稳定）时间12μs，写时间为200μs；后者为4Gb，2KB页容量，随机读（稳定）时间25μs，写时间为300μs。假设它们工作在20MHz。读取性能NAND型闪存的读取步骤分为：发送命令和寻址信息→将数据传向页面寄存器（随机读稳定时间）→数据传出（每周期8bit，需要传送512+16或2K+64次）。K9K1G08U0M读一个页需要：5个命令、寻址周期×50ns+12μs+（512+16）×50ns=38.7μs；K9K1G08U0M实际读传输率：512字节÷38.7μs=13.2MB/s；K9K4G08U0M读一个页需要：6个命令、寻址周期×50ns+25μs+（2K+64）×50ns=131.1μs；K9K4G08U0M实际读传输率：2KB字节÷131.1μs=15.6MB/s。因此，采用2KB页容量比512字节页容量约提高读性能20%。写入性能NAND型闪存的写步骤分为：发送寻址信息→将数据传向页面寄存器→发送命令信息→数据从寄存器写入页面。其中命令周期也是一个，我们下面将其和寻址周期合并，但这两个部分并非连续的。K9K1G08U0M写一个页需要：5个命令、寻址周期×50ns+（512+16）×50ns+200μs=226.7μs。K9K1G08U0M实际写传输率：512字节÷226.7μs=2.2MB/s。K9K4G08U0M写一个页需要：6个命令、寻址周期×50ns+（2K+64）×50ns+300μs=405.9μs。K9K4G08U0M实际写传输率：2112字节/405.9μs=5MB/s。因此，采用2KB页容量比512字节页容量提高写性能两倍以上。块容量块是擦除操作的基本单位，由于每个块的擦除时间几乎相同（擦除操作一般需要2ms，而之前若干周期的命令和地址信息占用的时间可以忽略不计），块的容量将直接决定擦除性能。大容量NAND型闪存的页容量提高，而每个块的页数量也有所提高，一般4Gb芯片的块容量为2KB×64个页=128KB，1Gb芯片的为512字节×32个页=16KB。可以看出，在相同时间之内，前者的擦速度为后者8倍！I/O位宽8gbit闪存以往NAND型闪存的数据线一般为8条，不过从256Mb产品开始，就有16条数据线的产品出现了。但由于控制器等方面的原因，x16芯片实际应用的相对比较少，但将来数量上还是会呈上升趋势的。虽然x16的芯片在传送数据和地址信息时仍采用8位一组，占用的周期也不变，但传送数据时就以16位为一组，带宽增加一倍。K9K4G16U0M就是典型的64M×16芯片，它每页仍为2KB，但结构为（1K+32）×16bit。模仿上面的计算，我们得到如下。K9K4G16U0M读一个页需要：6个命令、寻址周期×50ns+25μs+（1K+32）×50ns=78.1μs。K9K4G16U0M实际读传输率：2KB字节÷78.1μs=26.2MB/s。K9K4G16U0M写一个页需要：6个命令、寻址周期×50ns+（1K+32）×50ns+300μs=353.1μs。K9K4G16U0M实际写传输率：2KB字节÷353.1μs=5.8MB/s可以看到，相同容量的芯片，将数据线增加到16条后，读性能提高近70%，写性能也提高16%。频率工作频率的影响很容易理解。NAND型闪存的工作频率在20～33MHz，频率越高性能越好。前面以K9K4G08U0M为例时，我们假设频率为20MHz，如果我们将频率提高一倍，达到40MHz，则K9K4G08U0M读一个页需要：6个命令、寻址周期×25ns+25μs+（2K+64）×25ns=78μs。K9K4G08U0M实际读传输率：2KB字节÷78μs=26.3MB/s。可以看到，如果K9K4G08U0M的工作频率从20MHz提高到40MHz，读性能可以提高近70%！当然，上面的例子只是为了方便计算而已。在三星实际的产品线中，可工作在较高频率下的应是K9XXG08UXM，而不是K9XXG08U0M，前者的频率可达33MHz。制造工艺制造工艺可以影响晶体管的密度，也对一些操作的时间有影响。譬如前面提到的写稳定和读稳定时间，它们在我们的计算当中占去了时间的重要部分，尤其是写入时。如果能够降低这些时间，就可以进一步提高性能。90nm的制造工艺能够改进性能吗？答案恐怕是否！实际情况是，随着存储密度的提高，需要的读、写稳定时间是呈现上升趋势的。前面的计算所举的例子中就体现了这种趋势，否则4Gb芯片的性能提升更加明显。综合来看，大容量的NAND型闪存芯片虽然寻址、操作时间会略长，但随着页容量的提高，有效传输率还是会大一些，大容量的芯片符合市场对容量、成本和性能的需求趋势。而增加数据线和提高频率，则是提高性能的最有效途径，但由于命令、地址信息占用操作周期，以及一些固定操作时间（如信号稳定时间等）等工艺、物理因素的影响，它们不会带来同比的性能提升。1Page=（2K+64）Bytes；1Block=（2K+64）B×64Pages=（128K+4K）Bytes；1Device=（2K+64）B×64Pages×4096Blocks=4224Mbits其中：A0～11对页内进行寻址，可以被理解为“列地址”。A12～29对页进行寻址，可以被理解为“行地址”。为了方便，“列地址”和“行地址”分为两组传输，而不是将它们直接组合起来一个大组。因此每组在最后一个周期会有若干数据线无信息传输。没有利用的数据线保持低电平。NAND型闪存所谓的“行地址”和“列地址”不是我们在DRAM、SRAM中所熟悉的定义，只是一种相对方便的表达方式而已。为了便于理解，我们可以将上面三维的NAND型闪存芯片架构图在垂直方向做一个剖面，在这个剖面中套用二维的“行”、“列”概念就比较直观了。发展过程播报编辑发展历史在1984年，东芝公司的发明人舛冈富士雄首先提出了快速闪存存储器（此处简称闪存）的概念。与传统电脑内存不同，闪存的特点是非易失性（也就是所存储的数据在主机掉电后不会丢失），其记录速度也非常快。Intel是世界上第一个生产闪存并将其投放市场的公司。1988年，公司推出了一款256Kbit闪存芯片。它如同鞋盒一样大小，并被内嵌于一个录音机里。後来，Intel发明的这类闪存被统称为NOR闪存。它结合EPROM（可擦除可编程只读存储器）和EEPROM（电可擦除可编程只读存储器）两项技术，并拥有一个SRAM接口。第二种闪存称为NAND闪存。它由日立公司于1989年研制，并被认为是NOR闪存的理想替代者。NAND闪存的写周期比NOR闪存短90%，它的保存与删除处理的速度也相对较快。NAND的存储单元只有NOR的一半，在更小的存储空间中NAND获得了更好的性能。鉴于NAND出色的表现，它常常被应用于诸如CompactFlash、SmartMedia、SD、MMC、xD、andPCcards、USBsticks等存储卡上。2021年，第三届中国西部国际投资贸易洽谈会上，长江存储带来128层QLC规格的3DNAND闪存，是业内首款128层QLC3DNAND闪存，拥有业内已知型号产品中最高单位面积存储密度，最高I/O传输速度和最高单颗NAND闪存芯片容量。[2]市场分析闪存市场仍属于群雄争霸的未成熟时期。三星、日立、Spansion和Intel是这个市场的四大生产商。由于战略上的一些错误，Intel在第一次让出了它的榜首座椅，下落至三星、日立和Spansion之後。AMD闪存业务部门Spansion同时生产NAND和NOR闪存。它上半年的NOR闪存产量几乎与Intel持平，成为NOR闪存的最大制造商。该公司在上半年赢利为13亿美元，几乎是它整个公司利润额（25亿美元）的一半以上。总体而言，Intel和AMD在上半年成绩喜人，但三星和日立却遭受挫折。替代品与许多寿命短小的信息技术相比，闪存以其多年的发展历程，充分显示了其“老前辈”的作风。九十年代初，闪存才初入市场；至2000年，利益额已突破十亿美元。英飞凌科技闪存部门主任，彼得曾说：“就闪存的生命周期而言，我们仍处于一个上升的阶段。”英飞凌相信，闪存的销售仍具有上升空间，并在酝酿加入对该市场的投入。英飞凌宣布，其位于德累斯顿的200毫米DRAM工厂已经开始生产512MbNAND兼容闪存芯片。到2004年底，英飞凌公司计划采用170纳米制造工艺，每月制造超过10,000片晶圆。而2007年，该公司更希望在NAND市场成为前三甲。尽管对闪存替代品的讨论越来越激励，闪存仍然受到市场的重视。未来的替代品不仅必须是类似闪存一样的非易失性存储器，而且在速度和写周期上略胜一筹。此外，生产成本也应该相对低廉。由于制造技术还不成熟，新的替代品不会对闪存构成绝对的威胁。与硬盘比播报编辑如果单从储存介质上来说，闪存比硬盘好。这是指数据传输的速度还有抗震度来说（闪存不存在抗震）。优点：1．闪存的体积小。并不是说闪存的集成度就一定会高。微硬盘做的这么大一块主要原因就是微硬盘不能做的小过闪存，并不代表微硬盘的集成度就不高。2．相对于硬盘来说闪存结构不怕震，更抗摔。硬盘最怕的就是强烈震动。虽然我们使用的时候可以很小心，但老虎也有打盹的时候，不怕一万就怕万一。3．闪存可以提供更快的数据读取速度，硬盘则受到转速的限制。4．闪存存储数据更加安全，原因包括：1.其非机械结构，因此移动并不会对它的读写产生影响；2.广泛应用的机械型硬盘的使用寿命与读写次数和读写速度关系非常大，而闪存受影响不大；3.硬盘的写入是靠磁性来写入，闪存则采用电压，数据不会因为时间而消除。5．质量更轻。缺点：1、材料贵，所以单位容量更贵。2、读写速度相对较慢。问题解决播报编辑1.什么是usb2.0usb2.0是usb技术的新版本。传输速率高达480mbps，是usb1.1的40倍。适合新型高速外设。它继承了usb1.1的易用性，即插即用、免安装驱动，完全兼容usb1.1标准，您已经购买的usb1.1设备和连接线仍然可以继续使用。2.关于USB要知道：USB1.1的闪存盘读速一般为630KB，写速一般为520KB；USB2.0的读速一般为1.5MB，写速一般为1.0MBusb2.0设备接在usb1.1接口上，但受usb1.1的速度限制发挥不了USB2.0效果。同时使用usb2.0和usb1.1设备，在os9.x系统中使用usb2.0设备可以，但必须安装驱动程序；但是这些操作系统并不支持usb2.0，该设备在这些系统中只能工作在usb1.1模式6.读写闪存盘时，是否可以运行其它应用程序？可以。7.闪存盘可擦写多少次？闪存盘里的数据能保存多久？闪存盘可擦写1000000次，闪存盘里数据可保存10年8.一台电脑可同时接几个闪存盘？理论上一台电脑可同时接127个闪存盘，但由于驱动器英文字母的排序原因以及现有的驱动器需占用几个英文字母，故闪存盘最多只可以接23个（除开A、B、C)且需要USBHUB的协助。9.闪存盘在DOS状态下能否使用闪存盘支持WINDOWS虚拟DOS方式（启动Windows后在附件中进入）。10.闪存盘支持WINDOWS95吗闪存盘不支持WINDOWS95操作系统，建议用户升级操作系统至WINDOWS98或以上版本。11.WINDOWSNT4.0下闪存盘如何使用12.闪存盘可以在什么驱动程序下使用？A9Windows98、WindowsME、Windows2000、WindowsXP、Windows7、Windows8、Windows8.1、MACOS、Linux。13.闪存盘是否需要驱动程序？在MacOS、Windows2000以上版本上不需要，在Win98上需要驱动程序14.闪存盘可以在Windows98/Windows2000/MacOS下被格式化吗可以。15.闪存盘的内容能否加密？可以。16.闪存盘在局域网里是否可以共享？可以。17.闪存盘可以存储哪些类型的数据？所有电脑数据都可以存储，包括文件、程序、图象、音乐、多媒体等。18.安装闪存盘时是否需要关闭电脑？不需要，闪存盘是即插即用型产品，可以进行插拔。19.闪存盘可以防水吗？闪存盘是电子类产品，掉入水中后可能会造成闪存盘内部短路而损坏。20.插拔闪存盘时，有哪些注意事项当闪存盘指示灯快闪时，即电脑在读写闪存盘状态下，不要拔下闪存盘；当插入闪存盘后，最好不要立即拔出。特别是不要反复快速插拔，因为操作系统需要一定的反应时间，中间的间隔最好在5秒以上。21.闪存盘是否会感染病毒？闪存盘像所有硬盘一样可能感染病毒22.闪存盘用于桌面电脑时，并且USB接口在电脑的后面时，有什么办法使之更方便？通过一条USB转接电缆（具有A-TypePlugandA-TypeReceptacle）与电脑连接23.存盘的LED灯显示表示什么含义？当LED灯亮的时候，它表示闪存盘连接成功暂时没有数据传输。当LED闪烁的时候，它表示闪存盘正在数据传输过程中。24.当闪存盘的LED还在闪时，是否可以拔出闪存盘？不可以。会使闪存盘的数据丢失或使FAT表破坏且出现蓝屏。当操作系统读闪存盘时它会使电脑出现蓝屏。25.闪存盘上的文件出现乱码或文件打不开使用闪存盘专用工具做格式化26.双击闪存盘盘符时，电脑提示闪存盘需格式化当闪存盘分区表遭到破坏或是闪存盘性能不稳定时，会出现上述现象。出现这种问题，一般可以使用闪存盘专用工具做格式化27.闪存盘写保护不起作用，在写保护关锁状态，数据也能够顺利写入。28.切换闪存写保护开关，需要在断开与电脑的联接的状态下进行。如果是在与电脑联接状态下切换了写保护开关，需要重新插拔一次闪存，才能切实使切换起作用。磁荷随机存储器两家公司都认为，MRAM不仅将是闪存的理想替代品，也是DRAM与SRAM的强有力竞争者。今年六月，英飞凌已将自己的第一款产品投放市场。与此同时，Freescale也正在加紧研发，力争推出4Mbit芯片。但是，一些评论者担心MRAM是否能达到闪存存储单元的尺寸。根据英飞凌的报告，闪存存储单元的尺寸为0.1&micro;m²，而16MbitMRAM芯片仅达到1.42&micro;m²。另外，MRAM的生产成本也是个不小的问题。OUMOUM（OvonicUnifiedMemoryOvonyx标准化内存）OUM是由Intel研发的，利用Ge、Sb与Te等化合物为材料制成的薄膜。OUM。OUM的写、删除和读的功能与CD-RW与DVD-RW相似。但CD/DVD使用激光来加热和改变称为硫系化合物（chalcogenides）的材料；而OUM则通过电晶体控制电源，使其产生相变方式来储存资料。OUM的擦写次数为10的12次方，100次数据访问时间平均为200纳秒。OUM的速度比闪存要快。尽管OUM比MRAM的数据访问时间要慢，但是低廉的成本却是OUM的致胜法宝。与MRAM不同，OUM的发展仍处于初期。尽管已制成测试芯片，它们仅仅能用来确认概念而不是说明该技术的可行性。Intel在过去四年一直致力于OUM的研发，并正在努力扩大该市场。闪存式U盘总结除了上文提到的MRAM和OUM，其它可替代的产品还有MRAM（FeRAM）、Polymermemory（PFRAM）、PCRAM、ConductiveBridgeRAM（CBRAM）、OrganicRAM（ORAM）以及最近的NanotubeRAM（NRAM）。替代闪存的产品有许多，但是哪条路能够成功，以及何时成功仍然值得怀疑。对大多数公司而言，闪存仍是一个理想的投资。不少公司已决定加大对闪存的投资额。此外，据估计，到2004年，闪存总产值将与DRAM并驾齐驱，到2006年将超越DRAM产品。DRAM：简介播报编辑动态随机存取存储器（DynamicRandomAccessMemory，DRAM）是一种半导体存储器，主要的作用原理是利用电容内存储电荷的多寡来代表一个二进制比特（bit）是1还是0。由于在现实中晶体管会有漏电电流的现象，导致电容上所存储的电荷数量并不足以正确的判别数据，而导致数据毁损。因此对于DRAM来说，周期性地充电是一个无可避免的要件。由于这种需要定时刷新的特性，因此被称为“动态”存储器。相对来说，静态存储器（SRAM）只要存入数据后，纵使不刷新也不会丢失记忆。与SRAM相比，DRAM的优势在于结构简单——每一个比特的数据都只需一个电容跟一个晶体管来处理，相比之下在SRAM上一个比特通常需要六个晶体管。正因这缘故，DRAM拥有非常高的密度，单位体积的容量较高因此成本较低。但相反的，DRAM也有访问速度较慢，耗电量较大的缺点。与大部分的随机存取存储器（RAM）一样，由于存在DRAM中的数据会在电力切断以后很快消失，因此它属于一种易失性存储器（volatilememory）设备。[1]工作原理播报编辑DRAM通常以一个电容和一个晶体管为一个单元排成二维矩阵。基本的操作机制分为读(Read)和写(Write)，读的时候先让Bitline(BL)先充电到操作电压的一半，然后再把晶体管打开让BL和电容产生电荷共享的现象，若内部存储的值为1，则BL的电压会被电荷共享抬高到高于操作电压的一半，反之，若内部存储的值为0，则会把BL的电压拉低到低于操作电压的一半，得到了BL的电压后，在经过放大器来判别出内部的值为0和1。写的时候会把晶体管打开，若要写1时则把BL电压抬高到操作电压使电容上存储著操作电压，若要写0时则把BL降低到0伏特使电容内部没有电荷。[1]随机存取存储器播报编辑随机存取存储器（英语：RandomAccessMemory，缩写：RAM），也叫主存，是与CPU直接交换数据的内部存储器。它可以随时读写（刷新时除外，见下文），而且速度很快，通常作为操作系统或其他正在运行中的程序的临时数据存储媒介。主存（Mainmemory）即电脑内部最主要的存储器，用来加载各式各样的程序与数据以供CPU直接运行与运用。由于DRAM的性价比很高，且扩展性也不错，是现今一般电脑主存的最主要部分。2014年生产电脑所用的主存主要是DDR3SDRAM，而2016年开始DDR4SDRAM逐渐普及化，笔电厂商如华硕及宏碁开始在笔电以DDR4存储器取代DDR3L。[1]相关条目播报编辑存储器挥发性记忆体静态随机存取存储器动态随机存储器价格操纵SDRAM硬件：基本部件播报编辑运算器，控制器，存储器联系计算机由运算器、控制器、存储器、输入设备和输出设备等五个逻辑部件组成运算器硬件(13张)运算器由算术逻辑单元（ALU）、累加器、状态寄存器、通用寄存器组等组成。算术逻辑运算单元（ALU）的基本功能为加、减、乘、除四则运算，与、或、非、异或等逻辑操作，以及移位、求补等操作。控制器控制器（ControlUnit），是整个计算机系统的控制中心，它指挥计算机各部分协调地工作，保证计算机按照预先规定的目标和步骤有条不紊地进行操作及处理。控制器从存储器中逐条取出指令，分析每条指令规定的是什么操作以及所需数据的存放位置等，然后根据分析的结果向计算机其它部件发出控制信号，统一指挥整个计算机完成指令所规定的操作。中央处理器中央处理器（CentralProcessingUnit，CPU），由运算器和控制器组成，是任何计算机系统中必备的核心部件。CPU由运算器和控制器组成，分别由运算电路和控制电路实现。存储器存储器（Memory）是计算机系统中的记忆设备，用来存放程序和数据。计算机中全部信息，包括输入的原始数据、计算机程序、中间运行结果和最终运行结果都保存在存储器中。它根据控制器指定的位置存入和取出信息。有了存储器，计算机才有记忆功能，才能保证正常工作。输入部件向计算机输入数据和信息的设备。是计算机与用户或其他设备通信的桥梁。输入设备是用户和计算机系统之间进行信息交换的主要装置之一。输出设备输出设备（OutputDevice）是计算机的终端设备，用于接收计算机数据的输出显示、打印、声音、控制外围设备操作等。也是把各种计算结果数据或信息以数字、字符、图像、声音等形式表示出来。计算机部件表格计算机基本部件输入设备键盘鼠标扫描仪数码绘图板触摸板轨迹球麦克风摄像头输出设备显示器音箱打印机耳机扬声器投影仪存储设备固态硬盘移动硬盘CDDVD软盘闪存磁带机机箱内的设备中央处理器随机存取存储器显示卡声卡主板电源供应器硬盘接口串行端口并行端口USBFirewirePS/2RJ-45VGADVITRSS/PDIFHDMI关系表播报编辑输入键盘鼠标触摸板轨迹球数字化输入板及输入笔/指向器触控屏幕游戏控制器游戏控制杆麦克风扫描仪条码阅读机摄像头数码相机存储设备可携存储设备CD、CD-ROM、CD-RW、CD-RDVD、DVD/CD-RWCombo、DVD-ROM、DVD-RW、DVD-R、DVD-RAM、DVD+RW、DVD+R软盘磁带机移动硬盘闪存快闪碟存储卡SD、CF、MMC、SM内置存储器硬盘固态硬盘磁盘阵列控制器微操作：历史背景播报编辑在即时战略游戏流行之初，并没有微操的概念。在红色警戒时代，玩家们通常更关注如何制造更多的作战单位来取得游戏的胜利。但是随着玩家对游戏熟悉度的增加，有越来越多的人发现，在局部战场上，若是对单位进行适当的操作控制，就能大大优化其作战效率，甚至能达到以少胜多的巨大效果。这是由于游戏设计AI总以某个特定规则进行动作，而事实上，这些规则并不是最优的。例如AI通常会做出类似判断：对一个目标一直攻击直至其消灭，若是目标脱出攻击范围则查找范围内有无其他攻击目标，有则对其攻击直至消灭……而此时第一个目标若是重新回到攻击范围内，AI也会无视它，继续攻击第二个目标。在这个规则下，由AI控制的四个单位分两队厮杀的结果是同归于尽。但是若有一方人为的控制单位，使其分摊伤害，就能够达成2:0的结果。发展播报编辑当游戏平衡性更佳的星际争霸流行之后，微操作的意义变得越来越大。而在职业电子竞技选手之间，微操作能力也成了评价其水准的重要指标。由于微操在局部战场的对抗上能产生巨大影响，双方选手互相施展全力进行操作，这让比赛的观赏性大大提高！一些精妙的操作更被爱好者们津津乐道，微操也成了比赛重要的看点之一。随着魔兽争霸Ⅲ的推出，游戏单位数量的减少也意味着微操作的重要度更高。同时，也有了一群以注重极限优化的微操作来获取比赛胜利的玩家流派出现，既“操作流”，亦会被戏谑为“抽筋流”。APM播报编辑ActionPerMinute的缩写，是由软件统计出操作者每分钟各种操作数的数据，从某种程度上能反映玩家的微操作水平。一个职业玩家的APM通常在200以上，甚至超过300。由于APM统计的是所有操作数，并不能表现出操作的有效性，所以仅仅靠APM来说明微操作水平是片面的。围杀播报编辑用己方若干单位（通常是四个以上，若是利用地形的话可以更少）围住并杀死敌方单位，在魔兽争霸中由于单位数量的减少，每个单位的价值也大大提高，这也使得围杀敌方单位有了更大的意义，而且被围杀的单位若是一个具有重大战略意义的英雄的话，这几乎可以左右胜负了。卡位播报编辑在魔兽争霸以及各种即时战略游戏中，由于英雄和小兵都有碰撞体积，而利用自己挡住对方（比如他要追杀你同伴的时候，或者被追杀的时候）叫做卡位。或者是利用视野的盲角，让对方找不到自己，叫做走位。引申义播报编辑不管多么中性含义的词，也有人能听出邪恶的内涵。因此，微操也被极少数人用作人身攻击的词汇。微操（微：精细连贯；操：画面单角色或多角色操作）的含义变成了（微：极短的，不长久的；操：合体）微指令：定义播报编辑微指令是指在机器的一个CPU周期中，一组实现一定操作功能的微命令的组合[1]，描述微操作的语句。微命令是指控制部件通过控制线向执行部件发出各种控制命令。操作微指令是描述受控电路的操作语句,分支微指令是描述控制电路的分支语句。一条机器指令的功能是若干条微指令组成的序列来实现的，即一条机器指令所完成的操作分成若干条微指令来完成，由微指令进行解释和执行，这个微指令序列通常叫做微程序。微指令的编译方法是决定微指令格式的主要因素。考虑到速度，成本等原因，在设计计算机时采用不同的编译法。因此微指令的格式大体分成两类：水平型微指令和垂直型微指令。类型播报编辑水平型微指令一次能定义并执行多个并行操作微命令的微指令，叫做水平型微指令。水平型微指令的一般格式如下：控制字段，判别测试字段和下地址字段。按照控制字段的编码方法不同，水平型微指令又分为三种：一种是全水平型(不译法)微指令，第二种是字段译码法水平型微指令，第三种是直接和译码相混合的水平型微指令。垂直型微指令微指令中设置微操作码字段，采用微操作码编译法，由微操作码规定微指令的功能，称为垂直型微指令。垂直型微指令的结构类似于机器指令的结构.它有操作码，在一条微指令中只有l-2个微操作命令，每条微指令的功能简单，因此，实现一条机器指令的微程序要比水平型微指令编写的微程序长得多.它是采用较长的微程序结构去换取较短的微指令结构。水平型微指令与垂直型微指令的比较(1)水平型微指令并行操作能力强，指令高效，快速，灵活，垂直型微指令则较差。(2)水平型微指令执行一条指令时间短，垂直型微指令执行时间长。(3)由水平型微指令解释指令的微程序，有微指令字较长而微程序短的特点。垂直型微指令则相反。(4)水平型微指令用户难以掌握，而垂直型微指令与指令比较相似，相对来说，比较容易掌握。规范化描述播报编辑规范化描述就是在指令系统的微指令描述中尽量减小语句使用的随意性，使整个指令系统的描述具有较强的规律性，并使微操作集中的元素最少。事实上只要微指令描述合理规范，从微程序设计角度来看，所描述的功能都是可以通过ASIC技术实现的。在一条指令的描述中，指令的微操作步数必须与指令所需的时钟周期数相吻合，分配好各微指令序列所占的时钟数，安排好各微指令组和各微指令序列在整个控制序列中的位置，这是指令系统规范化描述的基础。在同类指令的描述中，完成相同微功能的微指令序列所占的时钟周期数必须相同，在控制序列中的分配位置必须合理。例如字除法指令比字节除法指令多8个状态周期，因此每位除法只能占用一个状态周期。再例如操作数长度相同的有符号数除法指令和无符号数除法指令相比多增加4个状态周期，因此有符号除法中被除数和除数、商和余数的符号化处理，只能分别在2个状态周期中实现，且删除这4个状态周期中的所有微指令[2]。相关指令播报编辑机器指令和微指令的关系一台数字计算机基本上可以划分为两大部分——控制部件和执行部件。控制器就是控制部件，而运算器、存储器、外围设备相对控制器来说就是执行部件。控制部件与执行部件的一种联系就是通过控制线。控制部件通过控制线向执行部件发出各种控制命令，通常这种控制命令叫做微命令，而执行部件接受微命令后所执行的操作就叫做微操作。控制部件与执行部件之间的另一种联系就是反馈信息。执行部件通过反馈线向控制部件反映操作情况，以便使得控制部件根据执行部件的状态来下达新的微命令，这也叫做“状态测试”。微操作在执行部件中是组基本的操作。由于数据通路的结构关系，微操作可分为相容性和相斥性两种。在机器的一个CPU周期中，一组实现一定操作功能的微命令的组合，构成一条微指令。一般的微指令格式由操作控制和顺序控制两部分构成。操作控制部分用来发出管理和指挥全机工作的控制信号。其顺序控制部分用来决定产生下一个微指令的地址。事实上一条机器指令的功能是由许多条微指令组成的序列来实现的。这个微指令序列通常叫做微程序。既然微程序是由微指令组成的，那么当执行当前的一条微指令的时候。必须指出后继微指令的地址，以便当前一条微指令执行完毕以后，取下一条微指令执行。机器指令和微指令的关系归纳如下：1.一条机器指令对应一个微程序，这个微程序是由若干条微指令构成的。因此，一条机器指令的功能是若干条微指令组成的序列来实现的。简而言之，一条机器指令所完成的操作划分成若干条微指令来完成，由微指令进行解释和执行。2.从指令与微指令，程序与微程序，地址与微地址的一一对应关系上看，前者与内存储器有关，而后者与控制存储器（它是微程序控制器的一部分。微程序控制器主要由控制存储器、微指令寄存器和地址转移逻辑三部分组成。其中，微指令寄存器又分为微地址寄存器和微命令寄存器两部分）有关，与此相关也有相对应的硬设备。3.一条机器指令对应4个CPU周期，每个CPU周期就对于一条微指令。微程序：微程序控制器播报编辑微程序控制的提出，其主要目的是希望能实现灵活可变的计算机指令系统。[2]（1）微程序控制[2]微程序控制和组合逻辑控制是微命令产生的两种方式。组合逻辑控制方式采用许多门电路，设计复杂，设计效率低，检查调试困难，而微程序控制器改进了其缺点。微程序控制器的核心部件是微地址转移逻辑。[2]微程序控制器的基本思想包括以下两点：[2]①将控制器所需的微命令以代码形式编成微指令，存入一个由ROM构成的控制存储器（CM）中。[2]②将各种机器指令的操作分解成若干微操作序列。每条微指令包含的微命令控制实现一步操作。若干条微指令组成一小段微程序，解释执行一条机器指令。[2]（2）常见概念及定义[2]①微命令：构成控制信号序列的最小单位。[2]②微操作：由微命令控制实现的最基本的操作。[2]③微周期：从控制存储器读取一条微指令并执行相应的一步操作所需的时间。通常一个时钟周期为一个微周期。[2]④控制存储器（微指令存储器）：主要存放控制命令（信号）和下一条要执行的微指令地址。由于计算机的指令系统是固定的，实现这个指令系统的微程序也是固定的，所以控制存储器采用只读存储器（ROM）。[2]微程序控制器原理播报编辑微程序控制器的基本原理是用多条微指令（Microinstruction）组成的微程序解释执行一条指令的功能，硬件组成的核心电路是“控制存储器”（简称控存，用ROM芯片实现，即固件），用于保存由微指令代码（Microcode）组成的微程序。在指令执行过程中，按照指令及其执行步骤，依次从控制存储器中读出微指令，用微指令控制各执行部件的运行，并用下一地址字段形成下一条微指令的地址，使微指令可以连续运行。[3]硬布线控制器：简介播报编辑硬布线控制器，又称组合逻辑控制器方法原理播报编辑图1一旦控制部件构成后，除非重新设计和物理上对它重新布线，否则要想增加新的控制功能是不可能的。硬布线控制器是计算机中最复杂的逻辑部件之一。当执行不同的机器指令时，通过激活一系列彼此很不相同的控制信号来实现对指令的解释，其结果使得控制器往往很少有明确的结构而变得杂乱无章。结构上的这种缺陷使得硬布线控制器的设计和调试非常复杂且代价很大。正因为如此，硬布线控制器被微程序控制器所取代。但是，在同样的半导体工艺条件下，硬布线控制器速度要比微程序控制的快，随着新一代机器及VLSI技术的发展与不断进步，硬布线的随机逻辑设计思想又得到了重视，现代新型计算机体系结构如RISC中多采用硬布线控制逻辑。硬布线控制器主要由组合逻辑网络、指令寄存器和指令译码器、节拍电位/节拍脉冲发生器等部分组成，硬布线控制器的结构方框图如图1所示。其中组合逻辑网络产生计算机所需的全部操作命令，是控制器的核心。信号来源播报编辑(1)来自指令操作码译码器的输出I1～Im,译码器每根输出线表示一条指令，译码器的输出反映出当前正在执行的指令；(2)来自执行部件的反馈信息B1～Bj；(3)来自时序产生器的时序信号，包括节拍电位信号M1～Mi和节拍脉冲信号T1～Tk。其中节拍电位信号就是机器周期(CPU周期)信号，节拍脉冲信号是时钟周期信号。组合逻辑网络N的输出信号就是微操作控制信号C1～Cn，用来对执行部件进行控制。另有一些信号则根据条件变量来改变时序发生器的计数顺序，以便跳过某些状态，从而可以缩短指令周期。硬布线控制器的基本原理，归纳起来可叙述为：某一微操作控制信号C是指令操作码译码器输出Im、时序信号(节拍电位Mi，节拍脉冲Tk)和状态条件信号Bj的逻辑函数，其数学描述为：C=f(Im，Mi，Tk，Bj)控制信号C是用门电路、触发器等许多器件采用布尔代数方法来设计实现的。当机器加电工作时，某一操作控制信号C在某条特定指令和状态条件下，在某一操作的特定节拍电位和节拍脉冲时间间隔中起作用，从而激活这条控制信号线，对执行部件实施控制。显然，从指令流程图出发，就可以一个不漏地确定在指令周期中各个时刻必须激活的所有操作控制信号。例如，对引起一次主存读操作的控制信号C3来说，当节拍电位M1=1，取指令时被激活；而节拍电位M4=1，三条指令（LDA，ADD，AND）取操作数时也被激活，此时指令译码器的LDA，ADD，AND输出均为1，因此C3的逻辑表达式可由下式确定：C3=M1+M4（LDA+ADD+AND）一般来说，还要考虑节拍脉冲和状态条件的约束，所以每一控制信号C可以由以下形式的布尔代数表达式来确定：Cn=∑(Mi*Tk*Bj*∑Im)与微程序控制相比，硬布线控制的速度较快。其原因是微程序控制中每条微指令都要从控存中读取一次，影响了速度，而硬布线控制主要取决于电路延迟。因此，在某些超高速新型计算机结构中，又选用了硬布线控制器或与微程序控制器混合使用。设计注意播报编辑(1)采用适宜指令格式，合理分配指令操作码；(2)确定机器周期、节拍与主频；(3)确定机器周期数及一周期内的操作；(4)进行指令综合；综合所有指令的每一个操作命令，写出逻辑表达式，并进行化简。(5)明确组合逻辑电路。将简化后的逻辑表达式用组合逻辑电路来实现。操作命令的控制信号先用逻辑表达式列出，进行化简，考虑各种条件的约束，合理选用逻辑门电路、触发器等器件，采用组合逻辑电路的设计方法产生控制信号。总之，控制信号的设计与实现，技巧性较强，一些专门的开发系统或工具供逻辑设计使用，但是，对全局的考虑主要依靠设计人员的智慧和经验实现。比较硬布线控制器与微程序控制器相比较，在操作控制信号的形成上有较大的区别外，其它没有本质的区别。对于实现相同的一条指令，不管是采用硬布线控制还是采用微程序控制技术，都可以采用多种逻辑设计方案，导致了各种不同的控制器在具体实现方法和手段上的区别，性能差异。硬布线控制与微程序控制的主要区别归纳为如下方面：实现方式微程序控制器的控制功能是在存放微程序存储器和存放当前正在执行的微指令的寄存器直接控制下实现的，而硬布线控制的功能则由逻辑门组合实现。微程序控制器的电路比较规整，各条指令信号的差别集中在控制存储器内容上，因此，无论是增加或修改指令都只要增加或修改控制存储器内容即可，若控制存储器是ROM，则要更换芯片，在设计阶段可以先用RAM或EPROM来实现，验证正确后或成批生产时，再用ROM代替。硬布线控制器的控制信号先用逻辑式列出，经化简后用电路来实现，因此，显得零乱复杂，当需要修改指令或增加指令时就必须重新设计电路，非常麻烦而且有时甚至无法改变。因此，微操作控制取代了硬布线控制并得到了广泛应用，尤其是指令复杂的计算机，一般都采用微程序来实现控制功能。性能方面在同样的半导体工艺条件下，微程序控制的速度比硬布线控制的速度低，因为执行每条微程序指令都要从控制存储器中读取，影响了速度；而硬布线控制逻辑主要取决于电路延时，因而在超高速机器中，对影响速度的关键部分如核心部件CPU，往往采用硬布线逻辑实现。在一些新型计算机系统中，例如，RISC(精简指令系统计算机)中，一般都选用硬布线逻辑电路。I/O接口：基本功能播报编辑·进行端口地址译码设备选择。·向CPU提供I/O设备的状态信息和进行命令译码。·进行定时和相应时序控制。·对传送数据提供缓冲，以消除计算机与外设在“定时”或数据处理速度上的差异。·提供计算机与外设间有关信息格式的相容性变换。提供有关电气的适配·还可以中断方式实现CPU与外设之间信息的交换。接口组成播报编辑I/O接口包括硬件电路和软件编程两部分硬件电路包括基本逻辑电路，端口译码电路和供选电路等。软件编程包括初始化程序段，传送方式处理程序段，主控程序段程序终止与退出程序段及辅助程序段等.接口分类播报编辑I/O接口的功能是负责实现CPU通过系统总线把I/O电路和外围设备联系在一起，按照电路和设备的复杂程度，I/O接口的硬件主要分为两大类：（1）I/O接口芯片这些芯片大都是集成电路，通过CPU输入不同的命令和参数，并控制相关的I/O电路和简单的外设作相应的操作，常见的接口芯片如定时/计数器、中断控制器、DMA控制器、并行接口等。（2）I/O接口控制卡有若干个集成电路按一定的逻辑组成为一个部件，或者直接与CPU同在主板上，或是一个插件插在系统总线插槽上。按照接口的连接对象来分，又可以将他们分为串行接口、并行接口、键盘接口和磁盘接口等。接口功能播报编辑由于计算机的外围设备品种繁多，几乎都采用了机电传动设备，因此，CPU在与I/O设备进行数据交换时存在以下问题：速度不匹配：I/O设备的工作速度要比CPU慢许多，而且由于种类的不同，他们之间的速度差异也很大，例如硬盘的传输速度就要比打印机快出很多。时序不匹配：各个I/O设备都有自己的定时控制电路，以自己的速度传输数据，无法与CPU的时序取得统一。信息格式不匹配：不同的I/O设备存储和处理信息的格式不同，例如可以分为串行和并行两种；也可以分为二进制格式、ACSII编码和BCD编码等。信息类型不匹配：不同I/O设备采用的信号类型不同，有些是数字信号，而有些是模拟信号，因此所采用的处理方式也不同。基于以上原因，CPU与外设之间的数据交换必须通过接口来完成，通常接口有以下一些功能：（1）设置数据的寄存、缓冲逻辑，以适应CPU与外设之间的速度差异，接口通常由一些寄存器或RAM芯片组成，如果芯片足够大还可以实现批量数据的传输；（2）能够进行信息格式的转换，例如串行和并行的转换；（3）能够协调CPU和外设两者在信息的类型和电平的差异，如电平转换驱动器、数/模或模/数转换器等；（4）协调时序差异；（5）地址译码和设备选择功能；（6）设置中断和DMA控制逻辑，以保证在中断和DMA允许的情况下产生中断和DMA请求信号，并在接受到中断和DMA应答之后完成中断处理和DMA传输。控制方式播报编辑CPU通过接口对外设进行控制的方式有以下几种：（1）程序查询方式这种方式下，CPU通过I/O指令询问指定外设当前的状态，如果外设准备就绪，则进行数据的输入或输出，否则CPU等待，循环查询。这种方式的优点是结构简单，只需要少量的硬件电路即可，缺点是由于CPU的速度远远高于外设，因此通常处于等待状态，工作效率很低（2）中断处理方式在这种方式下，CPU不再被动等待，而是可以执行其他程序，一旦外设为数据交换准备就绪，可以向CPU提出服务请求，CPU如果响应该请求，便暂时停止当前程序的执行，转去执行与该请求对应的服务程序，完成后，再继续执行原来被中断的程序。中断处理方式的优点是显而易见的，它不但为CPU省去了查询外设状态和等待外设就绪所花费的时间，提高了CPU的工作效率，还满足了外设的实时要求。但需要为每个I/O设备分配一个中断请求号和相应的中断服务程序，此外还需要一个中断控制器（I/O接口芯片）管理I/O设备提出的中断请求，例如设置中断屏蔽、中断请求优先级等。此外，中断处理方式的缺点是每传送一个字符都要进行中断，启动中断控制器，还要保留和恢复现场以便能继续原程序的执行，花费的工作量很大，这样如果需要大量数据交换，系统的性能会很低。（3）DMA（直接存储器存取）传送方式DMA最明显的一个特点是它不是用软件而是采用一个专门的控制器来控制内存与外设之间的数据交流，无须CPU介入，大大提高CPU的工作效率。在进行DMA数据传送之前，DMA控制器会向CPU申请总线控制权，CPU如果允许，则将控制权交出，因此，在数据交换时，总线控制权由DMA控制器掌握，在传输结束后，DMA控制器将总线控制权交还给CPU。（4）无条件传送方式（5）I/O通道方式（6）I/O处理机方式IO：定义播报编辑输入输出I/O流可以看成对字节或者包装后的字节的读取就是拿出来放进去双路切换；实现联动控制系统的弱电线路与被控设备的强电线路之间的转接、隔离，以防止强电窜入系统，保障系统的安全；与专线控制盘连接，用于控制重要消防设备（如消防泵、喷淋泵、风机等），一只模块可控制一台大型消防设备的启、停控制；插拔式结构，可像安装探测器一样先将底座安装在墙上，布线后工程调试前再将切换模块插入底座。易于施工、维护；通过无源动合接点或切换AC220V电压作为回答信号。确认灯动作灯—红色，回答灯—绿色；动作时，动作灯常亮、回答灯常亮。IO输出口可接继电器，继电器接点负载AC250V/3A、DC30V/7A启动为一组常开/常闭触点、停止为一组常开触点。安装与接线播报编辑安装孔距为65mm，用2只M4螺钉或A4自攻钉固定在安装位置。端子1接多线盘启动端；端子2接多线盘停止端；端子3接多线盘回答端；端子4接电源地G；端子5、6为停止命令对应的常开触点输出；端子11、12接220V回答信号；端子13、14为启动命令对应的常开触点输出；端子14、15为启动命令对应的常闭触点输出；触点输出均为无源。端子16接24V电源正极；应用（接专线控制盘）注意事项：可使用AC220V或无源闭合信号作为回答反馈信号。JBF-151F/D只有1个回答输入，它是启动1的回答。JBF-151F/D启动发出后可提供一组常开或常闭触点，停止命令输出时只输出一对常开点。提高缓存播报编辑衡量性能的几个指标的计算中我们可以看到一个15k转速的磁盘在随机读写访问的情况下IOPS竟然只有140左右，但在实际应用中我们却能看到很多标有5000IOPS甚至更高的存储系统，有这么大IOPS的存储系统怎么来的呢?这就要归结于各种存储技术的使用了，在这些存储技术中使用最广的就是高速缓存(Cache)和磁盘冗余阵列(RAID)了，本文就将探讨缓存和磁盘阵列提高存储IO性能的方法。高速缓存播报编辑在当下的各种存储产品中，按照速度从快到慢应该就是内存＞闪存＞磁盘＞磁带了，然而速度越快也就意味着价格越高，闪存虽然说是发展势头很好，磁盘的速度无疑是计算机系统中最大的瓶颈了，所以在必须使用磁盘而又想提高性能的情况下，人们想出了在磁盘中嵌入一块高速的内存用来保存经常访问的数据从而提高读写效率的方法来折中的解决，这块嵌入的内存就被称为高速缓存。说到缓存，到操作系统层，再到磁盘控制器，还有CPU内部，单个磁盘的内部也都存在缓存，所有这些缓存存在的目的都是相同的，就是提高系统执行的效率。当然在这里我们只提跟IO性能相关的缓存，与IO性能直接相关的几个缓存分别是文件系统缓存(FileSySTemCache)、磁盘控制器缓存(DiskCONtrollerCache)和磁盘缓存(DiskCache,也称为DiskBuffer)，不过当在计算一个磁盘系统性能的时候文件系统缓存也是不会考虑在内的，我们重点考察的就是磁盘控制器缓存和磁盘缓存。不管是控制器缓存还是磁盘缓存，他们所起的作用主要是分为三部分：缓存数据、预读(Read-ahead)和回写(Write-back)。缓存数据首先是系统读取过的数据会被缓存在高速缓存中，这样下次再次需要读取相同的数据的时候就不用再访问磁盘，直接从缓存中取数据就可以了。当然，使用过的数据也不可能在缓存中永久保留的，缓存的数据一般是采取LRU算法来进行管理，目的是将长时间不用的数据清除出缓存，那些经常被访问的却能一直保留在缓存中，直到缓存被清空。预读预读是指采用预读算法在没有系统的IO请求的时候事先将数据从磁盘中读入到缓存中，然后在系统发出读IO请求的时候，就会实现去检查看看缓存里面是否存在要读取的数据，如果存在(即命中)的话就直接将结果返回，这时候的磁盘不再需要寻址、旋转等待、读取数据这一序列的操作了，这样是能节省很多时间的;如果没有命中则再发出真正的读取磁盘的命令去取所需要的数据。缓存的命中率跟缓存的大小有很大的关系，理论上是缓存越大的话，所能缓存的数据也就越多，这样命中率也自然越高，当然缓存不可能太大，毕竟成本在那儿呢。如果一个容量很大的存储系统配备了一个很小的读缓存的话，这时候问题会比较大的，因为小缓存缓存的数据量非常小，相比整个存储系统来说比例非常低，这样随机读取(数据库系统的大多数情况)的时候命中率也自然就很低，这样的缓存不但不能提高效率(因为绝大部分读IO都还要读取磁盘)，反而会因为每次去匹配缓存而浪费时间。执行读IO操作是读取数据存在于缓存中的数量与全部要读取数据的比值称为缓存命中率(ReadCacheHitRadio)，假设一个存储系统在不使用缓存的情况下随机小IO读取能达到150IOPS，而它的缓存能提供10%的缓存命中率的话，那么实际上它的IOPS可以达到150/(1-10%)=166。回写要先说一下，用于回写功能的那部分缓存被称为写缓存(WriteCache)。在一套写缓存打开的存储中，操作系统所发出的一系列写IO命令并不会被挨个的执行，这些写IO的命令会先写入缓存中，然后再一次性的将缓存中的修改推到磁盘中，这就相当于将那些相同的多个IO合并成一个，多个连续操作的小IO合并成一个大的IO，还有就是将多个随机的写IO变成一组连续的写IO，这样就能减少磁盘寻址等操作所消耗的时间，大大的提高磁盘写入的效率。写缓存虽然对效率提高是很明显的，但是它所带来的问题也比较严重，因为缓存和普通内存一样，掉电以后数据会全部丢失，当操作系统发出的写IO命令写入到缓存中后即被认为是写入成功，而实际上数据是没有被真正写入磁盘的，此时如果掉电，缓存中的数据就会永远的丢失了，这个对应用来说是灾难性的，解决这个问题最好的方法就是给缓存配备电池了，保证存储掉电之后缓存数据能如数保存下来。和读一样，写缓存也存在一个写缓存命中率(WriteCacheHitRadio)，不过和读缓存命中情况不一样的是，尽管缓存命中，也不能将实际的IO操作免掉，只是被合并了而已。控制器缓存和磁盘缓存除了上面的作用之外还承当着其他的作用，比如磁盘缓存有保存IO命令队列的功能，单个的磁盘一次只能处理一个IO命令，但却能接收多个IO命令，这些进入到磁盘而未被处理的命令就保存在缓存中的IO队列中。RAID(RedundantArrayOfInexpensiveDisks)如果你是一位数据库管理员或者经常接触服务器，那对RAID应该很熟悉了，作为最廉价的存储解决方案，RAID早已在服务器存储中得到了普及。在RAID的各个级别中，应当以RAID10和RAID5(不过RAID5已经基本走到头了，RAID6正在崛起中，看看这里了解下原因)应用最广了。下面将就RAID0，RAID1，RAID5，RAID6，RAID10这几种级别的RAID展开说一下磁盘阵列对于磁盘性能的影响，当然在阅读下面的内容之前你必须对各个级别的RAID的结构和工作原理要熟悉才行，这样才不至于满头雾水，推荐查看wikipedia上面的如下条目：RAID，StandardRAIDlevels，NestedRAIDlevels。RAID0播报编辑RAID0将数据条带化(striping)将连续的数据分散在多个磁盘上进行存取，系统发出的IO命令(不管读IO和写IO都一样)就可以在磁盘上被并行的执行，每个磁盘单独执行自己的那一部分请求，这样的并行的IO操作能大大的增强整个存储系统的性能。假设一个RAID0阵列有n(n＞=2)个磁盘组成，每个磁盘的随机读写的IO能力都达到140的话，那么整个磁盘阵列的IO能力将是140*n。同时如果在阵列总线的传输能力允许的话RAID0的吞吐率也将是单个磁盘的n倍。其他RAID区域RAID1镜像磁盘，使用2块硬盘，一般做系统盘的镜像，读IO为一块硬盘的IO，写IO为2块硬盘的IO。RAID10既能增加IO的读写性能又能实现数据的冗余,使用盘的数量为2的倍数且要大于等于4，且硬盘空间相同，这样的缺点是要实现IO扩展就必须增加相应的硬盘数量，实现同样的性能硬盘成本要成倍增长。允许不同硬盘数据的任何一块丢失。RAID3拿出单独一块盘做奇偶校验盘，做到数据的冗余这种情况下允许一块硬盘损坏。由于磁盘的任何数据发生改变都会重新对校验盘进行改写，所以过多的写操作会成为整个系统的瓶颈，此种RAID级别只能用于对读请求相对较高，写请求不多的环境。RAID3已基本淘汰，一般用RAID5技术替代。直接映射：定义主要用于主存储器与高速缓存之间的一种地址映射关系，主存储器中的一块只能映射到高速缓存的一个特定块中。[1]SSD：基本简介播报编辑固态硬盘，因为台湾的英语里把固体电容称为Solid而得名。SSD由控制单元和存储单元（FLASH芯片、DRAM芯片）组成。固态硬盘在接口的规范和定义、功能及使用方法上与普通硬盘的完全相同，在产品外形和尺寸上基本与普通硬盘一致（新兴的U.2，M.2等形式的固态硬盘尺寸和外形与SATA机械硬盘完全不同）。被广泛应用于军事、车载、工控、视频监控、网络监控、网络终端、电力、医疗、航空、导航设备等诸多领域。芯片的工作温度范围很大，商规产品（0~70℃）工规产品（-40~85℃）。虽然成本较高，但是正在普及至DIY市场。由于固态硬盘的技术与传统硬盘的技术不同，所以产生了不少新兴的存储器厂商。厂商只需购买NAND颗粒，再配适当的控制芯片，编写主控制器代码，就制造了固态硬盘。新一代的固态硬盘普遍采用SATA-2接口、SATA-3接口、SAS接口、MSATA接口、PCI-E接口、M.2接口、CFast接口、SFF-8639接口和NVME/AHCI协议。[1]分类播报编辑分类方式：固态硬盘的存储介质分为两种，一种是采用闪存（FLASH芯片）作为存储介质，另外一种是采用DRAM作为存储介质。最新还有英特尔的XPoint颗粒技术。基于闪存的固态硬盘：基于闪存的固态硬盘（IDEFLASHDISK、SerialATAFlashDisk）：采用FLASH芯片作为存储介质，这也是通常所说的SSD。它的外观可以被制作成多种模样，例如：笔记本硬盘、微硬盘、存储卡、U盘等样式。这种SSD固态硬盘最大的优点就是可以移动，而且数据保护不受电源控制，能适应于各种环境，适合于个人用户使用。寿命较长，根据不同的闪存介质有所不同。SLC闪存普遍达到上万次的PE，MLC可达到3000次以上，TLC也达到了1000次左右，最新的QLC也能确保300次的寿命，普通用户一年的写入量不超过硬盘的50倍总尺寸，即便最廉价的QLC闪存，也能提供6年的写入寿命。可靠性很高，高品质的家用固态硬盘可轻松达到普通家用机械硬盘十分之一的故障率。基于DRAM类：基于DRAM的固态硬盘：采用DRAM作为存储介质，应用范围较窄。它仿效传统硬盘的设计，可被绝大部分操作系统的文件系统工具进行卷设置和管理，并提供工业标准的PCI和FC接口用于连接主机或者服务器。应用方式可分为SSD硬盘和SSD硬盘阵列两种。它是一种高性能的存储器，理论上可以无限写入，美中不足的是需要独立电源来保护数据安全。DRAM固态硬盘属于比较非主流的设备。[1]基于3DXPoint类基于3DXPoint的固态硬盘：原理上接近DRAM，但是属于非易失存储。读取延时极低，可轻松达到现有固态硬盘的百分之一，并且有接近无限的存储寿命。缺点是密度相对NAND较低，成本极高，多用于发烧级台式机和数据中心。发展历程播报编辑1956年，IBM公司发明了世界上第一块硬盘。1968年，IBM重新提出“温彻斯特”（Winchester）技术的可行性，奠定了硬盘发展方向。1970年，StorageTek公司(SunStorageTek)开发了第一个固态硬盘驱动器。1984年，东芝发明闪存。1989年，世界上第一款固态硬盘出现。2006年3月，三星率先发布一款32GB容量的固态硬盘笔记本电脑，2007年1月，SanDisk公司发布了1.8寸32GB固态硬盘产品，3月又发布了2.5寸32GB型号。2007年6月，东芝推出了其第一款120GB固态硬盘笔记本电脑。2008年9月，忆正MemoRightSSD的正式发布，标志着中国企业加速进军固态硬盘行业。2009年，SSD井喷式发展，各大厂商蜂拥而来，存储虚拟化正式走入新阶段。2010年2月，镁光发布了全球首款SATA6Gbps接口固态硬盘，突破了SATAII接口300MB/s的读写速度。2010年底，瑞耐斯Renice推出全球第一款高性能mSATA固态硬盘并获取专利权。[1]2013年，三星推出VNand3D闪存。2022年7月21日，三星电子宣布，公司成功研制出第二代智能固态硬盘（SmartSSD），今后将以此抢占未来市场。[8]基本结构播报编辑基于闪存的固态硬盘是固态硬盘的主要类别，其内部构造十分简单，固态硬盘内主体其实就是一块PCB板，而这块PCB板上最基本的配件就是控制芯片，缓存芯片（部分低端硬盘无缓存芯片）和用于存储数据的闪存芯片。主控芯片市面上比较常见的固态硬盘有LSISandForce、Indilinx、JMicron、Marvell、Phison、Sandisk、Goldendisk、Samsung以及Intel等多种主控芯片。主控芯片是固态硬盘的大脑，其作用一是合理调配数据在各个闪存芯片上的负荷，二则是承担了整个数据中转，连接闪存芯片和外部SATA接口。不同的主控之间能力相差非常大，在数据处理能力、算法，对闪存芯片的读取写入控制上会有非常大的不同，直接会导致固态硬盘产品在性能上差距高达数倍。缓存颗粒主控芯片旁边是缓存颗粒，固态硬盘和传统硬盘一样需要高速的缓存芯片辅助主控芯片进行数据处理。这里需要注意的是，有一些廉价固态硬盘方案为了节省成本，省去了这块缓存芯片，这样对于使用时的性能会有一定的影响，尤其是小文件的读写性能和使用寿命上。闪存芯片除了主控芯片和缓存芯片外，PCB板上其余大部分位置都是NANDFlash闪存芯片。NANDFlash闪存芯片又分为SLC（Single-LevelCell，单层单元）、MLC（Multi-LevelCell，双层单元）、TLC（Trinary-LevelCell，三层单元）、QLC（Quad-LevelCell，四层单元）这四种规格。另还有一种eMLC（EnterpriseMulti-LevelCell，企业多层单元）是MLCNAND闪存的一个“增强型”的版本，它在一定程度上弥补了SLC和MLC之间的性能和耐久差距。对比传统硬盘播报编辑固态硬盘的接口规范和定义、功能及使用方法上与普通硬盘几近相同，外形和尺寸也基本与普通的2.5英寸硬盘一致。固态硬盘具有传统机械硬盘不具备的快速读写、质量轻、能耗低以及体积小等特点，同时其劣势也较为明显。尽管IDC认为SSD已经进入存储市场的主流行列，但其价格仍较为昂贵，容量较低，一旦硬件损坏，数据较难恢复等；并且亦有人认为固态硬盘的耐用性（寿命）相对较短。影响固态硬盘性能的几个因素主要是：主控芯片、NAND闪存介质和固件。在上述条件相同的情况下，采用何种接口也可能会影响SSD的性能。主流的接口是SATA（包括3Gb/s和6Gb/s两种）接口，亦有PCIe3.0接口的SSD问世。由于SSD与普通磁盘的设计及数据读写原理的不同，使得其内部的构造亦有很大的不同。一般而言，固态硬盘（SSD）的构造较为简单，并且也可拆开；所以我们通常看到的有关SSD性能评测的文章之中大多附有SSD的内部拆卸图。而反观普通的机械磁盘，其数据读写是靠盘片的高速旋转所产生的气流来托起磁头，使得磁头无限接近盘片，而又不接触，并由步进电机来推动磁头进行换道数据读取。所以其内部构造相对较为复杂，也较为精密，一般情况下不允许拆卸。一旦人为拆卸，极有可能造成损害，磁盘无法正常工作。这也是为何在对磁盘进行评测时，我们基本看不到关于磁盘拆卸图的原因。[3]优点播报编辑读写速度快：采用闪存作为存储介质，读取速度相对机械硬盘更快。固态硬盘不用磁头，寻道时间几乎为0。持续写入的速度非常惊人，固态硬盘厂商大多会宣称自家的固态硬盘持续读写速度超过了500MB/s，近年来的NVMe固态硬盘可达到2000MB/s左右，甚至4000MB/s以上。固态硬盘的快绝不仅仅体现于持续读写上，随机读写速度快才是固态硬盘的终极奥义，这最直接体现于绝大部分的日常操作中。与之相关的还有极低的存取时间，最常见的7200转机械硬盘的寻道时间一般为12-14毫秒，而固态硬盘可以轻易达到0.1毫秒甚至更低。[4]防震抗摔性：传统硬盘都是磁碟型的，数据储存在磁碟扇区里。而固态硬盘是使用闪存颗粒（即MP3、U盘等存储介质）制作而成，所以SSD固态硬盘内部不存在任何机械部件，这样即使在高速移动甚至伴随翻转倾斜的情况下也不会影响到正常使用，而且在发生碰撞和震荡时能够将数据丢失的可能性降到最小。相较传统硬盘，固态硬盘占有绝对优势。[4]低功耗：固态硬盘的功耗上要低于传统硬盘。无噪音：固态硬盘没有机械马达和风扇，工作时噪音值为0分贝。基于闪存的固态硬盘在工作状态下能耗和发热量较低（但高端或大容量产品能耗会较高）。内部不存在任何机械活动部件，不会发生机械故障，也不怕碰撞、冲击、振动。由于固态硬盘采用无机械部件的闪存芯片，所以具有了发热量小、散热快等特点。[4]工作温度范围大：典型的硬盘驱动器只能在5到55摄氏度范围内工作。而大多数固态硬盘可在-10~70摄氏度工作。固态硬盘比同容量机械硬盘体积小、重量轻。固态硬盘的接口规范和定义、功能及使用方法上与普通硬盘的相同，在产品外形和尺寸上也与普通硬盘一致。其芯片的工作温度范围很宽（-40~85摄氏度）。轻便：固态硬盘在重量方面更轻，与常规1.8英寸硬盘相比，重量轻20-30克。缺点播报编辑容量：随着MLC、TLC、QLC乃至未来的PLC等多阶存储单元的发展，固态硬盘容量正在迅速增长。截止2021年1月世界上容量最大的固态硬盘是NimbusData推出的ExaDriveDC100系列固态硬盘，容量可达100TB。[5]寿命限制：固态硬盘闪存具有擦写次数限制的问题，这也是许多人诟病其寿命短的所在。闪存完全擦写一次叫做1次P/E，因此闪存的寿命就以P/E作单位。34nm的闪存芯片寿命约是5000次P/E，而25nm的寿命约是3000次P/E。随着SSD固件算法的提升，新款SSD都能提供更少的不必要写入量。一款120G的固态硬盘，要写入120G的文件才算做一次P/E。普通用户正常使用，即使每天写入50G，平均2天完成一次P/E，3000个P/E能用20年，到那时候，固态硬盘早就被替换成更先进的设备了(在实际使用中，用户更多的操作是随机写，而不是连续写，所以在使用寿命内，出现坏道的机率会更高)。另外，虽然固态硬盘的每个扇区可以重复擦写100000次(SLC)，但某些应用，如操作系统的LOG记录等，可能会对某一扇区进行多次反复读写，而这种情况下，固态硬盘的实际寿命还未经考验。不过通过均衡算法对存储单元的管理，其预期寿命会延长。SLC有10万次的写入寿命，成本较低的MLC，写入寿命仅有1万次,而廉价的TLC闪存则更是只有1000-2000次。此外，使用全盘模拟SLC提升写入速度的多阶存储固态会面临写入放大问题，进一步缩短寿命。售价高：截止2021年1月市场上采用TLC存储单元的256GB固态硬盘价格大约为240元人民币左右（采用SATA接口+TLC颗粒），而1TB固态硬盘产品的价格大约在650元人民币左右（NVMe接口+TLC颗粒）。计算下来每GB大约0.6-1元。相比每GB仅为0.2元的机械硬盘高了不少。使用与保养播报编辑对于固态硬盘的使用和保养，最重要的一条就是：在机械硬盘时代养成的“良好习惯”，未必适合固态硬盘。一、不要使用碎片整理碎片整理是对付机械硬盘变慢的一个好方法，但对于固态硬盘来说这完全就是一种“折磨”。消费级固态硬盘的擦写次数是有限制，碎片整理会大大减少固态硬盘的使用寿命。其实，固态硬盘的垃圾回收机制就已经是一种很好的“磁盘整理”，再多的整理完全没必要。Windows的“磁盘整理”功能是机械硬盘时代的产物，并不适用于SSD。除此之外，使用固态硬盘最好禁用Win7的预读(Superfetch)和快速搜索(WindowsSearch)功能。这两个功能的实用意义不大，而禁用可以降低硬盘读写频率。（在Windows10中，这一项优化不需要）二、小分区少分区还是由于固态硬盘的“垃圾回收机制”。在固态硬盘上彻底删除文件，是将无效数据所在的整个区域摧毁，过程是这样的：先把区域内有效数据集中起来，转移到空闲的位置，然后把“问题区域”整个清除。这一机制意味着，分区时不要把SSD的容量都分满。例如一块128G的固态硬盘，厂商一般会标称120G，预留了一部分空间。但如果在分区的时候只分100G，留出更多空间，固态硬盘的性能表现会更好。这些保留空间会被自动用于固态硬盘内部的优化操作，如磨损平衡、垃圾回收和坏块映射。这种做法被称之为“小分区”。“少分区”则是另外一种概念，关系到“4k对齐”对固态硬盘的影响。一方面主流SSD容量都不是很大，分区越多意味着浪费的空间越多，另一方面分区太多容易导致分区错位，在分区边界的磁盘区域性能可能受到影响。最简单地保持“4k对齐”的方法就是用Win7自带的分区工具进行分区，这样能保证分出来的区域都是4K对齐的。三、保留足够剩余空间固态硬盘存储越多性能越慢。而如果某个分区长期处于使用量超过90%的状态，有些固态硬盘崩溃的可能性将大大增加，绝大部分硬盘也会出现性能降低的现象。所以及时清理无用的文件，设置合适的虚拟内存大小，将电影音乐等大文件存放到机械硬盘非常重要，必须让固态硬盘分区保留足够的剩余空间。四、及时刷新固件“固件”好比主板上的BIOS，控制固态硬盘一切内部操作，不仅直接影响固态硬盘的性能、稳定性，也会影响到寿命。优秀的固件包含先进的算法能减少固态硬盘不必要的写入，从而减少闪存芯片的磨损，维持性能的同时也延长了固态硬盘的寿命。因此及时更新官方发布的最新固件显得十分重要。不仅能提升性能和稳定性，还可以修复之前出现的bug。五、学会使用恢复指令固态硬盘的Trim重置指令可以把性能完全恢复到出厂状态。[6]随着互联网的飞速发展，人们对数据信息的存储需求也在不断提升，多家存储厂商推出了自己的便携式固态硬盘，更有支持Type-C接口的移动固态硬盘和支持指纹识别的固态硬盘推出。相关资讯播报编辑2021年11月15日，铭瑄发布旗下首款电竞之心系列SSD，国产主控+国产TLC颗粒。[7]磁带：简介播报编辑定义英文名称：magnetictapetitle在中国大陆，通常“磁带”或者“录音带”一词都指紧凑音频盒带，因为它的应用非常广泛。在中国台湾，reel-to-reeltape被称为盘式录音带、紧凑音频盒带（Compactaudiocassette）被称为卡式录音带、8轨软片（8-trackcartridges)）被称为匣式录音带。磁带主要由磁粉、带基、粘合剂三种材料组成，其中磁性层尤为重要，它是磁带记录和存贮信息的主体部分，而且磁带质量的好坏主要由磁性层决定。[7]磁带54年1963-2017年：承载记忆的AB面磁带，作为承载一个时代记忆的载体，已有50年的历史，即从最初的数据存储到主流的音乐存储介质。磁带1963年，荷兰飞利浦公司研制成了全球首盘盒式磁带，大小仅为早期的菲德里派克（Fidelipac）循环卡式录音机的1/4，磁带双面都由塑料外壳包裹，可最大程度保护其中的数据，每一面可容纳30到45分钟的立体声音乐。1965年，8声轨磁带诞生。3年后，TDK的超级动态系列上市，宣告了第一款“高保真”磁带诞生。1970年，第一盘120分钟磁带诞生，即每一面可容纳60分钟的音频数据。1971年，Advent公司推出了201型磁带机——其搭载杜比B型降噪系统，磁带才被更加认真地用于录制音乐，为之后开始的高保真卡带和播放器时代奠定了坚实基础。20世纪80年代，以索尼Walkman系列为代表的便携式随身听出现，造就了磁带在全世界范围内的风靡。正是在这个时期，音乐磁带的销售开始取代密纹唱片，随身听一跃成为便携式音乐市场的象征。然而好景不长，在很多西方国家，磁带市场在经历了上世纪80年代末的销售高峰后，就开始急速萎缩。到了90年代初期，CD的销售就超过了预录制卡带。1998年，韩国三星公司推出了全球首台MP3播放器。在随后的几年时间里，尤其是进入了千禧年之后，MP3格式开始在市场上大行其道。2007年，当英国一个主要的电器零售商宣告停止销售磁带后，《太阳报》就自作主张宣告了磁带的死亡。2009年，网络杂志PopMatters认为磁带已经可以圆满退场了：“一些媒介就是注定要灭亡且永无复兴之日，磁带注定是这种命运。”2010年秋，美国媒体报道了磁带的“重生”：美国25个音乐厂牌开始重新制作磁带，著名的音乐网站Pitchfork也早就进行了类似的尝试，并且这些磁带不是老专辑的翻录，而是新发行的专辑。一些独立乐队，如AnimalCollective、Deerhoof、theMountainGoats也推出了磁带专辑。如今，磁带变为一种收藏，依旧在市场上活跃。据业内行家称，老磁带的大部分品种发行量小，外加绞带、受潮等自然损耗和人为损耗，其收藏价值会越来越高。尺寸磁带尺寸广义上讲包括磁带的宽度、长度或者磁带盒的规格。磁带盒常见的规格：AIT磁带多为3.5英寸（8.89厘米）、DLT磁带多为5.25英寸（13.335厘米）。工作原理为什么磁带可以存储音频信号呢？它的工作原理是什么呢？原来，录音磁头实际上是个蹄形电磁铁，两极相距很近，中间只留个狭缝。整个磁头封在金属壳内。录音磁带的带基上涂着一层磁粉，实际上就是许多铁磁性小颗粒。磁带紧贴着录音磁头走过，音频电流使得录音头缝隙处磁场的强弱、方向不断变化，磁带上的磁粉也就被磁化成一个个磁极方向和磁性强弱各不相同的“小磁铁”，声音信号就这样记录在磁带上了。放音头的结构和录音头相似。当磁带从放音头的狭缝前走过时，磁带上“小磁铁”产生的磁场穿过放音头的线圈。由于“小磁铁”的极性和磁性强弱各不相同，它在线圈内产生的磁通量也在不断变化，于是在线圈中产生感应电流，放大后就可以在扬声器中发出声音。技术磁带卷轴螺旋扫描记录技术的历史可追溯到40多年前。1956年，ampex公司将螺旋扫描设备作为一种可靠的存储设备推向了视频市场。该设备每平方英寸磁带可存储的数据大幅度增长，读数据的速度比当时线性磁带技术还要快。螺旋扫描技术的高性能和大容量迅速使螺旋扫描技术成为视频广播业的标准。许多电视台仍使用类似的螺旋扫描磁带驱动器，每套磁带系统的价格超过了10万美元。第一种高性能、高容量磁带驱动器exabyte8200于1987年被引入到unix开放系统市场中，该驱动器传输速率为240kb/s，容量为2．4gb。这种螺旋驱动器使用8毫米磁带，利用不同的读、写磁头从磁带读取数据并向磁带写入数据。写后读技术，即在安装磁头的磁鼓每转一圈时，使用一个磁头写数据，随后再利用读磁头来校验数据。这种技术是用来校验写入操作正确性的通用方法。如果检测到错误的话，就对数据进行重写，直到读出的数据没有错误为止。这类驱动器的高密度、高速度以及错误检测和纠正等特性使螺旋扫描技术非常流行。对螺旋扫描技术的改进包括1990年推出的硬件压缩，它可以将存储在磁带上的数据密度增加一倍。1990年，人们还对螺旋扫描技术进行了另一项改进，即使用方位角记录技术。这项技术利用以不同角度安装在扫描器上的磁头在磁带上生成的人字形或v形轨迹。这就使高密磁轨容错技术成为可能。这项技术在历史上曾使螺旋扫描技术在性能和容量上处于领先位置。此外，磁带介质上的改进则进一步增加了螺旋扫描磁带的数据密度。新型驱动器的发展提供了更高的记录速率、更大的磁带容量，并提高了数据密度。[1]分类播报编辑根据用途不同，磁带按用途可大致分成录音带、录像带、计算机带和仪表磁带四种。[7]录音带磁带20世纪30年代开始出现，是用量最大的一种磁带。1963年，荷兰飞利浦公司研制成盒式录音带,由于具有轻便、耐用、互换性强等优点而得到迅速发展。1973年，日本研制成功Avilyn包钴磁粉带。1978年，美国生产出金属磁粉带。由日本日立玛克赛尔公司创造的MCMT技术（即特殊定向技术、超微粒子及其分散技术）制成了微型及数码盒式录音带，又使录音带达到一个新的水平，并使音频记录进入了数字化时代。中国在60年代初开始生产录音带，1975年试制成盒式录音带，并已达较高水平。录像带自从1956年美国安佩克斯公司制成录像机以来，录像带已从电视广播逐步进入到科学技术、文化教育、电影和家庭娱乐等领域。除了用二氧化铬包钴磁粉以及金属磁粉制成录像带外，日本还制成微型镀膜录像带，并开发了钡铁氧体型垂直磁化录像带。计算机带盒式磁带（线性磁带开放协议，即LTO技术）计算机带作为数字信息的存贮具有容量大、价格低的优点。主要大量用于计算机的外存贮器。如今仅在专业设备上使用（比如计算机磁带存储器、车床控制机）。线性磁带开放协议（LTO-2的滤芯）仪表磁带也称仪器磁带或精密磁带。近代科学技术，常需要把人们无法接近的测量数据自动而连续地记录下来，即所谓遥控遥测技术。如原子弹爆炸和卫星空间探测都要求准确无误地同时记录上百、上千个数据。仪表磁带就是在上述需要下发展起来的，它是自动化和磁记录技术相结合的产物。对这种磁带的性能和制造都有着严格的要求。此外，还有其他磁带和打字机用磁性染色带等。[2]挑战播报编辑读写记录线性磁带技术在时间上早于螺旋扫描记录技术十多年。在使用线性记录技术时，磁带被安装在两个磁带轴上，通过磁带轴的转动使磁带高速经过磁头。如今线性技术已经成为非常流行的技术，并对螺旋扫描技术发起了挑战。磁带写后读技术被广泛地应用在线性磁带中。利用隔开一小段距离的写磁头和读磁头，完成先写后读的操作。读磁头读取写磁头刚刚写入的数据，以保证数据完整地写到磁带上。错误处理的方式与螺旋扫描使用的方式相似。记录介质、磁头设计和固件上的改进，使线性技术超越了每条磁带36条磁轨的人为限制。这就使蛇形记录成为可能。在使用蛇形记录技术时，磁带机先沿整条磁带写入一个磁轨集后，再重新定位磁头；然后反方向再沿整个磁带写入另一个磁轨集。线性技术可以在一条磁带上这样写52遍，写入208条磁轨。利用这种方法，可以增加记录密度。但是，即使利用这种技术，与螺旋扫描相比，数据密度仍很有限。数据磁轨之间的距离越小，磁轨之间串音的可能性就越高。dlt7000磁带机针对这一问题采用轻微地旋转磁头的方法，产生一个有角度的写形式，类似人字形或v形。这种形式与螺旋扫描驱动器的写形式非常相似。磁头对磁带的精确校准，尤其在磁轨的数量不断增加的情况下，对磁带驱动器设计者一直是一个挑战。用于校准磁头与磁带位置的伺服器已经成为了当今和下一代线性驱动器的通用特性。线性记录已经成为一种成功的产品，并且已在许多应用中取代了螺旋磁带驱动器。不过，事物是在不断变化的，三十年河东，三十年河西。襟抱堂网络策划机构评论，光盘媒介对磁带的取代已成为了历史发展的必然趋势，磁带的发展由其产品的制约性必然被科技所淘汰。传输速率提高8毫米传输速率在过去的五年中，螺旋扫描驱动器的性能已经滞后于线性驱动器。例如，dlt7000磁带的传输速率为5mb/s，而mammoth1和ait磁带驱动器只具有3mb/s的传输速率。通过增加更多的并行磁带通道，线性磁带驱动器上的传输速率一直不断地改进。例如，dlt7000使用了四条磁轨达到了5mb/s，而螺旋扫描驱动器不能超过两条通道的限制。以前，螺旋扫描设计上的部分限制是由于它们与用于消费类视频技术之间存在过近关系。mammoth是第一种与基于消费用8毫米设计脱钩的8毫米驱动器。这项技术在1996年推出。该解决方案特别定位于满足企业数据存储需要。工业化的机芯设计利用轴对轴伺服系统取代了早期设计中造成很多麻烦的绞盘和压紧导辊。这有助于取得精确的磁带速度，实现准确的张力控制。螺旋扫描技术方面两项最新的进展克服了8毫米螺旋扫描驱动器在传输速率上的限制。这两项改进将成为安百特（exabyte）下一代驱动器必不可少的部分。下一代驱动器性能将增至四倍，存储容量将增至三倍。边写边读和加电转子这两项技术消除了以前制约传输速率和数据密度的限制。这些限制曾使螺旋扫描的传输速率和数据密度低于线性磁带技术。这两种新技术结合的结果是，现可以在磁鼓上（扫描器）安装更多的磁头（大大多于以前螺旋扫描可能安装的磁头数量），实现更高的传输率并增加了密度。在未来的产品中，可以在扫描器上安装8个通道（16个磁头）。在使用8个通道时，系统可以达到超过100mb/s的传输速率。最新一代的扫描器，其设计将读/写电器件集成到扫描仪（带电转子）上，缩短了电子器件与磁头的距离，同时提高了驱动器的性能和可靠性。技术提升mammoth2的设计在其它许多方面超过了线性磁带。定义性能两个主要因素：一是磁头对磁带的速度；二是螺旋扫描驱动器可以方便地升级。为使螺旋扫描驱动器增加磁头对磁带的速度，扫描器应当更快地旋转。与此相比，线性驱动器已接近磁带运动的极限。例如，线性磁带驱动器耗电约为35瓦。将磁带的速度提高一倍，会使耗电达到60至65瓦，产生的烤箱效应足以烤熟磁带和驱动器。靠线性驱动器以更高速的磁带运动使性能得到改进是不可能的。相反，螺旋扫描驱动器速度的提高，相应的耗电增加仅为不到1瓦。因此，对螺旋扫描技术来说，增加扫描器马达速度耗电将从12瓦升至12．5瓦。此外，螺旋磁带密度比线性磁带的密度更高。螺旋扫描磁轨在实时伺服控制下写磁轨的偏差为0．2微米，而线性磁轨偏差为10微米。事实上，螺旋驱动器可以在3微米宽的磁轨上进行读写。这样细的磁轨尺寸对线性磁带驱动器几乎是不可能的，其原因是线性蛇形记录本身固有的容错问题。存储容量至于容量，最大的线性磁带驱动器的存储容量要比8毫米磁带高，这已是公认的事实了。这主要是由于在磁带盒中使用了五倍的磁带。老实说，与dlt相比较，8毫米磁带的格式（它的磁带盒和磁带都比较小）可以被认为每盒磁带的容量受到了限制。但是，如果mammoth与dlt有同样多的磁带的话，那么，它的容量可以达到100gb。然而，部分是由于磁带盒较小的原因，同样更紧凑的磁带机也是可能做到的。换句话说，在相同空间里，可以比dlt驱动器和磁带放入更多的8毫米驱动器和磁带。此外，较小的磁带盒使8毫米驱动器可以具有更快的文件访问时间，因而对数据的访问也更快。日本富士胶片公司和瑞士苏黎世的研究人员研发出一种新型超密磁带，被称之为“线性磁带文件系统”。这种存储系统存储密度更高，能耗更低，能够取代当前的硬盘。他们研制的原型超密磁带覆盖钡铁氧体颗粒图层，所使用的带盒长10厘米，宽10厘米，高2厘米，能够存储35TB数据，大约相当于3500个图书馆所涵盖的信息。技术比较如果将线性和螺旋磁带并排放在一起比较的话，这两种技术一些有趣的方面就会变得非常明显。在安百特（exabyte）公司的磁带库解决方案中，在同样大小的机箱内既可采用mammoth，也可采用dlt。dlt库提供了30mb/s的性能和6．3tb的容量。相比之下，8毫米库也提供了同样的30mb/s的传输速率，但可以多存储1．7tb的数据，即总存储量为8tb。在过去的几年里，8毫米技术已经得到了改进，它所具有的传输速率与竞争对手线性技术一样好，或许甚至更好。这些改进包括工业强度的机械和创新的工程上的进步，使采用最多8个磁头成为可能。通过增加磁带对磁头的速度来进一步提高传输速率可以方便地利用mammoth技术实现，而这种改进对于线性驱动技术而言将越来越困难。录音磁带第二次世界大战虽然造成了78转唱片市场的萎缩，却阴差阳错地从另一个方面对流行音乐市场提供了帮助。德国的工程师们为了更好地广播希特勒的讲话，在磁带录音技术上取得了革命性的进步。二战后，美国把这一技术原样拿了过来，并很快就运用在流行音乐领域。磁带录音方便可靠，价钱便宜，质量又好，使得投资不多的小型录音公司得以生存下去，为五十年代独立唱片公司的发展壮大立下了汗马功劳，这些小型公司的兴起直接促成了摇滚乐的诞生。六十年代中期，RCA发明了可以在汽车上使用的八轨磁带（8-Track），这一发明立刻吸引了众多以前不怎么买唱片的消费者的注意，美国的音乐销售也从这一时期开始直线上升。七十年代初，一批自称是“低者”（Downer,相对于传统的“Higher”）的吸毒群体高速行驶中的汽车里听震耳欲聋的重摇滚对达到“状态”很有帮助。这种说法很快在听众中流传开来，并很大程度上造就了七十年代初期重摇滚的流行。一批重摇滚乐队因此受益匪浅，如“深紫”、“黑色安息日”（BlackSabbath）和“AC/DC”等，他们的磁带销售往往会占到总销售额的70%以上。磁带原理图后来，杜比技术的发明让可录音的卡式磁带走进了消费者的家中。这一新技术使得盗版磁带开始在地下泛滥。唱片商不得不象当年对抗广播业一样，又开始借助法律手段进行抵制。不过，磁带的录音质量比不上黑胶唱片（LP），再加上因为各种原因，六七十年代的美国流行音乐市场格外繁荣，因此盗版的影响不算太坏，倒是一些歌迷在地下市场交换私自录制的歌手实况演唱录音，算是弥补了录音室唱片的不足。这些非法录音不但为乐队造就了一批批铁杆歌迷，而且为后来音乐史学家们研究这段历史帮助很大。[3]相关资料播报编辑常见故障声音不清晰（国标允许误差范围≤-48dB）可能的故障部位：①放音机磁头上有脏物。解决方法：用酒精棉球轻擦放音磁头，注意不要用镊子，螺丝刀等金属物。②磁带顶部毛粘垫松动或脱落。解决方法：要修复，更换毛粘垫。③磁带变形、打折、受潮或被磁化。解决方法：调换、报废。④放音磁头磨损严重。解决方法：更换放音头，业余更换时要求磁头电感量和阻值一样。⑤磁头方位角偏移不正确。调校：把录音带放入盒中放音，用小螺丝刀调校磁头上带弹簧的螺丝里外移动，使放音量最大为宜。声音忽大忽小可能的故障部位：①检查放音机机械传动是否正常，如压带轮是否老化，主导轴是否有脏物，皮带是否老化、错槽。解决方法：清洗或更换。②盒式录音带白轮是否变形，毛粘垫是否松动。解决方法：修复、更换左右声道串音（国标允许误差范围≤-34dB）可能的故障部位：①检查放音机磁头是否磨损。解决方法：更换磁头。②检查走动机械是否正常。解决方法：修复。③磁带不合格。解决方法：调换磁带AB面串音（国标允许误差范围≤-52dB）可能的故障部位：①检查放音磁头，机械传动是否正常。解决方法：修复。②磁头磁叉是否松动。解决方法：调校粘牢。③是否使用了特大功率放大器。解决方法：旋小放音量。④磁带不合格。解决方法：调换。走带过程中断带可能的故障部位：①检查机器供带轮是否转动。解决方法：修复或更换。②检查磁带两个轮是否转动灵活。解决方法：修复或更换。③放音机收带轮是否转动。解决方法：修复或更换。④操作放音机方法是否正确。解决方法：改变操作方法。声音模糊听不清可能的故障部位：①检查磁头是否有脏物，是否磨损、老化以及磁头方位角是否正确。解决方法：清洗磁头，修复，调校。②检查磁带顶部毛粘垫是否脱落。解决方法：修复，更换。③工厂加工是反带不合格。解决方法：反带修复，也就是把磁带前轮和后轮翻面倒个相位重新倒带即可。声音断话、停顿可能的故障部位：①检查放音操作方法是否失误，按错按键。（如误按了录音键）解决方法：改正操作方法。②放音机传动机械是否正常，电源电压是否稳定，电池夹是否氧化，接触是否不良。解决方法：修复、更换电池或电源。③磁带转动是否灵活。解决方法：修复，把磁带正面五个螺丝松动录音带左右声道电平不一致，AB面声音不一样（国标允许左右相差1dB，AB面相差2dB）可能的故障部位：①音头有脏物、磁头磨损或出厂不合格。解决方法：清洗磁头或更换放音机。②放音头老化、磁头偏磨、方位角不平或磁带不合格。解决方法：更换或修复放音机或调换磁带。磁带保管磁带保管不善，也会使磁带变形、变脆，机械强度降低，电磁性能下降，严重影响和缩短磁带使用寿命，甚至报废。磁带保管中要注意几个问题：[7]1.远离磁场2.保持适宜的温湿度3.防光、防尘4.正确卷绕5.正确放置6.严禁磁带同有害的液体、气体接触盗版区别正版（原版）磁带一般均采用进口原材料，包括饼带粘带胶条，AB贴和外封都是正规印刷厂印刷，工厂机器刷标，机器包装。仪器设备均采用进口数码母机和采用10MHZ偏磁独立放大、频响宽、噪音低、失真小的高速复录子机。分切灌带机均由国标正规厂家所生产，分切可靠，头尾一致，前后没有空白，声音清晰，不跑调。另外，歌曲磁带中，正版（原版）磁带的特点是唱片充足，磁带里的歌曲完整、歌曲长，有的歌曲甚至长达将近5分钟、5分多钟或者更长，有些磁带甚至出现了超长版的歌曲。盗版磁带使用低劣饼带，各轮（前轮、后轮、白轮等）不耐磨，贴片滑纸质量很差，复制设备极差（一般都是小机复录），录出的声音电平偏低，噪音很大，频响很差，声音不清晰，跑调，前后空白较长。另外，歌曲磁带中，盗版磁带的特点是唱片不足，磁带里的歌曲残缺、歌曲短，有的歌曲甚至被缩短的只有1分多钟或者更短。录制的时候，有的歌曲被录制的有头无尾，还有的歌曲被录制的时候是从中间省略一部分，个别的歌曲甚至唱了没一会儿就没了。[4]组相联映射：定义播报编辑主要用于主存储器与高速缓存之间的一种地址映射关系，将主存储器和高速缓存按同样大小分组，组内再分成同样大小的块，组间采用直接映射，组内的块之间采用全相联映射。出处播报编辑《计算机科学技术名词》第三版。[1]存取周期：概念播报编辑存储器的两个基本操作为“读出”与“写入”，是指将存储单元与存储寄存器(MDR)之间进行读写。存储器从接收读出命令到被读出信息稳定在MDR的输出端为止的时间间隔，称为“取数时间TA”。两次独立的存取操作之间所需最短时间称为“存储周期TMC”。半导体存储器的存取周期一般为6ns～10ns。[1]其中存储单元(memorylocation)简称“单元”。为存储器中存储一机器字或一字节的空间位置。一个存储器划分为若干存储单元，并按一定顺序编号，称为“地址”。如一存储单元存放一有独立意义的代码。即存放作为一个整体来处理或运算的一组数字，则称为“字”。字的长度，即字所包含的位数，称为“字长”。如以字节来划分存储单元，则一机器字常须存放在几个存储单元中。存储单元中的内容一经写入，虽经反复使用，仍保持不变。如须写入新内容，则原内容被“冲掉”，而变成新写入的内容。[2]存储器（storage）又称“记忆装置”。能按一定地址随机存取计算程序、原始数据、中间和最后结果的装置。存储器须保存大量表示数据或程序的二进制代码，故“按地址”存取的组织方式，将其分成众多单元(称“存储单元”)，并按一定顺序编号(称“地址”)，以便按地址根据指令的要求存取。常以存储容量和存取周期作为衡量性能的主要指标。[2]意义播报编辑为存储器的性能指标之一，直接影响电子计算机的技术性能。存储周期愈短，运算速度愈快，但对存储元件及工艺的要求也愈高。[2]存取周期例如磁芯存储器的存取周期为零点几到几个微秒。半导体存储器的存取周期通常在几十到几百毫微秒之间。那么半导体存储器的性能一般比磁芯存储器的性能要好。[3]缓存：简介播报编辑缓存的工作原理缓存是指可以进行高速数据交换的存储器，它先于内存与CPU交换数据，因此速率很快。L1Cache（一级缓存）是CPU第一层高速缓存。内置的L1高速缓存的容量和结构对CPU的性能影响较大，不过高速缓冲存储器均由静态RAM组成，结构较复杂，在CPU管芯面积不能太大的情况下，L1级高速缓存的容量不可能做得太大。一般L1缓存的容量通常在32—256KB。L2Cache（二级缓存）是CPU的第二层高速缓存，分内部和外部两种芯片。内部的芯片二级缓存运行速率与主频相同，而外部的二级缓存则只有主频的一半。L2高速缓存容量也会影响CPU的性能，原则是越大越好，普通台式机CPU的L2缓存一般为128KB到2MB或者更高，笔记本、服务器和工作站上用CPU的L2高速缓存最高可达1MB-3MB。由于高速缓存的速度越高价格也越贵，故有的计算机系统中设置了两级或多级高速缓存。紧靠CPU的一级高速缓存的速度最高，而容量最小，二级高速缓存的容量稍大，速度也稍低[1]。缓存只是内存中少部分数据的复制品，所以CPU到缓存中寻找数据时，也会出现找不到的情况（因为这些数据没有从内存复制到缓存中去），这时CPU还是会到内存中去找数据，这样系统的速率就慢下来了，不过CPU会把这些数据复制到缓存中去，以便下一次不要再到内存中去取。随着时间的变化，被访问得最频繁的数据不是一成不变的，也就是说，刚才还不频繁的数据，此时已经需要被频繁的访问，刚才还是最频繁的数据，又不频繁了，所以说缓存中的数据要经常按照一定的算法来更换，这样才能保证缓存中的数据是被访问最频繁的。工作原理播报编辑缓存工作原理缓存的工作原理是当CPU要读取一个数据时，首先从CPU缓存中查找，找到就立即读取并送给CPU处理；没有找到，就从速率相对较慢的内存中读取并送给CPU处理，同时把这个数据所在的数据块调入缓存中，可以使得以后对整块数据的读取都从缓存中进行，不必再调用内存。正是这样的读取机制使CPU读取缓存的命中率非常高（大多数CPU可达90%左右），也就是说CPU下一次要读取的数据90%都在CPU缓存中，只有大约10%需要从内存读取。这大大节省了CPU直接读取内存的时间，也使CPU读取数据时基本无需等待。总的来说，CPU读取数据的顺序是先缓存后内存。RAM(Random-AccessMemory)和ROM(Read-OnlyMemory)相对的，RAM是掉电以后，其中的信息就消失那一种，ROM在掉电以后信息也不会消失那一种。RAM又分两种，一种是静态RAM，SRAM(StaticRAM)；一种是动态RAM，DRAM(DynamicRAM)。前者的存储速率要比后者快得多，使用的内存一般都是动态RAM。为了增加系统的速率，把缓存扩大就行了，扩的越大，缓存的数据越多，系统就越快了，缓存通常都是静态RAM，速率是非常的快，但是静态RAM集成度低（存储相同的数据，静态RAM的体积是动态RAM的6倍），价格高（同容量的静态RAM是动态RAM的四倍），由此可见，扩大静态RAM作为缓存是一个非常愚蠢的行为，但是为了提高系统的性能和速率，必须要扩大缓存，这样就有了一个折中的方法，不扩大原来的静态RAM缓存，而是增加一些高速动态RAM做为缓存，这些高速动态RAM速率要比常规动态RAM快，但比原来的静态RAM缓存慢，把原来的静态RAM缓存叫一级缓存，而把后来增加的动态RAM叫二级缓存。功能作用播报编辑硬盘的缓存主要起三种作用：预读取数据缓存当硬盘受到CPU指令控制开始读取数据时，硬盘上的控制芯片会控制磁头把正在读取的簇的下一个或者几个簇中的数据读到缓存中（由于硬盘上数据存储时是比较连续的，所以读取命中率较高），当需要读取下一个或者几个簇中的数据的时候，硬盘则不需要再次读取数据，直接把缓存中的数据传输到内存中就可以了，由于缓存的速率远远高于磁头读写的速率，所以能够达到明显改善性能的目的。写入缓存(16张)当硬盘接到写入数据的指令之后，并不会马上将数据写入到盘片上，而是先暂时存储在缓存里，然后发送一个“数据已写入”的信号给系统，这时系统就会认为数据已经写入，并继续执行下面的工作，而硬盘则在空闲（不进行读取或写入的时候）时再将缓存中的数据写入到盘片上。虽然对于写入数据的性能有一定提升，但也不可避免地带来了安全隐患——数据还在缓存里的时候突然掉电，那么这些数据就会丢失。对于这个问题，硬盘厂商们自然也有解决办法：掉电时，磁头会借助惯性将缓存中的数据写入零磁道以外的暂存区域，等到下次启动时再将这些数据写入目的地。临时存储有时候，某些数据是会经常需要访问的，像硬盘内部的缓存（暂存器的一种）会将读取比较频繁的一些数据存储在缓存中，再次读取时就可以直接从缓存中直接传输。缓存就像是一台计算机的内存一样，在硬盘读写数据时，负责数据的存储、寄放等功能。这样一来，不仅可以大大减少数据读写的时间以提高硬盘的使用效率。同时利用缓存还可以让硬盘减少频繁的读写，让硬盘更加安静，更加省电。更大的硬盘缓存，你将读取游戏时更快，拷贝文件时候更快，在系统启动中更为领先。硬盘缓存缓存容量的大小不同品牌、不同型号的产品各不相同，早期的硬盘缓存基本都很小，只有几百KB，已无法满足用户的需求。16MB和32MB缓存是现今主流硬盘所采用，而在服务器或特殊应用领域中还有缓存容量更大的产品，甚至达到了64MB、128MB等。大容量的缓存虽然可以在硬盘进行读写工作状态下，让更多的数据存储在缓存中，以提高硬盘的访问速率，但并不意味着缓存越大就越出众。缓存的应用存在一个算法的问题，即便缓存容量很大，而没有一个高效率的算法，那将导致应用中缓存数据的命中率偏低，无法有效发挥出大容量缓存的优势。算法是和缓存容量相辅相成，大容量的缓存需要更为有效率的算法，否则性能会大大折扣，从技术角度上说，高容量缓存的算法是直接影响到硬盘性能发挥的重要因素。更大容量缓存是未来硬盘发展的必然趋势。技术发展播报编辑缓存集群的配置最早先的CPU缓存是个整体的，而且容量很低，英特尔公司从Pentium时代开始把缓存进行了分类。当时集成在CPU内核中的缓存已不足以满足CPU的需求，而制造工艺上的限制又不能大幅度提高缓存的容量。因此出现了集成在与CPU同一块电路板上或主板上的缓存，此时就把CPU内核集成的缓存称为一级缓存，而外部的称为二级缓存。一级缓存中还分数据缓存（DataCache，D-Cache）和指令缓存（InstructionCache，I-Cache）。二者分别用来存放数据和执行这些数据的指令，而且两者可以同时被CPU访问，减少了争用Cache所造成的冲突，提高了处理器效能。英特尔公司在推出Pentium4处理器时，用新增的一种一级追踪缓存替代指令缓存，容量为12KμOps，表示能存储12K条微指令。随着CPU制造工艺的发展，二级缓存也能轻易的集成在CPU内核中，容量也在逐年提升。再用集成在CPU内部与否来定义一、二级缓存，已不确切。而且随着二级缓存被集成入CPU内核中，以往二级缓存与CPU大差距分频的情况也被改变，此时其以相同于主频的速率工作，可以为CPU提供更高的传输速率。二级缓存是CPU性能表现的关键之一，在CPU核心不变化的情况下，增加二级缓存容量能使性能大幅度提高。而同一核心的CPU高低端之分往往也是在二级缓存上有差异，由此可见二级缓存对于CPU的重要性。CPU在缓存中找到有用的数据被称为命中，当缓存中没有CPU所需的数据时（这时称为未命中），CPU才访问内存。从理论上讲，在一颗拥有二级缓存的CPU中，读取一级缓存的命中率为80%。也就是说CPU一级缓存中找到的有用数据占数据总量的80%，剩下的20%从二级缓存中读取。由于不能准确预测将要执行的数据，读取二级缓存的命中率也在80%左右（从二级缓存读到有用的数据占总数据的16%）。那么还有的数据就不得不从内存调用，但这已经是一个相当小的比例了。较高端的CPU中，还会带有三级缓存，它是为读取二级缓存后未命中的数据设计的—种缓存，在拥有三级缓存的CPU中，只有约5%的数据需要从内存中调用[5]，这进一步提高了CPU的效率。为了保证CPU访问时有较高的命中率，缓存中的内容应该按一定的算法替换。一种较常用的算法是“最近最少使用算法”（LRU算法），它是将最近一段时间内最少被访问过的行淘汰出局。因此需要为每行设置一个计数器，LRU算法是把命中行的计数器清零，其他各行计数器加1。当需要替换时淘汰行计数器计数值最大的数据行出局。这是一种高效、科学的算法，其计数器清零过程可以把一些频繁调用后再不需要的数据淘汰出缓存，提高缓存的利用率。CPU产品中，一级缓存的容量基本在4KB到64KB之间，二级缓存的容量则分为128KB、256KB、512KB、1MB、2MB、4MB等。一级缓存容量各产品之间相差不大，而二级缓存容量则是提高CPU性能的关键。二级缓存容量的提升是由CPU制造工艺所决定的，容量增大必然导致CPU内部晶体管数的增加，要在有限的CPU面积上集成更大的缓存，对制造工艺的要求也就越高。主流的CPU二级缓存都在2MB左右，其中英特尔公司07年相继推出了台式机用的4MB、6MB二级缓存的高性能CPU，不过价格也是相对比较高的，对于对配置要求不是太高的朋友，一般的2MB二级缓存的双核CPU基本也可以满足日常上网需要了。2022年，新一代的奔腾处理器采用了与12代酷睿一样的Intel7工艺，但没有大小核架构。参数方面，奔腾G7400为2核4线程，3.7GHz，6MB三级缓存，46WTDP，支持DDR4-3200内存和DDR5-4800内存。核显为UHD710，16EU1.35GHz。[4]主要意义播报编辑缓存的工作方式缓存工作的原则，就是“引用的局部性”，这可以分为时间局部性和空间局部性。空间局部性是指CPU在某一时刻需要某个数据，那么很可能下一步就需要其附近的数据；时间局部性是指当某个数据被访问过一次之后，过不了多久时间就会被再一次访问。对于应用程序而言，不管是指令流还是数据流都会出现引用的局部性现象。举个简单的例子，比如在播放DVD影片的时候，DVD数据由一系列字节组成，这个时候CPU会依次从头处理到尾地调用DVD数据，如果CPU这次读取DVD数据为1分30秒，那么下次读取的时候就会从1分31秒开始，因此这种情况下有序排列的数据都是依次被读入CPU进行处理。从数据上来看，对于Word一类的应用程序通常都有着较好的空间局部性。用户在使用中不会一次打开7、8个文档，不会在其中某一个文档中打上几个词就换另一个。大多数用户都是打开一两个文档，然后就是长时间对它们进行处理而不会做其他事情。这样在内存中的数据都会集中在一个区域中，也就可以被CPU集中处理。从程序代码上来考虑，设计者通常也会尽量避免出现程序的跳跃和分支，让CPU可以不中断地处理大块连续数据。游戏、模拟和多媒体处理程序通常都是这方面的代表，以小段代码连续处理大块数据。不过在办公运用程序中，情况就不一样了。改动字体，改变格式，保存文档，都需要程序代码不同部分起作用，而用到的指令通常都不会在一个连续的区域中。于是CPU就不得不在内存中不断跳来跳去寻找需要的代码。这也就意味着对于办公程序而言，需要较大的缓存来读入大多数经常使用的代码，把它们放在一个连续的区域中。如果缓存不够，就需要内存中的数据，而如果缓存足够大的话，所有的代码都可以放入，也就可以获得最高的效率。同理，高端的数据应用以及游戏应用则需要更高容量的缓存。CPU缓存播报编辑CPU缓存CPU缓存（CacheMemory）是位于CPU与内存之间的临时存储器，它的容量比内存小的多但是交换速率却比内存要快得多。缓存的出现主要是为了解决CPU运算速率与内存读写速率不匹配的矛盾，因为CPU运算速率要比内存读写速率快很多，这样会使CPU花费很长时间等待数据到来或把数据写入内存。在缓存中的数据是内存中的一小部分，但这一小部分是短时间内CPU即将访问的，当CPU调用大量数据时，就可避开内存直接从缓存中调用，从而加快读取速率。由此可见，在CPU中加入缓存是一种高效的解决方案，这样整个内存储器（缓存+内存）就变成了既有缓存的高速率，又有内存的大容量的存储系统了。缓存对CPU的性能影响很大，主要是因为CPU的数据交换顺序和CPU与缓存间的带宽引起的。缓存基本上都是采用SRAM存储器，SRAM是英文StaticRAM的缩写，它是一种具有静态存取功能的存储器，不需要刷新电路即能保存它内部存储的数据。不像DRAM内存那样需要刷新电路，每隔一段时间，固定要对DRAM刷新充电一次，否则内部的数据即会消失，因此SRAM具有较高的性能，但是SRAM也有它的缺点，即它的集成度较低，相同容量的DRAM内存可以设计为较小的体积，但是SRAM却需要很大的体积，这也是不能将缓存容量做得太大的重要原因。它的特点归纳如下：优点是节能、速率快、不必配合内存刷新电路、可提高整体的工作效率，缺点是集成度低、相同的容量体积较大、而且价格较高，只能少量用于关键性系统以提高效率。工作原理1、读取顺序CPU要读取一个数据时，首先从Cache中查找，如果找到就立即读取并送给CPU处理；如果没有找到，就用相对慢的速度从内存中读取并送给CPU处理，同时把这个数据所在的数据块调入Cache中，可以使得以后对整块数据的读取都从Cache中进行，不必再调用内存。正是这样的读取机制使CPU读取Cache的命中率非常高（大多数CPU可达90%左右），也就是说CPU下一次要读取的数据90%都在Cache中，只有大约10%需要从内存读取。这大大节省了CPU直接读取内存的时间，也使CPU读取数据时基本无需等待。总的来说，CPU读取数据的顺序是先Cache后内存。2、缓存分类Intel从Pentium开始将Cache分开，通常分为一级高速缓存L1和二级高速缓存L2。在以往的观念中，L1Cache是集成在CPU中的，被称为片内Cache。在L1中还分数据Cache（D-Cache）和指令Cache（I-Cache）。它们分别用来存放数据和执行这些数据的指令，而且两个Cache可以同时被CPU访问，减少了争用Cache所造成的冲突，提高了处理器效能。3、读取命中率CPU在Cache中找到有用的数据被称为命中，当Cache中没有CPU所需的数据时（这时称为未命中），CPU才访问内存。从理论上讲，在一颗拥有2级Cache的CPU中，读取L1Cache的命中率为80%。也就是说CPU从L1Cache中找到的有用数据占数据总量的80%，剩下的20%从L2Cache读取。由于不能准确预测将要执行的数据，读取L2的命中率也在80%左右（从L2读到有用的数据占总数据的16%）。那么还有的数据就不得不从内存调用，但这已经是一个相当小的比例了。在一些高端领域的CPU（像Intel的Itanium）中，我们常听到L3Cache，它是为读取L2Cache后未命中的数据设计的—种Cache，在拥有L3Cache的CPU中，只有约5%的数据需要从内存中调用，这进一步提高了CPU的效率。一级缓存播报编辑一级缓存（Level1Cache）简称L1Cache，位于CPU内核的旁边，是与CPU结合最为紧密的CPU缓存，也是历史上最早出现的CPU缓存。由于一级缓存的技术难度和制造成本最高，提高容量所带来的技术难度增加和成本增加非常大，所带来的性能提升却不明显，性价比很低，而且现有的一级缓存的命中率已经很高，所以一级缓存是所有缓存中容量最小的，比二级缓存要小得多。一级缓存可以分为一级数据缓存（DataCache，D-Cache）和一级指令缓存（InstructionCache，I-Cache）。二者分别用来存放数据以及对执行这些数据的指令进行即时解码，而且两者可以同时被CPU访问，减少了争用Cache所造成的冲突，提高了处理器效能。大多数CPU的一级数据缓存和一级指令缓存具有相同的容量，例如AMD的AthlonXP就具有64KB的一级数据缓存和64KB的一级指令缓存，其一级缓存就以64KB+64KB来表示，其余的CPU的一级缓存表示方法以此类推。Intel的采用NetBurst架构的CPU（最典型的就是Pentium4）的一级缓存有点特殊，使用了新增加的一种一级追踪缓存（ExecutionTraceCache，T-Cache或ETC）来替代一级指令缓存，容量为12KμOps，表示能存储12K条即12000条解码后的微指令。一级追踪缓存与一级指令缓存的运行机制是不相同的，一级指令缓存只是对指令作即时的解码而并不会储存这些指令，而一级追踪缓存同样会将一些指令作解码，这些指令称为微指令（micro-ops），而这些微指令能储存在一级追踪缓存之内，无需每一次都作出解码的程序，因此一级追踪缓存能有效地增加在高工作频率下对指令的解码能力，而μOps就是micro-ops，也就是微型操作的意思。它以很高的速率将μops提供给处理器核心。IntelNetBurst微型架构使用执行跟踪缓存，将解码器从执行循环中分离出来。这个跟踪缓存以很高的带宽将uops提供给核心，从本质上适于充分利用软件中的指令级并行机制。Intel并没有公布一级追踪缓存的实际容量,只知道一级追踪缓存能储存12000条微指令（micro-ops）。所以，不能简单地用微指令的数目来比较指令缓存的大小。实际上，单核心的NetBurst架构CPU使用8Kμops的缓存已经基本上够用了，多出的4kμops可以大大提高缓存命中率。而要使用超线程技术的话，12KμOps就会有些不够用，这就是为什么有时候Intel处理器在使用超线程技术时会导致性能下降的重要原因。例如Northwood核心的一级缓存为8KB+12KμOps，就表示其一级数据缓存为8KB，一级追踪缓存为12KμOps；而Prescott核心的一级缓存为16KB+12KμOps，就表示其一级数据缓存为16KB，一级追踪缓存为12KμOps。在这里12KμOps绝对不等于12KB，单位都不同，一个是μOps，一个是Byte（字节），而且二者的运行机制完全不同。所以那些把Intel的CPU一级缓存简单相加，例如把Northwood核心说成是20KB一级缓存，把Prescott核心说成是28KB一级缓存，并且据此认为Intel处理器的一级缓存容量远远低于AMD处理器128KB的一级缓存容量的看法是完全错误的，二者不具有可比性。在架构有一定区别的CPU对比中，很多缓存已经难以找到对应的东西，即使类似名称的缓存在设计思路和功能定义上也有区别了，此时不能用简单的算术加法来进行对比；而在架构极为近似的CPU对比中，分别对比各种功能缓存大小才有一定的意义。二级缓存播报编辑二级缓存结构剖析二级缓存（Level2cache），它是处理器内部的一些缓冲存储器，其作用跟内存一样。上溯到上个世纪80年代，由于处理器的运行速率越来越快，慢慢地，处理器需要从内存中读取数据的速率需求就越来越高了。然而内存的速率提升速率却很缓慢，而能高速读写数据的内存价格又非常高昂，不能大量采用。从性能价格比的角度出发，英特尔等处理器设计生产公司想到一个办法，就是用少量的高速内存和大量的低速内存结合使用，共同为处理器提供数据。这样就兼顾了性能和使用成本的最优。而那些高速的内存因为是处于cpu和内存之间的位置，又是临时存放数据的地方，所以就叫做缓冲存储器了，简称“缓存”。它的作用就像仓库中临时堆放货物的地方一样，货物从运输车辆上放下时临时堆放在缓存区中，然后再搬到内部存储区中长时间存放。货物在这段区域中存放的时间很短，就是一个临时货场。最初缓存只有一级，后来处理器速率又提升了，一级缓存不够用了，于是就添加了二级缓存。二级缓存是比一级缓存速率更慢，容量更大的内存，主要就是做一级缓存和内存之间数据临时交换的地方用。为了适应速率更快的处理器p4ee，已经出现了三级缓存了，它的容量更大，速率相对二级缓存也要慢一些，但是比内存可快多了。缓存的出现使得cpu处理器的运行效率得到了大幅度的提升，这个区域中存放的都是cpu频繁要使用的数据，所以缓存越大处理器效率就越高，同时由于缓存的物理结构比内存复杂很多，所以其成本也很高。大量使用二级缓存带来的结果是处理器运行效率的提升和成本价格的大幅度不等比提升。举个例子，服务器上用的至强处理器和普通的p4处理器其内核基本上是一样的，就是二级缓存不同。至强的二级缓存是2mb～16mb，p4的二级缓存是512kb，于是最便宜的至强也比最贵的p4贵，原因就在二级缓存不同。即l2cache。由于l1级高速缓存容量的限制，为了再次提高cpu的运算速率，在cpu外部放置一高速存储器，即二级缓存。工作主频比较灵活，可与cpu同频，也可不同。cpu在读取数据时，先在l1中寻找，再从l2寻找，然后是内存，在后是外存储器。所以l2对系统的影响也不容忽视。最早先的cpu缓存是个整体的，而且容量很低，英特尔公司从pentium时代开始把缓存进行了分类。当时集成在cpu内核中的缓存已不足以满足cpu的需求，而制造工艺上的限制又不能大幅度提高缓存的容量。因此出现了集成在与cpu同一块电路板上或主板上的缓存，此时就把cpu内核集成的缓存称为一级缓存，而外部的称为二级缓存。随着cpu制造工艺的发展，二级缓存也能轻易的集成在cpu内核中，容量也在逐年提升。再用集成在cpu内部与否来定义一、二级缓存，已不确切。而且随着二级缓存被集成入cpu内核中，以往二级缓存与cpu大差距分频的情况也被改变，此时其以相同于主频的速率工作，可以为cpu提供更高的传输速率。三级缓存播报编辑L3Cache(三级缓存)，分为两种，早期的是外置，逐渐都变为内置的。而它的实际作用即是，L3缓存的应用可以进一步降低内存延迟，同时提升大数据量计算时处理器的性能。降低内存延迟和提升大数据量计算能力对游戏都很有帮助。而在服务器领域增加L3缓存在性能方面仍然有显著的提升。比方具有较大L3缓存的配置利用物理内存会更有效，故它比较慢的磁盘I/O子系统可以处理更多的数据请求。具有较大L3缓存的处理器提供更有效的文件系统缓存行为及较短消息和处理器队列长度。其实最早的L3缓存被应用在AMD发布的K6-III处理器上，当时的L3缓存受限于制造工艺，并没有被集成进芯片内部，而是集成在主板上。在只能够和系统总线频率同步的L3缓存同主内存其实差不了多少。后来使用L3缓存的是英特尔为服务器市场所推出的Itanium处理器。接着就是P4EE和至强MP。Intel还打算推出一款9MBL3缓存的Itanium2处理器，和以后24MBL3缓存的双核心Itanium2处理器。但基本上L3缓存对处理器的性能提高显得不是很重要，比方配备1MBL3缓存的XeonMP处理器却仍然不是Opteron的对手，由此可见前端总线的增加，要比缓存增加带来更有效的性能提升。超级缓存播报编辑SuperCache，也就是超级缓存，计算机的速度瓶颈主要在于机械硬盘的读写速度，SuperCache就是给硬盘的读写用高速内存来做缓存，是大内存机器的提速首选，服务器的必备利器。工作原理：对于SuperCache而言，硬盘上没有文件的概念，只是用户指定大小的一个一个小格子，例如32k，硬盘上某个小格子里面的内容被读取了，则被缓存在内存里面，下次还读这个小格子的时候，直接从内存读取，硬盘没有任何动作，从而达到了加速的目的。有两种缓存模式，1、MFU模式，每个小格子被读取的时候，做一个简单的计数，当缓存满的时候，计数值小的先被清出缓存；2、MRU模式，简单的队列，先进先出。系统缓存播报编辑缓存设计将CPU比作一个城里的家具厂，而将存储系统比作郊区的木料厂，那么实际情况就是木料厂离家具厂越来越远，即使使用更大的卡车来运送木料，家具厂也得停工来等待木料送来。在这样的情况下，一种解决方法是在市区建立一个小型仓库，在里面放置一些家具厂最常用到的木料。这个仓库实际上就是家具厂的“Cache”，家具厂就可以从仓库不停的及时运送需要的木料。当然，仓库越大，存放的木料越多，效果就越好，因为这样即使是些不常用的东西也可以在仓库里找到。需要的木料仓库里没有，就要从城外的木料厂里继续找，而家具厂就得等着了。仓库就相对于L1缓存，可以由CPU及时快速的读写，所以存储的是CPU最常用代码和数据（后面会介绍一下如何挑选“最常用”）。L1缓存的速率比系统内存快的多是因为使用的是SRAM，这种内存单晶元使用四到六个晶体管。这也使得SRAM的造价相当的高，所以不能拿来用在整个存储系统上。在大多数CPU上，L1缓存和核心一起在一块芯片上。在家具厂的例子中，就好比工厂和仓库在同一条街上。这样的设计使CPU可以从最近最快的地方得到数据，但是也使得“城外的木料厂”到“仓库”和到“家具厂”的距离差不多远。这样CPU需要的数据不在L1缓存中，也就是“CacheMiss”，从存储设备取数据就要很长时间了。处理器速率越快，两者之间的差距就越大。使用Pentium4那样的高频率处理器，从内存中取得数据就相当于“木料厂”位于另一个国家。其实，缓存是CPU的一部分，它存在于CPU中CPU存取数据的速率非常的快，一秒钟能够存取、处理十亿条指令和数据（术语：CPU主频1G），而内存就慢很多，快的内存能够达到几十兆就不错了，可见两者的速率差异是多么的大缓存是为了解决CPU速率和内存速率的速率差异问题内存中被CPU访问最频繁的数据和指令被复制入CPU中的缓存，这样CPU就可以不经常到象“蜗牛”一样慢的内存中去取数据了，CPU只要到缓存中去取就行了，而缓存的速率要比内存快很多。这里要特别指出的是：1因为缓存只是内存中少部分数据的复制品，所以CPU到缓存中寻找数据时，也会出现找不到的情况（因为这些数据没有从内存复制到缓存中去），这时CPU还是会到内存中去找数据，这样系统的速率就慢下来了，不过CPU会把这些数据复制到缓存中去，以便下一次不要再到内存中去取。2因为随着时间的变化，被访问得最频繁的数据不是一成不变的，也就是说，刚才还不频繁的数据，此时已经需要被频繁的访问，刚才还是最频繁的数据，后来又不频繁了，所以说缓存中的数据要经常按照一定的算法来更换，这样才能保证缓存中的数据是被访问最频繁的。3关于一级缓存和二级缓存为了分清这两个概念，我们先了解一下RAMram和ROM相对的，RAM是掉电以后，其中信息才消失的那一种，ROM是在掉电以后信息也不会消失的那一种。RAM又分两种：一种是静态RAM、SRAM；一种是动态RAM、DRAM。磁盘缓存播报编辑磁盘缓存磁盘缓存分为读缓存和写缓存。读缓存是指，操作系统为已读取的文件数据，在内存较空闲的情况下留在内存空间中（这个内存空间被称之为“内存池”），当下次软件或用户再次读取同一文件时就不必重新从磁盘上读取，从而提高速率。写缓存实际上就是将要写入磁盘的数据先保存于系统为写缓存分配的内存空间中，当保存到内存池中的数据达到一个程度时，便将数据保存到硬盘中。这样可以减少实际的磁盘操作，有效的保护磁盘免于重复的读写操作而导致的损坏，也能减少写入所需的时间。根据写入方式的不同，有写通式和回写式两种。写通式在读硬盘数据时，系统先检查请求指令，看看所要的数据是否在缓存中，在的话就由缓存送出响应的数据，这个过程称为命中。这样系统就不必访问硬盘中的数据，由于SDRAM的速率比磁介质快很多，因此也就加快了数据传输的速率。回写式就是在写入硬盘数据时也在缓存中找，找到就由缓存就数据写入盘中，多数硬盘都是采用的回写式缓存，这样就大大提高了性能。缓存英文名为Cache。CPU缓存也是内存的一种，其数据交换速率快且运算频率高。磁盘缓存则是操作系统为磁盘输入输出而在普通物理内存中分配的一块内存区域。硬盘的缓冲区，硬盘的缓冲区是硬盘与外部总线交换数据的场所。硬盘的读数据的过程是将磁信号转化为电信号后，通过缓冲区一次次地填充与清空，再填充，再清空，一步步按照PCI总线的周期送出，可见，缓冲区的作用是相当重要的。它的作用也是提高性能，但是它与缓存的不同之处在于：一它是容量固定的硬件，而不像缓存是可以由操作系统在内存中动态分配的。二它对性能的影响大大超过磁盘缓存对性能的影响，因为没有缓冲区，就会要求每传一个字（通常是4字节）就需要读一次磁盘或写一次磁盘。缓存映射播报编辑高速缓存可以被分为直接映射缓存，组相联缓存和全相联缓存。直接映射缓存缓存的映射这种缓存中，每个组只有一行，E=1，结构很简单，整个缓存就相当于关于组的一维数组。不命中时的行替换也很简单，就一个行嘛，哪不命中替换哪。为了适应容量小的情况，第n+1层存储器中的某个数据块，你只能被替换到上一层（也就是第n层）存储器中的某个位置的子集中。假设一个直接映射的高速缓存，（S，E，B，m)=(4,1,2,4)，也就是说，地址是4位（16个），有四个组，每个组一行，每个块两个字节。由于有16个地址，表征16个字节，所以总共有8个块，但只有4个组，也就是4行。只能把多个块映射到相同的缓存组，比如0和4都映射到组1，1和5都映射到组2，等等。这下问题就来了，比如先读块0，此时块0的数据被cache到组0。然后我再读块4，因为块4也是被映射到组0的，组0又只有一行，那就只有把以前块0的数据覆盖了，要是之后我又读块0，就数据丢失了，只能到下级的存储器去找。实际的循环程序中，很容易引起这种情况，称其为抖动。这种情况的存在，自然大大影响了性能。所以，需要更好的映射方案。组相联缓存在组相联缓存里，E大于1，就是说一个组里面有多个cacheline。E等于多少，就叫有多少路，所以叫E路组相联。组相联的行匹配就要复杂一些了，因为要检查多个行的标记位和有效位。如果最终找到了，还好。当然，找不到会从下一级存储器中取出包含所需求数据的行来替换，但一个组里面这么多行，替换哪个行。如果有一个空行，自然就是替换空行，如果没有空行，那就引发了一些其他的替换策略了。除了刚才介绍过的随机策略，还有最不常使用策略，最近最少使用策略。这些策略本身是需要一定开销的，但要知道，不命中的开销是很大的，所以为了保证命中率，采取一些相对复杂的策略是值得的。全相联缓存所谓全相联，就是由一个包含所有缓存行的组组成的缓存（块可以放在高速缓存中的任意位置）[2]。由于只有一个组，所以组选择特别简单，此时地址就没有组索引了，只有标记和偏移，也就是t部分和b部分。其他的步骤，行匹配和数据选择，和组相联原理是一样的，只是规模大得多了。如果说上面关于这三种映射方法的描述非常抽象，为了能理解得更加透彻，把存储器比作一家大超市，超市里面的东西就是一个个字节或者数据。为了让好吃好玩受欢迎的东西能够容易被看到，超市可以将这些东西集中在一块放在一个专门的推荐柜台中，这个柜台就是缓存。如果仅仅是把这些货物放在柜台中即完事，那么这种就是完全关联的方式。可是如果想寻找自己想要的东西，还得在这些推荐货物中寻找，而且由于位置不定，甚至可能把整个推荐柜台寻找个遍，这样的效率无疑还是不高的。于是超市老总决定采用另一种方式，即将所有推荐货物分为许多类别，如“果酱饼干”，“巧克力饼干”，“核桃牛奶”等，柜台的每一层存放一种货物。这就是直接关联的访问原理。这样的好处是容易让顾客有的放矢，寻找更快捷，更有效。但这种方法还是有其缺点，那就是如果需要果酱饼干的顾客很多，需要巧克力饼干的顾客相对较少，显然对果酱饼干的需求量会远多于对巧克力饼干的需求量，可是放置两种饼干的空间是一样大的，于是可能出现这种情况：存放的果酱饼干的空间远不能满足市场需求的数量，而巧克力饼干的存放空间却被闲置。为了克服这个弊病，老板决定改进存货方法：还是将货物分类存放，不过分类方法有所变化，按“饼干”，“牛奶”，“果汁”等类别存货，也就是说，无论是什么饼干都能存入“饼干”所用空间中，这种方法显然提高了空间利用的充分性，让存储以及查找方法更有弹性。技术指标播报编辑CPU缓存CPU产品中，一级缓存的容量基本在4kb到64kb之间，二级缓存的容量则分为128kb、256kb、512kb、1mb、2mb等。一级缓存容量各产品之间相差不大，而二级缓存容量则是提高cpu性能的关键。二级缓存容量的提升是由cpu制造工艺所决定的，容量增大必然导致cpu内部晶体管数的增加，要在有限的cpu面积上集成更大的缓存，对制造工艺的要求也就越高缓存(cache)大小是CPU的重要指标之一，其结构与大小对CPU速率的影响非常大。简单地讲，缓存就是用来存储一些常用或即将用到的数据或指令，当需要这些数据或指令的时候直接从缓存中读取，这样比到内存甚至硬盘中读取要快得多，能够大幅度提升cpu的处理速率。所谓处理器缓存，通常指的是二级高速缓存，或外部高速缓存。即高速缓冲存储器，是位于CPU和主存储器dram(dynamicram)之间的规模较小的但速率很高的存储器，通常由sram（静态随机存储器）组成。用来存放那些被cpu频繁使用的数据，以便使cpu不必依赖于速率较慢的dram（动态随机存储器）。l2高速缓存一直都属于速率极快而价格也相当昂贵的一类内存，称为sram(静态ram)，sram(staticram)是静态存储器的英文缩写。由于sram采用了与制作cpu相同的半导体工艺，因此与动态存储器dram比较，sram的存取速率快，但体积较大，价格很高。处理器缓存的基本思想是用少量的sram作为cpu与dram存储系统之间的缓冲区，即cache系统。80486以及更高档微处理器的一个显著特点是处理器芯片内集成了sram作为cache，由于这些cache装在芯片内，因此称为片内cache。486芯片内cache的容量通常为8k。高档芯片如pentium为16kb，powerpc可达32kb。pentium微处理器进一步改进片内cache，采用数据和双通道cache技术，相对而言，片内cache的容量不大，但是非常灵活、方便，极大地提高了微处理器的性能。片内cache也称为一级cache。由于486，586等高档处理器的时钟频率很高，一旦出现一级cache未命中的情况，性能将明显恶化。在这种情况下采用的办法是在处理器芯片之外再加cache，称为二级cache。二级cache实际上是cpu和主存之间的真正缓冲。由于系统板上的响应时间远低于cpu的速率，没有二级cache就不可能达到486，586等高档处理器的理想速率。二级cache的容量通常应比一级cache大一个数量级以上。在系统设置中，常要求用户确定二级cache是否安装及尺寸大小等。二级cache的大小一般为128kb、256kb或512kb。在486以上档次的微机中，普遍采用256kb或512kb同步cache。所谓同步是指cache和cpu采用了相同的时钟周期，以相同的速率同步工作。相对于异步cache，性能可提高30%以上。pc及其服务器系统的发展趋势之一是cpu主频越做越高，系统架构越做越先进，而主存dram的结构和存取时间改进较慢。因此，缓存（cache）技术愈显重要，在pc系统中cache越做越大。广大用户已把cache做为评价和选购pc系统的一个重要指标。光驱缓存播报编辑光存储驱动器都带有内部缓冲器或高速缓存存储器。这些缓冲器是实际的存储芯片，安装在驱动器的电路板上，它在发送数据给PC之前可能准备或存储更大的数据段。CD/DVD典型的缓冲器大小为128KB，不过具体的驱动器可大可小（通常越多越好）。可刻录CD或DVD驱动器一般具有2MB-4MB以上的大容量缓冲器，用于防止缓存欠载（bufferunderrun）错误，同时可以使刻录工作平稳、恒定的写入。一般来说，驱动器越快，就有更多的缓冲存储器，以处理更高的传输速率。CD/DVD驱动器带有缓冲或高速缓存具有很多好处。缓冲可以保证PC以固定速率接收数据。当一个应用程序从驱动器请求数据时，数据可能位于分散在光盘上不同地方。因为驱动器的访问速率相对较慢，在数据读取时会使驱动器不得不间隔性向PC发送数据。驱动器的缓冲在软件的控制下可以预先读取并准备光盘的内容目录，从而加速第一次数据请求。光驱读取数据的规律是首先在缓存里寻找，如果在缓存中没有找到才会去光盘上寻找，大容量的缓存可以预先读取的数据越多，但在实际应用中CD-ROM、DVD-ROM等读取操作时，读取重复信息的机会是相对较少的，大部分的光盘更多的时候是一次读取数量较多的文件内容，因此在CD-ROM、DVD-ROM驱动器上缓存重要性得不到体现，因此大多此类产品采用较小的缓存容量。CD-ROM一般有128KB、256KB、512KB几种；而DVD一般有128KB、256KB、512KB，只有个别的外置式DVD光驱采用了较大容量的缓存。在刻录机或COMMBO产品上，缓存就变得十分重要了。在刻录光盘时，系统会把需要刻录的数据预先读取到缓存中，然后再从缓存读取数据进行刻录，缓存就是数据和刻录盘之间的桥梁。系统在传输数据到缓存的过程中，不可避免的会发生传输的停顿，如在刻录大量小容量文件时，硬盘读取的速率很可能会跟不上刻录的速率，就会造成缓存内的数据输入输出不成比例，如果这种状态持续一段时间，就会导致缓存内的数据被全部输出，而得不到输入，此时就会造成缓存欠载错误，这样就会导致刻录光盘失败。因此刻录机和COMMBO产品都会采用较大容量的缓存容量，再配合防刻死技术，就能把刻坏盘的几率降到最低。同时缓存还能协调数据传输速率，保证数据传输的稳定性和可靠性。刻录机产品一般有2MB、4MB、8MB，COMBO产品一般有2MB、4MB、8MB的缓存容量，受制造成本的限制，缓存不可能制作到足够大，但适量的缓存容量还是选择光储需要考虑的关键之一。网络缓存播报编辑概念WWW是互联网上最受欢迎的应用之一，其快速增长造成网络拥塞和服务器超载，导致客户访问延迟增大，WWW服务质量日益显现出来。缓存技术被认为是减轻服务器负载、降低网络拥塞、增强WWW可扩展性的有效途径之一，其基本思想是利用客户访问的时间局部性（TemproralLocality）原理，将客户访问过的内容在Cache中存放一个副本，当该内容下次被访问时，不必连接到驻留网站，而是由Cache中保留的副本提供。Web内容可以缓存在客户端、代理服务器以及服务器端。研究表明，缓存技术可以显著地提高WWW性能，它可以带来以下好处：（1）减少网络流量，从而减轻拥塞。（2）降低客户访问延迟，其主要原因有：①缓存在代理服务器中的内容，客户可以直接从代理获取而不是从远程服务器获取，从而减小了传输延迟；②没有被缓存的内容由于网络拥塞及服务器负载的减轻而可以较快地被客户获取。（3）由于客户的部分请求内容可以从代理处获取，从而减轻了远程服务器负载。（4）如果由于远程服务器故障或者网络故障造成远程服务器无法响应客户的请求，客户可以从代理中获取缓存的内容副本，使得WWW服务的鲁棒性得到了加强。Web缓存系统也会带来以下问题：（1）客户通过代理获取的可能是过时的内容。（2）如果发生缓存失效，客户的访问延迟由于额外的代理处理开销而增加。因此在设计Web缓存系统时，应力求做到Cache命中率最大化和失效代价最小化。（3）代理可能成为瓶颈。因此应为一个代理设定一个服务客户数量上限及一个服务效率下限，使得一个代理系统的效率至少同客户直接和远程服务器相连的效率一样。影响Internet访问速率访问网站的过程是通过建立在TCP/IP协议之上的HTTP协议来完成的。从客户端发出一个HTTP请求开始，用户所经历的等待时间主要决定于DNS和网站的响应时间。网站域名首先必须被DNS服务器解析为IP地址，HTTP的延时则由在客户端和服务器间的若干个往返时间所决定。往返时间是指客户端等待每次请求的响应时间，平均往返时间取决于三个方面：网站服务器的延时网站服务器造成的延时在往返时间中占主要比例。当某个服务器收到多个并发HTTP请求时，会产生排队延时。由于响应一个HTTP请求，往往需要多次访问本地硬盘，所以即使是一台负载并不大的服务器，也可能产生几十或几百微秒的延时。由路由器、网关、代理服务器和防火墙引入的延时通常在客户端和服务器之间的路径上会存在多个网络设备，如路由器、网关、代理和防火墙等。它们对经过的IP包都要做存储/转发的操作，于是会引入排队延时和处理延时。在网络拥塞时，这些设备甚至会丢包，此时会寄希望于客户端和服务器通过端到端的协议来恢复通信。不同通信链路上的数据传输速率在广域网中，从一个网络设备到另一个网络设备间的数据传输速率是决定往返时间的一个重要因素。但基本带宽的作用并不是像人们想象的那么重要，一项测试表明，当网站采用T3速率接入Internet时，也仅有2%的网页或对象能以64kbps的速率提供给客户端，这显然表明，带宽在网络性能上不是最关键的因素。Internet在向世界的每一个角落延伸，用户向一个服务器发出的请求可能会经过8000公里到1.6万公里的距离，光速带来的延时和网络设备的延时是网络如此缓慢的最根本原因。网络缓存解决根本问题既然影响网络速率的原因是由距离和光速引起，那么加速Web访问的唯一途径就是缩短客户端与网站之间的距离。通过将用户频繁访问的页面和对象存放在离用户更近的地方，才能减少光速引入的延时，同时由于减少了路由中的环节，也相应地减少了路由器、防火墙和代理等引入的延时。传统的解决办法是建立镜像服务器来达到缩短距离的目的。但这个办法存在很大的不足，对于某个站点而言，不可能在离每个用户群较近的地方都建立镜像站点，若对大多数网站都用这样的办法就更不经济，同时管理和维护镜像站点是一项非常困难的工作。网络缓存是一种降低Internet流量和提高终端用户响应时间的新兴网络技术。它的观念来自于计算机和网络的其他领域，如流行的Intel架构的CPU中就存在缓存，用于提高内存存取的速率；各种操作系统在进行磁盘存取时也会利用缓存来提高速率；分布式文件系统通常也通过缓存来提高客户机和服务器之间的速率。类型静态页面的缓存可能有2种形式：其实主要区别就是CMS是否自己负责关联内容的缓存更新管理。1静态缓存：是在新内容发布的同时就立刻生成相应内容的静态页面，比如：2003年3月22日，管理员通过后台内容管理界面录入一篇文章后，并同步更新相关索引页上的链接。2动态缓存：是在新内容发布以后，并不预先生成相应的静态页面，直到对相应内容发出请求时，如果前台缓存服务器找不到相应缓存，就向后台内容管理服务器发出请求，后台系统会生成相应内容的静态页面，用户第一次访问页面时可能会慢一点，但是以后就是直接访问缓存了。静态缓存的缺点：网络缓存系统结构图复杂的触发更新机制：这两种机制在内容管理系统比较简单的时候都是非常适用的。但对于一个关系比较网络缓存系统结构图复杂的网站来说，页面之间的逻辑引用关系就成为一个非常非常复杂的问题。最典型的例子就是一条新闻要同时在新闻首页和相关的3个新闻专题中出现，在静态缓存模式中，每发一篇新文章，除了这篇新闻内容本身的页面外，还需要系统通过触发器生成多个新的相关静态页面，这些相关逻辑的触发也往往就会成为内容管理系统中最复杂的部分之一。旧内容的批量更新：通过静态缓存发布的内容，对于以前生成的静态页面的内容很难修改，这样用户访问旧页面时，新的模板根本无法生效。在动态缓存模式中，每个动态页面只需要关心，而相关的其他页面能自动更新，从而大大减少了设计相关页面更新触发器的需要。网络缓存可以在客户端，也可以在网络上，由此我们将缓存分为两类：浏览器缓存和代理缓存。几乎所有的浏览器都有一个内置的缓存，它们通常利用客户端本地的内存和硬盘来完成缓存工作，同时允许用户对缓存的内容大小作控制。浏览器缓存是网络缓存的一个极端的情况，因为缓存设在客户机本地。通常一个客户端只有一个用户或几个共享计算机用户，浏览器缓存要求的硬盘空间通常在5MB到50MB的范围内。但是浏览器缓存在用户之间难以共享，不同客户端的缓存无法实现交流，因而缓存的内容与效果相当有限。代理缓存则是一种独立的应用层网络服务,它更像E－mail、Web、DNS等服务。许多用户不仅可以共享缓存，而且可以同时访问缓存中的内容。企业级代理缓存一般需要配置高端的处理器和存储系统，采用专用的软件，要求的硬盘空间在5MB到50GB左右，内存为64MB到512MB。代理处于客户端与网站服务器之间,在某些情况下，这种连接是不允许的，如网站在防火墙内,这时客户端必须与代理建立TCP连接，然后由代理建立与网站服务器的TCP连接。代理在服务器和客户端之间起到了数据接力的作用。代理发出的HTTP请求与一般的HTTP请求有细小的不同，主要在于它包含了完整的URL，而不只是URL的路径。代理缓存的工作原理当代理缓存收到客户端的请求时，它首先检查所请求的内容是否已经被缓存。如果没有找到，缓存必须以客户端的名义转发请求，并在收到服务器发出的文件时，将它以一定的形式保存在本地硬盘，并将其发送给客户端。如果客户端请求的内容已被缓存，还存在两种可能：其一，缓存的内容已经过时，即缓存中保存的内容超过了预先设定的时限，或网站服务器的网页已经更新，这时缓存会要求原服务器验证缓存中的内容，要么更新内容，要么返回“未修改”的消息；其二，缓存的内容是新的，即与原网站的内容保持同步，此时称为缓存命中，这时缓存会立即将已保存的内容送给客户端。在客户端的请求没有命中时，反而增加了缓存存储和转发的处理时间。在这种情况下，代理缓存是否仍有意义呢？实际上，代理缓存能够同时与网站服务器建立多个并发的TCP/IP连接，并行获取网站上的内容。缓存的存在从整体上降低了对网站访问的次数，也就降低了单位时间内服务器端的排队数目，因而这时并发连接的排队延时要小得多。优秀的缓存甚至能实现对网页内相关链接内容的预取以加快连接的速率。代理缓存的策略当原服务器的文件修改或被删除后，缓存又如何知道它保存的拷贝已经作废呢？HTTP协议为缓存服务提供了基本的支持，它使缓存能向原服务器查询，某个文件是否更改,如果缓存的拷贝过时则进行有条件下载。仅当原服务器文件超过指定的日期时，才会发出新的文件。但是这些询问操作对网络服务器造成的负载几乎和获取该文件差不多,因此不可能在客户端向缓存发起请求时都执行这样的操作。HTTP协议使得服务器可以有选择地为每个文档指定生存时间,即清楚地指出某个文件的有效生命周期，生存时间很短即意味着“不要对其缓存”。拷贝的保留时间可以是固定的，也可以是通过这个文件的大小、来源、生存时间或内容计算出来的。[3]分布缓存播报编辑分布式缓存系统是为了解决数据库服务器和web服务器之间的瓶颈。如果一个网站的流量很大，这个瓶颈将会非常明显，每次数据库查询耗费的时间将会非常可观。对于更新速度不是很快的网站，我们可以用静态化来避免过多的数据库查询。对于更新速度以秒计的网站，静态化也不会太理想，可以用缓存系统来构建。如果只是单台服务器用作缓存，问题不会太复杂，如果有多台服务器用作缓存，就要考虑缓存服务器的负载均衡。使用Memcached分布式缓存服务来达到保存用户的会话数据，而达到各个功能模块都能够跨省份、跨服务器共享本次会话中的私有数据的目的。每个省份使用一台服务器来做为Memcached服务器来存储用话的会话中的数据，当然也可以多台服务器，但必须确保每个省份的做Memcached服务器数量必须一致，这样才能够保证Memcached客户端操作的是同一份数据，保证数据的一致性。会话数据的添加、删除、修改Memcached客户端，添加、删除和、修改会话信息数据时，不仅要添加、删除、修改本省的Memcached服务器数据，而且同时要对其它省份的Memcahed服务器做同样的操作，这样用户访问其它省份的服务器的功能模块进也能读取到相同的会话数据。Memcached客户端服务器的列表使用局域网的内网IP（如：192.168.1.179）操作本省的Memcahed服务器，使用公网的IP（（如：202.183.62.210））操作其它省份的Memcahe服务器。会话数据的读取系统所有模块读取会话数据的Memcached客户端服务器列表都设为本省Memcached服务器地址的内网IP来向Memcahed服务器中读取会话数据。同一会话的确认使用Cookie来保持客户与服务端的联系。每一次会话开始就生成一个GUID作为SessionID，保存在客户端的Cookie中，作用域是顶级域名，这样二级、三级域名就可以共享到这个Cookie，系统中就使用这个SessionID来确认它是否是同一个会话。会话数据的唯一ID会话数据存储在Memcached服务器上的唯一键Key也就是会话数据数据的唯一ID定义为：SessionID_Name,SessionID就是保存在客户端Cookie中的SessionID,Name就是会话数据的名称，同一次会话中各个会话数据的Name必须是唯一的，否则新的会话数据将覆盖旧的会话数据。会话的失效时间会话的失效通过控制Cookie的有效时间来实现，会话的时间设为SessionID或Cookie中的有效时间，且每一次访问SessionID时都要重新设置一下Cookie的有效时间，这样就达到的会话的有效时间就是两次间访问Cookie中SessionID值的的最长时间，如果两次访问的间隔时间超过用效时间，保存在SessionID的Cookie将会失效，并生成新的SessionID存放在Cookie中,SessionID改变啦，会话就结束啦。Memcached服务器中会话数据的失效，每一次向Memcache服务器中添加会话数据时，都把有效时间设为一天也就是24小时，让Memcached服务使用它内部的机制去清除，不必在程序中特别做会话数据的删除操作。数据在Memcache服务器中有有效时间只是逻辑上的，就算是过了24小时，如果分配给Memcached服务的内存还够用的话，数据还是保存在内存当中的，只是Memcache客户端读取不到而已。只有到了分配给Memcached服务的内存不够用时，它才会清理没用或者比较旧的数据，也就是懒性清除。增加缓存的方法播报编辑CPU的缓存CPU的缓存分二级：L1（一级缓存）和L2（二级缓存），当处理器要读取数据时，首先要在L1缓存中查找，其次才是L2缓存，最后才是系统内存。如果有一天你发觉自己的电脑慢了很多，进入到Windows桌面也要几分钟，这时候就要检查一下CPU的一、二级缓存有没有打开。在BIOS设置中的StandardCMOSSetup（标准CMOS设定）有两项是用来打开或关闭缓存的：CPUInternalCache设为Enable时开启CPU内部的一级缓冲区，若设置为Disabl则为关闭，这时系统性能将大大降低；ExternalCache选项是控制主板上二级缓冲区，如果主板上有二级缓存则应设成Enable。硬盘的缓存点击电脑桌面上的“开始”/“运行”，键入“Msconfig”启动“系统配置实用程序”，跟着选中“system．ini”标签下的“Vcache”项，就可以根据系统的实际情况来调节硬盘的缓存了。在该选项中一般会有三行内容：ChunkSize=1024、MaxFileCache=10240和MinFileCache=10240；其中第一行是缓冲区读写单元值，第二、三行是硬盘的最大和最小缓冲值，等号后的数值都是可以修改的，只要右键单击选中任一行就可以进行修改了。如果你的内存是128MB的话，上面这三行的取值就比较合理了，当然也可以自定。如果不知道该如何设置合适的缓冲值，请“Windows优化大师”帮忙吧，这个软件中有一个“磁盘缓存优化”项，用鼠标就可以方便地设置好缓存；又或者让“Windows优化大师”自动帮你进行优化设置。当硬盘的缓存值足够大时，硬盘就不用频繁地读写磁盘，一来可以延长硬盘的寿命，二来也可以提高数据的传输速度。另外，将硬盘的“文件系统缓存”设置为“网络服务器”，可以加快系统对硬盘的访问速度，因为文件系统缓存里存放了硬盘最近被访问过的文件名和路径，缓存越大所能储存的内容也就越多。如果点击“控制面板”/“系统”/“性能”/“文件系统”/“硬盘”，将“此计算机的主要用途”由“台式机”改为“网络服务器”，可以将原来10K左右的缓存增加至近50K左右。软驱和光驱的缓存一般来说，软驱读写数据的速度都比较慢，这是因为盘片的转速不能太高，但是，我们可以提高软驱的读写缓存，让软驱一次读写更多的数据。方法是：在桌面上的“开始”/“运行”框中键入“Regedit”运行注册表编辑器，依次进入HKEY－LOCAL－MACHINE\System\CurrentControlSet\Services\Class\FDC\0000，新建一个为ForeFifo的“DWORD值”，将其值设为“0”，这样就对软驱进行了软提速。很多人都知道右键单击桌面“我的电脑”图标，选“属性”/“性能”/“文件系统”/“CD－ROM”，将最佳的访问方式设为“四倍速或更高速”，将追加的高速缓存大小滑块拖到最大处，可以明显提高光驱的读盘速度。除了这种方式，我们还可以在注册表中设置缓冲值，方法是：进入到注册表，在HKEY－LOCAL－MACHINE\System\CurrentControlSet\Control\FileSystem\CDFS下，将CacheSize（缓存值的大小）和Prefetch（预读文件大小）两项进行手工调整，只要右键单击要选的项就可以进行修改了。[3]总线仲裁：简介播报编辑总线上的设备一般分为总线主设备和总线从设备。总线主设备是指具有控制总线能力的模块，通常是CPU或以CPU为中心的逻辑模块，在获得总线控制权之后能启动数据信息的传输；与之相对应的总线从设备，是指能够对总线上的数据请求做出响应，但本身不具备总线控制能力的模块。在早期的计算机系统中，一条总线上只有一个主设备，总线一直由它占用，技术简单，实现也比较容易。随着应用的发展，主要是工业控制、科学计算的需求，多个主设备共享总线的情况越来越多，这对总线技术提出了新的要求。根据这类系统的特点，需要解决各个主设备之间资源争用等问题，这使得总线的复杂性大为增加。总线仲裁就是在多个总线主设备的环境中提出来的。在多处理机系统中，每个处理机都可以作为总线主设备，都要共享资源，它们都必须通过系统总线才能访问其它资源，总线也可视为是一种重要的公共资源。由于每个处理机都会随机地提出对总线使用的要求，这样就可能发生总线竞争现象。为了防止多个处理机同时控制总线，就要在总线上设立一个处理上述总线竞争的机构，按优先级次序，合理地分配资源，这就是总线仲裁问题。用硬件来实现总线分配的逻辑电路称为总线仲裁器(BusArbiter)。它的任务是响应总线请求，通过对分配过程的正确控制，达到最佳使用总线。总线判优控制按照仲裁控制机构的设置可分为集中控制和分散控制两种。其中就集中控制而言，常用的总线仲裁方式有：菊花链仲裁、二维仲裁、同步通信方式、异步通信方式和半同步通信方式。连接到总线上的功能模块有主动和被动两种形态，CPU可以做主方也可以做从方，而存取器模块只能用作从方。主方可以启动一个总线周期，而从方只能响应主方的请求。对多个主设备提出的占用总线请求，一般采用优先级或公平策略进行仲裁[1]。仲裁方式分类播报编辑按照总线仲裁电路的位置不同，仲裁方式分为集中式仲裁和分布式仲裁两类：1.集中式总线仲裁的控制逻辑基本集中在一处，需要中央仲裁器，分为链式查询方式、计数器定时查询方式、独立请求方式；(1)链式查询方式链式查询方式的主要特点：总线授权信号BG串行地从一个I/O接口传送到下一个I/O接口。假如BG到达的接口无总线请求，则继续往下查询；假如BG到达的接口有总线请求，BG信号便不再往下查询，该I/O接口获得了总线控制权。离中央仲裁器最近的设备具有最高优先级，通过接口的优先级排队电路来实现。链式查询方式的优点:只用很少几根线就能按一定优先次序实现总线仲裁，很容易扩充设备。链式查询方式的缺点:对询问链的电路故障很敏感，如果第i个设备的接口中有关链的电路有故障，那么第i个以后的设备都不能进行工作。查询链的优先级是固定的，如果优先级高的设备出现频繁的请求时，优先级较低的设备可能长期不能使用总线。(2)计数器定时查询方式总线上的任一设备要求使用总线时，通过BR线发出总线请求。中央仲裁器接到请求信号以后，在BS线为“0”的情况下让计数器开始计数，计数值通过一组地址线发向各设备。每个设备接口都有一个设备地址判别电路，当地址线上的计数值与请求总线的设备地址相一致时，该设备置“1”BS线，获得了总线使用权，此时中止计数查询。每次计数可以从“0”开始，也可以从中止点开始。如果从“0”开始，各设备的优先次序与链式查询法相同，优先级的顺序是固定的。如果从中止点开始，则每个设备使用总线的优先级相等。计数器的初值也可用程序来设置，这可以方便地改变优先次序，但这种灵活性是以增加线数为代价的。(3)独立请求方式每一个共享总线的设备均有一对总线请求线BRi和总线授权线BGi。当设备要求使用总线时，便发出该设备的请求信号。中央仲裁器中的排队电路决定首先响应哪个设备的请求，给设备以授权信号BGi。独立请求方式的优点：响应时间快，确定优先响应的设备所花费的时间少，用不着一个设备接一个设备地查询。其次，对优先次序的控制相当灵活，可以预先固定也可以通过程序来改变优先次序；还可以用屏蔽(禁止)某个请求的办法，不响应来自无效设备的请求。2.分布式仲裁不需要中央仲裁器，每个潜在的主方功能模块都有自己的仲裁号和仲裁器。当它们有总线请求时，把它们唯一的仲裁号发送到共享的仲裁总线上，每个仲裁器将仲裁总线上得到的号与自己的号进行比较。如果仲裁总线上的号大，则它的总线请求不予响应，并撤消它的仲裁号。最后，获胜者的仲裁号保留在仲裁总线上。显然，分布式仲裁是以优先级仲裁策略为基础[2]。总线分配技术播报编辑对总线仲裁问题的解决是以优先级(又称优先权)的概念为基础的，通常有三种总线分配的优先级技术──串联、并联和循环。串联优先级判别法图1串联优先级判别法图1中有Ⅰ、Ⅱ、…、N等N个模块，都可作为总线主设备，各个模块中的“请求”输出端采用集电极(漏极)开路门，“请求”端用“线或”方式接到仲裁器“请求”输入端，每个模块的“忙”端同仲裁器的“总线忙”状态线相连，这是一个输入输出双向信号线。当一个模块占有总线控制权时，该模块的“忙”信号端成为输出端，向系统的“忙”状态线送出有效信号(例如低电平)。其它模块的“忙”信号端全部作为输入端工作，检测“忙”线上状态。一个模块若要提出总线“请求”，其必要条件是选检测到“忙”信号输入端处于无效状态。与此相应，仲裁器接受总线请求输入的条件，也是“忙”线处于无效状态。进一步可以规定仲裁器输出“允许”信号的条件首先是“忙”线无效，表示总线没有被任一模块占用；其次才是有模块提出了总线请求。“允许”信号在链接的模块之间传输，直到提出总线“请求”的那个模块为止。这里用“允许”信号的边沿触发，它把共享总线的各模块要使用总线时，便发生信号禁止后面的部件使用总线。通过这种方式，就确定了请求总线各模块中优先级最高的模块。显然，在这种方式中，当优先级高的模块频繁请求时，优先级别低的模块可能很长时间都无法获得总线。一旦有模块占用总线后，“允许”信号就不再存在。并联优先级别判别法图2并联优先级别判别法图2中有N个模块，都可作为总线主设备，每个模块都有总线“请求”线和总线“允许”线，模块之间是独立的，没有任何控制关系。这些信号接到总线优先控制器(仲裁器)，任一模块使用总线，都要通过“请求”线向仲裁器发出“请求”信号。仲裁器一般由一个优先级编码器和一个译码器组成。该电路接到某个模块或多个模块发来的请求信号后，首先优先级编码器进行编码，然后由译码器产生相应的输出信号，发往请求总线模块中优先级最高的模块，并把“允许”信号送给该模块。被选中的模块撤销总线“请求”信号，输出总线“忙”信号，通知其余模块，总线已经占用。在一个模块占用总线的传输结束以后，就把总线“忙”信号撤销，仲裁器也撤销“允许”信号。根据各请求输入的情况，仲裁器重新分配总线控制权。循环优先级判别法循环优先级判别方法类似于并联优先级判别方法，只是其中的优先级是动态分配的，原来的优先级编码器由一个更为复杂的电路代替，该电路把占用总线的优先级在发出总线请求的那些模块之间循环移动，从而使每个总线模块使用总线的机会相同。总线仲裁：简介播报编辑总线上的设备一般分为总线主设备和总线从设备。总线主设备是指具有控制总线能力的模块，通常是CPU或以CPU为中心的逻辑模块，在获得总线控制权之后能启动数据信息的传输；与之相对应的总线从设备，是指能够对总线上的数据请求做出响应，但本身不具备总线控制能力的模块。在早期的计算机系统中，一条总线上只有一个主设备，总线一直由它占用，技术简单，实现也比较容易。随着应用的发展，主要是工业控制、科学计算的需求，多个主设备共享总线的情况越来越多，这对总线技术提出了新的要求。根据这类系统的特点，需要解决各个主设备之间资源争用等问题，这使得总线的复杂性大为增加。总线仲裁就是在多个总线主设备的环境中提出来的。在多处理机系统中，每个处理机都可以作为总线主设备，都要共享资源，它们都必须通过系统总线才能访问其它资源，总线也可视为是一种重要的公共资源。由于每个处理机都会随机地提出对总线使用的要求，这样就可能发生总线竞争现象。为了防止多个处理机同时控制总线，就要在总线上设立一个处理上述总线竞争的机构，按优先级次序，合理地分配资源，这就是总线仲裁问题。用硬件来实现总线分配的逻辑电路称为总线仲裁器(BusArbiter)。它的任务是响应总线请求，通过对分配过程的正确控制，达到最佳使用总线。总线判优控制按照仲裁控制机构的设置可分为集中控制和分散控制两种。其中就集中控制而言，常用的总线仲裁方式有：菊花链仲裁、二维仲裁、同步通信方式、异步通信方式和半同步通信方式。连接到总线上的功能模块有主动和被动两种形态，CPU可以做主方也可以做从方，而存取器模块只能用作从方。主方可以启动一个总线周期，而从方只能响应主方的请求。对多个主设备提出的占用总线请求，一般采用优先级或公平策略进行仲裁[1]。仲裁方式分类播报编辑按照总线仲裁电路的位置不同，仲裁方式分为集中式仲裁和分布式仲裁两类：1.集中式总线仲裁的控制逻辑基本集中在一处，需要中央仲裁器，分为链式查询方式、计数器定时查询方式、独立请求方式；(1)链式查询方式链式查询方式的主要特点：总线授权信号BG串行地从一个I/O接口传送到下一个I/O接口。假如BG到达的接口无总线请求，则继续往下查询；假如BG到达的接口有总线请求，BG信号便不再往下查询，该I/O接口获得了总线控制权。离中央仲裁器最近的设备具有最高优先级，通过接口的优先级排队电路来实现。链式查询方式的优点:只用很少几根线就能按一定优先次序实现总线仲裁，很容易扩充设备。链式查询方式的缺点:对询问链的电路故障很敏感，如果第i个设备的接口中有关链的电路有故障，那么第i个以后的设备都不能进行工作。查询链的优先级是固定的，如果优先级高的设备出现频繁的请求时，优先级较低的设备可能长期不能使用总线。(2)计数器定时查询方式总线上的任一设备要求使用总线时，通过BR线发出总线请求。中央仲裁器接到请求信号以后，在BS线为“0”的情况下让计数器开始计数，计数值通过一组地址线发向各设备。每个设备接口都有一个设备地址判别电路，当地址线上的计数值与请求总线的设备地址相一致时，该设备置“1”BS线，获得了总线使用权，此时中止计数查询。每次计数可以从“0”开始，也可以从中止点开始。如果从“0”开始，各设备的优先次序与链式查询法相同，优先级的顺序是固定的。如果从中止点开始，则每个设备使用总线的优先级相等。计数器的初值也可用程序来设置，这可以方便地改变优先次序，但这种灵活性是以增加线数为代价的。(3)独立请求方式每一个共享总线的设备均有一对总线请求线BRi和总线授权线BGi。当设备要求使用总线时，便发出该设备的请求信号。中央仲裁器中的排队电路决定首先响应哪个设备的请求，给设备以授权信号BGi。独立请求方式的优点：响应时间快，确定优先响应的设备所花费的时间少，用不着一个设备接一个设备地查询。其次，对优先次序的控制相当灵活，可以预先固定也可以通过程序来改变优先次序；还可以用屏蔽(禁止)某个请求的办法，不响应来自无效设备的请求。2.分布式仲裁不需要中央仲裁器，每个潜在的主方功能模块都有自己的仲裁号和仲裁器。当它们有总线请求时，把它们唯一的仲裁号发送到共享的仲裁总线上，每个仲裁器将仲裁总线上得到的号与自己的号进行比较。如果仲裁总线上的号大，则它的总线请求不予响应，并撤消它的仲裁号。最后，获胜者的仲裁号保留在仲裁总线上。显然，分布式仲裁是以优先级仲裁策略为基础[2]。总线分配技术播报编辑对总线仲裁问题的解决是以优先级(又称优先权)的概念为基础的，通常有三种总线分配的优先级技术──串联、并联和循环。串联优先级判别法图1串联优先级判别法图1中有Ⅰ、Ⅱ、…、N等N个模块，都可作为总线主设备，各个模块中的“请求”输出端采用集电极(漏极)开路门，“请求”端用“线或”方式接到仲裁器“请求”输入端，每个模块的“忙”端同仲裁器的“总线忙”状态线相连，这是一个输入输出双向信号线。当一个模块占有总线控制权时，该模块的“忙”信号端成为输出端，向系统的“忙”状态线送出有效信号(例如低电平)。其它模块的“忙”信号端全部作为输入端工作，检测“忙”线上状态。一个模块若要提出总线“请求”，其必要条件是选检测到“忙”信号输入端处于无效状态。与此相应，仲裁器接受总线请求输入的条件，也是“忙”线处于无效状态。进一步可以规定仲裁器输出“允许”信号的条件首先是“忙”线无效，表示总线没有被任一模块占用；其次才是有模块提出了总线请求。“允许”信号在链接的模块之间传输，直到提出总线“请求”的那个模块为止。这里用“允许”信号的边沿触发，它把共享总线的各模块要使用总线时，便发生信号禁止后面的部件使用总线。通过这种方式，就确定了请求总线各模块中优先级最高的模块。显然，在这种方式中，当优先级高的模块频繁请求时，优先级别低的模块可能很长时间都无法获得总线。一旦有模块占用总线后，“允许”信号就不再存在。并联优先级别判别法图2并联优先级别判别法图2中有N个模块，都可作为总线主设备，每个模块都有总线“请求”线和总线“允许”线，模块之间是独立的，没有任何控制关系。这些信号接到总线优先控制器(仲裁器)，任一模块使用总线，都要通过“请求”线向仲裁器发出“请求”信号。仲裁器一般由一个优先级编码器和一个译码器组成。该电路接到某个模块或多个模块发来的请求信号后，首先优先级编码器进行编码，然后由译码器产生相应的输出信号，发往请求总线模块中优先级最高的模块，并把“允许”信号送给该模块。被选中的模块撤销总线“请求”信号，输出总线“忙”信号，通知其余模块，总线已经占用。在一个模块占用总线的传输结束以后，就把总线“忙”信号撤销，仲裁器也撤销“允许”信号。根据各请求输入的情况，仲裁器重新分配总线控制权。循环优先级判别法循环优先级判别方法类似于并联优先级判别方法，只是其中的优先级是动态分配的，原来的优先级编码器由一个更为复杂的电路代替，该电路把占用总线的优先级在发出总线请求的那些模块之间循环移动，从而使每个总线模块使用总线的机会相同。存储容量：单位简介播报编辑网络上的所有信息都是以“位”（bit）为单位传递的，一个位就代表一个0或1。每8个位（bit）组成一个字节（byte）。字节是什么概念呢？一个英文字母就占用一个字节，也就是8位，一个汉字占用两个字节。一般位简写为小写字母“b”，字节简写为大写字母“B”。存贮容量的设计播报编辑根据要求，福建理工大学监控系统采用集中式存储解决方案。具体设计为：在监控中心部署H3CEX1000SIPSAN存储服务器，前端所有摄像头的图像通过监控专网传输到监控中心，集中存储到IPSAN服务器上。监控平台建成后，还需针对存储需求进行不同码流设计：CIF：图像分辨率为352×288D1：图像分辨率为720×576采用CIF方式：每路每秒是采用512K进行存储，我们参考512k存储系统按照160个摄像头存储30天的需求，共需要存储容量；(计算公式：存储容量（GB)=（码流/1024/1024/8）×CBR影响系数×60秒×60分钟×24小时×天数）以512K单路视频图像码流，计算图像存储容量。每小时容量=3600秒×（512/1024/1024/8）×1.10=0.242G/小时每路图像一天24小时一天容量=24Hour×0.242GB/Hour=5.801GB/天一月容量=30天×5.801GB/天=174.03GB160个摄像头保存30天容量=160×174.03GB=27844.8GB=27.8TB采用FullD1方式：每路每秒是采用2M进行存储，我们参考2M存储系统按照14个摄像头存储30天的需求，共需要存储容量；(计算公式：存储容量（GB)=（码流/1024/1024/8）×CBR影响系数×60秒×60分钟×24小时×天数）以1M单路视频图像码流，视频图像分辨率为D1720*576PAL25帧,计算图像存储容量。每小时容量=3600秒×（2048/1024/1024/8）×1.10=0.967G/小时每路图像一天24小时一天容量=24Hour×0.967GB/Hour=23.203GB/天一月容量=30天*23.203GB/天=696.09GB14个摄像头保存30天容量=14×696.09GB=9745.26GB=9.75TB[1]存贮容量的计算播报编辑每一千个字节称为1KB，注意，这里的“千”不是我们通常意义上的1000，而是指1024。即：1KB=1024B。但如果不要求严格计算的话，也可以忽略地认为1K就是1000。4）每1024个KB就是1MB（同样这里的K是指1024），即：1MB=1024KB=1024×1024B=1,048,576B这是准确的计算。如果不精确要求的话，也可认为1MB=1,000KB=1,000,000B另外需要注意的是，存储产品生产商会直接以1GB=1000MB，1MB=1000KB，1KB=1000B的计算方式统计产品的容量，这就是为何买回的存储设备容量达不到标称容量的主要原因（如320G的硬盘只有300G左右）每1024MB就是1GB，即1GB=1024MB，至于等于多少字节，自己算吧。我们搞清楚了，常听人说什么一张软盘是1.44MB、一张CD光盘是650MB、一块硬盘是120GB是什么意思了。打个比方，一篇10万汉字的小说，如果我们把存到磁盘上，需要占用多少空间呢？100,000汉字=200,000B=200,000B÷1024≈195.3KB≈195.3KB÷1024≈0.19MB硬盘计算：750GBSATA实际容量为667（698.5）GB（少于的部分用于操作系统）；CBR影响系数：是指CBR(恒定码流）正误差给存储容量带来的影响系数。存储设备采用RAID5+1的方式布置，每台存储需要损耗2块硬盘，如果IPSAN的硬盘为500GB的侧每台存储有效容量为6.316TB；如果IPSAN的硬盘为750GB的侧每台存储有效容量为9.119TB存储模式与硬盘数量关系：模式1:部署JBOD盘，采用750G硬盘（有效容量667GB)，单机16个有效盘位总容量为10.672TB，不考虑存储数据可靠性为最经济模式。模式2：部署RAID5但不配热备盘，采用750G硬盘（有效容量667GB），单机15个有效盘位总容量为9.771TB，不考虑RAID5重建对存储性能影响，这是最经济的模式。模式3：部署RAID5且配热备盘，采用750G硬盘（有效容量667GB)，单机14个有效盘位总容量为9.119TB，不考虑RAID5重建对存储性能影响（允许在坏掉一个硬盘后短时间内再坏掉一个硬盘）。根据各布点区域监控点的数量可具体计算出所需的存储容量。（方案存储数据）方案中我们IPSAN存储，可以根据需要随时增加存储设备，并进行统一管理。[1]单位换算介绍播报编辑随着存贮信息量的增大，有更大的单位表示存贮容量单位，比吉字节（GB,gigabyte）更高的还有：太字节（TB，terabyte）、PB(Petabyte)、EB(Exabyte)、ZB(Zettabyte)和YB(yottabyte)等，其中，1PB=1024TB，1EB=1024PB，1ZB=1024EB，1YB=1024ZB。那么，这些单位的容量究竟有多大呢？请看一下表示：Ki1obyte(KB)=1024B相当于一则短篇故事的内容。Megabyte(MB)=1024KB相当于一则短篇小说的文字内容。Gigabyte(GB)=1024MB相当于贝多芬第五乐章交响曲的乐谱内容。Terabyte(TB)=1024GB相当于一家大型医院中所有的X光图片资讯量。Petabyte(PB)=1024TB相当于50%的全美学术研究图书馆藏书资讯内容。Exabyte(EB)=1024PB；5EB相当于至今全世界人类所讲过的话语。Zettabyte(ZB)=1024EB如同全世界海滩上的沙子数量总和。Yottabyte(YB)=1024ZB相当于7000位人类体内的微细胞总和。常用单位播报编辑存储容量是指该便携存储产品最大所能存储的数据量，是便携存储产品最为关键的参数。一般U盘的容量有1GB、2GB、4GB、8GB、16GB、32GB、64GB，还有部分更高容量的产品，但价格已超出了用户可以接受的地步。其中1GB～2GB的便携存储，已基本被市场淘汰；而4GB～16GB的产品是市场中的主流，价格在普通用户可以接受的范围内，也是厂家推出产品类型最多的容量类型；32GB以上的产品，因为价格昂贵，用户群体较少，产品种类也较少。磁盘存储容量播报编辑如上面所说，一块磁盘通常采用三级编址，因此，磁盘存储器的存储容量可以用如下公式来计算：存储容量C=柱面(磁道)数Tx磁盘面(磁头)数Hx扇区数S应当指出，这里所说的存储容量是指磁盘存储器能够保存的有效数据量，在磁盘上记录的许多其他信息不计算在存储容量之内。有些人可能已经注意到，新购买的硬盘，格式化之后显示的存储容量与磁盘上实际标称的存储容量并不符合。其主要原因是：磁盘上的标称容量是用十进制给出的，而计算机内部实际上是用二进制来表示存储容量的。例如，1KB=1024B，1MB=1048576B等，如果用MB来表示磁盘存储器的容量，则磁盘的标称容量与实际显示的容量之间有近5%的误差，如果用GB来表示，则有7.4%的误差，如果用TB表示，则误差高达10%。数据库避免存储容量浪费播报编辑数据库存储容量大量浪费的表现之一是数据冗余，指的是一个字段在多个表里重复出现。举个例子，如果每条客户购买商品的信息里都连带记录了客户自身的信息，这样的数据冗余可能造成不一致，因为客户自身的信息可能不一样。数据冗余会导致数据异常和损坏，一般来说设计上应该被避免。数据库规范化防止了冗余而且不浪费存储容量。适当的使用外键可以使得数据冗余和异常降到最低。但是，如果考虑效率和便利，有时候也会设计冗余数据，而不考虑数据被破坏的风险。[1-2]多核处理器：技术发展播报编辑256线程的CPU英特尔工程师们开发了多核芯片，使之满足“横向扩展”（而非“纵向扩充”）方法，从而提高性能。该架构实现了“分治法”战略。通过划分任务，线程应用能够充分利用多个执行内核，并可在特定的时间内执行更多任务。多核处理器是单枚芯片（也称为“硅核”），能够直接插入单一的处理器插槽中，但操作系统会利用所有相关的资源，将每个执行内核作为分立的逻辑处理器。通过在两个执行内核之间划分任务，多核处理器可在特定的时钟周期内执行更多任务。多核架构能够使软件更出色地运行，并创建一个促进未来的软件编写更趋完善的架构。尽管认真的软件厂商还在探索全新的软件并发处理模式，但是，随着向多核处理器的移植，现有软件无需被修改就可支持多核平台。操作系统专为充分利用多个处理器而设计，且无需修改就可运行。为了充分利用多核技术，应用开发人员需要在程序设计中融入更多思路，但设计流程与对称多处理(SMP)系统的设计流程相同，并且现有的单线程应用也将继续运行。得益于线程技术的应用在多核处理器上运行时将显示出卓越的性能可扩充性。此类软件包括多媒体应用（内容创建、编辑，以及本地和数据流回放）、工程和其他技术计算应用以及诸如应用服务器和数据库等中间层与后层服务器应用。多核技术能够使服务器并行处理任务，而在以前，这可能需要使用多个处理器，多核系统更易于扩充，并且能够在更纤巧的外形中融入更强大的处理性能，这种外形所用的功耗更低、计算功耗产生的热量更少。多核技术是处理器发展的必然。推动微处理器性能不断提高的因素主要有两个：半导体工艺技术的飞速进步和体系结构的不断发展。半导体工艺技术的每一次进步都为微处理器体系结构的研究提出了新的问题，开辟了新的领域；体系结构的进展又在半导体工艺技术发展的基础上进一步提高了微处理器的性能。这两个因素是相互影响，相互促进的。一般说来，工艺和电路技术的发展使得处理器性能提高约20倍，体系结构的发展使得处理器性能提高约4倍，编译技术的发展使得处理器性能提高约1.4倍。但是今天，这种规律性的东西却很难维持。多核的出现是技术发展和应用需求的必然产物。发展历程播报编辑1971年，英特尔推出的全球第一颗通用型微处理器4004，由2300个晶体管构成。当时，公司的联合创始人之一戈登摩尔(GordonMoore)，就提出后来被业界奉为信条的“摩尔定律”——每过18个月，芯片上可以集成的晶体管数目将增加一倍。在一块芯片上集成的晶体管数目越多，意味着运算速度即主频就更快。今天英特尔的奔腾(Pentium)四至尊版840处理器，晶体管数量已经增加至2.5亿个，相比当年的4004增加了10万倍。其主频也从最初的740kHz(每秒钟可进行74万次运算)，增长到3.9GHz(每秒钟运算39亿次)以上。当然，CPU主频的提高，或许在一定程度上也要归功于1975年进入这个领域的AMD公司的挑战。正是这样的“双雄会”，使得众多计算机用户有机会享受不断上演的“速度与激情”。一些仍不满足的发烧友甚至选择了自己超频，因为在玩很多游戏时，更快的速度可以带来额外的饕餮享受。但到了2005年，当主频接近4GHz时，英特尔和AMD发现，速度也会遇到自己的极限：那就是单纯的主频提升，已经无法明显提升系统整体性能。以英特尔发布的采用NetBurst架构的奔腾四CPU为例，它包括Willamette、Northwood和Prescott等三种采用不同核心的产品。利用冗长的运算流水线，即增加每个时钟周期同时执行的运算个数，就达到较高的主频。这三种处理器的最高频率，分别达到了2.0G、3.4G和3.8G。按照当时的预测，奔腾四在该架构下，最终可以把主频提高到10GHz。但由于流水线过长，使得单位频率效能低下，加上由于缓存的增加和漏电流控制不利造成功耗大幅度增加，3.6GHz奔腾四芯片在性能上反而还不如早些时推出的3.4GHz产品。所以，Prescott产品系列只达到3.8G，就戛然而止。英特尔上海公司一位工程师在接受记者采访时表示，Netburst微架构的好处在于方便提升频率，可以让产品的主频非常高。但性能提升并不明显，频率提高50%，性能提升可能微不足道。因为Netburst微架构的效率较低，CPU计算资源未被充分利用，就像开车时“边踩刹车边踩油门”。此外，随着功率增大，散热问题也越来越成为一个无法逾越的障碍。据测算，主频每增加1G，功耗将上升25瓦，而在芯片功耗超过150瓦后，现有的风冷散热系统将无法满足散热的需要。3.4GHz的奔腾四至尊版，晶体管达1.78亿个，最高功耗已达135瓦。实际上，在奔腾四推出后不久，就在批评家那里获得了“电炉”的美称。更有好事者用它来玩煎蛋的游戏。很显然，当晶体管数量增加导致功耗增长超过性能增长速度后，处理器的可靠性就会受到致命性的影响。就连戈登摩尔本人似乎也依稀看到了“主频为王”这条路的尽头——2005年4月，他曾公开表示，引领半导体市场接近40年的“摩尔定律”，在未来10年至20年内可能失效。多核心CPU解决方案(多核)的出现，似乎给人带来了新的希望。早在上世纪90年代末，就有众多业界人士呼吁用CMP(单芯片多处理器)技术来替代复杂性较高的单线程CPU。IBM、惠普、Sun等高端服务器厂商，更是相继推出了多核服务器CPU。不过，由于服务器价格高、应用面窄，并未引起大众广泛的注意。直到AMD抢先手推出64位处理器后，英特尔才想起利用“多核”这一武器进行“帝国反击战”。2005年4月，英特尔仓促推出简单封装双核的奔腾D和奔腾四至尊版840。AMD在之后也发布了双核皓龙(Opteron)和速龙(Athlon)64X2和处理器。但真正的“双核元年”，则被认为是2006年。这一年的7月23日，英特尔基于酷睿(Core)架构的处理器正式发布。2006年11月，又推出面向服务器、工作站和高端个人电脑的至强(Xeon)5300和酷睿双核和四核至尊版系列处理器。与上一代台式机处理器相比，酷睿2双核处理器在性能方面提高40%，功耗反而降低40%。作为回应，7月24日，AMD也宣布对旗下的双核Athlon64X2处理器进行大降价。由于功耗已成为用户在性能之外所考虑的首要因素，两大处理器巨头都在宣传多核处理器时，强调其“节能”效果。英特尔发布了功耗仅为50瓦的低电压版四核至强处理器。而AMD的“Barcelona”四核处理器的功耗没有超过95瓦。在英特尔高级副总裁帕特基辛格(PatGelsinger)看来，从单核到双核，再到多核的发展，证明了摩尔定律还是非常正确的，因为“从单核到双核，再到多核的发展，可能是摩尔定律问世以来，在芯片发展历史上速度最快的性能提升过程”。技术优势播报编辑从应用需求上去看，越来越多的用户在使用过程中都会涉及到多任务应用环境，日常应用中用到的非常典型的有两种应用模式。一种应用模式是一个程序采用了线程级并行编程，那么这个程序在运行时可以把并行的线程同时交付给两个核心分别处理，因而程序运行速度得到极大提高。这类程序有的是为多路工作站或服务器设计的专业程序，例如专业图像处理程序、非线视频编缉程序、动画制作程序或科学计算程序等。对于这类程序，两个物理核心和两颗处理器基本上是等价的，所以，这些程序往往可以不作任何改动就直接运行在双核电脑上。还有一些更常见的日常应用程序，例如Office、IE等，同样也是采用线程级并行编程，可以在运行时同时调用多个线程协同工作，所以在双核处理器上的运行速度也会得到较大提升。例如，打开IE浏览器上网。看似简单的一个操作，实际上浏览器进程会调用代码解析、Flash播放、多媒体播放、Java、脚本解析等一系列线程，这些线程可以并行地被双核处理器处理，因而运行速度大大加快（实际上IE浏览器的运行还涉及到许多进程级的交互通信，这里不再详述）。由此可见，对于已经采用并行编程的软件，不管是专业软件，还是日常应用软件，在多核处理器上的运行速度都会大大提高。日常应用中的另一种模式是同时运行多个程序。许多程序没有采用并行编程，例如一些文件压缩软件、部分游戏软件等等。对于这些单线程的程序，单独运行在多核处理器上与单独运行在同样参数的单核处理器上没有明显的差别。但是，由于日常使用的最最基本的程序——操作系统——是支持并行处理的，所以，当在多核处理器上同时运行多个单线程程序的时候，操作系统会把多个程序的指令分别发送给多个核心，从而使得同时完成多个程序的速度大大加快。另外，虽然单一的单线程程序无法体现出多核处理器的优势，但是多核处理器依然为程序设计者提供了一个很好的平台，使得他们可以通过对原有的单线程序进行并行设计优化，以实现更好的程序运行效果。上面介绍了多核心处理器在软件上面的应用，但游戏其实也是软件的一种，作为一种特殊的软件，对PC发展作出了较大的贡献。一些多线程游戏已经能够发挥出多核处理器的优势，对于单线程游戏，相信游戏厂商也将会改变编程策略，例如，一些游戏厂商正在对原来的一些单线程游戏进行优化，采用并行编程使得游戏运行得更快。有的游戏可以使用一个线程实现人物动画，而使用另一个线程来载入地图信息。或者使用一个线程来实现图像渲染中的矩阵运算，而使用另一个来实现更高的人工智能运算。如今，大量的支持多核心的游戏涌现出来，从而使得多核处理器的优势能得到进一步的发挥。技术瓶颈播报编辑布赖恩特直言不讳地指出，要想让多核完全发挥效力，需要硬件业和软件业更多革命性的更新。其中，可编程性是多核处理器面临的最大问题。一旦核心多过八个，就需要执行程序能够并行处理。尽管在并行计算上，人类已经探索了超过40年，但编写、调试、优化并行处理程序的能力还非常弱。易观国际分析师李也认为，“出于技术的挑战，双核甚至多核处理器被强加给了产业，而产业却并没有事先做好准备”。或许正是出于对这种失衡的担心，中国国家智能计算机中心主任孙凝辉告诉《财经》记者，“十年以后，多核这条道路可能就到头了”。在他看来，一味增加并行的处理单元是行不通的。并行计算机的发展历史表明，并行粒度超过100以后，程序就很难写，能做到128个以上的应用程序很少。CPU到了100个核以上后，并行计算机系统遇到的问题，在CPU一样会存在。“如果解决不了主流应用并行化的问题，主流CPU发展到100个核就到头了。还不知道什么样的革命性的进展能解决这些问题。”孙补充说。实际上，市场研究公司In-Stat分析师吉姆克雷格(JimMcGregor)就承认，虽然英特尔已向外界展示了80核处理器原型，但尴尬的是，还没有能够利用这一处理器的操作系统。中科院软件所并行计算实验室副主任张云泉也持类似的观点。他对《财经》记者表示，这个问题实际一直就存在，但原来在超级计算机上才会遇到，所以，讨论也多局限在学术界。所有用户都要面对这样的问题。多核心技术在应用上的优势有两个方面：为用户带来更强大的计算性能；更重要的，则是可满足用户同时进行多任务处理和多任务计算环境的要求。两大巨头都给消费者描绘出了使用多核处理器在执行多项任务时的美妙前景：同时可以检查邮件、刻录CD、修改照片、剪辑视频，并且同时可以运行杀毒软件。或者利用同一台电脑，父亲在查看财务报表，女儿在打游戏，母亲在给远方的朋友打网络电话。但并不是所有家庭只有一台电脑，也不是所有用户都要用电脑一下子做那么多事，更何况大部分应用程序还并不能自动分割成多任务，分别交给多个核心去执行。所以，对于大多数用户来说，多核所带来的实际益处，很可能并不明显。而多核所带来的挑战，或者说麻烦，却是实实在在的。美国卡内基梅隆大学计算机系教授朗道布赖恩特(RandalEBryant)在接受《财经》记者采访时就坦称，“这给软件业制造了巨大的问题”。技术原理播报编辑多核CPU就是基板上集成有多个单核CPU，早期PD双核需要北桥来控制分配任务，核心之间存在抢二级缓存的情况，后期酷睿自己集成了任务分配系统，再搭配操作系统就能真正同时开工，2个核心同时处理2“份”任务，速度快了，万一1个核心死机，起码另一个U还可以继续处理关机、关闭软件等任务。技术关键播报编辑与单核处理器相比，多核处理器在体系结构、软件、功耗和安全性设计等方面面临着巨大的挑战，但也蕴含着巨大的潜能。多核处理器CMP和SMT一样，致力于发掘计算的粗粒度并行性。CMP可以看做是随着大规模集成电路技术的发展，在芯片容量足够大时，就可以将大规模并行处理机结构中的SMP（对称多处理机）或DSM（分布共享处理机）节点集成到同一芯片内，各个处理器并行执行不同的线程或进程。在基于SMP结构的单芯片多处理机中，处理器之间通过片外Cache或者是片外的共享存储器来进行通信。而基于DSM结构的单芯片多处理器中，处理器间通过连接分布式存储器的片内高速交叉开关网络进行通信。由于SMP和DSM已经是非常成熟的技术了，CMP结构设计比较容易，只是后端设计和芯片制造工艺的要求较高而已。正因为这样，CMP成为了最先被应用于商用CPU的“未来”高性能处理器结构。虽然多核能利用集成度提高带来的诸多好处，让芯片的性能成倍地增加，但很明显的是原来系统级的一些问题便引入到了处理器内部。核结构研究同构还是异构CMP的构成分成同构和异构两类，同构是指内部核的结构是相同的，而异构是指内部的核结构是不同的。为此，面对不同的应用研究核结构的实现对未来微处理器的性能至关重要。核本身的结构，关系到整个芯片的面积、功耗和性能。怎样继承和发展传统处理器的成果，直接影响多核的性能和实现周期。同时，根据Amdahl定理，程序的加速比决定于串行部分的性能，所以，从理论上来看似乎异构微处理器的结构具有更好的性能。核所用的指令系统对系统的实现也是很重要的，多核之间采用相同的指令系统还是不同的指令系统，能否运行操作系统等，也将是研究的内容之一。程序执行模型处理器设计的首要问题是选择程序执行模型。程序执行模型的适用性决定多核处理器能否以最低的代价提供最高的性能。程序执行模型是编译器设计人员与系统实现人员之间的接口。编译器设计人员决定如何将一种高级语言程序按一种程序执行模型转换成一种目标机器语言程序;系统实现人员则决定该程序执行模型在具体目标机器上的有效实现。当目标机器是多核体系结构时，产生的问题是:多核体系结构如何支持重要的程序执行模型？是否有其他的程序执行模型更适于多核的体系结构？这些程序执行模型能多大程度上满足应用的需要并为用户所接受？Cache设计多级Cache设计与一致性问题处理器和主存间的速度差距对CMP来说是个突出的矛盾，因此必须使用多级Cache来缓解。有共享一级Cache的CMP、共享二级Cache的CMP以及共享主存的CMP。通常，CMP采用共享二级Cache的CMP结构，即每个处理器核心拥有私有的一级Cache，且所有处理器核心共享二级Cache。Cache自身的体系结构设计也直接关系到系统整体性能。但是在CMP结构中，共享Cache或独有Cache孰优孰劣、需不需要在一块芯片上建立多级Cache，以及建立几级Cache等等，由于对整个芯片的尺寸、功耗、布局、性能以及运行效率等都有很大的影响，因而这些都是需要认真研究和探讨的问题。另一方面，多级Cache又引发一致性问题。采用何种Cache一致性模型和机制都将对CMP整体性能产生重要影响。在传统多处理器系统结构中广泛采用的Cache一致性模型有:顺序一致性模型、弱一致性模型、释放一致性模型等。与之相关的Cache一致性机制主要有总线的侦听协议和基于目录的目录协议。CMP系统大多采用基于总线的侦听协议。核间通信技术CMP处理器的各CPU核心执行的程序之间有时需要进行数据共享与同步，因此其硬件结构必须支持核间通信。高效的通信机制是CMP处理器高性能的重要保障，比较主流的片上高效通信机制有两种，一种是基于总线共享的Cache结构，一种是基于片上的互连结构。总线共享Cache结构是指每个CPU内核拥有共享的二级或三级Cache，用于保存比较常用的数据，并通过连接核心的总线进行通信。这种系统的优点是结构简单，通信速度高，缺点是基于总线的结构可扩展性较差。基于片上互连的结构是指每个CPU核心具有独立的处理单元和Cache，各个CPU核心通过交叉开关或片上网络等方式连接在一起。各个CPU核心间通过消息通信。这种结构的优点是可扩展性好，数据带宽有保证;缺点是硬件结构复杂，且软件改动较大。也许这两者的竞争结果不是互相取代而是互相合作，例如在全局范围采用片上网络而局部采用总线方式，来达到性能与复杂性的平衡。总线设计传统微处理器中，Cache不命中或访存事件都会对CPU的执行效率产生负面影响，而总线接口单元（BIU）的工作效率会决定此影响的程度。当多个CPU核心同时要求访问内存或多个CPU核心内私有Cache同时出现Cache不命中事件时，BIU对这多个访问请求的仲裁机制以及对外存储访问的转换机制的效率决定了CMP系统的整体性能。因此寻找高效的多端口总线接口单元（BIU）结构，将多核心对主存的单字访问转为更为高效的猝发（burst）访问;同时寻找对CMP处理器整体效率最佳的一次Burst访问字的数量模型以及高效多端口BIU访问的仲裁机制将是CMP处理器研究的重要内容，Inter推出了最新的英特尔智能互连技术(QPI)技术总线，更大程度发掘了多核处理器的实力。操作系统设计任务调度、中断处理、同步互斥对于多核CPU，优化操作系统任务调度算法是保证效率的关键。一般任务调度算法有全局队列调度和局部队列调度。前者是指操作系统维护一个全局的任务等待队列，当系统中有一个CPU核心空闲时，操作系统就从全局任务等待队列中选取就绪任务开始在此核心上执行。这种方法的优点是CPU核心利用率较高。后者是指操作系统为每个CPU内核维护一个局部的任务等待队列，当系统中有一个CPU内核空闲时，便从该核心的任务等待队列中选取恰当的任务执行，这种方法的优点是任务基本上无需在多个CPU核心间切换，有利于提高CPU核心局部Cache命中率。多数多核CPU操作系统采用的是基于全局队列的任务调度算法。多核的中断处理和单核有很大不同。多核的各处理器之间需要通过中断方式进行通信，所以多个处理器之间的本地中断控制器和负责仲裁各核之间中断分配的全局中断控制器也需要封装在芯片内部。另外,多核CPU是一个多任务系统。由于不同任务会竞争共享资源，因此需要系统提供同步与互斥机制。而传统的用于单核的解决机制并不能满足多核，需要利用硬件提供的“读－修改－写”的原子操作或其他同步互斥机制来保证。低功耗设计半导体工艺的迅速发展使微处理器的集成度越来越高，同时处理器表面温度也变得越来越高并呈指数级增长，每三年处理器的功耗密度就能翻一番。低功耗和热优化设计已经成为微处理器研究中的核心问题。CMP的多核心结构决定了其相关的功耗研究是一个至关重要的课题。低功耗设计是一个多层次问题，需要同时在操作系统级、算法级、结构级、电路级等多个层次上进行研究。每个层次的低功耗设计方法实现的效果不同——抽象层次越高，功耗和温度降低的效果越明显。当前Intel的CPU的功耗相对较低，得益于先进的英特尔构架和45纳米、32纳米制程工艺，同时Intel还专门为CPU开发了不少节能技术，比如C6深度节能技、英特尔智能功效管理和主动管理技术等等，Intel在移动CPU市场，更是凭借超低电压处理器（ULV）和凌动（Atom）系列处理器，遥遥领先于对手。存储器墙为了使芯片内核充分地工作，最起码的要求是芯片能提供与芯片性能相匹配的存储器带宽，虽然内部Cache的容量能解决一些问题，但随着性能的进一步提高，必须有其他一些手段来提高存储器接口的带宽，如增加单个管脚带宽的DDR、DDR2、QDR、XDR等。同样，系统也必须有能提供高带宽的存储器。所以，芯片对封装的要求也越来越高，虽然封装的管脚数每年以20%的数目提升，但还不能完全解决问题，而且还带来了成本提高的问题，为此，怎样提供一个高带宽，低延迟的接口带宽，是必须解决的一个重要问题。可靠性及安全性设计随着技术革新的发展，处理器的应用渗透到现代社会的各个层面，但是在安全性方面却存在着很大的隐患。一方面，处理器结构自身的可靠性低下，由于超微细化与时钟设计的高速化、低电源电压化，设计上的安全系数越来越难以保证，故障的发生率逐渐走高。另一方面，来自第三方的恶意攻击越来越多，手段越来越先进，已成为具有普遍性的社会问题。可靠性与安全性的提高在计算机体系结构研究领域备受注目。今后，CMP这类处理器芯片内有多个进程同时执行的结构将成为主流，再加上硬件复杂性、设计时的失误增加，使得处理器芯片内部也未必是安全的，因此，安全与可靠性设计任重而道远。技术意义播报编辑多核处理器代表了计算技术的一次创新。由于数字数据和互联网的全球化，商业和消费者开始要求多核处理器带来性能改进，这个重要创新就开始了；因为多核处理器比单核处理器具有性能和效率优势，多核处理器将会成为被广泛采用的计算模型。在驱动pc安全性和虚拟化技术的重大进程过程中，多核处理器扮演着中心作用，这些安全性和虚拟化技术的开发用于为商业计算市场提供更大的安全性、更好的资源利用率、创造更大价值。普通消费者用户也期望得到前所未有的性能，这将极大地扩展其家庭pc和数字媒体计算系统的使用。多核处理器具有不增加功耗而提高性能的好处，实现更大的性能/能耗比。在一个处理器中放入两个或多个功能强大的计算核产生了一个重大的可能性。由于多核处理器能提供比单核处理器更好的性能和效率，下一代的软件应用程序很有可能是基于多核处理器而开发的。不管这些应用是帮助专业的电影公司以更少的投入和更少的时间完成更真实的电影，还是以更彻底的方法使得pc更自然和直观，多核处理器技术将永远改变计算世界。多核处理器表达了amd了解顾客需求并且开发最能满足客户要求产品的意愿。微软多核计算的主管DanReed称，整个世界上很缺乏那些并行计算的研究人员，而一个间接的原因就是学院里对于并行计算的关注度不够，而这些学院正是下一代软件开发人员诞生的地方。越来越高的时钟频率导致应用程序的代码运行的越来越快，而对于当前多核处理器来讲这一规则虽然成立，但却有所不同。而这种不同可以做一个形象的比喻，那就是一部跑车和一辆学校的巴士。当跑车能够以很快的速度飞奔时，巴士虽然比较慢，但它可以载着更多的人前行。问题就是，简单地在计算机CPU上增加多个核并不能增加传统应用程序代码的运行速度，这一结果是根据一项来自于Forrester研究公司的报告得出的。换句话说，复杂的工作需要拆分来填充这辆巴士上的空座位。Forrester的报告还谈到：同时，当前四核处理器会激发更多的多处理器设计的思想，我们期待着2009年x86的服务器使用64个处理器核，并且2012年台式机也可以实现这一梦想。使得芯片的制造商以及主要的板级应用的软件厂商意识到多核编程的机遇和挑战。[1]技术种类播报编辑单芯片多处理器(CMP)与同时多线程处理器(SimultaneousMultithreading，SMT)，这两种体系结构可以充分利用这些应用的指令级并行性和线程级并行性，从而显著提高了这些应用的性能。从体系结构的角度看，SMT比CMP对处理器资源利用率要高，在克服线延迟影响方面更具优势。CMP相对SMT的最大优势还在于其模块化设计的简洁性。复制简单设计非常容易，指令调度也更加简单。同时SMT中多个线程对共享资源的争用也会影响其性能，而CMP对共享资源的争用要少得多，因此当应用的线程级并行性较高时，CMP性能一般要优于SMT。此外在设计上，更短的芯片连线使CMP比长导线集中式设计的SMT更容易提高芯片的运行频率，从而在一定程度上起到性能优化的效果。总之，单芯片多处理器通过在一个芯片上集成多个微处理器核心来提高程序的并行性。每个微处理器核心实质上都是一个相对简单的单线程微处理器或者比较简单的多线程微处理器，这样多个微处理器核心就可以并行地执行程序代码，因而具有了较高的线程级并行性。由于CMP采用了相对简单的微处理器作为处理器核心，使得CMP具有高主频、设计和验证周期短、控制逻辑简单、扩展性好、易于实现、功耗低、通信延迟低等优点。此外，CMP还能充分利用不同应用的指令级并行和线程级并行，具有较高线程级并行性的应用如商业应用等可以很好地利用这种结构来提高性能。技术应用播报编辑并行计算技术是云计算的核心技术，也是最具挑战性的技术之一。多核处理器的出现增加了并行的层次性能使得并行程序的开发比以往更难。而当前业内并无有效的并行计算解决方案，无论是编程模型、开发语言还是开发工具，距离开发者的期望都有很大的差距。自动的并行化解决方案在过去的30年间已经被证明基本是死胡同，但传统的手工式的并行程序开发方式又难以为普通的程序员所掌握。Intel、微软、SUN、Cray等业内巨头正投入大量人力物力进行相关的研究，但真正成熟的产品在短期内很难出现。可扩展性是云计算时代并行计算的主要考量点之一，应用性能必须能随着用户的请求、系统规模的增大有效的扩展。当前大部分并行应用在超过一千个的处理器(核)上都难以获得有效的加速性能，未来的许多并行应用必须能有效扩展到成千上万个处理器上。这对开发者是巨大的挑战。[2]产品应用播报编辑从Power、UltraSPARCT1、安腾到双核Opteron、至强Xeon，各个领域都显示出，多核处理器计算平台势必成为服务器的主流或者说是强势计算平台，但这只是上游硬件厂商的乐观预计。并不是所有的操作系统和应用软件都做好了迎接多核平台的准备，尤其是在数十年来均为单一线程开发应用的x86服务器领域。微软软件架构师HerbSutter曾指出:软件开发者对多核处理器时代的来临准备不足。他说，软件开发社区认识到处理器厂商被迫采用多核设计以应对处理器速度提升带来的发热问题，但却没有清楚地了解这样的设计为软件开发带来多少额外的工作。在过去一段长时间里，x86系统上软件的性能随着来自Intel和AMD处理器速度越来越快而不断提高，开发者只需对现有软件程序作轻微改动就能坐观其性能在随着硬件性能的上升而不断提升。不过，多核设计概念的出现迫使软件世界不得不直面并行性(将单个任务拆分成多个小块以便分别处理之后再重新组合的能力)问题。当然，为服务器设计软件的开发者已经解决了一些此类难题，因为多核处理器和多路系统在服务器市场已经存在多年(在传统的Unix领域)，一些运行在RISC架构多核多路系统上的应用程序已经被设计成多线程以利用系统的并行处理能力。但是，在x86领域，应用程序开发者多年来一直停留在单线程世界，生产所谓的“顺序软件”。情况是软件开发者必须找出新的开发软件的方法，面向对象编程的兴起增加了汇编语言的复杂性，并行编程也需要新的抽象层次。另一方面，处理器设计厂商在设计产品时也应该将软件开发者考虑在内，“处理器的首要着眼点应该是可编程性，而不是速度。”Sutter说。多核处理器要想发挥出威力，关键在于并行化软件支持，多核设计带动并行化计算的推进，而给软件带来的影响更是革命性的。Intel很早就通过超线程技术实现了逻辑上的双处理器系统，可以并行计算，但这不过是对处理器闲置资源的一种充分利用而已，并且这种充分利用只有在特定的条件下，尤其是针对流水线比较长且两种运算并不相互交叉的时候，才会有较高的效率，如编码解码、长期重复某种矩阵运算以及一些没有经过仔细编写的软件等。即使IBM的Power5架构，也需要跟最新的操作系统进行融合，加上运行在其上的软件，才有可能利用并发多线程。虚拟化技术在一定程度上能够处理一些因为多核带来的问题，可以让应用软件和操作系统在透明的环境下对处理器资源进行分配和管理。在对称多处理器方面，操作系统对资源的分配和管理并没有本质的改变，多以对称的方式进行平均分配。也就是说，在操作系统层面，当一个任务到来时，剥离成为两个并行的线程，因为线程之间需要交流以及操作系统监管，它导致的效率损失要比硬件层面大得多。并且，多数软件并没有充分考虑到双核乃至多核的运行情况，导致线程的平均分配时间以及线程之间的沟通时间都会大大增加，尤其是当线程需要反复访问内存的时候。多数操作系统还没有完全实现自由的资源分配，如IBM是通过AIX5.3L来支持Power5上的虚拟化功能，才实现了资源的动态调配和划分的。从长远来看，需要使用虚拟化技术才可能实现操作系统对任务的具体划分，这很可能改变一些通用的编程模式。[3]英特尔播报编辑2009年9月6日下午，英特尔在北京发布了业界首款专为多路(MP)服务器设计的四核英特尔&reg;至强&reg;7300系列服务器处理器。与英特尔前代双核产品相比，此次发布的六款全新四核至强&reg;7300系列处理器的性能和性能功耗比分别提升了两倍和三倍之多。而随着这些产品的发布，英特尔在不到15个月的时间内完成了向创新和高能效的英特尔&reg;酷睿™微体系架构的快速切换。据了解，此次推出的至强&reg;7300系列产品包括主频高达2.93GHz处理器(功耗为130瓦)，几款80瓦处理器，和一款针对四插槽刀片式服务器和高密度机架式服务器优化的50瓦版处理器(主频为1.86GHz)。具备数据流量优化(DataTrafficOptimizations)特性的英特尔&reg;7300芯片组采用平衡的平台设计，具有多项全新技术，以改善数据在处理器、内存和I/O之间的传输能力。此外，英特尔还发布了一款50瓦(每内核12.5瓦)的处理器，以推动四插槽刀片式服务器和高密度机架式服务器等高能效超密度部署产品的发展。在芯片设计方面，除内核数量增加一倍之外，相对于前代英特尔多路平台，至强&reg;7300系列处理器和英特尔&reg;7300芯片组所支持的内存容量是原来的4倍，并能支持非常高的整合比例，以减少空间、降低功耗和运营成本。预计今后将有超过50家的系统制造商发售基于英特尔&reg;至强&reg;7300系列处理器的服务器，其中包括戴尔、Egenera、富士通、富士通-西门子、日立、惠普、IBM、NEC、Sun、超微和优利等。针对需要基于全新英特尔&reg;至强&reg;7300系列处理器的完整平台的渠道客户，英特尔特别为其提供了英特尔&reg;S7000FC4UR服务器平台。该款平台可提供强劲的可扩展性能、业经验证的企业级可靠性，用于基础设施的虚拟化和整合。许多软件厂商也为基于英特尔&reg;至强&reg;7300系列处理器的平台提供了创新性的支持虚拟化和性能扩展的解决方案，如BEA、微软、甲骨文、SAP和VMware等。此外，Solaris操作系统和其上运行的数千款应用能够充分利用英特尔&reg;至强&reg;7300系列处理器平台的领先性能优势，为英特尔&reg;至强&reg;服务器用户提供企业级、支持关键任务的UNIX操作系统环境。这些全新四核处理器的定价根据主频、特性和客户定购数量的不同，其千枚单价从856美元至2,301美元不等。指令集架构：CISC播报编辑x86架构微处理器如Intel的Pentium/Celeron/Xeon与AMD的Athlon/Duron/Sempron；以及其64位扩展系统的x86-64的架构的EM64T的Pentium/Xeon与AMD64的Athlon64/Opteron都属于CISC系列。主要针对的操作系统是微软的Windows。另外Linux，一些UNIX等都可以运行在x86（CISC）架构的微处理器。RISC播报编辑RISC这种指令集运算包括HP的PA-RISC，IBM的PowerPC，Compaq（被并入HP）的Alpha，MIPS公司的MIPS，SUN公司的SPARC等。只有UNIX，Linux，MacOS等操作系统运行在RISC处理器上。EPIC播报编辑EPIC是先进的全新指令集运算，只有Intel的IA-64架构的纯64位微处理器的Itanium/Itanium2。EPIC指令集运算的IA-64架构主要针对的操作系统是微软64位安腾版的WindowsXP以及64位安腾版的WindowsServer2003。另外一些64位的Linux，一些64位的UNIX也可以运行IA-64（EPIC）架构。VLIW播报编辑通过将多条指令放入一个指令字，有效的提高了CPU各个计算功能部件的利用效率，提高了程序的性能。。计算机系统不同于一般的电子设备，它是一个由硬件、软件组成的复杂的自动化设备。本章先说明计算机的分类，然后采用自上而下的方法，简要地介绍硬件、软件的概念和组成，目的在于使读者先有一个粗略的总体概念，以便于展开后续各章内容。电子计算机从总体上来说分为两大类。一类是电子模拟计算机。“模拟”就是相似的意思，例如计算尺是用长度来标示数值；时钟是用指针在表盘上转动来表示时间；电表是用角度来反映电量大小，这些都是模拟计算装置。模拟计算机的特点是数值由连续量来表示，运算过程也是连续的。另一类是电子数字计算机，它是在算盘的基础上发展起来的，是用数字来表示数量的大小。数字计算机的主要特点是按位运算，并且不连续地跳动计算。表1.1列出了电子数字计算机与电子模拟计算机的主要区别。电子模拟计算机由于精度和解题能力都有限，所以应用范围较小。电子数字计算机则与电子模拟计算机不同，它是以近似于人类的“思维过程”来进行工作的，所以有人把它叫做电脑。它的发明和发展是20世纪人类最伟大的科学技术成就之一，也是现代科学技术发展水平的主要标志。习惯上所称的电子计算机，一般是指现在广泛应用的电子数字计算机。电子数字计算机进一步又可分为专用计算机和通用计算机。专用和通用是根据计算机的效率、速度、价格、运行的经济性和适应性来划分的。专用计算机是最有效、最经济和最快速的计算机，但是它的适应性很差。通用计算机适应性很强，但是牺牲了效率、速度和经济性。通用计算机可分为超级计算机、大型机、服务器、PC机、单片机和多核机六类，它们的区别在于体积、简易性、功率损耗、性能指标、数据存储容量、指令系统规模和机器价格，见图1.1。一般来说，超级计算机主要用于科学计算，其运算速度在每秒万亿次以上，数据存储容量很大，结构复杂，价格昂贵。而单片机是只用一片集成电路做成的计算机，体积小，结构简单，性能指标较低，价格便宜。介于超级计算机和多核机之间的是大型机、服务器、PC机和单片机，它们的结构规模和性能指标依次递减。但随着巨大规模集成电路的迅速发展，单片机、多核机等彼此之间的概念也在发生变化，因为今天的单片机可能就是明天的多核机。专用计算机是针对某一任务设计的计算机，一般来说，其结构要比通用计算机简单。目前已经出现了多种型号的单片专用机及嵌入式单片机，用于测试或控制，成为计算机应用领域中最热门的产品。多核机是多于一个处理器的计算机芯片，具有更强的能力。世界上第一台电子数字计算机是1946年在美国宾夕法尼亚大学制成的。这台机器用了18000多个电子管，占地170m2，重量达30吨，而运算速度只有5000次/秒。用今天的眼光来看，这台计算机耗费既大又不完善，但却是科学史上一次划时代的创新，它奠定了电子计算机的基础。自从这台计算机问世70多年来，从使用器件的角度来说，计算机的发展大致经历了五代的变化。第一代为1946～1957年，电子管计算机。计算机运算速度为每秒几千次至几万次，体积庞大，成本很高，可靠性较低。在此期间，形成了计算机的基本体系，确定了程序设计的基本方法，数据处理机开始得到应用。第二代为1958～1964年，晶体管计算机。运算速度提高到每秒几万次至几十万次，可靠性提高，体积缩小，成本降低。在此期间，工业控制机开始得到应用。第三代为1965～1971年，中小规模集成电路计算机。可靠性进一步提高，体积进一步缩小，成本进一步下降，运算速度提高到每秒几十万次至几百万次。在此期间形成机种多样化，生产系列化，使用系统化，小型计算机开始出现。第四代为1972～1990年，大规模和超大规模集成电路计算机。可靠性更进一步提高，体积更进一步缩小，成本更进一步降低，速度提高到每秒1000万次至1亿次。由几片大规模集成电路组成的微型计算机开始出现。第五代为1991年开始的巨大规模集成电路计算机。运算速度提高到每秒10亿次。由一片巨大规模集成电路实现的单片计算机开始出现。总之，从1946年计算机诞生以来，大约每隔五年运算速度提高10倍，可靠性提高10倍，成本降低为1/10，体积缩小为1/10。而20世纪70年代以来，计算机的生产数量每年以25%的速度递增。计算机从第三代起，与集成电路技术的发展密切相关。LSI的采用，一块集成电路芯片上可以放置1000个元件，VLSI达到每个芯片1万个元件，现在的ULSI芯片超过了100万个元件。1965年摩尔观察到芯片上的晶体管数量每年翻一番，1970年这种态势减慢成每18个月翻一番，这就是人们所称的摩尔定律。在国际超级计算机500强排序中，中国2004年“曙光4000A”位居第10；2009年“星云号”位居第2；2010年“天河1号”位居第1，运算速度达2500万亿次/秒。20世纪50～60年代，所有计算机存储器都是由微小的铁磁体环(磁芯)做成，每个磁芯直径约1mm。这些小磁芯处在计算机内用三条细导线穿过网格板上。每个磁芯的一种磁化方向代表一个1，另一个磁化方向则代表一个0。磁芯存储器速度相当快，读存储器中的一位只需1微秒。但是磁芯存储器价格昂贵，体积大，而且读出是破坏性的，因此必须有读出后立即重写数据的电路。更重要的在于工艺复杂，甚至手工制作。1970年，仙童半导体公司生产出了第一个较大容量半导体存储器。一个相当于单个磁芯大小的芯片，包含了256位的存储器。这种芯片是非破坏性的，而且读写速度比磁芯快得多，读出一位只要70纳秒，但是其价格比磁芯要贵。1974年每位半导体存储器的价格低于磁芯。这以后，存储器的价格持续快速下跌，但存储密度却不断增加。这导致了新的机器比它之前的机器更小、更快、存储容量更大，价格更便宜。存储器技术的发展，与处理器技术的发展一起，在不到10年的时间里改变了计算机的生命力。虽然庞大昂贵的计算机仍然存在，但计算机已经走向了个人电脑时代。从1970年起，半导体存储器经历了11代：单个芯片1KB、4KB、16KB、64KB、256KB、1MB、4MB、16MB、64MB、256MB和现在的1GB。其中1K=210，1M=220，1G=230。每一代比前一代存储密度提高4倍，而每位价格和存取时间都在下降。与存储器芯片一样，处理器芯片的单元密度也在不断增加。随着时间的推移，每块芯片上的单元个数越来越多，因此构建一个计算机处理器所需的芯片越来越少。表1.2列出了Intel公司微处理器的演化。1971年Intel公司开发出Intel4004。这是第一个将CPU的所有元件都放入同一块芯片内的产品，于是，微处理器诞生了。第1章计算机系统概论5Intel4004能完成两个4位数相加，通过重复相加能完成乘法。按今天的标准，4004虽然过于简单，但是它却成为微处理器的能力和功能不断发展的奠基者。微处理器演变中的另一个主要进步是1972年出现的Intel8008，这是第一个8位微处理器，它比4004复杂一倍。1974年出现了Intel8080。这是第一个通用微处理器，而4004和8008是为特殊用途而设计的。8080是为通用微机而设计的中央处理器。它与8008一样，都是8位微处理器，但8080更快，有更丰富的指令系统和更强的寻址能力。大约在同时，16位微机被开发出来。但是直到20世纪70年代末才出现强大的通用16位微处理器，Intel8086便是其中之一。这一发展趋势中的另一阶段是在1981年，贝尔实验室和HP公司开发出了32位单片微处理器。Intel于1985年推出了32位微处理器Intel80386。吞吐量表征一台计算机在某一时间间隔内能够处理的信息量。响应时间表征从输入有效到系统产生响应之间的时间度量，用时间单位来度量。利用率在给定的时间间隔内系统被实际使用的时间所占的比率，用百分比表示。处理机字长指处理机运算器中一次能够完成二进制数运算的位数，如32位、64位。总线宽度一般指CPU中运算器与存储器之间进行互连的内部总线二进制位数。存储器容量存储器中所有存储单元的总数目，通常用KB、MB、GB、TB来表示。存储器带宽单位时间内从存储器读出的二进制数信息量，一般用字节数/秒表示。主频/时钟周期CPU的工作节拍受主时钟控制，主时钟不断产生固定频率的时钟，主时钟的频率(f)叫CPU的主频。度量单位是MHz(兆赫兹)、GHz(吉赫兹)。主频的倒数称为CPU时钟周期(T)，T=1/f，度量单位是μs、ns。CPU执行时间表示CPU执行一般程序所占用的CPU时间，可用下式计算：CPU执行时间=CPU时钟周期数×CPU时钟周期CPl表示每条指令周期数，即执行一条指令所需的平均时钟周期数。用下式计算：CPI=执行某段程序所需的CPU时钟周期数÷程序包含的指令条数MIPS(MillionInstructionsPerSecond)的缩写，表示平均每秒执行多少百万条定点指令数，用下式计算：MIPS=指令数÷(程序执行时间×106)FLOPS(Floating-pointOperationsPerSecond)的缩写，表示每秒执行浮点操作的次数，用来衡量机器浮点操作的性能。用下式计算：FLOPS=程序中的浮点操作次数÷程序执行时间(s)要了解数字计算机的主要组成和工作原理，可从打算盘说起。假设给一个算盘、一张带横格的纸和一支笔，要求计算y=ax+b–c这样一个题目。为了和下面讲到的内容做比较，不妨按以下方法把使用算盘进行解题的过程步骤事先用笔详细地记录在带横格的纸上。首先，将横格纸编上序号，每一行占一个序号，如1,2,3,…,n，如表1.3所示。其次，把计算式中给定的四个数a、b、c和x分别写到横格纸的第9、10、11、12行上，每一行只写一个数。接着详细列出给定题目的解题步骤，而解题步骤也需要记在横格纸上，每一步也只写一行。第一步写到横格纸的第1行，第二步写到第2行，……以此类推。在完成y=ax+b–c的计算过程中，用到了什么东西呢?首先，用到了带横格且编有序号的纸，把原始的数据及解题步骤记录在纸上，即纸“存储”了算题的原始信息。其次，用到了算盘，它用来对数据进行加、减、乘、除等算术运算。再次，用到了笔，利用笔把原始数据和解题步骤记录到纸上，还可把计算结果写出来告诉人。最后，用到了我们人本身，这主要是人的脑和手。在人的控制下，按照解题步骤一步一步进行操作，直到完成全部运算。电子数字计算机进行解题的过程完全和人用算盘解题的情况相似，也必须有运算工具，解题步骤和原始数据的输入与存储，运算结果的输出及整个计算过程的调度控制。和打算盘不同的是，以上这些部分都是由电子线路和其他设备自动进行的。在电子计算机里，相当于算盘功能的部件，我们称之为运算器；相当于纸那样具有“记忆”功能的部件，我们称之为存储器；相当于笔那样把原始解题信息送到计算机或把运算结果显示出来的设备，我们称之为输入设备或输出设备；而相当于人的大脑，能够自动控制整个计算过程的，称之为控制器。图1.2所示为数字计算机的主要组成结构，其中双线及箭头表示数据代码传送通路。运算器就好像是一个由电子线路构成的算盘，图1.3是它的示意图。它的主要功能是进行加、减、乘、除等算术运算。除此以外，还可以进行逻辑运算，因此通常称为ALU(算术逻辑运算部件)。人们习惯于十进制数的运算，但是考虑到电子器件的特性，计算机中通常采用二进制数。二进制数是以2为基数来计数，也就是“逢二进一”。在二进制数中，只有0和1两个数字。1和0可以用电压的高低、脉冲的有无来表示。这种电压的高低，脉冲的有无，在电子器件中很容易实现，而且设备也最省。二进制数的运算规律非常简单。例如，加法：0+0=0，0+1=1，1+0=1，1+1=10，最后一个加式中等号右边的“1”表示向上一位的进位。又如，乘法：0×0=0，0×1=0，1×0=0，1×1=1。正是由于二进制数运算规律简单，在电子器件中比较容易实现，因此，在电子数字计算机中广泛采用二进制数。二进制数和十进制数一样，在运算中，当数的位数越多时，计算的精度就越高。理论上讲，数的位数可以任意多。但是位数越多，所需的电子器件也越多，因此计算机的运算器长度一般是8位、16位、32位、64位。存储器的功能是保存或“记忆”解题的原始数据和解题步骤。为此，在运算前需要把参加运算的数据和解题步骤通过输入设备送到存储器中保存起来。注意，不论是数据，还是解题步骤，在存放到存储器以前，它们全已变成0或1表示的二进制代码。因此，存储器存储的也全是0或1表示的二进制代码。那么大量的0、1代码在存储器中如何保存呢?目前采用半导体器件来担当此任务。我们知道，一个半导体触发器由于有0和1两个状态，可以记忆一个二进制代码。一个数假定用16位二进制代码来表示，那么就需要有16个触发器来保存这些代码。通常，在存储器中把保存一个数的16个触发器称为一个存储单元。存储器是由许多存储单元组成的。每个存储单元都有编号，称为地址。向存储器中存数或者从存储器中取数，都要按给定的地址来寻找所选的存储单元，这相当于上面所讲的横格纸每一行存放一个数一样。图1.4所示为存储器的结构示意图。存储器所有存储单元的总数称为存储器的存储容量，通常用单位KB、MB来表示，如64KB、128MB。存储容量越大，表示计算机记忆储存的信息越多。半导体存储器的存储容量毕竟有限，因此计算机中又配备了存储容量更大的磁盘存储器和光盘存储器，称为外存储器。相对而言，半导体存储器称为内存储器，简称内存。控制器是计算机中发号施令的部件，它控制计算机的各部件有条不紊地进行工作。更具体地讲，控制器的任务是从内存中取出解题步骤加以分析，然后执行某种操作。运算器只能完成加、减、乘、除四则运算及其他一些辅助操作。对于比较复杂的计算题目，计算机在运算前必须化成一步一步简单的加、减、乘、除等基本操作来做。每一个基本操作就叫做一条指令，而解算某一问题的一串指令序列，叫做该问题的计算程序，简称为程序。例如，在前述求解y=ax+b–c的例子中，我们在横格纸上列出了它的解题步骤。解题步骤的每一步，只完成一种基本操作，所以就是一条指令，而整个解题步骤就是一个简单的计算程序。正如我们在横格纸上按行的序号记下解题步骤一样，计算机中为了顺利运算，也必须事先把程序和数据按地址安排到存储器里去。注意，程序中的指令通常按顺序执行，所以这些指令是顺次放在存储器里。这就相当于我们把表1.3所示的横格纸的内容原封不动地搬到存储器，因而所编的程序如表1.4所示。由表1.4可知，每条指令应当明确告诉控制器，从存储器的哪个单元取数，并进行何种操作。这样可知指令的内容由两部分组成，即操作的性质和操作数的地址。前者称为操作码，后者称为地址码。因而上述指令的形式如下：操作码地址码其中操作码指出指令所进行的操作，如加、减、乘、除、取数、存数等；而地址码表示参加运算的数据应从存储器的哪个单元中取来，或运算的结果应该存到哪个单元中去。指令的操作码和地址码用二进制代码来表示，其中地址码部分和数据一样，是二进制数的数码，而操作码部分则是二进制代码的编码。假定只有8种基本指令，那么这8种指令的操作码可用3位二进制代码来定义，如表1.5所示。这样一来，表1.5中指令的操作码部分就可以变成二进制代码。假如把地址码部分和数据也换成二进制数，那么整个存储器的内容全部变成了二进制的代码或数码，如图1.5所示。由图1.5可知，指令数码化以后，就可以和数据一样放入存储器。存储器的任何位置既可以存放数据也可以存放指令，不过一般是将指令和数据分开存放。将解题的程序(指令序列)存放到存储器中称为存储程序，而控制器依据存储的程序来控制全机协调地完成计算任务叫做程序控制。存储程序并按地址顺序执行，这就是冯·诺依曼型计算机的设计思想，也是机器自动化工作的关键。由于指令和数据放在同一个存储器，称为冯·诺依曼结构；如果指令和数据分别放在两个存储器，称为哈佛结构。显然后者结构的计算机速度更快。一台计算机通常有几十种基本指令，从而构成了该计算机的指令系统。指令系统不仅是硬件设计的依据，而且是软件设计的基础。因此，指令系统是衡量计算机性能的一个重要标志。由表1.4可知，计算机进行计算时，指令必须是按一定的顺序一条接一条地进行。控制器的基本任务，就是按照计算程序所排的指令序列，先从存储器取出一条指令放到控制器中，对该指令的操作码由译码器进行分析判别，然后根据指令性质，执行这条指令，进行相应的操作。接着从存储器取出第二条指令，再执行这第二条指令。以此类推。通常把取指令的一段时间叫做取指周期，而把执行指令的一段时间叫做执行周期。因此，控制器反复交替地处在取指周期与执行周期之中，如图1.6所示。每取出一条指令，控制器中的指令计数器就加1，从而为取下一条指令做好准备，这也就是指令在存储器中顺序存放的原因。在计算机系统中，运算器和控制器通常被组合在一个集成电路芯片中，合称为中央处理器（中央处理机），简称处理器，英文缩写为CPU。由于计算机仅使用0和1两个二进制数字，所以使用“位”(bit)作为数字计算机的最小信息单位。当CPU向存储器送入或从存储器取出信息时，不能存取单个的“位”，而用B(字节)和W(字)等较大的信息单位来工作。一个“字节”由8位二进制信息组成，而一个“字”则至少由一个以上的字节组成。通常把组成一个字的二进制位数叫做字长。例如，微型机的字长可以是8位，也可以达到64位。由于计算机使用的信息既有指令又有数据，所以计算机字既可以代表指令，也可以代表数据。如果某字代表要处理的数据，则称为数据字；如果某字为一条指令，则称为指令字。我们已经看到，指令和数据统统放在内存中，从形式上看，它们都是二进制数码，似乎很难分清哪些是指令字，哪些是数据字。然而控制器完全可以区分开哪些是指令字，哪些是数据字。一般来讲，取指周期中从内存读出的信息流是指令流，它流向控制器；而在执行周期中从内存读出的信息流是数据流，它由内存流向运算器。例如，图1.5中从地址1～7号单元读出的信息流是指令流，而从地址9～12号单元读出的信息流是数据流。显然，某些指令进行过程中需要两次访问内存，一次是取指令，另一次是取数据，如表1.4中取数、乘法、加法、减法、存数指令就是如此。理想的计算机输入设备应该是“会看”和“会听”，即能够把人们用文字或语言所表达的问题直接送到计算机内部进行处理，但是现在这种理想的输入设备还未大规模投入应用。目前常用的输入设备是键盘、鼠标、数字扫描仪及模数转换器等。它们的作用是把人们所熟悉的某种信息形式变换为机器内部所能接收和识别的二进制信息形式。输出设备的作用是把计算机处理的结果变换为人或其他机器设备所能接收和识别的信息形式。理想的输出设备应该是“会写”和“会讲”。“会写”已经做到，如目前广为使用的激光印字机、绘图仪、CRT显示器等。这些设备不仅能输出文字符号，而且还能画图作曲线。至于“会讲”即输出语言的设备，目前也有高级产品问世。计算机的输入/输出设备通常称为外围设备。这些外围设备有高速的也有低速的，有机电结构的，也有全电子式的。由于种类繁多且速度各异，因而它们不是直接与高速工作的主机相连接，而是通过适配器部件与主机相联系。适配器的作用相当于一个转换器。它可以保证外围设备用计算机系统特性所要求的形式发送或接收信息。一个典型的计算机系统具有各种类型的外围设备，因而有各种类型的适配器，它使得被连接的外围设备通过系统总线与主机进行联系，以便使主机和外围设备并行协调地工作。除了上述各部件外，计算机系统中还必须有总线。系统总线是构成计算机系统的骨架，是多个系统部件之间进行数据传送的公共通路。借助系统总线，计算机在各系统部件之间实现传送地址、数据和控制信息的操作。以上是我们对一台计算机硬件组成的概貌了解，其目的在于使读者对计算机的整体先有一个粗略的印象，为后面讲授各章提供一些方便。上面说过，现代电子计算机是由运算器、存储器、控制器、适配器、总线和输入/输出设备组成的。这些部件或设备都是由元器件构成的有形物体，因而称为硬件或硬设备。我们知道，使用算盘进行运算时，要按运算法则和计算步骤，利用珠算口诀来进行。如果只有算盘，没有运算法则和计算步骤，就不能用算盘来计算。电子计算机更是如此。如果只有上述硬件，计算机并不能进行运算，它仍然是一个“死”东西。那么计算机靠什么东西才能变“活”，从而高速自动地完成各种运算呢?这就是前面讲过的计算程序。因为它是无形的东西，所以称为软件或软设备。比方说，用算盘进行运算，算盘本身就是硬件，而运算法则和解题步骤等就是软件。事实上，利用电子计算机进行计算、控制或做其他工作时，需要有各种用途的程序。因此，凡是用于一台计算机的各种程序，统称为这台计算机的程序或软件系统。计算机软件一般分为两大类：一类叫系统程序，一类叫应用程序。系统程序用来简化程序设计，简化使用方法，提高计算机的使用效率，发挥和扩大计算机的功能及用途。它包括以下四类：①各种服务性程序，如诊断程序、排错程序、练习程序等；②语言程序，如汇编程序、编译程序、解释程序等；③操作系统；④数据库管理系统。应用程序是用户利用计算机来解决某些问题而编制的程序，如工程设计程序、数据处理程序、自动控制程序、企业管理程序、情报检索程序、科学计算程序等。随着计算机的广泛应用，这类程序的种类越来越多。如同硬件一样，计算机软件也是在不断发展的。下面以系统程序为例，简要说明软件的发展演变过程。在早期的计算机中，人们是直接用机器语言(即机器指令代码)来编写程序的，这种方式编写的程序称为手编程序。这种用机器语言书写的程序，计算机完全可以“识别”并能执行，所以又叫做目的程序。但直接用机器语言编写程序是一件很烦琐的工作，需要耗费大量的人力和时间，而且又容易出错，出错后寻找错误也相当费事。这些情况大大限制了计算机的使用。后来，为了编写程序方便和提高机器的使用效率，人们想了一种办法，用一些约定的文字、符号和数字按规定的格式来表示各种不同的指令，然后再用这些特殊符号表示的指令来编写程序。这就是所谓的汇编语言，它是一种能被转化为二进制文件的符号语言。对人来讲，符号语言简单直观、便于记忆，比二进制数表示的机器语言方便了许多。但计算机只“认识”机器语言而不认识这些文字、数字、符号，为此人们创造了一种程序，叫汇编器。如同英汉之间对话需要“翻译”一样，汇编器的作用相当于一个“翻译员”。借助于汇编器，计算机本身可以自动地把符号语言表示的程序(称为汇编语言程序)翻译成用机器语言表示的目的程序，从而实现了程序设计工作的部分自动化。使用符号语言编程序比用机器语言编程序是进了一步，但符号语言还是一种最初级的语言，和数学语言的差异很大，并且仍然面向一台具体的机器。由于不同的计算机其指令系统也不同，所以人们使用计算机时必须先花很多时间熟悉这台机器的指令系统，然后再用它的符号语言来编写程序，因此还是很不方便，节省的人力时间也有限。为了进一步实现程序自动化和便于程序交流，使不熟悉具体计算机的人也能很方便地使用计算机，人们又创造了各种接近于数学语言的算法语言。所谓算法语言，是指按实际需要规定好的一套基本符号及由这套基本符号构成程序的规则。算法语言比较接近数学语言，它直观通用，与具体机器无关，只要稍加学习就能掌握，便于推广使用计算机。有影响的算法语言有BASIC、FORTRAN、C、C++、Java等。用算法语言编写的程序称为源程序。但是，这种源程序如同汇编语言程序一样，是不能由机器直接识别和执行的，也必须给计算机配备一个既懂算法语言又懂机器语言的“翻译”，才能把源程序翻译为机器语言。通常采用的方法是给计算机配制一套用机器语言写的编译程序，它把源程序翻译成目的程序，然后机器执行目的程序，得出计算结果。但由于目的程序一般不能独立运行，还需要一种叫做运行系统的辅助程序来帮助。通常，把编译程序和运行系统合称为编译器。图1.7描述了一个在硬盘文件中的C语言程序，被转换成计算机上可运行的机器语言程序的四个步骤：C语言程序通过编译器首先被编译为汇编语言程序，然后通过汇编器汇编为机器语言的目标模块。链接器将多个模块与库程序组合在一起以解析所有的应用。加载器将机器代码放入合适的内存位置以便处理器执行。随着计算机技术的日益发展，原始的操作方式越来越不适应，特别是用户直接使用大型机器并独占机器，无论是对机器的效率来说还是对方便用户来说都不适宜。用户直接使用机器总觉得机器“太硬了”，很多情况都得依附它。而计算机又觉得用户及外部设备“太笨”，常常使它处于无事可做的状态，因此，迫切需要摆脱这种情况。显然人的思维速度跟不上计算机的计算速度，要摆脱这种情况还要依靠计算机来管理自己和管理用户，于是人们又创造出一类程序，叫做操作系统。它是随着硬件和软件的不断发展而逐渐形成的一套软件系统，用来管理计算机资源(如处理器，内存，外部设备和各种编译、应用程序)和自动调度用户的作业程序，而使多个用户能有效地共用一套计算机系统。操作系统的出现，使计算机的使用效率成倍地提高，并且为用户提供了方便的使用手段和令人满意的服务质量。根据不同使用环境要求，操作系统目前大致分为批处理操作系统、分时操作系统、网络操作系统、实时操作系统等多种。个人计算机中广泛使用微软公司的“视窗”操作系统。随着计算机在信息处理、情报检索及各种管理系统中应用的发展，要求大量处理某些数据，建立和检索大量的表格。这些数据和表格按一定的规律组织起来，使得处理更方便，检索更迅速，用户使用更方便，于是出现了数据库。所谓数据库，就是实现有组织地、动态地存储大量相关数据，方便多用户访问的计算机软、硬件资源组成的系统。数据库和数据库管理软件一起，组成了数据库管理系统。数据库管理系统有各种类型。目前许多计算机包括微型机，都配有数据库管理系统。随着软件的进一步发展，将开发更高级的计算机语言。这是因为目前所有的高级语言编写程序时，程序比较复杂，开发成本高。计算机语言发展的方向是标准化、积木化、产品化，最终是向自然语言发展，它们能够自动生成程序。从前两节讲述可知，计算机不能简单地认为是一种电子设备，而是一个十分复杂的硬、软件结合而成的整体。它通常由五个以上不同的级组成，每一级都能进行程序设计。第1级是微程序设计级或逻辑电路级。这是一个实在的硬件级，由硬件直接执行。如果某一个应用程序直接用微指令来编写，那么可在这一级上运行应用程序。第2级是一般机器级，也称为机器语言级，它由微程序解释机器指令系统。这一级也是硬件级。第3级是操作系统级，它由操作系统程序实现。这些操作系统由机器指令和广义指令组成，广义指令是操作系统定义和解释的软件指令，所以这一级也称为混合级。第4级是汇编语言级，它给程序人员提供一种符号形式语言，以减少程序编写的复杂性。这一级由汇编程序支持和执行。如果应用程序采用汇编语言编写，则机器必须要有这一级的功能；如果应用程序不采用汇编语言编写，则这一级可以不要。第5级是高级语言级，它是面向用户的，为方便用户编写应用程序而设置的。这一级由各种高级语言编译程序支持和执行。图1.8中，除第1级外，其他各级都得到它下级的支持，同时也受到运行在下面各级上的程序的支持。第1级到第3级编写程序采用的语言，基本是二进制数字化语言，机器执行和解释容易。第4、5两级编写程序所采用的语言是符号语言，用英文字母和符号来表示程序，因而便于大多数不了解硬件的人们使用计算机。显然，采用这种用一系列的级来组成计算机的概念和技术，对了解计算机如何组成提供了一种好的结构和体制。而且用这种分级的观点来设计计算机，对保证产生一个良好的系统结构也是很有帮助的。然而，随着大规模集成电路技术的发展和软件硬化的趋势，计算机系统的软、硬件界限已经变得模糊了。因为任何操作可以由软件来实现，也可以由硬件来实现；任何指令的执行可以由硬件完成，也可以由软件来完成。对于某一机器功能采用硬件方案还是软件方案，取决于器件价格、速度、可靠性、存储容量和变更周期等因素。当研制一台计算机的时候，设计者必须明确分配每一级的任务，确定哪些情况使用硬件，哪些情况使用软件，而硬件始终放在最低级。就目前而言，一些计算机的特点是，把原来明显地在一般机器级通过编制程序实现的操作，如整数乘除法指令、浮点运算指令、处理字符串指令等，改为直接由硬件完成。总之，随着大规模集成电路和计算机系统结构的发展，实体硬件机的功能范围在不断扩大。换句话说，第一级和第二级的边界范围，要向第三级乃至更高级扩展。这是因为容量大、价格低、体积小、可以改写的只读存储器提供了软件固化的良好物质手段。现在已经可以把许多复杂的、常用的程序制作成所谓的固件。就它的功能来说，是软件，但从形态上来说，又是硬件。其次，目前在一片硅单晶芯片上制作复杂的逻辑电路已经是实际可行的，这就为扩大指令的功能提供了物质基础，因此本来通过软件手段来实现的某种功能，现在可以通过硬件来直接解释执行。进一步的发展，就是设计所谓面向高级语言的计算机。这样的计算机，可以通过硬件直接解释执行高级语言的语句而不需要先经过编译程序的处理。因此传统的软件部分，今后完全有可能“固化”甚至“硬化”。习惯上所称的“电子计算机”是指现在广泛应用的电子数字计算机，它分为专用计算机和通用计算机两大类。专用和通用是根据计算机的效率、速度、价格、运行的经济性和适应性来划分的。通用计算机分为超级计算机、大型机、服务器、PC机、单片机、多核机六类，其结构复杂性、性能、价格依次递减。计算机的硬件是由有形的电子器件等构成的，它包括运算器、存储器、控制器、适配器、输入输出设备。早期将运算器和控制器合在一起称为CPU(中央处理器)。目前的CPU包含了存储器，因此称为中央处理机。存储程序并按地址顺序执行，这是冯·诺依曼型计算机的工作原理，也是CPU自动工作的关键。计算机的软件是计算机系统结构的重要组成部分，也是计算机不同于一般电子设备的本质所在。计算机软件一般分为系统程序和应用程序两大类。系统程序用来简化程序设计，简化使用方法，提高计算机的使用效率，发挥和扩大计算机的功能和用途，它包括：①各种服务性程序；②语言类程序；③操作系统；④数据库管理系统。应用程序是针对某一应用课题领域开发的软件。计算机系统是一个由硬件、软件组成的多级层次结构，它通常由微程序级、一般机器级、操作系统级、汇编语言级、高级语言级组成，每一级上都能进行程序设计，且得到下面各级的支持。计算机的性能指标主要是CPU性能指标、存储器性能指标和I/O吞吐率。在选择计算机的数的表示方式时，需要考虑以下几个因素：①要表示的数的类型(小数、整数、实数和复数)；②可能的数值范围；③数值精确度；④数据存储和处理所需要的硬件代价。计算机中常用的数据表示格式有两种，一是定点格式，二是浮点格式。一般来说，定点格式容许的数值范围有限，要求的处理硬件比较简单。而浮点格式容许的数值范围很大，要求的处理硬件比较复杂。1.定点数的表示方法所谓定点格式，即约定机器中所有数据的小数点位置是固定不变的。由于约定在固定的位置，小数点就不再使用记号“.”来表示。原理上讲，小数点位置固定在哪一位都可以，但是通常将数据表示成纯小数或纯整数。假设用一个n+1位字来表示一个定点数x，其中一位xn用来表示数的符号，其余位数代表它的量值。为了将整个n+1位统一处理，符号位xn放在最左位置，并用数值0和1分别代表正号和负号，这样，对于任意定点数x=xnxn–1…x1x0，在定点机中可表示为如下形式：目前计算机中多采用定点纯整数表示，因此将定点数表示的运算简称为整数运算。电子的质量(9×10–28g)和太阳的质量(2×1033g)相差甚远，在定点计算机中无法直接来表示这个数值范围。要使它们送入定点计算机进行某种运算，必须对它们分别取不同的比例因子，使其数值部分的绝对值小于1，即9×10–28=0.9×10–272×1033=0.2×1034这里的比例因子10–27和1034要分别存放在机器的某个存储单元中，便于以后对计算结果按这个比例增大。显然这要占用一定的存储空间和运算时间。从定点机取比例因子中我们得到一个启示，在计算机中还可以这样来表示数据：把一个数的有效数字和数的范围在计算机的一个存储单元中分别予以表示。这种把数的范围和精度分别表示的方法，相当于数的小数点位置随比例因子的不同而在一定范围内可以自由浮动，所以称为浮点表示法。任意一个十进制数N可以写成同样，在计算机中一个任意二进制数N可以写成其中M称为浮点数的尾数，是一个纯小数。e是比例因子的指数，称为浮点数的指数，是一个整数。比例因子的基数2对二进记数制的机器是一个常数。在机器中表示一个浮点数时，一是要给出尾数，用定点小数形式表示。尾数部分给出有效数字的位数，因而决定了浮点数的表示精度。二是要给出指数，用整数形式表示，常称为阶码，阶码指明小数点在数据中的位置，因而决定了浮点数的表示范围。浮点数也要有符号位。计算机中，一个机器浮点数由阶码和尾数及其符号位组成：大多数通用性较强的计算机都能直接处理十进制形式表示的数据。十进制数串在计算机内主要有两种表示形式：(1)字符串形式，即1字节存放一个十进制的数位或符号位。在主存中，这样的一个十进制数占用连续的多字节，故为了指明这样一个数，需要给出该数在主存中的起始地址和位数(串的长度)。这种方式表示的十进制字符串主要用在非数值计算的应用领域中。(2)压缩的十进制数串形式，即1字节存放两个十进制的数位。它比前一种形式节省存储空间，又便于直接完成十进制数的算术运算，是广泛采用的较为理想的方法。用压缩的十进制数串表示一个数，也要占用主存连续的多字节。每个数位占用半字节(即4个二进制位)，其值可用二-十编码(BCD码)或数字符的ASCII码的低4位表示。符第2章运算方法和运算器19号位也占半字节并放在最低数字位之后，其值选用四位编码中的六种冗余状态中的有关值，如用12(C)表示正号，用13(D)表示负号。在这种表示中，规定数位加符号位之和必须为偶数，当和不为偶数时，应在最高数字位之前补一个0。例如，+123和–12分别被表示成：在上述表示中，一个实线框表示1字节，虚线把一个字节分为高低各半字节，每一个小框内给出一个数值位或符号位的编码值(用十六进制形式给出)。符号位在数字位之后。与第一种表示形式类似，要指明一个压缩的十进制数串，也得给出它在主存中的首地址和数字位个数(不含符号位)，又称位长，位长为0的数其值为0。十进制数串表示法的优点是位长可变，许多机器中规定该长度为0～31，有的甚至更长。2.1.2数的机器码表示前面介绍了数的小数点表示，下面还需要解决数的机器码表示问题。在计算机中对数据进行运算操作时，符号位如何表示呢?是否也同数值位一道参加运算操作呢?如参加，会给运算操作带来什么影响呢?为了妥善地处理好这些问题，就产生了把符号位和数值位一起编码来表示相应的数的各种表示方法，如原码、补码、反码、移码。为了区别一般书写表示的数和机器中这些编码表示的数，通常将前者称为真值，后者称为机器数或机器码。若定点整数的原码形式为xnxn–1…x1x0(xn为符号位)，则原码表示的定义是式中，[x]原是机器数，x是真值。例如，x=+1001，则[x]原=01001x=–1001，则[x]原=11001一般情况下，对于正数x=+xn–1…x1x0，则有[x]原=0xn–1…x1x0对于负数x=–xn–1…x1x0，则有[x]原=1xn–1…x1x0对于0，原码机器中往往有“+0”、“–0”之分，故有两种形式：[+0]原=0000…0[–0]原=1000…0采用原码表示法简单易懂，即符号位加上二进制数的绝对值，但它的最大缺点是加法运算复杂。这是因为，当两数相加时，如果是同号则数值相加；如果是异号，则要进行减法。而在进行减法时，还要比较绝对值的大小，然后大数减去小数，最后还要给结果选择恰当的符号。为了解决这些矛盾，人们找到了补码表示法。计算机组成原理20我们先以钟表对时为例说明补码的概念。假设现在的标准时间为4点正，而有一只表已经7点了，为了校准时间，可以采用两种方法：一是将时针退7–4=3格；一是将时针向前拨12–3=9格。这两种方法都能对准到4点，由此看出，减3和加9是等价的。就是说9是(–3)对12的补码，可以用数学公式表示为–3=+9(mod12)mod12的意思就是12为模数，这个“模”表示被丢掉的数值。上式在数学上称为同余式。上例中7–3和7+9(mod12)等价，原因就是表指针超过12时，将12自动丢掉，最后得到16–12=4。同样地，以12为模时，–4=+8(mod12)–5=+7(mod12)从这里可以得到一个启示，就是负数用补码表示时，可以把减法转化为加法。这样，在计算机中实现起来就比较方便。对定点整数，补码形式为xnxn–1…x1x0，xn为符号位，则补码表示的定义是采用补码表示法进行减法运算比原码方便多了。因为不论数是正或负，机器总是做加法，减法运算可变成加法运算。但根据补码定义，求负数的补码还要做减法，这显然不方便，为此可通过反码来解决。我们先引出数的补码表示与真值的关系。设一个二进制整数补码有n+1位(含1位符号位xn)，即[x]补=xnxn–1xn–2…x1x0则其补码表示的真值为由此可知，式(2.7)统一表示了正负整数的补码与真值的关系。下面说明由原码表示法变成补码表示法的方法。在定点数的反码表示法中，正数的机器码仍然等于其真值；而负数的机器码符号位为1，尾数则将真值的各个二进制位取反。由于原码变反码很容易实现(触发器互补输出端得到)，所以用反码作为过渡，就可以很容易得到补码。一个正整数，当用原码、反码、补码表示时，符号位都固定为0，用二进制表示的数位值都相同，即三种表示方法完全一样。一个负整数，当用原码、反码、补码表示时，符号位都固定为1，用二进制表示的数位值都不相同。此时由原码表示法变成补码表示法的规则如下：(1)原码符号位为1不变，整数的每一位二进制数位求反得到反码；(2)反码符号位为1不变，反码数值位最低位加1，得到补码。3.移码表示法移码通常用于表示浮点数的阶码。由于阶码是个k位的整数，假定定点整数移码形式为ekek–1…e2e1e0(最高位为符号位)时，移码的传统定义是[e]移=2k+e，2k＞e≥–2k(2.8)式中，[e]移为机器数，e为真值，2k是一个固定的偏移值常数。若阶码数值部分为5位，以e表示真值，则[e]移=25+e，25＞e≥–25例如，当正数e=+10101时，[e]移=1，10101；当负数e=–10101时，[e]移=25+e=25–10101=0，01011。移码中的逗号不是小数点，而是表示左边一位是符号位。显然，移码中符号位ek表示的规律与原码、补码、反码相反。移码表示法对两个指数大小的比较和对阶操作都比较方便，因为阶码域值大者其指数值也大。4.浮点数的机器表示早期，各个计算机系统的浮点数使用不同的机器码表示阶和尾数，给数据的交换和比较带来很大麻烦。当前的计算机都采用统一的IEEE754标准中的格式表示浮点数。IEEE754标准规定的32位短浮点数和64位长浮点数的标准格式为不论是32位浮点数还是64位浮点数，由于基数2是固定常数，对每一个浮点数都一样，所以不必用显式方式来表示它。32位的浮点数中，S是浮点数的符号位，占1位，安排在最高位，S=0表示正数，S=1表示负数。M是尾数，放在低位部分，占用23位，小数点位置放在尾数域最左(最高)有效位的右边。E是阶码，占用8位，阶符采用隐含方式，即采用移码方法来表示正负指数。采用这种方式时，将浮点数的指数真值e变成阶码E时，应将指数e加上一个固定的偏置常数127，即E=e+127。若不对浮点数的表示作出明确规定，同一个浮点数的表示就不是唯一的。例如，(1.75)10可以表示成1.11×20、0.111×21、0.0111×22等多种形式。为了提高数据的表示精度，当尾数的值不为0时，尾数域的最高有效位应为1，这称为浮点数的规格化表示。对于非规格化浮点数，一般可以通过修改阶码同时右移动小数点位置的办法，使其变成规格化数的形式。在IEEE754标准中，一个规格化的32位浮点数x的真值表示为其中尾数域所表示的值是1.M。由于规格化的浮点数的尾数域最左位(最高有效位)总是1，故这一位无需存储，而认为隐藏在小数点的左边。于是用23位字段可以存储24位有效数。对32位浮点数N，IEEE754定义：(1)若E=255且M<>0，则N=NaN。符号NaN表示无定义数据，采用这个标志的目的是让程序员能够推迟进行测试及判断的时间，以便在方便的时候进行。(2)若E=255且M=0，则N=(–1)S∞。当阶码E为全1且尾数M为全0时，表示的真值N为无穷大，结合符号位S为0或1，也有+∞和–∞之分。(3)若E=0且M=0，则N=(–1)S0。当阶码E为全0且尾数M也为全0时，表示的真值N为零(称为机器0)，结合符号位S为0或1，有正零和负零之分。(4)若0<E<255，则N=(–1)S×(1.M)×2E–127(规格化数)。除去用E为全0和全1(即十进制255)表示零和无穷大的特殊情况，指数的偏移值不选27=128(10000000)，而选27–1=127(01111111)。对于规格化浮点数，阶码E的范围变为1～254，指数值e则为–126～+127。因此32位浮点数表示的绝对值的范围是10–38～1038。(5)若E=0且M<>0，则N=(–1)S×(0.M)×2–126(非规格化数)。对于规格化无法表示的数据，可以用非规格化形式表示。64位的浮点数中符号位1位，阶码域11位，尾数域52位，指数偏移值是1023。因此规格化的64位浮点数x的真值为浮点数所表示的范围远比定点数大。一般在高档微机以上的计算机中同时采用定点、浮点表示，由使用者进行选择。而单片机中多采用定点表示。现代计算机不仅处理数值领域的问题，而且处理大量非数值领域的问题。这样一来，必然要引入文字、字母及某些专用符号，以便表示文字语言、逻辑语言等信息。例如，人机交换信息时使用英文字母、标点符号、十进制数及诸如＄，%，+等符号。然而数字计算机只能处理二进制数据，因此，上述信息应用到计算机中时，都必须编写成二进制格式的代码，也就是字符信息用数据表示，称为符号数据。目前国际上普遍采用的一种字符系统是七单位的IRA码。其美国版称为ASCII码(美国国家信息交换标准字符码)，它包括10个十进制数码，26个英文字母和一定数量的专用符号，如＄，%，+等，总共128个元素，因此二进制编码需要7位，加上一个偶校验位，共8位，刚好为1字节。ASCII码规定8个二进制位的最高一位为0，余下的7位可以给出128个编码，表示128个不同的字符。其中95个编码，对应着计算机终端能敲入并且可以显示的95个字符，打印机设备也能打印这95个字符，如大小写各26个英文字母，0～9这10个数字符，通用的运算符和标点符号+，–，*，\，>，=，<等。另外的33个字符，其编码值为0～31和127，则不对应任何一个可以显示或打印的实际字符，它们被用作控制码，控制计算机某些外围设备的工作特性和某些计算机软件的运行情况。ASCII编码和128个字符的对应关系如表2.1所示。表中编码符号的排列次序为b7b6b5b4b3b2b1b0，其中b7恒为0，表中未给出，b6b5b4为高位部分，b3b2b1b0为低位部分。可以看出，十进制的8421码可以去掉b6b5b4(=011)而得到。字符串是指连续的一串字符，通常方式下，它们占用主存中连续的多字节，每字节存一个字符。当主存字由2或4字节组成时，在同一个主存字中，既可按从低位字节向高位字节的顺序存放字符串内容，也可按从高位字节向低位字节的顺序存放字符串内容。这两种存放方式都是常用方式，不同的计算机可以选用其中任何一种。例如下述字符串：IFA>BTHENREAD(C)就可以按图2.1所示从高位字节到低位字节依次存放在主存中。其中主存单元长度由4字节组成。每字节中存放相应字符的ASCII值，文字表达式中的空格“”在主存中也占1字节的位置。因而每字节分别存放十进制的73，70，32，65，62，66，32，84，72，69，78，32，82，69，65，68，为了能直接使用西文标准键盘把汉字输入到计算机，就必须为汉字设计相应的输入编码方法。当前采用的方法主要有以下三类：数字编码常用的是国标区位码，用数字串代表一个汉字输入。区位码是将国家标准局公布的6763个两级汉字分为94个区，每个区分94位，实际上把汉字表示成二维数组，每个汉字在数组中的下标就是区位码。区码和位码各两位十进制数字，因此输入一个汉字需按键四次。例如“中”字位于第54区48位，区位码为5448。数字编码输入的优点是无重码，且输入码与内部编码的转换比较方便，缺点是代码难以记忆。拼音码拼音码是以汉语拼音为基础的输入方法。凡掌握汉语拼音的人，不需训练和记忆，即可使用。但汉字同音字太多，输入重码率很高，因此按拼音输入后还必须进行同音字选择，影响了输入速度。字形编码字形编码是用汉字的形状进行的编码。汉字总数虽多，但是由一笔一画组成，全部汉字的部件和笔画是有限的。因此，把汉字的笔画部件用字母或数字进行编码，按笔画的顺序依次输入，就能表示一个汉字。例如五笔字型编码是最有影响的一种字形编码方法。除了上述三种编码方法之外，为了加快输入速度，在上述方法基础上，发展了词组输入、联想输入等多种快速输入方法。但是都利用了键盘进行“手动”输入。理想的输入方式是利用语音或图像识别技术“自动”将拼音或文本输入到计算机内，使计算机能认识汉字，听懂汉语，并将其自动转换为机内代码表示。目前这种理想已经成为现实。汉字内码是用于汉字信息的存储、交换、检索等操作的机内代码，一般采用2字节表示。英文字符的机内代码是七位的ASCII码，当用1字节表示时，最高位为“0”。为了与英文字符能相互区别，汉字机内代码中2字节的最高位均规定为“1”。例如，汉字操作系统CCDOS中使用的汉字内码是一种最高位为“1”的两字节内码。有些系统中字节的最高位用于奇偶校验位，这种情况下用3字节表示汉字内码。字模码是用点阵表示的汉字字形代码，它是汉字的输出形式。根据汉字输出的要求不同，点阵的多少也不同。简易型汉字为16×16点阵，提高型汉字为24×24点阵、32×32点阵，甚至更高。因此字模点阵的信息量是很大的，所占存储空间也很大。以16×16点阵为例，每个汉字要占用32字节，国标两级汉字要占用256K字节。因此字模点阵只能用来构成汉字库，而不能用于机内存储。字库中存储了每个汉字的点阵代码。当显示输出或打印输出时才检索字库，输出字模点阵，得到字形。注意，汉字的输入编码、汉字内码、字模码是计算机中用于输入、内部处理、输出三种不同用途的编码，不要混为一谈。元件故障、噪声干扰等各种因素常常导致计算机在处理信息过程中出现错误。例如，将1位二进制数x从部件A传送到部件B，可能由于传送信道中的噪声干扰而受到破坏，以至于在接收部件B收到的是x而不是x。为了防止这种错误，可将信号采用专门的逻辑电路进行编码以检测错误，甚至校正错误。通常的方法是，在每个字上添加一些校验位，用来确定字中出现错误的位置。计算机中常用这种检错或纠错技术进行存储器读写正确性或传输信息的检验。这里仅介绍检错码。最简单且应用广泛的检错码是采用一位校验位的奇校验或偶校验。设X=(x0x1…xn–1)是一个n位字，则奇校验位C定义为2.1节已介绍了数的补码表示法，负数用补码表示后，就可以和正数一样来处理。这样，运算器里只需要一个加法器就可以了，不必为了负数的加法运算，再配一个减法器。计算机组成原理28补码加法的公式是[x]补+[y]补=[x+y]补(mod2n+1)(2.13)可分四种情况来证明。假设采用定点整数表示，因此证明的先决条件是：x＜(2n–1)，y＜(2n–1)，xy＜(2n–1)。(1)x≥0，y≥0，则x+y≥0。相加两数都是正数，故其和也一定是正数。正数的补码和原码是一样的，根据数据补码定义可得[x]补+[y]补=x+y=[x+y]补(mod2n+1)(2)x≥0，y＜0，则x+y≥0或x+y＜0。相加的两数一个为正，一个为负，因此相加结果有正、负两种可能。根据补码定义，[x]补=x，[y]补=2n+1+y所以[x]补+[y]补=x+2n+1+y=2n+1+(x+y)=[x+y]补(mod2n+1)(3)x＜0，y≥0，则x+y≥0或x+y＜0。这种情况和第(2)种情况一样，把x和y的位置对调即得证。(4)x＜0，y＜0，则x+y＜0。相加两数都是负数，则其和也一定是负数。[x]补=2n+1+x，[y]补=2n+1+y所以[x]补+[y]补=2n+1+x+2n+1+y=2n+1+(2n+1+x+y)=[x+y]补(mod2n+1)式(2.13)说明，在模2n+1意义下，任意两数的补码之和等于该两数之和的补码。这是补码加法的理论基础。在定点整数机器中，数的表示范围x<(2n–1)。在运算过程中如出现大于字长绝对值的现象，称为“溢出”。在定点机中，运算过程中出现溢出时其结果是不正确的，故运算器必须能检测出溢出。【之所以发生错误，是因为运算结果产生了溢出。两个正数相加，结果大于机器字长所能表示的最大正数，称为正溢。而两个负数相加，结果小于机器所能表示的最小负数，称为负溢，如图2.2所示。为了判断“溢出”是否发生，可采用两种检测方法。第一种方法是采用双符号位法，这称为“变形补码”，从而可使模2n+1补码所能表示的数的范围扩大一倍。数的变形补码用同余式表示时为了得到两数变形补码之和等于两数和的变形补码，同样必须：①两个符号位都看做数码一样参加运算；②两数进行以2n+2为模的加法，即最高符号位上产生的进位要丢掉。采用变形补码后，任何正数，两个符号位都是“0”，即00xn–1xn–2…x1x0；任何负数，两个符号位都是“1”，即11xn–1xn–2…x1x0。如果两个数相加后，其结果的符号位出现“01”或“10”两种组合时，表示发生溢出。最高符号位永远表示结果的正确符号。两个符号位出现“10”，表示负溢出，即结果小于–2n。由此，我们可以得出如下结论：(1)当以变形补码运算，运算结果的二符号位相异时，表示溢出；相同时，表示未溢出。故溢出逻辑表达式为V=Sf1Sf2，其中Sf1和Sf2分别为最高符号位和第二符号位。此逻辑表达式可用异或门实现。(2)模2n+2补码相加的结果，不论溢出与否，最高符号位始终指示正确的符号。第二种溢出检测方法是采用单符号位法。从例17和例18中看到，当最高有效位产生进位而符号位无进位时，产生正溢；当最高有效位无进位而符号位有进位时，产生负溢。故溢出逻辑表达式为V=CfC0，其中Cf为符号位产生的进位，C0为最高有效位产生的进位。此逻辑表达式也可用异或门实现。在定点机中，当运算结果发生溢出时表示出错，机器通过逻辑电路自动检查出这种溢出，并进行中断处理。图2.3(a)示出了补码运算的二进制加法/减法器逻辑结构图。由图看到，n个1位的全加器(FA)可级联成一个n位的行波进位加减器。M为方式控制输入线，当M=0时，做加法(A+B)运算；当M=1，做减法(A–B)运算，在后一种情况下，A–B运算转化成[A]补+[–B]补运算，求补过程由B+1来实现。因此，图中最右边的全加器的起始进位输入端被连接到功能方式线M上，做减法时M=1，相当于在加法器的最低位上加1。另外，图中左边还表示出单符号位法的溢出检测逻辑：当Cn=Cn–1时，运算无溢出；而当Cn≠Cn–1时，运算有溢出，经异或门产生溢出信号。两个二进制数字Ai，Bi和一个进位输入Ci相加，产生一个和输出Si，以及一个进位输出Ci+1。表2.2中列出一位全加器FA进行加法运算的输入输出真值表。根据表2.2所示的真值表，三个输入端和两个输出端可按如下逻辑方程进行联系：Si=AiBiCiCi+1=AiBi+BiCi+CiAi=AiBi+(AiBi)Ci(2.20)按此表达式组成的FA示于图2.3(a)，进位链采用1个与门和1个或门。对图2.3(a)所示的一位全加器(FA)来说，求和结果Si的时间延迟为6T(每级异或门延迟3T)。Ci+1的时间延迟为2T，其中T被定义为相应于单级逻辑电路的单位门延迟。T通常采用一个“与”门或一个“或”门的时间延迟来作为度量单位，因此多级进位链的时间延迟可以用与-或门的级数或者T的数目来计算得到。现在计算n位行波进位加法器图2.3(b)的时间延迟。假如采用图2.3(a)所示的一位全加器FA并考虑溢出检测，那么n位行波进位加法器的延迟时间ta为其中，9T为最低位上的两级“异或”门再加上溢出“异或”门的总时间，2T为每级进位链的延迟时间。ta意味着加法器的输入端输入加数和被加数后，在最坏情况下加法器输出端得到稳定的求和输出所需的最长时间。显然这个时间越小越好。注意，加数、被加数、进位与和数都是用电平来表示的，因此，所谓稳定的求和输出，就是指稳定的电平输出。思考题为什么一套加法器可以实现加法和减法操作？创新点在何处？在定点计算机中，两个原码表示的数相乘的运算规则是：乘积的符号位由两数的符号位按异或运算得到，而乘积的数值部分则是两个正数相乘之积。设n位被乘数和乘数用定点整数表示被乘数[x]原=xfxn–1…x1x0乘数[y]原=yfyn–1…y1y0乘积[z]原=(xfyf)+(xn–1…x1x0)(yn–1…y1y0)(2.22)式中，xf为被乘数符号，yf为乘数符号。乘积符号的运算法则是：同号相乘为正，异号相乘为负。由于被乘数和乘数的符号组合只有四种情况(xfyf=00,01,10,11)，因此积的符号可按“异或”(按位加)运算得到。数值部分的运算方法与普通的十进制小数乘法相类似，不过对于用二进制表达的数来说，其乘法规则更为简单一些。设x=1101，y=1011，先用习惯方法求其乘积，其过程如下：1101(x)×1011(y)110111010000+110110001111(z)运算的过程与十进制乘法相似：从乘数y的最低位开始，若这一位为“1”，则将被乘数x写下；若这一位为“0”，则写下全0。然后再对乘数y的高一位进行乘法运算，其规则同上，不过这一位乘数的权与最低位乘数的权不一样，因此被乘数x要左移一位。以此类推，直到乘数各位乘完为止，最后将它们统统加起来，便得到最后乘积z。如果被乘数和乘数用定点小数表示，我们也会得到同样的结果。但是人们习惯的算法对机器并不完全适用。原因之一，机器通常只有n位长，两个n位数相乘，乘积可能为2n位。原因之二，只有两个操作数相加的加法器，难以胜任将n个位积一次相加起来的运算。因此，在早期计算机中为了简化硬件结构，采用串行的1位乘法方案，即多次执行“加法-移位”操作来实现。这种方法并不需要很多器件。然而串行方法毕竟太慢，不能满足科学技术对高速乘法所提出的要求。由于乘法运算大约占全部算术运算的1/3，因此采用高速乘法部件，无论从速度上来说还是从效率上来说，都是十分必要的。自从大规模集成电路问世以来，高速的单元阵列乘法器应运而生，出现了各种形式的流水式阵列乘法器，它们属于并行乘法器。鉴于串行乘法器已被淘汰，下面只介绍并行乘法器。设有两个不带符号的二进制整数：A=am–1…a1a0B=bn–1…b1b0上述过程说明了在m位×n位不带符号整数的阵列乘法中加法-移位操作的被加数矩阵。每一个部分乘积项(位积)aibj叫做一个被加数。这m×n个被加数｛aibj｜0≤i≤m–1和0≤j≤n–1｝可以用m×n个“与”门并行地产生，如图2.4的上半部分所示。显然，设计高速并行乘法器的基本问题，就在于缩短被加数矩阵中每列所包含的1的加法时间。现以5位×5位不带符号的阵列乘法器(m=n=5)为例来说明并行阵列乘法器的基本原理。图2.5示出了5位×5位阵列乘法器的逻辑电路图，其中FA是前面讲过的一位全加器，FA的斜线方向为进位输出，竖线方向为和输出，而所有被加数项的排列和前述A×B=P乘法过程中的被加数矩阵相同。图中用虚线围住的阵列中最后一行构成了一个行波进位加法器，其求和时间延迟为(n–1)2T+3T(异或门)。当然，为了缩短加法时间，最下一行的行波进位加法器也可以用先行进位加法器来代替。这种乘法器要实现n位×n位时，需要n(n–1)个全加器和n2个与门。该乘法器的总的乘法时间可以估算如下：令Ta为与门的传输延迟时间，Tf为全加器(FA)的进位传输延迟时间，假定用2级“与或”逻辑来实现FA的进位链功能，那么就有Ta=T，Tf=2T从图2.5可见，最坏情况下的延迟途径，即是沿着矩阵p4垂直线和最下面的一行进位及p8求和。参见图2.3(b)，n位×n位不带符号的阵列乘法器总的乘法时间估算为对带符号的阵列乘法器的结构来说，按其所用的数的表示方法而有所不同。在介绍带符号的阵列乘法器基本原理以前，我们先来看看算术运算部件设计中经常用到的求补电路。图2.6示出了一个具有使能控制的二进制对2求补器电路图，其逻辑表达式如下：C–1=0，Ci=ai+Ci–1*ia=aiECi–1，0≤i≤n对2求补时，采用按位扫描技术来执行所需要的求补操作。令A=an…a1a0是给定的(n+1)位带符号的数，要求确定它的补码形式。进行求补的方法就是从数的最右端a0开始，由右向左，直到找出第一个“1”，例如，ai=1，0≤i≤n。这样，ai以右的每一个输入位，包括ai自己，都保持不变，而ai以左的每一个输入位都求反，即1变0，0变1。鉴于此，横向链式线路中的第i扫描级的输出Ci为1的条件是：第i级的输入位ai=1，或者第i级链式输入(来自右起前i–1级的链式输出)Ci–1=1。另外，最右端的起始链式输入C–1必须永远置成“0”。当控制信号线E为“1”时，启动对2求补的操作；当控制信号线E为“0”时，输出将和输入相等。显然，我们可以利用符号位来作为控制信号。例如，在一个4位的对2求补器中，如果输入数为1010，那么输出数应是0110，其中从右算起的第2位，就是所遇到的第一个“1”的位置。用这种对2求补器来转换一个(n+1)位带符号的数，所需的总时间延迟为tTC=n·2T+5T=(2n+5)T(2.24)其中每个扫描级需2T延迟，而5T则是由于“与”门和“异或”门引起的。现在让我们来讨论带符号的阵列乘法器。图2.7给出了(n+1)位×(n+1)位带求补器的阵列乘法器逻辑方框图。通常，把包含这些求补级的乘法器又称为符号求补的阵列乘法器。在这种逻辑结构中，共使用了三个求补器。其中两个算前求补器的作用是：将两个操作数A和B在被不带符号的乘法阵列(核心部件)相乘以前，先变成正整数。而算后求补器的作用则是：当两个输入操作数的符号不一致时，把运算结果变换成带符号的数。设A=anan–1…a1a0和B=bnbn–1…b1b0均为用定点表示的(n+1)位带符号整数。由图2.7看到，在必要的求补操作以后，A和B的码值输送给n位×n位不带符号的阵列乘法器，并由此产生2n位乘积为A·B=P=p2n–1…p1p0p2n=anbn其中，p2n为符号位。图2.7所示的带求补器的阵列乘法器既适用于原码乘法，也适用于间接的补码乘法。不过在原码乘法中，算前求补和算后求补都不需要，因为输入数据都是立即可用的。而间接的补码阵列乘法却需要使用三个求补器。为了完成所必需的求补与乘法操作，时间大约比原码阵列乘法增加1倍。1.可控加法/减法(CAS)单元和阵列乘法器相似，阵列除法器也是一种并行运算部件，采用大规模集成电路制造。与早期的串行除法器相比，阵列除法器不仅所需要的控制线路少，而且能够提供令人满意的高速运算速度。阵列除法器有多种形式，如加减交替阵列除法器、补码阵列除法器等。这里以加减交替阵列除法器为例，来说明这类除法器的组成原理。在介绍加减交替阵列除法器以前，首先介绍可控加法/减法(CAS)单元，因为它将被采用于下面所介绍的除法流水逻辑阵列中。图2.8(a)示出了可控加法/减法(CAS)单元的逻辑电路图，它有四个输出端和四个输入端。当输入线P=0时，CAS做加法运算；当P=1时，CAS做减法运算。在这两个表达式中，每一个都能用一个三级组合逻辑电路(包括反相器)来实现。因此每一个基本的CAS单元的延迟时间为3T单位。后面将利用这个单元的延迟时间来精确确定除法时间。2.加减交替的阵列除法器现在转入讨论加减交替的阵列除法器，假定所有被处理的数都是正小数。在加减交替的除法阵列中，每一行所执行的操作究竟是加法还是减法，取决于前一行输出的符号与被除数的符号是否一致。当出现不够减时，部分余数相对于被除数来说要改变符号。这时应该产生一个商位“0”，除数首先沿对角线右移，然后加到下一行的部分余数上。当部分余数不改变它的符号时，即产生商位“1”，下一行的操作应该是减法。图2.8(b)示出了4位除4位的加减交替阵列除法器的逻辑原理图。其中被除数x=0.x6x5x4x3x2x1(双倍长)除数y=0.y3y2y1商数q=0.q3q2q1余数r=0.00r6r5r4r3字长n+1=4由图2.8看出，该阵列除法器是用一个可控加法/减法(CAS)单元所组成的流水阵列来实现的。推广到一般情况，一个(n+1)位÷(n+1)位的加减交替除法阵列由(n+1)2个CAS单元组成，其中两个操作数(被除数与除数)都是正的。单元之间的互联是用n=3的阵列来表示的。这里被除数x是一个6位的小数(双倍长数值)：x=0.x6x5x4x3x2x1它是由顶部一行和最右边的对角线上的垂直输入线来提供的。除数y是一个3位的小数：y=0.y3y2y1它沿对角线方向进入这个阵列。这是因为，在除法中将所需要的部分余数保持固定，而将除数沿对角线右移。商q是一个3位的小数：q=0.q3q2q1它在阵列的左边产生。余数r是一个6位的小数：r=0.00r6r5r4r3它在阵列的最下一行产生。最上面一行所执行的初始操作一定是减法。因此最上面一行的控制线P固定置成“1”。减法是用2的补码运算来实现的，这时右端各CAS单元上的反馈线用作初始的进位输入，即最低位上加“1”。每一行最左边的单元的进位输出决定着商的数值。将当前的商反馈到下一行，我们就能确定下一行的操作。由于进位输出信号指示出当前的部分余数的符号，因此，正如前面所述，它决定下一行的操作将进行加法还是减法。对加减交替阵列除法器来说，在进行运算时，沿着每一行都有进位(或借位)传播，同时所有行在它们的进位链上都是串行连接。而每个CAS单元的延迟时间为3T单元，因此，对一个2n位除以n位的加减交替阵列除法器来说，单元的数量为(n+1)2，考虑最大情况下的信号延迟，其除法执行时间为td=3(n+1)2T(2.27)其中n为尾数数位。运算器是数据的加工处理部件，是CPU的重要组成部分。尽管各种计算机的运算器结构可能有这样或那样的不同，但是它们的最基本的结构中必须有算术/逻辑运算单元、数据缓冲寄存器、通用寄存器、多路转换器和数据总线等逻辑构件。计算机中除了进行加、减、乘、除等基本算术运算以外，还可对两个或一个逻辑数进行逻辑运算。所谓逻辑数，是指不带符号的二进制数。利用逻辑运算可以进行两个数的比较，或者从某个数中选取某几位等操作。例如，当利用计算机做过程控制时，我们可以利用逻辑运算对一组输入的开关量做出判断，以确定哪些开关是闭合的，哪些开关是断开的。总之，在非数值应用的广大领域中，逻辑运算是非常有用的。计算机中的逻辑运算，主要是指逻辑非、逻辑加、逻辑乘、逻辑异等四种基本运算。逻辑非也称求反。对某数进行逻辑非运算，就是按位求它的反，常用变量上方加一横来表示。设一个数x表示成：x=x0x1x2…xn对x求逻辑非，则有x=z=z0z1z2…znzi=ix，i=0,1,2,…,n我们在2.2.4节中曾介绍由一位全加器(FA)构成的行波进位加法器，它可以实现补码数的加法运算和减法运算。但是这种加法/减法器存在两个问题。一是由于串行进位，它的运算时间很长。假如加法器由n位全加器构成，每一位的进位延迟时间为20ns，那么最坏情况下，进位信号从最低位传递到最高位而最后输出稳定，至少需要n×20ns，这在高速计算中显然是不利的。二是就行波进位加法器本身来说，它只能完成加法和减法两种操作而不能完成逻辑操作。为此，本节先介绍多功能算术/逻辑运算单元(ALU)，它不仅具有多种算术运算和逻辑运算的功能，而且具有先行进位逻辑，从而能实现高速运算。1.基本思想2.2.4节中给出一位全加器(FA)的逻辑表达式(2.20)为Fi=AiBiCiCi+1=AiBi+BiCi+CiAi式中，Fi是第i位的和数，Ai、Bi是第i位的被加数和加数，Ci是第i位的进位输入，Ci+1为第i位的进位输出。为了将全加器的功能进行扩展以完成多种算术/逻辑运算，我们先不将输入Ai、Bi和下一位的进位数Ci直接进行全加，而是将Ai和Bi先组合成由控制参数S0、S1、S2、S3控制的组合函数Xi和Yi(图2.9)，然后再将Xi、Yi和下一位进位数通过全加器进行全加。这样，不同的控制参数可以得到不同的组合函数，因而能够实现多种算术运算和逻辑运算。因此，一位算术/逻辑运算单元的逻辑表达式修改为Fi=XiYiCn+iCn+i+1=XiYi+YiCn+i+Cn+iXi(2.28)式(2.28)中进位下标用n+i代替原来一位全加器中的i，i代表集成在一片电路上的ALU的二进制位数，对于4位一片的ALU，i=0,1,2,3。n代表若干片ALU组成更大字长的运算器时每片电路的进位输入，如当4片组成16位字长的运算器时，n=0,4,8,12。2.逻辑表达式控制参数S0、S1、S2、S3分别控制输入Ai和Bi，产生Yi和Xi的函数。其中Yi是受S0、S1控制的Ai和Bi的组合函数，而Xi是受S2、S3控制的Ai和Bi的组合函数，其函数关系如表2.3所示。根据上面所列的函数关系，即可列出Xi和Yi的逻辑表达式这样，对一片ALU来说，可有三个进位输出。其中G称为进位发生输出，P称为进位传送输出。在电路中多加这两个进位输出的目的，是为了便于实现多片(组)ALU之间的先行进位，为此还需一个配合电路，称为先行进位发生器(CLA)，将在下面介绍。Cn+4是本片(组)的最后进位输出。逻辑表达式表明，这是一个先行进位逻辑。换句话说，第0位的进位输入Cn可以直接传送到最高进位位上去，因而可以实现高速运算。图2.10示出了用正逻辑表示的4位算术/逻辑运算单元(ALU)的逻辑电路图，它是根据上面的原始推导公式用TTL电路实现的。这个器件的商业标号为74181ALU。3.算术逻辑运算的实现图2.11中除了S0～S3四个控制端外，还有一个控制端M，它用来控制ALU进行算术运算还是进行逻辑运算。当M=0时，M对进位信号没有任何影响。此时Fi不仅与本位的被操作数Yi和操作数Xi有关，而且与向本位的进位值Cn+i有关，因此M=0时，进行算术操作。当M=1时，封锁了各位的进位输出，即Cn+i=0，因此各位的运算结果Fi仅与Yi和Xi有关，故M=1时，进行逻辑操作。表2.4列出了74181ALU的运算功能表，它有两种工作方式。对正逻辑操作数来说，算术运算称高电平操作，逻辑运算称正逻辑操作(即高电平为“1”，低电平为“0”)。对于负逻辑操作数来说，正好相反。由于S0～S3有16种状态组合，因此对正逻辑输入与输出而言，有16种算术运算功能和16种逻辑运算功能。同样，对于负逻辑输入与输出而言，也有16种算术运算功能和16种逻辑运算功能。表2.4中只列出了正逻辑的16种算术运算和16种逻辑运算功能。注意，表2.4中算术运算操作是用补码表示法来表示的。其中“加”是指算术加，运算时要考虑进位，而符号“+”是指“逻辑加”。其次，减法是用补码方法进行的，其中数的反码是内部产生的，而结果输出“A减B减1”，因此做减法时须在最末位产生一个强迫进位(加1)，以便产生“A减B”的结果。另外，“A=B”输出端可指示两个数相等，因此它与其他ALU的“A=B”输出端按“与”逻辑连接后，可以检测两个数的相等条件。4.两级先行进位的ALU前面说过，74181ALU设置了P和G两个本组先行进位输出端。如果将四片74181的P，G输出端送入到74182先行进位部件(CLA)，又可实现第二级的先行进位，即组与组之间的先行进位。假设4片(组)74181的先行进位输出依次为P0，G0，P1，G1，P2，G2，P3，G3，那么参考式(2.29)的进位逻辑表达式，先行进位部件74182CLA所提供的进位逻辑关系如下：Cn+x=G0+P0CnCn+y=G1+P1Cn+x=G1+G0P1+P0P1CnCn+z=G2+P2Cn+y=G2+G1P2+G0P1P2+P0P1P2Cn(2.31)Cn+4=G3+P3Cn+z=G3+G2P3+G1P2P3+G0P1P2P3+P0P1P2P3Cn=G*+P*Cn其中P*=P0P1P2P3G*=G3+G2P3+G1P2P3+G0P1P2P3根据以上表达式，用TTL器件实现的成组先行进位部件74182的逻辑电路图如图2.11所示。其中G*称为成组进位发生输出，P*称为成组进位传送输出。下面介绍如何用若干个74181ALU位片，与配套的74182先行进位部件CLA在一起，构成一个全字长的ALU。图2.12示出了用两个16位全先行进位部件级联组成的32位ALU逻辑方框图。在这个电路中使用了八个74181ALU和两个74182CLA器件。很显然，对一个16位来说，CLA部件构成了第二级的先行进位逻辑，即实现四个小组(位片)之间的先行进位，从而使全字长ALU的运算时间大大缩短。由于计算机内部的主要工作过程是信息传送和加工的过程，因此在机器内部各部件之间的数据传送非常频繁。为了减少内部数据传送线并便于控制，通常将一些寄存器之间数据传送的通路加以归并，组成总线结构，使不同来源的信息在此传输线上分时传送。根据总线所处的位置，总线分为内部总线和外部总线两类。内部总线是指CPU内各部件的连线，而外部总线是指系统总线，即CPU与存储器、I/O系统之间的连线。本节只讨论内部总线。按总线的逻辑结构来说，总线可分为单向传送总线和双向传送总线。所谓单向总线，就是信息只能向一个方向传送。所谓双向总线，就是信息可以向两个方向传送，既可以发送数据，也可以接收数据。图2.13是带有缓冲驱动器的4位双向数据总线。其中所用的基本电路就是三态逻辑电路。当“发送”信号有效时，数据从左向右传送。反之，当“接收”信号有效时，数据从右向左传送。这种类型的缓冲器通常根据它们如何使用而叫做总线扩展器、总线驱动器、总线接收器等等。运算器包括ALU、阵列乘除器、寄存器、多路开关、三态缓冲器、数据总线等逻辑部件。运算器的设计，主要是围绕着ALU和寄存器同数据总线之间如何传送操作数和运算结果而进行的。在决定方案时，需要考虑数据传送的方便性和操作速度，在微型机和单片机中还要考虑在硅片上制作总线的工艺。计算机的运算器大体有如下三种结构形式：1.单总线结构的运算器单总线结构的运算器如图2.14(a)所示。由于所有部件都接到同一总线上，所以数据可以在任何两个寄存器之间，或者在任一个寄存器和ALU之间传送。如果具有阵列乘法器或除法器，那么它们所处的位置应与ALU相当。对这种结构的运算器来说，在同一时间内，只能有一个操作数放在单总线上。为了把两个操作数输入到ALU，需要分两次来做，而且还需要A、B两个缓冲寄存器。例如，执行一个加法操作时，第一个操作数先放入A缓冲寄存器，然后再把第二个操作数放入B缓冲寄存器。只有两个操作数同时出现在ALU的两个输入端，ALU才执行加法。当加法结果出现在单总线上时，由于输入数已保存在缓冲寄存器中，它并不会打扰输入数。然后，再由第三个传送动作，以便把加法的“和”选通到目的寄存器中。由此可见，这种结构的主要缺点是操作速度较慢。虽然在这种结构中输入数据和操作结果需要三次串行的选通操作，但它并不会对每种指令都增加很多执行时间。例如，如果有一个输入数是从存储器来的，且运算结果又送回存储器，那么限制数据传送速度的主要因素是存储器访问时间。只有在对全都是CPU寄存器中的两个操作数进行操作时，单总线结构的运算器才会造成一定的时间损失。但是由于它只控制一条总线，故控制电路比较简单。2.双总线结构的运算器双总线结构的运算器如图2.14(b)所示。在这种结构中，两个操作数同时加到ALU进行运算，只需要一次操作控制，而且马上就可以得到运算结果。图中，两条总线各自把其数据送至ALU的输入端。专用寄存器分成两组，它们分别与一条总线交换数据。这样，通用寄存器中的数就可以进入到任一组专用寄存器中去，从而使数据传送更为灵活。ALU的输出不能直接加到总线上去。这是因为，当形成操作结果的输出时，两条总线都被输入数占据，因而必须在ALU输出端设置缓冲寄存器。为此，操作的控制要分两步来完成：第一步，在ALU的两个输入端输入操作数，形成结果并送入缓冲寄存器；第二步，把结果送入目的寄存器。假如在总线1、2和ALU输入端之间再各加一个输入缓冲寄存器，并把两个输入数先放至这两个缓冲寄存器，那么，ALU输出端就可以直接把操作结果送至总线1或总线2上去。3.三总线结构的运算器三总线结构的运算器如图2.14(c)所示。在三总线结构中，ALU的两个输入端分别由两条总线供给，而ALU的输出则与第三条总线相连。这样，算术逻辑操作就可以在一步的控制之内完成。由于ALU本身有时间延迟，所以打入输出结果的选通脉冲必须考虑到这个延迟。另外，设置了一个总线旁路器(桥)。如果一个操作数不需要修改，而直接从总线2传送到总线3，那么可以通过总线旁路器把数据传出；如果一个操作数传送时需要修改，那么就借助于ALU。三总线运算器的特点是操作时间快。思考题你能评价三种运算器的结构特点吗？设有两个浮点数x和y，它们分别为x=2Ex·Mxy=2Ey·My其中，Ex和Ey分别为数x和y的阶码，Mx和My分别为数x和y的尾数。两浮点数进行加法和减法的运算规则是z=x±y=(Mx2Ex－Ey±My)2Ey，Ex≤Ey(2.32)完成浮点加减运算的操作过程大体分为四步：第一步，0操作数检查；第二步，比较阶码大小并完成对阶；第三步，尾数进行加或减运算；第四步，结果规格化并进行舍入处理。图2.15示出浮点加减运算的操作流程。1)0操作数检查浮点加减运算过程比定点运算过程复杂。如果判知两个操作数x或y中有一个数为0，即可得知运算结果而没有必要再进行后续的一系列操作，以节省运算时间。0操作数检查步骤则用来完成这一功能。2)比较阶码大小并完成对阶两浮点数进行加减，首先要看两数的阶码是否相同，即小数点位置是否对齐。若两数阶码相同，表示小数点是对齐的，就可以进行尾数的加减运算。反之，若两数阶码不同，表示小数点位置没有对齐，此时必须使两数的阶码相同，这个过程叫做对阶。要对阶，首先应求出两数阶码Ex和Ey之差，即ΔE=Ex–Ey若ΔE=0，表示两数阶码相等，即Ex=Ey；若ΔE>0，表示Ex>Ey；若ΔE<0，表示Ex<Ey。当Ex≠Ey时，要通过尾数的移动以改变Ex或Ey，使之相等。原则上，既可以通过Mx移位以改变Ex来达到Ex=Ey，也可以通过My移位以改变Ey来实现Ex=Ey。但是，由于浮点表示的数多是规格化的，尾数左移会引起最高有效位的丢失，造成很大误差。而尾数右移虽引起最低有效位的丢失，但造成的误差较小。因此，对阶操作规定使尾数右移，尾数右移后使阶码作相应增加，其数值保持不变。很显然，一个增加后的阶码与另一个阶码相等，所增加的阶码一定是小阶。因此在对阶时，总是使小阶向大阶看齐，即小阶的尾数向右移位(相当于小数点左移)，每右移一位，其阶码加1，直到两数的阶码相等为止，右移的位数等于阶差ΔE。3)尾数加减运算对阶结束后，即可进行尾数的加减运算。不论是加法运算还是减法运算，都按加法进行操作，其方法与定点加减运算完全一样。4)结果规格化在浮点加减运算时，尾数求和的结果也可以得到01.φ…φ或10.φ…φ，即两符号位不相等，这在定点加减运算中称为溢出，是不允许的。但在浮点运算中，它表明尾数求和结果的绝对值大于1，向左破坏了规格化。此时将尾数运算结果右移以实现规格化表示，称为向右规格化，即尾数右移1位，阶码加1。当尾数不是1.M时须向左规格化。5)舍入处理在对阶或向右规格化时，尾数要向右移位，这样，被右移的尾数的低位部分会被丢掉，从而造成一定误差，因此要进行舍入处理。在IEEE754标准中，舍入处理提供了四种可选办法。就近舍入其实质就是通常所说的“四舍五入”。例如，尾数超出规定的23位的多余位数字是10010，多余位的值超过规定的最低有效位值的一半，故最低有效位应增1。若多余的5位是01111，则简单的截尾即可。对多余的5位10000这种特殊情况：若最低有效位现为0，则截尾；若最低有效位现为1，则向上进1位使其变为0。朝0舍入即朝数轴原点方向舍入，就是简单的截尾。无论尾数是正数还是负数，截尾都使取值的绝对值比原值的绝对值小。这种方法容易导致误差累积。朝+∞舍入对正数来说，只要多余位不全为0则向最低有效位进1；对负数来说，则是简单的截尾。朝–∞舍入处理方法正好与朝+∞舍入情况相反。对正数来说，则是简单截尾；对负数来说，只要多余位不全为0，则向最低有效位进1。6)溢出处理浮点数的溢出是以其阶码溢出表现出来的。在加、减运算过程中要检查是否产生了溢出：若阶码正常，加(减)运算正常结束；若阶码溢出，则要进行相应的处理。另外对尾数的溢出也需要处理。图2.16表示了32位格式浮点数的溢出概念。阶码上溢超过了阶码可能表示的最大值的正指数值，一般将其认为是+∞和–∞。阶码下溢超过了阶码可能表示的最小值的负指数值，一般将其认为是0。尾数上溢两个同符号尾数相加产生了最高位向上的进位，要将尾数右移，阶码增1来重新对齐。尾数下溢在将尾数右移时，尾数的最低有效位从尾数域右端流出，要进行舍入处理。图2.17示出浮点加减法运算电路的硬件框图。首先，两个加数的指数部分通过ALU1相减，从而判断出哪一个的指数较大、大多少。指数相减所得的差值控制着下面的三个多路开关；按从左到右的顺序，这三个多路开关分别挑选出较大的指数、较小加数的有效数位以及较大加数的有效数位。较小加数的有效数位部分右移适当的位数，然后再在ALU2中与另一个加数的有效数位部分相加。接下来对结果进行规格化，这是通过将求得的和向左或向右做适当的移位操作(同时相应地增大或减小和的指数部分)来实现的。最后对结果进行舍入，舍入之后可能还需要再次进行规格化，才能得到最终的结果。2.浮点乘、除法运算步骤浮点数的乘除运算大体分为六步：第一步，0操作数检查，如果被除数x为0，则商为0，如果除数y为0，则商为∞；第二步，阶码加/减操作；第三步，尾数乘/除操作；第四步，结果规格化；第五步，舍入处理；第六步，确定积的符号。1)浮点数的阶码运算浮点乘除法中，对阶码的运算有+1、–1、两阶码求和、两阶码求差四种，运算时还必须检查结果是否溢出。2)尾数处理浮点加减法对结果的规格化及舍入处理也适用于浮点乘除法。第一种简单办法是，无条件地丢掉正常尾数最低位之后的全部数值。这种办法被称为截断处理，其好处是处理简单，缺点是影响结果的精度。第二种简单办法是，运算过程中保留右移中移出的若干高位的值，最后再按某种规则用这些位上的值修正尾数。这种处理方法被称为舍入处理。当尾数用原码表示时，舍入规则比较简单。最简便的方法，是只要尾数最低位为1，或移出的几位中有为1的数值位，就使最低位的值为1。另一种是0舍1入法，即当丢失的最高位的值为1时，把这个1加到最低数值位上进行修正。第3步，规格化与溢出检查。乘积的有效数位已经规格化，由于指数–3处在127≥–3≥–126，故没有发生上溢和下溢。第4步，舍入到4位有效数字。这一步无需做任何操作，结果仍为1.1102×2–3第5步，确定积的符号：x和y符号相反，乘积为负数，即(x×y)浮=–1.1102×2–3十进制浮点数验证：–1.110×2–3=–0.0011102=–0.001112=–0.21875100.5×(–0.4375)=–0.218751.流水线原理计算机的流水处理过程同工厂中的流水装配线类似。为了实现流水，首先必须把输入的任务分割为一系列子任务，使各子任务能在流水线的各个阶段并发地执行。将任务连续不断地输入流水线，从而实现了子任务级的并行。因此流水处理大幅度地改善了计算机的系统性能，是在计算机上实现时间并行性的一种非常经济的方法。在流水线中，原则上要求各个阶段的处理时间都相同。若某一阶段的处理时间较长，势必造成其他阶段的空转等待。因此对子任务的划分，是决定流水线性能的一个关键因素，它取决于操作部分的效率、所期望的处理速度，以及成本价格等。假设作业T被分成k个子任务，可表达为T=｛T1,T2,…,Tk｝各个子任务之间有一定的优先关系：若i＜j，则必须在Ti完成以后，Tj才能开始工作。具有这种线性优先关系的流水线称为线性流水线。线性流水线的硬件基本结构如图2.19所示。图2.19中，处理一个子任务的过程为过程段(Si)。线性流水线由一系列串联的过程段组成，各个过程之间设有高速的缓冲寄存器(L)，以暂时保存上一过程子任务处理的结果。在一个统一的时钟(C)控制下，数据从一个过程段流向相邻的过程段。设过程段Si所需的时间为τi，缓冲寄存器的延时为，线性流水线的时钟周期定义为τ=max｛i｝+=τm+(2.35)故流水线处理的频率为f=1/τ。在流水线处理中，当任务饱满时，任务源源不断地输入流水线，不论有多少级过程段，每隔一个时钟周期都能输出一个任务。从理论上说，一个具有k级过程段的流水线处理n个任务需要的时钟周期数为Tk=k＋(n–1)(2.36)其中k个时钟周期用于处理第一个任务。k个周期后，流水线被装满，剩余的n–1个任务只需n–1个周期就能完成。如果用非流水线的硬件来处理这n个任务，时间上只能串行进行，则所需时钟周期数为TL=n·k(2.37)当nk时，Ck→k。这就是说，理论上k级线性流水线处理几乎可以提高k倍速度。思考题你能举出工厂中的生产流水线实例吗？2.流水线浮点加法器从图2.15看出，浮点加减法由0操作数检查、对阶操作、尾数操作、结果规格化及舍入处理共4步完成，因此流水线浮点加法器可由4个过程段组成。图2.20仅示出了除0操作数检查之外的3段流水线浮点加法器框图。假设有两个规格化的浮点数x=1.1000×22，y=1.1100×24第2章运算方法和运算器59当此二数相加时，因x具有较小的阶码，首先应使它向Y对阶，从而得到x=0.0110×24，然后尾数再相加，即0.0110×24+1.1100×2410.0010×24其结果要进行规格化，将尾数向右移1位，阶码增1。即规格化的结果为1.0001×25。在图2.20所示的流水线浮点加法器框图中，标出了上述例子在每一个过程段和锁存器L中保存的流水运算结果值。本章小结一个定点数由符号位和数值域两部分组成。按小数点位置不同，定点数有纯小数和纯整数两种表示方法。按IEEE754标准，一个浮点数由符号位S、阶码E、尾数M三个域组成。其中阶码E的值等于指数的真值e加上一个固定偏移值。为了使计算机能直接处理十进制形式的数据，采用两种表示形式：①字符串形式，主要用在非数值计算的应用领域；②压缩的十进制数串形式，用于直接完成十进制数的算术运算。数的真值变成机器码时有四种表示方法：原码表示法、反码表示法、补码表示法、移码表示法。其中移码主要用于表示浮点数的阶码E，以利于比较两个指数的大小和对阶操作。字符信息属于符号数据，是处理非数值领域的问题。国际上采用的字符系统是七单位的ASCII码。直接使用西文标准键盘输入汉字，进行处理，并显示打印汉字，是一项重大成就。为此要解决汉字的输入编码、汉字内码、字模码等三种不同用途的编码。为运算器构造的简单性，运算方法中算术运算通常采用补码加、减法，原码乘除法或补码乘除法。为了运算器的高速性和控制的简单性，采用了先行进位、阵列乘除法、流水线等并行技术措施。运算方法和运算器是本章的重点。定点运算器和浮点运算器的结构复杂程度有所不同。早期微型机中浮点运算器放在CPU芯片外，随着高密度集成电路技术的发展，现已移至CPU内部。在冯·诺依曼体系结构中，存储器是计算机系统的五大组成部件之一。早期的计算机系统只有单一的存储器存放为数不多的数据和指令。但是，随着软件复杂度的提高、多媒体技术和网络技术的普及，对存储器容量的要求不断提高。而微电子技术的发展又为大幅度提升存储器的存储密度提供了可能性，这反过来又促使对存储器容量的需求进一步提升。由于存储器的价格相对较高，而且在整机成本中占有较大的比例，因而从性能价格比的角度不能通过简单配置更大容量的存储器满足用户的需求。为此，必须使用某种策略解决成本和性能之间的矛盾。这一策略就是存储器分层，即利用不同容量、成本、功耗和速度的多种存储器构成有机结合的多级存储系统。构成多级存储系统的依据就是程序的局部性原理。1.程序的局部性原理统计表明，无论是访问存取指令还是存储数据，在一个较短的时间间隔内，程序所访问的存储器地址在很大比例上集中在存储器地址空间的很小范围内。这种在某一段时间内频繁访问某一局部的存储器地址空间，而对此范围以外的地址空间则很少访问的现象称为程序的局部性原理。程序的局部性可以从两个角度分析。(1)时间局部性：最近被访问的信息很可能还要被访问。(2)空间局部性：最近被访问的信息邻近地址的信息也可能被访问。2.多级存储系统的组成在CPU内部有少量的寄存器可以存储正在执行的指令或者正在参加运算的数据，寄存器的访问速度非常快，但数量较少。正在执行的程序的指令和数据存储在CPU能直接访问的存储器中，这种狭义的存储器就是内存储器。内存储器速度高、容量小、价格高，由半导体器件构成。为了扩大存储容量，在内存储器之外增加容量更大但访问速度稍慢的外存储器(外存)，或者称为辅助存储器(辅存)。相对而言，外存储器速度低、容量大、价格便宜，可以由磁盘存储器、光盘存储器等非半导体器件或者固态半导体存储器构成。CPU不能直接访问外存储器，外存储器的信息必须调入内存储器后才能由CPU处理。内存储器和外存储器构成了两级存储系统。随着半导体技术的发展，CPU和内存储器的工作速度都在提高，但CPU速度提高得更快，而更高速度的内存储器价格非常高。为此，人们在常规内存储器与CPU之间增加了速度更高但容量更小的半导体高速缓冲存储器，即cache，用于存放常规内存中正在使用的一些信息块的副本。常规的内存被称为主存。这样，内存储器就分为cache和主存两部分，由此构成了三级存储系统，其结构如图3.1所示。在三级存储系统中，cache用于提升访问速度，以便使存取速度和CPU的运算速度相匹配；外存储器则主要解决存储容量问题，以满足计算机的大容量存储要求；主存储器介于cache与外存之间，要求选取适当的存储容量和存取周期，使它能容纳系统的核心软件和较多的用户程序。多级存储系统的出发点是提高存储系统的性能/价格比，让整个存储系统在速度上接近cache，而在容量和价格上接近外存。对性能要求更高的系统还可以将cache分成一级(L1)cache和二级(L2)cache，甚至更多级。对存储容量要求更多的系统还可以用磁带等可更换介质实现无容量限制的存储。如图3.2所示，在由cache、主存、磁盘和磁带构成的多级存储体系中，存储容量、存储密度逐级提升，访问速度和价格逐级降低，构成金字塔式的存储结构。构成存储器的存储介质，目前主要采用半导体器件和磁性材料。一个双稳态半导体电路或一个CMOS晶体管或磁性材料的存储元，均可以存储一位二进制代码。这个二进制代码位是存储器中最小的存储单位，称为存储位元。由若干存储位元组成一个存储单元，然后再由许多存储单元组成一个存储器。根据存储材料的性能及使用方法不同，存储器有各种不同的分类方法。存储介质作为存储介质的基本要求，必须有两个明显区别的物理状态，分别用来表示二进制的代码0和1。另外，存储器的存取速度又取决于这种物理状态的改变速度。目前使用的存储介质主要是半导体器件、磁性材料和光存储器。用半导体器件组成的存储器称为半导体存储器。用磁性材料做成的存储器称为磁表面存储器，如磁盘存储器和磁带存储器。光存储器是指只读光盘或者读写光盘。磁盘和光盘的共同特点是存储容量大，储存的信息不易丢失。存取方式如果存储器中任何存储单元的内容都能被随机存取，且存取时间和存储单元的物理位置无关，这种存储器称为随机存取存储器。如果存储器只能按某种顺序来存取，也就是说存取时间和存储单元的物理位置有关，这种存储器称为顺序存取存储器。如磁带存储器就是顺序存取存储器，它的存取周期较长。磁盘存储器则是半顺序(直接)存取存储器，沿磁道方向顺序存取，垂直半径方向随机存取。读写功能有些半导体存储器存储的内容在存储器工作过程中只能读出而不能写入，这种半导体存储器称为只读存储器(ROM)。在存储器工作过程中既能读出又能写入的半导体存储器称为读写存储器或随机存取存储器(RAM)。信息易失性断电后信息消失的存储器，称为易失性存储器。断电后仍能保存信息的存储器，称为非易失性存储器。半导体存储器中，RAM是易失性存储器，一旦掉电，储存信息全部丢失。而ROM是非易失性存储器。磁性材料做成的存储器是非易失性存储器。与CPU的耦合程度根据存储器在计算机系统中所处的位置，可分为内部存储器和外部存储器。内存又可分为主存和高速缓冲存储器。计算机系统的主存习惯上被分为RAM和ROM两类。RAM用来储存当前运行的程序和数据，并可以在程序运行过程中反复更改其内容。而ROM常用来储存不变或基本不变的程序和数据(如监控程序、引导加载程序及常数表格等)。RAM可以根据信息储存方法分为静态RAM(SRAM)和动态RAM(DRAM)。SRAM是用半导体管的“导通”或“截止”来记忆的，只要不掉电，储存信息就不会丢失。而DRAM的信息是用电荷储存在电容上，随着时间的推移，电荷会逐渐漏掉，储存信息也会丢失，因此要周期性地对其“刷新”。根据工艺和特性的不同，只读存储器又分为掩膜ROM、一次可编程ROM(PROM)和可擦除PROM(EPROM)，后者又分为紫外线擦除EPROM(UV-EPROM)、电擦除EPROM(EEPROM或E2PROM)和闪速(Flash)只读存储器。存放一个机器字的存储单元，通常称为字存储单元，相应的单元地址称为字地址。而存放一字节的单元，称为字节存储单元，相应的地址称为字节地址。编址方式是存储器地址的组织方式，一般在设计处理器时就已经确定了。如果计算机中编址的最小单位是字存储单元，则该计算机称为按字编址的计算机。如果计算机中编址的最小单位是字节，则该计算机称为按字节编址的计算机。一个机器字可以包含数字节，所以一个存储单元也可占用数个能够单独编址的字节地址。例如，一个16位二进制的字存储单元包含两字节，当采用字节编址方式时，该字占两字节地址。当一个存储字的字长高于八位时，就存在一个存储字内部的多字节的排列顺序问题，第3章存储系统65其排列方式称为端模式。大端(big-endian)模式将一个字的高有效字节放在内存的低地址端，低有效字节放在内存的高地址端，而小端(little-endian)模式则将一个字的低有效字节放在内存的低地址端，高有效字节放在内存的高地址端。如图3.3所示，如果一个32位数(0A0B0C0D)16按照大端模式存放在内存中，则最低地址存放最高有效字节(0A)16，最高地址存放最低有效字节(0D)16；而按照小端模式存放时，字节顺序刚好相反。常用的英特尔64系列处理器采用小端模式。ARM系列的处理器一般默认采用小端模式，但可以随时在程序中进行大小端模式的切换。许多处理器允许在CPU每次访问存储器时动态确定读写的信息量大小，相应地选择不同的寻址宽度。例如，字寻址每次访存读写一个存储字，半字寻址每次访存读写半个存储字，字节寻址则每次访存读写一字节。内存储器的性能指标主要是存储容量和存取速度，后者通常可以用存取时间、存储周期和存储器带宽描述。存储容量存储容量指一个存储器中可存储的信息比特数，常用比特数(bit)或字节数(B)来表示，也可使用KB、MB、GB、TB等单位。其中1KB=210B，1MB=220B，1GB=230B，1TB=240B。为了清楚地表示其组织结构，存储容量也可表示为：存储字数(存储单元数)×存储字长(每单元的比特数)。例如，1Mbit容量的存储器可以组织成1M×1bit，也可组织成128K×8bit，或者512K×4bit。存取时间又称存储器访问时间，是从存储器接收到读/写命令开始到信息被读出或写入完成所需的时间，取决于存储介质的物理特性和寻址部件的结构。存储周期(存取周期)是在存储器连续读写过程中一次完整的存取操作所需的时间，即CPU连续两次访问存储器的最小间隔时间。通常，存储周期略大于存取时间。存储器带宽(数据传送速率，频宽)单位时间里存储器所存取的信息量，通常以位/秒或字节/秒做度量单位。若系统的总线宽度为W位，则带宽=W/存取周期(bit/s)。静态随机存取存储器(SRAM)的优点是存取速度快，但存储密度和容量不如DRAM大。本节先讨论SRAM。图3.4表示基本的静态存储元阵列。SRAM用锁存器(触发器)作为存储元。只要直流供电电源一直加在这个记忆电路上，它就无限期地保持记忆的1状态或0状态。如果电源断电，则存储的数据(1或0)就会丢失。任何一个SRAM，都有三组信号线与外部打交道：①地址线，本例中有6条，即A0、A1、A2、A3、A4、A5，它指定了存储器的容量是26=64个存储单元。②数据线，本例中有4条，即I/O0、I/O1、I/O2和I/O3，说明存储器的字长是4位，因此存储位元的总数是64×4=256。③控制线，本例中R/W控制线，它指定了对存储器进行读(R/W高电平)，还是进行写(R/W低电平)。注意，读写操作不会同时发生。地址译码器输出有64条选择线，称为行线，其作用是打开每个存储位元的输入与非门。当外部输入数据为1时，锁存器便记忆了1；当外部输入数据为0时，锁存器便记忆了0。目前的SRAM芯片采用双译码方式，以便组织更大的存储容量。这种译码方式的实质是采用了二级译码：将地址分成x向、y向两部分，第一级进行x向(行译码)和y向(列译码)的独立译码，然后在存储阵列中完成第二级的交叉译码。而数据宽度有1位、4位、8位，甚至有更多的字节。图3.5(a)表示存储容量为32K×8位的SRAM逻辑结构图。它的地址线共15条，其中x方向8条(A0～A7)，经行译码输出256行，y方向7条(A8～A14)，经列译码输出128列，存储阵列为三维结构，即256行×128列×8位。双向数据线有8条，即I/O0～I/O7。向SRAM写入时，8个输入缓冲器被打开，而8个输出缓冲器被关闭，因而8条I/O数据线上的数据写入存储阵列中。从SRAM读出时，8个输出缓冲器被打开，8个输入缓冲器被关闭，读出的数据送到8条I/O数据线上。控制信号中CS是片选信号，CS有效时(低电平)，门G1、G2均被打开。OE为读出使能信号，OE有效时(低电平)，门G2开启，当写命令WE=1时(高电平)，门G1关闭，存储器进行读操作。写操作时，WE=0，门G1开启，门G2关闭。注意，门G1和G2是互锁的，一个开启时另一个必定关闭，这样保证了读时不写，写时不读。图3.5(b)为32K×8位SRAM的逻辑图。如图3.6所示，读/写周期波形图精确地反映了SRAM工作的时间关系。我们把握住地址线、控制线、数据线三组信号线何时有效，就能很容易看懂这个周期时序图。在读周期中，地址线先有效，以便进行地址译码，选中存储单元。为了读出数据，片选信号CS和读出使能信号OE也必须有效(由高电平变为低电平)。从地址有效开始经tAQ(读出)时间，数据总线I/O上出现了有效的读出数据。之后CS、OE信号恢复高电平，tRC以后才允许地址总线发生改变。tRC时间即为读周期时间。在写周期中，也是地址线先有效，接着片选信号CS有效，写命令WE有效(低电平)，此时数据总线I/O上必须置写入数据，在tWD时间段将数据写入存储器。之后撤销写命令WE和CS。为了写入可靠，I/O线的写入数据要有维持时间thD，CS的维持时间也比读周期长。tWC时间称为写周期时间。为了控制方便，一般取tRC=tWC，通常称为存取周期。当单个存储器芯片的容量不能满足系统要求时，需要把多片存储器芯片组合起来，组成更大容量的存储器。所需芯片数为：d=设计要求的存储器容量/已知芯片存储容量。1.位扩展若给定的芯片的字数(地指数)符合要求，但位数较短，不满足设计要求的存储器字长，则需要进行位扩展，让多片给定芯片并行工作。三组信号线中，地址线和控制线公用而数据线单独分开连接。3.字位扩展若给定的芯片的字数和位数均不符合要求，则需要先进行位扩展，再进行字扩展。SRAM的存储元是一个触发器，它具有两个稳定的状态。而动态随机存取存储器(DRAM)简化了每个存储元的结构，因而DRAM的存储密度很高，通常用作计算机的主存储器。作为开关使用，而所存储的信息1或0则是由电容器上的电荷量来体现——当电容器充满电荷时，代表存储了1，当电容器放电没有电荷时，代表存储了0。写1到存储元时，输出缓冲器关闭、刷新缓冲器关闭，输入缓冲器打开(R/W为低)，输入数据DIN=1送到存储元位线上，而行选线为高，打开MOS管，于是位线上的高电平给电容器充电，表示存储了1。写0到存储元时，输出缓冲器和刷新缓冲器关闭，输入缓冲器打开，输入数据DIN=0送到存储元位线上；行选线为高，打开MOS管，于是电容上的电荷通过MOS管和位线放电，表示存储了0。从存储元读出时，输入缓冲器和刷新缓冲器关闭，输出缓冲器/读放打开(R/W为高)。行选线为高，打开MOS管，若当前存储的信息为1，则电容上所存储的1送到位线上，通过输出缓冲器/读出放大器发送到DOUT，即DOUT=1。读出过程破坏了电容上存储的信息，所以要把信息重新写入，即刷新。读出的过程中可以完成刷新。读出1后，输入缓冲器关闭，刷新缓冲器打开，输出缓冲器/读放打开，读出的数据DOUT=1又经刷新缓冲器送到位线上，再经MOS管写到电容上，存储元重写1。注意，输入缓冲器与输出缓冲器总是互锁的。这是因为读操作和写操作是互斥的，不会同时发生。与SRAM相比，DRAM的存储元所需元件更少，所以存储密度更高。但是DRAM的附属电路比较复杂，访问时需要额外的电路和操作支持。与SRAM不同的是，图中增加了行地址锁存器和列地址锁存器。由于DRAM容量很大，地址线的数目相当多，为减少芯片引脚的数量，将地址分为行、列两部分分时传送。存储容量为1M字，共需20位地址线。此芯片地址引脚的数量为10位，先传送行地址码A0～A9，由行选通信号RAS打入到行地址锁存器；然后传送列地址码A10～A19，由列选通信号CAS打入到列地址锁存器。片选信号的功能也由增加的RAS和CAS信号实现。3.3.3DRAM读/写时序图3.11(a)为DRAM的读周期波形。当地址线上行地址有效后，用行选通信号RAS打入行地址锁存器；接着地址线上传送列地址，并用列选通信号CAS打入列地址锁存器。此时经行、列地址译码，读/写命令R/W=1(高电平表示读)，数据线上便有输出数据。图3.11(b)为DRAM的写周期波形。此时读/写命令R/W=0(低电平表示写)，在此期间，数据线上必须送入欲写入的数据DIN(1或0)。从图中可以看出，每个读周期或写周期是从行选通信号RAS下降沿开始，到下一个RAS信号的下降沿为止的时间，也就是连续两个读/写周期的时间间隔。通常为控制方便，读周期和写周期时间相等。DRAM存储位元是基于电容器上的电荷量存储信息的，DRAM的读操作是破坏性的，读操作会使电容器上的电荷流失，因而读出后必须刷新。而未读写的存储元也要定期刷新，因为电荷量会逐渐泄漏而减少。从外部看，刷新操作与读操作类似，只是刷新时无须送出数据，并且可以将一行的所有存储元同时刷新。现代的DRAM芯片通常会在一次读操作之后自动地刷新选中行中的所有存储位元。但是读操作出现的时间不是固定的，因此必须对DRAM进行周期性的刷新，以保持其记忆的信息不丢失。早期的DRAM需要由存储器控制器从外部向DRAM芯片送入刷新行地址并启动一次刷新，而现代的DRAM都支持自动刷新功能，由芯片内部提供刷新行地址。故图3.10中增加了刷新计数器(刷新行地址发生器)和相应的控制电路。刷新计数器的宽度等于行地址锁存器的宽度。由于自动刷新不需要给出列地址，而行地址由片内刷新计数器自动生成，故可利用CAS信号先于RAS信号有效来启动一次刷新操作，此时地址线上的地址无效。当前主流的DRAM器件的刷新间隔时间(刷新周期)为64ms。周期性的刷新操作是与读/写操作交替进行的，所以通过2选1多路开关选择刷新行地址或正常读/写的行地址。常用的刷新策略有集中式刷新和分散式刷新两种。例如，对于一片有8192行、刷新周期为64ms的DRAM内存来说：在集中式刷新策略中，每一个刷新周期中集中一段时间对DRAM的所有行进行刷新。64ms的刷新周期时间可以分为两部分：前一段时间进行正常的读/写操作；后一段时间作为集中刷新操作时间，连续刷新8192行。由于刷新操作的优先级高，刷新操作时正常的读/写操作被暂停，数据线输出被封锁。等所有行刷新结束后，又开始正常的读/写周期。由于在刷新的过程中不允许读/写操作，集中式刷新策略存在“死时间”。在分散式刷新策略中，每一行的刷新操作被均匀地分配到刷新周期时间内。由于64ms除以8192约等于7.8μs，所以DRAM每隔7.8μs刷新一行。由于CPU送出的访存地址要分行地址和列地址两次送入DRAM芯片，并且DRAM还要实现定时刷新，因而使用DRAM做系统主存的系统通常要通过存储器控制器或者DRAM控制器产生DRAM访问和刷新时序控制与地址信号。DRAM存储密度高，大容量DRAM价格相对较低，因而适合用作系统主存。但是，DRAM的访问速度相对要低一些，提升其访问速度是改进系统性能的重要途径之一。近年来，人们在传统DRAM的基础上应用了诸多技术提升其访问速度。突发(Burst，猝发)访问指的是在存储器同一行中对相邻的存储单元进行连续访问的方式，突发长度可以从几字节到数千字节不等。由于访问地址是连续的，因而只需要向存储器发送一次访问地址。突发访问时先激活一行，然后按照一定的顺序依次发出列选择信号，访问相应的目标存储单元。突发方式可以消除地址建立时间及第一次存取之后的行、列线的预充电时间。在第一次存取后，一系列数据能够快速地输出。通过支持突发模式、快速页模式和扩展数据输出等方式，可以允许重复存取DRAM存储矩阵的行缓冲区而无须增加另外的行存取时间，以提升等效数据访问速度。传统的DRAM是异步工作的，处理器送地址和控制信号到存储器后，等待存储器进行内部操作(选择行线和列线读出信号放大并送输出缓冲器等)，处理器需等待一段存取延时时间后才能存取数据，因而必须消耗较长时间以确保数据传输可靠，影响了系统性能。在DRAM接口上增加时钟信号则可以降低存储器芯片与控制器同步的开销，优化DRAM与CPU之间的接口，这是同步DRAM(SDRAM)的最主要改进。1.SDRAM的特征SDRAM存储体的存储单元电路仍然是标准的DRAM存储体结构，只是在工艺上进行了改进，如功耗更低、集成度更高等。与传统的DRAM相比，SDRAM在存储体的组织方式和对外操作上作了重大改进。图3.12显示了SDRAM的逻辑结构，其主要特性如下。同步操作处理器访问SDRAM时，SDRAM的所有输入信号均在系统时钟CLK的上升沿被存储器内部电路锁定；SDRAM的所有输出信号均在系统时钟CLK的上升沿被输出。这样做的目的是使SDRAM的操作在系统时钟CLK的控制下，与系统的高速操作严格同步进行。CKE为时钟使能信号，只有该信号有效时，时钟输入才能作用于SDRAM芯片。多存储体配置为了进一步提高存取速度和减少内部操作冲突，SDRAM的存储体被拆分为多个相互独立的存储体(bank)。这种内部组织结构可以支持流水线方式的并行操作。各存储体可同时和独立工作，也可选择顺序工作或交替工作。例如，当一个存储体正在刷新时，另一个存储体可以进行正常的读写操作，从而提高存取速度。通常由片内地址线的最高一位或若干位选择存储体。命令控制传统的异步DRAM是根据控制信号的电平组合选择工作方式的，而SDRAM将一组控制信号的电平编码组合为“命令”。例如，RAS、CAS、WE、CS以及特定地址线的不同组合分别代表激活存储体(active，所有存储体在读/写之前都必须被激活)、读、写、预充等不同的命令。模式寄存器在SDRAM加电后必须先对模式寄存器进行设置，控制SDRAM工作在不同的操作模式下。在模式寄存器中可以设置CAS延迟、突发类型、突发长度和测试模式等。表3.1比较了传统异步DRAM和SDRAM的功能差异。2.SDRAM的控制方式下面以读周期为例说明SDRAM的控制方式。图3.13对比了异步DRAM和SDRAM的读操作时序。在SDRAM操作过程中，所有的动作都是以时钟信号为依据的。在T1时钟的上升沿(图中<1>处)，激活命令ACT和行地址首先被锁存，表明开始一次存取操作。而异步DRAM并没有时钟信号，对应的动作为RAS有效(低)。第3章存储系统75在T3时钟的上升沿(<2>处)，读命令和列地址被锁存，表明当前是一次读操作。对应异步DRAM的CAS有效(低)。此后，SDRAM将完成内部准备操作，并在2个时钟周期之后送出数据。从列地址被锁存到数据有效输出的时间间隔称为CAS延迟CL，图中CL=2。在T6时钟的上升沿(<3>处)，控制器送入预充命令。对应异步DRAM的RAS和CAS无效(变高)。SDRAM的操作时序都是确定的，在系统时钟控制下，CPU向SDRAM送出地址和控制命令后，需等待事先确定好的一定数量的时钟周期。在此期间，SDRAM完成读或写的内部操作(如行列选择、地址译码、数据读出或写入、数据放大等)，处理器则可照常安全地执行其他任务，不必单纯等待，以此来提高系统效率。3.SDRAM的命令图3.14给出了SDRAM读和写命令操作的时序，可以看出SDRAM的命令发送方式。在T1时钟的上升沿，控制器发出存储体A的激活命令。存储体激活命令通过在时钟上升沿发出下列信号组合发出：CS=0、RAS=0、CAS=1、WE=1，地址线A11=0选择存储体A。在T3时钟的上升沿，控制器发出存储体A的读命令。读命令通过在时钟上升沿发出下列信号组合发出：CS=0、RAS=1、CAS=0、WE=1。经过2个时钟周期的内部操作，数据在T5时钟的上升沿开始送出。此例中，突发长度BL=4，故在随后的四个时钟周期内分别送出一个数据字。在T9时钟的上升沿，DQ输出被设置为高阻状态。在T10时钟的上升沿，控制器发出存储体A的写命令。写命令通过在时钟上升沿发出下列信号组合发出：CS=0、RAS=1、CAS=0、WE=0。在T14时钟的上升沿开始下一次读操作。3.3.7双倍数据率SDRAM(DDRSDRAM)在SDRAM出现之后，又出现了双数据率的DDRSDRAM，故后来将单数据率的SDRAM称为SDRSDRAM。狭义的SDRAM仅指SDRSDRAM。DDRSDRAM沿袭了SDRSDRAM内存的制造体系，又能够提供更快的操作速度和更低的功耗。SDRAM仅能在时钟上升沿传输数据，而DDRSDRAM的最大特点便是在时钟的上升沿和下降沿都能传输数据。双倍数据率结构本质上是一个2n预取结构，如图3.15所示。内部总线宽度是外部总线宽度的两倍，从存储矩阵到I/O缓冲区每个时钟周期传输2n比特数据，从I/O缓冲区到数据总线则在时钟触发沿的上、下沿都能进行数据传输。差分时钟也是DDRSDRAM的一个必要设计。由于数据是在CK的上下沿触发，因而传输周期缩短了一半，因此必须要保证传输周期的稳定，以确保数据的正确传输。因为温度和电阻特性的改变等原因，CK上下沿间距可能发生变化，此时与其反相的CK就起到触发时钟校准的作用。在第一代DDRSDRAM出现之后，相继又出现了DDR2、DDR3和DDR4等SDRAM技术。这些技术的主要改进点在于提升存储矩阵输出的数据率。例如，DDR2技术采用4n预取结构，将数据总线的时钟频率提升至内部传输频率的2倍，从而使外部总线数据率比DDRSDRAM提升一倍。类似地，DDR3SDRAM则采用8n预取结构。DDR4SDRAM仍然采用8n预取，但是允许使用两个或者四个存储体组，每个存储体组都有独立的激活、读取、写入和刷新操作。因此，如果设计两个独立的存储体组，相当于将内存预取值提高到了16n；如果是四个独立的存储体组，则预取值提高到了32n。3.3.8DRAM读/写校验DRAM通常用作主存储器，其读/写操作的正确性与可靠性至关重要。为此除了正常的数据位宽度，还增加了附加位，用于读/写操作正确性校验。增加的附加位也要同数据位一起写入DRAM中保存。显然这增加了DRAM的位成本。图3.16表示DRAM正确性校验的概念示意图。最简单的校验是奇偶校验，除了数据位外只需增加1位附加位(k=1)，进行奇校验或偶校验即可。图中的F部分为进行奇校验或偶校验的异或运算电路，如果存储器读/写正确，那么写入存储器前与读出存储器后两部分的F运算结果应该一致，否则给出错误信号。奇偶校验只能检出1位错误，不能纠正错误。但是由于技术简单，成本较低，所以在早期主存储器中常常使用。为了能纠正错误，纠错码设成k位，如果数据字为m位，则实际存储的字长为m+k位。最简单的纠错码是汉明码。为了能纠错，汉明码要求的校验位长度如表3.2所示。由表3.2可见，数据位8位时，附加的校验码要求为4位，存储器字长变成12位，位成本增加了50%。但是数据位64位时，校验码要求为7位，字长变成71位，位成本只增加约11%。在汉明码校验中，F电路的运算要比奇偶校验复杂，如8位数据时，F部分有4位，所以有4个异或运算表达式。纠正器电路部分则是新、老校验位比较时形成的故障字，它也通过异或运算形成。3.3.9CDRAMCDRAM(CachedDRAM)是一种附带高速缓冲存储器的动态存储器，它是在常规的DRAM芯片封装内又集成了一个小容量SRAM作为高速缓冲存储器，从而使DRAM芯片的访问速度得到显著提升。1.CDRAM芯片的结构图3.17为1M×4位CDRAM芯片的结构框图。一片512×4位的SRAM构成cache，保存最近访问的一行数据。另外增加了最后读出行地址锁存器和行地址比较器，如果后续访问的数据就在最近访问过的行中，则可直接从cache中读出数据而无须访问DRAM存储体。访问1M×4位的CDRAM芯片需20位内存地址。在行选通信号RAS作用下，内存地址的高11位行地址经A0～A10地址线输入，并被锁存在行地址锁存器和最后读出行地址锁存器中。在DRAM阵列的2048行中，此地址指定行的全部512×4位数据被读取到SRAM中暂存。然后，内存地址的低9位列地址在列选通信号CAS有效时经A0～A10地址线输入，并被锁存到列地址锁存器中。如果是首次读操作，则在读命令信号有效时，SRAM中512个4位组内的某一个4位组被此列地址选中，经D0～D3送出芯片。下一次读取时，输入的11位行地址立即与最后读出行地址锁存器的内容进行比较：若相符则SRAM命中，由输入的列地址直接从SRAM中选择某一4位组送出即可；只在比较不相符时，才需要再次访问DRAM阵列，更新SRAM和最后读出行地址锁存器的内容，并送出指定的4位组。CDRAM在常规DRAM的基础上增加了一点成本，但是有几个明显的优点。一是突发操作的速度高，如果连续访问的地址的高11位相同(属于同一行地址)，那么只需连续变动9位列地址就能从SRAM中快速读出数据。二是在SRAM读出期间可同时对DRAM阵列进行刷新。三是允许在写操作完成的同时启动同一行的读操作，因为芯片内的数据输出路径(由SRAM到I/O)与数据输入路径(由I/O到读出放大和列写选择)是分开的。2.CDRAM存储模块8片容量为1M×4位的CDRAM芯片可以组成1M×32位(4MB)的存储模块，如图3.18所示。8个芯片共用片选信号Sel、行选通信号RAS、刷新信号Ref和地址输入信号A0～A10。每两片1M×4位的CDRAM芯片的列选通信号CAS接在一起，形成一个1M×8位(1MB)的片组。4个片组组合成一个1M×32位的存储模块。数据总线宽度为32位。为了CPU与存储器交换数据方便，每次访存时可以由CPU选择实现字存取(32位)、半字存取(高16位或低16位)或字节存取(任意8位)。由于存储器按字节编址，因而每次访存数据总线上可能会传输4个地址(字)、2个地址(半字)或者1个地址(字节)的数据。为此，CPU送出的地址线中最低两位的A1和A0并不送出，而是送出由连续四字节组成的一个32位字的字地址(字地址的最低两位固定为00)，外加4个字节低位地址排列关系。该模块按小端模式安排地址，故每个字的最低有效字节(与数据线D7~D0对应)安排在低地址(最低两位地址为00)，而每个字的最高有效字节(与数据线D31~D24对应)安排在高地址(最低两位地址为11)。4个片组的列选通信号3CAS～0CAS分别与CPU送出的4个字节允许信号3BE～0BE相对应。当某模块被选中并完成32位存取时，此模块的8个CDRAM芯片同时动作。8个4位数据I/O端口D3～D0同时与32位数据总线交换数据，完成一次32位的存取。此32位存储字的模块内地址对应系统存储地址中的A21～A2。这20位地址分为11位的行地址和9位的列地址，分别在RAS和CAS有效时同时输入到8个芯片的地址引脚端。系统存储地址的最高两位A23、A22作为模块选择地址，译码输出可以分别驱动4个这样的4MB模块的Sel信号。即系统可配置4个这样的模块，存储器容量达到16MB。上述存储模块具有高速的突发存取能力。如果连续访问的数据块的高13位地址相同(同一行)，那么只是第一个存储字需要一个完整的存取周期(如6个总线时钟周期)，而后续存储字的存取因内容已在SRAM中，故存取周期大为缩短(如2个总线时钟周期)。这样，读取4个32位字只使用了6-2-2-2个总线时钟周期。存储器写入也有相似的速度提高。半导体只读存储器(ROM)最大的特点是其非易失性，其访问速度比RAM稍低，可以按地址随机访问并在线执行程序，因而在计算机中用于储存固件、引导加载程序、监控程序及不变或很少改变的数据。“只读”的意思是在其工作时只能读出，不能写入。早期的只读存储器中存储的原始数据必须在其工作以前离线存入芯片中，现代的许多只读存储器都能够支持在线更新其存储的内容，但更新操作与RAM的写操作完全不同，不仅控制复杂，而且耗时长，更新所需的时间比ROM的读操作时间长很多，可以重复更新的次数也相对较少。因此，这种更新ROM存储内容的操作实际上不是“写入”，而是编程。狭义的ROM仅指掩模ROM。掩模ROM实际上是一个存储内容固定的ROM，由半导体生产厂家根据用户提供的信息代码在生产过程中将信息存入芯片内。一旦ROM芯片做成，就不能改变其中的存储内容。掩模ROM一般用于存储广泛使用的具有标准功能的程序或数据，或用户定做的具有特殊功能的程序或数据，当然这些程序或数据均转换成二进制码。由于成本很低，在没有更新需求的大批量的应用中适宜使用掩模ROM。为了让芯片的用户能更新ROM中存储的内容，可以使用可编程ROM(PROM)。一次性编程ROM、紫外线擦除PROM、E2PROM和闪速存储器均可由用户编程。狭义的PROM即指一次性编程ROM(OTPROM)，只能编程一次。紫外线擦除PROM(UV-EPROM)通常简称EPROM，器件的上方有一个石英窗口，通常将其从电路板上的插座上拔下后，在专用的擦除器中使用一定波长的紫外线照射数分钟至十余分钟即可擦除存储的信息，且可在通用编程器或电路板上实现多次编程和验证。电可擦PROM(EEPROM，E2PROM)采用电擦除，因而不需要离线擦除，且擦除速度快，可以单字节编程和擦除(或者擦除块尺寸很小)，使用更方便。E2PROM通常容量比较小，单位成本高，但可重复擦除的次数多，一般在一百万次左右，一般用于存储偶尔需要更新的系统配置信息、系统参数、加密保护数据或历史信息等。许多单片机或者简单电子模块往往会内置E2PROM芯片。常规并行总线E2PROM访问速度快，接口简单，但引脚数量多，封装尺寸较大，故近年来更多地被串行E2PROM(SEEPROM)或闪存取代。常见的串行E2PROM支持SPI、I²C、Microwire或1-Wire等1至4线的串行总线，芯片封装只需8个或者更少的引脚。闪速(Flash)存储器(闪存)也属于电可擦、可在线编程的非易失性只读存储器。Flash意为擦除速度高，其擦除时间远高于传统的UV-EPROM和E2PROM。闪速存储器的存储密度高，工作速度快，擦除块尺寸较大(通常在512字节以上)，可擦除的次数相对较少(NOR闪存为一万到十万次)。闪存自20世纪80年代末出现以来，应用已经极为普遍，在很多情况下取代了传统的其他ROM。根据存储元工作原理和制造工艺的不同，闪存可以分为NOR技术、DINOR技术、AND技术和NAND技术等不同类别。其中应用最普遍的是NOR技术和NAND技术。NOR闪存通常被称为线性闪存，最早由英特尔和AMD等公司生产。相对于其他技术的闪存，其特点是：可以像SRAM和传统ROM那样随机读出任意地址的内容，读出速度高；存储在其中的指令代码可以直接在线执行；可以对单字节或单字进行编程(在重新编程之前需要先进行擦除操作)；以区块(sector)或芯片为单位执行擦除操作；拥有独立的数据线和地址线，因而接口方式与SRAM相似；信息存储的可靠性高。因此，NOR闪存更适用于擦除和编程操作较少而直接执行代码的场合，尤其是纯代码存储应用。由于擦除和编程速度相对较慢，且区块尺寸较大，NOR闪存不太适合纯数据存储和文件存储等应用场景。NOR闪存可在线“写入”数据，又具有ROM的非易失性，因而可以取代全部的UV-EPROM和大部分的E2PROM，存储监控程序、引导加载程序等不经常改变的程序代码，或者储存在掉电时需要保持的系统配置等不常改变的数据。NAND闪存通常被称为非线性闪存，最早由三星和东芝等公司生产。相对于其他技术的闪存，其特点是：每次读出以页(page)为单位，因而属于非随机访问的存储器；存储在其中的指令代码不能够直接在线执行；以页为单位进行编程操作；以数十页组成的块(block)为单位进行擦除操作；快速编程和快速擦除；数据线、地址线和控制线复用在同一组总线信号上，故其接口方式与传统ROM不同；位成本低、位密度高；由于工艺的限制，存在较高的比特错误率，通常需要软件处理坏块。NAND闪存不能够随机读出，所以一般不能直接用于存储在线执行的代码；但是由于其存储密度高，价格低，通常容量较大，增加NAND闪存控制器后也可用于程序代码存储。由于NAND闪存有10倍于NOR闪存的可擦除次数，故适用于大容量存储设备，如存储卡、优盘(USB闪存盘)、固态盘等应用。由于NAND闪存的数据存取无机械运动，可靠性高，存取速度快，体积小巧，因而已经部分取代了磁介质辅存。1.NOR闪存的外部接口与逻辑结构下面以飞索公司(现赛普拉斯公司)生产的S29AL016J系列16Mbit闪存为例，说明NOR闪存的接口和工作方式。图3.20(a)给出了其外部引脚。该芯片有两种工作模式：字模式组织成1M×16bit，需要A19~A0共20位地址，DQ15～DQ0共16位数据线；字节模式组织成2M×8bit，需要A19~A–1共21位地址，DQ7～DQ0共8位数据线。引脚BYTE#(#代表低电平有效)为低时选择字节模式，为高时选择字模式。此外，CE#为片选信号线，OE#为输出允许线，WE#为写使能信号。闪存芯片内部需要有状态机支持其操作，复位信号RESET#可以让其通过硬件复位恢复到初始状态。由于闪存经常存放系统上电引导程序，为了防止误操作或其他原因导致存储的信息被删除，WP#信号为低电平时可以让芯片处于写保护状态。为了获取闪存内部的工作状态，可以读取RY/BY#(Ready/Busy#)信号的电平：高表示芯片准备好接收新的命令，低表示芯片内部正忙于处理上一操作。从图3.20(b)的逻辑结构图可以看出，闪存芯片的核心仍然是存储矩阵。该芯片由单一3.3V电源供电，内部集成了编程电压发生器和擦除电压发生器，无需外接高电压电源。与传统只读存储器不同，闪存可以通过命令寄存器接收外部命令。而且，闪存内部有状态机，需要有状态控制逻辑，并且通过定时器给出内部操作定时。2.NOR闪存的区块划分S29AL016J是一种区块(sector)式闪存，外部按1M×16bit或2M×8bit组织，内部组织为35个区块。表3.4给出了底部引导区版本的区块地址表，其低地址区通常存放系统引导程序和一些参数，因而区块尺寸较小并且可以附加特定的写保护措施，前4个区块大小分别为16KB、8KB、8KB、32KB。SA4～SA34大小均为64KB。每个存储单元的地址由高位的区块地址(A12以上)和低位的区块内偏移地址两个字段组成，两个字段的长度与区块尺寸相关。表3.4S29AL016J的区块地址表(底部引导区)3.NOR闪存的总线操作与工作方式表3.5给出了S29AL016J的部分总线操作。NOR闪存的外部接口信号线与SRAM类似，但除了读出和编程写入这些常规的PROM操作外，NOR闪存还具有内部控制寄存器和状态寄存器，可以通过“命令写”和“状态读”操作进行灵活的控制。为了在保持与传统ROM兼容的情况下实现更多新功能，闪存内部通过状态机控制其操作状态。*WP#=0时，最外区块保持保护状态；WP#=1时，最外区块的保护状态由先前的保护/去保护状态决定。RESET#信号为低时为硬件复位。上电或复位之后，芯片内部的状态机使器件自动进入“读存储矩阵”操作状态。在该状态下，NOR闪存的读出操作与传统ROM芯片相同，只需给出片选信号和一定的地址并使读信号(输出允许)线有效即可。因而其读操作与传统ROM完全兼容。如果需要执行传统ROM不支持的其他操作，需要执行特定的命令序列，使NOR闪存转入其他状态，进行芯片擦除、区块擦除、编程写入、软件数据保护或者读标识码等操作。为防止状态机的误动作，闪存的各种命令是以“向特定地址写入特定内容的命令序列”方式定义的。命令寄存器本身并不占据单独的存储器片内地址，而是通过特定的地址和特定的数据组合给出不同的命令。表3.5中的“写”操作是指总线上的写入操作，并非直接写入存储矩阵，而是写命令寄存器的“写周期”操作。不同命令通常要占用长短不一的若干个总线写周期。在每一次命令操作之后，可以查询状态寄存器，以使CPU能够了解命令的执行情况。不同厂商生产的芯片支持的命令序列不同，常见的有AMD/Fujitsu的标准命令集和Intel/Sharp的扩展命令集。表3.6给出了字模式下S29AL016J使用的标准命令集中的部分命令。表中地址和数据均为十六进制。其中的地址是指芯片地址线上应该给出的地址模式，形式上为片内偏移地址，但并非向存储矩阵的相应单元写入，而是与其他地址和数据模式组合代表特定命令。例如，芯片擦除命令将所有存储元擦除到存储1的状态。当芯片在连续的6个总线写周期中依次从其地址线/数据线上接收到555/AA、2AA/55、555/80、555/AA、2AA/55和555/10这组信息时，将会把内部状态机转到“整片擦除”状态，并启动整片擦除操作。区块擦除操作与此类似，但最后一个写周期需给出欲擦除的区块的地址，且数据线送入30，芯片收到此命令后将启动该区块的擦除操作。编程命令需要四个写总线周期，依次送入555/AA、2AA/55、555/A0和欲编程地址/欲编程数据后，芯片将转入“编程”状态。需要注意的是，无论是擦除操作还是编程操作都不是能在接到命令后立即完成的，闪存收到擦除或编程命令后需要执行内嵌擦除/编程算法进行费时的内部复杂操作才有可能完成操作任务。在闪存完成上一命令之前，不能接收新的命令。为了让CPU知晓闪存的内部操作是否完成，芯片支持多种编程/擦除状态判定方法。例如，通过通用I/O引脚读取RY/BY#信号的电平可以获知闪存是处于“准备好”状态还是“忙”状态。还有一种常用的判定编程和写入的状态的方法称为data#polling，如图3.21所示。在发出编程或擦除命令之后，对欲编程的存储单元地址或者欲擦除的任意存储单元的地址VA发出读命令，并检查数据线返回的状态值。设欲向该地址编程的数据的第七位为D7，若编程未完成时，读出的DQ7=7D；而编程结束后，读出的DQ7=D7。擦除操作可以看作写全1的操作，故擦除过程中，DQ7=0；擦除完成时，DQ7=1。闪存内部状态机设置了超时时间，以判断编程或擦除是否因错误而超时。超时时，数据线上的DQ5输出为1，表示编程或擦除操作失败。在超时之前，可以通过不断读取该地址的方式轮询闪存的状态，直到DQ7翻转。由于在超时的瞬间DQ7仍可能翻转，故可以在超时后最后读取一次状态字，判断编程或者擦除操作是否失败。编程或擦除失败后只能通过复位命令返回读存储矩阵状态。从NOR闪存的编程和擦除方式可以看出闪存与RAM的差异。闪存的存储单元在编程之前需首先擦除；闪存发出编程命令也比RAM发出写命令复杂许多；闪存编程的速度远低于RAM的写入速度；闪存的读出速度也远低于RAM。可见，虽然闪存具有非易失性并可在线编程，但仍然属于ROM，一般情况下闪存不能取代RAM。CPU和主存储器之间在速度上是不匹配的，这种情况成为限制高速计算机设计的主要问题。为了提高CPU和主存之间的数据交换速率，可以在不同层次采用不同的技术加速存储器访问速度：芯片技术提高单个芯片的访问速度。可以选用更高速的半导体器件，或者改善存储芯片内部结构和对外接口方式。例如，前述的突发传输技术、同步DRAM技术和CDRAM技术等。结构技术为了解决存储器与CPU速度不匹配问题，需要改进存储器与CPU之间的连接方式，加速CPU和存储器之间的有效传输。例如，采用并行技术的双口存储器甚至是多口存储器，以及多体交叉存储器，都可以让CPU在一个周期中访问多个存储字。系统结构技术这是从整个存储系统的角度采用分层存储结构解决访问速度问题。例如，增加cache，采用虚拟存储器等。本节讲授双端口存储器和多体交叉存储器，前者采用空间并行技术，后者采用时间并行技术。早期的计算机系统以CPU为中心。机器内部各个部件之间的信息传递都受CPU控制，I/O设备与主存之间的信息交换也经过CPU的运算器。这种结构严重影响了CPU效能的发挥，故以内存为中心的系统逐渐取代了以CPU为中心的结构。这种以内存为中心的结构要求不仅CPU可以访问主存，而且其他部件(如I/O设备)也可不经CPU而直接与主存交换信息。这样，多个部件都可以与主存交换信息，使主存的访问次数明显增多。而传统的存储器在任一时刻只能进行一个读或写操作，不能被多个部件同时访问。为了进一步扩展主存的信息交换能力，提出了多口存储器结构。1.双端口存储器的逻辑结构双端口存储器由于同一个存储器具有两组相互独立的读写控制电路而得名。由于进行并行的独立操作，因而是一种高速工作的存储器，在科研和工程中非常有用。图3.22为双端口存储器IDT7133的逻辑框图。这是一个存储容量为2K字长16位的SRAM，它提供了两个相互独立的端口，即左端口和右端口。它们分别具有各自的地址线(A0～A10)、数据线(I/O0～I/O15)和控制线(R/W、CE、OE、BUSY)，因而可以对存储器中任何位置上的数据进行独立的存取操作。图中，字母符号下标中L表示左端口，R表示右端口，LB表示低位字节，UB表示高位字节。事实上双端口存储器也可以由DRAM构成。2.无冲突读写控制当两个端口的地址不相同时，在两个端口上进行读写操作，一定不会发生冲突。当任一端口被选中驱动时，就可对整个存储器进行存取，每一个端口都有自己的片选控制(CE)和输出驱动控制(OE)。读操作时，端口的OE(低电平有效)打开输出驱动器，由存储矩阵读出的数据就出现在I/O线上。表3.7列出了无冲突的读写条件，表中符号1代表高电平，0为低电平，×为任意，Z为高阻态。3.有冲突的读写控制当两个端口同时存取存储器同一存储单元，而且至少有一个端口为写操作时，便发生读写冲突。为解决此问题，特设置了BUSY标志。在这种情况下，片上的判断逻辑可以决定对哪个端口优先进行写操作，而对另一个被延迟的端口置BUSY标志(BUSY变为低电平)，即暂时关闭此端口。换句话说，写操作对BUSY变为低电平的端口是不起作用的。一旦优先端口完成写操作，才将被延迟端口的BUSY标志复位(BUSY变为高电平)，开放此端口，允许延迟端口进行写操作。总之，当两个端口均为开放状态(BUSY为高电平)且存取地址相同时，发生写冲突。此时仲裁逻辑可以根据两个端口的地址匹配或片选使能信号有效的时间决定对哪个端口进行存取。判断方式有以下两种。(1)如果地址匹配且在CE之前有效，片上的控制逻辑在CEL和CER之间进行判断来选择端口(CE判断)。(2)如果CE在地址匹配之前变低，片上的控制逻辑在左、右地址间进行判断来选择端口(地址有效判断)。无论采用哪种判断方式，延迟端口的BUSY标志都将置位而关闭此端口，而当允许存取的端口完成操作时，延迟端口BUSY标志才进行复位而打开此端口。表3.8列出了左、右端口进行读写操作时的功能判断。1.存储器的模块化组织一个由若干个模块组成的主存储器是线性编址的。这些地址在各模块中如何安排，有两种方式：一种是顺序方式，一种是交叉方式。在常规主存储器设计中，访问地址采用顺序方式，如图3.23(a)所示。为了说明原理，设存储器容量为32字，分成M0、M1、M2、M3四个模块，每个模块存储8个字。访问地址按顺序分配给一个模块后，接着又按顺序为下一个模块分配访问地址。这样，存储器的32个字可由5位地址寄存器指示，其中高2位选择4个模块中的一个，低3位选择每个模块中的8个字。双端口存储器读写时序可以看出，在顺序方式中某个模块进行存取时，其他模块不工作。而某一模块出现故障时，其他模块可以照常工作。另外通过增添模块来扩充存储器容量也比较方便。但顺序方式的缺点是各模块一个接一个串行工作，因此存储器的带宽受到了限制。图3.23(b)表示采用交叉方式寻址的存储器模块化组织示意图。存储器容量也是32个字，也分成4个模块，每个模块8个字。但地址的分配方法与顺序方式不同：先将4个线性地址0、1、2、3依次分配给M0、M1、M2、M3模块，再将线性地址4、5、6、7依次分配给M0、M1、M2、M3模块……直到全部线性地址分配完毕为止。当存储器寻址时，用地址寄存器的低2位选择4个模块中的一个，而用高3位选择模块中的8个字。可以看出，用地址码的低位字段经过译码选择不同的模块，而高位字段指向相应模块内的存储字。这样，连续地址分布在相邻的不同模块内，而同一个模块内的地址都是不连续的。因此，从定性分析，对连续字的成块传送，交叉方式的存储器可以实现多模块流水式并行存取，大大提高存储器的带宽。由于CPU的速度比主存快，假如能同时从主存取出n条指令，这必然会提高机器的运行速度。多模块交叉存储器就是基于这种思想提出来的。2.多模块交叉存储器的基本结构图3.24示出四模块交叉存储器结构框图。主存被分成4个相互独立、容量相同的模块M0、M1、M2、M3，每个模块都有自己的读写控制电路、地址寄存器和数据寄存器，各自以等同的方式与CPU交换信息。在理想情况下，如果程序段或数据块都是连续地在主存中存取，那么将大大提高主存的访问速度。CPU同时访问四个模块，由存储器控制部件控制它们分时使用数据总线进行信息传递。这样，对每一个存储模块来说，从CPU给出访存命令直到读出信息仍然使用了一个存取周期时间；而对CPU来说，它可以在一个存取周期内连续访问四个模块。各模块的读写过程将重叠进行，所以多模块交叉存储器是一种并行存储器结构。下面进行定量分析。设模块字长等于数据总线宽度，又假设模块存取一个字的存储周期为T，总线传送周期为τ，存储器的交叉模块数为m，那么为了实现流水线方式存取，应当满足T≤mτ(3.1)即成块传送可按τ间隔流水方式进行，也就是每经τ时间延迟后启动下一个模块。图3.25示出了m=4的流水线方式存取示意图。m的最小值mmin=T/τ称为交叉存取度。交叉存储器要求其模块数必须大于或等于mmin，以保证启动某模块后经mτ时间再次启动该模块时，它的上次存取操作已经完成。这样，连续读取m个字所需的时间为t1=T+(m–1)τ(3.2)而顺序方式存储器连续读取m个字所需时间为t2=mT(3.3)图3.24四模块交叉存储器结构框图图3.25流水线方式存取示意图从以上定量分析可知，由于t1＜t2，交叉存储器的带宽确实大大提高了。3.二模块交叉存储器举例图3.26表示二模块交叉存储器方框图。每个模块的容量为1MB(256K×32位)，由8片256K×4位的DRAM芯片组成(位扩展)。二模块的总容量为2MB(512K×32位)。数据总线宽度为32位，地址总线宽度为24位。为简化，将2片DRAM芯片用一个256K×8位的长条框表示。DRAM有读周期、写周期和刷新周期。存储器读/写周期时，在行选通信号RAS有效下输入行地址，在列选通信号CAS有效下输入列地址，于是芯片中行列矩阵中的某一位组被选中。如果是读周期，此位组内容被读出；如果是写周期，将总线上数据写入此位组。刷新周期是在RAS有效下输入刷新地址，此地址指示的一行所有存储元全部被再生。刷新周期比读/写周期有高的优先权，当对同一行进行读/写与刷新操作时，存储控制器对读/写请求予以暂存，延迟到此行刷新结束后再进行。由图3.26可看出：24位的存储器物理地址指定的系统主存总容量可达16MB，按“存储体-块-字”进行寻址。其中高3位用于存储体选择(字扩展)，1个存储体为2MB，全系统有8个2MB存储体。A20～A3的18位地址用于模块中256K个存储字的选择。读/写周期时，它们分为行、列地址两部分送至芯片的9位地址引脚。一个模块内所有芯片的RAS引脚连接到一起，模块0由0RAS驱动，模块1由1RAS驱动。在读/写周期时，主存地址中A2=0，0RAS有效；A2=1，1RAS有效。因此A2用于模块选择，连续的存储字(32位)交错分布在两个模块上，偶字地址在模块0，奇字地址在模块1。CPU给出的主存地址中没有A1和A0位，替代的是4字节允许信号3BE～0BE，以允许对A23～A2指定的存储字中的字节或字完成读/写访问。当3BE～0BE全有效时，即完成字存取。图3.27中没给出译码逻辑，只暗示了3BE～0BE与3CAS～0CAS的对应关系。DRAM需要逐行定时刷新，以使不因存储信息的电容漏电而造成信息丢失。另外，DRAM芯片的读出是一种破坏性读出，因此在读取之后要立即按读出信息予以充电再生。这样，若CPU先后两次读取的存储字使用同一RAS选通信号，CPU在接收到第一个存储字之后必须插入等待状态，直至前一存储字再生完毕才开始第二个存储字的读取。为避免这种情况，模块0由0RAS驱动，模块1由1RAS驱动。图3.27是无等待状态成块存取示意图。由于采用m=2的交叉存取度的成块传送，两个连续地址字的读取之间不必插入等待状态，这称为零等待存取。1.cache的功能cache是一种高速缓冲存储器，是为了解决CPU和主存之间速度不匹配而采用的一项重要技术。其原理基于程序运行中具有的空间局部性和时间局部性特征。如图3.28所示，cache是介于CPU和主存M2之间的小容量存储器，但存取速度比主存快，容量远小于主存。cache能高速地向CPU提供指令和数据，从而加快了程序的执行速度。从功能上看，它是主存的缓冲存储器，由高速的SRAM组成。为追求高速，包括管理在内的全部功能由硬件实现，因而对程序员是透明的。当前，随着半导体器件集成度的进一步提高，可以将小容量的cache与CPU集成到同一芯片中，其工作速度接近于CPU的速度，从而组成两级以上的cache系统。2.cache的基本原理cache除包含SRAM外，还要有控制逻辑。若cache在CPU芯片外，它的控制逻辑一般与主存控制逻辑合成在一起，称为主存/chace控制器；若cache在CPU内，则由CPU提供它的控制逻辑。CPU与cache之间的数据交换是以字为单位，而cache与主存之间的数据交换是以块为单位。一个块由若干字组成，是定长的。当CPU读取内存中一个字时，便发出此字的内存地址到cache和主存。此时cache控制逻辑依据地址判断此字当前是否在cache中：若是，则cache命中，此字立即传送给CPU；若非，则cache缺失(未命中)，用主存读周期把此字从主存读出送到CPU，与此同时，把含有这个字的整个数据块从主存读出送到cache中。图3.29示出了cache的原理图。假设cache读出时间为50ns，主存读出时间为250ns。存储系统是模块化的，主存中每个8K模块和容量16字的cache相联系。cache分为4行，每行4个字(W)。分配给cache的地址存放在一个相联存储器CAM中，它是按内容寻址的存储器。当CPU执行访存指令时，就把所要访问的字的地址送到CAM；如果W不在cache中，则将W从主存传送到CPU。与此同时，把包含W的由前后相继的4个字所组成的一行数据送入cache，替换原来cache中的一行数据。在这里，由始终管理cache使用情况的硬件逻辑电路来实现替换算法。3.cache的命中率从CPU来看，增加cache的目的，就是在性能上使主存的平均读出时间尽可能接近cache的读出时间。为了达到这个目的，在所有的存储器访问中由cache满足CPU需要的部分应占很高的比例，即cache的命中率应接近于1。由于程序访问的局部性，实现这个目标是可能的。在一个程序执行期间，设Nc表示cache完成存取的总次数，Nm表示主存完成存取的总次数，h定义为命中率，则有(3.4)若tc表示命中时的cache访问时间，tm表示未命中时的主存访问时间，1–h表示未命中率(缺失率)，则cache/主存系统的平均访问时间ta为ta=htc+(1–h)tm(3.5)我们追求的目标是，以较小的硬件代价使cache/主存系统的平均访问时间ta越接近tc越好。设r=tm/tc表示主存与cache的访问时间之比，e表示访问效率，则有由式(3.6)看出，为提高访问效率，命中率h越接近1越好。r值以5～10为宜，不宜太大。命中率h与程序的行为、cache的容量、组织方式、块的大小有关。4.cache结构设计必须解决的问题从cache的基本工作原理可以看出，cache的设计需要遵循两个原则：一是希望cache的命中率尽可能高，实际应接近于1；二是希望cache对CPU而言是透明的，即不论是否有cache，CPU访存的方法都是一样的，软件不需增加任何指令就可以访问cache。解决了命中率和透明性问题，就CPU访存的角度而言，内存将具有主存的容量和接近cache的速度。为此，必须增加一定的硬件电路完成控制功能，即cache控制器。在设计cache结构时，必须解决几个问题：①主存的内容调入cache时如何存放？②访存时如何找到cache中的信息？③当cache空间不足时如何替换cache中已有的内容？④需要写操作时如何改写cache的内容？其中，前两个问题是相互关联的，即如何将主存信息定位在cache中，如何将主存地址变换为cache地址。与主存容量相比，cache的容量很小，它保存的内容只是主存内容的一个子集，且cache与主存的数据交换是以块为单位。为了把主存块放到cache中，必须应用某种方法把主存地址定位到cache中，称为地址映射。“映射”一词的物理含义是确定位置的对应关系，并用硬件来实现。这样当CPU访问存储器时，它所给出的一个字的内存地址会自动变换成cache的地址，即cache地址变换。cache替换问题主要是选择和执行替换算法，以便在cache不命中时替换cache中的内容。最后一个问题涉及cache的写操作策略，重点是在更新时保持主存与cache的一致性。地址映射方式有全相联方式、直接方式和组相联方式三种，下面分别介绍。1.全相联映射方式cache的数据块大小称为行，用Li表示，其中i=0,1,2,…,m–1，共有m=2r行。主存的数据块大小称为块，用Bj表示，其中j=0,1,2,…,n–1，共有n=2s块。行与块是等长的，每个块(行)由k=2w个连续的字组成，字是CPU每次访问存储器时可存取的最小单位。在全相联映射中，将主存中一个块的地址(块号)与块的内容(字)一起存于cache的行中，其中块地址存于cache行的标记(tag)部分中。这种带全部块地址一起保存的方法，可使主存的一个块直接复制到cache中的任意一行上，非常灵活。图3.30(a)是全相联映射的多对一示意图，其中cache为8行，主存为256块，每块(行)中有同样多的字。图3.30(b)表示全相联映射方式的检索过程。CPU访存指令指定了一个主存地址，为了快速检索，指令中的块号与cache中所有行的标记同时在比较器中进行比较。如果块号命中，则按字地址从cache中读取一个字；如果块号未命中，则按主存地址从主存中读取这个字。在全相联cache中，全部标记用一个相联存储器来实现，全部数据存储用一个普通RAM来实现。全相联方式的主要缺点是高速比较器电路难于设计和实现，因此只适合于小容量cache采用。2.直接映射方式直接映射方式也是一种多对一的映射关系，但一个主存块只能拷贝到cache的一个特定行位置上去。cache的行号i和主存的块号j有如下函数关系：i=jmodm(3.7)式中，m为cache中的总行数。显然，主存的第0块，第m块，第2m块，…，第2s–m块只能映射到cache的第0行；而主存的第1块，第m+1块，第2m+1块，…，第2s–m+1块只能映射到cache的第1行。图3.31(a)表示直接映射方式的示意图，cache假设为8行，主存假设为256块，故以8为模进行映射。这样，允许存于cache第L0行的主存块号是B0,B8,B16,…,B248(共32块)。同样，映射到第L7的主存块号也是32块。此处s=8，Y=3，s–Y=5。为了理解方便，可以把主存首先分区，每个区的块数与cache的行数m相等。如图3.31(a)所示。所有区的第0块在调入cache时只能映射到cache的第0行，所有区的第1块在调入cache时只能映射到cache的第1行……所有区的第m–1块在调入cache时只能映射到cache的第m–1行。在直接映射方式中，将s位的主存块地址分成两部分：低r位主存区内块号作为cache的行地址，s–r位区号作为标记(tag)与块数据一起保存在该行。当CPU以一个给定的内存地址访问cache时，首先用r位区内块号找到cache中的特定一行，然后用地址中的s–r位区号部分与此行的标记在比较器中做比较。若相符即命中，在cache中找到了所要求的块，而后用地址中最低的w位读取所需求的字。若不符，则未命中，由主存读取所要求的字。直接映射方式的优点是硬件简单，成本低，地址变换速度快。缺点是每个主存块只有一个固定的行位置可存放。如果连续访问块号相距m整数倍的两个块，因两个块映射到同一cache行时，就会发生冲突。发生冲突时就要将原先存入的行换出去，但很可能过一段时间又要换入。频繁的置换会使cache效率下降。因此直接映射方式适合于需要大容量cache的场合，更多的行数可以减小冲突的机会。思考题可否将第0区的所有页映射到cache第0行？可否将第1区的所有页映射到cache第1行？……请与上面的映射方式对比。3.组相联映射方式全相联映射和直接映射两种方式的优缺点正好相反。从存放位置的灵活性和命中率来看，前者为优；从比较器电路简单及硬件投资来说，后者为佳。而组相联映射方式是前两种方式的折中方案，它适度地兼顾了二者的优点又尽量避免二者的缺点，因此被普遍采用。如图3.32(a)所示，所有区的第0块在调入cache时只能映射到cache的第0组，所有区的第1块在调入cache时只能映射到cache的第1组，所有区的第u–1块在调入cache时只能映射到cache的第u–1组。在直接映射方式中，每个区第i块只能映射到cache唯一的第i行，冲突的概率可能会很大。而在组相联映射方式中，每个区第i块可以映射到第i组的v行中(图中v=2)，而且在v行中可以自由选择空余的行。这种方式将cache分成u组，每组v行。主存块存放到哪个组是固定的，取决于主存块在主存区中是第几块。至于存到该组哪一行是灵活的，即有如下函数关系：内存地址中，s位块号划分成两部分：低d位(2d=u)主存区内块号用于表示cache组号(而不是cache行号)，高s–d位区号作为标记与块数据一起存于此组的某行中。图3.32(b)表示组相联映射的示意图。例中cache划分u=4组，每组有v=2行，即m=u×v=8。主存容量为256块，其中B0,B4,B9,…,B252共64个主存块映射到cache第S0组；B1,B5,B10,…,B253共64个主存块映射到cache的第S1组；以此类推。图3.32(c)表示组相联cache的检索过程。注意cache的每一小框代表的不是“字”而是“行”。当CPU给定一个内存地址访问cache时，首先用d位区内块号找到cache的相应组，然后将主存地址高s–d位区号部分与该组v行中的所有标记同时进行比较。哪行的标记与之相符，哪行即命中。此后再以内存地址的w位字地址部分检索此行的具体字，并完成所需要求的存取操作。如果此组没有一行的标记与之相符，即cache未命中，此时需按主存地址访问主存。组相联映射方式中的每组行数v一般取值较小，典型值是2、4、8、16。这种规模的v路比较器容易设计和实现。而块在组中的排放又有一定的灵活性，使冲突减少。为强调比较器的规模和存放的灵活程度，常称之为v路组相联cache①。cache工作原理要求它尽量保存最新数据。当一个新的主存块需要拷贝到cache，而允许存放此块的行位置都被其他主存块占满时，就要产生替换。替换问题与cache的组织方式紧密相关。对直接映射的cache来说，因一个主存块只有一个特定的行位置可存放，所以解决问题很简单，只要把此特定位置上的原主存块换出cache即可。对全相联和组相联cache来说，就要从允许存放新主存块的若干特定行中选取一行换出。如何选取就涉及替换策略，又称替换算法。硬件实现的常用算法主要有以下三种。1)最不经常使用(LFU)算法LFU算法认为应将一段时间内被访问次数最少的那行数据换出。为此，每行设置一个计数器。新行调入后从0开始计数，每访问一次，被访行的计数器增1。当需要替换时，对这些特定行的计数值进行比较，将计数值最小的行换出，同时将这些特定行的计数器都清零。这种算法将计数周期限定在两次替换之间的间隔时间内，因而不能严格反映近期访问情况。2)近期最少使用(LRU)算法LRU算法将近期内长久未被访问过的行换出。为此，每行也设置一个计数器，但它们是cache每命中一次，命中行计数器清零，其他各行计数器增1。当需要替换时，比较各特定行的计数值，将计数值最大的行换出。这种算法保护了刚复制到cache中的新数据行，符合cache工作原理，因而使cache有较高的命中率。对2路组相联的cache来说，LRU算法的硬件实现可以简化。因为一个主存块只能在一个特定组的两行中来做存放选择，二选一完全不需要计数器，只需一个二进制位即可。例如，规定一组中的A行复制进新数据可将此位置“1”，B行复制进新数据可将此位置“0”。当需要置换时，只需检查此二进制位状态即可：为0换出A行，为1换出B行，实现了保护新行的原则。奔腾CPU内的数据cache是一个2路组相联结构，就采用这种简捷的LRU替换算法。3)随机替换随机替换策略实际上是不要什么算法，从特定的行位置中随机地选取一行换出即可。这种策略在硬件上容易实现，且速度也比前两种策略快。缺点是随意换出的数据很可能马上又要使用，从而降低命中率和cache工作效率。但这个不足随着cache容量增大而减小。研究表明，随机替换策略的性能只是稍逊于前两种策略。由于cache的内容只是主存部分内容的副本，它应当与主存内容保持一致。而CPU对cache的写入更改了cache的内容。如何与主存内容保持一致，可选用如下三种写操作策略。1)写回法(writeback,copyback)写回法要求：当CPU写cache命中时，只修改cache的内容，而不立即写入主存；只有当此行被换出时才写回主存。这种方法使cache真正在CPU-主存之间读/写两方面都起到高速缓存作用。对一个cache行的多次写命中都在cache中快速完成，只是需要替换时才写回速度较慢的主存，减少了访问主存的次数。实现这种方法时，每个cache行必须配置一个修改位，以反映此行是否被CPU修改过。当某行被换出时，根据此行修改位是1还是0，来决定将该行内容写回主存还是简单弃去。如果CPU写cache未命中，为了包含欲写字的主存块在cache分配一行，将此块整个复制到cache后对其进行修改。主存的写修改操作统一留到换出时再进行。显然，这种写cache与写主存异步进行的方式可显著减少写主存次数，但是存在不一致性的隐患。2)全写法(writethrough)全写法要求：当写cache命中时，cache与主存同时发生写修改，因而较好地维护了cache与主存的内容的一致性。当写cache未命中时，只能直接向主存进行写入。但此时是否将修改过的主存块取到cache，有两种选择方法：一种称为WTWA法，取主存块到cache并为它分配一个行位置；另一种称为WTNWA法，不取主存块到cache。全写法是写cache与写主存同步进行，优点是cache中每行无须设置一个修改位，以及相应的判断逻辑。缺点是，cache对CPU向主存的写操作无高速缓冲功能，降低了cache的性能。3)写一次法(writeonce)写一次法是基于写回法并结合全写法的写策略：写命中与写未命中的处理方法和写回法基本相同，只是第一次写命中时要同时写入主存。这是因为第一次写cache命中时，CPU要在总线上启动一个存储写周期，其他cache监听到此主存块地址及写信号后，即可复制该块或及时作废，以便维护系统全部cache的一致性。奔腾CPU的片内数据cache就采用了写一次法。我们可以从Intel微处理器的演变中清楚地看到cache组织的演变。80386不包含片内cache。80486包含8KB的片内cache，它采用每行16B的4路组相联结构。所有的Pentium处理器包含两个片内L1cache，一个是D-cache(数据cache)，一个是I-cache(指令cache)。Pentium2还包含一个L2cache，其容量是256KB，每行128B，采用8路组相联结构。Pentium3增加了一个L3cache。到Pentium4，L3cache已移到处理器芯片中。图3.33示出了Pentium4的三级cache的布局。Pentium4处理器的核心由下列四个主要部件组成：取指/译码单元按顺序从L2cache中取程序指令，将它们译成一系列的微指令，并存入L1指令cache中。乱序执行逻辑依据数据相关性和资源可用性，调度微指令的执行，因而微指令可按不同于所取机器指令流的顺序被调度执行。执行单元它执行微指令，从L1数据cache中取所需数据，并在寄存器组中暂存运算结果。存储器子系统这部分包括L2cache、L3cache和系统总线。当L1、L2cache未命中时，使用系统总线访问主存。系统总线还用于访问I/O资源。不同于所有先前Pentium模式和大多数处理器所采用的结构，Pentium4的指令cache位于指令译码逻辑和执行部件之间。其设计理念是：Pentium4将机器指令译成由微指令组成的简单RISC类指令，而使用简单定长的微指令可允许采用超标量流水线和调度技术，从而增强机器的性能。关于流水线技术，将留在第五章中讨论。思考题Pentium4中为什么设置L1、L2、L3三个cache？L1cache分成I-cache和D-cache有什么好处？所有现代计算机都使用了cache。大多数情况下，这些cache和组成CPU的微处理器集成到一个芯片上。为进一步缩小现代处理器高时钟频率和访问DRAM相对较慢之间的差距，高性能微处理器可支持附加一级的cache。这种二级的cache，位于处理器芯片内或是位于处理器芯片外单独的一组SRAM，当访问主cache缺失后就会访问它。如果二级cache包含所请求的数据，缺失损失就是二级cache的访问时间，这要比主存的访问时间少得多。如果第一级cache、第二级cache都不包含这个数据，就需要访问主存储器，产生更大的缺失损失。使用二级cache能使性能提高多少？下面通过例子来说明。1.实地址与虚地址在早期的单用户单任务操作系统(如DOS)中，每台计算机只有一个用户，每次运行一计算机组成原理104个程序，且程序不是很大，单个程序完全可以存放在实际内存中。这时虚拟存储器(简称虚存)并没有太大的用处。但随着程序占用存储器容量的增长和多用户多任务系统的出现，在程序设计时，程序所需的存储器容量与计算机系统实际配备的主存储器的容量之间往往存在着矛盾。例如，在某些低档的计算机中，物理内存的容量较小，而某些程序却需要很大的内存才能运行；而在多用户多任务系统中，多个用户或多个任务共享全部主存，要求同时执行多道程序。这些同时运行的程序到底占用实际内存中的哪一部分，在编制程序时是无法确定的，必须等到程序运行时才动态分配。为此，希望在编制程序时独立编址，既不考虑程序是否能在物理存储器中存放得下(因为这与程序运行时的系统配置和当时其他程序的运行情况有关，在编程时一般无法确定)，也不考虑程序应该存放在什么物理位置。而在程序运行时，则分配给每个程序一定的运行空间，由地址转换部件(硬件或软件)将编程时的地址转换成实际内存的物理地址。如果分配的内存不够，则只调入当前正在运行的或将要运行的程序块(或数据块)，其余部分暂时驻留在辅存中。这样，用户编制程序时使用的地址称为虚地址或逻辑地址，其对应的存储空间称为虚存空间或逻辑地址空间；而计算机物理内存的访问地址则称为实地址或物理地址，其对应的存储空间称为物理存储空间或主存空间。程序进行虚地址到实地址转换的过程称为程序的再定位。2.虚存的访问过程虚存空间的用户程序按照虚地址编程并存放在辅存中。程序运行时，由地址变换机构依据当时分配给该程序的实地址空间把程序的一部分调入实存。每次访存时，首先判断该虚地址所对应的部分是否在实存中：如果是，则进行地址转换并用实地址访问主存；否则按照某种算法将辅存中的部分程序调度进内存，再按同样的方法访问主存。由此可见，每个程序的虚地址空间可以远大于实地址空间，也可以远小于实地址空间。前一种情况以提高存储容量为目的，后一种情况则以地址变换为目的。后者通常出现在多用户或多任务系统中：实存空间较大，而单个任务并不需要很大的地址空间，较小的虚存空间则可以缩短指令中地址字段的长度。有了虚存机制后，应用程序就可以透明地使用整个虚存空间。对应用程序而言，如果主存的命中率很高，虚存的访问时间就接近于主存访问时间，而虚存的大小仅仅依赖于辅存的大小。这样，每个程序就可以拥有一个虚拟的存储器，它具有辅存的容量和接近主存的访问速度。但这个虚存是由主存和辅存以及辅存管理部件构成的概念模型，不是实际的物理存储器。虚存是在主存和辅存之外附加一些硬件和软件实现的。由于软件的介入，虚存对设计存储管理软件的系统程序员而言是不透明的，但对应用程序员而言仍然是透明的。3.cache与虚存的异同从虚存的概念可以看出，主存-辅存的访问机制与cache-主存的访问机制是类似的。这是由cache存储器、主存和辅存构成的三级存储体系中的两个层次。cache和主存之间以及主存和辅存之间分别有辅助硬件和辅助软硬件负责地址变换与管理，以便各级存储器能够组成有机的三级存储体系。cache和主存构成了系统的内存，而主存和辅存依靠辅助软硬件的支持支撑虚拟存储器工作。在三级存储体系中，cache-主存和主存-辅存这两个存储层次有许多相同点。(1)出发点相同二者都是为了提高存储系统的性能价格比而构造的分层存储体系，都力图使存储系统的性能接近高速存储器，而价格和容量接近低速存储器。(2)原理相同都是利用了程序运行时的局部性原理把最近常用的信息块从相对慢速而大容量的存储器调入相对高速而小容量的存储器。但cache-主存和主存-辅存这两个存储层次也有许多不同之处。(1)侧重点不同cache主要解决主存与CPU的速度差异问题；而就性能价格比的提高而言，虚存主要是解决存储容量问题，另外还包括存储管理、主存分配和存储保护等方面。(2)数据通路不同CPU与cache和主存之间均可以有直接访问通路，cache不命中时可直接访问主存；而虚存所依赖的辅存与CPU之间不存在直接的数据通路，当主存不命中时只能通过调页解决，CPU最终还是要访问主存。(3)透明性不同cache的管理完全由硬件完成，对系统程序员和应用程序员均透明；而虚存管理由软件(操作系统)和硬件共同完成，由于软件的介入，虚存对实现存储管理的系统程序员不透明，而只对应用程序员透明(段式和段页式管理对应用程序员“半透明”)。(4)未命中时的损失不同由于主存的存取时间是cache的存取时间的5～10倍，而主存的存取速度通常比辅存的存取速度快上千倍，故主存未命中时系统的性能损失要远大于cache未命中时的损失。4.虚存机制要解决的关键问题虚存机制也要解决一些关键问题。(1)调度问题决定哪些程序和数据应被调入主存。(2)地址映射问题在访问主存时把虚地址变为主存物理地址(这一过程称为内地址变换)；在访问辅存时把虚地址变成辅存的物理地址(这一过程称为外地址变换)，以便换页。此外还要解决主存分配、存储保护与程序再定位等问题。(3)替换问题决定哪些程序和数据应被调出主存。(4)更新问题确保主存与辅存的一致性。在操作系统的控制下，硬件和系统软件为用户解决了上述问题，从而使应用程序的编程大大简化。1.页式虚存地址映射页式虚拟存储系统中，虚地址空间被分成等长的页，称为逻辑页；主存空间也被分成同样大小的页，称为物理页。相应地，虚地址分为两个字段：高字段为逻辑页号，低字段为页内地址(偏移量)；实存地址也分为两个字段：高字段为物理页号，低字段为页内地址。通过页表可以把虚地址(逻辑地址)转换成物理地址。在大多数系统中，每个进程对应一个页表。页表中对应每一个虚存页面有一个表项，表项的内容包含该虚存页面所在的主存页面的地址(物理页号)，以及指示该逻辑页是否已调入主存的有效位。地址变换时，用逻辑页号作为页表内的偏移地址索引页表(将虚页号看作页表数组下标)并找到相应物理页号，用物理页号作为实存地址的高字段，再与虚地址的页内偏移量拼接，就构成了完整的物理地址。现代的中央处理器通常有专门的硬件支持地址变换。图3.34显示了页式虚拟存储器的地址映射过程。每个进程所需的页数并不固定，所以页表的长度是可变的，因此通常的实现方法是把页表的基地址保存在寄存器中，而页表本身则放在主存中。由于虚存地址空间可以很大，因而每个进程的页表有可能非常长。例如，如果一个进程的虚地址空间为2GB，每页的大小为512B，则总的虚页数为231/29=222。为了节省页表本身占用的主存空间，一些系统把页表安排存储在虚存空间，因而页表本身也要进行分页。当一个进程运行时，其页表中一部分在主存中，另一部分则在辅存中保存。另一些系统采用二级页表结构。每个进程有一个页目录表，其中的每个表项指向一个页表。因此，若页目录表的长度(表项数)是m，每个页表的最大长度(表项数)为n，则一个进程最多可以有m×n个页。在页表长度较大的系统中，还可以采用反向页表(invertedpagetable)实现物理页号到逻辑页号的反向映射。页表中对应每一个物理页号有一个表项，表项的内容包含该物理页所对应的逻辑页号。访存时，通过逻辑页号在反向页表中逐一查找。如果找到匹配的页，则用表项中的物理页号取代逻辑页号；如果没有匹配表项，则说明该页不在主存中。这种方式的优点是页表所占空间大大缩小，但代价是需要对反向页表进行检索，查表的时间很长。有些系统通过散列(哈希)表加以改进。2.内页表和外页表上面所说的页表是虚地址到主存物理地址的变换表，通常称为内页表。与内页表对应的还有外页表，用于虚地址与辅存地址之间的变换。当主存缺页时，调页操作首先要定位辅存，而外页表的结构与辅存的寻址机制密切相关。例如，对磁盘而言，辅存地址包括磁盘机号、磁头号、磁道号和扇区号等。外页表通常放在辅存中，在需要时可调入主存。当主存不命中时，由存储管理部件向CPU发出“缺页中断”，进行调页操作。3.转换后援缓冲器(TLB)由于页表通常在主存中，因而即使逻辑页已经在主存中，也至少要访问两次物理存储器才能实现一次访存，这将使虚拟存储器的存取时间加倍。为了避免对主存访问次数的增多，可以对页表本身实行二级缓存，把页表中最活跃的部分存放在高速存储器中。这个专用于页表缓存的高速存储部件通常称为转换后援缓冲器(TLB)，又称为快表。而保存在主存中的完整页表则称为慢表。快表的作用是加快地址变换。TLB的作用与主存和CPU之间的cache作用相似，通常由相联存储器实现，容量比慢表小得多，存储慢表中部分信息的副本，可以完成硬件高速检索操作。地址变换时，根据逻辑页号同时查快表和慢表，当在快表中有此逻辑页号时，就能很快地找到对应的物理页号。根据程序的局部性原理，多数虚拟存储器访问都将通过TLB进行，从而有效降低访存的时间延迟。图3.35显示了TLB的地址映射过程。由于TLB的缓冲过程与cache的缓冲过程是独立的，所以在每次存储器访问过程中有可能要经历多次变换。存储管理部件首先用虚地址中的虚页号部分检索TLB：匹配成功时则通过实页号与偏移量拼接出物理地址；TLB匹配不成功则需查询主存中的页表，然后通过实页号与偏移量拼接出物理地址。而该物理地址所在的主存空间可能已经被调入cache中，也可能还在主存中，甚至还有可能在辅存中。对后一种情况，包含该地址的页必须被调入主存，并将其所在的块装入cache中，修改相应的页表和TLB表项。可见虚拟存储器的地址映射与地址变换过程是相当复杂的过程。4.虚拟存储器、TLB和cache的协同操作虚拟存储器和cache系统如同一个层次结构般一起工作。操作系统在管理该层次结构时起到关键作用，当它决定要把某一页移到磁盘上去时，就迫使该页的全部内容从cache中删除。同时，操作系统修改页表和TLB，而试图访问该页上的任何数据可能将导致缺页。在最好的情况下，虚拟地址由TLB进行转换，然后被送到cache，找到正确的数据并取回处理器。在最坏的情况下，一次访问会在存储器层次结构的三个组成部分都产生缺失：TLB、页表和cache。1.段式虚拟存储器页面是主存物理空间中划分出来的等长的固定区域。分页方式的优点是页长固定，因而便于构造页表、易于管理，且不存在外碎片。但分页方式的缺点是页长与程序的逻辑大小不相关。例如，某个时刻一个子程序可能有一部分在主存中，另一部分则在辅存中。这不利于编程时的独立性，并给换入换出处理、存储保护和存储共享等操作造成麻烦。另一种划分可寻址的存储空间的方法称为分段。段是按照程序的自然分界划分的长度可以动态改变的区域。通常，程序员把子程序、操作数和常数等不同类型的数据划分到不同的段中，并且每个程序可以有多个相同类型的段。在段式虚拟存储系统中，虚地址由段号和段内地址(偏移量)组成。虚地址到实主存地址的变换通过段表实现。每个程序设置一个段表，段表的每一个表项对应一个段。每个表项至少包含下面三个字段：(1)有效位指明该段是否已经调入实存。(2)段起址指明在该段已经调入实存的情况下，该段在实存中的首地址。(3)段长记录该段的实际长度。设置段长字段的目的是保证访问某段的地址空间时，段内地址不会超出该段长度导致地址越界而破坏其他段。段表本身也是一个段，可以存在辅存中，但一般驻留在主存中。针对每个虚地址，存储管理部件首先以段号s为索引访问段表的第s个表项。若该表项的有效位为1，则将虚地址的段内偏移量d与该表项的段长字段比较：若偏移量较大则说明地址越界，将产生地址越界中断；否则，将该表项的段起址与段内偏移量相加，求得主存实地址并访存。如果该表项的有效位为0，则产生缺段中断，从辅存中调入该段，并修改段表。段式虚地址向实存地址的变换过程如图3.36所示。分页对程序员而言是不可见的，而分段通常对程序员而言是可见的，因而分段为组织程序和数据提供了方便。与页式虚拟存储器相比，段式虚拟存储器有许多优点：①段的逻辑独立性使其易于编译、管理、修改和保护，也便于多道程序共享。②段长可以根据需要动态改变，允许自由调度，以便有效利用主存空间。因为段的长度不固定，段式虚拟存储器也有一些缺点：①主存空间分配比较麻烦。②容易在段间留下许多外碎片，造成存储空间利用率降低。③由于段长不一定是2的整数次幂，因而不能简单地像分页方式那样用虚地址和实地址的最低若干二进制位作为段内偏移量，并与段号进行直接拼接，必须用加法操作通过段起址与段内偏移量的求和运算求得物理地址。因此，段式存储管理比页式存储管理方式需要更多的硬件支持。2.段页式虚拟存储器段页式虚拟存储器是段式虚拟存储器和页式虚拟存储器的结合。实存被等分成页。每个程序先按逻辑结构分段，每段再按照实存的页大小分页，程序按页进行调入和调出操作，但可按段进行编程、保护和共享。在段页式虚拟存储系统中，每道程序均通过一个段表和多个页表进行两级再定位。段表中的每个表项对应一个段，每个表项有一个指针指向该段的页表。页表则指明该段各页在主存中的位置，以及是否已装入、是否已修改等状态信息。一个虚地址由段号、段内页号和页内偏移量构成。在多任务系统中，操作系统还会在每个虚地址前面增加一个表明该程序在系统中的序号的基号。一个虚地址可以看作由四个字段构成：(基号N)段号S段内逻辑页号P页内地址偏移量D【在主存中，每道程序都有一张段表，A程序有4段，C程序有3段，每段应有一张页表，段表的每行就表示相应页表的起始位置，而页表内的每行即为相应的物理页号。请说明虚实地址变换过程。解地址变换过程如下：(1)由存储管理部件根据基号C找到段表基址寄存器表第c个表项，获得程序C的段表基址SC。再根据段号S(=1)找到程序C段表的第S个表项，得到段S的页表起始地址b。(2)根据段内逻辑页号P(=2)检索页表，得到物理页号(图中为10)。(3)物理页号与页内地址偏移量拼接即得物理地址。假如计算机系统中只有一个基址寄存器，则基号可不要。多道程序切换时，由操作系统修改基址寄存器内容。实际上，上述每个段表和页表的表项中都应设置一个有效位。只有在有效位为1时才按照上述流程操作，否则需中断当前操作先进行建表或调页。可以看出，段页式虚拟存储器的缺点是在由虚地址向主存地址的映射过程中需要多次查表，因而实现复杂度较高。当从辅存调页至主存而主存已满时，也需要进行主存页面的替换。虚拟存储器的替换算法与cache的替换算法类似，有FIFO算法、LRU算法、LFU算法等。虚拟存储器的替换算法与cache的替换算法不同的是：(1)cache的替换全部靠硬件实现，而虚拟存储器的替换有操作系统的支持。(2)虚存缺页对系统性能的影响比cache未命中要大得多，因为调页需要访问辅存，并且要进行任务切换。(3)虚存页面替换的选择余地很大，属于一个进程的页面都可替换。为支持虚存的替换，通常在页表或段表的每一表项中设置一个修改位，标识该表项所对应的主存页或段空间在被调入主存后是否被修改过。对于将被替换出去的空间，假如其内容没有被修改过，就不必进行额外处理；否则就需把该空间存储的内容重新写入辅存，以保证辅存中数据的正确性。在FIFO算法中，FIFO队列中的页面始终按照从a到c的顺序依次推进，页面从a位置进入队列，替换始终在页面c的位置进行。FIFO+LRU算法是对FIFO算法的一种改进。但与FIFO算法不同的是，如果某个页面命中，则将该页面移动到FIFO队列入口位置(页面a所在的位置)。因为根据程序的局部性原理，刚被访问的页面在最近的将来被再次访问的概率较大，故将其被替换的时间延后。上面的例子说明FIFO+LRU算法比FIFO算法的命中率高。存储管理部件(MemoryManagementUnit，MMU)是系统中进行虚实地址转换的核心部件。MMU的主要功能有：在TLB的协助下完成虚实地址转换；维护TLB的控制机制；负责存储保护；在TLB失效或非法访问时向处理器发起中断；维护一个TLB失效后的再填充机制(tablewalking)。MMU的工作流程大致如下：CPU发出访存的虚拟地址后，MMU通过页表查找机制访问主存页表，获得映射关系；如果主存命中，MMU将虚页号变换为物理页号，产生物理地址访存；如果主存缺页，CPU将转到操作系统的页面失效程序入口，由操作系统进行调页操作。基于英特尔IA-32体系结构的奔腾系列机为存储管理提供了硬件支持。目前广泛使用的奔腾处理机的存储管理机制与英特尔80386和80486基本相同。IA-32体系结构微处理机的存储管理硬件支持三种存储器模型，如图3.38所示。平坦存储器模型(flatmemorymodel)内存被组织成单一的、连续的地址空间，称为“线性地址空间”。所有的代码、数据和堆栈均包含在该地址空间内，该空间的字节地址范围为0～232–1。分段存储器模型(segmentedmemorymodel)每个程序均使用一组独立的地址空间，每个地址空间就是一个段，段的最大长度为232B。逻辑地址由段选择器和偏移量组成，处理机将逻辑地址透明地转换为线性地址。实地址模式存储器模型(real-addressmodememorymodel)是为保持与早期的8086处理机兼容的存储器模式。线性地址空间被分为段，段的最大长度为64KB。线性地址空间的最大长度为220B。IA-32体系结构微处理机的虚拟存储器可以通过两种方式实现：分段和分页。存储管理部件包括分段部件(SU)和分页部件(PU)两部分。分段部件将程序中使用的虚地址转换成线性地址。而分页部件则将线性地址转换为物理地址。在分段部件和分页部件中，每一部分都可以独立地打开或关闭，因而可出现四种组合方式：(1)不分段不分页模式程序中使用的逻辑地址与物理地址相同。(2)分段不分页模式相当于段式虚拟存储器。程序中使用的逻辑地址由一个16位段选择器和一个32位偏移量组成。段选择器中的最低两位用于存储保护，其余14位选择一个特定的段。因此，对于分段的存储器，用户的虚拟地址空间是214+32=246=64TB。而物理地址空间使用32位地址，最大4GB。由分段部件将二维的虚拟地址转换为一维的线性地址。在分页部件不工作的情况下，线性地址也就是主存物理地址。(3)不分段分页模式相当于页式虚拟存储器。程序中使用的是32位线性地址，由分页部件将其转换成32位物理地址。用户的虚拟地址空间是232=4GB。(4)分段分页模式在分段基础上增加分页存储管理的模式，即段页式虚拟存储器。程序中使用的逻辑地址由一个16位段选择器和一个32位偏移量组成，由分段部件将二维的虚拟地址转换为一维的线性地址，再由分页部件将其转换成32位物理地址。用户的虚拟地址空间是214+32=246=64TB。3.8.3分页模式下的地址转换在分页模式下，有两种页大小，其地址映射方式不同：一种是兼容早期的80386和80486的4KB的页大小，使用页目录表和页表两级结构进行地址转换；另一种是从奔腾处理机开始采用的4MB页大小，使用单级页表结构。4MB分页方式的地址转换如图3.39所示。32位线性地址分为高10位的页号和低22位的页内偏移量两个字段。系统中由一个有1024个表项的页表实现地址转换。控制寄存器CR3指向页表，页表的每个表项为32位。其中：I位指示页大小I=1为4MB页大小；I=0为4KB大小。P为出现位P=1表示此页已被装入主存；P=0时访问此页将引起缺页中断。A为已访问位若在装入主存后此页被访问过，则A被置为1；否则置A为0。D为脏位若该页在调入主存后被修改过，则D被置为1，表示在该页被换出主存时应写回辅存。R/W为读/写控制位用于指明用户对该页的权限是只读还是可读写。U/S为用户/管理员权限控制位指明该页是只能被操作系统访问还是同时允许操作系统和用户程序访问。本章小结对存储器的要求是容量大、速度快、成本低。为了解决这三方面的矛盾，计算机采用多级存储体系结构，即cache、主存和外存。CPU能直接访问内存(cache、主存)，但不能直接访问外存。存储器的技术指标有存储容量、存取时间、存储周期、存储器带宽。广泛使用的SRAM和DRAM都是半导体随机读写存储器，前者速度比后者快，但集成度不如后者高。二者的优点是体积小，可靠性高，价格低廉，缺点是断电后不能保存信息。只读存储器和闪速存储器正好弥补了SRAM和DRAM的缺点，即使断电也仍然保存原先写入的数据。特别是闪速存储器能提供高性能、低功耗、高可靠性以及移动性，是一种全新的存储器体系结构。双端口存储器和多模块交叉存储器属于并行存储器结构。前者采用空间并行技术，后者采用时间并行技术。这两种类型的存储器在科研和工程中大量使用。cache是一种高速缓冲存储器，是为了解决CPU和主存之间速度不匹配而采用的一项重要的硬件技术，并且发展为多级cache体系，指令cache与数据cache分设体系。要求cache的命中率接近于1。主存与cache的地址映射有全相联、直接、组相联三种方式。其中组相联方式是前二者的折中方案，适度地兼顾了二者的优点又尽量避免其缺点，从灵活性、命中率、硬件投资来说较为理想，因而得到了普遍采用。用户程序按照虚地址(逻辑地址)编程并存放在辅存中。程序运行时，由地址变换机构依据当时分配给该程序的实地址空间把程序的一部分调入实存(物理存储空间或主存空间)。由操作系统在硬件的支持下对程序进行虚地址到实地址的变换，这一过程称为程序的再定位。每次访存时，首先判断该虚地址所对应的部分是否在实存中：如果是，则进行地址转换并用实地址访问主存；否则，按照某种算法将辅存中的部分程序调度进内存，再按同样的方法访问主存。对应用程序而言，如果主存的命中率很高，虚存的访问时间就接近于主存访问时间，而虚存的大小仅仅依赖于辅存的大小。虚存机制也要解决一些关键问题，包括调度问题、地址映射问题和替换问题等。在操作系统的控制下，硬件和系统软件为用户解决了上述问题，从而使应用程序的编程大大简化。页式虚拟存储系统中，虚地址空间和主存空间都被分成大小相等的页，通过页表可以把虚地址转换成物理地址。为了避免对主存访问次数增多，可以对页表本身实行二级缓存，把页表中的最活跃部分存放在转换后援缓冲器(TLB)中。分页方式的缺点是页长与程序的逻辑大小不相关，而分段方式则可按照程序的自然分界将内存空间划分为长度可以动态改变的存储区域。在段式虚拟存储系统中，虚地址由段号和段内地址(偏移量)组成。虚地址到实主存地址的变换通过段表实现。段页式虚拟存储器是段式虚拟存储器和页式虚拟存储器的结合，程序按页进行调入和调出操作，但可按段进行编程、保护和共享。虚拟存储器还解决了存储保护等问题。在虚拟存储系统中，通常采用页表保护、段表保护和键式保护方法实现存储区域保护。还可以结合对主存信息的使用方式实现访问方式保护。计算机的程序是由一系列的机器指令组成的。指令就是要计算机执行某种操作的命令。从计算机组成的层次结构来说，计算机的指令有微指令、机器指令和宏指令之分。微指令是微程序级的命令，它属于硬件；宏指令是由若干条机器指令组成的软件指令，它属于软件；而机器指令则介于微指令与宏指令之间，通常简称为指令，每一条指令可完成一个独立的算术运算或逻辑运算操作。本章所讨论的指令，是机器指令。一台计算机中所有机器指令的集合，称为这台计算机的指令系统(指令集)。指令系统是表征一台计算机性能的重要因素，它的格式与功能不仅影响到机器的硬件结构，而且影响到系统软件。因为指令是设计一台计算机的硬件与低层软件的接口。20世纪50年代，由于受器件限制，计算机的硬件结构比较简单，所支持的指令系统只有定点加减、逻辑运算、数据传送、转移等十几至几十条指令。60年代后期，随着集成电路的出现，硬件功能不断增强，指令系统越来越丰富，除以上基本指令外，还设置了乘除运算、浮点运算、十进制运算、字符串处理等指令，指令数目多达一二百条，寻址方式也趋多样化。随着集成电路的发展和计算机应用领域的不断扩大，60年代后期开始出现系列计算机。所谓系列计算机，是指基本指令系统相同、基本体系结构相同的一系列计算机，如Pentium系列就是曾经流行的一种个人机系列。一个系列往往有多种型号，但由于推出时间不同，采用器件不同，它们在结构和性能上有所差异。通常是新机种在性能和价格方面比旧机种优越。系列机解决了各机种的软件兼容问题，其必要条件是同一系列的各机种有共同的指令系统，而且新推出的机种指令系统一定包含所有旧机种的全部指令。因此旧机种上运行的各种软件可以不加任何修改便可在新机种上运行，大大减少了软件开发费用。70年代末期，计算机硬件结构随着VLSI技术的飞速发展而越来越复杂化，大多数计算机的指令系统多达几百条。我们称这些计算机为复杂指令系统计算机，简称CISC。但是如此庞大的指令系统不但使计算机的研制周期变长，且由于采用了大量使用频率很低的复杂指令而造成硬件资源浪费，产生指令系统所谓百分比20∶80的规律，即最常使用的简单指令仅占指令总数的20%，但在程序中出现的频率却占80%。为此人们又提出了便于VLSI技术实现的精简指令系统计算机，简称RISC。指令系统的性能如何，决定了计算机的基本功能，因而指令系统的设计是计算机系统设计中的一个核心问题，它不仅与计算机的硬件结构紧密相关，而且直接关系到用户的使用需要。一个完善的指令系统应满足如下四方面的要求：完备性完备性是指用汇编语言编写各种程序时，指令系统直接提供的指令足够使用，而不必用软件来实现。完备性要求指令系统丰富、功能齐全、使用方便。一台计算机中最基本、必不可少的指令是不多的。许多指令可用最基本的指令编程来实现。例如，乘除运算指令、浮点运算指令可直接用硬件来实现，也可用基本指令编写的程序来实现。采用硬件指令的目的是提高程序执行速度，便于用户编写程序。有效性有效性是指利用该指令系统所编写的程序能够高效率地运行。高效率主要表现在程序占据存储空间小、执行速度快。一般来说，一个功能更强、更完善的指令系统，必定有更好的有效性。规整性规整性包括指令系统的对称性、匀齐性、指令格式和数据格式的一致性。对称性是指：在指令系统中所有的寄存器和存储器单元都可同等对待，所有的指令都可使用各种寻址方式；匀齐性是指：一种操作性质的指令可以支持各种数据类型，如算术运算指令可支持字节、字、双字整数的运算，十进制数运算和单、双精度浮点数运算等；指令格式和数据格式的一致性是指：指令长度和数据长度有一定的关系，以方便处理和存取。例如，指令长度和数据长度通常是字节长度的整数倍。兼容性系列机各机种之间具有相同的基本结构和共同的基本指令系统，因而指令系统是兼容的，即各机种上基本软件可以通用。但由于不同机种推出的时间不同，在结构和性能上有差异，做到所有软件都完全兼容是不可能的，只能做到“向上兼容”，即低档机上运行的软件可以在高档机上运行。计算机的程序，就是人们把需要用计算机解决的问题变换成计算机能够识别的一串指令或语句。编写程序的过程，称为程序设计，而程序设计所使用的工具则是计算机语言。计算机语言有高级语言和低级语言之分。高级语言如C，FORTRAN等，其语句和用法与具体机器的指令系统无关。低级语言分为机器语言(二进制语言)和汇编语言(符号语言)，这两种语言都是面向机器的语言，它们和具体机器的指令系统密切相关。机器语言用指令代码编写程序，而符号语言用指令助记符来编写程序。表4.1列出了高级语言与低级语言的性能比较。计算机能够直接识别和执行的唯一语言是二进制机器语言，但人们用它来编写程序很不方便。另一方面，人们采用符号语言或高级语言编写程序，虽然对人提供了方便，但是机器却不懂这些语言。为此，必须借助汇编器(汇编程序)或编译器(编译程序)，把符号语言或高级语言翻译成二进制码组成的机器语言。汇编语言依赖于计算机的硬件结构和指令系统。不同的机器有不同的指令，所以用汇编语言编写的程序不能在其他类型的机器上运行。高级语言与计算机的硬件结构及指令系统无关，在编写程序方面比汇编语言优越。但是高级语言程序“看不见”机器的硬件结构，因而不能用它来编写直接访问机器硬件资源(如某个寄存器或存储器单元)的系统软件或设备控制软件。为了克服这一缺陷，一些高级语言(如C，FORTRAN等)提供了与汇编语言之间的调用接口。用汇编语言编写的程序，可作为高级语言的一个外部过程或函数，利用堆栈来传递参数或参数的地址。两者的源程序通过编译或汇编生成目标(OBJ)文件后，利用连接程序(LINKER)把它们连接成可执行文件便可运行。采用这种方法，用高级语言编写程序时，若用到硬件资源，则可用汇编程序来实现。机器语言程序员看到的计算机的属性就是指令系统体系结构，简称ISA(InstructionSetArchitecture)，是与程序设计有关的计算机架构。指令系统体系结构主要包括：寄存器组织，存储器的组织和寻址方式，I/O系统结构，数据类型及其表示，指令系统，中断机制，机器工作状态的定义及切换，以及保护机制等。机器指令是用机器字来表示的。表示一条指令的机器字，就称为指令字，通常简称指令。指令格式，则是指令字用二进制代码表示的结构形式，通常由操作码字段和地址码字段组成。操作码字段表征指令的操作特性与功能，而地址码字段通常指定参与操作的操作数的地址。因此，一条指令的结构可用如下形式来表示：操作码字段OP地址码字段A设计计算机时，对指令系统的每一条指令都要规定一个操作码。指令的操作码OP表示该指令应进行什么性质的操作，如进行加法、减法、乘法、除法、取数、存数等。不同的指令用操作码字段的不同编码来表示，每一种编码代表一种指令。例如，操作码001可以规定为加法操作；操作码010可以规定为减法操作；而操作码110可以规定为取数操作等。CPU中的专门电路用来解释每个操作码，因此机器就能执行操作码所表示的操作。组成操作码字段的位数一般取决于计算机指令系统的规模。较大的指令系统就需要更多的位数来表示每条特定的指令。例如，一个指令系统只有8条指令，则有3位操作码就够了(23=8)。如果有32条指令，那么就需要5位操作码(25=32)。一般来说，一个包含n位的操作码最多能够表示2n条指令。对于一个机器的指令系统，在指令字中操作码字段和地址码字段长度通常是固定的。在单片机中，由于指令字较短，为了充分利用指令字长度，指令字的操作码字段和地址码字段是不固定的，即不同类型的指令有不同的划分，以便尽可能用较短的指令字长来表示越来越多的操作种类，并在越来越大的存储空间中寻址。根据一条指令中有几个操作数地址，可将该指令称为几操作数指令或几地址指令。一般的操作数有被操作数、操作数及操作结果这三种数，因而就形成了三地址指令格式，这是早期计算机指令的基本格式。在三地址指令格式的基础上，后来又发展成二地址格式、一地址格式和零地址格式。各种不同操作数的指令格式如下所示：(1)零地址指令的指令字中只有操作码，而没有地址码。例如，停机指令就不需要地址码，因为停机操作不需要操作数。(2)一地址指令只有一个地址码，它指定一个操作数，另一个操作数地址是隐含的。例如，以运算器中累加寄存器AC中的数据为隐含的被操作数，指令字的地址码字段所指明的数为操作数，操作结果又放回累加寄存器AC中，而累加寄存器中原来的数即被覆盖掉了，其数学含义为AC←(AC)OP(A)式中，OP表示操作性质，如加、减、乘、除等；(AC)表示累加寄存器AC中的数；(A)表示内存中地址为A的存储单元中的数，或者是运算器中地址为A的通用寄存器中的数；←表示把操作(运算)结果传送到指定的地方。注意：地址码字段A指明的是操作数的地址，而不是操作数本身。(3)二地址指令常称为双操作数指令，它有两个地址码字段A1和A2，分别指明参与操作的两个数在内存中或运算器中通用寄存器的地址，其中地址A1兼作存放操作结果的地址。计算机组成原理122其数学含义为A1←(A1)OP(A2)(4)三地址指令字中有三个操作数地址A1，A2和A3，其数学含义为A3←(A1)OP(A2)式中，A1为被操作数地址，也称源操作数地址；A2为操作数地址，也称终点操作数地址；A3为存放操作结果的地址。三地址指令中A1，A2，A3通常指定为运算器中通用寄存器的地址，这是为了加快指令执行速度。在二地址指令格式中，从操作数的物理位置来说，又可归结为三种类型：第一种是访问内存的指令格式，我们称这类指令为存储器存储器(SS)型指令。这种指令操作时都是涉及内存单元，即参与操作的数都放在内存里。从内存某单元中取操作数，操作结果存放至内存另一单元中，因此机器执行这种指令需要多次访问内存。第二种是访问寄存器的指令格式，我们称这类指令为寄存器寄存器(RR)型指令。机器执行这类指令过程中，需要多个通用寄存器或个别专用寄存器，从寄存器中取操作数，把操作结果放到另一寄存器。机器执行寄存器-寄存器型指令的速度很快，因为执行这类指令，不需要访问内存。第三种类型为寄存器-存储器(RS)型指令，执行此类指令时，既要访问内存单元，又要访问寄存器。在CISC计算机中，一个指令系统中指令字的长度和指令中的地址结构并不是单一的，往往采用多种格式混合使用，这样可以增强指令的功能。4.2.3指令字长度一个指令字中包含二进制代码的位数，称为指令字长度。而机器字长是指计算机能直接处理的二进制数据的位数，它决定了计算机的运算精度。机器字长通常与主存单元的位数一致。指令字长度等于机器字长度的指令，称为单字长指令；指令字长度等于半个机器字长度的指令，称为半字长指令；指令字长度等于两个机器字长度的指令，称为双字长指令。例如，IBM370系列，它的指令格式有16位(半字)的，有32位(单字)的，还有48位(一个半字)的。在Pentium系列机中，指令格式也是可变的：有8位、16位、32位、64位不等。早期计算机使用多字长指令的目的，在于提供足够的地址位来解决访问内存任何单元的寻址问题。但是使用多字长指令的缺点是必须两次或三次访问内存以取出一整条指令，这就降低了CPU的运算速度，同时又占用了更多的存储空间。在一个指令系统中，如果各种指令字长度是相等的，称为等长指令字结构，它们可以都是单字长指令或半字长指令。这种指令字结构简单，且指令字长度是不变的。如果各种指令字长度随指令功能而异，如有的指令是单字长指令，有的指令是双字长指令，就称为变长指令字结构。这种指令字结构灵活，能充分利用指令长度，但指令的控制较复杂。随着技术发展，指令字长度逐渐变成多于32位的固定长度。由于硬件只能识别1和0，所以采用二进制操作码是必要的，但是我们用二进制来书写程序却非常麻烦。为了便于书写和阅读程序，每条指令通常用3个或4个英文缩写字母来表示。这种缩写码称为指令助记符，如表4.3所示。这里我们假定指令系统只有7条指令，所以操作码只需3位二进制。于一条存数指令，可以用助记符STO表示操作码110。需要注意的是，在不同的计算机中，指令助记符的规定是不一样的。我们知道，硬件只能识别二进制语言。因此，指令助记符还必须转换成与它们相对应的二进制操作码。这种转换借助汇编器可以自动完成，汇编器的作用相当于一个“翻译”。1.八位微型计算机的指令格式早期的8位微型机字长只有8位。由于指令字较短，所以指令结构是一种可变字长形式。指令格式包含单字长指令、双字长指令、三字长指令等多种。指令格式如下：单字长指令只有操作码，没有操作数地址。双字长或三字长指令包含操作码和地址码。由于内存按字节编址，所以单字长指令每执行一条指令后，指令地址加1。双字长指令或三字长指令每执行一条指令时，必须从内存连续读出2字节或3字节代码，所以，指令地址要加2或加3，可见多字长的指令格式不利于提高机器速度。2.MIPSR4000指令格式MIPSR4000是20世纪80年代后期推出的RISC系统，字长32位，字节寻址。它的指令格式简单，指令数量少，通用寄存器32个。其算术指令格式如下：指令格式中各个字段的含义如下：OP字段——操作码，指定一条指令的基本操作。rs字段——指定第1个源操作数寄存器，最多有32个寄存器。rt字段——指定第2个源操作数寄存器，最多有32个寄存器。rd字段——指定存放操作结果的目的数寄存器，最多有32个寄存器。shamt字段——移位值，用于移位指令。funct字段——函数码，指定R型指令的特定操作。在MIPS中，所有的算术运算，数据必须放在通用寄存器中。此时的指令格式称为R型(寄存器)指令。R型指令格式就是上面所示的算术指令格式。在MIPS中，访问存储器(取数或存数)需要使用数据传送指令。此时的指令格式，称为I型(立即数)指令，其指令格式如下所示：16位字段address(地址)提供取字指令(IW)，存字指令(SW)访问存储器的基值地址码(也称位移量)。保持指令格式基本一致可以降低硬件复杂程度。例如，R型和I型格式的前3个字段长度相等，并且名称也一样；I型格式的第四个字段和R型后三个字段的长度相等。指令格式由第一个字段的值来区分：每种格式的第一个字段(OP)都被分配了一套不同的值，因此计算机硬件可以根据OP来确定指令的后半部分是三个字段(R型)还是一个字段(I型)。表4.4给出了MIPS指令的每一字段的值(十进制)。表中，reg表示0～31中间的一个寄存器号，address表示一个16位地址，而—表示该格式中这个字段没有出现。注意：加法(add)指令和减法(sub)指令的OP字段值相同；硬件根据funct字段来确定操作类型：加法(32)或减法(34)。3.ARM的指令格式ARM是字长32位的嵌入式处理机，2008年生产了4亿片，它具有世界上最流行的指令系统。下面是ARM指令系统的一种指令格式：各字段的含义如下：opcode——指明指令的基本操作，称为操作码。Rd——指明目标寄存器地址(4位)，共16个寄存器。Rn——指明源寄存器地址(4位)，共16个寄存器。operand2——指明第2个源操作数。I——指明立即数，如果I=0，第2个源操作数在寄存器中；如果I=1，第2个源操作数是12位的立即数。S——设置状态，该字段涉及条件转移指令。cond——指明条件，该字段涉及条件转移指令。F——说明指令类型，当需要时该字段允许设置不同的指令。4.Pentium指令格式Pentium机的指令字长度是可变的：从1B到12B，1B表示1字节。指令格式如下所示。这种非固定长度的指令格式是典型的CISC结构特征。之所以如此，一是为了与它的前身80486保持兼容，二是希望能给编译程序写作者以更多灵活的编程支持。指令本身由操作码字段、Mod-R/M字段、SIB字段、位移量字段、立即数字段组成。除操作码字段外，其他四个字段都是可选字段(不选时取0字节)。Mod-R/M字段规定了存储器操作数的寻址方式，给出了寄存器操作数的寄存器地址号。除少数预先规定寻址方式的指令外，绝大多数指令都包含这个字段。SIB字段由比例系数S、变址寄存器号I、基址寄存器号B组成。利用该字段，可和Mod-R/M字段一起，对操作数来源进行完整的说明。显然，Pentium采用RS型指令，指令格式中只有一个存储器操作数。机器指令对数据进行操作，数据通常分以下四类：地址数据地址实际上也是一种形式的数据。多数情况下，对指令中操作数的引用必须完成某种计算，才能确定它们在主存中的有效地址。此时，地址将被看作无符号整数。数值数据计算机中普遍使用的三种类型的数值数据是：①定点整数或定点小数；②浮点数；③压缩十进制数，1字节用2位BCD码表示。字符数据也称为文本数据或字符串，目前广泛使用ASCII码。以这种编码，每个字符被表示成唯一的7位代码，共有128个可表示字符，加上最高位(b7)用作奇偶校验，因此每个字符总是以8位的字节来存储和传送。逻辑数据一个单元由若干二进制位项组成，每个位的值可以是1或0。当数据以这种方式看待时，称为逻辑性数据，它创造了对某个具体位进行布尔逻辑运算的机会。Pentium能处理8位(字节)、16位(字)、32位(双字)、64位(四字)各种长度的数据类型。为求得数据结构最大的灵活性和最有效地使用存储器，单字不需要在偶数地址上对齐，双字也不需要在4倍(字节)整数地址上对齐，四字不需要在8倍(字节)整数地址上对齐。然而当经32位数据总线存取数据时，数据传送是以双字为单位进行的，双字的起始地址是能被4整除的。表4.7列出了Pentium的数据类型。PowerPC是精简指令系统计算机，能处理8位(字节)、16位(半字)、32位(字)和64位(双字)各种长度的数据。处理器能识别如下数据类型：(1)无符号字节用于逻辑和整数算术运算。它由存储器取出装入通用寄存器时，寄存器左端以0填充。(2)无符号半字同无符号字节，只是一个16位的量。(3)有符号半字用于16位算术运算。由存储器取出装入通用寄存器时，要进行符号位扩展，即所有空出位用符号位填充。(4)无符号字用于32位逻辑运算，或作为地址指针。(5)有符号字用于32位算术运算。(6)无符号双字用作64位地址指针。(7)字节串可从0到128字节长。(8)浮点数支持IEEE754中定义的单、双精度浮点数据类型。存储器既可用来存放数据，又可用来存放指令。因此，当某个操作数或某条指令存放在某个存储单元时，其存储单元的编号，就是该操作数或指令在存储器中的地址。在存储器中，操作数或指令字写入或读出的方式，有地址指定方式、相联存储方式和堆栈存取方式。几乎所有的计算机，在内存中都采用地址指定方式。当采用地址指定方式时，形成操作数或指令地址的方式，称为寻址方式。寻址方式分为两类，即指令寻址方式和数据寻址方式，前者比较简单，后者比较复杂。值得注意的是，在冯·诺依曼型结构的计算机中，内存中指令的寻址与数据的寻址是交替进行的。而哈佛型计算机中指令寻址和数据寻址是独立进行的。指令的寻址方式有两种，一种是顺序寻址方式，另一种是跳跃寻址方式。1.顺序寻址方式由于指令地址在内存中按顺序安排，当执行一段程序时，通常是按一条指令接一条指令的顺序进行。就是说，从存储器取出第一条指令，然后执行这条指令；接着从存储器取出第二条指令，再执行第二条指令；接着再取出第三条指令……这种程序顺序执行的过程，我们称为指令的顺序寻址方式。为此，必须使用程序计数器(又称指令指针寄存器)PC来计数指令的顺序号，该顺序号就是指令在内存中的地址。图4.1(a)是指令顺序寻址方式的示意图。2.跳跃寻址方式当程序转移执行的顺序时，指令的寻址就采取跳跃寻址方式。所谓跳跃，是指下条指令的地址码不是由程序计数器给出的，而是由本条指令给出。图4.1(b)画出了指令跳跃寻址方式的示意图。注意，程序跳跃后，按新的指令地址开始顺序执行。因此，指令计数器的内容也必须相应改变，以便及时跟踪新的指令地址。采用指令跳跃寻址方式，可以实现程序转移或构成循环程序，从而能缩短程序长度，或将某些程序作为公共程序引用。指令系统中的各种条件转移或无条件转移指令，就是为了实现指令的跳跃寻址而设置的。在指令执行过程中，操作数的来源一般有三个：①由指令中的地址码部分直接给出操作数，虽然简便快捷，但是操作数是固定不变的；②将操作数存放在CPU内的通用数据寄存器中，这样可以很快获取操作数，但是可以存储的操作数的数量有限；③更一般化的方式是将操作数存放在内存的数据区中。而对于内存寻址，既可以在指令中直接给出操作数的实际访存地址(称为有效地址)，也可以在指令的地址字段给出所谓的形式地址，在指令执行时，将形式地址依据某种方式变换为有效地址再取操作数。形成操作数的有效地址的方法，称为操作数的寻址方式。例如，一种单地址指令的结构如下所示，其中用X、I、A各字段组成该指令的操作数地址。操作码OP变址X间址I形式地址A由于指令中操作数字段的地址码由形式地址和寻址方式特征位等组合形成，因此，一般来说，指令中所给出的地址码，并不是操作数的有效地址。形式地址A，也称偏移量，它是指令字结构中给定的地址量。寻址方式特征位，此处由间址位和变址位组成。如果这条指令无间址和变址的要求，那么形式地址就是操作数的有效地址。如果指令中指明要变址或间址变换，那么形式地址就不是操作数的有效地址，而要经过指定方式的变换，才能形成有效地址。因此，寻址过程就是把操作数的形式地址，变换为操作数的有效地址的过程。由于大型机、微型机和单片机结构不同，从而形成了各种不同的操作数寻址方式。表4.8列出了比较典型而常用的寻址方式，而图4.2画出了它们形成有效地址的示意图。1.隐含寻址这种类型的指令，不是明显地给出操作数的地址，而是在指令中隐含着操作数的地址，如图4.2(a)所示。例如，单地址的指令格式，就不是明显地在地址字段中指出第二操作数的地址，而是规定累加寄存器AC作为第二操作数地址。指令格式明显指出的仅是第一操作数的地址D。因此，累加寄存器AC对单地址指令格式来说是隐含地址。2.立即寻址指令的地址字段指出的不是操作数的地址，而是操作数本身，这种寻址方式称为立即寻址，如图4.2(b)所示。指令中的操作数称为立即数。立即寻址方式的特点是指令中包含的操作数立即可用，节省了访问内存的时间。3.直接寻址直接寻址是一种基本的寻址方法，其特点是：在指令格式的地址字段中直接指出操作数在内存的地址A。由于操作数的地址直接给出而不需要经过某种变换，所以称这种寻址方式为直接寻址方式。图4.2(c)是直接寻址方式的示意图。采用直接寻址方式时，指令字中的形式地址A就是操作数的有效地址EA。因此通常把形式地址A又称为直接地址。此时，由寻址模式给予指示，如X1=0。如果用D表示操作数，那么直接寻址的表达式为D=(A)。4.间接寻址间接寻址是相对于直接寻址而言的，在间接寻址的情况下，指令地址字段中的形式地址A不是操作数D的真正地址，而是操作数地址的指示器。图4.2(d)画出了间接寻址方式的示意图。通常，在间接寻址情况下，由寻址特征位给予指示。如果把直接寻址和间接寻址结合起来，指令有如下形式：操作码IA若寻址特征位I=0，表示直接寻址，这时有效地址EA=A；若I=1，则表示间接寻址，这时有效地址EA=(A)。间接寻址方式是早期计算机中经常采用的方式，但由于两次访存，影响指令执行速度，现在较少使用。5.寄存器寻址当操作数不在内存中，而是放在CPU的通用寄存器中时，可采用寄存器寻址方式，如图4.2(e)所示。显然，此时指令中给出的操作数地址不是内存的地址单元号，而是通用寄存器的编号，EA=R。指令结构中的RR型指令，就是采用寄存器寻址方式的例子。6.寄存器间接寻址寄存器间接寻址与寄存器寻址的区别在于：指令格式中的寄存器内容不是操作数，而是操作数的地址，该地址指明的操作数在内存中，如图4.2(f)所示。此时EA=(R)。7.偏移寻址一种强有力的寻址方式是直接寻址和寄存器间接寻址方式的结合，它有几种形式，我们称它为偏移寻址，如图4.2(g)所示。有效地址计算公式为EA=A+(R)它要求指令中有两个地址字段，至少其中一个是显示的。容纳在一个地址字段中的形式地址A直接被使用；另一个地址字段，或基于操作码的一个隐含引用，指的是某个专用寄存器。此寄存器的内容加上形式地址A就产生有效地址EA。常用的三种偏移寻址是相对寻址、基址寻址、变址寻址。相对寻址隐含引用的专用寄存器是程序计数器(PC)，即EA=A+(PC)，它是当前PC的内容加上指令地址字段中A的值。一般来说，地址字段的值在这种操作下被看成2的补码数的值。因此有效地址是对当前指令地址的一个上下范围的偏移，它基于程序的局部性原理。使用相对寻址可节省指令中的地址位数，也便于程序在内存中成块搬动。基址寻址被引用的专用寄存器含有一个存储器地址，地址字段含有一个相对于该地址的偏移量(通常是无符号整数)。寄存器的引用可以是显式的，也可以是隐式的。基址寻址也利用了存储器访问的局部性原理。后面讲到的段寻址方式中，就采用了段基址寄存器，它提供了一个范围很大的存储空间。变址寻址地址域引用一个主存地址，被引用的专用寄存器含有对那个地址的正偏移量。这意味着主存地址位数大于寄存器中的偏移量位数，与基址寻址刚好相反。但是二者有效地址的计算方法是相同的。变址的用途是为重复操作的完成提供一种高效机制。例如，主存位置A处开始放一个数值列表，打算为表的每个元素加1。我们需要取每个数位，对它加1，然后再存回，故需要的有效地址序列是A,A+1,A+2,…直到最后一个位置。此时值A存入指令地址字段，再用一个变址寄存器(初始化为0)。每次操作之后，变址寄存器内容增1。此时，EA=A+(R)，R←(R+1)。8.段寻址微型机中采用了段寻址方式，例如，它们可以给定一个20位的地址，从而有220=1MB存储空间的直接寻址能力。为此将整个1MB空间存储器按照最大长度64KB划分成若干段。在寻址一个内存具体单元时，由一个基地址再加上某些寄存器提供的16位偏移量来形成实际的20位物理地址。这个基地址就是CPU中的段寄存器。在形成20位物理地址时，段寄存器中的16位数会自动左移4位，然后与16位偏移量相加，即可形成所需的内存地址，如图4.3所示。这种寻址方式的实质还是基址寻址。思考题你能说出段寻址方式的创新点吗？9.堆栈寻址堆栈有寄存器堆栈和存储器堆栈两种形式，它们都以先进后出的原理存储数据，如图4.2(h)所示。不论是寄存器堆栈，还是存储器堆栈，数据的存取都与栈顶地址打交通，为此需要一个隐式或显式的堆栈指示器(寄存器)。数据进栈时使用PUSH指令，将数据压入栈顶地址，堆栈指示器减1；数据退栈时，使用POP指令，数据从栈顶地址弹出，堆栈指示器加1。从而保证了堆栈中数据先进后出的存取顺序。不同的指令系统采用不同的方式指定寻址方式。一般而言，有些指令固定使用某种寻址方式；有些指令则允许使用多种寻址方式，或者在指令中加入寻址方式字段指明，或者对不同的寻址方式分配不同的操作码而把它们看作不同的指令。有些指令系统会把常见的寻址方式组合起来，构成更复杂的复合寻址方式。4.4.3寻址方式举例1.Pentium的寻址方式Pentium的外部地址总线宽度是36位，但它也支持32位物理地址空间。在实地址模式下，逻辑地址形式为段寻址方式：将段名所指定的段寄存器内容(16位)左移4位，低4位补全0，得到20位段基地址，再加上段内偏移，即得20位物理地址。在保护模式下，32位段基地址加上段内偏移得到32位线性地址LA。由存储管理部件将其转换成32位的物理地址，如图4.4所示。这个转换过程对指令系统和程序员是透明的。有6个用户可见的段寄存器，每个保存相应段的起始地址、段长和访问权限。图4.4Pentium寻址方式的计算无论是实地址模式还是保护模式，段基地址的获取方式已是固定的方式。因此这里介绍的寻址方式主要是指有效地址的获取方式，用字母EA表示。表4.9列出了Pentium机的9种寻址方式。下面对32位寻址方式作几点说明。(1)立即寻址：立即数可以是8位、16位、32位的操作数，包含在指令中。(2)寄存器寻址：一般指令或使用8位通用寄存器(AH，AL，BH，BL，CH，CL，DH，DL)，或使用16位通用寄存器(AX，BX，CX，DX，SI，DI，SP，BP)，或使用32位通用寄存器(EAX，EBX，ECX，EDX，ESI，EDI，ESP，EBP)。对64位浮点数操作，要使用一对32位寄存器。有些指令用段寄存器(CS，DS，ES，SS，FS，GS)来实施寄存器寻址方式。以下的寻址方式引用的是存储器位置，通过指定包含此位置的段和离段起点的位移来说明存储器位置。(3)偏移量寻址：也称直接寻址，偏移量就是操作数距段起点的位移。偏移量长度达32位，能用于访问全局。(4)基址寻址：基址寄存器B可以是上述通用寄存器中任何一个。基址寄存器B的内容为有效地址。(5)基址+偏移量寻址：基址寄存器B是32位通用寄存器中任何一个。(6)比例变址+偏移量寻址：也称为变址寻址方式，变址寄存器I是32位通用寄存器中除ESP外的任何一个，而且可将此变址寄存器内容乘以1、2、4或8的比例因子S，然后再加上偏移量而得到有效地址。(7)、(8)两种寻址方式是(4)、(6)两种寻址方式的组合，此时偏移量可有可无。(9)相对寻址：适用于转移控制类指令。用当前指令指针寄存器EIP或IP的内容(下一条指令地址)加上一个有符号的偏移量，形成CS段的段内偏移。2.PowerPC寻址方式不像Pentium和大多数CISC机器，PowerPC是RISC机器，它采用了相当简单的一组寻址方式。如表4.10所示，这些寻址方式按指令类型来分类。不同机器的指令系统是各不相同的。从指令的操作码功能来考虑，一个较完善的指令系统，应当有数据处理、数据存储、数据传送、程序控制四大类指令，具体有数据传送类指令、算术运算类指令、逻辑运算类指令、程序控制类指令、输入输出类指令、字符串类指令、系统控制类指令。1.数据传送指令数据传送指令主要包括取数指令、存数指令、传送指令、成组传送指令、字节交换指令、清寄存器指令、堆栈操作指令等，这类指令主要用来实现主存和寄存器之间，或寄存器和寄存器之间的数据传送。例如，通用寄存器Ri中的数存入主存；通用寄存器Ri中的数送到另一通用寄存器Rj；从主存中取数至通用寄存器Ri；寄存器清零或主存单元清零等。2.算术运算指令这类指令包括二进制定点加、减、乘、除指令，浮点加、减、乘、除指令，求反、求补指令，算术移位指令，算术比较指令，十进制加、减运算指令等。这类指令主要用于定点或浮点的算术运算，大型机中有向量运算指令，直接对整个向量或矩阵进行求和、求积运算。3.逻辑运算指令这类指令包括逻辑加、逻辑乘、按位加、逻辑移位等指令，主要用于无符号数的位操作、代码的转换、判断及运算。移位指令用来对寄存器的内容实现左移、右移或循环移位。左移时，若寄存器的数看作算术数，符号位不动，其他位左移，低位补零，右移时则高位补零，这种移位称算术移位。移位时，若寄存器的数为逻辑数，则左移或右移时，所有位一起移位，这种移位称逻辑移位。4.程序控制指令程序控制指令也称转移指令。计算机在执行程序时，通常情况下按指令计数器的现行地址顺序取指令。但有时会遇到特殊情况：机器执行到某条指令时，出现了几种不同结果，这时机器必须执行一条转移指令，根据不同结果进行转移，从而改变程序原来执行的顺序。这种转移指令称为条件转移指令。转移条件有进位标志(C)、结果为零标志(Z)、结果为负标志(N)、结果溢出标志(V)和结果奇偶标志(P)等。除各种条件转移指令外，还有无条件转移指令、转子程序指令、返回主程序指令、中断返回指令等。转移指令的转移地址一般采用直接寻址和相对寻址方式来确定。若采用直接寻址方式，则称为绝对转移，转移地址由指令地址码部分直接给出。若采用相对寻址方式，则称为相对转移，转移地址为当前指令地址(PC的值)和指令地址部分给出的偏移量之和。5.输入输出指令输入输出指令主要用来启动外围设备，检查测试外围设备的工作状态，并实现外部设备和CPU之间，或外围设备与外围设备之间的信息传送。各种不同机器的输入输出指令差别很大。例如，有的机器指令系统中含有输入输出指令，而有的机器指令系统中没有设置输入输出指令。这是因为后一种情况下外部设备的寄存器和存储器单元统一编址，CPU可以和访问内存一样去访问外部设备。换句话说，可以使用取数、存数指令来代替输入输出指令。6.字符串处理指令字符串处理指令是一种非数值处理指令，一般包括字符串传送、字符串转换(把一种编码的字符串转换成另一种编码的字符串)、字符串比较、字符串查找(查找字符串中某一子串)、字符串抽取(提取某一子串)、字符串替换(把某一字符串用另一字符串替换)等。这类第4章指令系统137指令在文字编辑中对大量字符串进行处理。7.特权指令特权指令是指具有特殊权限的指令。由于指令的权限最大，若使用不当，会破坏系统和其他用户信息。因此这类指令只用于操作系统或其他系统软件，一般不直接提供给用户使用。在多用户、多任务的计算机系统中特权指令必不可少。它主要用于系统资源的分配和管理，包括改变系统工作方式，检测用户的访问权限，修改虚拟存储器管理的段表、页表，完成任务的创建和切换等。8.其他指令除以上各类指令外，还有状态寄存器置位、复位指令、测试指令、暂停指令、空操作指令，以及其他一些系统控制用的特殊指令。CISC的指令系统一般多达二三百条，如VAX11/780计算机有303条指令，18种寻址方式。Pentium机也有191条指令，9种寻址方式。但是对CISC进行的测试表明，最常使用的是一些最简单最基本的指令，仅占指令总数的20%，但在程序中出现的频率却占80%。因此从教学目的考虑，下面给出一个基本指令系统的操作，如表4.12所示。从应用角度考虑，这些指令的功能也具有普遍意义，几乎所有计算机的指令系统中都能找到这些指令。RISC指令系统的最大特点是：①选取使用频率最高的一些简单指令，指令条数少；②指令长度固定，指令格式种类少，寻址方式种类少；③只有取数/存数指令访问存储器，其余指令的操作都在寄存器之间进行。表4.13列出了典型RISC指令系统的基本特征。表4.14比较了RISC和CICS的性能。设高级语言程序经编译后在机器上运行的机器指令数为I，每条机器指令执行时所需要的平均机器周期数是C，每个机器周期的执行时间为T。表中I、T为比值，C为实际周期数。由计算机执行程序的时间P的计算公式可以看出两种类型的机器的性能差异：P=I×C×T下面以PowerPC机为例来说明，该机是一个32位字长的计算机，共有64条指令。图4.5示出了它的指令类型与格式。PowerPC机有如下五种指令类型：(1)整数算术、逻辑、移位/旋转(循环移位)指令；(2)浮点算术指令；(3)取数/存数指令；(4)条件寄存器指令；(5)转移指令。计算机组成原理140所有的指令都是32位长，并有规整的格式。指令的前6位(网点表示)指定操作码部分。在某些情况下在其他部分有此操作码的扩展，用于指定操作的细节(也用网点表示)。所有的取数/存数、算术、逻辑指令，在操作码之后是两个5位的寄存器字段，这表示可以使用32个通用寄存器。转移指令包括了一个链接(L)位，它指示此转移指令之后的那条指令的有效地址是否放入链接寄存器。两种转移指令格式还包含一个(A)位，它指示寻址方式是绝对寻址还是PC相对寻址。对于条件转移指令，CR位字段指定条件寄存器中被测试的位，选项字段指向转移发生的条件(如无条件转移；计数=0转移；计数≠0转移；条件是真转移；条件是假转移；等等)。进行计算的大多数指令(算术、逻辑、浮点算术)都包含一个(R)位，它指示运算结果是否应记录在条件寄存器中。这个特征对于转移预测处理是很有用的。浮点指令有三个源寄存器字段。多数情况下只使用两个源寄存器，少数指令涉及两个源寄存器内容相乘，然后再加上或减去第三个源寄存器内容。这种复合指令经常用在矩阵运算中，使得一部分内部积用“乘—加”来实现。思考题你能说出PowerPC机指令系统的特点吗？汇编语言是计算机机器语言(二进制指令代码)进行符号化的一种表示方式，每一个基本汇编语句对应一条机器指令。为了有一个完整概念，表4.15列出了嵌入式处理机ARM的汇编语言。其中操作数使用16个寄存器(r0，r1～r12，SP，Ir，PC)，230个存储字(字节编址，连续的字的地址之间相差4)。在进行汇编语言程序设计时，可直接使用英文单词或其缩写表示指令，使用标识符表示数据或地址，从而有效地避免了记忆二进制的指令代码，不再由程序设计人员为指令和数据分配内存地址，直接调用操作系统的某些程序段完成输入输出及读写文件等操作功能。用编辑程序建立好的汇编语言源程序，需要经过系统软件中的“汇编器”翻译为机器语言程序之后，才能交付给计算机硬件系统去执行。本章小结一台计算机中所有机器指令的集合，称为这台计算机的指令系统。指令系统是表征一台计算机性能的重要因素，它的格式与功能不仅直接影响到机器的硬件结构，而且影响到系统软件。指令格式是指令字用二进制代码表示的结构形式，通常由操作码字段和地址码字段组成。操作码字段表征指令的操作特性与功能，而地址码字段指示操作数的地址。目前多采用二地址、单地址、零地址混合方式的指令格式。指令字长度分为：单字长、半字长、双字长三种形式。高档微机采用32位长度的单字长形式。形成指令地址的方式，称为指令寻址方式。有顺序寻址和跳跃寻址两种，由指令计数器来跟踪。形成操作数地址的方式，称为数据寻址方式。操作数可放在专用寄存器、通用寄存器、内存和指令中。数据寻址方式有隐含寻址、立即寻址、直接寻址、间接寻址、寄存器寻址、寄存器间接寻址、相对寻址、基值寻址、变址寻址、块寻址、段寻址等多种。按操作数的物理位置不同，有RR型和RS型。前者比后者执行的速度快。堆栈是一种特殊的数据寻址方式，采用“先进后出”原理。按结构不同，分为寄存器堆栈和存储器堆栈。不同机器有不同的指令系统。一个较完善的指令系统应当包含数据传送类指令、算术运算类指令、逻辑运算类指令、程序控制类指令、I/O类指令、字符串类指令、系统控制类指令。RISC指令系统是目前计算机发展的主流，也是CISC指令系统的改进，它的最大特点是：①指令条数少；②指令长度固定，指令格式和寻址方式种类少；③只有取数/存数指令访问存储器，其余指令的操作均在寄存器之间进行。汇编语言与具体机器的依赖性很强。为了了解该语言的特点，列出了目前较流行的嵌入式处理机ARM的汇编语言，以举一反三。当用计算机解决某个问题时，我们首先必须为它编写程序。程序是一个指令序列，这个序列明确告诉计算机应该执行什么操作，在什么地方找到用来操作的数据。一旦把程序装入内存储器，就可以由计算机部件来自动完成取指令和执行指令的任务。专门用来完成此项工作的计算机部件称为中央处理器，通常简称CPU。CPU对整个计算机系统的运行是极其重要的，它具有如下四方面的基本功能。指令控制程序的顺序控制，称为指令控制。由于程序是一个指令序列，这些指令的相互顺序不能任意颠倒，必须严格按程序规定的顺序进行，因此，保证机器按顺序执行程序是CPU的首要任务。操作控制一条指令的功能往往是由若干个操作信号的组合来实现的，因此，CPU管理并产生由内存取出的每条指令的操作信号，把各种操作信号送往相应的部件，从而控制这些部件按指令的要求进行动作。时间控制对各种操作实施时间上的定时，称为时间控制。因为在计算机中，各种指令的操作信号均受到时间的严格定时。另外，一条指令的整个执行过程也受到时间的严格定时。只有这样，计算机才能有条不紊地自动工作。数据加工所谓数据加工，就是对数据进行算术运算和逻辑运算处理。完成数据的加工处理，是CPU的根本任务。因为，原始信息只有经过加工处理后才能对人们有用。运算器和控制器是组成CPU的两大核心部件。随着VLSI技术的发展，CPU芯片外部的一些逻辑功能部件，如浮点运算器、cache、总线仲裁器等往往集成到CPU芯片内部。从教学目的出发，本章以CPU执行指令为主线来组织教学内容。为便于读者建立计算机的整机概念，突出主要矛盾，给出图5.1所示的CPU模型。控制器由程序计数器、指令寄存器、指令译码器、时序产生器和操作控制器组成，它是发布命令的“决策机构”，即完成协调和指挥整个计算机系统的操作。控制器的主要功能有：(1)从指令cache中取出一条指令，并指出下一条指令在指令cache中的位置。(2)对指令进行译码或测试，并产生相应的操作控制信号，以便启动规定的动作。比如，一次数据cache的读/写操作，一个算术逻辑运算操作，或一个输入/输出操作。(3)指挥并控制CPU、数据cache和输入/输出设备之间数据流动的方向。运算器由算术逻辑运算单元(ALU)、通用寄存器、数据缓冲寄存器(DR)和程序状态字寄存器(状态条件寄存器，PSWR)组成，它是数据加工处理部件。相对控制器而言，运算器接受控制器的命令而进行动作，即运算器所进行的全部操作都是由控制器发出的控制信号来指挥的，所以它是执行部件。运算器有两个主要功能：(1)执行所有的算术运算。(2)执行所有的逻辑运算，并进行逻辑测试，如零值测试或两个值的比较。通常，一个算术操作产生一个运算结果，而一个逻辑操作则产生一个判决。鉴于第2、3章中已经详细讨论了运算器和存储器，所以本章重点放在控制器上。各种计算机的CPU可能有这样或那样的不同，但是在CPU中至少要有六类寄存器，如图5.1所示。这些寄存器是：数据缓冲寄存器(DR)，指令寄存器(IR)，程序计数器(PC)，数据地址寄存器(AR)，通用寄存器(R0～R3)，程序状态字寄存器(PSWR)。上述这些寄存器用来暂存一个计算机字。根据需要，可以扩充其数目。下面详细介绍这些寄存器的功能与结构。(1)数据缓冲寄存器(DR)数据缓冲寄存器用来暂时存放ALU的运算结果，或由数据存储器读出的一个数据字，或来自外部接口的一个数据字。缓冲寄存器的作用是：①作为ALU运算结果和通用寄存器之间信息传送中时间上的缓冲；②补偿CPU和内存、外围设备之间在操作速度上的差别。(2)指令寄存器(IR)指令寄存器用来保存当前正在执行的一条指令。当执行一条指令时，先把它从指令存储器(简称指存)读出，然后再传送至指令寄存器。指令划分为操作码和地址码字段，由二进制数字组成。为了执行任何给定的指令，必须对操作码进行测试，以便识别所要求的操作。一个叫做指令译码器的部件就是做这项工作的。指令寄存器中操作码字段OP的输出就是指令译码器的输入。操作码一经译码后，即可向操作控制器发出具体操作的特定信号。(3)程序计数器(PC)为了保证程序能够连续地执行下去，CPU必须具有某些手段来确定下一条指令的地址。而程序计数器(PC)正是起到这种作用，所以它又称为指令计数器。在程序开始执行前，必须将它的起始地址，即程序的第一条指令所在的指存单元地址送入PC，因此PC的内容即是从指存提取的第一条指令的地址。当执行指令时，CPU将自动修改PC的内容，以便使其保持的总是将要执行的下一条指令的地址。由于大多数指令都是按顺序来执行的，所以修改的过程通常只是简单的对PC加1。但是，当遇到转移指令如JMP指令时，那么后继指令的地址(即PC的内容)必须从指令寄存器中的地址字段取得。在这种情况下，下一条从指存取出的指令将由转移指令来规定，而不是像通常一样按顺序来取得。因此程序计数器的结构应当是具有寄存器和计数两种功能的结构。(4)数据地址寄存器(AR)数据地址寄存器用来保存当前CPU所访问的数据存储器(简称数存)单元的地址。由于要对存储器阵列进行地址译码，所以必须使用地址寄存器来保持地址信息，直到一次读/写操作完成。地址寄存器的结构和数据缓冲寄存器、指令寄存器一样，通常使用单纯的寄存器结构。信息的存入一般采用电位-脉冲方式，即电位输入端对应数据信息位，脉冲输入端对应控制信号，在控制信号作用下，瞬时将信息打入寄存器。(5)通用寄存器在我们的模型中，通用寄存器有4个(R0～R3)，其功能是：当算术逻辑单元(ALU)执行算术或逻辑运算时，为ALU提供一个工作区。例如，在执行一次加法运算时，选择两个操作数(分别放在两个寄存器)相加，所得的结果送回其中一个寄存器(如R2)中，而R2中原有的内容随即被替换。目前CPU中的通用寄存器，可多达64个，甚至更多。其中任何一个可存放源操作数，也可存放结果操作数。在这种情况下，需要在指令格式中对寄存器号加以编址。从硬件结构来讲，需要使用通用寄存器堆结构，以便选择输入信息源。通用寄存器还用作地址指示器、变址寄存器、堆栈指示器等。(6)程序状态字寄存器(PSWR)程序状态字寄存器又称为状态条件寄存器，保存由算术运算指令和逻辑运算指令运算或测试结果建立的各种条件代码，如运算结果进位标志(C)，运算结果溢出标志(V)，运算结果为零标志(Z)，运算结果为负标志(N)，等等。这些标志位通常分别由1位触发器保存。除此之外，状态条件寄存器还保存中断和系统工作状态等信息，以便使CPU和系统能及时了解机器运行状态和程序运行状态。因此，状态条件寄存器是一个由各种状态条件标志拼凑而成的寄存器。从上面叙述可知，CPU中的6类主要寄存器，每一类完成一种特定的功能。然而信息怎样才能在各寄存器之间传送呢?也就是说，数据的流动是由什么部件控制的呢?通常把许多寄存器之间传送信息的通路，称为数据通路。信息从什么地方开始，中间经过哪个寄存器或三态门，最后传送到哪个寄存器，都要加以控制。在各寄存器之间建立数据通路的任务，是由称为操作控制器的部件来完成的。操作控制器的功能，就是根据指令操作码和时序信号，产生各种操作控制信号，以便正确地选择数据通路，把有关数据打入到一个寄存器，从而完成取指令和执行指令的控制。根据设计方法不同，操作控制器可分为时序逻辑型和存储逻辑型两种。第一种称为硬布线控制器，它是采用时序逻辑技术来实现的；第二种称为微程序控制器，它是采用存储逻辑来实现的。本书重点介绍微程序控制器。操作控制器产生的控制信号必须定时，为此必须有时序产生器。因为计算机高速地进行工作，每一个动作的时间是非常严格的，不能太早也不能太迟。时序产生器的作用，就是对各种操作信号实施时间上的控制。CPU中除了上述组成部分外，还有中断系统、总线接口等其他功能部件，这些内容将在以后各章中陆续展开。我们知道，指令和数据从形式上看都是二进制代码，所以人们很难区分出这些代码是指令还是数据。然而CPU却能识别这些二进制代码：它能准确地判别出哪些是指令字，哪些是数据字，并将它们送往相应的部件。本节我们将讨论在一些典型的指令周期中，CPU的各部分是怎样工作的，从而能加深对这一问题的理解和体验。计算机之所以能自动地工作，是因为CPU能从存放程序的内存里取出一条指令并执行这条指令；紧接着又是取指令，执行指令……如此周而复始，构成了一个封闭的循环。除非遇到停机指令，否则这个循环将一直继续下去，其过程如图5.2所示。CPU每取出一条指令并执行这条指令，都要完成一系列的操作，这一系列操作所需的时间通常叫做一个指令周期。换言之，指令周期是取出图5.2取指令-执行指令序列一条指令并执行这条指令的时间。由于各种指令的操作功能不同，因此各种指令的指令周期是不尽相同的。指令周期常常用若干个CPU周期数来表示，CPU周期又称为机器周期。CPU访问一次内存所花的时间较长，因此通常用内存中读取一个指令字的最短时间来规定CPU周期。这就是说，一条指令的取出阶段(通常称为取指)需要一个CPU周期时间。而一个CPU周期时间又包含有若干个时钟周期(又称T周期或节拍脉冲，它是处理操作的最基本单位)。这些Ti周期的总和规定了一个CPU周期的时间宽度。图5.3示出了采用定长CPU周期的指令周期示意图。从这个例子知道，取出和执行任何一条指令所需的最短时间为两个CPU周期。需要说明的是，不同的计算机系统中定义的术语未必相同。例如，在不采用三级时序的系统中，机器周期就相当于时钟周期。单周期CPU和多周期CPU单周期CPU在一个时钟周期内完成从指令取出到得到结果的所有工作，指令系统中所有指令执行时间都以最长时间的指令为准，因而效率低，当前较少采用。多周期CPU把指令的执行分成多个阶段，每个阶段在一个时钟周期内完成，因而时钟周期短，不同指令所用周期数可以不同。以下仅讨论多周期CPU。表5.1列出了由6条指令组成的一个简单程序。这6条指令是有意安排的，因为它们是非常典型的，既有RR型指令，又有RS型指令；既有算术逻辑指令，又有访存指令，还有程序转移指令。我们将在下面通过CPU取出一条指令并执行这条指令的分解动作，来具体认识每条指令的指令周期。MOV是一条RR型指令，其指令周期如图5.4所示。它需要两个CPU周期，其中取指周期需要一个CPU周期，执行周期需要一个CPU周期。取指周期中CPU完成三件事：①从指存取出指令；②对程序计数器PC加1，以便为取下一条指令做好准备；③对指令操作码进行译码或测试，以便确定进行什么操作。执行周期中CPU根据对指令操作码的译码或测试，进行指令所要求的操作。对MOV指令来说，执行周期中完成到两个通用寄存器R0、R1之间的数据传送操作。由于时间充足，执行周期一般只需要一个CPU周期。1.取指周期第一条指令的取指周期示于图5.5。假定表5.1的程序已装入指存中，因而在此阶段内，CPU的动作如下：(1)程序计数器PC中装入第一条指令地址101(八进制)；(2)PC的内容被放到指令地址总线ABUS(I)上，对指存进行译码，并启动读命令；(3)从101号地址读出的MOV指令通过指令总线IBUS装入指令寄存器IR；(4)程序计数器内容加1，变成102，为取下一条指令做好准备；(5)指令寄存器中的操作码(OP)被译码；(6)CPU识别出是MOV指令。至此，取指周期结束。2.执行指令阶段(执行周期)MOV指令的执行周期示于图5.6中，在此阶段，CPU的动作如下：(1)操作控制器(OC)送出控制信号到通用寄存器，选择R1(10)作源寄存器，选择R0作目标寄存器；(2)OC送出控制信号到ALU，指定ALU做传送操作；(3)OC送出控制信号，打开ALU输出三态门，将ALU输出送到数据总线DBUS上。注意，任何时候DBUS上只能有一个数据；(4)OC送出控制信号，将DBUS上的数据打入到数据缓冲寄存器DR(10)；(5)OC送出控制信号，将DR中的数据10打入到目标寄存器R0，R0的内容由00变为10。至此，MOV指令执行结束。5.2.3LAD指令的指令周期LAD指令是RS型指令，它先从指令存储器取出指令，然后从数据存储器6号单元取出数据100装入通用寄存器R1，原来R1中存放的数据10被更换成100。由于一次访问指存，一次访问数存，LAD指令的指令周期需要3个CPU周期，如图5.7所示。1.LAD指令的取指周期在LAD指令的取指周期中，CPU的动作完全与MOV指令取指周期中一样(图5.5)，只是PC提供的指令地址为102，按此地址从指令存储器读出“LDAR1,6”指令放入IR中，然后将PC+1，使PC内容变成103，为取下条ADD指令做好准备。以下ADD、STO、JMP三条指令的取指周期中，CPU的动作完全与MOV指令一样，不再细述。2.LAD指令的执行周期LAD指令的执行周期如图5.8所示。CPU执行的动作如下：(1)操作控制器OC发出控制命令打开IR输出三态门，将指令中的直接地址码6放到数据总线DBUS上；(2)OC发出操作命令，将地址码6装入数存地址寄存器AR；(3)OC发出读命令，将数存6号单元中的数100读出到DBUS上；(4)OC发出命令，将DBUS上的数据100装入缓冲寄存器DR；(5)OC发出命令，将DR中的数100装入通用寄存器R1，原来R1中的数10被冲掉。至此，LAD指令执行周期结束。注意，数据总线DBUS上分时进行了地址传送和数据传送，所以需要2个CPU周期。ADD指令是RR型指令，在运算器中用两个寄存器R1和R2的数据进行加法运算。指令周期只需两个CPU周期，其中一个是取指周期，与图5.5相同。下面只讲执行周期，CPU完成的动作如图5.9所示。(1)操作控制器OC送出控制命令到通用寄存器，选择R1做源寄存器，R2做目标寄存器；(2)OC送出控制命令到ALU，指定ALU做R1(100)和R2(20)的加法操作；(3)OC送出控制命令，打开ALU输出三态门，运算结果120放到DBUS上；(4)OC送出控制命令，将DBUS上数据打入缓冲寄存器DR；ALU产生的进位信号保存在状态字寄存器PSWR中；(5)OC送出控制命令，将DR(120)装入R2，R2中原来的内容20被冲掉。至此，ADD指令执行周期结束。STO指令是RS型指令，它先访问指存取出STO指令，然后按(R3)=30地址访问数存，将(R2)=120写入到30号单元。由于一次访问指存，一次访问数存，因此指令周期需3个CPU周期，其中执行周期为2个CPU周期，如图5.10所示。下面也只讲执行周期，CPU完成的动作如图5.11所示。(1)操作控制器OC送出操作命令到通用寄存器，选择(R3)=30做数据存储器的地址单元；(2)OC发出操作命令，打开通用寄存器输出三态门(不经ALU以节省时间)，将地址30放到DBUS上；(3)OC发出操作命令，将地址30打入AR，并进行数存地址译码；(4)OC发出操作命令到通用寄存器，选择(R2)=120，作为数存的写入数据；(5)OC发出操作命令，打开通用寄存器输出三态门，将数据120放到DBUS上；(6)OC发出操作命令，将数据120写入数存30号单元，它原先的数据40被冲掉。至此，STO指令执行周期结束。注意，DBUS是单总线结构，先送地址(30)，后送数据(120)，必须分时传送。JMP指令是一条无条件转移指令，用来改变程序的执行顺序。指令周期为两个CPU周期，其中取指周期为1个CPU周期，执行周期为1个CPU周期(图5.12)。下面也只讲执行周期，CPU完成的动作如图5.13所示。(1)OC发生操作控制命令，打开指令寄存器IR的输出三态门，将IR中的地址码101发送到DBUS上；(2)OC发出操作控制命令，将DBUS上的地址码101打入到程序计数器PC中，PC中的原先内容106被更换。于是下一条指令不是从106号单元取出，而是转移到101号单元取出。至此，JMP指令执行周期结束。应当指出，执行“JMP101”指令时，我们此处所给的五条指令组成的程序进入了死循环，除非人为停机，否则这个程序将无休止地运行下去。当然，我们此处所举的转移地址101是随意的，仅仅用来说明转移指令能够改变程序的执行顺序而已。CPU取指令与执行指令的动态过程，请见CAI动画视频演示。在上面介绍了五条典型指令的指令周期，从而使我们对一条指令的取指过程和执行过程有了一个较深刻的印象。然而我们是通过画示意图或数据通路图来解释这些过程的。这样做的目的主要是为了教学。但是在进行计算机设计时，如果用这种办法来表示指令周期，那就显得过于烦琐，而且也没有必要。在进行计算机设计时，可以采用方框图语言来表示指令的指令周期。一个方框代表一个CPU周期，方框中的内容表示数据通路的操作或某种控制操作。除了方框，还需要一个菱形符号，它通常用来表示某种判别或测试，不过时间上它依附于紧接它的前面一个方框的CPU周期，而不单独占用一个CPU周期。我们把前面的五条典型指令加以归纳，用方框图语言表示的指令周期示于图5.15。可以明显地看到，所有指令的取指周期是完全相同的，而且是一个CPU周期。但是指令的执行周期，由于各条指令的功能不同，所用的CPU周期是各不相同的，其中MOV、ADD、JMP指令是一个CPU周期；LAD和STO指令是两个CPU周期。框图中DBUS代表数据总线，ABUS(D)代表数存地址总线，ABUS(I)代表指存地址总线，RD(D)代表数存读命令，WE(D)代表数存写命令，RD(I)代表指存读命令。图5.15中，还有一个“～”符号，我们称它为公操作符号。这个符号表示一条指令已经执行完毕，转入公操作。所谓公操作，就是一条指令执行完毕后，CPU所开始进行的一些操作，这些操作主要是CPU对外围设备请求的处理，如中断处理、通道处理等。如果外围设备没有向CPU请求交换数据，那么CPU又转向指存取下一条指令。由于所有指令的取指周期是完全一样的，因此，取指令也可认为是公操作。这是因为，一条指令执行结束后，如果没有外设请求，CPU一定转入“取指令”操作。在日常生活中，人们学习、工作和休息都有一个严格的作息时间。比如，早晨6:00起床；8:00～12:00上课，12:00～14:00午休，……每个教师和学生都必须严格遵守这一规定，在规定的时间里上课，在规定的时间里休息，不得各行其是，否则就难以保证正常的教学秩序。CPU中也有一个类似“作息时间”的东西，它称为时序信号。计算机所以能够准确、迅速、有条不紊地工作，正是因为在CPU中有一个时序信号产生器。机器一旦被启动，即CPU开始取指令并执行指令时，操作控制器就利用定时脉冲的顺序和不同的脉冲间隔，有条理、有节奏地指挥机器的动作，规定在这个脉冲到来时做什么，在那个脉冲到来时又做什么，给计算机各部分提供工作所需的时间标志。为此，需要采用多级时序体制。再来考虑5.2节中提出的一个问题：用二进制码表示的指令和数据都放在内存里，那么CPU是怎样识别出它们是数据还是指令呢?事实上，通过5.2节讲述指令周期后，就自然会得出如下结论：从时间上来说，取指令事件发生在指令周期的第一个CPU周期中，即发生在“取指令”阶段，而取数据事件发生在“执行指令”阶段。从空间上来说，如果取出的代码是指令，那么一定送往指令寄存器，如果取出的代码是数据，那么一定送往运算器。由此可见，时间控制对计算机来说太重要了。不仅如此，在一个CPU周期中，又把时间分为若干个小段，以便规定在这一小段时间中CPU干什么，在那一小段时间中CPU又干什么，这种时间约束对CPU来说是非常必要的，否则就可能造成丢失信息或导致错误的结果。因为时间的约束是如此严格，以至于时间进度既不能来得太早，也不能来得太晚。总之，计算机的协调动作需要时间标志，而时间标志则是用时序信号来体现的。一般来说，操作控制器发出的各种控制信号都是时间因素(时序信号)和空间因素(部件位置)的函数。如果忽略了时间因素，那么我们学习计算机硬件时往往就会感到困难，这一点务请读者加以注意。组成计算机硬件的器件特性决定了时序信号最基本的体制是电位-脉冲制。这种体制最明显的一个例子，就是当实现寄存器之间的数据传送时，数据加在触发器的电位输入端，而打入数据的控制信号加在触发器的时钟输入端。电位的高低，表示数据是1还是0，而且要求打入数据的控制信号到来之前，电位信号必须已稳定。这是因为，只有电位信号先建立，打入到寄存器中的数据才是可靠的。当然，计算机中有些部件，如算术逻辑运算单元ALU只用电位信号工作就可以了。但尽管如此，运算结果还是要送入通用寄存器，所以最终还是需要脉冲信号来配合。硬布线控制器中，时序信号往往采用主状态周期-节拍电位-节拍脉冲三级体制。一个节拍电位表示一个CPU周期的时间，它表示了一个较大的时间单位；在一个节拍电位中又包含若干个节拍脉冲，以表示较小的时间单位；而主状态周期可包含若干个节拍电位，所以它是最大的时间单位。主状态周期可以用一个触发器的状态持续时间来表示。在微程序控制器中，时序信号比较简单，一般采用节拍电位-节拍脉冲二级体制。就是说，它只有一个节拍电位，在节拍电位中又包含若干个节拍脉冲(T周期)。节拍电位表示一个CPU周期的时间，而节拍脉冲把一个CPU周期划分成几个较小的时间间隔。根据需要，这些时间间隔可以相等，也可以不相等。前面已分析了指令周期中需要的一些典型时序。时序信号产生器的功能是用逻辑电路来实现这些时序。各种计算机的时序信号产生电路是不尽相同的。一般来说，大型计算机的时序电路比较复杂，而微型机的时序电路比较简单，这是因为前者涉及的操作动作较多，后者涉及的操作动作较少。另一方面，从设计操作控制器的方法来讲，硬布线控制器的时序电路比较复杂，而微程序控制器的时序电路比较简单。然而不管是哪一类，时序信号产生器最基本的构成是一样的。图5.18示出了微程序控制器中使用的时序信号产生器的结构图，它由时钟源、环形脉冲发生器、节拍脉冲和读写时序译码、启停控制逻辑等部分组成。(1)时钟源时钟源用来为环形脉冲发生器提供频率稳定且电平匹配的方波时钟脉冲信号。它通常由石英晶体振荡器和与非门组成的正反馈振荡电路组成，其输出送至环形脉冲发生器。(2)环形脉冲发生器环形脉冲发生器的作用是产生一组有序的间隔相等或不等的脉冲序列，以便通过译码电路来产生最后所需的节拍脉冲，其电路参见动画视频。(3)节拍脉冲和存储器读/写时序我们假定在一个CPU周期中产生四个等间隔的节拍脉冲1T～4T，每个节拍脉冲的脉冲宽度均为200ns，因此一个CPU周期便是800ns，在下一个CPU周期中，它们又按固定的时间关系重复。不过注意，图5.19中画出的节拍脉冲信号是T1～T4，它们在逻辑关系上与1T～4T是完全一致的，是后者经过启停控制逻辑中与门以后的输出，图中忽略了一级与门的时间延迟细节。存储器读/写时序信号RD°、WE°用来进行存储器的读/写操作。在硬布线控制器中，节拍电位信号是由时序产生器本身通过逻辑电路产生的，一个节拍电位持续时间正好包容若干个节拍脉冲。然而在微程序设计的计算机中，节拍电位信号可由微程序控制器提供。一个节拍电位持续时间，通常也是一个CPU周期时间。例如，图5.20中的RD°，WE°信号持续时间均为800ns，而一个CPU周期也正好是800ns。关于微程序控制器如何产生节拍电位信号，将留在5.4节介绍。(4)启停控制逻辑机器一旦接通电源，就会自动产生原始的节拍脉冲信号1T～4T，然而，只有在启动机器运行的情况下，才允许时序产生器发出CPU工作所需的节拍脉冲T1～T4。为此需要由启停控制逻辑来控制1T～4T的发送。同样，对读/写时序信号也需要由启停逻辑加以控制。图5.20给出作者发明的启停控制逻辑，它是一个实用有效的工具性电路。启停控制逻辑的核心是一个运行标志触发器Cr。当运行触发器为“1”时，原始节拍脉冲1T～4T和读/写时序信号RD°，WE°通过门电路发送出去，变成CPU真正需要的节拍脉冲信号T1～T4和读/写时序RD，WE。反之，当运行触发器“0”时，就关闭时序产生器。由于启动计算机是随机的，停机也是随机的，为此必须要求：当计算机启动时，一定要从第1个节拍脉冲前沿开始工作，而在停机时一定要在第4个节拍脉冲结束后关闭时序产生器。只有这样，才能使发送出去的脉冲都是完整的脉冲。图5.20中，在Cr(D触发器)下面加上一个SR触发器，且用4T信号作Cr触发器的时钟控制端，那么就可以保证在T1的前沿开启时序产生器，而在T4的后沿关闭时序产生器。从5.2节知道，机器指令的指令周期是由数目不等的CPU周期数组成，CPU周期数的多少反映了指令动作的复杂程度，即操作控制信号的多少。对一个CPU周期而言，也有操作控制信号的多少与出现的先后问题。这两种情况综合在一起，说明每条指令和每个操作控制信号所需的时间各不相同。控制不同操作序列时序信号的方法，称为控制器的控制方式。常用的有同步控制、异步控制、联合控制三种方式，其实质反映了时序信号的定时方式。1.同步控制方式在任何情况下，已定的指令在执行时所需的机器周期数和时钟周期数都是固定不变的，称为同步控制方式。根据不同情况，同步控制方式可选取如下方案。(1)采用完全统一的机器周期执行各种不同的指令。这意味着所有指令周期具有相同的节拍电位数和相同的节拍脉冲数。显然，对简单指令和简单的操作来说，将造成时间浪费。(2)采用不定长机器周期。将大多数操作安排在一个较短的机器周期内完成，对某些时间紧张的操作，则采取延长机器周期的办法来解决。(3)中央控制与局部控制结合。将大部分指令安排在固定的机器周期完成，称为中央控制，对少数复杂指令(乘、除、浮点运算)采用另外的时序进行定时，称为局部控制。2.异步控制方式异步控制方式的特点是：每条指令、每个操作控制信号需要多少时间就占用多少时间。这意味着每条指令的指令周期可由多少不等的机器周期数组成；也可以是当控制器发出某一操作控制信号后，等待执行部件完成操作后发回“回答”信号，再开始新的操作。显然，用这种方式形成的操作控制序列没有固定的CPU周期数(节拍电位)或严格的时钟周期(节拍脉冲)与之同步。3.联合控制方式此为同步控制和异步控制相结合的方式。一种情况是，大部分操作序列安排在固定的机器周期中，对某些时间难以确定的操作则以执行部件的“回答”信号作为本次操作的结束标志。例如，CPU访问主存时，依靠其送来的“READY”信号作为读/写周期的结束标志(半同步方式)。另一种情况是，机器周期的节拍脉冲数固定，但是各条指令周期的机器周期数不固定。例如，5.4节所讲的微程序控制就是这样。微程序控制器同硬布线控制器相比较，具有规整性、灵活性、可维护性等一系列优点，因而在计算机设计中逐渐取代了早期采用的硬布线控制器，并已广泛地应用。在计算机系统中，微程序设计技术是利用软件方法来设计硬件的一门技术。微程序控制的基本思想，就是仿照通常的解题程序的方法，把操作控制信号编成所谓的“微指令”，存放到一个只读存储器里。当机器运行时，一条又一条地读出这些微指令，从而产生全机所需要的各种操作控制信号，使相应部件执行所规定的操作。1.微命令和微操作一台数字计算机基本上可以划分为两大部分——控制部件和执行部件。控制器就是控制部件，而运算器、存储器、外围设备相对控制器来讲，就是执行部件。那么两者之间是怎样进行联系的呢?控制部件与执行部件的一种联系，就是通过控制线。控制部件通过控制线向执行部件发出各种控制命令，通常把这种控制命令称为微命令，而执行部件接受微命令后所进行的操作，称为微操作。控制部件与执行部件之间的另一种联系是反馈信息。执行部件通过反馈线向控制部件反映操作情况，以便使控制部件根据执行部件的“状态”来下达新的微命令，这也称为“状态测试”。微操作在执行部件中是最基本的操作。由于数据通路的结构关系，微操作可分为相容性和相斥性两种。所谓相容性的微操作，是指在同时或同一个CPU周期内可以并行执行的微操作。所谓相斥性的微操作，是指不能在同时或不能在同一个CPU周期内并行执行的微操作。图5.21示出了一个简单运算器模型，其中ALU为算术逻辑单元，R1、R2、R3为三个寄存器。三个寄存器的内容都可以通过多路开关从ALU的X输入端或Y输入端送至ALU，而ALU的输出可以送往任何一个寄存器或同时送往R1，R2，R3三个寄存器。在我们给定的数据通路中，多路开关的每个控制门仅是一个常闭的开关，它的一个输入端代表来自寄存器的信息，而另一个输入端则作为操作控制端。一旦两个输入端都有输入信号时，它才产生一个输出信号，从而在控制线能起作用的一个时间宽度中来控制信息在部件中流动。图中每个开关门由控制器中相应的微命令来控制，例如，开关门4由控制器中编号为4的微命令控制，开关门6由编号为6的微命令控制，如此等等。三个寄存器R1、R2、R3的时钟输入端1、2、3也需要加以控制，以便在ALU运算完毕而输出公共总线上电平稳定时，将结果打入到某一寄存器。另外，我们假定ALU只有+，–，M(传送)三种操作。Cy为最高进位触发器，有进位时该触发器状态为“1”。ALU的操作(加、减、传送)在同一个CPU周期中只能选择一种，不能并行，所以+，–，M(传送)三个微操作是相斥性的微操作。类似地，4、6、8三个微操作是相斥性的，5、7、9三个微操作也是相斥性的。ALU的X输入微操作4、6、8与Y输入的5、7、9这两组信号中，任意两个微操作也都是相容性的。2.微指令和微程序在机器的一个CPU周期中，一组实现一定操作功能的微命令的组合，构成一条微指令。图5.22表示一个具体的微指令结构，微指令字长为23位，它由操作控制和顺序控制两大部分组成。操作控制部分用来发出管理和指挥全机工作的控制信号。为了形象直观，在我们的例子中，该字段为17位，每一位表示一个微命令。每个微命令的编号同图5.21所示的数据通路相对应，具体功能示于微指令格式的左上部。当操作控制字段某一位信息为“1”时，表示发出微命令；而某一位信息为“0”时，表示不发出微命令。例如，当微指令字第1位信息为“1”时，表示发出LDR′1的微命令，那么运算器将执行ALU→R1的微操作，把公共总线上的信息打入到寄存器R1。同样，当微指令第10位信息为“1”时，表示向ALU发出进行“+”的微命令，因而ALU就执行“+”的微操作。注意，图5.22中微指令给出的控制信号都是节拍电位信号，它们的持续时间都是一个CPU周期。如果要用来控制图5.21所示的运算器数据通路，势必会出现问题，因为前面的这些微命令信号还要加入时间控制，例如同节拍脉冲T4相与而得到LDR1～LDR3信号，如图5.23(a)所示。在这种情况下，控制器最后发给运算器的12个控制信号中，3个是节拍脉冲信号(LDR1，LDR2，LDR3)，其他9个都是节拍电位信号，从而保证运算器在前600ns时间内进行运算。600ns后运算完毕，公共总线上输出稳定的运算结果，由LDR1(或LDR2，LDR3)信号打入到相应的寄存器，其时间关系如图5.23所示。微指令格式中的顺序控制部分用来决定产生下一条微指令的地址。下面我们将会知道，一条机器指令的功能是用许多条微指令组成的序列来实现的，这个微指令序列通常称为微程序。既然微程序是由微指令组成的，那么当执行当前一条微指令时，必须指出后继微指令的地址，以便当前一条微指令执行完毕后，取出下一条微指令。决定后继微指令地址的方法不只一种。在我们所举的例子中，由微指令顺序控制字段的6位信息来决定。其中4位(20～23)用来直接给出下一条微指令的地址。第18、19两位作为判别测试标志。当此两位为“0”时，表示不进行测试，直接按顺序控制字段第20～23位给出的地址取下一条微指令；当第18位或第19位为“1”时，表示要进行P1或P2的判别测试，根据测试结果，需要对第20～23位的某一位或几位进行修改，然后按修改后的地址取下一条微指令。3.微程序控制器原理框图微程序控制器原理框图如图5.24所示。它主要由控制存储器、微指令寄存器和地址转移逻辑三大部分组成，其中微指令寄存器分为微地址寄存器和微命令寄存器两部分。(1)控制存储器控制存储器用来存放实现全部指令系统的微程序，它是一种只读型存储器。一旦微程序固化，机器运行时则只读不写。其工作过程是：每读出一条微指令，则执行这条微指令；接着又读出下一条微指令，又执行这一条微指令……读出一条微指令并执行微指令的时间总和称为一个微指令周期。通常，在串行方式的微程序控制器中，微指令周期就是只读存储器的工作周期。控制存储器的字长就是微指令字的长度，其存储容量视机器指令系统而定，即取决于微程序的数量。对控制存储器的要求是速度快，读出周期要短。(2)微指令寄存器微指令寄存器用来存放由控制存储器读出的一条微指令信息。其中微地址寄存器决定将要访问的下一条微指令的地址，而微命令寄存器则保存一条微指令的操作控制字段和判别测试字段的信息。(3)地址转移逻辑在一般情况下，微指令由控制存储器读出后直接给出下一条微指令的地址，通常我们简称微地址，这个微地址信息就存放在微地址寄存器中。如果微程序不出现分支，那么下一条微指令的地址就直接由微地址寄存器给出。当微程序出现分支时，意味着微程序出现条件转移。在这种情况下，通过判别测试字段P和执行部件的“状态条件”反馈信息，去修改微地址寄存器的内容，并按改好的内容去读下一条微指令。地址转移逻辑就承担自动完成修改微地址的任务。4.微程序举例一条机器指令是由若干条微指令组成的序列来实现的。因此，一条机器指令对应着一个微程序，而微程序的总和便可实现整个的指令系统。现在我们举“十进制加法”指令为例，具体看一看微程序控制的过程。“十进制加法”指令的功能是用BCD码来完成十进制数的加法运算。在十进制运算时，当相加两数之和大于9时，便产生进位。可是用BCD码完成十进制数运算时，当和数大于9时，必须对和数进行加6修正。这是因为，采用BCD码后，在两数相加的和数小于等于9时，十进制运算的结果是正确的；而当两数相加的和数大于9时，结果不正确，必须加6修正后才能得出正确结果。假定指令存放在指存中，数据a、b及常数6已存放在图5.21中的R1、R2、R3三寄存器中，因此，完成十进制加法的微程序流程图示于图5.25中。执行周期要求先进行a+b+6运算，然后判断结果有无进位：当进位标志Cy=1，不减6；当Cy=0，减去6，从而获得正确结果。可以看到，十进制加法微程序流程图由四条微指令组成，每一条微指令用一个长方框表示。第一条微指令为“取指”微指令，它是一条专门用来取机器指令的微指令，任务有三：①从内存取出一条机器指令，并将指令放到指令寄存器IR。在我们的例子中，取出的是“十进制加法”指令。②对程序计数器加1，做好取下一条机器指令的准备。③对机器指令的操作码用P1进行判别测试，然后修改微地址寄存器内容，给出下一条微指令的地址。在微程序流程图中，每一条微指令的地址用数字示于长方框的右上角。注意，菱形符号代表判别测试，它的动作在时间上依附于第一条微指令。第二条微指令完成a+b运算。第三条微指令完成a+b+6运算，同时又进行判别测试。不过这一次的判别标志不是P1而是P2，P2用来测试进位标志Cy。根据测试结果，微程序或者转向公操作，或者转向第四条微指令。当微程序转向公操作(用符号～表示)时，如果没有外围设备请求服务，那么又转向取下一条机器指令。与此相对应，第三条微指令和第四条微指令的下一个微地址就又指向第一条微指令，即“取指”微指令。假设我们已经按微程序流程图编好了微程序，并已事先存放到控制存储器中。同时假定用图5.21所示的运算器做执行部件。机器启动时，只要给出控制存储器的首地址，就可以调出所需要的微程序。为此，首先给出第一条微指令的地址0000，经地址译码，控制存储器选中所对应的“取指”微指令，并将其读到微指令寄存器中。第一条微指令的二进制编码是00000000000011111100000在这条微指令中，操作控制字段有五个微命令：第16位发出PC→ABUS(I)，将PC内容送到指存地址总线ABUS(I)；第13位发出指存读命令RD(I)，于是指存执行读操作，从指存单元取出“十进制加法”指令放到指令总线IBUS上，其数据通路可参阅图5.5。第15位发出LDIR′，将IBUS上的“十进制加法”指令打入到指令寄存器IR。假定“十进制加法”指令的操作码为1010，那么指令寄存器的OP字段现在是1010。第17位发出PC+1微命令，使程序计数器加1，做好取下一条机器指令的准备。另一方面，微指令的顺序控制字段指明下一条微指令的地址是0000，但是由于判别字段中第18位为1，表明是P1测试，因此0000不是下一条微指令的真正的地址。P1测试的“状态条件”是指令寄存器的操作码字段，即用OP字段作为形成下一条微指令的地址，于是微地址寄存器的内容修改成1010。在第二个CPU周期开始时，按照1010这个微地址读出第二条微指令，它的二进制编码是01010010010000000001001在这条微指令中，操作控制部分发出如下四个微命令：R1→X，R2→Y，+，LDR2′，于是运算器完成R1+R2→R2的操作，其数据通路如图5.21所示。与此同时，这条微指令的顺序控制部分由于判别测试字段P1和P2均为0，表示不进行测试，于是直接给出下一条微指令的地址为1001。在第三个CPU周期开始时，按照1001这个微地址读出第三条微指令，它的二进制编码是01000100110000000010000这条微指令的操作控制部分发出R2→X，R3→Y，+，LDR2′的四个微命令，运算器完成R2+R3→R2的操作。顺序控制部分由于判别字段中P2为1，表明进行P2测试，测试的“状态条件”为进位标志Cy。换句话说，此时微地址0000需要进行修改，我们假定用Cy的状态来修改微地址寄存器的最后一位：当Cy=0时，下一条微指令的地址为0001；当Cy=1时，下一条微指令的地址为0000。显然，在测试一个状态时，有两条微指令作为要执行的下一条微指令的“候选”微指令。现在假设Cy=0，则要执行的下一条微指令地址为0001。在第四个CPU周期开始时，按微地址0001读出第四条微指令，其编码是01000100100100000000000微指令发出R2→X，R3→Y，–，LDR2′的微命令，运算器完成了R2–R3→R2的操作功能。顺序控制部分直接给出下一条微指令的地址为0000，按该地址取出的微指令是“取指”微指令。如果第三条微指令进行测试时Cy=1，那么微地址仍保持为0000，将不执行第四条微指令而直接由第三条微指令转向公操作。当下一个CPU周期开始时，“取指”微指令又从内存读出第二条机器指令。如果这条机器指令是STO指令，那么经过P1测试，就转向执行STO指令的微程序。以上是由四条微指令序列组成的简单微程序。从这个简单的控制模型中，我们就可以看到微程序控制的主要思想及大概过程。5.CPU周期与微指令周期的关系在串行方式的微程序控制器中，微指令周期等于读出微指令的时间加上执行该条微指令的时间。为了保证整个机器控制信号的同步，可以将一个微指令周期时间设计得恰好和CPU周期时间相等。图5.26示出了某计算机中CPU周期与微指令周期的时间关系。一个CPU周期为0.8μs，它包含四个等间隔的节拍脉冲T1～T4，每个脉冲宽度为200ns。用T4作为读取微指令的时间，用T1+T2+T3时间作为执行微指令的时间。例如，在前600ns时间内运算器进行运算，在600ns时间的末尾运算器已经运算完毕，可用T4上升沿将运算结果打入某个寄存器。与此同时可用T4间隔读取下条微指令，经200ns时间延迟，下条微指令又从只读存储器读出，并用T1上升沿打入到微指令寄存器。如忽略触发器的翻转延迟，那么下条微指令的微命令信号就从T1上升沿起开始有效，直到下一条微指令读出后打入微指令寄存器为止。因此一条微指令的保持时间恰好是0.8μs，也就是一个CPU周期的时间。6.机器指令与微指令的关系经过上面的讲述，应该说，我们能够透彻地了解机器指令与微指令的关系。也许读者会问：一会儿取机器指令，一会儿取微指令，它们之间到底是什么关系?现在让我们把前面内容归纳一下，作为对此问题的问答。(1)一条机器指令对应一个微程序，这个微程序是由若干条微指令序列组成的。因此，一条机器指令的功能是由若干条微指令组成的序列来实现的。简言之，一条机器指令所完成的操作划分成若干条微指令来完成，由微指令进行解释和执行。(2)从指令与微指令，程序与微程序，地址与微地址的一一对应关系来看，前者与内存储器有关，后者与控制存储器有关。与此相关，也有相对应的硬设备，如图5.27所示。(3)我们在讲述本章5.2节时，曾讲述了指令与机器周期概念，并归纳了五条典型指令的指令周期(参见图5.15)。现在我们看到，图5.15就是这五条指令的微程序流程图，每一个CPU周期就对应一条微指令。这就告诉我们如何设计微程序，也将使我们进一步体验到机器指令与微指令的关系。已经了解了微程序控制器的基本原理。这使我们认识到，如何确定微指令的结构，乃是微程序设计的关键。设计微指令结构应当追求的目标是：①有利于缩短微指令字长度；②有利于减小控制存储器的容量；③有利于提高微程序的执行速度；④有利于对微指令的修改；⑤有利于提高微程序设计的灵活性。1.微命令编码微命令编码，就是对微指令中的操作控制字段采用的表示方法。通常有以下三种方法。(1)直接表示法采用直接表示法的微指令结构如图5.22所示，其特点是操作控制字段中的每一位代表一个微命令。这种方法的优点是简单直观，其输出直接用于控制。缺点是微指令字较长，因而使控制存储器容量较大。(2)编码表示法编码表示法是把一组相斥性的微命令信号组成一个小组(即一个字段)，然后通过小组(字段)译码器对每一个微命令信号进行译码，译码输出作为操作控制信号，其微指令结构如图5.28所示。采用字段译码的编码方法，可以用较小的二进制信息位表示较多的微命令信号。例如，3位二进制位译码后可表示7个微命令，4位二进制位译码后可表示15个微命令。与直接控制法相比，字段译码控制法可使微指令字大大缩短，但由于增加译码电路，使微程序的执行速度稍稍减慢。目前在微程序控制器设计中，字段直接译码法使用较普遍。(3)混合表示法这种方法是把直接表示法与字段编码法混合使用，以便能综合考虑微指令字长、灵活性、执行微程序速度等方面的要求。另外，在微指令中还可附设一个常数字段。该常数可作为操作数送入ALU运算，也可作为计数器初值用来控制微程序循环次数。2.微地址的形成方法微指令执行的顺序控制问题，实际上是如何确定下一条微指令的地址问题。通常，产生后继微地址有两种方法。(1)计数器方式这种方法同用程序器计数来产生机器指令地址的方法相类似。在顺序执行微指令时，后继微地址由现行微地址加上一个增量来产生；在非顺序执行微指令时，必须通过转移方式，使现行微指令执行后，转去执行指定后继微地址的下一条微指令。在这种方法中，微地址寄存器通常改为计数器。为此，顺序执行的微指令序列就必须安排在控制存储器的连续单元中。计数器方式的基本特点是：微指令的顺序控制字段较短，微地址产生机构简单。但是多路并行转移功能较弱，速度较慢，灵活性较差。(2)多路转移方式一条微指令具有多个转移分支的能力称为多路转移。例如，“取指”微指令根据操作码OP产生多路微程序分支而形成多个微地址。在多路转移方式中，当微程序不产生分支时，后继微地址直接由微指令的顺序控制字段给出；当微程序出现分支时，有若干“后选”微地址可供选择：即按顺序控制字段的“判别测试”标志和“状态条件”信息来选择其中一个微地址，其原理如图5.23所示。“状态条件”有1位标志，可实现微程序两路转移，涉及微地址寄存器的一位；“状态条件”有2位标志，可实现微程序4路转移，涉及微地址寄存器的两位。以此类推，“状态条件”有n位标志，可实现微程序2n路转移，涉及微地址寄存器的n位。因此执行转移微指令时，根据状态条件可转移到2n个微地址中的一个。多路转移方式的特点是，能以较短的顺序控制字段配合，实现多路并行转移，灵活性好，速度较快，但转移地址逻辑需要用组合逻辑方法设计。3.微指令格式微指令的编译方法是决定微指令格式的主要因素。考虑到速度、成本等原因，在设计计算机时采用不同的编译法。因此微指令的格式大体分成两类：水平型微指令和垂直型微指令。1)水平型微指令一次能定义并执行多个并行操作微命令的微指令，称为水平型微指令。例如5.4节中所讲的微指令即为水平型微指令。水平型微指令的一般格式如下：按照控制字段的编码方法不同，水平型微指令又分为三种：第一种是全水平型(不译码法)微指令，第二种是字段译码法水平型微指令，第三种是直接和译码相混合的水平型微指令。2)垂直型微指令微指令中设置微操作码字段，采用微操作码编译法，由微操作码规定微指令的功能，称为垂直型微指令。垂直型微指令的结构类似于机器指令的结构。它有微操作码，在一条微指令中只有1～2个微操作命令，每条微指令的功能简单，因此，实现一条机器指令的微程序要比水平型微指令编写的微程序长得多。它是采用较长的微程序结构去换取较短的微指令结构。下面用4条垂直型微指令的微指令格式加以说明。设微指令字长为16位，微操作码3位。(1)寄存器-寄存器传送型微指令。其功能是把源寄存器数据送目标寄存器。13～15位为微操作码，源寄存器和目标寄存器编址各5位，可指定31个寄存器。(2)运算控制型微指令。其功能是选择ALU的左、右两输入源信息，按ALU字段所指定的运算功能(8种操作)进行处理，并将结果送入暂存器中。左、右输入源编址可指定31种信息源之一。(3)访问主存微指令。其功能是将主存中一个单元的信息送入寄存器或者将寄存器的数据送往主存。存储器编址是指按规定的寻址方式进行编址。第1、2位指定读操作或写操作(取其之一)。(4)条件转移微指令。其功能是根据测试对象的状态决定是转移到D所指定的微地址单元，还是顺序执行下一条微指令。9位D字段不足以表示一个完整的微地址，但可以用来替代现行μPC的低位地址。测试条件字段有4位，可规定16种测试条件。3)水平型微指令与垂直型微指令的比较(1)水平型微指令并行操作能力强，效率高，灵活性强，垂直型微指令则较差。在一条水平型微指令中，设置有控制信息传送通路(门)以及进行所有操作的微命令，因此在进行微程序设计时，可以同时定义比较多的并行操作的微命令，来控制尽可能多的并行信息传送，从而使水平型微指令具有效率高及灵活性强的优点。在一条垂直型微指令中，一般只能完成一个操作，控制一两个信息传送通路，因此微指令的并行操作能力低，效率低。(2)水平型微指令执行一条指令的时间短，垂直型微指令执行时间长。因为水平型微指令的并行操作能力强，所以与垂直型微指令相比，可以用较少的微指令数来实现一条指令的功能，从而缩短了指令的执行时间。而且当执行一条微指令时，水平型微指令的微命令一般直接控制对象，而垂直型微指令要经过译码，会影响速度。(3)由水平型微指令解释指令的微程序，有微指令字较长而微程序短的特点。垂直型微指令则相反，微指令字较短而微程序长。(4)水平型微指令用户难以掌握，而垂直型微指令与指令比较相似，相对来说，比较容易掌握。水平型微指令与机器指令差别很大，一般需要对机器的结构、数据通路、时序系统以及微命令很精通才能设计。垂直型微指令的设计思想在Pentium4、安腾系列机中得到了应用。4.动态微程序设计微程序设计技术还有静态微程序设计和动态微程序设计之分。对应于一台计算机的机器指令只有一组微程序，而且这一组微程序设计好之后，一般无须改变而且也不好改变，这种微程序设计技术称为静态微程序设计。本节前面讲述的内容基本上属于静态微程序设计的概念。当采用E2PROM作为控制存储器时，还可以通过改变微指令和微程序来改变机器的指令系统，这种微程序设计技术称为动态微程序设计。采用动态微程序设计时，微指令和微程序可以根据需要加以改变，因而可在一台机器上实现不同类型的指令系统。这种技术又可用于仿真其他机器指令系统，以便扩大机器的功能。1.基本思想硬布线控制器是早期设计计算机的一种方法。这种方法是把控制部件看作产生专门固定时序控制信号的逻辑电路，而此逻辑电路以使用最少元件和取得最高操作速度为设计目标。一旦控制部件构成后，除非重新设计和物理上对它重新布线，否则要想增加新的控制功能是不可能的。这种逻辑电路是一种由门电路和触发器构成的复杂树形逻辑网络，故称之为硬布线控制器。硬布线控制器是计算机中最复杂的逻辑部件之一。当执行不同的机器指令时，通过激活一系列彼此很不相同的控制信号来实现对指令的解释，其结果使得控制器往往很少有明确的结构而变得杂乱无章。结构上的这种缺陷使得硬布线控制器的设计和调试非常复杂且代价很大。正因为如此，硬布线控制器被微程序控制器所取代。但是随着新一代机器及VLSI技术的发展，硬布线逻辑设计思想又得到了重视。图5.29示出了硬布线控制器的结构方框图。逻辑网络的输入信号来源有三个：①来自指令操作码译码器的输出Im；②来自执行部件的反馈信息Bj；③来自时序产生器的时序信号，包括节拍电位信号M和节拍脉冲信号T。其中节拍电位信号就是5.3节规定的机器周期(CPU周期)信号，节拍脉冲信号是时钟周期信号。逻辑网络N的输出信号就是微操作控制信号，它用来对执行部件进行控制。另有一些信号则根据条件变量来改变时序发生器的计数顺序，以便跳过某些状态，从而可以缩短指令周期。显然，硬布线控制器的基本原理，归纳起来可叙述为：某一微操作控制信号C是指令操作码译码器输出Im、时序信号(节拍电位Mi，节拍脉冲Tk)和状态条件信号Bj的逻辑函数，即C=f(Im,Mi,Tk,Bj)这个控制信号是用门电路、触发器等许多器件采用布尔代数方法来设计实现的。当机器加电工作时，某一操作控制信号C在某条特定指令和状态条件下，在某一序号的特定节拍电位和节拍脉冲时间间隔中起作用，从而激活这条控制信号线，对执行部件实施控制。显然，从指令流程图出发，就可以一个不漏地确定在指令周期中各个时刻必须激活的所有操作控制信号。例如，对引起一次主存读操作的控制信号C3来说，当节拍电位M1=1，取指令时被激活；而节拍电位M4=1，三条指令(LAD，ADD，AND)取操作数时也被激活，此时指令译码器的LAD，ADD，AND输出均为1，因此C3的逻辑表达式可由下式确定：C3=M1+M4(LAD+ADD+AND)一般来说，还要考虑节拍脉冲和状态条件的约束，所以每一控制信号Cn可以由以下形式的布尔代数表达式来确定：与微程序控制相比，硬布线控制的速度较快。其原因是微程序控制中每条微指令都要从控存中读取一次，影响了速度，而硬布线控制主要取决于电路延迟。因此在某些超高速新型计算机结构中，又选用了硬布线控制器，或与微程序控制器混合使用。2.指令执行流程前面在介绍微程序控制器时曾提到，一个机器指令对应一个微程序，而一个微指令周期则对应一个节拍电位时间。一条机器指令用多少条微指令来实现，则该条指令的指令周期就包含了多少个节拍电位时间，因而对时间的利用是十分经济的。由于节拍电位是用微指令周期来体现的，因而时序信号比较简单，时序计数器及其译码电路只需产生若干节拍脉冲信号即可。在用硬布线实现的操作控制器中，通常，时序产生器除了产生节拍脉冲信号外，还应当产生节拍电位信号。这是因为，在一个指令周期中要顺序执行一系列微操作，需要设置若干节拍电位来定时。如图5.15所示五条指令的指令周期，其指令流程可用图5.30来表示。由图5.30可知，所有指令的取指周期放在M1节拍。在此节拍中，操作控制器发出微操作控制信号，完成从指令存储器取出一条机器指令。指令的执行周期由M2、M3两个节拍来完成。MOV、ADD和JMP指令只需一个节拍(M2)即可完成。LAD和STO指令需要两个节拍(M2、M3)。为了简化节拍控制，指令的执行过程可采用同步工作方式，即各条指令的执行阶段均用最长节拍数M3来考虑。这样，对MOV、ADD、JMP三条指令来讲，在M3节拍中没有什么操作。显然，由于采用同步工作方式，长指令和短指令对节拍时间的利用都是一样的。这对短指令来讲，在时间的利用上是浪费的，因而也降低了CPU的指令执行速度，影响到机器的速度指标。为了改变这种情况，在设计短指令流程时可以跳过某些节拍，如MOV指令、ADD指令和JMP指令执行M2节拍后跳过M3节拍而返回M1节拍。当然在这种情况下，节拍信号发生器的电路相应就要复杂一些。节拍电位信号的产生电路与节拍脉冲产生电路十分类似，它可以在节拍脉冲信号时序器的基础上产生，运行中以循环方式工作，并与节拍脉冲保持同步。3.微操作控制信号的产生在微程序控制器中，微操作控制信号由微指令产生，并且可以重复使用。在硬布线控制器中，某一微操作控制信号由布尔代数表达式描述的输出函数产生。设计微操作控制信号的方法和过程是，根据所有的机器指令流程图，寻找出产生同一个微操作信号的所有条件，并与适当的节拍电位和节拍脉冲组合，从而写出其布尔代数表达式并进行简化，然后用门电路或可编程器件来实现。为了防止遗漏，设计时可按信号出现在指令流程图中的先后次序来书写，然后进行归纳和简化。要特别注意控制信号是电位有效还是脉冲有效，如果是脉冲有效，必须加入节拍脉冲信号进行相“与”。计算机自诞生到现在，人们追求的目标之一是很高的运算速度，因此并行处理技术便成为计算机发展的主流。早期的计算机基于冯·诺伊曼的体系结构，采用的是串行处理。这种计算机的主要特征是：计算机的各个操作(如读/写存储器，算术或逻辑运算，I/O操作)只能串行地完成，即任一时刻只能进行一个操作。而并行处理则使得以上各个操作能同时进行，从而大大提高了计算机的速度。广义地讲，并行性有着两种含义：一是同时性，指两个以上事件在同一时刻发生；二是并发性，指两个以上事件在同一时间间隔内发生。计算机的并行处理技术可贯穿于信息加工的各个步骤和阶段，概括起来，主要有三种形式：①时间并行；②空间并行；③时间并行+空间并行。时间并行指时间重叠，在并行性概念中引入时间因素，让多个处理过程在时间上相互错开，轮流重叠地使用同一套硬件设备的各个部分，以加快硬件周转而赢得速度。时间并行性概念的实现方式就是采用流水处理部件。这是一种非常经济而实用的并行技术，能保证计算机系统具有较高的性能价格比。目前的高性能微型机几乎无一例外地使用了流水技术。空间并行指资源重复，在并行性概念中引入空间因素，以“数量取胜”为原则来大幅度提高计算机的处理速度。大规模和超大规模集成电路的迅速发展为空间并行技术带来了巨大生机，因而成为目前实现并行处理的一个主要途径。空间并行技术主要体现在多处理器系统和多计算机系统。但是在单处理器系统中也得到了广泛应用。时间并行+空间并行指时间重叠和资源重复的综合应用，既采用时间并行性又采用空间并行性。例如，奔腾CPU采用了超标量流水技术，在一个机器周期中同时执行两条指令，因而既具有时间并行性，又具有空间并行性。显然，第三种并行技术带来的高速效益是最好的。图5.31为现代流水计算机的系统组成原理示意图。其中CPU按流水线方式组织，通常由三大部分组成：指令部件、指令队列、执行部件。这三个功能部件可以组成一个3级流水线。程序和数据存储在主存中，主存通常采用多体交叉存储器，以提高访问速度。cache是一个高速缓冲存储器，用以弥补主存和CPU速度上的差异。指令部件本身又构成一个流水线，即指令流水线，它由取指令、指令译码、计算操作数地址、取操作数等几个过程段组成。指令队列是一个先进先出(FIFO)的寄存器栈，用于存放经过译码的指令和取来的操作数。它也是由若干个过程段组成的流水线。执行部件可以具有多个算术逻辑运算部件，这些部件本身又用流水线方式构成。由图可见，当执行部件正在执行第I条指令时，指令队列中存放着I+1,I+2,…,I+k条指令，而与此同时，指令部件正在取第I+k+1条指令。为了使存储器的存取时间能与流水线的其他各过程段的速度相匹配，一般都采用多体交叉存储器。例如，IBM360/91计算机，根据一个机器周期输出一条指令的要求、存储器的存取周期、CPU访问存储器的频率，采用了模8交叉存储器。在现有的流水线计算机中，存储器几乎都是采用交叉存取的方式工作。执行段的速度匹配问题，通常采用并行的运算部件以及部件流水线的工作方式来解决。一般采用的方法包括：①将执行部件分为定点执行部件和浮点执行部件两个可并行执行的部分，分别处理定点运算指令和浮点运算指令；②在浮点执行部件中，又有浮点加法部件和浮点乘/除部件，它们也可以同时执行不同的指令；③浮点运算部件都以流水线方式工作。2.流水CPU的时空图计算机的流水处理过程非常类似于工厂中的流水装配线。为了实现流水，首先把输入的任务(或过程)分割为一系列子任务，并使各子任务能在流水线的各个阶段并发地执行。当任务连续不断地输入流水线时，在流水线的输出端便连续不断地吐出执行结果，从而实现了子任务级的并行性。下面通过时空图来证明这个结论。图5.32(a)表示流水CPU中一个指令周期的任务分解。假设指令周期包含四个子过程：取指令(IF)、指令译码(ID)、执行运算(EX)、结果写回(WB)，每个子过程称为过程段(Si)，这样，一个流水线由一系列串联的过程段组成。各个过程段之间设有高速缓冲寄存器，以暂时保存上一过程段子任务处理的结果。在统一的时钟信号控制下，数据从一个过程段流向相邻的过程段。图5.32(b)表示非流水计算机的时空图。对非流水计算机来说，上一条指令的四个子过程全部执行完毕后才能开始下一条指令。因此，每隔4个机器时钟周期才有一个输出结果。图5.32(c)表示流水计算机的时空图。对流水计算机来说，上一条指令与下一条指令的四个子过程在时间上可以重叠执行。因此，当流水线满载时，每一个时钟周期就可以输出一个结果。图5.32(d)表示超标量流水计算机的时空图。一般的流水计算机因只有一条指令流水线，所以称为标量流水计算机。所谓超标量流水，是指它具有两条以上的指令流水线。如图所示，当流水线满载时，每一个时钟周期可以执行2条指令。显然，超标量流水计算机是时间并行技术和空间并行技术的综合应用。Pentium微型机就是一个超标量流水计算机。直观比较后发现：标量流水计算机在8个单位时间中执行了5条指令，超标量流水计算机在8个单位时间中执行了10条指令，而非流水计算机在8个单位时间中仅执行了2条指令。显然，流水技术的应用，使计算机的速度大大提高了。3.流水线分类一个计算机系统可以在不同的并行等级上采用流水线技术。常见的流水线形式有：指令流水线指指令步骤的并行。将指令流的处理过程划分为取指令、译码、取操作数、执行、写回等几个并行处理的过程段。目前，几乎所有的高性能计算机都采用了指令流水线。算术流水线指运算操作步骤的并行。如流水加法器、流水乘法器、流水除法器等。现代计算机中已广泛采用了流水的算术运算器。例如，STAR-100为4级流水运算器，TI-ASC为8级流水运算器，CRAY-1为14级流水运算器，等等。处理机流水线又称为宏流水线，是指程序步骤的并行。由一串级联的处理机构成流水线的各个过程段，每台处理机负责某一特定的任务。数据流从第一台处理机输入，经处理后被送入与第二台处理机相联的缓冲存储器中。第二台处理机从该存储器中取出数据进行处理，然后传送给第三台处理机，如此串联下去。随着高档微处理器芯片的出现，构造处理机流水线将变得容易了。处理机流水线应用在多机系统中。要使流水线具有良好的性能，必须使流水线畅通流动，不发生断流。但由于流水过程中会出现以下三种相关冲突，实现流水线的不断流是困难的，这三种相关是资源相关、数据相关和控制相关。1.资源相关所谓资源相关，是指多条指令进入流水线后在同一机器时钟周期内争用同一个功能部件所发生的冲突。假定一条指令流水线由五段组成，分别为取指令(IF)、指令译码(ID)、计算有效地址或执行(EX)、访存取数(MEM)、结果写寄存器堆(WB)。由表5.2看出，在时钟4时，第I1条的MEM段与第I4条的IF段都要访问存储器。当数据和指令放在同一个存储器且只有一个访问口时，便发生两条指令争用存储器资源的相关冲突。解决冲突的办法，一是第I4条指令停顿一拍后再启动，二是增设一个存储器，将指令和数据分别放在两个存储器中。2.数据相关在一个程序中，如果必须等前一条指令执行完毕后，才能执行后一条指令，那么这两条指令就是数据相关的。第5章中央处理器179在流水计算机中，指令的处理是重叠进行的，前一条指令还没有结束，第二、三条指令就陆续地开始工作。由于多条指令的重叠处理，当后继指令所需的操作数，刚好是前一指令的运算结果时，便发生“先读后写”的数据相关冲突。例如：ADDR1,R2,R3；(R2)+(R3)→R1SUBR4,R1,R5；(R1)–(R5)→R4ANDR6,R1,R7；(R1)·(R7)→R6如表5.3所示，ADD指令在时钟5时将运算结果写入寄存器堆(R1)，但SUB指令在时钟4时读寄存器堆(R1)到ALU运算，AND指令在时钟5时读寄存器堆(R1)到ALU运算。本来ADD指令应该先写R1，SUB指令后读R1，结果变成SUB指令先读R1，ADD指令后写R1。因而发生了SUB、ADD两条指令间先读后写的数据相关冲突；AND、ADD两条指令间发生了同时读写数据的相关冲突。为了解决数据相关冲突，流水CPU的运算器中特意设置若干运算结果缓冲寄存器，暂时保留运算结果，以便于后继指令直接使用，这称为“向前”或定向传送技术。3.控制相关控制相关冲突是由转移指令引起的。当执行转移指令时，依据转移条件的产生结果，可能为顺序取下条指令；也可能转移到新的目标地址取指令，从而使流水线发生断流。为了减小转移指令对流水线性能的影响，常用以下两种转移处理技术。延迟转移法由编译程序重排指令序列来实现。基本思想是“先执行再转移”，即发生转移取时并不排空指令流水线，而是让紧跟在转移指令Ib之后已进入流水线的少数几条指令继续完成。如果这些指令是与Ib结果无关的有用指令，那么延迟损失时间片正好得到了有效的利用。转移预测法硬件方法来实现，依据指令过去的行为来预测将来的行为。通过使用转移取和顺序取两路指令预取队列器以及目标指令cache，可将转移预测提前到取指阶段进行，以获得良好的效果。第一台RISC(精简指令系统计算机)于1981年在美国加州大学伯克利分校问世。它是在继承了CISC(复杂指令系统计算机)的成功技术，并在克服了CISC机器缺点的基础上发展起来的。尽管众多厂家生产的RISC处理器实现手段有所不同，但是RISC概括的三个基本要素是普遍认同的。这三个要素是：①一个有限的简单的指令系统；②CPU配备大量的通用寄存器；③强调对指令流水线的优化。RISC的目标绝不是简单的缩减指令系统，而是使处理器的结构更简单，更合理，具有更高的性能和执行效率，并降低处理器的开发成本。基于三要素的RISC机器的特征如下。(1)使用等长指令，目前的典型长度是4B。(2)寻址方式少且简单，一般为二三种，最多不超过4种，绝不出现存储器间接寻址方式。(3)只有取数指令、存数指令访问存储器。指令中最多出现RS型指令，绝不出现SS型指令。(4)指令系统中的指令数目一般少于100种，指令格式一般少于4种。(5)指令功能简单，控制器多采用硬布线方式，以期更快的执行速度。(6)平均而言，所有指令的执行时间为一个处理时钟周期。(7)指令格式中，用于指派整数寄存器的个数不少于32个，用于指派浮点数寄存器的个数不少于16个。(8)强调通用寄存器资源的优化使用。(9)支持指令流水并强调指令流水的优化使用。(10)RISC技术的复杂性在它的编译程序，因此软件系统开发时间比CISC机器长。表5.4中列出了RISC与CISC的主要特征对比。1.MC88110CPU结构框图MC88110CPU是Motorola公司的产品，其目标是以较好的性能价格比作为PC和工作站的通用微处理器。它是一个RISC处理器。处理器有12个执行功能部件，三个cache和一个控制部件。其结构框图如图5.33所示。在三个cache中，一个是指令cache，一个是数据cache，它们能同时完成取指令和取数据，还有一个是目标指令cache(TIC)，它用于保存转移目标指令。两个寄存器堆：一个是通用寄存器堆，用于整数和地址指针，其中有R0～R31共32个寄存器(32位长)；另一个是扩展寄存器堆，用于浮点数，其中有X0～X31共32个寄存器(长度可以是32位、64位或80位)。12个执行功能部件是：取数/存数(读写)部件、整数运算部件(2个)、浮点加法部件、乘法部件、除法部件、图形处理部件(2个)、位处理部件、用于管理流水线的超标量指令派遣/转移部件。所有这些cache、寄存器堆、功能部件，在处理器中通过六条80位宽的内部总线相连接。其中2条源1总线，2条源2总线，2条目标总线。2.MC88110的指令流水线由于MC88110是超标量流水CPU，所以指令流水线在每个机器时钟周期完成两条指令。流水线分为三段：取指和译码(F＆D)段、执行(EX)段、写回(WB)段，如图5.34所示。F＆D段需要一个时钟周期，完成由指令cache取一对指令并译码，并从寄存器堆取操作数，然后判断是否把指令发射到EX段。如果所要求的资源(操作数寄存器、目标寄存器、功能部件)发生资源使用冲突，或与先前指令发生数据相关冲突，或转移指令将转向新的目标指令地址，则F＆D段不再向EX段发射指令，或不发射紧接转移指令之后的指令。EX段对于大多数指令只需一个时钟周期，某些指令可能多于一个时钟周期。EX段执行的结果在WB段写回寄存器堆，WB段只需时钟周期的一半。为了解决数据相关冲突，EX段执行的结果一方面在WB段写回寄存器堆，另一方面经定向传送电路提前传送到ALU，可直接被当前进入EX的指令所使用。图5.34(a)表示MC88110CPU超标量流水线正常运行情况。3.指令动态调度策略88110采用按序发射、按序完成的指令动态调度策略。指令派遣单元总是发出单一地址，然后从指令cache取出此地址及下一地址的两条指令。译码后总是力图同一时间发射这两条指令到EX段。若这对指令的第一条指令由于资源冲突或数据相关冲突，则这一对指令都不发射，两条指令在F＆D段停顿，等待资源的可用或数据相关的消除。若第一条指令能发射而第二条指令不能发射，则只发射第一条指令，而第二条指令停顿并与新取的指令之一进行配对等待发射，此时原第二条指令作为配对的第一条指令对待。可见，这样实现的方式是按序发射，图5.34(b)示出了指令配对情况。为了判定能否发射指令，88110使用了计分牌方法。计分牌是一个位向量，寄存器堆中每个寄存器都有一个相应位。每当一条指令发射时，它预约的目的寄存器在位向量中的相应位上置“1”，表示该寄存器“忙”。当指令执行完毕并将结果写回此目的寄存器时，该位被清除。于是，每当判定是否发射一条指令(STO存数指令和转移指令除外)时，一个必须满足的条件是：该指令的所有目的寄存器、源寄存器在位向量中的相应位都已被清除。否则，指令必须停顿等待这些位被清除。为了减少经常出现的数据相关，流水线采用了如前面所述的定向传送技术，将前面指令执行的结果直接送给后面指令所需此源操作数的功能部件，并同时将位向量中的相应位清除。因此，指令发射和定向传送是同时进行的。如何实现按序完成呢?因为执行段有多个功能部件，很可能出现无序完成的情况。为此，88110提供了一个FIFO指令执行队列，称为历史缓冲器。每当一条指令发射出去，它的副本就被送到FIFO队尾。队列最多能保存12条指令。只有前面的所有指令执行完，这条指令才到达队首。当它到达队首并执行完毕后才离开队列。对于转移处理，88110使用了延迟转移法和目标指令cache(TIC)法。延迟转移是个选项(.n)。如果采用这个选项(指令如bcnd.n)，则跟随在转移指令后的指令将被发射。如果不采用这个选项，则在转移指令发射之后的转移延迟时间片内没有任何指令被发射。延迟转移通过编译程序来调度。TIC是一个32项的全相联cache，每项能保存转移目标路径的前两条指令。当一条转移指令译码并命中cache时，能同时由TIC取来它的目标路径的前面两条指令。所谓动态流水线调度，是对指令进行重新排序以避免处理器阻塞的硬件支持。图5.36描述了动态流水线调度模型。通常流水线分为3个主要单元：一个取指令发射单元，多个功能单元(10个或更多)，一个指令完成单元。第一个单元用于取指令，将指令译码，并将它们送到相应的功能单元执行。每个功能单元都有自己的缓冲器，称为保留站，它用于暂存操作数和操作指令。当缓冲器中包含了所有的操作数，并且功能单元已经就绪，结果就被计算出来。当完成结果时，它就被发送到等待特殊结果的储存站及指令完成单元。而指令完成单元确定何时能够安全地将结果放入到寄存器堆或内存中。指令完成单元中的缓冲器通常称为重排序缓冲器，它也可以用来提供操作数，其工作方式类似于旁路逻辑在静态调度流水线中的工作方式。一且结果写回寄存器堆，便可以从寄存器堆中直接取得操作数，就像一般流水线取得操作数的方式一样。本章小结CPU是计算机的中央处理部件，具有指令控制、操作控制、时间控制、数据加工等基本功能。早期的CPU由运算器和控制器组成。随着集成电路技术的发展，当今的CPU芯片变成运算器、cache和控制器三大部分，CPU中至少有六类寄存器：指令寄存器、程序计数器、地址寄存器、数据缓冲寄存器、通用寄存器、状态条件寄存器。CPU从存储器取出一条指令并执行这条指令的时间和称为指令周期。CISC中，由于各种指令的操作功能不同，各种指令的指令周期是不尽相同的。划分指令周期，是设计操作控制器的重要依据。RISC中，由于流水执行，大部分指令在一个机器周期完成。时序信号产生器提供CPU周期(也称机器周期)所需的时序信号。操作控制器利用这些时序信号进行定时，有条不紊地取出一条指令并执行这条指令。微程序设计技术是利用软件方法设计操作控制器的一门技术，具有规整性、灵活性、可维护性等一系列优点，因而在计算机设计中得到了广泛应用。但是随着ULSI技术的发展和对机器速度的要求，硬布线逻辑设计思想又得到了重视。硬布线控制器的基本思想是：某一微操作控制信号是指令操作码译码输出、时序信号和状态条件信号的逻辑函数，即用布尔代数写出逻辑表达式，然后用门电路、触发器等器件实现。从简单到复杂，举出一个CPU模型，目的在于使读者由浅入深地理解教学内容，这对于建立整机概念是十分重要的。不论微型机还是超级计算机，并行处理技术已成为计算机技术发展的主流。并行处理技术可贯穿于信息加工的各个步骤和阶段。概括起来，主要有三种形式：①时间并行；②空间并行；③时间并行+空间并行。流水CPU是以时间并行性为原理构造的处理机，是一种非常经济而实用的并行技术。目前的高性能微处理机几乎无一例外地使用了流水技术。流水技术中的主要问题是资源相关、数据相关和控制相关，为此需要采取相应的技术对策，才能保证流水线畅通而不断流。RISCCPU是继承CISC的成功技术，并在克服CISC机器缺点的基础上发展起来的。RISC机器的三个基本要素是：①一个有限的简单指令系统；②CPU配备大量的通用寄存器；③强调指令流水线的优化。RISC机器一定是流水CPU，但流水CPU不一定是RISC机器。如奔腾CPU是流水CPU，但奔腾机是CISC机器。数字计算机是由若干系统功能部件构成的，这些系统功能部件在一起工作才能形成一个完整的计算机系统。总线是构成计算机系统的互联机构，是多个系统功能部件之间进行数据传送的公共通路。借助于总线连接，计算机在各系统功能部件之间实现地址、数据和控制信息的交换，并在争用资源的基础上进行工作。一个单处理器系统中的总线，大致分为三类：(1)CPU内部连接各寄存器及运算部件之间的总线，称为内部总线。(2)CPU同计算机系统的其他高速功能部件，如存储器、通道等互相连接的总线，称为系统总线。(3)中、低速I/O设备之间互相连接的总线，称为I/O总线。1.总线的特性物理特性总线的物理特性是指总线的物理连接方式，包括总线的根数，总线的插头、插座的形状，引脚线的排列方式等。功能特性功能特性描述总线中每一根线的功能。如地址总线的宽度指明了总线能够直接访问存储器的地址空间范围；数据总线的宽度指明了访问一次存储器或外设时能够交换数据的位数；控制总线包括CPU发出的各种控制命令(如存储器读/写、I/O读/写)，请求信号与仲裁信号，外设与CPU的时序同步信号，中断信号，DMA控制信号等。电气特性电气特性定义每一根线上信号的传递方向及有效电平范围。一般规定送入CPU的信号叫输入(IN)信号，从CPU发出的信号叫输出(OUT)信号。例如，地址总线是输出线，数据总线是双向传送的信号线，这两类信号线都是高电平有效。控制总线中各条线一般是单向的，有CPU发出的，也有进入CPU的，有高电平有效的，也有低电平有效的。总线的电平都符合相应电平规范的定义。时间特性时间特性定义了每根线在什么时间有效。也就是说，只有规定了总线上各信号有效的时序关系，CPU才能正确无误地使用。2.总线的标准化相同的指令系统，相同的功能，不同厂家生产的各功能部件在实现方法上几乎没有相同的，但各厂家生产的相同功能部件却可以互换使用，其原因何在呢?就是因为它们都遵守了相同的系统总线的要求，这就是系统总线的标准化问题。例如，微型计算机系统中采用的标准总线，从ISA总线(16位，带宽8MB/s)发展到EISA总线(32位，带宽33.3MB/s)，又发展到VESA总线(32位，带宽132MB/s)，而PCI总线又进一步过渡到64位，100MHz。衡量总线性能的重要指标是总线带宽，它定义为总线本身所能达到的最高传输速率，单位是兆字节每秒(MB/s)。实际带宽会受到总线布线长度、总线驱动器/接收器性能、连接在总线上的模块数等因素的影响。这些因素将造成信号在总线上的畸变和延时，使总线最高传输速率受到限制。任何数字计算机的用途很大程度上取决于它所能连接的外围设备的范围。遗憾的是，由于外围设备种类繁多，速度各异，不可能简单地把外围设备直接连接在CPU上。因此必须寻找一种方法，以便将外围设备同某种计算机连接起来，使它们在一起可以正常工作。通常，这项任务用适配器部件来完成。通过适配器可以实现高速CPU与低速外设之间工作速度上的匹配和同步，并完成计算机和外设之间的所有数据传送和控制。适配器通常简称为接口。大多数总线都是以相同方式构成的，其不同之处仅在于总线中数据线和地址线的宽度，以及控制线的多少及其功能。然而，总线的排列布置与其他各类部件的连接方式对计算机系统的性能来说，将起着十分重要的作用。根据连接方式不同，单机系统中采用的总线结构有两种基本类型：①单总线结构；②多总线结构。1.单总线结构在许多单处理器的计算机中，使用单一的系统总线来连接CPU、主存和I/O设备，称为单总线结构，如图6.1所示。在单总线结构中，要求连接到总线上的逻辑部件必须高速运行，以便在某些设备需要使用总线时，能迅速获得总线控制权；而当不再使用总线时，能迅速放弃总线控制权。否则，由于一条总线由多种功能部件共用，可能导致很大的时间延迟。在单总线系统中，当CPU取一条指令时，首先把程序计数器PC中的地址同控制信息一起送至总线上。该地址不仅加至主存，同时也加至总线上的所有外围设备。然而，只有与出现在总线上的地址相对应的设备，才执行数据传送操作。我们知道，在“取指令”情况下的地址是主存地址，所以，此时该地址所指定的主存单元的内容一定是一条指令，而且将被传送给CPU。取出指令之后，CPU将检查操作码。操作码规定了对数据要执行什么操作，以及数据是流进CPU还是流出CPU。在单总线系统中，对输入/输出设备的操作，完全和主存的操作方法一样来处理。这样，当CPU把指令的地址字段送到总线上时：①如果该地址字段对应的地址是主存地址，则主存予以响应，从而在CPU和主存之间发生数据传送，而数据传送的方向由指令操作码决定。②如果该指令地址字段对应的是外围设备地址，则外围设备译码器予以响应，从而在CPU和与该地址相对应的外围设备之间发生数据传送，而数据传送的方向由指令操作码决定。在单总线系统中，某些外围设备也可以指定地址。此时，外围设备通过与CPU中的总线控制部件交换控制信号的方式占有总线。一旦外围设备得到总线控制权后，就可向总线发送地址信号，使总线上的地址线置为适当的代码状态，以便指定它将要与哪一个设备进行信息交换。如果一个由外围设备指定的地址对应于一个主存单元，则主存予以响应，于是在主存和外设之间将进行直接存储器传送。我们发现，单总线结构容易扩展成多CPU系统。2.多总线结构单总线系统中，由于所有的高速设备和低速设备都挂在同一总线上，且总线只能分时工作，即某一时间只能允许在一对儿设备之间传送数据，这就使信息传送的效率和吞吐量受到极大限制。为此出现了图6.2所示的多总线系统结构。图6.2中，CPU、存储器控制器和两个PCI-E桥通过接口与高速的前端总线(FSB)相连。总线桥是一种具有缓冲、转换、控制功能的逻辑电路。不同类型的桥扩展出不同层次的总线，并分别连接高速、中速和低速设备。图中的两个PCI-E桥分别连接图形处理器(GPU)和其他高速I/O设备。连接I/O设备的PCI-E总线又分别连接以太网设备控制器接口(DCI)、USB主机控制器接口、SATA(串行高级技术附件)桥、VGA(视频图形阵列)桥、DMA控制器和PCI总线扩展桥。SATA总线用于与SATA硬盘和光盘驱动器连接，PCI总线上连接的第二个USB主机控制器接口用于与USB键盘和USB鼠标相连。多总线结构确保高速、中速、低速设备连接到不同的总线上同时工作，以提高总线的效率和吞吐量，而且处理器结构的变化不影响高速总线。思考题你能说出多总线结构比单总线结构的创新点吗？早期总线的内部结构如图6.3所示，它实际上是处理器芯片引脚的延伸，是处理器与I/O设备适配器的通道。这种简单的总线一般也由50～100条信号线组成，这些信号线按其功能可分为三类：地址线、数据线和控制线。地址线是单向的，用来传送主存与设备的地址；数据线是双向的，用来传送数据；控制线一般而言对每一根线是单向的(CPU发向接口，或接口发向CPU)，用来指明数据传送的方向(存储器读、存储器写、I/O读、I/O写)、中断控制(请求、识别)和定时控制等。早期总线结构的不足之处在于：①CPU是总线上唯一的主控者。即使后来增加了具有简单仲裁逻辑的DMA控制器以支持DMA传送，但仍不能满足多CPU环境的要求。②总线信号是CPU引脚信号的延伸，故总线结构紧密与CPU相关，通用性较差。图6.4示出了当代流行的总线内部结构，它是一些标准总线，追求与结构、CPU、技术无关的开发标准，并满足包括多个CPU在内的主控者环境需求。在当代总线结构中，CPU和它私有的cache一起作为一个模块与总线相连。系统中允许有多个这样的处理器模块。而总线控制器完成多个总线请求者之间的协调与仲裁。整个总线分成如下四部分。数据传送总线由地址线、数据线、控制线组成。其结构与图6.3中的简单总线相似，但一般信号条数较多，如32条地址线，32或64条数据线。为了减少引脚数量，64位数据的低32位数据线常常和地址线采用多路复用方式。仲裁总线包括总线请求线和总线授权线。中断和同步总线用于处理带优先级的中断操作，包括中断请求线和中断认可线。公用线包括时钟信号线、电源线、地线、系统复位线以及加电或断电的时序信号线等。大多数计算机采用了分层次的多总线结构。在这种结构中，速度差异较大的设备模块使用不同速度的总线，而速度相近的设备模块使用同一类总线。显然，这种结构的优点在于不仅解决了总线负载过重的问题，而且使总线设计简单，并能充分发挥每类总线的效能。图6.5是Pentium计算机主板的总线结构框图。可以看出，它是一个三层次的多总线结构，即有CPU总线、PCI总线和ISA总线。CPU总线也称CPU-存储器总线，它是包含64位数据线和32位地址线的同步总线。总线时钟频率为66.6MHz(或60MHz)，CPU内部时钟是此时钟频率的倍频。此总线可连接4～128MB的主存。主存扩充容量是以内存条形式插入主板有关插座来实现的。CPU总线还接有L2级cache。主存控制器和cache控制器芯片用来管理CPU对主存和cache的存取操作。CPU是这条总线的主控者，但必要时可放弃总线控制权。从传统的观点看，可以把CPU总线看成是CPU引脚信号的延伸。PCI总线用于连接高速的I/O设备模块，如图形显示器适配器、网络接口控制器、硬盘控制器等。通过“桥”芯片，上面与更高速的CPU总线相连，下面与低速的ISA总线相接。PCI总线是一个32(或64)位的同步总线，32位(或64位)数据/地址线是同一组线，分时复用。总线时钟频率为33.3MHz，总线带宽是132MB/s。PCI总线采用集中式仲裁方式，有专用的PCI总线仲裁器。主板上一般有3个PCI总线扩充槽。ISA总线Pentium机使用该总线与低速I/O设备连接。主板上一般留有3～4个ISA总线扩充槽，以便使用各种16位/8位适配器卡。该总线支持7个DMA通道和15级可屏蔽硬件中断。另外，ISA总线控制逻辑还通过主板上的片级总线与实时钟/日历、ROM、键盘和鼠标控制器(8042微处理器)等芯片相连接。我们看到，CPU总线、PCI总线、ISA总线通过两个“桥”芯片连成整体。桥芯片在此起到了信号速度缓冲、电平转换和控制协议的转换作用。有的资料将CPU总线-PCI总线的桥称为北桥，将PCI总线-ISA总线的桥称为南桥。通过桥将两类不同的总线“粘合”在一起的技术特别适合于系统的升级换代。这样，每当CPU芯片升级时只需改变CPU总线和北桥芯片，全部原有的外围设备可自动继续工作。Pentium机总线系统中有一个核心逻辑芯片组，简称PCI芯片组，它包括主存控制器和cache控制器芯片、北桥芯片和南桥芯片。数字计算机使用二进制数，它们或用电位的高、低来表示，或用脉冲的有、无来表示。在前一种情况下，如果电位高时表示数字“1”，那么电位低时则表示数字“0”。在后一种情况下，如果有脉冲时表示数字“1”，那么无脉冲时就表示数字“0”。计算机系统中，传输信息一般采用串行传送或并行传送两种方式之一。但是出于速度和效率上的考虑，系统总线上传送的信息必须采用并行传送方式。1.串行传送当信息以串行方式传送时，只有一条传输线，且采用脉冲传送。在串行传送时，按顺序来传送表示一个数码的所有二进制位(bit)的脉冲信号，每次一位，通常以第一个脉冲信号表示数码的最低有效位，最后一个脉冲信号表示数码的最高有效位。图6.6(a)示出了串行传送的示意图。当串行传送时，有可能按顺序连续传送若干个“0”或若干个“1”。如果在编码时用有脉冲表示二进制数“1”，无脉冲表示二进制数“0”，那么当连续出现几个“0”时，表示某段时间间隔内传输线上没有脉冲信号。为了要确定传送了多少个“0”，必须采用某种时序格式，以便使接收设备能加以识别。通常采用的方法是指定位时间，即指定一个二进制位在传输线上占用的时间长度。显然，位时间是由同步脉冲来体现的。假定串行数据是由位时间组成的，那么传送8比特需要8个位时间。例如，如果接收设备在第一个位时间和第三个位时间接收到一个脉冲，而其余的6个位时间没有收到脉冲，那么就会知道所收到的二进制信息是00000101。注意，串行传送时低位在前，高位在后。在串行传送时，被传送的数据需要在发送部件进行并-串变换，这称为拆卸；而在接收部件又需要进行串-并变换，这称为装配。串行传送的主要优点是只需要一条传输线，这一点对长距离传输显得特别重要，不管传送的数据量有多少，只需要一条传输线，成本比较低廉。2.并行传送用并行方式传送二进制信息时，对每个数据位都需要单独一条传输线。信息由多少二进制位组成，就需要多少条传输线，从而使得二进制数“0”或“1”在不同的线上同时进行传送。并行传送的过程示于图6.6(b)。如果要传送的数据由8位二进制位组成(1字节)，那么就使用8条线组成的扁平电缆。每一条线分别代表了二进制数的不同位值。例如，最上面的线代表最高有效位，最下面的线代表最低有效位，因而图中正在传送的二进制数是10101100。并行传送一般采用电位传送。由于所有的位同时被传送，所以并行数据传送比串行数据传送快得多，例如，使用32条单独的地址线，可以从CPU的地址寄存器同时传送32位地址信息给主存。I/O功能模块通常简称为I/O接口，也叫适配器。广义地讲，I/O接口是指CPU、主存和外围设备之间通过系统总线进行连接的标准化逻辑部件。I/O接口在它动态连接的两个部件之间起着“转换器”的作用，以便实现彼此之间的信息传送。图6.7示出了CPU、I/O接口和外围设备之间的连接关系。外围设备本身带有自己的设备控制器，它是控制外围设备进行操作的控制部件。它通过I/O接口接收来自CPU传送的各种信息，并根据设备的不同要求把这些信息传送到设备，或者从设备中读出信息传送到I/O接口，然后送给CPU。由于外围设备种类繁多且速度不同，因而每种设备都有适应它自己工作特点的设备控制器。图6.7中将外围设备本体与它自己的控制电路画在一起，统称为外围设备。为了使所有的外围设备能在一起正确地工作，CPU规定了不同的信息传送控制方法。不管什么样的外围设备，只要选用某种数据传送控制方法，并按它的规定通过总线和主机连接，就可进行信息交换。通常在总线和每个外围设备的设备控制器之间使用一个适配器(接口)电路来解决这个问题，以保证外围设备用计算机系统特性所要求的形式发送和接收信息。因此接口逻辑必须标准化。一个标准I/O接口可能连接一个设备，也可能连接多个设备。图6.8是I/O接口模块的一般结构框图。它通常具有如下功能。控制接口模块靠指令信息来控制外围设备的动作，如启动、关闭设备等。缓冲接口模块在外围设备和计算机系统其他部件之间用作为一个缓冲器，以补偿各种设备在速度上的差异。状态接口模块监视外围设备的工作状态并保存状态信息。状态信息包括数据“准备就绪”“忙”“错误”等，供CPU询问外围设备时进行分析之用。转换接口模块可以完成任何要求的数据转换，如并-串转换或串-并转换，因此数据能在外围设备和CPU之间正确地进行传送。整理接口模块可以完成一些特别的功能，例如，在需要时可以修改字计数器或当前内存地址寄存器。程序中断每当外围设备向CPU请求某种动作时，接口模块即发生一个中断请求信号到CPU。例如，如果设备完成了一个操作或设备中存在着一个错误状态，接口即发出中断。事实上，一个I/O接口模块有两个接口：一是和系统总线的接口。CPU和I/O接口模块的数据交换一定是并行方式；二是和外设的接口。I/O接口模块和外设的数据交换可能是并行方式，也可能是串行方式。因此，根据外围设备供求串行数据或并行数据的方式不同，I/O接口模块分为串行数据接口和并行数据接口两大类。连接到总线上的功能模块有主动和被动两种形态。如CPU模块，它在不同的时间可以用作主方，也可用作从方；而存储器模块只能用作从方。主方(主设备)可以启动一个总线周期，而从方(从设备)只能响应主方的请求。每次总线操作，只能有一个主方占用总线控制权，但同一时间里可以有一个或多个从方。我们知道，除CPU模块外，I/O模块也可提出总线请求。为了解决多个主设备同时竞争总线控制权的问题，必须具有总线仲裁部件，以某种方式选择其中一个主设备作为总线的下一次主方。对多个主设备提出的占用总线请求，一般采用优先级或公平策略进行仲裁。例如，在多处理器系统中对各CPU模块的总线请求采用公平的原则来处理，而对I/O模块的总线请求采用优先级策略。被授权的主方在当前总线业务一结束，即接管总线控制权，开始新的信息传送。主方持续控制总线的时间称为总线占用期。按照总线仲裁电路的位置不同，仲裁方式分为集中式仲裁和分布式仲裁两类。集中式仲裁中每个功能模块有两条线连到总线控制器：一条是送往仲裁器的总线请求信号线BR，一条是仲裁器送出的总线授权信号线BG。链式查询方式为减少总线授权线数量，采用了图6.10(a)所示的菊花链查询方式，其中A表示地址线，D表示数据线。BS线为1，表示总线正被某外设使用。链式查询方式的主要特点是，总线授权信号BG串行地从一个I/O接口传送到下一个I/O接口。假如BG到达的接口无总线请求，则继续往下查询；假如BG到达的接口有总线请求，BG信号便不再往下查询。这意味着该I/O接口就获得了总线控制权。作为思考题，读者不妨画出链式查询电路的逻辑结构图。显然，在查询链中离总线仲裁器最近的设备具有最高优先级，离总线仲裁器越远，优先级越低。因此，链式查询是通过接口的优先级排队电路来实现的。链式查询方式的优点是，只用很少几根线就能按一定优先次序实现总线仲裁，并且这种链式结构很容易扩充设备。链式查询方式的缺点是对询问链的电路故障很敏感，如果第i个设备的接口中有关链的电路有故障，那么第i个以后的设备都不能进行工作。另外查询链的优先级是固定的，如果优先级高的设备出现频繁的请求，那么优先级较低的设备可能长期不能使用总线。计数器定时查询方式计数器定时查询方式原理示于图6.10(b)。总线上的任一设备要求使用总线时，通过BR线发出总线请求。总线仲裁器接到请求信号以后，在BS线为“0”的情况下让计数器开始计数，计数值通过一组地址线发向各设备。每个设备接口都有一个设备地址判别电路，当地址线上的计数值与请求总线的设备地址相一致时，该设备置“1”BS线，获得了总线使用权，此时中止计数查询。每次计数可以从“0”开始，也可以从中止点开始。如果从“0”开始，各设备的优先次序与链式查询法相同，优先级的顺序是固定的。如果从中止点开始，则每个设备使用总线的优先级相等。计数器的初值也可用程序来设置，这就可以方便地改变优先次序，显然这种灵活性是以增加线数为代价的。独立请求方式独立请求方式原理示于图6.10(c)。在独立请求方式中，每一个共享总线的设备均有一对总线请求线BRi和总线授权线BGi。当设备要求使用总线时，便发出该设备的请求信号。总线仲裁器中有一个排队电路，它根据一定的优先次序决定首先响应哪个设备的请求，给设备以授权信号BGi。独立请求方式的一个优点是响应时间快，即确定优先响应的设备所花费的时间少，用不着一个设备接一个设备地查询。另一个优点是对优先次序的控制相当灵活。它可以预先固定，如BR0优先级最高，BR1次之……BRn最低；也可以通过程序来改变优先次序；还可以用屏蔽(禁止)某个请求的办法，不响应来自无效设备的请求。因此当代总线标准普遍采用独立请求方式。对于单处理器系统总线而言，总线仲裁器又称为总线控制器，它是CPU的一部分，一般是一个单独的功能模块，如图6.4所示。思考题三种集中式仲裁方式中，哪种方式效率最高？为什么？分布式仲裁不需要集中的总线仲裁器，每个潜在的主方功能模块都有自己的仲裁号和仲裁器。当它们有总线请求时，把它们唯一的仲裁号发送到共享的仲裁总线上，每个仲裁器将仲裁总线上得到的号与自己的号进行比较。如果仲裁总线上的号大，则它的总线请求不予响应，并撤销它的仲裁号。最后，获胜者的仲裁号保留在仲裁总线上。显然，分布式仲裁是以优先级仲裁策略为基础的。(1)所有参与本次竞争的各主设备(本例中共8个)将设备竞争号CN取反后打到仲裁总线AB上，以实现“线或”逻辑。AB线低电平时表示至少有一个主设备的CNi为1，AB线高电平时表示所有主设备的CNi为0。(2)竞争时CN与AB逐位比较，从最高位(b7)至最低位(b0)以一维菊花链方式进行，只有上一位竞争得胜者Wi+1位为1。当CNi=1，或CNi=0且ABi为高电平时，才使Wi位为1。若Wi=0时，将一直向下传递，使其竞争号后面的低位不能送上AB线。(3)竞争不到的设备自动撤除其竞争号。在竞争期间，由于W位输入的作用，各设备在其内部的CN线上保留其竞争号并不破坏AB线上的信息。(4)由于参加竞争的各设备速度不一致，这个比较过程反复(自动)进行，才有最后稳定的结果。竞争期的时间要足够，保证最慢的设备也能参与竞争。总线的一次信息传送过程，大致可分为如下五个阶段：请求总线，总线仲裁，寻址(目的地址)，信息传送，状态返回(或错误报告)。为了同步主方、从方的操作，必须制订定时协定。所谓定时，是指事件出现在总线上的时序关系。下面介绍数据传送过程中采用的几种定时协定：同步定时协定、异步定时协定、半同步定时协定和周期分裂式总线协定。1.同步总线定时协定在同步定时协议中，事件出现在总线上的时刻由总线时钟信号来确定，所以总线中包含时钟信号线。一次I/O传送被称为时钟周期或总线周期。图6.12表示读数据的同步时序例子，所有事件都出现在时钟信号的前沿，大多数事件只占据单一时钟周期。例如，在总线读周期，CPU首先将存储器地址放到地址线上，它亦可发出一个启动信号，指明控制信息和地址信息已出现在总线上。第2个时钟周期发出一个读命令。存储器模块识别地址码，经一个时钟周期延迟(存取时间)后，将数据和认可信息放到总线上，被CPU读取。如果是总线写周期，CPU在第2个时钟周期开始将数据放到数据线上，待数据稳定后CPU发出一个写命令，存储器模块在第3个时钟周期存入数据。由于采用了公共时钟，每个功能模块什么时候发送或接收信息都由统一时钟规定，因此，同步定时具有较高的传输频率。同步定时适用于总线长度较短、各功能模块存取时间比较接近的情况。这是因为同步方式对任何两个功能模块的通信都给予同样的时间安排。由于同步总线必须按最慢的模块来设计公共时钟，当各功能模块存取时间相差很大时，会大大损失总线效率。2.异步总线定时协定在异步定时协议中，后一事件出现在总线上的时刻取决于前一事件的出现时刻，即建立在应答式或互锁机制基础上。在这种系统中，不需要统一的公共时钟信号。总线周期的长度是可变的。图6.13(a)表示系统总线读周期时序图。CPU发送地址信号和读状态信号到总线上。待这些信号稳定后，它发出读命令，指示有效地址和控制信号的出现。存储器模块进行地址译码并将数据放到数据线上。一旦数据线上的信号稳定，则存储器模块使确认线有效，通知CPU数据可用。CPU由数据线上读取数据后，立即撤销读状态信号，从而引起存储器模块撤销数据和确认信号。最后，确认信号的撤销又使CPU撤销地址信息。图6.13(b)表示系统总线写周期时序图。CPU将数据放到数据线上，与此同时启动状态线和地址线。存储器模块接受写命令从数据线上写入数据，并使确认线上信号有效。然后，CPU撤销写命令，存储器模块撤销确认信号。异步定时的优点是总线周期长度可变，不把响应时间强加到功能模块上，因而允许快速和慢速的功能模块都能连接到同一总线上。但这以增加总线的复杂性和成本为代价。思考题你能说出同步定时与异步定时各自的应用环境吗？3.半同步总线定时协定同步总线的优点是控制简单，传输速率通常较高，但不适用于速度差异较大的设备。如果在总线上传输的大部分设备的速度相当，仅有很少的设备需要较长的传输时间，则可以在同步总线定时协定的基础上稍加改动，扩展为半同步总线定时协定。半同步总线整体上仍然采用同步操作方式，其总线周期是时钟周期的整数倍。不同之处在于增加一根联络信号线，如高电平有效的准备好信号READY(或者低电平有效的等待信号nWAIT))，由此信号决定是否需要增加时钟周期。图6.15为某种半同步总线的操作时序图。从图中可以看出，基本的总线传输周期由T1到T4四个时钟周期构成，但如果某个设备来不及在四个时钟周期内完成总线操作，可以使READY信号无效(或者nWAIT信号有效)以增加时钟周期数。总线控制逻辑在T3的前沿检测READY引脚是否有效：如果READY有效，则在T3时钟周期后进入T4时钟周期；如果READY无效，则在T3和T4之间插入一个等待周期Tw，并在Tw前沿再次检测READY引脚是否有效，直到READY有效后才进入T4时钟周期。半同步总线协定在同步总线协定的基础上仅仅增加了一点点成本，但适应能力却大大提升。因此，现代的许多同步总线都已扩展为半同步总线。4.周期分裂式总线定时协定分析图6.12中的同步总线读操作时序可以看出，在第一个时钟周期CPU送出地址信息和最后一个时钟周期存储器送出数据之间，通常有若干个时钟周期的延迟时间。这是存储器内部准备数据的操作时间，占用的时钟周期数取决于存储器自身的速度。但是这部分时间实际上并不需要占用总线传输数据，因而宝贵的总线资源被浪费了。故在对总线性能要求非常高的系统中，可以将每个读周期分为三步：①主方通过总线向从方发送地址和读命令；②从方根据命令进行内部读操作，这是从方执行读命令的数据准备时间；③从方通过数据总线向主方提供数据。相应地，将一个读周期分解成两个分离的传输子周期：第一个子周期，主方发送地址和命令及有关信息后，立即和总线断开，供其他设备使用；第二个子周期，被读出的设备重新申请总线使用权后将数据通过总线发向请求数据的设备。而写周期只需要第一个子周期即可完成。在分离式总线定时协定中，由于每个设备都要申请总线使用权，故读数据的双方都是总线主方。分离式总线定时协定以硬件复杂度的提高换取总线性能的提升。当代的总线标准大都能支持以下四类模式的数据传送，如图6.16所示。读、写操作读操作是由从方到主方的数据传送；写操作是由主方到从方的数据传送。一般，主方先以一个总线周期发出命令和从方地址，经过一定的延时再开始数据传送总线周期。为了提高总线利用率，减少延时损失，主方完成寻址总线周期后可让出总线控制权，以使其他主方完成更紧迫的操作。然后再重新竞争总线，完成数据传送总线周期。块传送操作只需给出块的起始地址，然后对固定块长度的数据一个接一个地读出或写入。对于CPU(主方)-存储器(从方)而言的块传送，常称为突发(猝发)式传送，其块长一般固定为数据线宽度(存储器字长)的4倍。例如，一个64位数据线的总线，一次猝发式传送可达256位。这在超标量流水中十分有用。写后读、读修改写操作这是两种组合操作。只给出地址一次(表示同一地址)，或进行先写后读操作，或进行先读后写操作。前者用于校验目的，后者用于多道程序系统中对共享存储资源的保护。这两种操作和猝发式操作一样，主方掌管总线直到整个操作完成。广播、广集操作一般而言，数据传送只在一个主方和一个从方之间进行。但有的总线允许一个主方对多个从方进行写操作，这种操作称为广播。与广播相反的操作称为广集，它将选定的多个从方数据在总线上完成AND或OR操作，用以检测多个中断源。图6.17示出了典型的多总线结构框图。实际上，这也是PC机和服务器的主板总线的经典结构。如图6.17所示，整个系统有如下三种不同的总线。HOST总线该总线有CPU总线、系统总线、主存总线、前端总线等多种名称，各自反映了总线功能的一个方面。这里称“宿主”总线，也许更全面，因为HOST总线不仅连接主存，还可以连接多个CPU。HOST总线是连接“北桥”芯片与CPU之间的信息通路，它是一个64位数据线和32位地址线的同步总线。32位的地址线可支持处理器4GB的存储寻址空间。总线上还接有L2级cache，主存与cache控制器芯片。后者用来管理CPU对主存和cache的存取操作。CPU拥有HOST总线的控制权，但在必要情况下可放弃总线控制权。PCI总线连接各种高速的PCI设备。PCI是一个与处理器无关的高速外围总线，又是至关重要的层间总线。它采用同步时序协议和集中式仲裁策略，并具有自动配置能力。PCI设备可以是主设备，也可以是从设备，或兼而有之。在PCI设备中不存在DMA(直接存储器传送)的概念，这是因为PCI总线支持无限的猝发式传送。这样，传统总线上用DMA方式工作的设备移植到PCI总线上时，采用主设备工作方式即可。系统中允许有多条PCI总线，它们可以使用HOST桥与HOST总线相连，也可使用PCI/PCI桥与已和HOST总线相连的PCI总线相连，从而得以扩充整个系统的PCI总线负载能力。LEGACY总线可以是ISA、EISA、MCA等这类性能较低的传统总线，以便充分利用市场上丰富的适配器卡，支持中、低速I/O设备。在PCI总线体系结构中有三种桥。其中HOST桥又是PCI总线控制器，含有中央仲裁器。桥起着重要的作用，它连接两条总线，使彼此间相互通信。桥又是一个总线转换部件，可以把一条总线的地址空间映射到另一条总线的地址空间上，从而使系统中任意一个总线主设备都能看到同样的一份地址表。桥本身的结构可以十分简单，如只有信号缓冲能力和信号电平转换逻辑，也可以相当复杂，如有规程转换、数据快存、装拆数据等。PCI总线的基本传输机制是猝发式传送，利用桥可以实现总线间的猝发式传送。写操作时，桥把上层总线的写周期先缓存起来，以后的时间再在下层总线上生成写周期，即延迟写。读操作时，桥可早于上层总线，直接在下层总线上进行预读。无论延迟写和预读，桥的作用可使所有的存取都按CPU的需要出现在总线上。由上可见，以桥连接实现的PCI总线结构具有很好的扩充性和兼容性，允许多条总线并行工作。它与处理器无关，不论HOST总线上是单CPU还是多CPU，也不论CPU是什么型号，只要有相应的HOST桥芯片(组)，就可与PCI总线相连。思考题多总线结构中“桥”起着何种作用？你怎样看待北桥和南桥？表6.1列出了PCI标准2.0版的必有类信号名称及其功能描述。它采用32～64位数据线和32位地址线，数据线和地址线是一组线，分时复用。使用同步时序协议，总线时钟为方波信号，频率为33.3MHz。总线所有事件都出现在时钟信号的下跳沿，正好是时钟周期的中间。采样发生在时钟信号的上跳沿。PCI采用集中式仲裁方式，每个PCI主设备都有总线请求REQ#和授权GNT#两条信号线与中央仲裁器相连。符号#表示信号低电平有效，in表示输入线，out表示输出线，t/s表示双向三态信号线，s/t/s表示一次只被一个拥有者驱动的抑制三态信号线，o/d表示开路驱动，允许多个设备以线或方式共享此线。总线周期类型由C/nBE线上的总线命令给出。总线周期长度由周期类型和nFRAME(帧)、nIRDY(主就绪)、nTRDY(目标就绪)、nSTOP(停止)等信号控制。一个总线周期由一个地址期和一个或多个数据期组成。启动此总线周期的主设备，在地址期送出总线命令和目标设备地址，而目标设备以nDEVSEL(设备选择)信号予以响应。还有一个IDSEL(初始化设备选择)信号，用以配置读写期间的芯片选择。除必有类信号外，还有16种可选类信号线。除一组信号线用于扩充到64位传送外，其他三组信号分别用于cache一致性支持、中断请求、测试与边界扫描。其中，中断请求信号线是开路驱动，允许多个设备共享一条中断请求信号线。有关中断的概念留在第7章介绍。电源线和地线未列入表中。2.0版定义了5V和3.3V两种信号环境，更新的版本均使用3.3V工作电压。PCI总线周期由当前被授权的主设备发起。PCI支持任何主设备和从设备之间点到点的对等访问，也支持某些主设备的广播读写。PCI总线周期类型由主设备在C/BE[3—0]线上送出的4位总线命令代码指明，被目标设备译码确认，然后主从双方协调配合完成指定的总线周期操作。4位代码组合可指定16种总线命令，但实际给出12种。PCI总线命令类型如表6.2所示。存储器读/写总线周期以猝发式传送为基本机制，一次猝发式传送总线周期通常由一个地址期和一个或几个数据周期组成。存储器读/写周期的解释，取决于PCI总线上的存储器控制器是否支持存储器/cache之间的PCI传输协议。如果支持，则存储器读/写一般是通过cache来进行；否则，是以数据块非缓存方式来传输。存储器写和使无效周期与存储器写周期的区别在于，前者不仅保证一个完整的cache行被写入，而且在总线上广播“无效”信息，命令其他cache中的同一行地址变为无效。关于存储器读的三个总线周期的说明示于表6.3中。特殊周期用于主设备将其信息(如状态信息)广播到多个目标方。它是一个特殊的写操作，不需要目标方以nDEVSEL信号响应。但各目标方须立即使用此信息，无权中止此写操作过程。配置读/写周期是PCI具有自动配置能力的体现。PCI有三个相互独立的物理地址空间，即存储器、I/O、配置空间。所有PCI设备必须提供配置空间，而多功能设备要为每一实现功能提供一个配置空间。配置空间是256个内部寄存器，用于保存系统初始化期间设置的配置参数。CPU通过HOST桥的两个32位专用寄存器(配置地址、配置数据)来访问PCI设备的配置空间。即HOST桥根据CPU提供给这两个寄存器的值，生成PCI总线的配置读/写周期，完成配置数据的读出或写入操作。双地址周期用于主方指示它正在使用64位地址。下面以数据传送类的总线周期为代表，说明PCI总线周期的操作过程。为了深化概念，图6.18中给出了一个读操作总线周期时序示例。图中的环形箭头符号表示某信号线由一个设备驱动转换成另一设备驱动的过渡期，以此过渡期避免两个设备同时驱动一条信号线的冲突。我们看到，PCI总线周期的操作过程有如下特点。(1)采用同步时序协议。总线时钟周期以上跳沿开始，半个周期高电平，半个周期低电平。总线上所有事件，即信号电平转换出现在时钟信号的下跳沿时刻，而对信号的采样出现在时钟信号的上跳沿时刻。(2)总线周期由被授权的主方启动，以帧nFRAME信号变为有效来指示一个总线周期的开始。(3)一个总线周期由一个地址期和一个或多个数据期组成。在地址期内除给出目标地址外，还在C/BE#线上给出总线命令以指明总线周期类型。(4)地址期为一个总线时钟周期，一个数据期在没有等待状态下也是一个时钟周期。一次数据传送是在挂钩信号nIRDY和nTRDY都有效情况下完成，任一信号无效(在时钟上跳沿被对方采样到)，都将加入等待状态。(5)总线周期长度由主方确定。在总线周期期间nFRAME持续有效，但在最后一个数据期开始前撤除。即以nFRAME无效后，nIRDY也变为无效的时刻表明一个总线周期结束。由此可见，PCI的数据传送以猝发式传送为基本机制，单一数据传送反而成为猝发式传送的一个特例。并且PCI具有无限制的猝发能力，猝发长度由主方确定，没有对猝发长度加以固定限制。(6)主方启动一个总线周期时要求目标方确认。即在nFRAME变为有效和目标地址送上AD线后，目标方在延迟一个时钟周期后必须以nDEVSEL信号有效予以响应。否则，主设备中止总线周期。(7)主方结束一个总线周期时不要求目标方确认。目标方采样到nFRAME信号已变为无效时，即知道下一数据传送是最后一个数据期。目标方传输速度跟不上主方速度，可用nTRDY无效通知主方加入等待状态时钟周期。当目标方出现故障不能进行传输时，以nSTOP信号有效通知主方中止总线周期。PCI总线采用集中式仲裁方式，每个PCI主设备都有独立的nREQ(总线请求)和nGNT(总线授权)两条信号线与中央仲裁器相连。由中央仲裁器根据一定的算法对各主设备的申请进行仲裁，决定把总线使用权授予谁。但PCI标准并没有规定仲裁算法。中央仲裁器不仅采样每个设备的nREQ信号线，而且采样公共的nFRAME和nIRDY信号线。因此，仲裁器清楚当前总线的使用状态：是处于空闲状态还是一个有效的总线周期。PCI总线支持隐藏式仲裁。即在主设备A正在占用总线期间，中央仲裁器根据指定的算法裁决下一次总线的主方应为主设备B时，它可以使nGNT-A无效而使nGNT-B有效。此时，设备A应在数据传送完成后立即释放nFRAME和nIRDY信号线，由设备B掌管后开始一个新的总线周期。隐藏式仲裁使裁决过程或在总线空闲期进行或在当前总线周期内进行，不需要单独的仲裁总线周期，提高了总线利用率。中央仲裁器使nGNT-A无效与nGNT-B有效之间至少有1个时钟周期的延迟，以保证信号线由A驱动变为B驱动时在临界情况下也不产生冲突，即上述的交换期。一个提出申请并被授权的主设备，应在nFRAME、nIRDY线已释放的条件下尽快开始新的总线周期操作。自nFRAME、nIRDY信号变为无效开始，16个时钟周期内信号仍不变为有效，中央仲裁器认为被授权的主设备为“死设备”，并收回授权，以后也不再授权给该设备。相比早期的ISA和EISA等第一代总线，PCI总线的传输速度有明显提升。但是计算机系统对传输性能的要求仍在不断提升中，PCI总线逐渐难以满足高速显卡等高性能传输模块的性能要求。于是，第三代的PCIe总线逐渐取代了PCI总线。PCIe总线全称为PCI-Express，是基于PCI总线技术发展起来的总线标准，对PCI总线有良好的继承性，在软件和应用上兼容PCI总线。与PCI总线相比，PCIe总线的主要改进有如下几点。(1)高速差分传输。与PCI总线使用的单端信号对地传输方式相比，PCIe总线改用差分信号进行数据传送，一个信号由D+和D–两根信号线传输，信号接收端通过比较这两个信号的差值判断发送端发送的是逻辑“1”还是逻辑“0”。由于外部干扰噪声将同时附加到D+和D–两根信号上，因而在理论上并不影响二者的差值，对外界的电磁干扰也比较小。因此差分信号抗干扰的能力更强，可以使用更高的总线频率。PCIe总线还引入了嵌入时钟技术，发送端不向接收端传输时钟信号，而是通过8b/10b或128b/130b编码将时钟信息嵌入数据信号中，接收端可以从数据中恢复出时钟。(2)串行传输。由于并行传输方式使用更多的信号线进行传输，因而理论上并行传输的速率比串行传输更高。但是并行总线通常需要在系统底板上进行复杂的走线，随着信号传输速度的提高，不同长度或在PCB板不同层布放的导线引起的定时偏差的影响和并行导线之间存在的相互干扰变得越来越严重，限制了信号传输的最高速率。而串行传输方式在每个方向只有一个差分信号，且时钟信息嵌入在数据信号中，故不会出现定时偏移。因此，串行信号在有些情况下传输速度反而更高。与USB总线和SATA接口类似，PCIe总线也采用串行传输方式替代PCI总线的并行传输方式。(3)全双工端到端连接。与PCI的共享总线模式不同，PCIe链路使用端到端的数据传送方式，每一通道(Lane)只能连接两个设备，设备之间通过双向的链路相连接，每个传输通道独享带宽。如图6.19所示，PCIe总线的物理链路的一个通道由两组差分信号组成，发送端的发送器与接收端的接收器通过一对儿差分信号连接，接收端的发送器与发送端的接收器通过另外一对儿差分信号连接。PCIe支持全双工通信，允许在同一时刻同时进行数据发送和接收。(4)基于多通道的数据传递方式。一个PCIe链路可以由多条通道组成，目前可支持×1、×2、×4、×8、×12、×16和×32宽度的PCIe链路。不同的PCIe总线规范所定义的总线频率和链路编码方式并不相同，PCIe1.0规范中，×1单通道单向传输带宽可达到250MB/s。多通道设计增加了灵活性，较慢的设备可以分配较少的通道。(5)基于数据包的传输。作为串行通信总线，PCIe所有的数据都是以数据包为单位进行传输的。一个完整的PCIe体系结构由上到下包括应用层、事务层、数据链路层和物理层，如图6.20所示。图6.21为PCIe总线的拓扑结构实例。可以看出，PCIe总线上包括四类实体：根复合体、交换器、PCIe桥和端点。根复合体(RootComplex)是PCIe的根控制器，将处理器/内存子系统连接到PCIe交换结构。一个根复合体可能包含多个PCIe端口，可将多个交换器连接到根复合体或级联的端口。PCIe总线采用基于交换的技术，交换器(Switch)可以扩展PCIe总线，PCIe总线系统可以通过交换器连接多个PCIe设备。PCIe桥(PCIebrige)负责PCIe和其他总线之间的转换，PCIe总线系统可以通过PCIe桥扩展出传统的PCI总线或PCI-X总线。在PCIe总线中，基于PCIe总线的设备称为端点(Endpoint)，如PCIe接口网卡、串口卡、存储卡等。端点处于PCIe总线系统拓扑结构中的最末端，一般作为总线操作的发起者或者终结者，老旧端点(LegacyEndpoint)则是指那些原本准备设计用于PCI-X总线但却被改为PCIe接口的设备。此外，电源管理、服务质量(QoS)、热插拔支持、数据完整性、错误处理机制等也是PCIe总线所支持的高级特征。本章小结总线是构成计算机系统的互联机构，是多个系统功能部件之间进行数据传送的公共通道，并在争用资源的基础上进行工作。总线有物理特性、功能特性、电气特性、机械特性，因此必须标准化。微型计算机系统的标准总线从ISA总线(16位，带宽8MB/s)发展到EISA总线(32位，带宽33.3MB/s)和VESA总线(32位，带宽132MB/s)，又进一步发展到PCI总线(64位，带宽264MB/s)。衡量总线性能的重要指标是总线带宽，它定义为总线本身所能达到的最高传输速率。当代流行的标准总线追求与结构、CPU、技术无关的开发标准。其总线内部结构包含：①数据传送总线(由地址线、数据线、控制线组成)；②仲裁总线；③中断和同步总线；④公用线(电源、地线、时钟、复位等信号线)。计算机系统中，根据应用条件和硬件资源不同，信息的传输方式可采用：①并行传送；②串行传送；③复用传送。各种外围设备必须通过I/O接口与总线相连。I/O接口是指CPU、主存、外围设备之间通过总线进行连接的逻辑部件。接口部件在它动态联结的两个功能部件间起着缓冲器和转换器的作用，以便实现彼此之间的信息传送。InfiniBand标准InfiniBand通信协议栈总线仲裁是总线系统的核心问题之一。为了解决多个主设备同时竞争总线控制权的问题，必须具有总线仲裁部件。它通过采用优先级策略或公平策略，选择其中一个主设备作为总线的下一次主方，接管总线控制权。按照总线仲裁电路的位置不同，总线仲裁分为集中式仲裁和分布式仲裁。集中式仲裁方式必有一个中央仲裁器，它受理所有功能模块的总线请求，按优先原则或公平原则进行排队，然后仅给一个功能模块发出授权信号。分布式仲裁不需要中央仲裁器，每个功能模块都有自己的仲裁号和仲裁器。总线定时是总线系统的核心问题之一。为了同步主方、从方的操作，必须制订定时协议，通常采用同步定时与异步定时两种方式。在同步定时协议中，事件出现在总线上的时刻由总线时钟信号来确定，总线周期的长度是固定的。在异步定时协议中，后一事件出现在总线上的时刻取决于前一事件的出现时刻，即建立在应答式或互锁机制基础上，不需要统一的公共时钟信号。在异步定时中，总线周期的长度是可变的。当代的总线标准大都能支持以下数据传送模式：①读/写操作；②块传送操作；③写后读、读修改写操作；④广播、广集操作。PCI总线是当前实用的总线，是一个高带宽且与处理器无关的标准总线，又是重要的层次总线。它采用同步定时协议和集中式仲裁策略，并具有自动配置能力。PCI适合于低成本的小系统，因此在微型机系统中得到了广泛的应用。PCI总线的升级版PCIe总线在许多方面进行了改进，其性能得到大幅度提升。外围设备这个术语涉及相当广泛的计算机部件。事实上，除了CPU和主存外，计算机系统的每一部分都可作为一个外围设备来看待。20世纪末，主机与外围设备的价格比为1∶6。这种情况表明：一方面，在计算机的发展中，外围设备的发展占有重要地位；另一方面，外围设备的发展同主机的发展还不相适应。尽管如此，外围设备还是得到了较快的发展。在指标上，外围设备不断采用新技术，向低成本、小体积、高速、大容量、低功耗等方面发展。在结构上，由初级的串行操作输入/输出方式，发展到有通道连接的多种外设并行操作方式。在种类上，由简单的输入/输出装置，发展到多种输入/输出装置、随机存取大容量外存、多种终端设备，等等。在性能上，信息交换速度大大提高，输入输出形态不仅有数字形式，还有直观的图像和声音等形式。外围设备的功能是在计算机和其他机器之间，以及计算机与用户之间提供联系。没有外围设备的计算机就像缺乏五官四肢的人一样，既不能从外界接收信息，又不能对处理的结果做出表达和反应。随着计算机系统的飞速发展和应用的扩大，系统要求外围设备类型越来越多，外围设备智能化的趋势越来越明显，特别是出现多媒体技术以后。毫无疑问，随着科学技术的发展，提供人-机联系的外围设备将会变成计算机真正的“五官四肢”。一般说来，外围设备由三个基本部分组成。(1)存储介质，具有保存信息的物理特征。例如，磁盘，用记录在盘上的磁化元表示信息。(2)驱动装置，用于移动存储介质。例如，磁盘设备中，驱动装置用于转动磁盘并进行定位。(3)控制电路，向存储介质发送数据或从存储介质接收数据。例如，磁盘读出时，控制电路把盘上用磁化元形式表示的信息转换成计算机所需要的电信号，并把这些信号用电缆一个计算机系统配备什么样的外围设备，是根据实际需要来决定的。图7.1示出了计算机的五大类外围设备，这只是一个典型化了的计算机环境。如图7.1所示，中央部分是CPU和主存，通过系统总线与第二层的适配器(接口)部件相连，第三层是各种外围设备控制器，最外层则是外围设备。外围设备可分为输入设备、输出设备、外存设备、数据通信设备和过程控制设备几大类。表7.1列出了各种I/O设备名称、功能及数据传输速率。每一种外围设备，都是在它自己的设备控制器控制下进行工作的，而设备控制器则通过I/O接口和主机连接，并受主机控制。计算机的外存储器又称磁表面存储设备。所谓磁表面存储，是用某些磁性材料薄薄地涂在金属铝或塑料表面作载磁体来存储信息。磁盘存储器、磁带存储器均属于磁表面存储器。磁表面存储器的优点：①存储容量大，位价格低；②记录介质可以重复使用；③记录信息可以长期保存而不丢失，甚至可以脱机存档；④非破坏性读出，读出时不需要再生信息。当然，磁表面存储器也有缺点，主要是存取速度较慢，机械结构复杂，对工作环境要求较高。磁表面存储器由于存储容量大，位成本低，在计算机系统中作为辅助大容量存储器使用，用以存放系统软件、大型文件、数据库等大量程序与数据信息。1.磁性材料的物理特性在计算机中，用于存储设备的磁性材料，是一种具有矩形磁滞回线的磁性材料。这种磁性材料在外加磁场的作用下，其磁感应强度B与外加磁场H的关系，可用矩形磁滞回线来描述，如图7.2所示。从磁滞回线可以看出，磁性材料被磁化以后，工作点总是在磁滞回线上。只要外加的正向脉冲电流(即外加磁场)幅度足够大，那么在电流消失后磁感应强度B并不等于零，而是处在+Br状态(正剩磁状态)。反之，当外加负向脉冲电流时，磁感应强度B将处在–Br状态(负剩磁状态)。这就是说，当磁性材料被磁化后，会形成两个稳定的剩磁状态，就像触发器电路有两个稳定的状态一样。利用这两个稳定的剩磁状态，可以表示二进制代码1和0。如果规定用+Br状态表示代码“1”，–Br状态表示代码“0”，那么要使磁性材料记忆“1”，就要加正向脉冲电流，使磁性材料正向磁化；要使磁性材料记忆“0”，则要加负向脉冲电流，使磁性材料反向磁化。磁性材料上呈现剩磁状态的地方形成了一个磁化元或存储元，它是记录一个二进制信息位的最小单位。2.磁表面存储器的读写原理在磁表面存储器中，利用一种称为“磁头”的装置来形成和判别磁层中的不同磁化状态。换句话说，写入时，利用磁头使载磁体(盘片)具有不同的磁化状态，而在读出时又利用磁头来判别这些不同的磁化状态。磁头实际上是由软磁材料做铁芯绕有读写线圈的电磁铁，如图7.3所示。写操作当写线圈中通过一定方向的脉冲电流时，铁芯内就产生一定方向的磁通。由于铁芯是高导磁率材料，而铁芯空隙处为非磁性材料，故在铁芯空隙处集中很强的磁场。如图7.3所示，在这个磁场作用下，载磁体就被磁化成相应极性的磁化位或磁化元。若在写线圈里通入相反方向的脉冲电流，就可得到相反极性的磁化元。如果我们规定按图中所示电流方向为写“1”，那么写线圈里通以相反方向的电流时即为写“0”。上述过程称为“写入”。显然，一个磁化元就是一个存储元，一个磁化元中存储一位二进制信息。当载磁体相对于磁头运动时，就可以连续写入一连串的二进制信息。读操作如何读出记录在磁表面上的二进制代码信息呢?也就是说，如何判断载磁体上信息的不同剩磁状态呢?当磁头经过载磁体的磁化元时，由于磁头铁芯是良好的导磁材料，磁化元的磁力线很容易通过磁头而形成闭合磁通回路。不同极性的磁化元在铁芯里的方向是不同的。当磁头对载磁体作相对运动时，由于磁头铁芯中磁通的变化，使读出线圈中感应出相应的电动势e，其值为ddekt(7.1)负号表示感应电势的方向与磁通的变化方向相反。不同的磁化状态，所产生的感应电势方向不同。这样，不同方向的感应电势经读出放大器放大鉴别，就可判知读出的信息是“1”还是“0”。图7.4示出了记录方式的写读过程波形图。归纳起来，通过电-磁变换，利用磁头写线圈中的脉冲电流，可把一位二进制代码转换成载磁体存储元的不同剩磁状态；反之，通过磁-电变换，利用磁头读出线圈，可将由存储元的不同剩磁状态表示的二进制代码转换成电信号输出。这就是磁表面存储器存取信息的原理。磁层上的存储元被磁化后，它可以供多次读出而不被破坏。当不需要这批信息时，可通过磁头把磁层上所记录的信息全部抹去，称为写“0”。通常，写入和读出是合用一个磁头，故称为读写磁头。每个读写磁头对应着一个信息记录磁道。硬磁盘是指记录介质为硬质圆形盘片的磁表面存储器。其逻辑结构如图7.5所示。此图中未反映出寻址机构，而仅仅表示了存取功能的逻辑结构，它主要由磁记录介质、磁盘控制器、磁盘驱动器三大部分组成。磁盘控制器包括控制逻辑与时序、数据并-串变换电路和串-并变换电路。磁盘驱动器包括写入电路与读出电路、读写转换开关、读写磁头与磁头定位伺服系统等。写入时，将计算机并行送来的数据取至并-串变换寄存器，变为串行数据，然后一位一位地由写电流驱动器作功率放大并加到写磁头线圈上产生电流，从而在盘片磁层上形成按位的磁化存储元。读出时，当记录介质相对磁头运动时，位磁化存储元形成的空间磁场在读磁头线圈中产生感应电势，此读出信息经放大检测就可还原成原来存入的数据。由于数据是一位一位串行读出的，故要送至串-并变换寄存器变换为并行数据，再并行送至计算机。硬磁盘按盘片结构，分成可换盘片式与固定盘片式两种；磁头也分为可移动磁头和固定磁头两种。可移动磁头固定盘片的磁盘机特点是一片或一组盘片固定在主轴上，盘片不可更换。盘片每面只有一个磁头，存取数据时磁头沿盘面径向移动。固定磁头磁盘机特点是磁头位置固定，磁盘的每一个磁道对应一个磁头，盘片不可更换。优点是存取速度快，省去磁头找道时间，缺点是结构复杂。可移动磁头可换盘片的磁盘机盘片可以更换，磁头可沿盘面径向移动。优点是盘片可以脱机保存，同种型号的盘片具有互换性。温彻斯特磁盘机温彻斯特磁盘简称温盘，是一种采用先进技术研制的可移动磁头固定盘片的磁盘机。它是一种密封组合式的硬磁盘，即磁头、盘片、电机等驱动部件乃至读写电路等组装成一个不可随意拆卸的整体。工作时，高速旋转在盘面上形成的气垫将磁头平稳浮起。优点是防尘性能好，可靠性高，对使用环境要求不高，成为最有代表性的硬磁盘存储器。而普通的硬磁盘要求具有超净环境，只能用于大型计算机中。常用的温盘盘片直径有5.25英寸、3.5英寸、2.5英寸、1.75英寸等几种。思考题温盘的发明具有划时代意义，你能说说为什么吗？磁盘驱动器它是一种精密的电子和机械装置，因此各部件的加工安装有严格的技术要求。对温盘驱动器，还要求在超净环境下组装。各类磁盘驱动器的具体结构虽然有差别，但基本结构相同，主要由定位驱动系统、主轴系统和数据转换系统组成。图7.6是磁盘驱动器外形和结构示意图。在可移动磁头的磁盘驱动器中，驱动磁头沿盘面径向位置运动以寻找目标磁道位置的机构称为磁头定位驱动系统，它由驱动部件、传动部件、运载部件(磁头小车)组成。当磁盘存取数据时，磁头小车的平移运动驱动磁头进入指定磁道的中心位置，并精确地跟踪该磁道。目前磁头小车的驱动方式主要采用步进电机和音圈电机两种。步进电机靠脉冲信号驱动，控制简单，整个驱动定位系统是开环控制，因此定位精度较低，一般用于道密度不高的硬磁盘驱动器。音圈电机是线性电机，可以直接驱动磁头作直线运动，整个驱动定位系统是一个带有速度和位置反馈的闭环控制系统，驱动速度快，定位精度高，因此用于较先进的磁盘驱动器。主轴系统的作用是安装盘片，并驱动它们以额定转速稳定旋转。其主要部件是主轴电机和有关控制电路。数据转换系统的作用是控制数据的写入和读出，包括磁头、磁头选择电路、读写电路以及索引、区标电路等。磁盘控制器它是主机与磁盘驱动器之间的接口，电路板实物如图7.7(a)所示。由于磁盘存储器是高速外存设备，故与主机之间采用成批交换数据方式。作为主机与驱动器之间的控制器，它需要有两个方面的接口：一个是与主机的接口，控制外存与主机总线之间交换数据；另一个是与设备的接口，根据主机命令控制设备的操作。前者称为系统级接口，后者称为设备级接口。主机与磁盘驱动器交换数据的控制逻辑见图7.7(b)。磁盘上的信息经读磁头读出以后送读出放大器，然后进行数据与时钟的分离，再进行串-并变换、格式变换，最后送入数据缓冲器，经DMA(直接存储器传送)控制将数据传送到主机总线。我们看到，磁盘控制器的功能全部转移到设备中，主机与设备之间采用标准的通用接口，如SCSI接口(小型计算机系统接口)，从而使设备相对独立。盘片的上下两面都能记录信息，通常把磁盘片表面称为记录面。记录面上一系列同心圆称为磁道。每个盘片表面通常有几百到几千个磁道，每个磁道又分为若干个扇区，如图7.8所示。从图中看出，外面扇区比里面扇区面积要大。磁盘上的这种磁道和扇区的排列称为格式。磁道的编址是从外向内依次编号，最外一个同心圆称为0磁道，最里面的一个同心圆称为n磁道，n磁道里面的圆面积并不用来记录信息。扇区的编号有多种方法，可以连续编号，也可间隔编号。磁盘记录面经这样编址后，就可用n磁道m扇区的磁盘地址找到实际磁盘上与之相对应的记录区。除了磁道号和扇区号，还有记录面的面号，以说明本次处理是在哪一个记录面上。例如，对活动头磁盘组来说，磁盘地址是由记录面号(也称磁头号)、磁道号和扇区号三部分组成的。在磁道上，信息是按区存放的，每个区中存放一定数量的字或字节，各个区存放的字或字节数是相同的。为进行读/写操作，要求定出磁道的起始位置，这个起始位置称为索引。索引标志在传感器检索下可产生脉冲信号，再通过磁盘控制器处理，便可定出磁道起始位置。磁盘存储器的每个扇区记录定长的数据，因此读/写操作是以扇区为单位一位一位串行进行的。每一个扇区记录一个记录块。数据在磁盘上的记录格式如图7.9所示。每个扇区开始时由磁盘控制器产生一个扇标脉冲。扇标脉冲的出现即标志一个扇区的开始。两个扇标脉冲之间的一段磁道区域即为一个扇区(一个记录块)。每个记录块由头部空白段、序标段、数据段、校验字段及尾部空白段组成。其中空白段用来留出一定的时间作为磁盘控制器的读写准备时间，序标被用来作为磁盘控制器的同步定时信号。序标之后即为本扇区所记录的数据。数据之后是校验字，它用来校验磁盘读出的数据是否正确。7.2.5磁盘存储器的技术指标磁盘存储器的主要技术指标包括存储密度、存储容量、存取时间及数据传输率。存储密度存储密度分道密度、位密度和面密度。道密度是沿磁盘半径方向单位长度上的磁道数，单位为道/英寸。位密度是磁道单位长度上能记录的二进制代码位数，单位为位/英寸。面密度是位密度和道密度的乘积，单位为位/英寸2。存储容量一个磁盘存储器所能存储的字节总数，称为磁盘存储器的存储容量。存储容量有格式化容量和非格式化容量之分。格式化容量是指按照某种特定的记录格式所能存储信息的总量，也就是用户可以真正使用的容量。非格式化容量是磁记录表面可以利用的磁化单元总数。将磁盘存储器用于某计算机系统中，必须首先进行格式化操作，然后才能供用户记录信息。格式化容量一般是非格式化容量的60%～70%，3.5英寸的硬盘容量可达数十TB。平均寻址时间寻址时间是指从读写命令发出后，磁头从某一起始位置移动至新的记录位置，再到磁道上需要访问的扇区移动到磁头下方所需的时间。这段时间包括寻道时间和等待时间。磁盘接到读/写指令后将磁头定位至所要访问的磁道上所需的时间，称为寻道时间或找道时间、定位时间。寻道完成后，磁道上需要访问的扇区移动到磁头下方所需的时间，称为等待时间或寻区时间、潜伏期、旋转延迟。这两个时间都是随机变化的，因此往往使用平均值来表示。平均寻道时间是最大寻道时间与最小寻道时间的平均值，一般由厂家给出，目前典型的平均寻道时间小于10ms。平均等待时间和磁盘转速有关，它用磁盘旋转一周所需时间的一半来表示。若r表示磁盘旋转速率，单位是转/秒，则平均等待时间为1/(2r)。转速为7200转/分的磁盘的平均等待时间约为4.16ms。平均存取时间存取(访问)时间是从读/写指令发出到开始第一笔数据读/写时所用的平均时间，包括寻道时间、等待时间及相关的内务操作时间。内务操作时间一般很短(一般在0.2ms左右)，可忽略不计。故平均访问时间近似等于平均寻道时间+平均等待时间，即平均寻址时间。因此，总的平均读写操作时间Ta可表示为式中，Ts表示平均寻道时间，b表示传送的字节数，N表示每磁道字节数，b/(rN)表示数据传输时间。数据传输率磁盘存储器在单位时间内向主机传送数据的字节数，称为数据传输率。现代磁盘设备通常会配置磁盘cache，单位时间内从硬盘cache向主机传送的数据信息量称为外部数据传输率，与磁盘的接口类型和磁盘缓存大小有关。从主机接口逻辑考虑，应有足够快的传送速度向设备发送或从设备接收信息。在磁盘存储器盘片上读写数据的速率则称为内部数据传输率，即磁头找到要访问的位置后，单位时间读/写的字节数，等于每个磁道上的字节数/磁盘旋转一周的时间。设磁盘旋转速度为n转/秒，每条磁道容量为N字节，则内部数据传输率为计算机组成原理224Dr=nN(字节/秒)或Dr=D·v(字节/秒)(7.3)其中，D为位密度，v为磁盘旋转的线速度。磁盘存储器的数据传输率可达几十兆字节/秒。1)磁盘cache的概念随着微电子技术的飞速发展，CPU的速度每年增长1倍左右，主存芯片容量和磁盘驱动器的容量每1.5年增长1倍左右。但磁盘驱动器的存取时间没有出现相应的下降，仍停留在毫秒(ms)级。而主存的存取时间为纳秒(ns)级，两者速度差别十分突出，因此磁盘I/O系统成为整个系统的瓶颈。为了减少存取时间，可采取的措施有：提高磁盘机主轴转速，提高I/O总线速度，采用磁盘cache(磁盘缓存)等。主存和CPU之间设置高速缓存cache是为了弥补主存和CPU之间速度上的差异。同样，磁盘cache是为了弥补慢速磁盘和主存之间速度上的差异。2)磁盘cache的原理在磁盘cache中，由一些数据块组成的一个基本单位称为cache行。当一个I/O请求送到磁盘驱动时，首先搜索驱动器上的高速缓冲行是否已写上数据？如果是读操作，且要读的数据已在cache中，则为命中，可从cache行中读出数据，否则需从磁盘介质上读出。写入操作和CPU中的cache类似，有“直写”和“写回”两种方法。磁盘cache利用了被访问数据的空间局部性和时间局部性原理。空间局部性是指当某些数据被存取时，该数据附近的其他数据可能也将很快被存取；时间局部性是指当一些数据被存取后，不久这些数据还可能再次存取。因此现在大多数磁盘驱动器中都使用了预读策略，而根据局部性原理预取一些不久将可能读入的数据放到磁盘cache中。CPU的cache存取时间一般小于10ns，命中率95%以上，全用硬件来实现。磁盘cache一次存取的数量大，数据集中，速度要求较CPU的cache低，管理工作较复杂，因此一般由硬件和软件共同完成。其中cache采用SRAM或DRAM。RAID最早称为廉价冗余磁盘阵列，后来改为独立冗余磁盘阵列，它是用多台磁盘存储器组成的大容量外存系统。其构造基础是利用数据分块技术和并行处理技术，在多个磁盘上交错存放数据，使之可以并行存取。在RAID控制器的组织管理下，可实现数据的并行存储、交叉存储、单独存储。由于阵列中的一部分磁盘存有冗余信息，一旦系统中某一磁盘失效，可以利用冗余信息重建用户信息。RAID是1988年由美国加州大学伯克利分校一个研究小组提出的，它的设计理念是用多个小容量磁盘代替一个大容量磁盘，并用分布数据的方法能够同时从多个磁盘中存取数据，因而改善了I/O性能，增加了存储容量，现已在超级或大型计算机中使用。工业上制定了一个称为RAID的标准，它分为7级(RAID0～RAID6)。这些级别不是表示层次关系，而是指出了不同存储容量、可靠性、数据传输能力、I/O请求速率等方面的应用需求。下面以RAID0级为例来说明。考虑到低成本比可靠性更重要，RAID0未采用奇偶校验等冗余技术。RAID0用于高速数据传输和高速I/O请求。对RAID0，用户和系统数据分布在阵列中的所有磁盘上。与单个大容量磁盘相比，其优点是：如果两个I/O请求正在等待两个不同的数据块，则被请求的块有可能在不同的盘上。因此，两个请求能够并行发出，减少了I/O排队的时间。图7.10表示使用磁盘阵列管理软件在逻辑磁盘和物理磁盘间进行映射。此软件可在磁盘子系统或主机上运行。所有的用户数据和系统数据都被看成是逻辑条带，存储在一个逻辑磁盘上。而实际物理磁盘也以条带形式划分，每个条带是一些物理的块、扇区或其他单位。数据条带以轮转方式映射到连续的阵列磁盘中。每个磁盘映射一条带，一组逻辑连续条带称为条带集。在一个有n个磁盘的阵列中，第1组的n个逻辑条带依次物理地存储在n个磁盘的第1个条带上，构成第1个条带集；第2组的n个逻辑条带分布在每个磁盘的第2个条带上；依次类推。这种布局的优点是，如果单个I/O请求由多个逻辑相邻的条带组成，则对多达n个条带的请求可以并行处理，从而大大减少了I/O的传输时间。磁带机的记录原理与磁盘机基本相同，只是它的载磁体是一种带状塑料，称为磁带。写入时可通过磁头把信息代码记录在磁带上。当记录有代码的磁带在磁头下移动时，就可在磁头线圈上感应出电动势，即读出信息代码。磁带存储设备由磁带机和磁带两部分组成，它通常用作为海量存储设备的数据备份。磁带速度比磁盘速度慢，原因是磁带上的数据采用顺序访问方式，而磁盘则采用随机访问方式。目前的磁带技术有如下几种类型。1)1/4英寸磁带(QIC)1/4英寸磁带看起来像家用录音带一样，内部有供带轮和收带轮。不同的是，QIC标准有36～72条磁道，数据并行记录，存储容量为80MB～1.2GB。最新技术通过增加磁带的长度和宽度，使磁带的存储容量达到4GB。QIC磁带驱动器使用3个磁头，即一个读磁头两侧各有一个写磁头，如图7.11所示。这种设计使磁带驱动器能在磁带往两个方向上运动时，都可以确认刚写入的数据。在规定的记录方式下，磁带以100英寸/秒的速度移动。磁带机的数据传输率D可用下式表示：D=d·v(7.4)其中，d表示记录密度(单位长度上的存储信息量)，v表示走带速度。2)数码音频磁带(DAT)DAT是数码音频磁带的英文缩写，它采用旋转扫描技术。DAT的存储容量最大达到12GB。与QIC相比，价格上比较昂贵。3)8mm磁带8mm磁带最初为视频行业设计，现已被计算机行业采用，被认为是存储大量计算机数据的可靠方式。8mm磁带与DAT磁带在结构上类似，但是最大存储容量可达25GB。4)数码线性磁带(DLT)DLT是数码线性磁带的英文缩写，它是半英寸宽的磁带，比8mm磁带宽60%，比QIC磁带宽2倍。因此DLT磁带提供所有磁带类型的存储容量，最大可以达到35GB。目前的光盘有CD-ROM、WORM、CD-R、CD-RW、DVD-ROM等类型。1.CD-ROM光盘CD-ROM是只读型光盘，一张光盘容量为680MB。光盘是直径为120mm、厚度为1.2mm的单面记录盘片。盘片的膜层结构如图7.12(a)所示，盘基为聚碳酸酯，反射层多为铝质，保护层为聚丙烯酸酯。最上层为印刷的盘标。所有的只读型光盘系统都基于一个共同原理，即光盘上的信息以坑点形式分布，有坑点表示为“1”，无坑点表示为“0”，一系列的坑点(存储元)形成信息记录道，见图7.12(b)。对数据存储用的CD-ROM光盘来讲，这种坑点分布作为数字“1”“0”代码的写入或读出标志。为此必须采用激光作为光源，并采用良好的光学系统才能实现。光盘的记录信息以凹坑方式永久性存储。读出时，当激光束聚焦点照射在凹坑上时将发生衍射，反射率低；而聚焦点照射在凸面上时大部分光将返回。根据反射光的光强变化并进行光-电转换，即可读出记录信息。信息记录的轨迹称为光道。光道上划分出一个个扇区，它是光盘的最小可寻址单位。光盘扇区分为4个区域。2个全0字节和10个全1字节组成同步(SYNC)区，标志着扇区的开始。4字节的扇区标识(ID)区用于说明此扇区的地址和工作模式。光盘的扇区地址编码不同于磁盘，它是以分(MN)、秒(SC)和分数秒(FR，1/75s)时间值作为地址。由于光盘的恒定线速度是每秒钟读出75个扇区，故FR的值实际上就是秒内的扇区号(0～74)。ID区的MD为模式控制，用于控制数据区和校验区的使用。共有三种模式：模式0规定数据区和校验区的全部2336字节都是0，这种扇区不用于记录数据，而是用于光盘的导入区和导出区；模式1规定288字节的校验区为4字节的检测码(EDC)、8字节的保留域(未定义)和276字节的纠错码(ECC)，这种扇区模式有2048字节的数据并有很强的检测和纠错能力，适合于保存计算机的程序和数据；模式2规定288字节的校验区也用于存放数据，用于保存声音、图像等对误码率要求不高的数据。2.WORM、CD-R光盘WORM表示一次写多次读，它是一种只能写一次的光盘。数据写到光盘后不可擦除但可多次读。记录信息时，低功率激光束在光盘表面灼烧形成微小的凹陷区。被灼烧的部分和未被灼烧的部分分别表示1和0。CD-R实质上是WORM的一种，区别在于CD-R允许多次分段写数据。CD-R光盘有与CD-ROM的相似的圆形轨道，但不再是机械的在盘面上烧印凹痕来表示数据。CD-R使用激光将微型斑点烧在有机燃料表层。读取数据时，在超过标准温度的激光束的照射下，这些烧过的斑点颜色发生变化，呈现出比未被灼烧的地方较暗的亮度。因此，CD-R光盘通过激光烧和不烧斑点表示1和0，而CD-ROM则通过凹凸区来表示。CD-R光盘的数据一旦写上也不能擦除。3.CD-RW光盘CD-RW表示可重复写光盘，用于反复读写数据。与CD-R所使的基于染料的记录表层不同，CD-RW光盘采用一种特殊的水晶复合物作为记录介质。当加热到一个确定的温度后，冷却时它即呈现出水晶状；但如果一开始把它加热到一个更高的温度，它会被熔化，随即冷却成一种非晶形的固态。写数据时，用激光束将待写区域加热至高温，使之熔化冷却成非晶形物质。由于非晶形区域比水晶形区域反射的光线强度弱，这样读数据时就可以区分出是1还是0。这种光盘允许多次写，重写数据时只需将被写过的呈非晶形的区域重新加热，温度在可结晶温度和熔化温度之间，使之重新转化为水晶态即可。4.DVD-ROM光盘最初DVD的全称是数字化视频光盘，但后来逐渐演变成数字化通用光盘的简称。DVD-ROM的数据也是事先存储在光盘上，这与CD-ROM是相同的。不过，凹陷区的大小相对更小一些，使得圆形光道上存储的数据总量更大。CD-ROM和DVD-ROM的主要区别是：CD光盘是单面使用，而DVD光盘两面都可以写数据。另外，除了有两面可写的DVD光盘，还有多层可写的光盘，在主数据层上还放置着多层透明的可写层，这种光盘的容量可以达到数十GB。读写这种多层数据光盘时，激光头每次都需要在层与层之间重新定位。顾名思义，磁光盘(MO)存储设备是采用磁场技术和激光技术相结合的产物。磁光盘和磁盘一样，由磁道和扇区组成。磁光盘是重写型光盘，可以进行随机写入、擦除或重写信息。MO盘和纯磁盘的基本区别是：磁光盘的磁表面需要高温来改变磁极。因此，MO盘在常温下是非常稳定的，数据不会改变。磁光盘的基本工作原理是：利用热磁效应写入数据：当激光束将磁光介质上的记录点加热到居里点温度以上时，外加磁场作用改变记录点的磁化方向，而不同的磁化方向可表示数字“0”和“1”。利用磁光克尔效应读出数据：当激光束照射到记录点时，记录点的磁化方向不同，会引起反射光的偏振面发生不同结果，从而检测出所记录的数据“1”或“0”。图7.14示出了磁光盘操作的四种情况。图7.14(a)表示未编码的磁盘，如所有磁化点均存“0”。图7.14(b)表示写操作：高功率激光束照射加热点(记录点)，磁头线圈中外加电流后产生的磁场使其对应的记录点产生相反的磁性微粒，从而写入“1”。图7.14(c)表示读操作：低功率的激光束反射掉相反极性的磁性粒子且使它的极性变化。如果这些粒子没有被反射掉，则反射激光束的极性是不变化的。图7.14(d)表示擦除操作：高功率激光束照射记录点，外加磁场改变方向，使磁性粒子恢复到原始极性。总之，MO盘介质材料发生的物理特性改变是可逆变化，因此信息是可重写的。以可见光的形式传递和处理信息的设备称为显示设备，它是目前计算机系统中应用最广泛的人-机界面设备。显示设备种类繁多。按显示设备所用的显示器件分类，有阴极射线管(CRT)显示器、液晶显示器(LCD)、等离子显示器等。按所显示的信息内容分类，有字符/图形显示器、图像显示器等。在CRT显示设备中，以扫描方式不同，分成光栅扫描和随机扫描两种显示器；以分辨率不同，分成高分辨率显示器和低分辨率显示器；以显示的颜色分类，有单色(黑白)显示器和彩色显示器。以CRT荧光屏对角线的长度分类，有14英寸、16英寸、19英寸等多种。1.分辨率和灰度级分辨率是指显示器所能表示的像素个数。像素越密，分辨率越高，图像越清晰。分辨率取决于显像管荧光粉的粒度、荧光屏的尺寸和CRT电子束的聚焦能力。同时刷新存储器要有与显示像素数相对应的存储空间，用来存储每个像素的信息。例如，12英寸彩色CRT的分辨率为640×480像素。每个像素的间距为0.31mm，水平方向的640像素所占显示长度为198.4mm，垂直方向480像素是按4∶3的长宽比例分配(640×3/4=480)。按这个分辨率表示的图像具有较好的水平线性和垂直线性，否则看起来会失真变形，同样16英寸的CRT显示1024×768像素也满足4∶3的比例。某些专用的方形CRT显示分辨率为1024×1024像素，甚至更多。灰度级是指黑白显示器中所显示的像素点的亮暗差别，在彩色显示器中则表现为颜色的不同。灰度级越多，图像层次越清楚逼真。灰度级取决于每个像素对应刷新存储器单元的位数和CRT本身的性能。如果用4位表示一像素，则只有16级灰度或颜色；如果用8位表示一像素，则有256级灰度或颜色。字符显示器只用“0”，“1”两级灰度就可表示字符的有无，故这种只有两级灰度的显示器称为单色显示器。具有多种灰度级的黑白显示器称为多灰度级黑白显示器。图像显示器的灰度级一般在256级以上。2.刷新和刷新存储器CRT发光是由电子束打在荧光粉上引起的。电子束扫过之后其发光亮度只能维持几十毫秒便消失。为了使人眼能看到稳定的图像显示，必须使电子束不断地重复扫描整个屏幕，这个过程称为刷新。按人的视觉生理，刷新频率大于30次/秒时才不会感到闪烁。为了不断提供刷新图像的信号，必须把一帧图像信息存储在刷新存储器，也称视频存储器。其存储容量M由图像分辨率和灰度级决定。M=r×C(7.5)分辨率r越高，颜色深度C越多，刷新存储器容量越大。如分辨率为1024×1024，256级颜色深度的图像，存储容量M=1024×1024×8bit=1MB。刷新存储器的存取周期必须满足刷新频率的要求。刷存容量和存取周期是刷新存储器的重要技术指标。不同的计算机系统，显示器的组成方式也不同。在大型计算机中，显示器作为终端设备独立存在，即键盘输入和CRT显示输出是一个整体，通过标准的串行接口与主机相连。在微型机系统中，CRT显示输出和键盘输入是两个独立的设备，显示系统由插在主机槽中的显示适配器卡和显示器两部分组成，而且将字符显示与图形显示结合为一体。1.字符显示显示字符的方法以点阵为基础。点阵是由m×n个点组成的阵列，并以此来构造字符。将点阵存入由ROM构成的字符发生器中，在CRT进行光栅扫描的过程中，从字符发生器中依次读出某个字符的点阵，按照点阵中0和1代码不同控制扫描电子束的开或关，从而在屏幕上显示出字符，如图7.15(a)所示。点阵的多少取决于显示字符的质量和字符窗口的大小。字符窗口是指每个字符在屏幕上所占的点数，它包括字符显示点阵和字符间隔。在IBM/PC系统中，屏幕上共显示80列×25行=2000个字符，故字符窗口数目为2000。在单色字符方式下，每个字符窗口为9×14点阵，字符为7×9点阵。对应于每个字符窗口，所需显示字符的ASCII代码被存放在视频存储器VRAM中，以备刷新，故VRAM应有2000个单元存放被显示的字符信息。字符发生器ROM的高位地址来自VRAM的ASCII代码，低位地址来自光栅地址计数器的输出RA3～RA0，它具体指向这个字形点阵中的某字节。在显示过程中，按照VRAM中的ASCII码和光栅地址计数器访问ROM，依次取出字形点阵，就可以完成一个字符的输出，见图7.15(b)。2.图形显示图形显示是指用计算机手段表示现实世界的各种事物，并形象逼真地加以显示。根据产生图形的方法，分随机扫描图形显示器和光栅扫描图形显示器。随机扫描图形显示器工作原理是将所显示图形的一组坐标点和绘图命令组成显示文件存放在缓冲存储器，缓存中的显示文件送矢量(线段)产生器，产生相应的模拟电压，直接控制电子束在屏幕上的移动。为了在屏幕上保留持久稳定的图像，需要按一定的频率对屏幕反复刷新。这种显示器的优点是分辨率高(可达4096×4096像素)，显示的曲线平滑。目前高质量图形显示器采用这种随机扫描方式。光栅扫描图形显示器产生图形的方法称为相邻像素串接法，即曲线是由相邻像素串接而成。因此光栅扫描图形显示器的原理是：把对应于屏幕上每个像素的信息都用刷新存储器存起来，然后按地址顺序逐个地刷新显示在屏幕上。刷新存储器中存放一帧图形的形状信息，它的地址和屏幕上的地址一一对应，例如，屏幕的分辨率为1024×1024像素，刷存就要有1024×1024单元；屏幕上像素的灰度为256级，刷存每个单元的字长就是8位。因此刷存的容量直接取决于显示器的分辨率和灰度级。换言之，此时需要有1MB的刷存与之对应。光栅扫描图形显示器的优点是通用性强，灰度层次多，色调丰富，显示复杂图形时无闪烁现象；所产生的图形有阴影效应、隐藏面消除、涂色等功能。它的出现使图形学的研究从简单的线条图扩展到丰富多彩、形象逼真的各种立体及平面图形，从而成为目前流行的显示器。图像的概念与图形的概念不同。图形是用计算机表示和生成的图，称为主观图像。在计算机中表示图形，只需存储绘图命令和坐标点，没有必要存储每个像素点。而图像所处理的对象多半来自客观世界，即由摄像机摄取下来存入计算机的数字图像，这种图像称为客观图像。由于数字化以后逐点存储，因此图像处理需要占用非常庞大的主存空间。图像显示器采用光栅扫描方式，其分辨率在256像素×256像素或512像素×512像素，与图形显示兼容的图像显示器已达1024像素×1024像素，灰度级在64～256级。图像显示器有两种类型。一种是图7.17所示的简单图像显示器，它仅仅显示由计算机送来的数字图像。图像处理操作在计算机中完成，显示器不做任何处理。虚线框中的I/O接口、图像存储器(刷新存储器)、A/D与D/A变换等组成单独的一个部分，称为图像输入控制板或视频数字化仪。图像输入控制板的功能是实现连续的视频信号与离散的数字量之间的转换。图像输入控制板接收摄像机模拟视频输入信号，经A/D变换为数字量存入刷新存储器用于显示，并可传送到计算机进行图像处理操作。处理后的结果送回刷存，经D/A变换成模拟视频输出，由监视器进行显示输出。监视器只包括扫描、视频放大等与显示有关的电路及显像管。也可以接入电视机的视频输入端来代替监视器。数字照相机的出现，更容易组成一个图像处理系统。另一种是图形处理子系统，其硬件结构较前一种复杂得多。它本身就是一个具有并行处理功能的专用计算机，不仅能完成显示操作，同时由于子系统内部有容量很大的存储器和高速处理器。可以快速执行许多图像处理算法，减轻主计算机系统的运算量。这种子系统可以单独使用，也可以联到通用计算机系统。目前流行的图形工作站就属于图形处理子系统。由于新一代多媒体计算机的发展，图像的处理与显示技术越来越受到人们的重视。不同的显示标准所支持的最大分辨率和颜色数目是不同的。随着IBMPC系列机的升级发展，PC机采用的显示标准经历了很多变化。MDA是PC机最早使用的显示标准。MDA是单色字符显示适配器，采用9×14点阵的字符窗口，满屏显示80列×25行字符，对应分辨率为720×350像素。VGA显示标准可兼容字符和图形两种显示方式。字符窗口为9×16点阵，图形方式下分辨率为640×480像素，16种颜色。自IBM公司推出VGA后，VESA(美国视频电子标准协会)定义了一个VGA扩展集，将显示方式标准化，从而成为著名的Super-VGA模式。该模式除兼容VGA的显示方式外，还支持1280×1024像素光栅，每像素点24位颜色深度，刷新频率可达75MHz。当今的显示适配器为支持视窗的API应用程序界面，几乎都安装图形加速器硬件，这样的适配器称为AVGA。它在显示方式上除遵循VESA的Super-VGA模式外，并没有提出新的显示方式。但由于有了图形加速器硬件，并在视窗驱动程序的支持下，系统的图形显示性能得到显著改善。表7.1中列出了VESA扩充的标准显示模式。早期的MDA等显示方式是由BIOS的一组功能调用(INT10h)来设置和管理的，使用7位的方式码。VESA保留了这种方式，将VGA类显示器及适配器所能支持的新的显示方式进行定义，并为新的显示方式指定了15位的方式码。方式码的b8位为VESA标志位，b14～b9为保留位，故VESA的显示方式号为1××h。表7.2中括号内的数字，如5∶5∶5，指的是三原色R∶G∶B每色所占的位数，有的还在前面有1，表示I(加亮)占1位。图7.18是显示适配器的结构框图，它由刷新存储器、显示控制器、ROMBIOS三部分组成。在Pentium系列中显示适配器大多作成插卡形式，插入一个PCI(或VESAVL)总线槽。它一方面与32位或64位的系统总线相接，另一方面通过一个15针D形插口与显示器电缆连接，将水平、垂直同步信号(VSYNC、HSYNC)和红(R)、绿(G)、蓝(B)三色模拟信号送至显示器。显示适配器的顶部另有一个VFC插头，通过一个24芯扁平电缆与视频卡相连，通过传送像素的电平信号，还可以实现视频图像与PC图形的合成。刷新存储器存放显示图案的点阵数据。其存储容量取决于设定的显示工作方式。例如，设定VESA显示模式中的方式码为118h时，其分辨率为1024×768像素，颜色深度为24位(3字节)，则显示一屏画面需要2304KB的存储器容量。因此当前的刷存容量一般在2～4MB，由高速的DRAM组成。刷存通过适配器内部的32位或64位总线与显示控制器连接。ROMBIOS含有少量的固化软件，用于支持显示控制器建立所要求的显示环境。此BIOS软件主要用于DOS操作系统。在视窗环境下，它的大部分功能不被使用，而由后者的设备驱动程序建立操作系统与适配器硬件的衔接。显示控制器是适配器的心脏。它依据设定的显示工作方式，自主地、反复不断地读取显存中的图像点阵(包括图形、字符文本)数据，将它们转换成R、G、B三色信号，并配以同步信号送至显示器刷新屏幕。显示控制器还要提供一个由系统总线至刷存总线的通路，以支持CPU将主存中已修改好的点阵数据写入到刷存，以更新屏幕。这些修改数据一般利用扫描回程的消隐时间写入到刷存中，因此显示屏幕不会出现凌乱。先进的显示控制器具有图形加速能力，这样的控制器芯片称为AVGA芯片。典型的图形加速功能有：①位和块传送，用于生成和移动一个矩形块(如窗口)数据；②画线，由硬件在屏上任意两点间画一向量；③填域，以预先指定的颜色或花样填满一个任意多边形；④颜色扩充，将一个单色的图像放到屏上某一位置后，给它加上指定的前景颜色和背景颜色。思考题显示适配器中为什么一定要具有显示存储器？1.图形输入设备图形输入方法较多，特别是交互式图形系统要求具有人-机对话功能：计算机将结果显示给人，人根据看到的显示决定下一步操作，并通过输入设备告诉计算机。如此反复多次，直到显示结果满意。为此必须具有方便灵活的输入手段，才能体现“交互式”的优越性。键盘输入键盘是字符和数字的输入装置，无论字符输入还是图形输入，键盘是一种最基本的常用设备。当需要输入坐标数据建立显示文件时，要利用键盘。另外，利用键盘上指定的字符与屏幕上的光标结合，可用来移动光标，拾取图形坐标，指定绘图命令等。鼠标器输入鼠标器是一种手持的坐标定位部件，有两种类型。一种是机械式的，在底座上装有一个金属球，在光滑的表面上摩擦，使金属球转动，球与四个方向的电位器接触，就可以测量出上下左右四个方向的相对位移量。另一种是光电式的鼠标器，需要一块画满小方格的长方形金属板配合使用。当鼠标器在板上移动时，安装在鼠标器底部的光电转换装置可以定位坐标点。光电式鼠标器比机械式鼠标器可靠性高，但需要附带一块金属板。另外，用相对坐标定位，必须和CRT显示的光标配合，计算机先要给定光标初始位置，然后用读取的相对位移移动光标。2.图像输入设备最理想的图像输入设备是数字摄像机。它可以摄取任何地点、任何环境的自然景物和物体，直接将数字图像存入磁盘。当图像已经记录到某种介质上时，要利用读出装置读出图像。例如，记录在录像带上的图像要用录像机读出，再将视频信号经图像板量化后输入计算机。记录在数字磁带上的遥感图像可以直接在磁带机上输入。如果想把纸上的图像输入计算机，一种方法是用摄像机对着纸上的图像摄像输入，另一种方法是利用装有CCD(电荷耦合器件)的图文扫描仪或图文传真机。还有一种叫“扫描仪”的专用设备，可以直接将纸上的图像转换成数字图像。由于一帧数字图像要占很大的存储空间，图像数据的传输与存储问题将是一个十分重要的研究课题，目前普遍采用的方法是压缩-恢复技术。3.语音输入设备利用人的自然语音实现人-机对话是新一代多媒体计算机的重要标志之一。图7.19示出了一种语音输入/输出设备的原理方框图。语音识别器作为输入设备，可以将人的语言声音转换成计算机能够识别的信息，并将这些信息送入计算机。而计算机处理的结果又可以通过语音合成器变成声音输出，以实现真正的“人机对话”。通常语音识别器与语言合成器放在一起做成语音输入/输出设备。图7.19中声音通过话筒进入语音识别器，然后送入计算机；计算机输出数据送入语音合成器变为声音，然后由喇叭输出。打印输出是计算机最基本的输出形式。与显示器输出相比，打印输出可产生永久性记录，因此打印设备又称为硬拷贝设备。1.打印设备的分类打印设备种类繁多，有多种分类方法。按印字原理分，分为击打式和非击打式两大类。击打式是利用机械作用使印字机构与色带和纸相撞击而打印字符。因此习惯上将属于击打式打印方式的机种称为“打印机”。击打式设备的成本低，缺点是噪声大，速度慢。非击打式是采用电、磁、光、喷墨等物理、化学方法印刷字符，因此习惯上将这类非击打式的机种称为“印字机”，如激光印字机、喷墨印字机等。非击打式的设备速度快，噪声低，印字质量高，但价格较贵，有的设备还需要专用纸张。目前的发展趋势是机械化的击打式设备逐步转向电子化的非击打式设备。另外，还有能够输出图形/图像的打印机，具有彩色效果的彩色打印机等。2.激光印字机激光印字机是激光技术和电子照相技术结合的产物，其基本原理与静电复印机相似。激光印字机的结构见图7.20。激光器输出的激光束经光学透镜系统被聚焦成一个很细7.19小的光点，沿着圆周运动的滚筒进行横向重复扫描。滚筒是记录装置，表面镀有一层具有光敏特性的感光材料，通常是硒，因此又将滚筒称为硒鼓。硒鼓在未被激光束扫描之前，首先在黑暗中充电，使鼓表面均匀地沉积一层电荷。此后根据控制电路输出的字符或图形，变换成数字信号来驱动激光器的打开与关闭。扫描时激光器将对鼓表面有选择地曝光，曝光部分产生放电现象，未曝光部分仍保留充电时的电荷，从而形成静电潜像。随着鼓的转动，潜像部分将通过装有碳粉盒的显影器，使得具有字符信息的区域吸附上碳粉，达到显影的目的。当鼓上的字符信息区和普通纸接触时，由于在纸的背面施以反向的静电电荷，鼓表面上的碳粉就会被吸附到纸上来，这个过程称为转印。最后，当记录有信息的纸经过定影辊高温加热，碳粉被溶化，永久性地黏附在纸上，达到定影的效果。另外，转印后的鼓面还留有残余的碳粉。因此先要除去鼓表面的电荷，然后经清扫刷，将残余的碳粉全部清除。清除以后的鼓表面又继续重复上述的充电、曝光、显影、转印、定影等一系列过程。激光印字机是非击打式硬拷贝输出设备，输出速度快，印字质量高，可使用普通纸张。其印字分辨率达到每英寸300个点以上，缓冲存储器容量一般在1MB以上，对汉字或图形/图像输出，是理想的输出设备，因而在办公自动化及轻印刷系统中得到了广泛的应用。本章小结外围设备大体分为输入设备、输出设备、外存设备、数据通信设备、过程控制设备五大类。每一种设备，都是在它自己的设备控制器控制下进行工作的，而设备控制器则通过I/O接口模块和主机相连，并受主机控制。磁盘、磁带属于磁表面存储器，特点是存储容量大，位价格低，记录信息永久保存，但存取速度较慢，因此在计算机系统中作为辅助大容量存储器使用。硬磁盘按盘片结构分为可换盘片式、固定盘片式两种，磁头也分为可移动磁头和固定磁头两种。温彻斯特磁盘是一种采用先进技术研制的可移动磁头、固定盘片的磁盘机，组装成一个不可拆卸的机电一体化整体，防尘性能好，可靠性高，因而得到了广泛的应用，成为最有代表性的硬磁盘存储器。磁盘存储器的主要技术指标有存储密度、存储容量、平均存取时间、数据传输速率。磁盘阵列RAID是多台磁盘存储器组成的大容量外存系统，它实现数据的并行存储、交叉存储，单独存储，改善了I/O性能，增加了存储容量，是一种先进的硬磁盘体系结构。各种可移动硬盘的诞生，是磁盘先进技术的又一个重要进展。光盘和磁光盘是近年发展起来的一种外存设备，是多媒体计算机不可缺少的设备。按读写性质分类有：①只读型：记录的信息只能读出，不能被修改。②一次型：用户可在这种盘上记录信息，但只能写一次，写后的信息不能再改变，只能读。③重写型：用户可对这类光盘进行随机写入、擦除或重写信息。光盘由于存储容量大、耐用、易保存等优点，成为计算机大型软件的传播载体和电子出版物的媒体。不同的CRT显示标准所支持的最大分辨率和颜色数目是不同的。VESA标准，是一个可扩展的标准，它除兼容传统的VGA等显示方式外，还支持1280像素×1024像素光栅，每像素点24位颜色深度，刷新频率可达75MHz。显示适配器作为CRT与CPU的接口，由刷新存储器、显示控制器、ROMBIOS三部分组成。先进的显示控制器具有图形加速能力。常用的计算机输入设备有图形输入设备(键盘、鼠标)、图像输入设备、语音输入设备。常用的打印设备有激光打印机、彩色喷墨打印机等，它们都属于硬拷贝输出设备。外围设备的种类繁多，有机械式和电动式，也有电子式和其他形式。其输入信号，可以是数字式的电压，也可以是模拟式的电压和电流。从信息传输速率来讲，相差也很悬殊。例如，当用手动的键盘输入时，每个字符输入的间隔可达数秒钟。又如，磁盘输入的情况下，在找到磁道以后，磁盘能以大于30000B/s的速率输入数据。在计算机系统中，为了保证高速的主机和不同速度的外设之间的高效和可靠的交互，CPU必须通过I/O接口与外设连接。因此，CPU的输入/输出操作实际上分为两个传输阶段：I/O接口与外设间的数据传送，以及CPU与I/O接口之间的数据传送如图8.1所示。显然，这两个阶段是相互关联的。I/O接口是由半导体介质构成的逻辑电路，它作为一个转换器，保证外部设备用计算机系统特性所要求的形式发送或接收信息。为了与CPU交互信息的方便，在接口内部一般要设置一些可以被CPU直接访问的寄存器。这些寄存器称为端口(Port)。例如，接口内用于接收来自CPU等主控设备的控制命令的寄存器称为命令端口，简称命令口，接口内向CPU报告I/O设备的工作状态的寄存器称为状态端口或状态口，接口内在外设和总线间交换数据的缓冲寄存器称为数据端口或数据口。为便于CPU访问端口，也需对端口安排地址。通常有两种不同的编址方式。一种是统一编址方式：输入/输出设备接口中的控制寄存器、数据寄存器、状态寄存器等和内存单元一样看待，它们和内存单元联合在一起编排地址。这样就可用访问内存的指令(读、写指令)去访问I/O设备接口内的某个寄存器，因而不需要专门的I/O指令组。另一种是I/O独立编址方式：内存地址和I/O设备地址是分开的，访问内存和访问I/O设备使用不同的指令，即访问I/O设备有专门的I/O指令组。8.1.2输入/输出操作的一般过程由于接口与CPU的速度大致相当，仅从CPU读写接口内寄存器的角度看，CPU读写端口的方式与CPU读写内存单元是相似的。但是，内存单元的功能是存储数据，而端口的功能则是辅助CPU与外设交互，故端口中的数据并不是静态的，而是动态变化的。CPU写入控制口的信息要由接口内的逻辑电路转换成相关控制信号发送给外设，外设的状态信息则由接口的逻辑电路转换成状态字存入状态口供CPU读取。CPU写入输出数据口的信息要由外设取走。外设发送给CPU的数据则通过输入数据口缓冲。外设状态信息可能是时刻变化的，给外设的控制命令也往往会不断改变，CPU与外设交互数据一般情况下也是成批连续进行的。因此，对端口的连续访问必须确保信息的有效性。首先我们看看输入/输出设备同CPU交换数据的一般过程。如果是输入过程，一般需要以下三个步骤：(1)CPU把一个地址值放在地址总线上，选择某一输入设备；(2)CPU等候输入设备的数据成为有效；(3)CPU从数据总线读入数据，并放在一个相应的寄存器中。如果是输出过程，一般需要以下三个步骤：(1)CPU把一个地址值放在地址总线上，选择一个输出设备；(2)CPU把数据放在数据总线上；(3)输出设备认为数据有效，从而把数据取走。从上述输入/输出过程看出，问题的关键就在于：究竟什么时候数据才成为有效?事实上，各种外围设备的数据传输速率相差甚大。如果把高速工作的处理器同按照不同速度工作的外围设备相连接，那么首先遇到的一个问题，就是如何保证处理器与外围设备在时间上同步?这就是我们要讨论的外围设备的定时问题。很显然，由于输入/输出设备本身的速度差异很大，因此，对于不同速度的外围设备，需要有不同的定时方式。一个计算机系统，即使CPU有极高的速度，如果忽略I/O速度的提升，对整个系统的性能仍然影响极大。下面通过一个例子说明I/O对系统性能的影响。根据外设工作速度的不同，I/O接口与外设间的数据传送方式有以下三种。1.速度极慢或简单的外围设备：无条件传送方式对这类设备，如机械开关、发光二极管等，在任何一次数据交换之前，外设无需进行准备操作。换句话说，对机械开关来讲，可以认为输入的数据一直有效，因为机械开关的动作相对主机的速度来讲是非常慢的。对发光二极管来讲，可以认为主机输出时外设一定准备就绪，因为只要给出数据，发光二极管就能进行显示。所以，对于简单的慢速设备，接口与外设之间只需要数据信号线，无需握手联络信号线，接口只需实现数据缓冲和寻址功能，故称为无条件传送方式或零线握手联络方式。2.慢速或中速的外围设备：应答方式(异步传送方式)由于这类设备的速度和主机的速度并不在一个数量级，或者由于设备(如键盘)本身是在不规则时间间隔下操作的，因此，主机与这类设备之间的数据交换通常采用异步定时方式，接口与外设之间在数据传送信号线之外安排若干条握手(联络、挂钩)信号线，用以在收发双方之间传递控制信息，指明何时能够交换数据。例如，最常见的双线握手方式设置两条联络握手信号线：一条发方向收方发出的选通信号或请求信号，指明数据是否有效；一条收方向发方发出的应答信号，指明数据是否已经被取走。3.高速的外围设备：同步传送方式对于中等以上数据传送速率并按规则间隔工作的外部设备，接口以某一确定的时钟速率和外设交换信息。因此，这种方式称为同步定时方式。一旦接口和外设确认同步，它们之间的数据交换便靠时钟脉冲控制来进行。例如，若外设是一条传送2400位/秒的同步通信线路，那么接口即每隔1/2400秒执行一次串行的输入/输出操作。为便于理解，先讲一个例子，假设幼儿园一个阿姨带10个孩子，要给每个孩子分2块水果糖。假设孩子们把2块糖都吃完，那么她采用什么方法呢?第一种方法：她先给孩子甲一块糖，盯着甲吃完，然后再给第二块。接着给孩子乙，其过程与孩子甲完全一样。以此类推，直至到第10个孩子发完2块糖。看来这种方法效率太低，重要之点还在于孩子们吃糖时她一直在守候，什么事也不能干。于是她想了第二种方法：每人发一块糖各自去吃，并约定谁吃完后就向她举手报告，再发第二块。看来这种新方法提高了工作效率，而且在未接到孩子们吃完糖的报告以前，她还可以腾出时间给孩子们批改作业。但是这种方法还可以改进，于是她想了第三种方法，进行批处理：每人拿2块糖各自去吃，吃完2块糖后再向她报告。显然这种方法工作效率大大提高，她可以腾出更多的时间批改作业。还有没有更好的方法呢?我们假定她给孩子们改作业是她的主要任务，那么她还可以采用第四种方法：权力下放，把发糖的事交给另一个人分管，只是必要时她才过问一下。在计算机系统中，CPU管理外围设备也有几种类似的方式。1.无条件传送方式(简单I/O方式)无条件传送方式假设外设始终处于就绪状态，数据传送时，CPU不必通过接口查询外设的状态，而直接执行I/O指令进行数据传输。显然，只有当接口与外设之间采用无条件传送方式时，CPU与接口之间才能采用无条件传送方式。这种方式下，CPU在端口读、写操作之前对目标设备的状态不作任何检测。当简单外设作为输入设备时，可使用三态缓冲器与数据总线相连；当简单外设作为输出设备时，输出一般采用锁存器。2.程序查询(轮询)方式多数外设每传送完一次数据总要进行一段时间的处理或准备才能传送下一个数据，因此在数据传送之前，CPU需要通过接口对目标设备的状态进行查询：如果外设已准备好传送数据则进行数据传送；如果外设未准备好传送数据，则CPU不断地查询并等待，直到外设准备好信息交互。其定时过程如下：如果CPU希望从外设接收一个字，则它首先通过状态口询问外设的状态，如果该外设的状态标志表明设备已“准备就绪”，那么CPU就从总线上接收数据。CPU在接收数据以后，通过接口发出输入响应信号，告诉外设已经把数据总线上的数据取走。然后，外设把“准备就绪”的状态标志复位，并准备下一个字的交换。如果外设没有“准备就绪”，那么它就发出“忙”的标志。于是，CPU将进入一个循环程序中等待，并在每次循环中询问外设的状态，一直到外设发出“准备就绪”信号以后，才从外设接收数据。CPU发送数据的情况也与上述情况相似，外设先通过接口发出请求输出信号，而后CPU询问外设是否准备就绪。如果外设已准备就绪，CPU便发出准备就绪信号，并送出数据。外设接收数据以后，将向CPU发出“数据已经取走”的通知。程序查询方式是一种简单的输入输出方式，数据在CPU和外围设备之间的传送完全靠计算机程序控制。这种方式的优点是CPU的操作和外围设备的操作能够同步，而且软硬件结构都比较简单。但问题是，外围设备通常动作很慢，程序进入查询循环时将白白消耗掉CPU很多时间。这种情况类似于上述例子中第一种方法。即使CPU采用定期地由主程序转向查询设备状态的子程序进行扫描轮询(polling)的办法，CPU时间的消耗也是可观的。因此程序查询方式只适用于连接低速外设或者CPU任务不繁忙的情况。3.程序中断方式中断是外围设备用来“主动”通知CPU，准备送出输入数据或接收输出数据的一种方法。通常，当一个中断发生时，CPU暂停其现行程序，而转向中断处理程序，从而可以输入或输出一个数据。当中断处理完毕后，CPU又返回到原来执行的任务，并从其停止的地方开始执行程序。这种方式和我们前述例子的第二种方法类似。可以看出，它节省了CPU宝贵的时间，是管理I/O操作的一个比较有效的方法。中断方式一般适用于随机出现的服务请求，并且一旦提出要求，能使服务请求立即得到响应，因而适合于计算机工作量十分饱满、而I/O处理的实时性要求又很高的系统。同程序查询方式相比，中断方式硬件结构相对复杂，软件复杂度也提高了，服务开销时间较大。4.直接内存访问(DMA)方式用中断方式交换数据，是通过CPU执行程序来实现数据传送的。每进行一次传送，CPU必须执行一遍中断处理程序，完成一系列取指令、分析指令、执行指令的过程。而且，每进入一次中断处理程序，CPU都要保护被打断的程序的下一条指令地址(断点)和状态条件寄存器的当前值；在中断处理程序中，通常还要保护及恢复通用数据寄存器。因此，每处理一次I/O交换，需几十微秒到几百微秒的时间。在指令流水方式中，中断发生或从中断返回时，指令队列预取的指令会全部作废。因此，在高速、成批传送数据时，中断方式难以满足速度要求。直接内存访问(DMA)方式是一种完全由硬件执行I/O交换的工作方式。这种方式既能够响应随机发生的服务请求，同时又可以省去中断处理的开销。此时，DMA控制器从CPU完全接管对总线的控制，数据交换不经过CPU，而直接在内存和外围设备之间进行，以高速传送数据。这种方式和前述例子的第三种方法相仿，主要的优点是数据传送速度很高，传送速率仅受到内存访问时间的限制。与中断方式相比，需要更多的硬件。DMA方式适用于内存和高速外围设备之间大批数据交换的场合。5.通道和输入/输出处理器DMA方式的出现已经减轻了CPU执行I/O操作的压力，使得CPU的效率有显著的提高，而通道的出现则进一步提高了CPU的效率。这是因为，CPU将部分权力下放给通道。通道是一个具有特殊功能的简化版处理器，它可以实现对外围设备的统一管理和外围设备与内存之间的数据传送控制。更进一步，现代的很多高性能计算机系统为输入/输出操作配置专用的处理器，称为输入输出处理器(IOP)或者外围处理器。这种方式与前述例子的DMA方式相仿，大大提高了CPU的工作效率。然而这种提高CPU效率的方式是以耗费更多硬件为代价的。综上所述，外围设备的输入/输出方式可用图8.2表示。程序查询方式和程序中断方式适用于数据传输率比较低的外围设备，而DMA方式、通道方式和IOP方式适用于数据传输率比较高的设备。程序查询方式又称为程序控制I/O方式。在这种方式中，数据在CPU和外围设备之间的传送完全靠计算机程序控制，是在CPU主动控制下进行的。当需要输入/输出时，CPU暂停执行主程序，转去执行设备输入/输出的服务程序，根据服务程序中的I/O指令进行数据传送。这是一种最简单、最经济的输入/输出方式，只需要很少的硬件。1.输入/输出指令当用程序实现输入/输出传送时，I/O指令一般具有如下功能：(1)置“1”或置“0”I/O接口的某些控制触发器，用于控制设备进行某些动作，如启动、关闭设备等。(2)测试设备的某些状态，如“忙”“准备就绪”等，以便决定下一步的操作。(3)传送数据，当输入数据时，将I/O接口中数据寄存器的内容送到CPU某一寄存器；当输出数据时，将CPU中某一寄存器的内容送到I/O接口的数据寄存器。不同的机器，所采用的I/O指令格式和操作也不相同。例如，某机的I/O指令格式如下：其中第0～1位01表示I/O指令；OP表示操作码，用以指定I/O指令的8种操作类型；DMs表示64个外部设备的设备地址，每个设备地址中可含有A、B、C三个数据寄存器；8、9位表示控制功能，如01启动设备(S)、10关闭设备(C)等；R0～R7表示CPU中的8个通用寄存器。上述I/O指令如用汇编语言写出，指令“DOAS2,13”表示把CPU中R2的内容输出到13号设备的A数据缓冲寄存器中，同时启动13号设备工作。指令“DICC3,12”表示把12号设备中C寄存器的数据送入CPU中通用寄存器R3，并关闭12号设备。输入/输出指令不仅用于传送数据和控制设备的启动与关闭，而且也用于测试设备的状态。如SKP指令是测试跳步指令，它是程序查询方式中常用的指令，其功能是测试外部设备的状态标志(如“就绪”触发器)：若状态标志为“1”，则顺序执行下一条指令；若状态标志为“0”，则跳过下一条指令。2.程序查询方式的接口由于主机和外部设备之间进行数据传送的方式不同，因而接口的逻辑结构也相应有所不同。程序查询方式的接口是最简单的，如图8.3所示。程序查询方式的接口电路包括如下部分。(1)设备选择电路接到总线上的每个设备预先都给定了设备地址码。CPU执行I/O指令时需要把指令中的设备地址送到地址总线上，用以指示CPU要选择的设备。每个设备接口电路都包含一个设备选择电路，用它判别地址总线上呼叫的设备是不是本设备。如果是，本设备就进入工作状态，否则不予理睬。设备选择电路实际上是设备地址的译码器。(2)数据缓冲寄存器当输入操作时，用数据缓冲寄存器来存放从外部设备读出的数据，然后送往CPU；当输出操作时，用数据缓冲寄存器来存放CPU送来的数据，以便送给外部设备输出。(3)设备状态标志是接口中的标志触发器，如“忙”“准备就绪”“错误”等，用来标志设备的工作状态，以便接口对外设动作进行监视。一旦CPU用程序询问外部设备时，将状态标志信息取至CPU进行分析。3.程序查询输入/输出方式程序查询方式是利用程序控制实现CPU和外部设备之间的数据传送。程序执行的动作如下：(1)先向I/O设备发出命令字，请求进行数据传送。(2)从I/O接口读入状态字。(3)检查状态字中的标志，看看数据交换是否可以进行。(4)假如这个设备没有准备就绪，则第(2)、第(3)步重复进行，一直到这个设备准备好交换数据，发出准备就绪信号“Ready”。(5)CPU从I/O接口的数据缓冲寄存器输入数据，或者将数据从CPU输出至接口的数据缓冲寄存器。与此同时，CPU将接口中的状态标志复位。图8.3中用①～⑥表示了CPU从外设输入一个字的过程。按上述步骤执行时CPU资源浪费严重，故实际应用中做如下改进：CPU在执行主程序的过程中可周期性地调用各外部设备询问子程序，而询问子程序依次测试各I/O设备的状态触发器“Ready”。如果某设备的Ready为“1”，则转去执行该设备的服务子程序；如该设备的Ready为“0”，则依次测试下一个设备。图8.4示出了典型的程序查询流程图。图的右边列出了汇编语言所写的查询程序，其中使用了跳步指令SKP和无条件转移指令JMP。第1条指令“SKPDZ1”的含义是，检查1号设备的Ready标志是否为“1”?如果是，接着执行第2条指令，即执行1号设备的设备服务子程序PTRSV；如果Ready标志为“0”，则跳过第2条指令，转去执行第3条指令。依次类推。最后一条指令返回主程序断点m。设备服务子程序的主要功能是：①实现数据传送。输入时，由I/O指令将设备的数据传送到CPU某寄存器，再由访内指令把寄存器中的数据存入内存；输出时，其过程正好相反。②修改内存地址，为下一次数据传送做准备。③修改传送字节数，以便修改传送长度。④进行状态分析或其他控制功能。某设备的服务子程序执行完以后，接着查询下一个设备。被查询设备的先后次序由查询程序决定，图8.4中以1、2、3、4为序。也可以用改变程序的办法来改变询问次序。一般来说，总是先询问数据传输率高的设备，后询问数据传输率低的设备，因而后询问的设备要等待更长的时间。中断是一种程序随机切换的方式，有时也统称为异常。当外部发生某些随机的事件需要及时处理时，无论CPU正在执行哪一条指令，都可以通过中断响应的方式暂停正在执行的主程序的执行，转而执行另外一段中断服务程序。在高优先级的中断服务程序执行完毕后，可以返回被打断的主程序“断点”继续执行。中断方式的典型应用包括：(1)实现CPU与外界进行信息交换的握手联络。一方面，中断可以实现CPU与外设的并行工作；另一方面，对于慢速I/O设备，使用中断方式可以有效提高CPU的效率。(2)故障处理。中断可以用于处理常见的硬件故障，如掉电、校验错、运算出错等；也可以处理常见的软件故障，如溢出、地址越界、非法指令等。(3)实时处理。中断可以保证在事件出现的实际时间内及时地进行处理。(4)程序调度。中断是操作系统进行多任务调度的手段。(5)软中断(程序自愿中断)。软中断不是随机发生的，而是与子程序调用功能相似，但其调用接口简单，不依赖于程序入口地址，便于软件的升级维护和调用。中断概念的出现，是计算机系统结构设计中的一个重大变革。8.1节中曾经提到，在程序中断方式中，某一外设的数据准备就绪后，它“主动”向CPU发出请求中断的信号，请求CPU暂时中断目前正在执行的程序而进行数据交换。当CPU响应这个中断请求时，便暂停运行主程序，并自动转移到该设备的中断服务程序。当中断服务程序结束以后，CPU又回到原来的主程序。这种原理和调用子程序相仿，不过，这里要求转移到中断服务程序的请求是由外部设备发出的。中断方式特别适合于随机出现的服务。图8.5示出了中断处理示意图。主程序只是在设备A、B、C数据准备就绪时，才去与设备A、B、C进行数据交换。在速度较慢的外围设备准备自己的数据时，CPU照常执行自己的主程序。在这个意义上说，CPU和外围设备的一些操作是并行地进行的，因而同串行进行的程序查询方式相比，计算机系统的效率大大提高了。实际的中断过程还要复杂一些，图8.6示出了一个典型的向量中断处理过程的详细流程图。当CPU执行完一条现行指令时，如果外设向CPU发出中断请求，那么CPU在满足响应条件的情况下，将发出中断响应信号，与此同时关闭中断(“中断屏蔽”触发器置“1”)，表示CPU不再受理另外一个设备的中断请求。这时，CPU将寻找中断请求源是哪一个设备，并保存CPU自己的程序计数器(PC)的内容。然后，它将转移到处理该中断源的中断服务程序。CPU在保存现场信息，设备服务(如交换数据)以后，将恢复现场信息。在这些动作完成以后，开放中断(“中断屏蔽”触发器清“0”)，并返回到原来被中断的主程序的下一条指令。以上是中断处理的大致过程，但是有一些问题需要进一步加以说明。第一个问题，尽管外界中断请求是随机的，但CPU只有在当前一条指令执行完毕后，即转入公操作时才受理设备的中断请求，这样才不至于使当前指令的执行受到干扰。所谓公操作，是指一条指令执行结束后CPU所进行的操作，如中断处理、取下条指令等。外界中断请求信号通常存放在接口中的中断源锁存器里，并通过中断请求线连至CPU，每当一条指令执行到末尾，CPU便检查中断请求信号。若中断请求信号为“1”且允许响应该中断请求，则CPU转入“中断周期”，受理外界中断。第二个问题，为了在中断服务程序执行完毕以后，能够正确地返回到原来主程序被中断的断点而继续执行主程序，必须把程序计数器PC的内容，以及当前指令执行结束后CPU的状态(包括寄存器的内容和一些状态标志位)都保存到堆栈中。这些操作称为保存现场。第三个问题，当CPU响应中断后，正要去执行中断服务程序时，可能有另一个新的中断源向它发出中断请求。为了不致造成混乱，在CPU的中断管理部件中必须有一个“中断屏蔽”触发器，它可以在程序的控制下置“1”(关中断)，或清“0”(开中断)。只有在“中断屏蔽”标志为“0”时，CPU才可以受理中断。当一条指令执行完毕CPU接受中断请求并作出响应时，它一方面发出中断响应信号INTA，另一方面把“中断屏蔽”标志置“1”，即关闭中断。这样，CPU不能再受理另外的新的中断源发来的中断请求。只有在CPU把中断服务程序执行完毕以后，它才重新使“中断屏蔽”标志置“0”，即开放中断，并返回主程序。因此，中断服务程序的最后必须有两条指令，即开中断指令和中断返回指令，同时在硬件上要保证中断返回指令执行以后才受理新的中断请求。第四个问题，中断处理过程是由硬件和软件结合来完成的。如在图8.6中，“中断周期”由硬件实现，而中断服务子程序由机器指令序列实现。后者除执行保存现场、恢复现场、开放中断并返回主程序任务外，需对请求中断的设备进行服务，使其同CPU交换一个字的数据，或作其他服务。至于在中断周期中如何转移到各个设备的中断服务程序，将在稍后介绍。在中断周期中由硬件实现的响应中断、关中断等操作由于在主程序和中断服务程序的代码中都看不到，因而被称为“中断处理的隐操作”。第五个问题，中断分为内中断和外中断。机器内部原因导致出错引起的中断叫内中断，也叫异常。外部设备请求服务的中断叫外中断。现代计算机系统中，中断是频繁发生的，这些引起中断的事件被称为中断源。CPU在中断响应的过程中必须首先确认应该为哪个中断源服务。当有多个中断源同时提出中断申请时，还需对中断源进行优先级判别和排队，以确定应该首先响应哪个中断源的服务请求。然后，CPU需要获取应被服务的中断源的中断服务程序入口地址，并转到相应的中断服务程序执行。获取中断服务程序入口地址一般有两种方式：向量中断方式和查询中断方式，选择哪种方式通常在处理器的中断机构设计时就已经确定。向量中断向量中断是指CPU响应中断后，由中断机构自动将相应中断源的中断向量地址送入CPU，由其指明中断服务程序入口地址并实现程序切换的中断方式。在向量中断方式中，每个中断源都对应一个中断服务程序，而中断服务程序的入口地址被称为中断向量。在有的系统中，中断向量还包括中断服务程序开始执行时的程序状态字PSW的初始值。一般而言，系统中所有的中断向量都按顺序存放在内存指定位置的一张中断向量表中，当CPU识别出某中断源时，由硬件直接产生一个与该中断源对应的中断向量地址，以便能快速在中断向量表中找到并转入中断服务程序入口。图8.7给出了一个中断向量表实例。图中，A1、A2到An为n个中断向量的向量地址；PC1、PC2到PCn为各个中断服务程序的入口地址，在中断响应时由硬件自动加载到程序计数器PC中；PSW1、PSW2到PSWn为各个中断服务程序开始执行时的初始程序状态字，在中断响应时由硬件自动加载到程序状态字寄存器PSWR中。在有些计算机中，由硬件产生的向量地址不是直接地址，而是一个“位移量”，这个位移量加上CPU某寄存器里存放的基地址，最后得到中断服务程序的入口地址。还有的计算机在中断向量表中存放的不是中断服务程序入口地址，而是一条转移到中断服务程序入口地址的转移指令的指令字。在中断切换过程中，由硬件直接执行这条转移指令，从而跳转到相应的中断服务程序执行。查询中断在查询中断方式中，硬件不直接提供中断服务程序的入口地址，而是为所有中断服务程序安排一个公共的中断服务程序。在中断响应时，由公共的中断服务程序软件查询中断源，并跳转至相应中断服务子程序入口执行。图8.8给出了查询中断程序实例。在向量中断方式中，查找中断源、中断排队与判优、获取中断服务程序入口地址都是由硬件在中断周期中自动完成的。但在查询中断方式中，查找中断源和获取中断服务程序入口地址都是由软件实现的，而中断优先级则与软件查询中断源的顺序相关，因此可以更灵活地调整中断优先级。程序中断方式的基本接口示意图如图8.9所示。接口电路中有一个工作标志触发器(BS)，就绪标志触发器(RD)，还有一个控制触发器，称为允许中断触发器(EI)。程序中断由外设接口的状态和CPU两方面来控制。在接口方面，有决定是否向CPU发出中断请求的机构，主要是接口中的“准备就绪”标志(RD)和“允许中断”标志(EI)两个触发器。在CPU方面，有决定是否受理中断请求的机构，主要是“中断请求”标志(IR)和“中断屏蔽”标志(IM)两个触发器。上述四个标志触发器的具体功能如下。准备就绪触发器(RD)一旦设备做好一次数据的接收或发送，便发出一个设备动作完毕信号，使RD标志置“1”。在中断方式中，该标志用作中断源触发器，简称中断触发器。允许中断触发器(EI)可以用程序指令来置位。EI为“1”时，某设备可以向CPU发出中断请求；EI为“0”时，不能向CPU发出中断请求，这意味着某中断源的中断请求被禁止。设置EI标志的目的，就是通过软件来控制是否允许某设备发出中断请求。中断请求触发器(IR)它暂存中断请求线上由设备发出的中断请求信号。当IR标志为“1”时，表示设备发出了中断请求。中断屏蔽触发器(IM)是CPU是否受理中断或批准中断的标志。IM标志为“0”时，CPU可以受理外界的中断请求，反之，IM标志为“1”时，CPU不受理外界的中断请求。图8.9中，标号①～⑧表示由某一外设输入数据的控制过程。①表示由程序启动外设，将该外设接口的“忙”标志BS置“1”，“准备就绪”标志RD清“0”；②表示接口向外设发出启动信号；③表示数据由外设传送到接口的缓冲寄存器；④表示当设备动作结束或缓冲寄存器数据填满时，设备向接口送出一控制信号，将数据“准备就绪”标志RD置“1”；⑤表示允许中断标志EI为“1”时，接口向CPU发出中断请求信号；⑥表示在一条指令执行末尾CPU检查中断请求线，将中断请求线的请求信号接收到“中断请求”标志IR；⑦表示如果“中断屏蔽”标志IM为“0”时，CPU在一条指令执行结束后受理外设的中断请求，向外设发出响应中断信号并关闭中断；⑧表示转向该设备的中断服务程序入口；⑨表示在中断服务程序通过输入指令把接口中数据缓冲寄存器的数据读至CPU中的寄存器；⑩表示CPU发出控制信号C将接口中的BS和RD标志复位。1.单级中断的概念根据计算机系统对中断处理的策略不同，可分为单级中断系统和多级中断系统。单级中断系统是中断结构中最基本的形式。在单级中断系统中，所有的中断源都属于同一级，所有中断源触发器排成一行，其优先次序是离CPU近的优先权高。当响应某一中断请求时，执行该中断源的中断服务程序。在此过程中，不允许其他中断源再打断中断服务程序，即使优先权比它高的中断源也不能再打断。只有该中断服务程序执行完毕之后，才能响应其他中断。图8.10示出了单级中断示意图(a)和单级中断系统结构图(b)。图8.10(b)中所有的I/O设备通过一条线向CPU发出中断请求信号。CPU响应中断请求后，发出中断响应信号INTA，以链式查询方式识别中断源。这种中断结构与第6章讲的链式总线仲裁相对应，中断请求信号IR相当于总线请求信号BR。2.单级中断源的识别如何确定中断源，并转入被响应的中断服务程序入口地址，是中断处理首先要解决的问题。在单级中断中，采用串行排队链法来实现具有公共请求线的中断源判优识别。其逻辑电路见图8.11。图中下面的虚线部分是一个串行的优先链，称作中断优先级排队链。IRi是从各中断源设备来的中断请求信号，优先顺序从高到低是IR1、IR2、IR3。而IS1、IS2、IS3是与IR1、IR2、IR3相对应的中断排队选中信号，若ISi=1，即表示该中断源被选中。INTI为中断排队输入，INTO中断排队输出。若没有更高优先级的中断请求时，INTI=0，门1输出高电平，即IS1=1，若此时中断请求IR1=1(有中断请求)，当CPU发来中断识别信号INTA=1时，发出IR1请求的中断源被选中，选中信号经门7送入编码电路，产生一个唯一对应的设备地址，并经数据总线送往CPU的主存地址寄存器，然后执行该中断源设备的中断服务程序。另一方面，由于此时1IR为0，封锁门2，使IS2、IS3全为低电平，即排队识别工作不再向下进行。若IR1无请求，则IR1=0，门7被封锁，不会向编码电路送入选中信号。与此同时，因1IR=1，经门2和门3，使IS2=1，如果IR2=1，则被选中。否则查询链继续向下查询，直至找到发出中断请求信号IRi的中断源设备。3.中断向量的产生当CPU识别出某中断源时，由硬件直接产生一个与该中断源对应的向量地址，很快便引入中断服务程序。向量中断要求在硬件设计时考虑所有中断源的向量地址，而实际中断时只能产生一个向量地址。图8.11中上面部分即为中断向量产生逻辑，它是由编码电路实现的。1.多级中断的概念多级中断系统是指计算机系统中有相当多的中断源，根据各中断事件的轻重缓急程度不同而分成若干级别，每一中断级分配给一个优先权。一般说来，优先权高的中断级可以打断优先权低的中断服务程序，以程序嵌套方式进行工作。如图8.12(a)所示，三级中断优先权高于二级，而二级中断优先权又高于一级。根据系统的配置不同，多级中断又可分为一维多级中断和二维多级中断，如图8.12(b)所示。一维多级中断是指每一级中断中只有一个中断源，而二维多级中断是指每一级中断中有多个中断源。图中虚线左边结构为一维多级中断，如果去掉虚线则成为二维多级中断结构。对多级中断，着重说明如下几点。(1)一个系统若有n级中断，在CPU中就有n个中断请求触发器，总称为中断请求寄存器；与之对应的有n个中断屏蔽触发器，总称为中断屏蔽寄存器。与单级中断不同，在多级中断中，中断屏蔽寄存器的内容是一个很重要的程序现场，因此在响应中断时，需要把中断屏蔽寄存器的内容保存起来，并设置新的中断屏蔽状态。一般在某一级中断被响应后，要置“1”(关闭)本级和优先权低于本级的中断屏蔽触发器，清“0”(开放)更高级的中断屏蔽触发器，以此来实现正常的中断嵌套。(2)多级中断中的每一级可以只有一个中断源，也可以有多个中断源。在多级中断之间可以实现中断嵌套，但是同一级内有不同中断源的中断是不能嵌套的，必须是处理完一个中断后再响应和处理同一级内其他中断源。(3)设置多级中断的系统一般都希望有较快的中断响应时间，因此首先响应哪一级中断和哪一个中断源，由硬件逻辑实现，而不是用程序实现。图8.12中的中断优先级排队电路，就是用于决定优先响应中断级的硬件逻辑。另外，在二维中断结构中，除了有中断优先级排队电路确定优先响应中断级外，还要确定优先响应的中断源，一般通过链式查询的硬件逻辑来实现。显然，这里采用了独立请求方式与链式查询方式相结合的方法决定首先响应哪个中断源。(4)和单级中断情况类似，在多级中断中也使用中断堆栈保存现场信息。使用堆栈保存现场的好处是：①控制逻辑简单，保存和恢复现场的过程按先进后出顺序进行。②每一级中断不必单独设置现场保护区，各级中断现场可按其顺序放在同一个栈里。2.多级中断源的识别在多级中断中，每一级均有一根中断请求线送往CPU的中断优先级排队电路，对每一级赋予了不同的优先级。显然这种结构就是独立请求方式的逻辑结构。图8.13示出了独立请求方式的中断优先级排队与中断向量产生的逻辑结构。每个中断请求信号保存在“中断请求”触发器中，经“中断屏蔽”触发器控制后，可能有若干个中断请求信号IR′i进入虚线框所示的排队电路。排队电路在若干中断源中决定首先响应哪个中断源，并在其对应的输出线IRi上给出“1”信号，而其他各线为“0”信号(IR1～IR4中只有一个信号有效)。之后，编码电路根据排上队的中断源输出信号IRi，产生一个预定的地址码，转向中断服务程序入口地址。例如，假设图8.13中请求源1的优先级最高，请求源4的优先级最低。又假定中断请求寄存器的内容为1111，中断屏蔽寄存器的内容为0010，那么进入排队器的中断请求是1101。根据优先次序，排队器输出为1000。然后由编码器产生中断源1所对应的向量地址。在多级中断中，如果每一级请求线上还连接有多个中断源设备，那么在识别中断源时，还需要进一步用串行链式方式查询。这意味着要用二维方式来设计中断排队逻辑。【1.中断类型Pentium有两类中断源，即中断和异常。中断通常称为外部中断，它是由CPU的外部硬件信号引发的。有两种情况：①可屏蔽中断：CPU的INTR引脚收到中断请求信号，如果CPU中标志寄存器IF=1时，可引发中断；IF=0时，中断请求信号在CPU内部被禁止。②非屏蔽中断：CPU的NMI引脚收到的中断请求信号而引发的中断，这类中断不能被禁止。异常通常称为异常中断，它是由指令执行引发的。有两种情况：①执行异常：CPU执行一条指令过程中出现错误、故障等不正常条件引发的中断。②执行软件中断指令：如执行INT0，INT3，INTn等指令，执行时产生异常中断。如果详细分类，Pentium共有256种中断和异常。每种中断给予一个编号，称为中断向量号(0～255)，以便发生中断时，程序转向相应的中断服务子程序入口地址。当有一个以上的异常或中断发生时，CPU以一个预先确定的优先顺序为它们先后进行服务。中断优先级分为5级。异常中断的优先级高于外部中断的优先级，这是因为异常中断发生在取一条指令或译码一条指令或执行一条指令时出现故障的情况下，情况更为紧急。2.中断服务子程序进入过程中断服务子程序的入口地址信息存于中断向量号检索表内。实模式为中断向量表IVT，保护模式为中断描述符表IDT。CPU识别中断类型取得中断向量号的途径有三种：①指令给出，如软件中断指令INTn中的n即为中断向量号。②外部提供，可屏蔽中断是在CPU接收到INTR信号时产生一个中断识别周期，接收外部中断控制器由数据总线送来的中断向量号；非屏蔽中断是在接收到NMI信号时中断向量号固定为2。③CPU识别错误、故障现象，根据异常和中断产生的条件自动指定向量号。CPU依据中断向量号获取中断服务子程序入口地址，但在实模式下和保护模式下采用不同的途径。实模式下使用中断向量表中断向量表IVT位于内存地址0开始的1KB空间。实模式是16位寻址，中断服务子程序入口地址(段，偏移)的段寄存器和段内偏移量各为16位。它们直接登记在IVT表中，每个中断向量号对应一个中断服务子程序入口地址。每个入口地址占4字节。256个中断向量号共占1KB。CPU取得向量号后自动乘以4，作为访问IVT的偏移，读取IVT相应表项，将段地址和偏移量设置到CS和IP寄存器，从而进入相应的中断控制器8259中断控制器中断服务子程序。进入过程如图8.14(a)所示。保护模式下使用中断描述符表保护模式为32位寻址。中断描述符表IDT每一表项对应一个中断向量号，表项称为中断门描述符、陷阱门描述符。这些门描述符为8字节长，对应256个中断向量号，IDT表长为2KB。由中断描述符表寄存器IDTR来指示IDT的内存地址。以中断向量号乘以8作为访问IDT的偏移，读取相应的中断门/陷阱门描述符表项。门描述符给出中断服务子程序入口地址(段，偏移)，其中32位偏移量装入EIP寄存器，16位的段值装入CS寄存器。由于此段值是选择符，还必须访问GDT或LDT，才得到段的基地址。保护模式下进入中断服务子程序的过程如图8.14(b)所示。3.中断处理过程上面说明了中断向量号的获取方式，也说明了实模式与保护模式下进入中断服务子程序的途径。现将Pentium机的中断处理过程叙述如下：(1)当中断处理的CPU控制权转移涉及特权级改变时，必须把当前的SS和ESP两个寄存器的内容压入系统堆栈予以保存。(2)标志寄存器EFLAGS的内容也压入堆栈。(3)清除标志触发器TF和IF。(4)当前的代码段寄存器CS和指令指针EIP也压入此堆栈。(5)如果中断发生伴随有错误码，则错误码也压入此堆栈。(6)完成上述中断现场保护后，从中断向量号获取的中断服务子程序入口地址(段，偏移)分别装入CS和EIP，开始执行中断服务子程序。(7)中断服务子程序最后的IRET指令使中断返回。保存在堆栈中的中断现场信息被恢复，并由中断点继续执行原程序。直接内存访问(DMA)，是一种完全由硬件执行I/O交换的工作方式。在这种方式中，DMA控制器从CPU完全接管对总线的控制，数据交换不经过CPU，而直接在内存和I/O设备之间进行。DMA方式一般用于高速传送成组数据。DMA控制器将向内存发出地址和控制信号，修改地址，对传送的字的个数计数，并且以中断方式向CPU报告传送操作的结束。DMA方式的主要优点是速度快。由于CPU根本不参加传送操作，因此就省去了CPU取指令、取数、送数等操作。在数据传送过程中，没有保存现场、恢复现场之类的工作。内存地址修改、传送字个数的计数等，也不是由软件实现，而是用硬件线路直接实现的。所以DMA方式能满足高速I/O设备的要求，也有利于CPU效率的发挥。正因为如此，包括微型机在内，DMA方式在计算机中被广泛采用。目前由于大规模集成电路工艺的发展，很多厂家直接生产大规模集成电路的DMA控制器。虽然DMA控制器复杂程度差不多接近于CPU，但使用起来非常方便。DMA方式的特点如下。DMA方式以响应随机请求的方式，实现主存与I/O设备间的快速数据传送。DMA方式并不影响CPU的程序执行状态，只要不存在访存冲突，CPU就可以继续执行自己的程序。但是DMA只能处理简单的数据传送，不能在传送数据的同时进行判断和计算。与查询方式相比，在DMA方式中CPU不必等待查询，可以执行自身的程序，而且直接由硬件(DMA控制器)控制传输过程，CPU不必执行指令。与中断方式相比，DMA方式仅需占用系统总线，不切换程序，因而CPU可与DMA传送并行工作；DMA可以实现简单的数据传送，难以识别和处理复杂事态。由于DMA传送开始的时间是随机的，但开始传送后需要进行连续批量的数据交换，因此DMA方式非常适合主存与高速I/O设备间的简单数据传送。例如，以数据块为单位的磁盘读/写操作；以数据帧为单位的外部通信；以及大批量数据采集等场景。DMA的种类很多，但多种DMA至少能执行以下一些基本操作。(1)从外围设备发出DMA请求。(2)CPU响应请求，把CPU工作改成DMA操作方式，DMA控制器从CPU接管总线的控制。(3)由DMA控制器对内存寻址，即决定数据传送的内存单元地址及数据传送个数的计数，并执行数据传送的操作。第8章输入/输出系统261(4)向CPU报告DMA操作的结束。注意，在DMA方式中，一批数据传送前的准备工作，以及传送结束后的处理工作，均由管理程序承担，而DMA控制器仅负责数据传送的工作。DMA技术的出现，使得外围设备可以通过DMA控制器直接访问内存，与此同时，CPU可以继续执行程序。那么DMA控制器与CPU怎样分时使用内存呢?根据每提出一次DMA请求，DMA控制器将占用多少个总线周期，可以将DMA传送分成以下几种方式：①成组连续传送方式(停止CPU访存)；②周期挪用方式(单字传送方式，周期窃取方式)；③透明DMA方式(DMA与CPU交替操作方式，总线周期分时方式)。1.成组连续传送方式当外围设备要求传送一批数据时，由DMA控制器发一个停止信号给CPU，要求CPU放弃对地址总线、数据总线和有关控制总线的使用权。DMA控制器获得总线控制权以后，开始进行数据传送。在一批数据传送完毕后，DMA控制器通知CPU可以使用内存，并把总线控制权交还给CPU。图8.15(a)是这种传送方式的时间图。很显然，在这种DMA传送过程中，CPU基本处于不工作状态或者说保持状态。这种传送方法的优点是控制简单，它适用于数据传输率很高的设备进行成组传送。缺点是在DMA控制器访内阶段，内存的效能没有充分发挥，相当一部分内存工作周期是空闲的。这是因为，外围设备传送两个数据之间的间隔一般总是大于内存存储周期，即使高速I/O设备也是如此。例如，软盘读出一个8位二进制数大约需要32μs，而半导体内存的存储周期小于0.2μs，因此许多空闲的存储周期不能被CPU利用。2.周期挪用方式在这种DMA传送方法中，当I/O设备没有DMA请求时，CPU按程序要求访问内存；一旦I/O设备有DMA请求，则由I/O设备挪用一个或几个内存周期。I/O设备要求DMA传送时可能遇到两种情况：一种是此时CPU不需要访内，如CPU正在执行乘法指令。由于乘法指令执行时间较长，此时I/O访内与CPU访内没有冲突，即I/O设备挪用一两个内存周期对CPU执行程序没有任何影响。另一种是I/O设备要求访内时CPU也要求访内，这就产生了访内冲突，在这种情况下I/O设备访内优先，因为I/O访内有时间要求，前一个I/O数据必须在下一个访内请求到来之前存取完毕。显然，在这种情况下I/O设备挪用一两个内存周期，意味着CPU延缓了对指令的执行，或者更明确地说，在CPU执行访内指令的过程中插入DMA请求，挪用了一两个内存周期。图8.15(b)是周期挪用的DMA方式示意图。与停止CPU访内的DMA方法比较，周期挪用的方法既实现了I/O传送，又较好地发挥了内存和CPU的效率，是一种广泛采用的方法。但是I/O设备每一次周期挪用都有申请总线控制权、建立总线控制权和归还总线控制权的过程，所以传送一个字对内存来说要占用一个周期，但对DMA控制器来说一般要2～5个内存周期(视逻辑线路的延迟而定)。因此，周期挪用的方法适用于I/O设备读写周期大于内存存储周期的情况。3.透明DMA方式如果CPU的工作周期比内存存取周期长很多，则采用交替访内的方法可以使DMA传送和CPU同时发挥最高的效率，其原理示意图如图8.15(c)所示。假设CPU工作周期为1.2μs，内存存取周期小于0.6μs，那么一个CPU周期可分为C1和C2两个分周期，其中C1专供DMA控制器访内，C2专供CPU访内。这种方式不需要总线使用权的申请、建立和归还过程，总线使用权是通过C1和C2分时控制的。CPU和DMA控制器各自有自己的访内地址寄存器、数据寄存器和读/写信号等控制寄存器。在C1周期中，如果DMA控制器有访内请求，可将地址、数据等信号送到总线上。在C2周期中，如CPU有访内请求，同样传送地址、数据等信号。事实上，对于总线，这是用C1和C2控制的一个多路转换器，这种总线控制权的转移几乎不需要什么时间，所以对DMA传送来讲效率是很高的。这种传送方式称为“透明的DMA”方式，其来由是这种DMA传送对CPU来说，如同透明的玻璃一般，没有任何感觉或影响。在透明的DMA方式下工作，CPU既不停止主程序的运行，也不进入等待状态，是一种高效率的工作方式。当然，相应的硬件逻辑也就更加复杂。1.DMA控制器的基本组成一个DMA控制器，实际上是采用DMA方式的外围设备与系统总线之间的接口电路。第8章输入/输出系统263这个接口电路是在中断接口的基础上再加DMA机构组成的。图8.16示出了一个最简单的DMA控制器组成示意图，它由以下逻辑部件组成。内存地址计数器用于存放内存中要交换的数据的地址。在DMA传送前，须通过程序将数据在内存中的起始位置(首地址)送到内存地址计数器。而当DMA传送时，每交换一次数据，将地址计数器加“1”，从而以增量方式给出内存中要交换的一批数据的地址。字计数器用于记录传送数据块的长度(多少字数)。其内容也是在数据传送之前由程序预置，交换的字数通常以补码形式表示。在DMA传送时，每传送一个字，字计数器就加“1”，当计数器溢出即最高位产生进位时，表示这批数据传送完毕，于是引起DMA控制器向CPU发中断信号。数据缓冲寄存器用于暂存每次传送的数据(一个字)。当输入时，由设备(如磁盘)送往数据缓冲寄存器，再由缓冲寄存器通过数据总线送到内存。反之，输出时，由内存通过数据总线送到数据缓冲寄存器，然后再送到设备。DMA请求标志每当设备准备好一个数据字后给出一个控制信号，使“DMA请求”标志置“1”。该标志置位后向“控制/状态”逻辑发出DMA请求，后者又向CPU发出总线使用权的请求(HOLD)，CPU响应此请求后发回响应信号HLDA，“控制/状态”逻辑接收此信号后发出DMA响应信号，使“DMA请求”标志复位，为交换下一个字做好准备。控制/状态逻辑由控制和时序电路以及状态标志等组成，用于修改内存地址计数器和字计数器，指定传送类型(输入或输出)，并对“DMA请求”信号和CPU响应信号进行协调和同步。中断机构当字计数器溢出时(全0)，意味着一组数据交换完毕，由溢出信号触发中断机构，向CPU提出中断报告。这里的中断与8.3节介绍的I/O中断所采用的技术相同，但中断的目的不同，前面是为了数据的输入或输出，而这里是为了报告一组数据传送结束。因此它们是I/O系统中不同的中断事件。2.DMA数据传送过程DMA的数据块传送过程可分为三个阶段：传送前预处理；正式传送；传送后处理。预处理阶段由CPU执行几条输入输出指令，测试设备状态，向DMA控制器的设备地址寄存器中送入设备号并启动设备，向内存地址计数器中送入起始地址，向字计数器中送入交换的数据字个数。在这些工作完成后，CPU继续执行原来的主程序。当外设准备好发送数据(输入)或接受数据(输出)时，它发出DMA请求，由DMA控制器向CPU发出总线使用权的请求(HOLD)。图8.17示出了成组连续传送方式的DMA传送数据的流程图。当外围设备发出DMA请求时，CPU在指令周期执行结束后响应该请求，并使CPU的总线驱动器处于第三态(高阻状态)。之后，CPU与系统总线相脱离，而DMA控制器接管数据总线与地址总线的控制，并向内存提供地址，于是，在内存和外围设备之间进行数据交换。每交换一个字，则地址计数器和字计数器加“1”，当计数值到达零时，DMA操作结束，DMA控制器向CPU提出中断报告。DMA的数据传送是以数据块为基本单位进行的，因此，每次DMA控制器占用总线后，无论是数据输入操作，还是输出操作，都是通过循环来实现的。当进行输入操作时，外围设备的数据(一次一个字或一字节)传向内存；当进行输出操作时，内存的数据传向外围设备。DMA的后处理进行的工作是，一旦DMA的中断请求得到响应，CPU停止主程序的执行，转去执行中断服务程序做一些DMA的结束处理工作。这些工作包括校验送入内存的数据是否正确；决定继续用DMA方式传送下去，还是结束传送；测试在传送过程中是否发生了错误等。基本DMA控制器与系统的连接可采用两种方式：一种是公用的DMA请求方式，另一种是独立的DMA请求方式，这与中断方式类似。思考题说出DMA方式的创新点，其意义何在？前面介绍的是最简单的DMA控制器，一个控制器只控制一个I/O设备。实际中经常采用的是选择型DMA控制器和多路型DMA控制器，它们已经被做成集成电路片子。1.选择型DMA控制器图8.18是选择型DMA控制器的逻辑框图，它在物理上可以连接多个设备，而在逻辑上只允许连接一个设备。换句话说，在某一段时间内只能为一个设备服务。选择型DMA控制器工作原理与前面的简单DMA控制器基本相同。除了前面讲到的基本逻辑部件外，还有一个设备号寄存器。数据传送是以数据块为单位进行的，在每个数据块传送之前的预置阶段，除了用程序中I/O指令给出数据块的传送个数、起始地址、操作命令外，还要给出所选择的设备号。从预置开始，一直到这个数据块传送结束，DMA控制器只为所选设备服务。下一次预置再根据I/O指令指出的设备号，为另一选择的设备服务。显然，选择型DMA控制器相当于一个逻辑开关，根据I/O指令来控制此开关与某个设备连接。选择型DMA控制器只增加少量硬件达到了为多个外围设备服务的目的，它特别适合数据传输率很高以至于接近内存存取速度的设备。在很快地传送完一个数据块后，控制器又可为其他设备服务。2.多路型DMA控制器选择型DMA控制器不适用于慢速设备。但是多路型DMA控制器却适合于同时为多个慢速外围设备服务。图8.19表示独立请求方式的多路型DMA控制器的原理图。多路型DMA不仅在物理上可以连接多个外围设备，而且在逻辑上也允许这些外围设备同时工作，各设备以字节交叉方式通过DMA控制器进行数据传送。由于多路型DMA同时要为多个设备服务，因此对应多少个DMA通路(设备)，在控制器内部就有多少组寄存器用于存放各自的传送参数。图8.20是一个多路型DMA控制器的芯片内部逻辑结构，通过配合使用I/O通用接口片子，它可以对8个独立的DMA通路(CH)进行控制，使外围设备以周期挪用方式对内存进行存取。8条独立的DMA请求线或响应线能在外围设备与DMA控制器之间进行双向通信。一条线上进行双向通信是通过分时和脉冲编码技术实现的。也可以分别设立DMA请求线和响应线实现双向通信。每条DMA线在优先权结构中具有固定位置，一般DMA0线具有最高优先权，DMA7线具有最低优先权。控制器中有8个8位的控制传送长度的寄存器，8个16位的地址寄存器。每个长度寄存器和地址寄存器对应一个设备。每个寄存器都可以用程序中的I/O指令从CPU送入控制数据。每一寄存器组各有一个计数器，用于修改内存地址和传送长度。当某个外围设备请求DMA服务时，操作过程如下：(1)DMA控制器接到设备发出的DMA请求时，将请求转送到CPU。(2)CPU在适当的时刻响应DMA请求。若CPU不需要占用总线则继续执行指令；若CPU需要占用总线，则CPU进入等待状态。(3)DMA控制器接到CPU的响应信号后，进行以下工作：①对现有DMA请求中优先权最高的请求给予DMA响应；②选择相应的地址寄存器的内容驱动地址总线；③根据所选设备操作寄存器的内容，向总线发读、写信号；④外围设备向数据总线传送数据，或从数据总线接收数据；⑤每字节传送完毕后，DMA控制器使相应的地址寄存器和长度寄存器加“1”或减“1”。以上是一个DMA请求的过程，在一批数据传送过程中，要多次重复上述过程，直到外围设备表示一个数据块已传送完毕，或该设备的长度控制器判定传送长度已满。1)通道的功能DMA控制器的出现已经减轻了CPU对数据输入输出的控制，使得CPU的效率有显著的提高。而通道的出现则进一步提高了CPU的效率。这是因为通道是一个特殊功能的处理器，它有自己的指令和程序专门负责数据输入输出的传输控制，而CPU将“传输控制”的功能下放给通道后只负责“数据处理”功能。这样，通道与CPU分时使用存储器，实现了CPU内部运算与I/O设备的并行工作。图8.22是典型的具有通道的计算机系统结构图。它具有两种类型的总线，一种是系统总线，它承担通道与存储器、CPU与存储器之间的数据传输任务。另一种是通道总线，即I/O总线，它承担外围设备与通道之间的数据传送任务。这两类总线可以分别按照各自的时序同时进行工作。由图8.20看出，通道总线可以接若干个I/O模块，一个I/O模块可以接一个或多个设备。因此，从逻辑结构上讲，I/O系统一般具有四级连接：CPU与存储器通道I/O模块外围设备。为了便于通道对各设备的统一管理，通道与I/O模块之间用统一的标准接口，I/O模块与设备之间则根据设备要求不同而采用专用接口。具有通道的机器一般是大型计算机和服务器，数据流量很大。如果所有的外设都接在一个通道上，那么通道将成为限制系统效能的瓶颈。因此大型计算机的I/O系统一般接有多个通道。显然，设立多个通道的另一好处是，对不同类型的外设可以进行分类管理。存储管理部件是存储器的控制部件，它的主要任务是根据事先确定的优先次序，决定下一周期由哪个部件使用系统总线访问存储器。由于大多数I/O设备是旋转性的设备，读写信号具有实时性，不及时处理会丢失数据，所以通道与CPU同时要求访存储器时，通道优先权高于CPU。在多个通道有访存请求时，选择通道的优先权高于多路通道，因为前者一般连接高速设备。通道的基本功能是执行通道指令，组织外围设备和内存进行数据传输，按I/O指令要求启动外围设备，向CPU报告中断等，具体有以下五项任务。(1)接受CPU的I/O指令，按指令要求与指定的外围设备进行通信。(2)从存储器选取属于该通道程序的通道指令，经译码后向I/O控制器模块发送各种命令。(3)组织外设和存储器之间进行数据传送，并根据需要提供数据缓存的空间，以及提供数据存入存储器的地址和传送的数据量。(4)从外围设备得到设备的状态信息，形成并保存通道本身的状态信息，根据要求将这些状态信息送到存储器的指定单元，供CPU使用。(5)将外设的中断请求和通道本身的中断请求，按次序及时报告CPU。2)CPU对通道的管理CPU是通过执行I/O指令以及处理来自通道的中断，实现对通道的管理。来自通道的中断有两种，一种是数据传送结束中断，另一种是故障中断。通常把CPU运行操作系统的管理程序的状态称为管态，而把CPU执行目的程序时的状态称为目态。大型计算机的I/O指令都是管态指令，只有当CPU处于管态时，才能运行I/O指令，目态时不能运行I/O指令。这是因为大型计算机的软、硬件资源为多个用户所共享，而不是分给某个用户专用。3)通道对设备控制器的管理通道通过使用通道指令来控制I/O模块进行数据传送操作，并以通道状态字接收I/O模块反映的外围设备的状态。因此，I/O模块是通道对I/O设备实现传输控制的执行机构。I/O模块的具体任务如下：(1)从通道接受通道指令，控制外围设备完成所要求的操作。(2)向通道反映外围设备的状态。(3)将各种外围设备的不同信号转换成通道能够识别的标准信号。思考题通道的设计理念，在技术上有什么创新？根据通道的工作方式，通道分为选择通道、多路通道两种类型。一个系统可以兼有两种类型的通道，也可以只有其中一种。1)选择通道选择通道又称高速通道，在物理上它可以连接多个设备，但是这些设备不能同时工作，在某一段时间内通道只能选择一个设备进行工作。选择通道很像一个单道程序的处理器，在一段时间内只允许执行一个设备的通道程序，只有当这个设备的通道程序全部执行完毕后，才能执行其他设备的通道程序。选择通道主要用于连接高速外围设备，如磁盘、磁带等，信息以数据块方式高速传输。由于数据传输率很高，所以在数据传送期间只为一台设备服务是合理的。但是这类设备的辅助操作时间很长，如磁盘机平均找道时间是10ms，磁带机走带时间可以长达几分钟。在这样长的时间里通道处于等待状态，因此整个通道的利用率不是很高。2)多路通道多路通道又称多路转换通道，在同一时间能处理多个I/O设备的数据传输。它又分为数组多路通道和字节多路通道。数组多路通道是对选择通道的一种改进，它的基本思想是当某设备进行数据传送时，通道只为该设备服务；当设备在执行寻址等控制性动作时，通道暂时断开与这个设备的连接，挂起该设备的通道程序，去为其他设备服务，即执行其他设备的通道程序。所以数组多路通道很像一个多道程序的处理器。数组多路通道不仅在物理上可以连接多个设备，而且在一段时间内能交替执行多个设备的通道程序，换句话说在逻辑上可以连接多个设备，这些设备应是高速设备。由于数组多路通道既保留了选择通道高速传送数据的优点，又充分利用了控制性操作的时间间隔为其他设备服务，使通道效率得到充分发挥，因此数组多路通道在大型系统中得到较多应用。字节多路通道主要用于连接大量的低速设备，如键盘、打印机等，这些设备的数据传输率很低。例如，数据传输率是1000B/s，即传送1字节的时间是1ms，而通道从设备接收或发送1字节只需要几百纳秒，因此通道在传送2字节之间有很多空闲时间，字节多路通道正是利用这个空闲时间为其他设备服务。字节多路通道和数组多路通道有共同之处，即它们都是多路通道，在一段时间内能交替执行多个设备的通道程序，使这些设备同时工作。字节多路通道和数组多路通道也有不同之处，主要是：①数组多路通道允许多个设备同时工作，但只允许一个设备进行传输型操作，其他设备进行控制型操作。而字节多路通道不仅允许多个设备同时操作，而且也允许它们同时进行传输型操作。②数组多路通道与设备之间数据传送的基本单位是数据块，通道必须为一个设备传送完一个数据块以后，才能为别的设备传送数据块。而字节多路通道与设备之间数据传送的基本单位是字节，通道为一个设备传送完1字节后，又可以为另一个设备传送1字节，因此各设备与通道之间的数据传送是以字节为单位交替进行。通道结构的进一步发展，出现了两种计算机I/O系统结构。一种是通道结构的I/O处理器，通常称为输入输出处理器(IOP)。IOP可以和CPU并行工作，提供高速的DMA处理能力，实现数据的高速传送。但是它不是独立于CPU工作的，而是主机的一个部件。有些IOP如Intel8089IOP，还提供数据的变换、搜索以及字装配/拆卸能力。这种IOP可应用于服务器及微型计算机中。另一种是外围处理机(PPU)。PPU基本上是独立于主机工作的，它有自己的指令系统，完成算术/逻辑运算，读/写主存储器，与外设交换信息等。有的外围处理机干脆就选用已有的通用机。外围处理机I/O方式一般应用于大型高效率的计算机系统中。思考题你对通道技术的未来发展有什么见解？SCSI是小型计算机系统接口的简称，其设计思想来源于IBM大型机系统的I/O通道结构，目的是使CPU摆脱对各种设备的繁杂控制。它是一个高速智能接口，可以混接各种磁盘、光盘、磁带机、打印机、扫描仪、条码阅读器以及通信设备。它首先应用于Macintosh和Sun平台上，后来发展到工作站、网络服务器和Pentium系统中，并成为ANSI(美国国家标准局)标准。SCSI有如下性能特点。(1)SCSI接口总线由8条数据线、一条奇偶校验线、9条控制线组成。使用50芯电缆，规定了两种电气条件：单端驱动，电缆长6m；差分驱动，电缆最长25m。(2)总线时钟频率为5MHz，异步方式数据传输率是2.5MB/s，同步方式数据传输率是5MB/s。(3)SCSI接口总线以菊花链形式最多可连接8台设备。在Pentium中通常是：由一个主适配器HBA与最多7台外围设备相接，HBA也算作一个SCSI设备，由HBA经系统总线(如PCI)与CPU相连，如图8.23所示。(4)每个SCSI设备有自己的唯一设备号ID0～7。ID=7的设备具有最高优先权，ID=0的设备优先权最低。SCSI采用分布式总线仲裁策略。在仲裁阶段，竞争的设备以自己的设备号驱动数据线中相应的位线(如ID=7的设备驱动DB7线)，并与数据线上的值进行比较。因此仲裁逻辑比较简单，而且在SCSI的总线选择阶段，启动设备和目标设备的设备号能同时出现在数据线上。(5)所谓SCSI设备是指连接在SCSI总线上的智能设备，即除主适配器HBA外，其他SCSI设备实际是外围设备的适配器或控制器。每个适配器或控制器通过各自的设备级I/O线可连接一台或几台同类型的外围设备(如一个SCSI磁盘控制器接2台硬盘驱动器)。标准允许每个SCSI设备最多有8个逻辑单元，每个逻辑单元可以是物理设备也可以是虚拟设备。每个逻辑单元有一个逻辑单元号(LUN0～LUN7)。(6)由于SCSI设备是智能设备，对SCSI总线以至主机屏蔽了实际外设的固有物理属性(如磁盘柱面数、磁头数等参数)，各SCSI设备之间就可用一套标准的命令进行数据传送，也为设备的升级或系统的系列化提供了灵活的处理手段。(7)SCSI设备之间是一种对等关系，而不是主从关系。SCSI设备分为启动设备(发命令的设备)和目标设备(接受并响应命令的设备)。但启动设备和目标设备是依当时总线运行状态来划分的，而不是预先规定的。总之，SCSI是系统级接口，是处于主适配器和智能设备控制器之间的并行I/O接口。一块主适配器可以接7台具有SCSI接口的设备，这些设备可以是类型完全不同的设备，主适配器却只占主机的一个槽口。这对于缓解计算机挂接外设的数量和类型越来越多、主机槽口日益紧张的状况很有吸引力。为提高数据传输率和改善接口的兼容性，20世纪90年代又陆续推出了SCSI-2和SCSI-3标准。SCSI-2扩充了SCSI的命令集，通过提高时钟速率和数据线宽度，最高数据传输率可达40MB/s，采用68芯电缆，且对电缆采用有源终端器。SCSI-3标准允许SCSI总线上连接的设备由8个提高到16个，可支持16位数据传输。另一个变化是发展串行SCSI，使串行数据传输率达到640Mb/s(电缆)或1Gb/s(光纤)，从而使串行SCSI成为IEEE1394标准的基础。1.1394性能特点随着CPU速度达到上百兆赫，存储器容量达到GB级，以及PC、工作站、服务器对快速I/O的强烈需求，工业界期望能有一种更高速、连接更方便的I/O接口。1993年Apple公司公布了一种高速串行接口，希望能取代并行的SCSI接口。IEEE接管了这项工作，在此基础上制定了IEEE1394-FireWire标准，它是一个通用的串行I/O接口。IEEE1394串行接口与SCSI等并行接口相比，有如下三个显著特点。(1)数据传送的高速性。1394的数据传输率分为100Mb/s、200Mb/s、400Mb/s三档。而SCSI-2也只有40MB/s(相当于320Mb/s)。这样的高速特性特别适合于新型高速硬盘及多媒体数据传送。1394之所以达到高速，一是因为串行传送比并行传送容易提高数据传送时钟速率；二是因为采用了DS-Link编码技术，把时钟信号的变化转变为选通信号的变化，即使在高的时钟速率下也不易引起信号失真。(2)数据传送的实时性。实时性可保证图像和声音不会出现时断时续的现象，因此对多媒体数据传送特别重要。1394之所以做到实时性，原因有二：一是它除了异步传送外，还提供了一种等步传送方式，数据以一系列的固定长度的包规整间隔地连续发送，端到端既有最大延时限制而又有最小延时限制；二是总线仲裁除优先权仲裁之外，还有均等仲裁和紧急仲裁方式。(3)体积小易安装，连接方便。1394使用6芯电缆，直径约为6mm，插座也小。而SCSI使用50芯或68芯电缆，插座体积也大。在当前PC机要连接的设备越来越多，主机箱的体积越显窄小的情况下，电缆细、插座小的1394是很有吸引力的，尤其对笔记本电脑一类机器。1394的电缆不需要与电缆阻抗匹配的终端，而且电缆上的设备随时可从插座拔出或插入，即具有热插入能力。这对用户安装和使用1394设备很有利。2.1394配置1394采用菊花链式配置，但也允许树形结构配置。事实上，菊花链结构是树形结构的一种特殊情况。1394接口也需要一个主适配器和系统总线相连。这个主适配器的功能逻辑在高档的Pentium机中是集成在主板的核心芯片组的PCI总线到ISA总线的桥芯片中。机箱的背面只看到主适配器的外接端口插座。在这里将主适配器及其端口称为主端口。主端口是1394接口树形配置结构的根节点。一个主端口最多可连接63台设备，这些设备称为节点，它们构成亲子关系。两个相邻节点之间的电缆最长为4.5m，但两个节点之间进行通信时中间最多可经过15个节点的转接再驱动，因此通信的最大距离是72m。电缆不需要终端器。图8.24给出一个IEEE1394配置的实例，其中右侧是线性链接方式，左侧是亲子层次链接方式。整体是一个树形结构。1394采用集中式总线仲裁方式。中央仲裁逻辑在主端口内，并以先到先服务方法来处理节点提出的总线访问请求。在n个节点同时提出使用总线请求时，按照优先权进行仲裁。最靠近根节点的竞争节点有高的优先权；同样靠近根节点的竞争节点，其设备标识号ID大的有更高优先权。1394具有PnP(即插即用)功能，设备标识号是系统自动指定的，而不是用户设定的。为了保证总线设备的对等性和数据传送的实时性，1394的总线仲裁还增加了均等仲裁和紧急仲裁功能。均等仲裁是将总线时间分成均等的间隔，当间隔期间开始时，竞争的每个节点置位自己的仲裁允许标志，在间隔期内各节点可竞争总线的使用权。一旦某节点获得总线访问权，则它的仲裁允许标志被复位，在此期间它不能再去竞争总线，以此来防止具有高优先权的忙设备独占总线。紧急仲裁是指对某些高优先权的节点可为其指派紧急优先权。具有紧急优先权的节点可在一个间隔期内多次获得总线控制权，允许它控制75%的总线可用时间。3.1394协议集1394的一个重要特色是，它规范了一个三层协议集，将串行总线与各外围设备的交互动作标准化。图8.25表示IEEE1394的协议集。业务层定义了一个完整的请求-响应协议实现总线传输，包括读操作、写操作和锁定操作。链路层可为应用程序直接提供等步数据传送服务。它支持异步和等步的包发送和接收。异步包传送是，一个可变总量的数据及业务层的几个信息字节作为一个包传送到显式地址的目标方，并要求返回一个认可包。等步包传送是，一个可变总量的数据以一串固定大小的包按照规整间隔来发送，使用简化寻址方式，不要求目标方认可。1394把完成一个包的递交过程称为子动作。物理层将链路层的逻辑信号根据不同的串行总线介质转换成相应的电信号，也为串行总线的接口定义了电气和机械特性。实际上，1394串行接口的物理拓扑结构分成“底板环境”和“电气环境”两部分。总线规范并未要求特别的环境设定。所有节点可严格限定在单一底板上，也可直接连在电缆上。串行总线管理它提供总线节点所需的标准控制、状态寄存器服务和基本控制功能。总之，IEEE1394是一种高速串行I/O标准接口。英特尔、微软等公司联手将1394列为1998年以后的新一代PC机新标准。另一个重大特点是，各被连接装置的关系是平等的，不用PC机介入也能自成系统。例如，利用数字相机直接进行印刷的打印机便可利用这一特点。这意味着1394在家电等消费类设备的连接应用方面有很好的前景。I/O系统设计要考虑两种主要规范：时延约束和带宽约束。在这两种情况下，对通信模式的认知将影响整个系统的分析和设计。时延约束时延约束确保完成一次I/O操作的延迟时间被限制在某个数量范围内。一种简单的情况是认为系统是无负载的，设计者必须保证满足某些时延约束，这是因为这种限制对应用程序非常重要，或者设备为了防止某种错误必须接受某些有保证的服务。同样，在一个无负载系统中计算延迟时间相对比较容易，因为只用跟踪I/O操作的路径并累加单个延迟时间即可。在有负载的情况下，得到平均时延是一个复杂的问题。这些问题可以通过排队理论(当工作量请求的行为和I/O服务次数能够通过简单的分布来近似时)或模拟(当I/O事件的行为很复杂时)的方法解决。带宽约束给定一个工作负载，设计一个满足一组带宽约束的I/O系统是设计者需要面对的另一个典型问题。或者，给定一个部分配置好的I/O系统，要求设计者平衡系统，以维持该系统预配置部分规定的可能达到的最大带宽。设计这样一个系统的一般方法如下。(1)找出I/O系统中效率最低的连接，它是I/O路径中约束设计的部件。依赖于不同的工作负载，该部件可以存在于任何地方，包括CPU、内存系统、底板总线、I/O控制器或I/O设计。工作负载和配置限制会决定这个效率最低的部件到底在哪儿。(2)配置这个部件以保持所需的带宽。(3)研究系统中其他部分的需求，配置它们以支持这个带宽。各种外围设备的数据传输速率相差很大。如何保证主机与外围设备在时间上同步，则涉及外围设备的定时问题。一个计算机系统的性能，不仅取决于CPU，还取决于I/O速度。在计算机系统中，CPU对外围设备的管理方式有：①程序查询方式；②程序中断方式；③DMA方式；④通道方式。每种方式都需要硬件和软件结合起来进行。程序查询方式是CPU管理I/O设备的最简单方式，CPU定期执行设备服务程序，主动来了解设备的工作状态。这种方式浪费CPU的宝贵资源。程序中断方式是各类计算机中广泛使用的一种数据交换方式。当某一外设的数据准备就绪后，它“主动”向CPU发出请求信号。CPU响应中断请求后，暂停运行主程序，自动转移到该设备的中断服务子程序，为该设备进行服务，结束时返回主程序。中断处理过程可以嵌套进行，优先级高的设备可以中断优先级低的中断服务程序。DMA技术的出现，使得外围设备可以通过DMA控制器直接访问内存，与此同时，CPU可以继续程序。DMA方式采用以下三种方法：①停止CPU访内；②周期挪用；③DMA与CPU交替访内。DMA控制器按其组成结构，分为选择型和多路型两类。通道是一个特殊功能的处理器。它有自己的指令和程序专门负责数据输入输出的传输控制，从而使CPU将“传输控制”的功能下放给通道，CPU只负责“数据处理”功能。这样，通道与CPU分时使用内存，实现了CPU内部的数据处理与I/O设备的平行工作。通道有两种类型：①选择通道；②多路通道。标准化是建立开放式系统的基础。CPU、系统总线、I/O总线及标准接口技术近年来取得了重大进步。其中并行I/O接口SCSI与串行I/O接口IEEE1394是两个最具权威性和发展前景的标准接口技术。SCSI是系统级接口，是处于主适配器和智能设备控制器之间的并行I/O接口，改进的SCSI可允许连接1～15台不同类型的高速外围设备。SCSI的不足处在于硬件较昂贵，并需要通用设备驱动程序和各类设备的驱动程序模块的支持。IEEE1394是串行I/O标准接口。与SCSI并行I/O接口相比，它具有更高的数据传输速率和数据传送的实时性，具有更小的体积和连接的方便性。IEEE1394的一个重大特点是，各被连接的设备的关系是平等的，不用PC介入也能自成系统。因此IEEE1394已成为Intel、Microsoft等公司联手制定的新标准。计算机系统中的并行性有不同的等级。所谓并行性，是指计算机系统具有可以同时进行运算或操作的特性，它包括同时性与并发性两种含义。同时性两个或两个以上的事件在同一时刻发生。并发性两个或两个以上的事件在同一时间间隔内发生。(1)从处理数据的角度看，并行性等级从低到高可分为：·字串位串：同时只对一个字的一位进行处理。这是最基本的串行处理方式，不存在并行性。·字串位并：同时对一个字的全部位进行处理，不同字之间是串行的。这里已开始出现并行性。·字并位串：同时对许多字的同一位进行处理。这种方式有较高的并行性。·全并行：同时对许多字的全部位进行处理。这是最高一级的并行。(2)从执行程序的角度看，并行性等级从低到高可分为：·指令内部并行：一条指令执行时各微操作之间的并行。·指令级并行：并行执行两条或多条指令。·任务级或过程级并行：并行执行两个以上过程或任务(程序段)。·作业或程序级并行：并行执行两个以上作业或程序。在计算机系统中，可以采取多种并行性措施。既可以有处理数据方面的并行性，又可以有执行程序方面的并行性。当并行性提高到一定级别时，则进入并行处理领域。并行处理着重挖掘计算过程中的并行事件，使并行性达到较高的级别。因此，并行处理是体系结构、硬件、软件、算法、编程语言等多方面综合的领域。计算机系统中提高并行性的措施多种多样，就其基本思想而言，可归纳成如下四条途径。(1)时间重叠。时间重叠即时间并行。在并行性概念中引入时间因素，让多个处理过程在时间上相互错开，轮流重叠地使用同一套硬件设备的各个部分，以加快硬件周转而赢得速度。时间重叠的实质就是把一件工作按功能分割为若干个相互联系的部分，每一部分指定专门的部件完成，各部分执行过程在时间上重叠起来，使所有部件依次分工合作完成完整的工作。时间重叠的典型应用就是流水线技术。(2)资源重复。资源重复即空间并行。在并行性概念中引入空间因素，以数量取胜的原则，通过重复设置硬件资源，大幅度提高计算机系统的性能。随着硬件价格的降低，资源重复在单处理机中通过部件冗余、多存储体等方式被广泛应用，而多处理机本身就是实施“资源重复”原理的结果。(3)时间重叠+资源重复。在计算机系统中同时运用时间并行和空间并行技术，这种方式在计算机系统中得到广泛应用，成为并行性主流技术。(4)资源共享。资源共享是一种软件方法的并行，它使多个任务按一定时间顺序轮流使用同一套硬件设备。多道程序、分时系统就是资源共享的具体应用。资源共享既降低了成本，又提高了计算机硬件的利用率。早期单处理机的发展过程中，起着主导作用的是时间并行(流水线)技术。实现时间并行的物质基础是“部件功能专用化”，即把一件工作按功能分割为若干相互联系的部分，把每一部分指定给专门的部件完成；然后按时间重叠原理把各部分执行过程在时间上重叠起来，使所有部件依次分工完成一组同样的工作。例如，指令执行的5个子过程分别需要5个专用部件，即取指令部件(IF)、指令译码部件(ID)、指令执行部件(EX)、访问存储器部件(M)、结果写回部件(WB)。将它们按流水方式连接起来，就满足时间重叠原理，从而使得处理机内部能同时处理多条指令，提高了处理机的速度。显然，时间并行技术开发了计算机系统中的指令级并行。在单处理机中，空间并行技术的运用也已经十分普遍。例如，不论是非流水线处理机，还是流水线处理机，多体存储器和多操作部件都是成功应用的结构形式。在多操作部件处理机中，通用部件被分解成若干个专用操作部件，如加法部件、乘法部件、除法部件、逻辑运算部件等。一条指令所需的操作部件只要空闲，就可以开始执行这条指令，这就是指令级并行。在单处理机中，资源共享的概念实质上是用单处理机模拟多处理机的功能，形成所谓虚拟机的概念。例如，分时系统，在多终端情况下，每个终端上的用户感到好像自己独占一台处理机一样。单处理机并行性发展的代表作有奔腾系列机和安腾系列机。多处理机系统也遵循时间重叠、资源重复、资源共享原理，向着不同体系结构的多处理机方向发展。但在采取的技术措施上与单处理机系统有些差别。为了反映多处理机系统各机器之间物理连接的紧密程度与交互作用能力的强弱，通常使用耦合度这一术语。多处理机系统的耦合度，分为紧耦合系统和松耦合系统两大类。紧耦合系统又称直接耦合系统，指处理机之间物理连接的频带较高，一般是通过总线或高速开关实现互连，可以共享主存。由于具有较高的信息传输率，因而可以快速并行处理作业或任务。松耦合系统又称间接耦合系统，一般是通过通道或通信线路实现处理机之间的互连，可以共享外存设备(磁盘、磁带等)。机器之间的相互作用是在文件或数据集一级上进行。松耦合系统表现为两种形式：一种是多台计算机和共享的外存设备连接，不同机器之间实现功能上的分工(功能专用化)，机器处理的结果以文件或数据集的形式送到共享外存设备，供其他机器继续处理。另一种是计算机网，机器通过通信线路连接，以求得更大范围的资源共享。多处理机中为了实现时间重叠，将处理功能分散给各专用处理机去完成，即功能专用化，各处理机之间则按时间重叠原理工作。如输入/输出功能的分离，导致由通道向专用外围处理机发展。许多主要功能，如数组运算、高级语言编译、数据库管理等，也逐渐分离出来，交由专用处理机完成，机间的耦合程度逐渐加强，从而发展成为异构多处理机系统。随着硬件价格的降低，系统设计的目标聚焦到通过多处理机的并行处理来提高整个系统的速度。为此，对计算机间互联网络的性能提出了更高要求。高带宽、低延迟、低开销的机间互联网络，是高效实现程序段或任务一级并行处理的前提条件。为了使并行处理的任务能在处理机之间随机地进行调度，就必须使各处理机具有同等的功能，从而成为同构多处理机系统。20世纪70年代以来，芯片技术的飞速发展，为多处理机系统的研究和设计提供了强大的物质基础，各种类型的并行计算机系统纷纷问世。20世纪80年代，我国研制了向量处理机YH-1/2和757。它们都是流水线单机内部并行的机器。进入90年代以来，我国又研制了多种类型的并行计算机系统，打破了国外在高性能计算机领域对我国的封锁。表9.1列出了我国90年代以来自行研制的几种并行计算机系统。2000年，超级计算机浮点最高运算速度达到每秒10000亿次。我国的神威号计算机运算速度达到每秒3480亿次，使我国成为继美国、日本之后世界上第三个拥有高速计算机的国家。2004年6月曙光4000A被评为世界超级计算机五百强的第十名，并作为中国国家网格最大主节点安装在上海超级计算中心。龙芯2F是中国科学院计算技术研究所研制的采用90nm设计技术的64位高性能通用CPU芯片。2007年中国科学技术大学第一个用国产龙芯2FCPU设计出了万亿次的高性能机器，这是值得称道和令人鼓舞的，是中国人用自己的CPU做超级计算机的开始。2010年11月，世界超级计算机五百强排行榜中，第一名是中国国防科技大学的“天河1A”(2500万亿次/秒)，第二名是美国Cray公司的Jaguar(美洲虎)，第三名是中国曙光信息产业有限公司的“星云”，第七名是美国IBM公司的Roadrunner(走鹃)。表9.2是这四台超级计算机的列表。1966年，M.J.Flynn从计算机体系结构的并行性出发，按照指令流和数据流的不同组织方式，把计算机系统结构分为如下四种类型，如图9.1所示。·单指令流单数据流(SISD)，其代表机型是单处理机。·单指令流多数据流(SIMD)，其代表机型是向量处理机。·多指令流单数据流(MISD)，这种结构从来没有实现过。·多指令流多数据流(MIMD)，其代表机型是多处理机和机群系统。前者为紧耦合系统，后者为松耦合系统。图9.2进一步说明了上述分类的组成方式。其中，图9.2(a)表示一个SISD的结构，CU代表控制单元，PU代表处理单元，MU代表存储单元，IS代表单一指令流，DS代表单一数据流。这是单处理机系统进行取指令和执行指令的过程。图9.2(b)表示SIMD的结构，仍是一个单一控制单元CU，但现在是向多个处理单元(PUl～PUn)提供单一指令流，每个处理单元可有自己的专用存储器(局部存储器LMl～LMn)。这些专用存储器组成分布式存储器。图9.2(c)和图9.2(d)表示MIMD的结构，两者均有多个控制单元(CUl～CUn)，每个控制单元向自己的处理部件(PUl～PUn)提供一个独立的指令流。不同的是，图9.2(c)是共享存储器多处理机，而图9.2(d)是分布式存储器多处理机。计算机体系结构可以采用不同方式的并行机制。1.超标量处理机和超长指令字处理机在计算机系统的最底层，流水线技术将时间并行性引入处理机，而多发射处理机则把空间并行性引入处理机。超标量(superscalar)设计采用多发射技术，在处理机内部设置多条并行执行的指令流水线，通过在每个时钟周期内向执行单元发射多条指令实现指令级并行。超长指令字技术(verylonginstructionword，VLIW)则由编译器在编译时找出指令间潜在的并行性，进行适当的调度安排，把多个能够并行执行的操作组合在一起，控制处理机中的多个相互独立的功能部件，相当于同时执行多条指令，从而提高处理机的并行性。2.多处理机和多计算机在单个处理机的性能一定的情况下，进一步提高计算机系统处理能力的简单方法就是让多个处理机协同工作，共同完成任务。广义而言，使用多台计算机协同工作来完成所要求的任务的计算机系统称为多处理机(multiprocessor)系统。具体而言，多处理机系统由多台独立的处理机组成，每台处理机都能够独立执行自己的程序和指令流，相互之间通过专门的网络连接，实现数据的交换和通信，共同完成某项大的计算或处理任务。多处理机系统中的各台处理机由操作系统管理，实现作业级或任务级并行。与广义多处理机系统不同，狭义多处理机系统仅指在同一计算机内处理机之间通过共享存储器方式通信的并行计算机系统。运行在狭义多处理机上的所有进程能够共享映射到公共内存的单一虚拟地址空间。任何进程都能通过执行LOAD或STORE指令来读写一个内存字。与狭义多处理机相对应，由不共享公共内存的多个处理机系统构成的并行系统又称为多计算机(multicomputers)系统。每个系统都有自己的私有内存，通过消息传递的方式进行互相通信。多计算机系统有各种不同的形状和规模。机群(cluster，也称集群)系统就是一种常见的多计算机系统。机群系统是由一组完整计算机通过高性能的网络或局域网互连而成的系统，这组计算机作为统一的计算机资源一起工作，并能产生一台机器的印象。术语“完整计算机”意指一台计算机离开机群系统仍能运行自己的任务。机群系统中的每台计算机一般称为节点。3.多线程处理机当通过简单提高处理机主频从而提升单处理机的性能的传统方法受到制约时，处理机厂商被迫转向处理机片内并行技术。除了传统的指令级并行技术之外，多线程技术和多核技术也是提高单芯片处理能力的片内并行技术。由于现代处理机广泛采用指令流水线技术，因而处理机必须面对一个固有的问题：如果处理机访存时cache缺失(不命中)，则必须访问主存，这会导致执行部件长时间的等待，直到相关的cache块被加载到cache中。解决指令流水线因此必须暂停的一种方法就是片上多线程(on-chipmultithreading)技术。该技术允许CPU同时运行多个硬件线程，如果某个线程被迫暂停，其他线程仍可以执行，这样能保证硬件资源被充分利用。4.多核处理机(片上多处理机)多线程技术能够屏蔽线程的存储器访问延迟，增加系统吞吐率，但并未提高每个单线程的执行速度。而多核(multicore)技术通过开发程序内的线程级或进程级并行性提高性能。多核处理机是指在一颗处理机芯片内集成两个或两个以上完整且并行工作的计算引擎(核)，也称为片上多处理机(chipmulti-processor，CMP)。核(core，又称内核或核心)是指包含指令部件、算术/逻辑部件、寄存器堆和一级或两级cache的处理单元，这些核通过某种方式互联后，能够相互交换数据，对外呈现为一个统一的多核处理机。多核技术的兴起一方面是由于单核技术面临继续发展的瓶颈，另一方面也是由于大规模集成电路技术的发展使单芯片容量增长到足够大，能够把原来大规模并行处理机结构中的多处理机和多计算机节点集成到同一芯片内，让各个处理机核实现片内并行运行。因此，多核处理机是一种特殊的多处理机架构。所有的处理机都在同一块芯片上，不同的核执行不同的线程，在内存的不同部分操作。多核也是一个共享内存的多处理机：所有的核共享同一个内存空间。多个核在一个芯片内直接连接，多线程和多进程可以并行运行。不同于多核结构，在传统的多处理机结构中，分布于不同芯片上的多个处理机通过片外系统总线连接，因此需要占用更大的芯片尺寸，消耗更多的热量，并需要额外的软件支持。多个处理机可以分布于不同的主板上，也可以构建在同一块电路板上，处理机之间通过高速通信接口连接。图9.3(a)～9.3(f)显示了不同结构的处理机形态。图9.3(a)是单核处理机结构，由执行单元、CPU状态、中断逻辑和片上cache组成。图9.3(b)是多处理机结构，由两个完全独立的单核处理机构成双处理机系统。图9.3(c)是多线程处理机结构，在一个物理处理机芯片内集成两个逻辑处理机，二者共享执行单元和片上cache，但各自有自己的CPU状态和中断逻辑。图9.3(d)是多核处理机结构，两个完全独立的单处理机核集成在同一个芯片内，构成双核处理机，每个核都有自己私有的片上cache。图9.3(e)同样是多核处理机结构，但与图9.3(d)显示的多核处理机结构的差别在于两个核共享片内cache。图9.3(f)显示的是多核多线程处理机结构，这是多核与多线程相结合的片上并行技术。两个完全独立的处理机核集成在同一个芯片内，每个核又是双线程的，故该处理机为双核四线程结构。硬件多线程技术是提高处理机并行度的有效手段，以往常被应用于高性能计算机的处理机。2002年秋，英特尔公司推出一款采用超线程(hyperthreading，HT)技术的Pentium4处理机，使多线程技术进入桌面应用环境。超线程技术是同时多线程技术在英特尔处理机上的具体实现。在经过特殊设计的处理机中，原有的单个物理内核经过简单扩展后被模拟成两个逻辑内核，并能够同时执行两个相互独立的程序，从而减少了处理机的闲置时间，充分利用了中央处理机的执行资源。1.超标量处理机的水平浪费和垂直浪费超标量技术和超长指令字技术都是针对单一的指令流中的若干指令来提高并行处理能力的，当单一的指令流出现cache缺失等现象时，指令流水线就会断流；而指令之间的相关性也会严重影响执行单元的利用率。例如，资源冲突会导致处理机流水线不能继续执行新的指令而造成垂直浪费，而指令相关会导致多条流水线中部分流水线被闲置，造成水平浪费。图9.4显示了一个有四条流水线的超标量处理机的指令执行实例。图中，每个方框代表一个可用的指令发射时间，水平方向表示并行执行指令的4条指令流水线(指令发射槽)，垂直方向表示时钟周期，“A”表示某指令流A占用的周期，白框为浪费的周期。显然，水平浪费和垂直浪费造成了处理机执行部件的空闲。因此，如何减少处理机执行部件的空闲时间成为提升处理机性能的关键。而线程级并行(thread-levelparallelism，TLP)技术正是针对这一问题而引入的。2.硬件线程的概念多任务系统必须解决的首要问题就是如何分配宝贵的处理机时间，这通常是由操作系统负责的。操作系统除了负责管理用户程序的执行外，也需要处理各种系统任务。在操作系统中，通常使用进程(process)这一概念描述程序的动态执行过程。通俗地讲，程序是静态实体，而进程是动态实体，是执行中的程序。进程不仅仅包含程序代码，也包含了当前的状态(这由程序计数器和处理机中的相关寄存器表示)和资源。因此，如果两个用户用同样一段代码分别执行相同功能的程序，那么其中的每一个都是一个独立的进程。虽然其代码是相同的，但是数据却未必相同。传统的计算机系统把进程当作系统中的一个基本单位，操作系统将内存空间、I/O设备和文件等资源分配给每个进程，调度和代码执行也以进程作为基本单位。但进程调度是频繁进行的，因而在处理机从一个进程切换到另一个进程的过程中，系统要不断地进行资源的分配与回收、现场的保存与恢复等工作，为此付出了较大的时间与空间的开销。因此，在现代操作系统中，大都引入线程作为进程概念的延伸，线程是在操作系统中描述能被独立执行的程序代码的基本单位。进程只作为资源分配的单位，不再是调度和执行的基本单位；而每个进程又拥有若干线程，线程则是调度和执行的基本单位。除了拥有一点儿在运行中必不可少的独立资源(如程序计数器、一组寄存器和栈)之外，线程与属于同一个进程的其他线程共享进程所拥有的全部资源。由于线程调度时不进行资源的分配与回收等操作，因而线程切换的开销比进程切换少得多。在处理机设计中引入硬件线程(hardwarethread)的概念，其原理与操作系统中的软件多线程并行技术相似。硬件线程用来描述一个独立的指令流，而多个指令流能共享同一个支持多线程的处理机。当一个指令流因故暂时不能执行时，可以转向执行另一个线程的指令流。由于各个线程相互独立，因而大大降低了因单线程指令流中各条指令之间的相互依赖导致的指令流水线冲突现象，从而有效提高处理机执行单元的利用率。因此，并行的概念就从指令级并行扩展至线程级并行。图9.5显示了一个支持两个线程的超标量处理机的指令执行实例。其中，“A”表示线程A(指令流A)占用的周期，“B”表示线程B(指令流B)占用的周期。在每个时钟周期内，所有的流水线都用于执行同一线程的指令，但在下一个时钟周期则可以选择另一个线程的指令并行执行。3.细粒度多线程和粗粒度多线程根据多线程处理机的具体实现方法差异，又可以分为细粒度多线程(交错多线程)处理机和粗粒度多线程(阻塞多线程)处理机。细粒度多线程如图9.5(a)所示，处理机交替执行A、B两个线程的指令，在每个时钟周期都进行线程切换。由于多个线程交替执行，并且处于阻塞状态的线程在切换时被跳过，故在一定程度上降低了指令阻塞造成的处理机吞吐率损失。当然，每个线程的执行速度降低了，因为就绪状态的线程会因为其他线程的执行而延迟。粗粒度多线程如图9.5(b)所示，只有在遇到代价较高的长延迟操作(如因cache缺失需要访问主存)时才由处理机硬件进行线程切换，否则一直执行同一个线程的指令。因此，粗粒度多线程比细粒度多线程有更低的线程切换开销，且每个线程的执行速度几乎不会降低。但是粗粒度多线程也有弱点，就是在线程切换的过程中需要排空或填充指令流水线。只有当长延迟操作导致线程被阻塞的时间远长于指令流水线排空或填充的时间时，粗粒度多线程才是有意义的。多线程处理机通常为每个线程维护独立的程序计数器和数据寄存器。处理机硬件能够快速实现线程间的切换。由于多个相互独立的线程共享执行单元的处理机时间，并且能够进行快速的线程切换，因而多线程处理机能够有效地减少垂直浪费情况，从而利用线程级并行来提高处理机资源的利用率。从图9.5可以看出，多线程处理机虽然可以减少长延迟操作和资源冲突造成的处理机执行单元浪费，但并不能完全利用处理机中的所有资源。这是因为每个时钟周期执行的指令都来自同一个线程，因而不能有效地消除水平浪费。为了最大限度地利用处理机资源，同时多线程(simultaneousmulti-threading，SMT)技术被引入现代处理机中。同时多线程技术结合了超标量技术和细粒度多线程技术的优点，允许在一个时钟周期内发射来自不同线程的多条指令，因而可以同时减少水平浪费和垂直浪费。图9.6显示了一个支持两个线程的同时多线程处理机的指令执行实例。在一个时钟周期内，处理机可以执行来自不同线程的多条指令。当其中某个线程由于长延迟操作或资源冲突而没有指令可以执行时，另一个线程甚至能够使用所有的指令发射时间。因此，同时多线程技术既能够利用线程级并行减少垂直浪费，又能够在一个时钟周期内同时利用线程级并行和指令级并行来减少水平浪费，从而大大提高处理机的整体性能。同时多线程技术是一种简单、低成本的并行技术。与单线程处理机相比，同时多线程处理机只花费很小的代价，而性能得到很大改善。在原有的单线程处理机内部为多个线程提供各自的程序计数器、相关寄存器以及其他运行状态信息，一个“物理”处理机被模拟成多个“逻辑”处理机，以便多个线程同步执行并共享处理机的执行资源。应用程序无须做任何修改就可以使用多个逻辑处理机。由于多个逻辑处理机共享处理机内核的执行单元、高速缓存和系统总线接口等资源，因而在实现多线程时多个逻辑处理机需要交替工作。如果多个线程同时需要某一个共享资源，只有一个线程能够使用该资源，其他线程要暂停并等待资源空闲时才能继续执行。因此，同时多线程技术就性能提升而言远不能等同于多个相同时钟频率处理机核组合而成的多核处理机，但从性能-价格比的角度看，同时多线程技术是一种对单线程处理机执行资源的有效而经济的优化手段。由于同时运行的多个线程需要共享执行资源，因而处理机的实时调度机制非常复杂。就调度策略而言，取指部件要在单线程执行时间延迟与系统整体性能之间取得平衡。与单线程处理机相比，并发执行的多个线程必然拉长单个线程的执行时间，但处理机可以通过指定一个线程为最高优先级而减小其执行延迟，只有当优先线程阻塞时才考虑其他线程。为了最大限度地提高处理机整体性能，同时多线程处理机也可以采用另外一种策略，即处理机的取指部件可以选择那些可以带来最大性能好处的线程优先取指并执行，代价是牺牲单个线程的执行时间延迟。为了实现同时多线程，处理机需要解决一系列问题。例如，处理机内需要设置大量寄存器保存每个线程的现场信息，需要保证由于并发执行多个线程带来的cache冲突不会导致显著的性能下降，确保线程切换的开销尽可能小。超线程技术是同时多线程技术在英特尔系列处理机产品中的具体实现。自2002年起，英特尔公司先后在其奔腾4处理机和至强(XEON)处理机等产品中采用超线程技术。奔腾4处理机和至强处理机基于同样的IntelNetBurst微体系结构(micro-architecture，处理机体系结构在硅芯片上的具体实现)。图9.7显示了支持超线程技术的NetBurst微体系结构的流水线结构。每条指令的执行过程都需要经过10个功能段组成的流水线。图9.7支持超线程技术的NetBurst微体系结构的流水线结构原有的流水线只支持单线程运行。统计表明，单线程的NetBurst微体系结构的流水线在执行典型的指令序列时仅仅利用了大约35％的流水线资源。为了支持两个硬件线程同时运行，需要对流水线进行改造。改造的方式是让每级流水线中的资源通过三种方式之一复用于两个线程：复制、分区或共享。其中，复制方式是在处理机设计时分别为两个线程设置独立的部件。被复制的资源包括所有的处理机状态、指令指针IP(程序计数器)寄存器、寄存器重命名部件和一些简单资源(如指令TLB等)。复制这些资源仅仅会少许提高处理机的成本，而每个线程使用这些资源的方式与单线程相同。分区方式则是在处理机设计时把原有的用于单线程的独立资源分割成两部分，分别供两个线程使用。采用分区方式的主要是各种缓冲区和队列，如重排序缓冲区、取数/存数缓冲区和各级队列等。与单线程相比，每个线程使用的缓冲区或队列的容量减半，而处理机成本并没有增加。共享方式则是由处理机在执行指令的过程中根据使用资源的需要在两个线程之间动态分享资源。乱序执行部件和cache采用共享方式复用。这种方式同样不增加处理机成本，但单线程运行时存在的资源闲置得到有效改善。由于不同的资源采用不同的复用方式，因此当指令在不同的资源之间转移时，处理机需在图中箭头和多路开关标识的选择点根据需要动态选择能够使用下级资源的线程。多线程技术只对传统的单线程超标量处理机结构做了很少改动，但却获得很大的性能提升。启用超线程技术的内核比禁用超线程技术的内核吞吐率要高出30%。当然，超线程技术需要解决一系列复杂的技术问题。例如，作业调度策略、取指和发射策略、寄存器回收机制、存储系统层次设计等比单线程处理机复杂许多。多处理机系统由多个独立的处理机组成，每个处理机能够独立执行自己的程序。现有的多处理机系统分为如下四种类型：并行向量处理机(PVP)、对称多处理机(SMP)、大规模并行处理机(MPP)、分布共享存储器多处理机(DSM)，如图9.8所示。并行向量处理机见图9.8(a)。它是由少数几台巨型向量处理机采用共享存储器方式互连而成，在这种类型中，处理机数目不可能很多。对称多处理机见图9.8(b)。它由一组处理机和一组存储器模块经过互联网络连接而成。有多个处理机且是对称的，每台处理机的能力都完全相同。每次访问存储器时，数据在处理机和存储器模块间的传送都要经过互联网络。由于是紧耦合系统，不管访问的数据在哪一个存储器模块中，访问存储器所需的延迟时间都是一样的。分布共享存储器多处理机见图9.8(c)。同PVP和SMP一样，它也属于紧耦合系统。它的共享存储器分布在各台处理机中，每台处理机都带有自己的本地存储器，组成一个处理机-存储器单元。但是这些分布在各台处理机中的实际存储器又合在一起统一编址，在逻辑上组成一个共享存储器。这些处理机-存储器单元通过互联网络连接在一起，每台处理机除了能访问本地存储器外，还能通过互联网络直接访问在其他处理机-存储器单元中的“远程存储器”。处理机在访问远程存储器时所需的延迟时间与访问本地存储器时所需的延迟时间是不一样的，访问本地存储器要快得多。大规模并行处理机见图9.8(d)。它属于松耦合多处理机系统。每个计算机模块称为一个结点。每个结点有一台处理机和它的局部存储器(LM)、结点接口(NIC)，有的还有本身的I/O设备，这几部分通过结点内的总线连在一起。计算机模块又通过结点接口连接到互联网络上。由于VLSI技术的发展，整个结点上的计算机已可以做在一个芯片上。第9章并行组织与结构291在这种松耦合的多计算机系统中，各台计算机间传送数据的速度低，延迟时间长，且各结点间的距离是不相等的，因此把经常要在结点间传送数据的任务放在相邻的结点中执行。由于松耦合的多计算机系统的互联网络的成本低得多，故同紧耦合多处理机系统相比，其优点是可以组成计算机数目很多的大规模并行处理系统。也就是说，可以比较经济合理地用微处理机构成几百台乃至几千台的多计算机系统。鉴于当前并行处理系统的发展趋势，下面重点讲授对称多处理机SMP。不久前，所有的单用户个人计算机和大多数工作站还只含有单一通用微处理机。随着性能需求的增长和微处理机价格的持续下跌，计算机制造商推出了SMP系统。SMP既指计算机硬件体系结构，也指反映此体系结构的操作系统行为。SMP定义为具有如下特征的独立计算机系统。(1)有两个以上功能相似的处理机。(2)这些处理机共享同一主存和I/O设施，以总线或其他内部连接机制互连在一起；这样，存储器存取时间对每个处理机都是大致相同的。(3)所有处理机共享对I/O设备的访问，或通过同一通道，或通过提供到同一设备路径的不同通道。(4)所有处理机能完成同样的功能。(5)系统被一个集中式操作系统(OS)控制。OS提供各处理机及其程序之间的作业级、任务级、文件级和数据元素级的交互。其中，(1)～(4)是十分明显的。(5)表示了SMP与机群系统之类的松耦合多处理系统的对照。后者的交互物理单位通常是消息或整个文件；而在SMP中，个别的数据元素能成为交互级别，于是处理机间能够有高度的相互协作。SMP的操作系统能跨越所有处理机来调度进程或线程。SMP有如下几个超过单处理机的优点。性能如果可以对一台计算机完成的工作进行组织，使得某些工作部分能够并行完成；则具有多个处理机的系统与具有同样类型的单处理机的系统相比，将产生更高的性能。可用性在一个对称多处理机系统中，所有处理机都能完成同样的功能，故单个处理机的故障不会造成系统的停机，系统在性能降低的情况下继续运行。增量式增长用户可以通过在系统中添加处理机来提高系统性能。可扩展性厂商能提供一个产品范围，它们基于系统中配置的处理机数目不同而有不同的价格和性能特征。SMP的一个有吸引力的特点是：多个处理机的存在对用户是透明的；由操作系统实际关注各个处理机上进程或线程的调度，以及处理机间的同步。对个人计算机、工作站和服务器而言，互连机构使用分时共享总线。分时共享总线是构成一个多处理机系统的最简单机构。结构和界面基本上同于使用总线互连的单处理机系统。总线由控制、地址和数据线组成。为便利来自I/O处理器的DMA传送，应具备如下特征。(1)寻址必须能区别总线上各模块，以确定数据的源和目标。(2)仲裁任何I/O模块都能临时具备主控器(master)功能。要提供一种机制来对总线控制的竞争请求进行仲裁，可使用某种类型的优先级策略。(3)分时共享当一个模块正在控制总线时，其他模块是被锁住的，而且如果需要，应能挂起它的操作直到当前的总线访问完成。这些单处理机特征在对称多处理机配置中是直接可用的，但可能会出现多个处理机以及多个I/O适配器都试图掌管总线，并对一个或多个存储器模块进行存取操作的更为复杂的情况。与其他方法比较，总线组织方式有如下几个优点。简易性这是多处理机系统组成的最简单方式。物理接口以及每个处理机的寻址、仲裁和分时逻辑保持与单处理机系统相同。灵活性以附加更多处理机到总线的方法来扩充系统，一般来说也是容易的。可靠性本质上来说，总线是一个被动介质，并且总线上任一设备的故障不会引起整个系统的失败。总线组织的主要缺点在于性能。所有的存储器访问都要通过公共总线，于是系统速度受限于总线周期。为改善性能，就要求为每个处理机配置cache，这将急剧地减少总线访问次数。一般来说，工作站和个人机SMP都有两级cache，L1cache是内部的(与处理机同一芯片)，L2cache或是内部的，或是外部的。现在，某些处理机还使用了L3cache。cache的使用导致某些新的设计考虑，因为每个局部cache只保存部分存储器的映像，如果在某个cache中修改了一个字，可想象出其他cache中的此字将会是无效的。为防止这个问题，必须通知其他处理机：已经发生了修改。这个问题称为cache一致性问题，并且一般是以硬件解决。从单处理机到多核处理机的变化并不是处理机设计厂商根据客户需求和市场趋势做出的主动选择，而是在物理规律限制下的无奈之举。多核解决方案可以利用新工艺带来的集成电路集成度的提高，将几个处理机核心集成在一块芯片内。与传统的单核技术相比，多核技术是应对芯片物理规律限制的相对简单的办法。与提高处理机主频相比，在一个芯片内集成多个相对简单而主频稍低的处理机核既可以充分利用摩尔定律带来的芯片面积提升，又可以更容易地解决功耗、芯片内部互联延迟和设计复杂度等问题。(1)高并行性：每个处理机核都不必提高晶体管的翻转速度，而多核处理机可同时执行的线程数或任务数是单处理机的数倍，极大地提升了处理机的并行性，带来了更强的并行处理能力和更高的计算密度。(2)高通信效率：多个核集成在片内，各个处理机核只需要在核内部的相对较小的区域内交换数据，不需要很长的互联线，通信延迟变低，提高了通信效率，数据传输带宽也得到提高。(3)高资源利用率：多核结构可以有效支持片内资源共享，片上资源的利用率得到了提高。(4)低功耗：处理机的功耗增长随着内核数目的增加呈线性增长，而不是随着频率的增加呈指数级增长。由于不再依靠提高主频改善性能，内核的工作频率不需要达到上限，多个简单低速核的功耗远低于一个高速复杂处理机的功耗。如果进一步采用动态管理各处理机核功耗的方法，针对不同的任务，每个核可以被降频或关闭，多核在功耗控制上会更有优势。(5)低设计复杂度：多核处理机中的每个核的结构相对简单，易于优化设计，扩展性强。设计高速而复杂的单处理机往往要采用超标量处理机结构和超长指令字结构，控制逻辑复杂。而在芯片内复制多个低速简单内核的设计难度显然更低，设计和验证周期更短，出现错误的机会也更小。(6)较低的成本：多核处理机内的各个核共享器件芯片封装和芯片I/O资源，也使占单核处理机成本25%～50%的芯片封装和I/O成本的比重大大下降，生产成本得以降低。设计复杂度的降低也会使处理机设计开发的成本降低。这些优势最终推动多核的发展并使多核逐渐取代单核处理机成为主流技术。多核技术是在超线程、超标量和多处理机等技术的基础上发展起来的，也充分吸收了其他技术的优势。超线程技术是通过隐藏潜在访存延迟的方法提高处理机的性能，其主要目的是充分利用空闲的处理机资源，本质上仍然是多个线程共享一个处理机核。因此，采用超线程技术是否能获得性能的提升依赖于应用程序以及硬件平台。多核处理机则是将多个独立的处理机核嵌入到一个处理机芯片内部，每个线程都具有完整的硬件执行环境，故各线程之间可以实现真正意义上的并行。当然，多核架构中灵活性的提升是以牺牲资源利用率为代价的。不管是超线程处理机还是多核处理机，性能的提升都需要软件的配合，性能提升的程度取决于并行性的大小。多处理机系统是利用任务级并行的方式提高系统性能的，即把任务并行化并分配到多个处理机中去执行。由于多处理机之间的耦合度较低，不适合实现细粒度并行，而功耗也较高。而多核处理机由于在一个芯片内集成多个核心，核间耦合度高，核间互连延迟更小，功耗更低，故可以在任务级、线程级和指令级等多个层次充分发挥程序的并行性，灵活度高。1.同构多核处理机与异构多核处理机与多处理机的分类方法类似，按多核处理机内的计算内核的地位对等与否划分，多核处理机可以分为同构多核和异构多核两种类型。1)同构多核(homogenousmulti-core)处理机同构多核处理机内的所有计算内核结构相同，地位对等。同构多核处理机大多由通用的处理机核心构成，每个处理机核心可以独立地执行任务，其结构与通用单核处理机结构相近。同构多核处理机的各个核心之间可以通过共享存储器互连，也可以通过cache或局部存储器互连。在英特尔公司的通用桌面计算机上的多核处理机通常采用同构多核结构。2)异构多核(heterogeneousmulti-core)处理机异构多核处理机内的各个计算内核结构不同，地位不对等。异构多核处理机根据不同的应用需求配置不同的处理机核心，一般多采用“主处理核+协处理核”的主从架构。异构多核处理机的优势在于可以同时发挥不同类型处理机各自的长处来满足不同种类的应用的性能和功耗需求。异构多核处理机将结构、功能、功耗、运算性能各不相同的多个核心集成在芯片上，并通过任务分工和划分将不同的任务分配给不同的核心，让每个核心处理自己擅长的任务。目前的异构多核处理机通常同时集成通用处理机、数字信号处理机(DSP)、媒体处理机、网络处理机等多种类型的处理机核心，并针对不同需求配置应用其计算性能。其中，通用处理机核常作为处理机控制主核，并用于通用计算；而其他处理机核则作为从核用于加速特定的应用。例如，多核异构网络处理机配有负责管理调度的主核和负责网络处理功能的从核，经常用于科学计算的异构多核处理机在主核之外可以配置用于定点运算和浮点运算等计算功能的专用核心。研究表明，异构组织方式比同构的多核处理机执行任务更有效率，实现了资源的最优化配置，而且降低了系统的整体功耗。2.多核处理机的对称性同构多核和异构多核是对处理机内核硬件结构和地位一致性的划分。如果再考虑各个核之上的操作系统，从用户的角度看，可以把多核处理机的运行模式划分为对称(symmetricmultiprocessing，SMP)多核和非对称(asymmetricmultiprocessing，AMP)多核两种类型。多核处理机中的对称(SMP)多核结构是指处理机片内包含相同结构的核，多个核紧密耦合，并运行一个统一的操作系统。每个核的地位是对等的，共同处理操作系统的所有任务。SMP由多个同构的处理机核和共享存储器构成，由一个操作系统的实例同时管理所有处理机核，并将应用程序分配至各个核上运行。只要有一个内核空闲可用，操作系统就在线程等待队列中分配下一个线程给这个空闲内核来运行。应用程序本身可以不关心有多少个核在运行，由操作系统自动协调运行，并管理共享资源。同构多核处理机也可以构成非对称(AMP)多核结构。若处理机芯片内部是同构多核，但每个核运行一个独立的操作系统或同一操作系统的独立实例，那就变成非对称多核。AMP多核系统也可以由异构多核和共享存储器构成。3.多核处理机的cache组织在设计多核处理机时，除了处理机的结构和数量，cache的级数和大小也是需要考虑的重要问题。根据多核处理机内的cache配置，可以把多核处理机的组织结构分成以下四种。1)片内私有L1cache结构图9.10(a)显示的多核结构是简单的多核计算机片内cache结构。系统cache由L1和L2两级组成。处理机片内的多个核各自有自己私有的L1cache，一般被划分为指令L1cache(L1-I)和数据L1cache(L1-D)。而多核共享的L2cache则存在于处理机芯片之外。ARM公司ARM11微体系结构的MPCore多核嵌入式处理机就采用这种结构。2)片内私有L2cache结构在图9.10(b)显示的多核结构中，处理机片内的多个核仍然保留自己私有的指令L1cache(L1-I)和数据L1cache(L1-D)，但L2cache被移至处理机片内，且L2cache为各个核私有。多核共享处理机芯片之外的主存。AMD公司专门为服务器和工作站设计的皓龙(Opteron)处理机就采用这种结构。3)片内共享L2cache结构在图9.10(c)显示的多核结构与图9.10(b)显示的多核结构相似，都是片上两级cache结构。不同之处在于处理机片内的私有L2cache变为多核共享L2cache。多核仍然共享处理机芯片之外的主存。对处理机的每个核而言，片内私有L2cache的访问速度更高。但在处理机片内使用共享的L2cache取代各个核私有的L2cache能够获得系统整体性能的提升，这是因为：(1)共享cache有助于提高整体cache命中率。如果处理机内的多个核先后访问主存同一个页面，首次访问该地址的操作会将该页面调入共享cache，其他核在此后访问同样的主存页面时可以直接在共享cache中快速存取，从而减少访问主存的次数。并且，在私有cache结构中，不同核访问主存相同页面会在各自私有cache中都保存该主存页面的副本，而共享cache则不会重复复制数据。(2)共享cache的存储空间可以在不同核之间动态按需分配，实现“统计时分复用”。而私有cache的大小是固定不变的。(3)共享cache还可以作为处理机间交互信息的通道。(4)多核处理机必须解决多级cache的一致性问题，而只设计L1一级私有cache可以降低解决cache一致性问题的难度，从而提供额外的性能优势。英特尔公司的第一代酷睿双核(CoreDuo)低功耗处理机就采用这种结构。4)片内共享L3cache结构随着处理机芯片上的可用存储器资源的增长，高性能的处理机甚至把L3cache也从处理机片外移至片内。图9.10(d)显示的多核结构在图9.10(b)显示的片内私有L2cache结构的基础上增加了片内多核共享L3cache，使存储系统的性能有了较大提高。由于处理机片内核心数和片内存储空间容量都在增长，在共享L2cache结构或私有L2cache结构上增加共享的L3cache显然有助于提高处理机的整体性能。英特尔公司于2008年推出的64位酷睿i7(Corei7)四核处理机就采用这种结构。尽管多核技术与单核技术相比存在性能高、集成度高、并行度高、结构简单和设计验证方便等诸多优势，但从单核到多核的转变并不是直接把多个芯片上的多个处理机集成到单一芯片之中这么简单。多核处理机必须解决诸多技术难题。1.多核处理机架构多核处理机的体系结构直接影响着多核的性能。而不同的应用的特性又差别很大，这些特性又对多核应该采用什么样的结构有着非常大的影响。为此，必须针对不同的应用设计多核的实现架构。首先是每个核自身的结构，这关系到整个芯片的面积、功耗和性能。就每个核而言，如何继承并扩展传统单处理机设计的成果，直接影响多核处理机的性能和实现周期。多核系统中的每个核是否应该采用超标量技术或超线程技术，是性能和成本平衡的问题。随着对处理机的性能要求的不断提高，在多核处理机的每个核上采用超线程技术的架构应用越来越广。而软件的并行化设计思想的推广也让超线程技术越来越有吸引力。其次就是多核之间的对等性，以及芯片上的核的数目。采用同构多核还是异构多核，一般要根据具体的应用场景、设计目标等因素综合决定。最初的多核处理机都采用同构处理机架构，每个核的功能较强，但集成的处理机核的数量较少，一般以总线或交叉开关互连。这种设计实际上是利用半导体技术的进步把原来放在不同芯片上的多处理机集成到一个芯片上，通过简单增加片内处理机核心的数量来提升处理机的性能，体系结构上的改进并不明显。这种设计方法简单、有效，可以重用复杂的处理机设计，并且借用板级总线协议，是多核发展的初级阶段。同构多核结构原理简单，硬件实现复杂度低，在通用桌面系统中被普遍采用。但在现实世界的应用场景中，并不总是能够把计算任务均匀分配到同构的多个核心上，多核必须面对如何平衡若干处理机的负载并进行任务协调等难题。即使能够不断增加同类型的处理机核心的数量以加强并行处理能力，整个系统的处理性能仍然会受到软件中必须串行执行的那部分的制约。达到极限值之后，性能就无法再随着内核数量的增加而提升了。这就是著名的阿姆达尔定律(Amdahl’slaw)。异构多核则通过配置不同特点的核心来优化处理机内部结构，实现处理机性能的最佳化，并能有效地降低系统功耗。异构多核架构的一个典型实例就是在通用个人计算机上将图形处理单元(GraphicProcessingUnit，GPU)与通用CPU集成在一颗芯片上构成的异构多核处理机。在这样的架构下，系统中必须串行执行的部分能在一个强大的CPU核上加速，而可以并行的部分则通过很多很小的GPU核来提速。GPU是在通用计算机系统上支持图形处理的专用处理单元。GPU的计算能力随着图形运算的复杂度的上升而逐渐提高，尤其是浮点运算能力已经远远超过通用CPU数倍。与CPU相比，GPU更适合重复计算，因为GPU是专门为图形运算而设计的，在设计时就考虑到了图形运算的特征。例如，对图形的色彩处理往往需要对所有待处理的像素执行相同或类似的重复运算。这恰恰让GPU非常适合进行SIMD运算。因此，人们很自然地试图利用GPU的这种优化设计来进行图形之外的通用计算，将GPU通用化，于是出现了通用图形处理机(GeneralPurposeGPU，GPGPU)。GPGPU兼有通用计算和图形处理两大功能，能完成CPU的运算工作，更适合高性能计算，并能使用高级程序设计语言，在性能和通用性上更加强大。GPGPU向着集成化方向发展，即将GPU核集成到CPU片内，就构成异构多核处理机。面向并行处理的应用软件所要求的浮点运算及定点运算将由GPU执行；而CPU内核则把重点放在执行传统处理机的主要任务，即运行操作系统、执行商务软件中的整数运算等。异构多核结构也存在着一些难点，如选择哪几种不同的核相互搭配、核间任务如何分工、如何实现良好的可扩展性等，必须在性能、成本、功耗等方面仔细平衡，并通过软硬件相互配合使任务的并行性最大化。2.多核系统存储结构设计为了使处理机的处理能力得到充分发挥，存储系统必须能够提供与处理机性能相匹配的存储器带宽。因此，处理机与主存储器之间的速度差距一直是处理机结构设计中必须考虑的问题。由于处理机内的核心数目增多，并且各核心采用共享存储器结构进行信息交互，对主存的访问需求进一步增加，在单处理机时代面临的存储墙问题依然存在，而且问题更加严重。故必须针对多核处理机进行相应的存储结构设计，并解决好存储系统的效率问题。目前的存储系统设计仍然采用存储器分级的方式解决存储速度问题，高性能的处理机采用二级甚至三级cache提高存储系统的等效访问速度，并且处理机片内的cache容量尽可能增大。但多核系统中的存储系统设计必须平衡系统整体性能、功耗、成本、运行效率等诸多因素。因此，在多核处理机设计时，必须评估共享cache和私有cache孰优孰劣、需要在芯内设置几级cache等因素。此外，在多核系统中，还面临多级cache的一致性(cachecoherency)问题。3.多核处理机的cache一致性cache一致性问题产生的原因是：在一个处理机系统中，不同的cache和主存空间中可能存放着同一个数据的多个副本，在写操作时，这些副本存在着潜在的不一致。在单处理机系统中，cache一致性问题主要表现为在内存写操作过程中如何保持cache中的数据副本和主存内容的一致，即使有I/O通道共享cache，也可以通过全写法较好地解决一致性问题。而在多核系统中，多个核都能够对内存进行写操作，而cache级数更多，同一数据的多个副本可能同时存放在多个cache存储器中，某个核的私有cache又只能被该核自身访问。即使采用全写法，也只能维持一个cache和主存之间的一致性，不能自动更新其他处理机核的私有cache中的相同副本。这些因素无疑加大了cache一致性问题的复杂度，同时又影响着多核系统的存储系统整体设计。维护cache一致性的关键在于跟踪每一个cache块的状态，并根据处理机的读写操作及总线上的相应事件更新cache块的状态。一般来说，导致多核处理机系统中cache内容不一致的原因如下。可写数据的共享一台处理机采用全写法或回写法修改某一个数据块时，会引起其他处理机的cache中同一副本的不一致。I/O活动如果I/O处理机直接接在系统总线上，也会导致cache不一致。核间线程迁移核间线程迁移就是把一个尚未执行完的线程调度到另一个空闲的处理机核中去执行。为提高整个系统的效率，有的系统允许线程核间迁移，使系统负载平衡。但这有可能引起cache的不一致。对于I/O活动和核间线程迁移而导致的cache不一致，可以分别通过禁止I/O通道与处理机共享cache以及禁止核间线程迁移来解决。因而多处理机中cache一致性问题主要是针对可写数据的共享。在多核系统中，cache一致性可以使用软件或者硬件维护。软件方法采取的手段是“预防”。在使用软件方式维护cache一致性时，处理机需要提供专门的显式cache操作指令，如cache块拷贝、回收和无效等指令，让程序员或编译器分析源程序的逻辑结构和数据相关性，判断可能出现的cache一致性问题，利用这些指令维护cache一致性。软件维护cache一致性的优点是硬件开销小，缺点是在多数情况下对性能有较大影响，而且需要程序员的介入。多数情况下，cache一致性由硬件维护。硬件方法采取的手段是“通过硬件发现和解决所发生的cache一致性问题”。不同的处理机系统使用不同的cache一致性协议维护cache一致性。cache一致性协议维护一个有限状态机，并根据存储器读写指令或者总线上的操作进行状态转移并完成相应cache块的操作，以维护cache一致性。目前，大多数多核处理机采用总线侦听(bussnooping)协议，也有的系统采用目录(directory)协议解决多级cache的一致性问题。目录协议在全局的角度统一监管不同cache的状态；而在总线侦听方式中，每个cache分别管理自身cache块的状态，并通过广播进行不同cache间的状态同步。1)目录协议目录协议收集并维护有关数据块副本驻存在何处的信息。典型地，系统有一中央控制器，它是主存控制器的一部分，目录就存于主存中。目录会有关于各个局部cache内容的全局性状态信息。当某个特定的cache控制器产生一个请求时，中央控制器检查此请求并发出必要的命令，以在存储器和cache之间或不同cache之间传送数据。中央控制器亦负责保持状态信息的更新。于是，任何一个能影响cache行的全局状态的局部动作必须报告给中央控制器。中央控制器维护着关于哪个处理机核具有哪个数据行副本的信息。在处理机核向局部cache行副本写入信息之前，必须向中央控制器请求排他性访问权限。在同意这次排他性访问之前，控制器发送一个消息给所有cache中保持有这一行副本的处理机核，以强迫每个处理机核使它的副本无效。接收到这些处理机核返回的确认信息后，控制器才将排他性访问权授予提出请求的处理机核。当一cache行已授权给某处理机核专有，而另外的处理机核企图读此行时，它将送出一个未命中指示给控制器。控制器则向持有此行的处理机核发布命令，要求它将此行写回到主存。于是，现在此行可被原先的处理机核和提出请求的处理机核读共享了。目录协议的缺点是存在中央瓶颈，且各cache控制器和中央控制器之间的通信开销也较大。然而，在采用了多条总线或某种另外的复杂互连机构的大型系统中，它们是很有效的。2)监听协议监听协议将维护cache一致性的责任分布到多核处理机中每个cache控制器上。一个cache必须知晓它保存的某个cache行何时会与其他cache共享。当对共享的cache行进行修改时，必须通过一种广播机制通知到所有其他cache。各cache控制器应能监听网络，以得到这些广播通知，并做出相应的反应。监听协议非常适合于基于总线的多核处理机，因为共享的总线能为广播和监听提供简洁的方式。然而，使用局部cache的目标之一就是希望避免或减少总线访问，因此必须小心设计以避免由于广播和监听而增加的总线传输抵消了使用局部cache的好处。监听协议已开发出两种基本方法：写-作废(write-invalidate)和写-更新(write-update)。使用写-作废协议，系统任一时刻可有多个读者，但只能有一个写者。最初，一个数据可能在几个cache中处于读共享状态。当某个cache要对此行进行写操作时，它要先发出一个通知，以使其他cache中此行作废，使此行变为cache写独占状态。一旦行变为独占状态，拥有该行的处理机核就可进行本地写操作，直到某些其他处理机核请求该数据行。在写-作废协议中，cache行的状态被分别标识为修改(Modified)、独占(Exclusive)、共享(Shared)和无效(Invilid)。故写-作废协议也称为MESI协议。写-更新协议又称为写-广播(write-broadcast)协议。采用该协议，系统中可有多个写者以及多个读者。当一个处理机核打算修改一个共享cache行时，将被写入的字数据也被同时广播到所有其他cache，于是拥有该数据行副本的cache能同时进行写修改。监听协议实现比较简单，但只适用于总线结构的多处理机系统，而且不管是写作废还是写更新，都要占用总线不少时间，所以只能用于处理机核数量不多的系统中。通常总线上能连接的处理机核不能超过10～16个。监听协议是应用广泛的cache一致性协议。4.多核处理机的核间通信与同步技术多核处理机片内的多个核心虽然各自执行自己的代码，但是不同核心间需要进行数据的共享和同步，因此多核处理机硬件结构必须支持高效的核间通信，片上通信结构的性能也将直接影响处理机的性能。当前主流的片上通信方式有三种：总线共享cache结构、交叉开关互连结构和片上网络结构。1)总线共享cache结构总线共享cache结构是指多核处理机核共享L2cache或L3cache，处理机片上核心、输入输出端口以及主存储器通过连接核心的总线进行通信。这种方式的优点是结构简单、易于设计实现、通信速度高，但缺点是总线结构的可扩展性较差，只适用于核心数较少的情况。采用总线共享结构的处理机有斯坦福大学研制的Hydra处理机、英特尔公司开发的酷睿(Core)处理机、IBM公司开发的Power4处理机和Power5处理机等。2)交叉开关互连结构总线采用分时复用的工作模式，因而在同一总线上同时只能有一个相互通信的过程。交叉开关(crossbarswitch)结构则能够有效提高数据交换的带宽。交叉开关是在传统电话交换机中沿用数十年的经典技术，它可以按照任意的次序把输入线路和输出线路连接起来。图9.11所示为连接8个处理机核和8个内存模块的交叉开关结构。图中左侧的每条水平线和每条垂直线的交点都是可控的交叉节点，可以根据控制信号的状态打开或闭合。闭合状态的交叉节点使其连接的垂直线和水平线处于连通状态。图中黑色实心节点处于闭合状态，空心节点处于打开状态，图中右侧显示了放大的节点示意图。图中显示有三个开关处于闭合状态，这意味着同时可以有三个处理机核分别与不同的存储器模块进行信息交互。交叉开关网络是一种无阻塞的网络，这就意味着不会因为网络本身的限制导致处理机第9章并行组织与结构301核无法与内存模块建立连接。只要不存在存储器模块本身的冲突，图9.11所示的8×8交叉开关结构最多可以同时支持八个连接。与总线结构相比，交叉开关的优势是数据通道多、访问带宽更大，但缺点是交叉开关结构占用的片上面积也较大，因为n×n的交叉开关需要n2个交叉节点。而且随着核心数的增加，交叉开关结构的性能也会下降。因此这种方式也只适用中等规模的系统。AMD公司的速龙(Athlon)X2双核处理机就是采用交叉开关来控制核心与外部通信的典型实例。3)片上网络结构片上网络(networkonachip，NoC)技术借鉴了并行计算机的互联网络，在单芯片上集成大量的计算资源以及连接这些资源的片上通信网络。每个处理机核心具有独立的处理单元及其私有的cache，并通过片上通信网络连接在一起，处理机核之间采用消息通信机制，用路由和分组交换技术替代传统的片上总线来完成通信任务，从而克服由总线互连所带来的各种瓶颈问题。片上网络与传统分布式计算机网络有很多相似之处，但限于片上资源有限，设计时要考虑更多的开销限制，针对延时、功耗、面积等性能标准进行优化设计，为实现高性能片上系统提供高效的通信支持。片上网络可以采用多种拓扑结构，如环形拓扑、网状拓扑、树状拓扑等。图9.12显示了一种常用的二维网状网络(2DMesh)片上网络结构。片上网络包括计算子系统和通信子系统两部分。计算子系统由处理单元(processingelement，PE)构成，完成计算任务，PE可以是处理机核心，也可以是各种专用功能的硬件部件或存储器阵列等。通信子系统由交换(switch)节点(图中缩写为“S”)及节点间的互连线路组成，负责连接PE，实现计算资源之间的高速通信。通信节点及其间的互连线所构成的网络就是片上通信网络。在二维网状网络结构中，每个PE与一个交换节点相连，而每个交换节点则与四个相邻的交换节点和一个PE相连，交换节点实现路由功能，并作为每个相邻的PE的网络接口。与总线结构和交叉开关互连结构相比，片上网络可以连接更多的计算节点，可靠性高，可扩展性强，功耗也更低。因此片上网络被认为是更加理想的大规模多核处理机核间互连技术。这种结构的缺点是硬件结构复杂，且软件改动较大。这三种互连结构还可以相互融合，例如，在整体结构上采用片上网络方式，而在局部选择总线或交叉开关结构，以实现性能与复杂度的平衡。由于多核处理机内的各个处理机核之间需要通过中断方式进行通信，所以多核处理机的中断处理方式也和单核有很大不同。多个处理机核内部的本地中断控制器和负责仲裁各核之间中断分配的全局中断控制器也需要封装在芯片内部。多核系统还需要解决的一个问题就是核之间的同步和互斥。多核处理机上运行的多个任务会竞争共享资源，因此需要操作系统和硬件配合提供核间同步机制与共享资源互斥访问机制。例如，多核系统硬件应提供“读-修改-写回”的原子操作或其他同步互斥机制，保证对共享资源的互斥访问。5.低功耗设计随着环保理念的普及和移动计算应用的推广，对处理机和整个计算机系统的功耗的关注度越来越高。低功耗设计是一个多层次的问题，需要同时在操作系统级、算法级、结构级、电路级等多个层次上综合考虑。在单处理机时代，低功耗技术主要在电路层次上进行低功耗设计，注重降低半导体电路的动态电能消耗和静态电能消耗。由于多核处理机在结构和实现上的特点，在多核处理机上可以采用异构结构设计、动态线程分派与转移技术等降低功耗。异构结构设计就是利用异构多核结构对片上资源进行优化配置，使处理机在提高性能的同时降低功耗。动态线程分派与转移技术则是在程序运行时动态地将某个核心上较高的负载转移到负载较小的核心上，从而使处理机在不降低处理性能的情况下，降低处理机功耗。当整体负载任务较少时，关闭某些核心或降低其处理机频率也可以使整个系统功耗降低。6.多核软件设计虽然多核技术与多处理机有许多相似之处，但二者之间的差别导致在许多情况下多处理机系统中的软件并不能直接拿到多核系统中运行。在多处理机系统中，各个处理机之间的界线是非常清晰的，每个处理机基本上都是独立运行的。而在多核系统中，资源的共享更加普遍。由于多核处理机内部有多个核心，因而如何在多个处理机核之间分配任务是必须要解决的关键问题。因此，支持多核的操作系统必须解决任务分配、任务调度、仲裁以及负载平衡等问题，必要时还需要支持多核之间的动态任务迁移。对于多核处理机，优化操作系统任务调度算法是保证效率的关键。当前关于多核的任务调度算法主要有全局队列调度和局部队列调度等算法。全局队列调度策略由操作系统维护一个全局的任务等待队列，当系统中有某个处理机核心空闲时，操作系统便从全局任务等待队列中选取就绪任务并开始在此核心上执行。这种调度策略的优点是处理机核心的利用率较高。局部队列调度策略是操作系统为每个处理机核心维护一个局部的任务等待队列，当系统中有某个处理机核心空闲时，便从该核心的任务等待队列中选取恰当的任务执行。局部队列调度策略的优点是任务基本上无需在多个处理机核心之间迁移，有利于提高处理机核心私有cache的命中率，缺点是处理机核心的利用率较低。目前，大多数支持多核的操作系统采用基于全局队列的任务调度算法。从某种程度上说，应用软件的设计是多核系统设计的难点。这是因为，人的自然思维模式是单任务串行化的，正所谓“一心不能二用”。而多核系统中运行的程序只有按照并行化的思想设计才可能最大限度地发挥多核处理机的潜能。并行编程困难的问题从并行计算机产生以来就存在，只是随着多核的主流化，问题更加突出了。虽然多处理机技术和多计算机技术已经应用多年，但当前的多核计算机系统与以往的并行计算机系统有很大的不同，以往的并行计算机系统都是应用在服务器或者超级计算中心等适合进行大型并行计算的领域，这些领域很容易发挥并行计算的优势。而现在的多核计算机系统则是应用到普通用户的各个层面，甚至是嵌入式系统中，在这些应用场景中实现软件并行编程，难度可能比服务器和超级计算中心更高。多核系统下的并行编程，必须充分发挥多核的线程级并行性，但是已有的编程语言不能完全适合多核环境，不能将多核的多线程并行潜力充分挖掘出来。为此，需要针对多核环境下对并行编程应用的要求，对现有的并行编程模式和编程语言(如OpenMP、MPI、并行C等)进行改进和优化，希望利用编程工具尽可能地帮助程序设计者发掘并行性。除了并行编程工具之外，另一个重要问题是并行设计思想。原来运行在单处理机上的众多应用程序并没有利用多核的性能潜力，其中很多应用程序的线程级加速潜力有限。改造这些依据串行化思想设计的程序不能单纯依赖并行编程工具，必须将其从单线程的编程模式改造为并行程序执行模式。所以对于这些应用程序，或者要重新编写并行代码，或者研发更加先进的面向多核结构的自动并行化工具，使得这些应用程序能在多核处理机系统中高效运行。7.平衡设计原则除了上面讨论的一些多核处理机的关键技术，多核系统设计还必须遵循一个重要的设计原则，就是平衡设计。与单处理机系统相比，多核计算机系统的设计复杂度大幅度提高。因为在解决某个方面问题的同时往往会带来其他方面的问题，所以多核处理机结构设计的重点不在于其中某一个细节采用什么复杂或性能表现较好的设计，而是在于整体设计目标。因此，在多核系统设计过程中必须仔细权衡对某些问题的解决方法，尽量采用简单、易于实现、成本低廉而且对整体性能影响不大的设计方案。平衡设计原则是指在芯片的复杂度、内部结构、性能、功耗、扩展性、部件成本等各个方面做一定的权衡，不能为了单纯地获得某一方面的性能提升而导致其他方面的问题。在设计过程中要坚持从整体结构的角度去权衡具体的结构问题。要得到在一个通常情况下，逻辑结构简单并且对大多数应用程序而言性能优良的处理机结构，为了整体目标往往要牺牲某些局部的最佳设计方案。Cortex-A15MPCore处理机是ARM公司2010年9月推出的ARMv7-A体系结构的多核产品。借助先进的多核处理机架构，Cortex-A15MPCore处理机在高性能产品应用中的运行主频最高可达2.5GHz，在提供强大的计算性能的同时，又保持着ARM特有的低功耗特性。该处理机有非常强的可扩展性(scalability)，支持单片1至4个处理机内核，可广泛应用在移动计算、高端数字家电、无线基站和企业级基础设施产品等领域。1.ARMCortex-A15处理机的整体结构图9.13显示了ARMCortex-A15MPCore四核处理机的整体结构。每个核内部包含支持ARMv7-A体系结构的32位CPU，采用超标量、可变长、乱序执行流水线结构。指令流水线为15至24级，其中12级为按序执行，另外3至12级为乱序执行。Cortex-A15处理机另外配备支持IEEE754标准的向量浮点运算单元(FPU)，对半精度、单精度和双精度浮点算法中的浮点操作提供硬件支持。ARM处理机独有的NEON媒体处理引擎则为消费类多媒体应用提供灵活强大的加速功能。NEON是ARMCortex-A系列处理机上的128位单指令流多数据流(SIMD)体系结构扩展技术，媒体处理引擎扩展了Cortex-A15处理机的浮点运算单元，支持整数和浮点向量的SIMD运算。NEON通用SIMD引擎旨在加速视频编解码、2D/3D图形、游戏、音频和语音处理、图像处理、电话和声音合成等多媒体和信号处理算法，从而明显改善用户体验。Cortex-A15还为每个处理机核配备了程序跟踪宏单元接口(programtracemacrocellinterface，PTMI/F)，连接至多核调试和跟踪部件。Cortex-A15的每个处理机核内包含32KB的L1指令cache和32KB的L1数据cache，L1cache专门针对性能和功耗进行了优化。在高性能应用中，可以通过可配置的512KB～4MB的共享L2cache实现对内存的低延迟、高带宽访问。L1指令cache支持奇偶校验功能，L1数据cache和L2cache则支持可选的纠错编码(errorcorrectioncode，ECC)功能，可纠正单比特错误、检测双比特错误。处理机内还集成了三个独立的32表项全相联L1转换后援缓冲器(TLB)，分别用于取指令、读数据和写数据。每个处理机内还包含512表项的4路组相联L2TLB。Cortex-A15为主存提供了超大寻址空间，40位物理地址可支持1TB的主存空间。2.ARMCortex-A15的多核支持功能Cortex-A15处理机利用被广泛认可的ARMMPCore多核技术，支持性能可扩展性和动态功耗控制功能。1)动态功耗控制当配备该处理机的设备需要高性能时，片内的所有处理机核可以全速运行，满足运算需求，但核间任务分担机制可以平衡各个核的工作负载，以保持尽可能低的功耗。当设备不需要满负荷运行时，四个处理机核中的任何一个都可以被动态关闭，以降低功耗。2)监听控制单元监听控制单元(snoopcontrolunit，SCU)提供系统一致性管理功能，负责管理cache之间以及cache与系统主存之间的互连和通信，并解决cache一致性问题、实现数据传输优先级仲裁以及其他相关的功能。除了处理机核，Cortex-A15MPCore处理机内的其他系统加速器(如FPU和NEON)和支持非缓冲DMA访问的外设也能够利用监听控制单元提供的支持，以便提高系统级的性能并降低功耗。监听控制单元提供的系统一致性管理功能还可降低在各个操作系统驱动程序中维持软件一致性的软件复杂度。3)加速器一致性端口加速器一致性端口是监听控制单元上提供的支持AMBA4AXI(高级可扩展接口，ARM推出的第四代AMBA接口规范)规范的从设备接口，能够让主设备直接连接到Cortex-A15处理机。该接口支持所有标准读操作和写操作，而不需要特别考虑一致性问题。不过，针对主存一致区域的任何读操作都必须首先与监听控制单元交互，以确认被访问的信息是否已存储在L1cache中。任何写操作也将首先由监听控制单元进行一致性处理，然后才提交给存储系统并可在L2cache中分配空间，从而消除直接写入片外主存空间对功耗和性能的影响。4)通用中断控制器标准化和结构化的通用中断控制器可以灵活地支持处理机核间通信功能，实现系统中断的优先级仲裁及其在处理机核之间的分配。中断控制器最多支持224个独立中断源。在软件控制下，每个中断均可在处理机核之间调配，进行硬件优先级排队。2012年4月，英特尔在北京发布了多款基于IvyBridge(简称IVB)微架构(micro-architecture)的第三代智能酷睿(Corei)系列处理机，是当时业界制造工艺最为先进的处理机。2011年推出的采用32nm半导体工艺的第二代智能酷睿处理机微架构SandyBridge处理机实现了处理机核、图形核心、视频引擎的单芯片封装。与SandyBridge(简称SNB)相比，IvyBridge对处理机架构没有做太大调整，但采用更加先进的22nm制造工艺，并结合3D晶体管技术，在大幅度提高晶体管密度的同时，处理机片上的图形核心的执行单元的数量翻一番，核芯显卡等部分性能有了一倍以上的提升。制造工艺的改进带来更小的核心面积、更低的功耗以及更加容易控制的发热量。1.酷睿多核处理机的整体结构IvyBridge微架构处理机由处理核心、三级cache、图形核心、内存控制器、系统助手(systemagent)、显示控制器、显示接口、PCI-EI/O控制器、DMI总线控制器等众多模块整合而成。IvyBridge微架构处理机采用模块化设计，有很强的可扩展性，支持多种不同主处理机核心数、不同性能的图形核心和cache容量的组合配置。从SandyBridge微架构开始，每个处理机内部处理除了中央处理机核之外，还集成了图形处理单元(GPU)核。这种与中央处理机封装在同一芯片上的图形处理单元又称为核芯显卡。SandyBridge和IvyBridge处理机上的处理机核和图形处理核采用完全融合的方式，在同一块晶圆中分别划分出CPU区域和GPU区域，CPU和GPU各自承担数据处理与图形处理任务。这种整合设计大大降低了处理机核、图形处理核、内存及内存控制器间的数据周转时间，可有效提升处理效能并大幅降低芯片组的整体功耗。在IvyBridge系列处理机中包含了两种集成GPU核：GT1和GT2。GT1有6个执行单元(executionunit，EU)和24个算术逻辑单元(ALU)及一个纹理单元。GT2有16个执行单元、64个ALU和2个纹理单元。处理机内的各个CPU核之外还集成了最后一级cache(last-levelCache，LLC)，即与主存储器直接相连的L3cache。目前发布的IvyBridge微架构有4种设计版本：4个中央处理机核心+8MB缓存+GT2图形核心；2个中央处理机核心+4MB缓存+GT1图形核心；4个中央处理机核心+6MB缓存+GT1图形核心；2个中央处理机核心+4MB缓存+GT1图形核心。图9.14(a)～(d)分别显示了IvyBridge微架构支持的四种配置。2.酷睿多核处理机的环形总线图9.15显示了IvyBridge四核处理机的完整体系结构。图中可以看出，IvyBridge微架构使用全新的环形总线(ringbus)结构连接各个CPU核、最后一级cache、图形处理单元(GPU)以及系统助手等模块。系统助手从功能上类似以前的北桥芯片，但包含了更为丰富的功能，包括集成内存控制器、支持16条PCI-E2.0通道的PCI-E控制器、显示控制器、电源控制单元(PCU)以及DMI总线(英特尔开发用于连接主板南北桥的总线)的IO接口等。环形总线由四条独立的环组成，分别是数据环(dataring)、请求环(requestring)、响应环(acknowledgering)和监听环(snoopring)。借助于环形总线，CPU与GPU可以共享LLCcache，从而大幅度提升GPU的性能。在环形总线上分布着多个环节点(ringstop)。环节点在每个CPU核、GPU核或最后一级cache上有两个连接点。在以往的产品中，多个核心共享一个最后一级cache，核心需要访问cache时必须先经过流水线发送请求，再进行优先级排队后才能进行。环形总线则可以大大减少核心访问最后一级cache的时间延迟。环形总线将最后一级cache分割成了若干部分，环形总线上的每个节点与其相邻的另两个节点采用点到点的连接方式，故环形总线是由多个子环组成的。借助于每个环节点，核心可以快速访问最后一级cache。又由于每个核心与最后一级cache之间可以实现并行访问，使得整体带宽可以显著提升。为了满足人类社会对计算性能的无止境需求，处理机内部的核心数量不断增加。当处理机内的核心的数量超过32个时，称为众核(many-core)处理机。2012年，英特尔公司发布了基于英特尔集成众核(manyintegratedcore，MIC)架构的至强融核(XEONphi)产品。英特尔集成众核处理机可作为中央处理机的协处理机工作，可通过PCI-E总线连接到配置英特尔至强(XEON)处理机的主机上，是高度优化、高度并行的协处理机，其运算性能超过每秒一百万亿次浮点双精度持续计算。至强融核使用开源Linux操作系统和通用源代码，可运行完整的应用程序，用于高度并行的计算密集型负荷，采用和至强处理机一致的通用编程模型与软件工具。至强处理机与一颗或多颗至强融核处理机构成异构多处理机架构，而至强融核本身则在单芯片内集成了57～61个处理核心(向量IA内核)。图9.16显示了至强融核众核处理机的微架构。处理机片上环形互连总线连接众多的计算核心、8个支持GDDR5的存储器控制器(MC)和1个PCI-E终端逻辑单元(PCIeclientlogic)。每个计算核心支持四个硬件线程，支持U、V两条七级指令流水线，双指令发射、按序执行，故每个时钟周期可以执行两条指令。计算核心通过环形总线接口(CRI)与互连总线相连。环形总线接口由L2cache和分布式标签目录(tagdirectory,TD)组成，后者为每个核心的L2cache建立标识目录副本，从而全局监视所有核心的L2cache，确保cache一致性。虽然至强融核处理机的每个计算核心的主频只有1～1.25GHz，处理能力不算强大，但在运行高性能计算应用时，可以将高度并行的计算任务分解成更小的子任务，采用SIMD方式分布到众多核心中并行运行，而高速的至强处理机主机上则可运行最低限度的串行代码。依靠众核架构，系统能够获得额外的性能提升。龙芯(Loongson)3号是中国科学院计算技术研究所研发的国产多核处理机系列产品，集高性能、低成本和低功耗于一身，主要面向服务器和高性能计算应用。龙芯3号单芯片内集成多个高性能64位超标量通用处理机核以及大容量L2cache，并通过高速I/O接口实现多芯片互连，以组成更大规模的系统。龙芯3号尤其可以满足国家安全需求。首台采用龙芯3A处理机的万亿次高性能计算机KD-60于2010年4月通过鉴定，实现了我国高性能计算机国产化的重大突破。1.龙芯3A处理机的整体结构龙芯3A是龙芯3号多核处理机系列的第一款产品，每个处理机芯片集成4颗64位的四发射超标量GS464高性能处理机核，最高工作主频为1GHz。片内集成4MB的分体共享L2cache(由4个体模块组成，每个体模块容量为1MB)。处理机内部通过目录协议维护多核及I/ODMA访问的cache一致性。处理机芯片内还集成了DDR2/DDR3存储器控制器、Hyper-Transport(HT)控制器、PCI-X/PCI总线控制器、LPC、UART、SPI等外围接口部件。图9.17显示了龙芯3A四核处理机的整体结构。每个处理机有两级AXI交叉开关。第一级互连采用6×6的AXI交叉开关(X1Switch)，连接P0、P1、P2和P3四个处理机核心(作为主设备)，统一编址的S0、S1、S2和S3四个L2cache模块(作为从设备)，以及两个I/O端口(每个端口使用一个主端口和一个从端口)。每个I/O端口通过一个DMA控制器连接一个16位的HT控制器(每个16位的HT端口可以拆分成两个8位的HT端口使用)。第二级互连采用5×4的交叉开关(X2Switch)，连接四个L2cache第9章并行组织与结构309模块、两个DDR2存储器控制器(MC)和I/O接口(包括PCI、LPC、SPI等)以及芯片内部的控制寄存器模块。两级互连开关都采用读写分离的数据通道，数据通道宽度为128位，工作频率与处理机核相同，用于提供高速的片上数据传输。2.龙芯3号的GS464处理机核心GS464是一款实现64位MIPS64指令系统及龙芯扩展指令系统的通用RISC处理机IP核。GS464有两个定点运算部件、两个浮点运算部件和一个访存部件。每个浮点部件都可以全流水地执行64位双精度浮点乘加操作。GS464的指令流水线在每个时钟周期取四条指令进行译码，并且动态地发射到五个全流水的功能部件中。指令按序发射，乱序执行。GS464的基本结构如图9.18所示。GS464的基本流水线包括取指、预译码、译码、寄存器重命名、调度、发射、读寄存器、执行、提交等9级，各个流水级的功能如下。(1)取指流水级：根据程序计数器PC的值访问指令cache和指令TLB，如果指令cache和指令TLB都命中，则把四条新的指令取到指令寄存器IR中。(2)预译码流水级：主要对转移指令进行译码并预测跳转的方向。(3)译码流水级：把IR中的四条指令转换成GS464内部指令格式送往寄存器重命名模块。(4)寄存器重命名流水级：为逻辑目标寄存器分配新的物理寄存器，并将逻辑源寄存器映射到最近分配给该逻辑寄存器的物理寄存器。(5)调度流水级：将重命名的指令分配到定点或浮点保留站中等待执行，同时送到重排序队列中用于执行后的顺序提交；此外，转移指令和访存指令还分别被送往转移队列和访存队列。(6)发射流水级：从定点或浮点保留站中为每个功能部件选出一条所有操作数都准备好的指令；在重命名时操作数没准备好的指令将等待其操作数准备好。(7)读寄存器流水级：为发射的指令从物理寄存器堆中读取相应的源操作数送到相应的功能部件。(8)执行流水级：根据指令的类型执行指令并把计算结果写回寄存器堆。(9)提交流水级：按照重排序队列记录的指令顺序提交已经执行完的指令，GS464最多每拍可以提交四条指令。GS464的L1cache由64KB的指令cache和64KB的数据cache组成，均采用四路组相联结构。GS464的TLB有64项，采用全相联结构。GS464支持128位的访存操作，其虚地址和物理地址均为48位。3.龙芯3A处理机的互连结构龙芯3A采用可扩展的互连结构，片内二维Mesh网络利用AXI交叉开关进行片内核间互连，片间通过HT接口进行可伸缩互连，构建多处理机系统。图9.19显示了四颗龙芯3A处理机构成的2×2Mesh网络结构。系统由16个处理机核心构成。全系统统一编址，硬件自动维护各处理机间的数据一致性。互连系统的物理实现对软件透明，不同配置的系统可以运行相同的操作系统。本章小结并行性是指计算机系统具有同时进行运算或操作的特性，它包括同时性(两个以上事件在同一时刻发生)与并发性(两个以上事件在同一时间间隔内发生)两种含义。并行性的4种技术是：①时间并行(时间重叠)；②空间并行(资源重复)；③时间并行+空间并行；④资源共享(软件方法)。Flynn将计算机体系结构分为SISD、SIMD、MISD和MIMD四种类型。虽然MISD没有实际机器，但是四种类型的分类方法确实纲目清晰，有利于认识计算机系统的总体结构。传统单处理机依靠超标量技术和超长指令字技术提高指令级并行性，而多线程技术和超线程技术则把重点放在线程级并行性上，在处理机内部增加少量部件，将一个物理处理机模拟成多个逻辑处理机，从而减少访存延迟造成的执行部件浪费，提高处理机内部资源的使用率。多处理机属于MIMD结构，是传统上为提高作业级或任务级并行性所采用的并行体系结构。多处理机系统由多台独立的处理机组成，通过通信网络或共享存储器进行通信，共同完成处理任务。SMP是多处理机的常见形式，组成SMP的每台处理机的能力都完全相同。多核处理机在一个处理机芯片内集成多个完整的计算引擎(内核)，通过开发程序内的线程级或进程级并行性提高性能。多核处理机具有高并行性、高通信效率、高资源利用率、低功耗、低设计复杂度、低成本等优势。可以根据多个核心的物理特征把多核系统分为同构多核和异构多核，也可以在逻辑上把多核系统分为SMP结构和AMP结构。SMP向上提供了一个完整的运行平台，上层应用程序不需要意识到多核的存在，而AMP必须由应用程序来对各个核心分配任务。多核系统必须解决核间通信、cache一致性等诸多问题。。1.1计算机的分类电子计算机从总体上来说分为两大类：电子模拟计算机特点是数值由连续量来表示，运算过程也是连续的。电子数字计算机主要特点是按位运算，并且不连续地跳动计算。10111958年完成的我国自行研制的模拟计算机红旗-551，慈云桂121960年，我国自行设计的第一台电子数字计算机107机中科院计算机夏培肃领导研制她也是我国计算机事业的奠基者现在计算机中的一些术语和专业名词都是她翻译的。中国计算机之母131.1.1计算机的分类根据性能、经济性和适应性，可以划分为两类：专用计算机：专用机是最有效、最经济和最快速的计算机，但是它的适应性很差。通用计算机：通用计算机适应性很大，但是牺牲了效率、速度和经济性。通用计算机分类可以分为：超级计算机大型机服务器工作站微型机单片机区别在于：体积、简易性、功耗、性能指标、数据存储容量、指令系统规模和机器价格等141.2计算机发展简史计算机的五代变化1946—1957年，电子管计算机：数据处理1958—1964年，晶体管计算机：工业控制1965—1971年，中小规模集成电路计算机：小型计算机1972—1990年，大规模和超大规模集成电路计算机：微型计算机1991年至今，甚大规模集成电路计算机：单片机151.2.2半导体存储器的发展20世纪50～60年代，所有计算机存储器都是由微小的铁磁体环构成1970年，仙童半导体公司生产出了第一个较大容量半导体存储器从1970年起，半导体存储器经历了若干代：单个芯片1KB~1MB~1GB。其中1K=1031M=103K=106,1G=103M=1091bit表示1个二进制位，1B=8bit规范的二进制位计数：1Ki=210,1Mi=220,1Gi=230161.2.3微处理器的发展1971年Intel公司开发出4004。1972年出现的8008，这是第一个8位微处理器1974年出现了8080，这是第一个通用微处理器。171.2.3微处理器的发展20世纪70年代末出现通用16位微处理器8086Intel于1985年推出了32位微处理器80386。到现在的64位处理器和多核处理器18我国计算机技术的发展1953年起步，1958年第一台103型通用计算机50年来相继研究出了第二代，第三代计算机。80年代研究出每秒１亿次的巨型机，银河I,II,曙光等。85年6月，第一台实现中文化系统、并量产的国产微机长城0520CH正式研发成功。在高性能计算，并行计算上已紧跟国际先进水平，但计算机的核心部件CPU技术还远远落后。191.2.3微处理器的发展微处理器一般称为CPU：CentralProcessUnit目前CPU芯片主要设计/生产商Intel：酷睿、奔腾、赛扬、至强！AMD：速龙、闪龙、皓龙、APU-天津海光VIA：C3、C7-上海兆芯IBM：-苏州国芯龙芯：嵌入式、桌面、专用计算机ARM：三星、高通、华为海思、华为鲲鹏201.2.3微处理器的发展龙芯属于MIPS架构（LoongArch）上海兆芯属于X86架构华为麒麟/鲲鹏属于ARM架构阿里平头哥属于RISC-V架构中国有着全球数量最多的芯片设计公司展讯、寒武纪等小米，百度、VIVO、OPPO都在布局芯片还未形成规模效益、人才缺口非常大通用计算机分类可以分为：超级计算机大型机服务器工作站微型机单片机区别在于：体积、简易性、功耗、性能指标、数据存储容量、指令系统规模和机器价格等22超级计算机-Top500（2023.5）1、Frontier(美),处理器核：8,730,112；峰值1102PFlop/s；AMD处理器2、Fugaku(日),处理器核：7,630,848；峰值442PFlop/s；ARM处理器2、LUMI(芬兰),处理器核：1,110,144；峰值151.9PFlop/s；AMD处理器+NVIDIATeslaV1007、神威太湖之光,处理器核：10,649,600；峰值93.01PFlop/s；神威处理器10、天河2A,处理器核：4,981,760；峰值61.4PFlop/s；Intel+国产Matrix-2000加速卡23超级计算机-Top500（2024.5）1、Frontier(美),处理器核：8,699,904；峰值1.206EFlop/s；AMD处理器2、Aurora(美),处理器核：9,264,128；峰值1.012EFlop/s；Intel处理器3、Eagle(美),处理器核：2,073,600；峰值561.2PFlop/s；Intel处理器+NVIDIAH1004、Fugaku(日),处理器核：7,630,848；峰值442PFlop/s；ARM处理器5、LUMI(芬兰),处理器核：2,752,704；峰值379.7PFlop/s；AMD处理器+NVIDIATeslaV100Top500组织在最新发布的报告中指出，中国已决定不再参加Top500的HPL基准测试。24日本Fugaku-富岳富士通和日本理化学研究所共同研制拥有超过7,630,848个核心，内存4752TB富士通A64FX处理器，ARMv8.2-A，配备32GBHBM2内存，带宽1TB/s，浮点性能2.7TFLOPS，使用台积电7nm工艺生产，晶体管数量878.6亿A64FX包含48个计算核心和2~4个辅助核心，没有GPU加速器，封装HBM2内存。252024/6/5神威-太湖之光2017年TOP500第一，2020年第四拥有40960个计算节点，内存1.31PB使用了国产众核芯片申威26010采用28nm制程工艺，主频1.45GHz拥有260个核心，浮点峰值达到3.06TFlops64位261.2.4计算机的性能指标272024/6/51.2.4计算机的性能指标CPU执行时间：表示一段程序执行过程中所占用的CPU时间。CPU时间=执行某段程序所使用的CPU周期数×CPU时钟周期CPI：CyclePerInstruction执行一条指令所需的平均周期数执行某段程序所使用的CPU周期数÷程序总指令数MIPS：MillionInstructionsPerSecond每秒百万指令数MIPS=程序总指令数÷(程序执行时间×106)2024/6/5281.2.4计算机的性能指标2024/6/529CPU性能公式30CPU性能公式31CPU性能公式322024/6/533[例2]用一台50MHz处理机执行标准测试程序，它包含的混合指令数和相应所需的平均时钟周期如下表所示：解341.3计算机的硬件1.3.1硬件组成要素控制器运算器存储器输入设备输出设备冯·诺依曼型计算机VonNeumann1.3计算机的硬件冯·诺依曼型计算机五大组成部分二进制表示存储程序程序控制35冯诺依曼架构361.3.2运算器37ALU-ArithmeticLogicUnit（算术逻辑运算单元）算术运算和逻辑运算在计算机中参与运算的数是二进制运算器的长度一般是8、16、32或64位计算机的字长381.3.3存储器存储数据和程序运算开始前，必须先将程序和数据存入存储器（存储程序思想）一个存储单元中存入一个二进制数据串。存储器按存储单元组织，存储器中有大量的存储单元。为了方便查找，每个存储单元都被分配一个地址。通常，存储器都是按地址查找，线性编址。391.3.3.存储器存储器的容量一般都按字节计算存储器单位：210Byte＝1KiB210KiB＝1MiB210MiB＝1GiB210GiB＝1TiB分类：内存、外存1.3.3.存储器内存有两种操作：写入：数据存入存储器写入新数据后，会“覆盖”旧数据读出：从存储器取出数据读出并不破坏存取器中的数据可以从同一存储单元中反复的读出同一数据401.3.4控制器控制器是计算机中发号施令的部件控制计算机的各部件有条不紊地工作任务：从内存中取出指令加以分析,然后执行某种操作（指令控制）一条指令（instruction）完成一种操作算术运算或者逻辑运算、传输数据等将复杂的问题简化为一系列简单操作每个简单操作用一条指令完成，一系列指令的有序集合叫做程序（program）411.3.4控制器(2)指令的形式指令的内容由两部分组成，即操作的性质和操作数的地址。每条指令应当明确告诉控制器，从存储器的哪个单元取数，并进行何种操作。指令系统：计算机的全部指令集合。42范例-模型计算机43存储器运算器和控制器存储单元44模型计算机存储器运算器和控制器范例45范例4647存储器中的机器语言程序10111213987654321指令集构造机器指令将汉语表达转为二进制表示汇编源程序同一个问题在不同实现的计算机上解决，步骤是不同的。编译器48要考虑两个问题：数据存储数据处理模型计算机存储器49表1.4计算y=ax+b-c的程序表1.5指令的操作码定义51(2)指令的形式数码化的指令和数据都放入存储器，两种方式：冯诺依曼结构（VonNeumannArchitecture）：存储器的任何位置既可以存放数据也可以存放指令哈佛结构（HarvardArchitecture）：指令和数据存储器物理上独立52冯诺依曼结构哈佛结构(2)指令的形式存储程序：将程序（指令序列）和数据存放到存储器中程序控制：控制器依据存储的程序来全机协调地计算任务53控制器执行程序的过程2024/6/554取指令1011001执行（9）→A取指令0111100执行(12)→B;(A)*(B)→A取指令0011010执行(10)→B;(A)+(B)→A取指令0101011执行(11)→B;(A)-(B)→A取指令1101101执行A→(13)取指令1110000执行StopSTO13LAD9MUL12ADD10SUB11SLT1.3.4(3)控制器的基本任务按照特定的顺序一条接着一条取指令、执行指令。55取指令1011001执行（9）→A取指令0111100执行(12)→B;(A)*(B)→A取指令0011010执行(10)→B;(A)+(B)→A取指令0101011执行(11)→B;(A)-(B)→A取指令1101101执行A→(13)取指令1110000执行Stop1.3.4(3)控制器的基本任务每取出一条指令，控制器中的指令计数器就加1，下一条指令做好准备指令计数器(Programcounter:PC)保存指令的地址指令要顺序存放每条指令在存储器都有地址56存储器中的机器语言程序7654321指令地址1.3.4(3)控制器的基本任务时间因素取指周期：从存储器中取指令到控制器的时间执行周期：在控制器中执行指令的时间57时间t1.3.4（4）指令流和数据流如何区分内存输出的是指令流？还是数据流？根据不同的时间取指周期中从内存读出的信息流是指令流，它流向控制器执行周期中从内存读出的信息流是数据流，它由内存流向运算器。581.3.4控制器其他任务：保证指令按规定序列自动连续地执行。对各种异常情况及时响应和处理。控制器向计算机各功能部件提供每一时刻协同运行所需要的控制信号591.3.5适配器与输入输出设备输入设备：把人们所熟悉的信息形式变换为二进制信息形式输出设备：把计算机处理结果变换为人或其他机器设备所能接收和识别的信息形式总线：构成计算机系统的骨架，是多个系统部件之间进行数据传送的公共通路。601.4计算机的软件1.4.1软件的组成与分类611.4.2软件的发展演变编程语言的发展手编程序：机器语言程序，手工编译二进制码汇编程序：符号语言程序，汇编程序汇编62可执行程序目的程序机器语言可执行程序目的程序汇编语言手工编写汇编源程序汇编程序翻译1.4.2软件的发展演变编程语言的发展高级程序：算法语言/高级语言编译系统：把源程序全部翻译成目的程序，然后机器执行目的程序解释系统：逐一翻译源程序语句并立即执行该语句。63源程序可执行程序目标程序编辑程序汇编或编译程序联接程序高级语言1.4.2软件的发展演变系统软件的发展操作系统：用来管理计算机软硬件资源和自动用户作业调度，而使多个用户能有效地共用一套计算机系统。数据库管理系统：数据库和数据库管理软件分布式系统软件641.5计算机系统的层次结构计算机是一个硬、软件结合而成的整体。它通常由五级组成。不同的计算机使用者看到的计算机的形式是不同的651.5计算机系统的层次结构高级语言级：方便用户编写应用程序，由各种高级语言编译程序支持和执行。汇编语言级：提供一种符号形式语言，以便能够精确地操作控制硬件。操作系统级：它由操作系统程序实现，管理所有的硬件资源661.5计算机系统的层次结构一般机器级：由微程序解释机器指令系统。微程序设计级：实际执行指令、处理数据的数字电路。671.5.2软件与硬件逻辑等价性随着大规模集成电路技术的发展任何操作可以由软件来实现，也可以由硬件来实现；采用哪种方案？应综合考虑各个因素：价格、速度、可靠性、存储容量、变更周期固件：介于传统的软件和硬件间的实体。功能------软件形态------硬件实现------软件写入ROM------固化68第一章小结计算机的分类冯·诺依曼型计算机特点计算机硬件的基本组成部分五大部件运算器、控制器、存储器计算机软件计算机的性能指标计算机层次结构69返回作业P15：4、5、6、7、8、1470一段C程序intmain(){inta=2,b=3;intc,d;c=a+b;d=a*b;}在线编程网站https://gcc.godbolt.org/X86架构的指令序列X86架构的指令序列8051单片机架构的指令序列SPARCV8架构的指令序列人工智能四层架构762024/6/5AI不同计算任务需要不同芯片77GPU与AI模型训练78FPGA：分布式+可定制79ASIC：实现性能和功耗均衡80国产服务器CPU81自动驾驶芯片指标AI算力TOPS根据地平线数据，L2级自动驾驶的算力需求为2-2.5TOPS，L3级自动驾驶算力需求为20-30TOPS,L4级自动驾驶算力需求为200TOPS以上，L5级自动驾驶算力需求为2000TOPS以上。82算力单位TOPSTOPS(TeraOperationsPerSecond)，表示每秒执行1万亿次(10^12)运算，用于衡量自动驾驶芯片的AI算力。TOPS描述芯片MAC(MultiplyAccumulate，乘积累加运算)的运算能力，并没有指定数据类型，具体算力评估需要结合数据类型及精度。MAC运算包括相乘和相加(a←a+b*c)。对于卷积、点积、矩阵等运算而言，MAC指令可以大幅提高运算效率。TOPS计算公式：理论峰值=MAC矩阵行*MAC矩阵列*主频*28384现代GPU集群极度耗电。GPT4在训练过程中使用了约50GWh的能量。相当于30辆普通汽车环绕地球300次。谷歌表示一次搜索使用0.28瓦时，而与谷歌搜索相比，GoogleGPT4使用的能量大约是谷歌搜索的四倍。8586SM（StreamingMultiprocessors）称为流式多处理器，是NVIDIAGPU的基本构建模块。每个SM包含CUDA核心（用于通用计算的处理单元）、张量核心（专门用于AI工作负载）以及其他用于图形和计算操作的组件。SM具有高度并行性，使GPU能够同时执行许多操作。主芯片上共有144个SM。但它们的参数产量约为90％，这意味着我们可以使用大约130个。在生产过程中发生故障的部分会被关闭。此外，如果看一下主芯片的尺寸，那是一个相当大的芯片，非常接近现代工厂机器的限制。。87HBM（高带宽内存）HBM是一种具有高带宽接口的堆叠内存类型。与传统的GDDR内存相比，HBM提供了显著更多的带宽，可以实现GPU和内存之间的数据传输速率更快，这对于对带宽需求高的任务（如深度学习和大数据分析）特别有益。如果查看内存控制器，您会看到有6个，但NVIDIA只启用了其中的5个。8889第二章运算方法和运算器2.1数据与文字的表示方法2.2定点加法、减法运算2.3定点乘法运算2.4定点除法运算2.5定点运算器的组成2.6浮点运算方法与浮点运算器1返回22.1数据与文字的表示方法2.1.1数据格式2.1.2数的机器码表示2.1.3字符与字符串的表示方法2.1.4汉字的表示方法2.1.5校验码32.1数据与文字的表示方法两大类数据：符号数据：非数字符号的表示（字符、汉字、图形等）数值数据：数字数据的表示方式（定点、浮点）编码：用少量、简单的基本符号，选择合适的规则表示尽量多的信息，同时利于信息处理（速度、方便）ASCII、GB、UnicodeMP3、FLAC、JPG、H.264、H.265等二进制与易经系统的提出二进制观点的是德国的数学家和哲学家莱布尼茨据说他根据易经发明了二进制太极生两仪，两仪生四象，四象生八卦两仪：阴和阳2024/6/54易经八卦2024/6/552024/6/562.1.1数据格式计算机数据的表示方式，考虑几个因素：数的类型（小数、整数、实数、复数）数值范围数值精度存储、处理、传送的硬件代价软件兼容性72.1.1数据格式8十进制转二进制整数部分除2取余小数部分乘2取整52100.625*210.25*200.5*210.0除尽为止1011低高求得位数满足要求为止进制转换的简单运算方法－17/128的二进制表示?大数的转换方法，记住几个常用的2的幂925＝3226＝6427＝12828＝25629＝512210＝1024(1Kilo)211＝2048212＝4096213＝8182214＝16364215＝32728216＝65536220＝1Mega230＝1Giga(吉)240＝1Tera(太)更大的单位是多少？250＝1Peta260＝1Exa270＝1Zetta280＝1Yotta千、兆、吉、太、拍、艾、泽、尧分、厘、毫、微、纳进制转换的简单运算方法1015=24-1＝16-1=10000-1=111131=25-1＝32-1=100000-1=11111127=27-1＝128-1=10000000-1=111_1111255=28-1＝256-1=1111_11111023=210-1＝1024-1=11_1111_111165535=216-1＝65536-1=1111_1111_1111_1111几个简化运算的例子130=?=128+2=27+2=10000000+10=1000001065539=?=65536+3=216+3=1_0000_0000_0000_00112010=?=2047-37=2048-1-32-4-1=211-1-25-22-1=111_1111_1111-25-22-1=111_1101_1010111111110111＝?=212-1-817/128=10001/27=0.0010001-11-计算机中使用的计量单位12我国传统文化中的数量单位132.1.1数据格式计算机中数值数据表示格式：定点表示：小数点位置固定浮点表示：小数点位置不固定定点格式容许的数值范围有限（字长一定），硬件简单。浮点格式容许的数值范围很大，硬件复杂。2024/6/5141.定点数的表示方法约定数据的小数点位置固定小数点不使用记号”.”表示将数据表示成纯小数或纯整数定点数表示：带符号数不带符号数运算器利用寄存器存储数据寄存器中每个位称bit(BinaryDigit)最高有效位(MSB)、最低有效位(LSB)2024/6/5152024/6/5161.定点数的表示方法xnxn-1xn-2…x1x0数的表示范围:符号：0代表正号1代表负号量值小数点位于符号位之后，不需专门存放位置带符号定点纯小数2024/6/517定点纯整数xnxn-1xn-2…x1x0MSB为符号量值小数点固定于LSB之后例：字长8位X=+1010110.纯整数：X=01010110正数，符号位取0Y=-1101001.纯整数：Y=11101001（原码）负数，符号位取1X=+0.11011Y=-0.10101符号位取0纯小数：X=01101100符号位取1纯小数：X=11010100（原码）2024/6/5191.定点数的表示方法纯整数的表示范围(n+1位)1.定点数的表示方法受字长限制，表示数的范围有限;定点小数表示的精度有限目前计算机中采用定点数表示纯整数，因此将定点数表示的运算简称为整数运算。2024/6/5202.浮点数的表示方法2024/6/5212024/6/5222.浮点数的表示方法指数e基数R尾数M2.浮点数的表示方法一个浮点数由阶码和尾数及其符号位组成尾数M：用定点小数表示，表明有效数字的位数，决定了浮点数的表示精度阶码E：用定点整数表示，指明小数点的位置，决定了浮点数的表示范围2024/6/523IEEE754标准2024/6/524IEEE75432位单精度浮点数标准2024/6/525浮点数的规格化例：156.78=15.678×101=1.5678×102=0.15678×103=RE×M对于二进制数1011.1101=0.10111101×2+4=0.0010111101×2+6=1.0111101×2+3那么，计算机中究竟采用哪种数据形式？多种数据形式规格化表示法2024/6/527IEEE754标准规格化：同一真值浮点数具有唯一的表示形式规格化尾数应为如下形式：1.xxxxxxxxx整数位的1属于隐藏位，在实际存储时，尾数域只存储小数点后面的数值。规格化表示：当尾数不为0，尾数左移1位（小数点右移1位），同时阶码减1（左规）尾数右移1位（小数点左移1位），同时阶码加1（右规）IEEE754标准一个规格化的32位浮点数x的真值表示为x=(-1)S×(1.M)×2E-12764位的浮点数（双精度浮点数）符号位1位，阶码域11位，尾数域52位，指数偏移值是1023。规格化的64位浮点数x的真值为：x=(-1)S×(1.M)×2E-10232024/6/5282024/6/5292.浮点数的表示方法【例1】若浮点数x的754标准存储格式为(41360000)16，求其浮点数的十进制数值。解：将16进制数展开后，可得二制数格式为指数e=阶码-127=10000010-01111111=00000011=(3)10包括隐藏位1的尾数1.M=1.011_0110_0000_0000_0000_0000=1.011011于是x=(-1)S×1.M×2e=+(1.011011)×23=+1011.011=(11.375)102024/6/5302.浮点数的表示方法【例2】将数(20.59375)10转换成754标准的32位浮点数的二进制存储格式（16进制表示）。解:首先分别将整数和分数部分转换成二进制数：20.59375=10100.10011规格化，尾数右移4位10100.10011=1.010010011×24e=4，于是得到：S=0,E=4+127=131,M=010010011最后得到32位浮点数的二进制存储格式为：0100_0001_1010_0100_1100_0000_0000_0000=(41A4C000)16真值0的机器数（机器零）阶码E＝0，尾数M＝0正0：S＝0，负0：S＝1非规格化浮点数：阶码E＝0，尾数M≠0规格化浮点数：阶码E＝1～254（11111110）无穷大的机器数阶码E＝全1（11111111），尾数M＝0＋∞：S＝0，－∞：S＝1NaN（notanumber，不是一个数）阶码E＝全1（11111111），尾数M≠0用来通知异常情况IEEE754标准32位单精度浮点数单精度IEEE浮点数区间2024/6/5321≦E≦254E=255E=0M=0M≠0M=0M≠0规格化浮点数的范围正0或负0正/负无穷大NaN非规格化数2024/6/5332.浮点数的表示范围浮点数所表示的范围远比定点数大一般计算机中同时采用定点、浮点表示。单片机中多采用定点表示。IEEE754单精度在线转换https://www.h-schmidt.net/FloatConverter/IEEE754.html2024/6/5343.十进制数串的表示方法有时十进制数在计算机中需要以十进制的方式进行运算，需要对十进制进行编码二-十进制编码（BCD码）每个十进制符号由4位二进制数表示8421有权码名称表示每一位的位权（8、4、2、1）每位的数码与相应的位权相乘，再求和，得到它所代表的十进制数码74.56表示：01110100010101102024/6/5352024/6/512.1.2数的机器码表示一般书写表示的数，称为真值计算机中表示的数，称为机器数在计算机中，为了妥善的处理好符号位问题，主要是负数的运算问题，引入4种表示方法：原码、补码、反码、移码。1.原码表示法定点整数的原码形式为xnxn-1…x1x0字长8位：X＝+105，则[X]原＝01101001X＝-105，则[X]原＝10000000+1101001＝111010010使用原码有两种表达形式[+0]原=00000000[-0]原=100000002024/6/531.原码表示法特点：表示简单，易于同真值之间进行转换，实现乘除运算简单。进行减法运算麻烦。要比较绝对值的大小，然后绝对值大的数减去绝对值小数，最后给结果选择符号。为了解决这些矛盾，找到了补码表示法。2024/6/542.补码表示法2024/6/552.补码表示法2024/6/563.反码表示法定义：正数的反码表示与原码相同负数的反码符号位不变，数值位是将原码的数值位按位取反。电路很容易实现，触发器的输出正负两值。2024/6/573.反码表示法反码表示有正0和负0之分[+0]反=00000000[-0]反=11111111负整数补码：反码加1解决了求补码还要减法的问题[-105]补＝10010110＋1＝10010111负数求补负数原码“符号位不变，数值位取反加1”得对应补码负数补码再求补得到负数原码补码：11100000原码：1[1100000]求反＋1＝10011111+1＝101000002024/6/594.移码表示法传统定义和754标准浮点数阶码的定义不同2024/6/510移码和补码尾数相同，符号位相反[例8]设机器字长16位,定点表示,尾数15位,数符1位,问：定点原码整数表示时，最大正数是多少?最小负数是多少?[解:]定点原码整数表示最大正数值＝(215－1)10＝(＋32767)10最小负数值＝－(215－1)10＝(－32767)10数的机器码表示正数的原码、反码、补码等于真值，只有负数才分别有不同的表示方法采用补码，减法运算可以用加法运算实现，节省硬件，目前机器中广泛采用补码表示法有些机器用原码进行存储和传送，运算时改用补码移码表示法主要用于表示浮点数的阶码，可以直接比较大小。表示范围和补码相同，只有最高位相反同一代码的不同含义一个代码，采用不同编码，其数值不一样计算机内一个二进制数：10000001不同的含义无符号二进制数：1298421BCD码：81有符号整数的原码：-1有符号整数的反码：-126有符号整数的补码：-1272.1.3字符和字符串的表示方法非数值数据通常指的是字符、字符串、图形符号、汉字等数据必须按照一定的规则用一组二进制编码来表示ASCII美国国家标准局（ANSI）制定的ASCII（AmericanStandardCodeforInformationInterchange，美国信息交换标准码）是现今最为通用的单字节编码系统主要用于显示现代英文字母和符号1516ASCII码用7位二进制编码表示一个字符，总共可以表示128个字符计算机用一个字节来存放一个ASCII字符，最高位固定为02024/6/517IBMPC104键盘keyboard(Windows格式)182.1.4汉字的表示方法1.汉字的输入编码用西文标准键盘上对汉字进行编码：数字编码：是用数字串代表一个汉字的输入,如区位码等。最大优点是无重码,但难记.字音编码：以汉语拼音作为编码基础。简单易学,但重码很高,有微软拼音、智能ABC输入法等。字形编码法：将汉字的字形信息分解归类而给出的编码。具有重码少的优点。常用的有表五笔字型、郑码等。音形编码法：音形编码吸取了音码和形码的优点，使编码规则简化,重码少。常用的有全息码等。2.1.4汉字的表示方法2.汉字内码汉字内码是汉字的机内代码。一般采用两个字节表示。为了与ASCII区别，汉字内码中两个字节的MSB规定为“1”。汉字字符集编码查询https://www.qqxiuzi.cn/bianma/zifuji.php2024/6/5192024/6/520汉字内码1981年，国标码字符集GB2312每个编码2个字节，共收集常用简体汉字6763个1984年，BIG5字符集称大五码，共收录13053个中文字，港台地区使用1995年，GBK字符集共收录汉字21003个，支持繁体中文、日韩汉字2000年，GB18030字符集收录了27484个汉字，覆盖中、日、朝鲜语和中国少数民族文字向下兼容GBK、GB23122024/6/5212024年6月5日星期三22Unicode码容纳全世界所有语言中任意一种符号为每种语言中的每个字符设定惟一的二进制编码，以满足跨语言、跨平台进行文本转换、处理的要求UCS-22-byteUniversalCharacterSet，每个字符占用2个字节，实际使用比较多UCS-4每个字符占用4个字节，理论上可以表示231=2147483648个字符Unicode码为了解决Unicode的传输、存储问题，主要是网络传输，对Unicode进行二次编码UTF：UnicodeTransformationFormatUTF-8可变长格式对英文使用1个字节，中文使用3个字节来编码UTF-16拿2个字节来表示字符字符编码查询https://www.qqxiuzi.cn/bianma/zifuji.php2024/6/5232024/6/524Chrome浏览器中打开的web页面，点击右键，选择“查看网页源代码”华电主页www.ncepu.edu.cn的编码记事本编码区别？-25-2.1.4汉字的表示方法3.汉字输出码为了能显示和打印汉字，必须先存储汉字的字形，这就是汉字字形码两类字形码：点阵字形和矢量字形2024/6/5263.汉字输出码点阵字形又称字模码每个字由m×n个像素的位图表示，称m×n点阵点阵中的每个点都只有两种状态1表示有笔画，对应像素应置为字符颜色；0表示无笔画，对应像素应置为背景颜色或不改变272.1.4汉字的表示方法一个16点阵字形（左图），一行用2个字节描述，总供有16行，它的信息量是2*16=32个字节。一个48点阵字形用6个字节乘48行组成，它的信息量是6*48=288个字节。复原字形速度快，但缩放后的字形质量难以保证2.1.4汉字的表示方法矢量字形通过数学方程来描述包含了字形边界上的关键点、连线的导数信息等在显示、打印时，要经过一系列的数学运算输出结果字体可以无限放大而不产生变形目前主流的矢量字体格式有3种：Type1，TrueType和OpenType292.1.5校验码数据在存取和传送的过程中可能会发生错误产生错误的原因可能有很多种设备的临界工作状态外界高频干扰收发设备中的间歇性故障等为减少和避免错误提高硬件本身的可靠性对数据采用专门的逻辑电路进行编码，以检测错误，甚至校正错误302.1.5校验码方法在每个字上添加一些校验位，用来确定字中出现错误的位置计算机中常用的检错或纠错技术奇偶校验ParityCheckCRC循环冗余校验(CyclicRedundancyCheck)Hamming码，ECC校验2024/6/531若干位有效信息（如1个字节）加上1位校验位组成校验码奇校验：校验码中1的个数为奇数偶校验：校验码中1的个数为偶数奇偶校验码32奇校验码设8位信息码组为D7D6D5D4D3D2D1D0：若D7~D0中有奇数个“1”，则奇校验位=0奇校验位D奇=D7⊕D6⊕D5⊕D4⊕D3⊕D2⊕D1⊕D0读出数据时，将9位校验码送入校验电路G=D7⊕D6⊕D5⊕D4⊕D3⊕D2⊕D1⊕D0⊕D奇若G=0，则无错误若G=1，则传输出现错误3334【例10】已知下表中左面一栏有5个字节的数据。请分别用奇校验和偶校验进行编码,填在右面2栏。【解】假定最低一位为校验位，高8位为数据位，列表如下：校验位的值取0还是取1，是由数据位中1的个数决定的奇偶校验码奇偶校验码是一种最简单且应用广泛硬件成本很低可以检测出一位或奇数位错误，但不能确定出错位置，也不能检测出偶数位错误一位出错的概率比多位同时出错的概率要高得多常用于存储器读写检查或ASCII字符传送过程检查2024/6/5352024/6/512.2定点加法、减法运算2.2.1补码加法2.2.2补码减法2.2.3溢出概念与检测方法2.2.4基本的二进制加法/减法器2024/6/522.2.1补码加法2024/6/53[ｘ]补＋[ｙ]补＝[ｘ＋ｙ]补证明2024/6/54[ｘ]补＋[ｙ]补＝[ｘ＋ｙ]补证明(3)ｘ<0,ｙ>0,则ｘ＋ｙ>0或ｘ＋ｙ<0这种情况和第2种情况一样,把ｘ和ｙ的位置对调即得证。(4)ｘ<0,ｙ<0,则ｘ＋ｙ<0相加两数都是负数,则其和也一定是负数。∵[ｘ]补＝2n+1＋ｘ,[ｙ]补＝2n+1＋ｙ∴[ｘ]补＋[ｙ]补＝2n+1＋ｘ＋2n+1＋ｙ＝2n+1＋(2n+1＋ｘ＋ｙ)=[ｘ＋ｙ]补在模2n+1意义下,任意两数的补码之和等于该两数之和的补码。[例11]设字长5位,ｘ＝+1001,ｙ＝+0101,用补码求ｘ＋ｙ[解:][ｘ]补＝01001,[ｙ]补＝00101[ｘ]补01001＋[ｙ]补00101[ｘ＋ｙ]补01110所以ｘ＋ｙ＝＋1110[例11]设字长6位,ｘ＝+1001,ｙ＝+0101,用补码求ｘ＋ｙ[解:][ｘ]补＝001001,[ｙ]补＝000101[ｘ]补001001＋[ｙ]补000101[ｘ＋ｙ]补001110所以ｘ＋ｙ＝＋1110[例12]设字长5位,ｘ＝＋1011,ｙ＝－0101,用补码求ｘ＋ｙ。[解:][ｘ]补＝01011,[ｙ]补＝11011[ｘ]补01011＋[ｙ]补11011[ｘ＋ｙ]补100110所以ｘ＋ｙ＝+0110补码加法的特点，一是符号位要作为数的一部分参加运算二是符号位的进位要丢掉2024/6/582.2.2补码减法数用补码表示时，减法运算的公式为[ｘ－ｙ]补＝[ｘ]补－[ｙ]补＝[ｘ]补＋[-ｙ]补只要证明[－ｙ]补＝－[ｙ]补,上式即得证。现证明如下：∵[ｘ＋ｙ]补＝[ｘ]补＋[ｙ]补(模2n+1)∴[ｙ]补＝[ｘ＋ｙ]补－[ｘ]补(2.15)又∵[ｘ－ｙ]补＝[ｘ＋(－ｙ)]补＝[ｘ]补＋[－ｙ]补∴[－ｙ]补＝[ｘ－ｙ]补－[ｘ]补(2.16)将式(2.15)与(2.16)相加,得[－ｙ]补＋[ｙ]补＝[ｘ＋ｙ]补＋[ｘ－ｙ]补－[ｘ]补－[ｘ]补＝[ｘ＋ｙ＋ｘ－ｙ]补－[ｘ]补－[ｘ]补＝[ｘ＋ｘ]补－[ｘ]补－[ｘ]补＝0故[－ｙ]补＝－[ｙ]补(模2n+1)从[ｙ]补求[－ｙ]补的法则：对[ｙ]补包括符号位“按位求反且加1”，即可得到[－ｙ]补。写成运算表达式，则为其中符号﹁表示对[ｙ]补作包括符号位在内的求反操作[例13]设字长5位，已知ｘ1＝－1110,ｘ2＝＋1101,求：[ｘ1]补,[－ｘ1]补,[ｘ2]补,[－ｘ2]补。[解:][ｘ1]补＝10010[－ｘ1]补＝﹁[ｘ1]补＋1＝01101＋00001＝01110[ｘ2]补＝01101[－ｘ2]补＝﹁[ｘ2]补＋1＝10010＋00001＝10011[例14]设字长5位，ｘ＝＋1101,ｙ＝＋0110,求ｘ－ｙ。[解:][ｘ]补＝01101[ｙ]补＝00110[－ｙ]补＝11010[ｘ]补01101＋[－ｙ]补11010[ｘ－ｙ]补100111所以ｘ－ｙ＝＋0111[练习]设字长5位，ｘ＝-1001,ｙ＝-0110,求ｘ－ｙ。[解:][ｘ]补＝10111[ｙ]补＝11010[－ｙ]补＝00110[ｘ]补10111＋[－ｙ]补00110[ｘ－ｙ]补11101所以ｘ－ｙ＝-0011[例15]ｘ＝＋1011,ｙ＝＋1001,求ｘ＋ｙ。[解:][ｘ]补＝01011[ｙ]补＝01001[ｘ]补01011＋[ｙ]补01001[ｘ＋ｙ]补10100两个正数相加的结果成为负数,这显然是错误的。[例16]ｘ＝－1101,ｙ＝－1011,求ｘ＋ｙ。[解:][ｘ]补＝10011[ｙ]补＝10101[ｘ]补10011＋[ｙ]补10101[ｘ＋ｙ]补01000两个负数相加的结果成为正数,这同样是错误的。2.2.3溢出的概念与检测方法2024/6/5152.2.3溢出的概念与检测方法溢出的检测方法单符号位法和双符号位法双符号位法：用两个符号位表示一个数据，也称为“变形补码”两个符号位一样参与运算最高符号位产生的进位要丢弃2024/6/5162024/6/5172.2.3溢出的概念与检测方法用双符号位法检测溢出结果的两个符号位一致则没有溢出如果两个符号位不一致则发生溢出判断溢出的逻辑表达式为V=Sf1⊕Sf2,可以用异或门来实现2024/6/5182.2.3溢出的概念与检测方法二、检验举例：ｘ＝＋1100,ｙ＝＋1000,求ｘ＋ｙｘ＝－1100,ｙ＝－1000,求ｘ＋ｙ结果出现了01或10的情况就为溢出[例]设字长5位ｘ＝＋1100,ｙ＝＋1000,求ｘ+ｙ。[解:][ｘ]补＝001101[ｙ]补＝001000[ｘ]补001101＋[ｙ]补001000[ｘ+ｙ]补010101结果两个符号不同，表示溢出2024/6/5202.2.3溢出的概念与检测方法2、单符号位法其中Cf为符号位产生的进位,C0为最高有效位产生溢出检测V=Cf⊕C02.2.4基本的二进制加法/减法器2024/6/521[X]补＝XnXn-1………X0[Y]补＝YnYn-1…….…Y0+?n?n-1…….…?0多位加法运算依赖于各位逐位相加的运算，所以先讨论一位全加器2.2.4基本的二进制加法/减法器半加器两个二进制位相加2024/6/522Si＝Ai⊕BiCi+1＝AiBi全加器的真值表与表达式23Si＝Ai⊕Bi⊕CiCi＋1＝AiBi＋BiCi＋CiAi=AiBi＋(Ai⊕Bi)Ci输入:加数Ai、Bi、低位进位输入Ci输出:和Si，进位输出Ci+12024/6/524FA逻辑电路和框图FA（全加器）逻辑电路图延迟分析：设异或门延迟为3T，与非门延迟为T对一位全加器(FA)来说，Si的时间延迟为6T，Ci＋1的时间延迟为5T。FA框图4位补码加法器2024/6/525FAFAFAFAB0B1B2B3A0A1A2A3C0=0S0C1S1S2S3C2C3C4溢出符号位单符号法检测溢出只能完成补码加法加法器的改造2024/6/526FAFAFAFAA3MS0C1S1S2S3C2C3C4溢出符号位B3A2B2A1B1A0B0能完成补码加法和补码减法[ｘ]补＋[ｙ]补＝[ｘ＋ｙ]补[ｘ]补＋[-ｙ]补＝[ｘ-ｙ]补4位补码加法器2024/6/527进位依次从地位传递高位，称为行波进位当M＝0，加法[A]补＋[B]补运算；当M＝1，减法[A]补-[B]补转化成[A]补＋[－B]补运算，异或。4位补码加法器2024/6/528延迟分析：找出时延最长的路径B0->C1为3T+3T+2T=8TC1->C2为10TC2->C3为12TC3->C4为14T溢出为17T2024/6/529n位行波进位补码加法器总延迟：从C0到溢出产生的延迟为(2n+9)T8T(B0->C1)+2(n-1)T(C1->Cn)+3T(溢出)=(8+2n-2+3)T=(2n+9)T加法器是算术运算电路的核心所有算术运算都基于加法器实现加法器不区分符号数与无符号数2024/6/5302.3定点乘法运算采用软件实现乘法运算利用加法运算指令，编写实现乘法的循环子程序所需的硬件最少，但速度最慢采用硬件实现乘法运算串行乘法器被乘数每次和一位乘数相乘并行乘法器被乘数同时和乘数所有二进制位相乘硬件乘法器，需要乘法指令1硬件增加新的功能需要提供必要的指令2当前CPU支持的新指令2.3.1原码并行乘法31.人工算法步骤4设ｘ＝1101,ｙ＝10111101(ｘ)×1011(ｙ)110111010000＋110110001111(ｚ)1.人工算法步骤5设ｘ＝1101,ｙ＝10111101(ｘ)×1011(ｙ)110111010000＋110110001111(ｚ)求部分积：从乘数y的最低位开始逐位与被乘数相乘（与运算）根据权重移位：每个部分积根据乘数的权相应左移部分积相加：部分积统统加起来得到乘积z（z的位数扩大一倍）。1.人工算法步骤求部分积：从乘数y的最低位开始逐位与被乘数相乘（与运算）根据权重移位：每个部分积根据乘数的权相应左移部分积相加：将移位后的部分积统统加起来便得到最后乘积z（z的位数扩大一倍）。6计算机乘法的困难两大困难其一：两个n位数相乘，乘积为2n位。部分积、乘积如何存储?其二：只有两个操作数相加的加法器如何将n个部分积相加？设计高速并行乘法器的基本问题就在于缩短部分积的加法时间7a4a3a2a1a0两个5位的二进制无符号数相乘乘数a和被乘数b都为5位，乘积P为10位阵列乘法器b0b1b2b3b4×8a3b2a2b2a1b2a0b2a4b2a3b3a2b3a1b3a0b3a4b3a4b0a3b0a2b0a1b0a0b0a4b1a3b4a2b4a0b4a4b4a1b4两个5位的二进制无符号数相乘乘数a和被乘数b都为5位，乘积P为10位生成所有部分积9p1p0a3b2a2b2a1b2a0b2a4b2a3b3a2b3a1b3a0b3a4b3a4b0a3b0a2b0a1b0a0b0a4b1a3b4a2b4a0b4a4b4a1b4表示全加器斜线表示进位，竖线表示和10p2p1p0a3b2a2b2a1b2a0b2a4b2a3b3a2b3a1b3a0b3a4b3a4b0a3b0a2b0a1b0a0b0a4b1a3b4a2b4a0b4a4b4a1b4表示全加器斜线表示进位，竖线表示和11p2p1p0a3b2a2b2a1b2a0b2a4b2a3b3a2b3a1b3a0b3a4b3a4b0a3b0a2b0a1b0a0b0a4b1p3a3b4a2b4a0b4a4b4a1b4表示全加器斜线表示进位，竖线表示和12p2p1p0a3b2a2b2a1b2a0b2a4b2a3b3a2b3a1b3a0b3a4b3a4b0a3b0a2b0a1b0a0b0a4b1p3p4a3b4a2b4a0b4a4b4a1b4表示全加器斜线表示进位，竖线表示和13p2p1p0a3b2a2b2a1b2a0b2a4b2a3b3a2b3a1b3a0b3a4b3a4b0a3b0a2b0a1b0a0b0a4b1p3p4p5a3b4a2b4a0b4a4b4a1b4表示全加器斜线表示进位，竖线表示和014p2p1p0a3b2a2b2a1b2a0b2a4b2a3b3a2b3a1b3a0b3a4b3a4b0a3b0a2b0a1b0a0b0a4b1p6p3p4p5a3b4a2b4a0b4a4b4a1b4表示全加器斜线表示进位，竖线表示和015p2p1p0a3b2a2b2a1b2a0b2a4b2a3b3a2b3a1b3a0b3a4b3a4b0a3b0a2b0a1b0a0b0a4b1p6p7p3p4p5a3b4a2b4a0b4a4b4a1b4表示全加器斜线表示进位，竖线表示和016p8p2p1p0a3b2a2b2a1b2a0b2a4b2a3b3a2b3a1b3a0b3a4b3a4b0a3b0a2b0a1b0a0b0a4b1p6p7p3p4p5p9a3b4a2b4a0b4a4b4a1b4表示全加器斜线表示进位，竖线表示和017p8p2p1p0a3b2a2b2a1b2a0b2a4b2a3b3a2b3a1b3a0b3a4b3a4b0a3b0a2b0a1b0a0b0a4b1p6p7p3p4p5p90a3b4a2b4a0b4a4b4a1b44*5个全加器斜线表示进位，竖线表示和表示全加器进位保留加法器行波进位加法器18192、不带符号的阵列乘法器不带符号阵列乘法器逻辑图2、不带符号的阵列乘法器203、带符号的阵列乘法器对于补码表示的乘数和被乘数在使用阵列乘法器前，需先将补码转换为原码求补电路21E=1，求补E=0，直通输出求补电路223、带符号的阵列乘法器求补器与原码阵列乘法器结合组成带符号的阵列乘法器共使用三个求补器。两个算前求补器：将操作数A和B变成正整数。算后求补器：输出结果的补码。23243、带符号的阵列乘法器原码／补码2.4定点除法运算25260.1101商q2.4.1原码除法运算原理设被除数ｘ＝0.1001，除数ｙ＝0.1011，模仿十进制除法运算，以手算方法求ｘ÷ｙ的过程如下：10111001r0被除数小于除数，不够减，商0－1011被除数低位补零，够减除数,商1111r1得余数r1低位补零－1011够减除数,商111r2得余数r2低位补零1011不够减除数,商0110r3余数r3低位补零－1011够减除数,商11r4得余数r4270.1101商q2.4.1原码除法运算原理设被除数ｘ＝0.1001，除数ｙ＝0.1011，模仿十进制除法运算，以手算方法求ｘ÷ｙ的过程如下：00002.4.1原码除法运算原理二进制除法实质:“被除数（余数）减除数，求新余数”人工算法：求商时从高位向低位逐位求，商符单独处理每次上商都是由心算来比较余数和除数的大小，确定商1还是0每做一次减法，总是保持余数不动，低位补0，再减去右移后的除数。重复上一步骤，直到余数为0，或商的位数满足要求282.4.1原码除法运算原理292.4.1原码除法运算原理补充：编码的移位机器数为正时，不论左移或右移，添补代码均为0。负数原码在移位时符号位不变，其空位均添0。负数反码在移位时符号位不变，其空位均添1。负数补码在移位时，符号位不变，左移添0，右移添1.30补充：编码的移位实例：A=-26，用8位二进制表示，写出三种机器数左移一位、右移一位、左移两位和右移两位后的表示形式及其真值。101101001000110111101000100001101100101111110010100101111111100111001100111100111001100011111001-52-13-104-6-52-13-104-6-52-13-104-731[例23]ｘ＝0.101001,ｙ＝0.111,求ｘ÷ｙ。（恢复余数法计算）[解:][ｙ]补＝0.111[-ｙ]补＝1.001被除数ｘ0.101001减ｙ1.001余数为负1.110001＜0q4＝0不够减，恢复余数加ｙ0.1110.101001y右移1位减1.1001余数为正0.001101＞0q3＝1右移2位减1.11001余数为负1.111111＜0q2＝0不够减，恢复余数加ｙ0.001110.001101ｙ右移3位减1.111001余数为正0.000110＞0q1＝1故得商q＝q4.q3q2q1＝0.101322.4.1原码除法运算原理33恢复余数法34不恢复余数法（加减交替法）3536YN结束YNYN37382、不恢复余数的除法2024/6/512.5定点运算器的组成2.5.1逻辑运算2.5.2多功能算术/逻辑运算单元ALU2.5.3内部总线2.5.4定点运算器的基本结构2024/6/522.5.1逻辑运算计算机中的逻辑运算，主要是指逻辑非、逻辑加、逻辑乘、逻辑异或四种基本运算。非运算：按位反逻辑加：按位或逻辑乘：按位与异或运算：又称“按位加”移位运算左移n位等于乘2n右移n位等于除2n移位和加法结合，实现乘（除）运算有符号数的移位称算术移位空出位补0或1无符号数的移位称逻辑移位空出位补0移位运算-算术移位有符号数的移位叫算术移位机器数为正时，不论左移或右移，添补代码均为0。负数原码在移位时符号位不变，其空位均添0。负数反码在移位时符号位不变，其空位均添1。负数补码在移位时，符号位不变，左移添0，右移添1.补充：编码的移位实例：A=-26，用8位二进制表示，写出三种机器数左移一位、右移一位、左移两位和右移两位后的表示形式及其真值。101101001000110111101000100001101100101111110010100101111111100111001100111100111001100011111001-52-13-104-6-52-13-104-6-52-13-104-72024/6/562.5.2多功能算术/逻辑运算单元ALU由全加器构成的加法器，可以实现补码的加法/减法运算。问题：由于串行进位它的运算时间很长不能完成逻辑运算以加法器为核心的算术/逻辑运算单元(ALU-ArithmeticLogicUnit)具有算术和逻辑运算的功能先行进位逻辑，能实现高速加法运算2024/6/572.5.2多功能算术/逻辑运算单元ALU改变FA的输入端Ai和Bi来实现算术运算和逻辑运算功能。一位全加器FA将Ai和Bi输入一个函数发生器得到输出Xi和Yi，作为一位全加器的输入。2024/6/581位ALU的逻辑图与逻辑表达式控制参数2024/6/592.5.2多功能算术/逻辑运算单元ALU可以处理16种算术\逻辑运算，每种运算只针对1位二进制102.5.2多功能算术/逻辑运算单元ALU进一步化简得到下式代入全加器的求和与进位表达式，可得如下逻辑表达式2.5.2多功能算术/逻辑运算单元ALU2024/6/5112.5.2多功能算术/逻辑运算单元ALU2024/6/5122024/6/5132.5.2多功能算术/逻辑运算单元ALU4位ALU:4个1位ALU串行连接能进行4位算术和逻辑运算进位信号太慢2024/6/5142.5.2多功能算术/逻辑运算单元ALU串行进位，速度慢Cn＋1Cn＋2Cn＋3Cn＋415对串行进位的改进串行改并行先行进位（CLA-CarryLookAhead）2.5.2多功能算术/逻辑运算单元ALUCn＋4＝Y3＋Y2X3＋Y1X2X3＋Y0X1X2X3＋X0X1X2X3Cn令G＝Y3＋Y2X3＋Y1X2X3＋Y0X1X2X3P＝X0X1X2X3G(Generation)为进位发生函数P(Propagation)为进位传递函数增加P和G的目的在于实现多片ALU之间的先行进位Cn＋4＝G＋PCn16逻辑电路图2024/6/517G＝Y3＋Y2X3＋Y1X2X3＋Y0X1X2X3P＝X0X1X2X32024/6/518741814位ALU逻辑图函数发生器先行进位运算方式控制A=B？2024/6/51974181功能202.5.2多功能算术/逻辑运算单元ALU4片74181组成16位ALU片内先行进位，片间串行进位212.5.2多功能算术/逻辑运算单元ALU4片74181组成16位ALUC4=G0+P0C0C8=G1+P1C4C12=G2+P2C8C16=G3+P3C12Cn＋ｘ＝G0＋P0CnCn＋ｙ＝G1＋P1Cn＋ｘ＝G1＋G0P1＋P0P1CnCn＋ｚ＝G2＋P2Cn＋ｙ＝G2＋G1P2＋G0P1P2＋P0P1P2CnCn＋4＝G3＋P3Cn＋ｚ＝G3＋G2P3＋G1P1P2＋G0P1P2P3＋P0P1P2P3Cn＝G*＋P*CnP*＝P0P1P2P3G*＝G3＋G2P3＋G1P1P2＋G0P1P2P3根据以上表达式实现的部件称为74182（组间先行进位产生器），与4个74181配合使用74182的逻辑电路图232024/6/52416位先行进位ALU片内先行进位，片间先行进位2024/6/52532位ALU2片741828片7418164位先行进位系统16片74181，5片74182芯片组成多级先行进位2.5.3内部总线将计算机各个部件之间的数据传送通路加以归并，组成总线结构任何一个时刻，总线上只能有一个来源的数据，数据源独占总线不同来源的信息在总线上分时传送只要数据源不撤销数据，该数据在总线上一直存在根据所在位置分类：内部总线：CPU内各部件的连线外部总线：CPU与存储器、I/O系统之间的连线2024/6/5272.5.3内部总线按总线的逻辑结构分：单向总线：信息只能向一个方向传送。传送地址信息或控制信息的总线双向总线：信息可以两个方向传送数据总线既可以发送数据，也可以接收数据。总线的基本电路是三态门逻辑1、逻辑0、高阻2024/6/528292.5.4定点运算器的基本结构基本组成包括：ALU：核心部件乘除法器，组合逻辑电路数据存储部件：存放参与计算的数据及运算结果暂存器：只对硬件设计者可见通用寄存器：可以被软件设计者所访问内部总线：连接各个部件的通道302.5.4定点运算器的基本结构一个二元运算需要两个操作数，产生一个结果操作数op操作数=操作结果按照数据从存储部件传输到ALU的方式将ALU分为三种结构单总线，双总线，三总线1、单总线结构的运算器两个操作数要分两次输入到ALU需要A、B两个暂存器临时保存操作数操作速度慢、控制简单2024/6/531一次运算要三步完成：通用寄存器->A通用寄存器->BA+B,ALU->通用寄存器2、双总线结构的运算器两个操作数通过两条总线同时输入到ALU进行运算ALU的输出经过缓冲器送入通用寄存器因为ALU的输入数据没有暂存器，计算过程中，两条总线都被输入数据占据，必须在ALU输出端设置缓冲器。2024/6/532一次运算要两步完成：通用寄存器->总线1，通用寄存器->总线2，总线1+总线2>缓冲器缓冲器->通用寄存器3、三总线结构的运算器总线旁路器：总线之间的数据传送一次运算一步完成：通用寄存器->总线1，通用寄存器->总线2，总线1+总线2>总线3，总线3->通用寄存器速度快，硬件复杂，成本高33Intel8086运算器结构34通用寄存器暂存器标志寄存器16位ALU单总线结构ARM的ALU35三总线结构通用寄存器Intelpentuim的ALU36三总线结构通用寄存器CPU和GPU37GPU中有海量的ALU，因而其计算能力很强大GPU的ALU38GTX1080的核心GP104每个SM有128个CUDA内核（绿色方块）CUDA内部392024/6/512.6浮点运算方法和浮点运算器2.6.1浮点加法、减法运算2.6.2浮点乘法、除法运算2.6.3浮点运算流水线2.6.4浮点运算器实例2.6.1浮点加法、减法运算22024/6/532.6.1浮点加法、减法运算浮点加减运算步骤如下：1.0操作数检查；2.比较阶码大小并完成对阶；3.尾数求和/差运算；4.结果规格化5.舍入处理6.溢出处理2024/6/542.6.1浮点加法、减法运算0操作数检查能否简化操作、节省运算时间比较阶码大小并完成对阶对阶：使得小数部分可以按位权值相加变为定点数定点加法器运算小数点位置是否对齐对阶:小阶向大阶看齐2.6.1浮点加法、减法运算两个浮点数相加：1.11011×231.11011×25浮点格式中，尾数为定点小数如果向小阶对齐，尾数左移易导致高位数据丢失如果向大阶对齐，尾数右移丢失的是低位数据52024/6/562.6.1浮点加法、减法运算2024/6/572.6.1浮点加法、减法运算2024/6/58IEEE754的四种舍入方法就近舍入：类似于四舍五入，多余位：最低有效位之后的若干位，用于舍入判断多余位中间值位：100…0多余位比100…0大，进位；比100…0小，舍去对于100……0的情况：有效位末尾是1：进1有效位末尾是0：舍弃例：保留有效位到0.0010.10111-0.001010.11110-0.01010IEEE754的四种舍入方法朝0舍入：截尾保留有效位到0.001：0.10111-0.001010.11110-0.0101092024/6/510IEEE754的四种舍入方法IEEE754的四种舍入方法11M＝10011001100110011001100110011例题：真值0.2，求32位单精度浮点数②移动小数点，使其在第1、2位之间S＝0e＝-3，E＝-3+127＝124＝01111100③得到32位浮点数的二进制存储格式为：00111110010011001100110011001101＝(3E4CCCCD)1623位就近舍入2024/6/5132.6.1浮点加法、减法运算真值0的机器数（机器零）阶码E＝0，尾数M＝0正0：S＝0，负0：S＝1非规格化浮点数：阶码E＝0，尾数M≠0规格化浮点数：阶码E＝1～254（11111110）无穷大的机器数阶码E＝全1（11111111），尾数M＝0＋∞：S＝0，－∞：S＝1NaN（notanumber，不是一个数）阶码E＝全1（11111111），尾数M≠0用来通知异常情况IEEE754标准32位单精度浮点数2024/6/5152.6.1浮点加法、减法运算2.6.2浮点乘法、除法运算222.6.2浮点乘法、除法运算232.浮点乘、除法运算步骤浮点数的乘除运算大体分为六步：①0操作数检查；②阶码加/减操作；③尾数乘/除操作；④结果规格化；⑤舍入处理；⑥确定积的符号；2.6.2浮点乘法、除法运算(1)浮点数的阶码运算乘法：两阶码求和，减偏移量除法：两阶码求差，加偏移量(2)尾数处理规格化与舍入与浮点加减法相同24现代处理中的浮点运算单元浮点运算单元FPU，floating-pointUnit27华为海思麒麟9904个ALU、2个FPUARMA77中的FPU28RISC-V中的FPU用于物联网的一种处理器架构平头哥玄铁9103个ALU、1个FPU29龙芯3A400030FP32浮点性能比较31以CNN为例，用于输入图像大小为224×224的分类任务的典型CNN模型需要高达390亿次(39G)FLOP和500MB以上的模型参数。第二章小结一个定点有符号数由符号位和数值域两部分组成。按小数点位置不同，定点数有纯小数和纯整数两种表示方法。按IEEE754标准，一个单精度浮点数由符号位S、阶码E、尾数M三个域组成。阶码E等于指数的真值e加上固定偏移值12732第二章小结数的真值变成机器码时四种表示方法：原码，反码、补码和移码移码主要用于表示浮点数的阶码字符信息属于符号数据，国际上采用的字符系统是7位的ASCII码。汉字有输入码、汉字内码和输出码三种不同用途的编码。为运算器构造的简单性，运算方法中算术运算通常采用补码加、减法，原码乘除法。33第2章教学要求-1掌握定点整数（有符号数和无符号数）的表示范围掌握IEEE754单精度浮点格式的表示，规格化，与真值的相互转换理解真值和机器数，掌握定点整数的补码、反码、原码，理解移码表示法了解汉字输入编码、机内码、输出码理解检验码的作用，掌握奇偶校验第2章教学要求-2掌握补码加减法运算掌握溢出的概念及检测方法理解运算器的三种组成方式掌握浮点加减法运算步骤理解IEEE754标准的4种舍入处理方法，掌握就近舍入C语言数据表示非数值数据char(8位)数值数据定点整数signed/unsignedchar(8位)/short（16位）/int（32位）/long（64位）浮点数Float（32位）/double（64位）-1-C语言中的整数（定点数）无符号整数unsignedchar/unsignedshort/unsignedint一般用于地址运算有符号整数char/short/int/long采用补码表示无符号整数/带符号整数的最大值8位无符号整数最大是255（11111111）8位带符号整数最大为+127（01111111）-2-编程实践在线编程网站https://c.runoob.com/compile/9c、c++、python等https://gcc.godbolt.org/离线python：anacondac：ubuntu、gcc数据的真值、机器码、存储值间的关系3C语言中的机器码？ex2_1.c-4-intmain(){chara=127,b=128,c=129,d=257;printf("%d\n",a);printf("%d\n",b);printf("%d\n",c);printf("%d\n",d);}127-127-128？？？？无符号数赋值补码真值输出变量a,b,c,d机器码实际存储值是多少？1变量的内存值ex2_2.c-5-main(){chara=127,b=128,c=129,d=257;printf("a=%d=%X\n",a,a);printf("b=%d=%X\n",b,b);printf("c=%d=%X\n",c,c);printf("d=%d=%X\n",d,d);}a=127=7Fb=-128=FFFFFF80c=-127=FFFFFF81d=1=1补码输出机器码输出32位补码表示范围[-231，231-1]-6-00000000000000000000000000000000two=01000000000000000000000000000000001two=+11000000000000000000000000000000010two=+210...01111111111111111111111111111110two=+2,147,483,646ten01111111111111111111111111111111two=+2,147,483,647ten10000000000000000000000000000000two=–2,147,483,648ten10000000000000000000000000000001two=–2,147,483,647ten10000000000000000000000000000010two=–2,147,483,646ten...11111111111111111111111111111101two=–3ten11111111111111111111111111111110two=–2ten11111111111111111111111111111111two=–1ten程序ex2_3.c-7-main(){intx=-1;unsignedu=2147483648;printf("x=%u=%X=%d\n",x,x,x);printf("u=%u=%X=%d\n",u,u,u);}机器码输出真值赋值x=4294967295=FFFFFFFF=-1u=2147483648=80000000=-2147483648无符号数输出一个奇怪的程序ex2_4.c8main(){doublea,b,c;intd;b=3.3;c=1.1;a=b/c;d=b/c;printf("%f,%d\n",a,d);if(3.0!=a)printf("Really?3.0!=a\n");}3.000000,2??????????Really?3.0!=a二进制存储浮点数不是精确数浮点转整数只保留浮点数的整数部分Double3.3/1.1ex2_5.cmain(){doublea,b,c;b=3.3;c=1.1;a=b/c;printf("a=%.60f\n",a);printf("b=%.60f\n",b);printf("c=%.60f\n",c);printf("a=%f,n",a);}-9-a=2.999999999999999555910790149937383830547332763671875000000000b=3.299999999999999822364316059974953532218933105468750000000000c=1.100000000000000088817841970012523233890533447265625000000000a=3.000000一个奇怪的程序ex2_6.c10main(){floata,b,c;intd;b=3.3;c=1.1;a=b/c;d=b/c;printf("%f,%d\n",a,d);if(3.0!=a)printf("Yeah!\n");}3.000000,3Float3.3/1.1ex2_7.cmain(){floata,b,c;b=3.3;c=1.1;a=b/c;printf("=%.60f\n",a);printf("b=%.60f\n",b);printf("c=%.60f\n",c);}-11-a=3.000000000000000000000000000000000000000000000000000000000000b=3.299999952316284179687500000000000000000000000000000000000000c=1.100000023841857910156250000000000000000000000000000000000000a=3.000000舍入的影响例题假定变量i、f和d的数据类型分别为int、float和double（int用补码表示，float和double分别用IEEE754单精度和双精度浮点数格式表示），已知i=785，f=1.5678e3，d=1.5e100。若在32位机器中执行下列关系表达式，则结果为“真”的是I．i==(int)(float)iII．f==(float)(int)fIII．f==(float)(double)fIV．(d+f)-d==fA．仅I和IIB．仅I和IIIC．仅II和IIID．仅III和IV解答float到double的转换完全相等double到float转换可能会发生舍入float/double到int，小数部分会丢弃int到float，当int有效数字超过24位，转换时需要舍入int到double，double尾数53位，能精确表示int型13I．i==(int)(float)ifloat是单精度，尾数24位int型有效数字有31位i=785,能实现精确转换，条件成立若i=16777217=224-114II．f==(float)(int)ff=1.5678e3浮点转换整数，只保留整数部分，小数部分舍去条件不成立15III．f==(float)(double)f双精度尾数53位f=1.5678e3,单精度float转double有效数字不变,条件成立若doublef=1.5678e3f==(double)(float)f则不成立16IV．(d+f)-d==f浮点运算不满足交换律、结合律(d+f)-d不等于(d-d)+f(d+f)-d不等于d+(f-d)C语言中单双精度混合运算，都按照双精度处理大数吃小数，两个差别巨大的浮点数相加，较小的数由于有效数字位数不够，会被舍去17浮点处理精度造成的事故1990年2月25日，海湾战争期间，在沙特的爱国者导弹防御系统未能拦截一枚伊拉克飞毛腿导弹，造成28名美军死亡。原因是浮点数舍入误差导致爱国者反导系统的计算机精度仅有24位，存在0.0001%的计时误差，所以有效时间阙值是20个小时。当系统运行100个小时以后，已经积累了0.3422秒的误差。这个误差导致导弹系统不能正确地瞄准目标。浮点处理精度造成的事故19失之毫厘，谬以千里浮点处理精度问题解决办法制度：每隔二十小时重启一次硬件：修改24位为32位或64位软件：升级软件20其他案例1996年6月4日，在阿丽亚娜五号运载火箭发射后37秒，偏离预定轨道炸毁。原因是软件系统将64位浮点数转换为16位浮点数，造成计算错误。温哥华证券交易所在1982年推出一项股票指数，指数的值是1000.000。后来，重新计算时多次运用舍入到小数点后三位的操作。22个月以后，指数的值是524.881，然而事实上应该是1009.81121浮点处理精度问题树立计算机系统的思想，理解软硬件的相互影响小概率事件常会导致大损失，在工程实践中要精益求精221第三章多层次存储器3.1存储器概述3.2SRAM存储器3.3DRAM存储器3.4只读存储器和闪速存储器3.5并行存储器3.6Cache存储器3.7虚拟存储器3.8奔腾系列机的虚存组织3.1存储器概述存储器是计算机系统中的记忆设备，用来存放程序和数据存储器中最小的存储单位叫存储元，可存储1bit若干个存储元组成一个存储单元许多存储单元组成一个存储器23.1.1存储器的分类按存储介质满足两个基本要求：有两个明显区别的状态，分别表示0和1两个状态的改变速度要快，影响存储器的读写速度半导体存储器：内存，闪存速度快、容量小，成本高磁表面存储器：磁带、磁盘容量大，速度慢、成本低光盘存储器：DVD、蓝光容量大，速度慢，成本低按存取方式随机存储器RAM（RandomAccessMemory）任何存储单元的内容都能被随机存取，且存取时间和存储单元的物理位置无关内存顺序存储器按顺序存取，存取时间和存储单元的物理位置有关磁带、磁盘33.1.1存储器的分类按信息掉电易失性非易失性存储器Non-VolatileMemory断电后仍能保存信息磁表面存储器、光盘存储器、闪存易失性存储器VolatileMemory断电后信息立即消失内存(SRAM、DRAM)半导体存储器按其存储内容可变性只读存储器(ROM-ReadOnlyMemory)存储的内容一般是固定不变的，只能读出而不能写入随机读写存储器(RAM)：既能读出又能写入43.1.1存储器的分类按在计算机系统中的作用主存储器：和CPU直接交换信息辅助存储器：主存的后援存储器高速缓冲存储器Cache：用于两个速度不同的部件之间，起到缓冲作用控制存储器等53.1.2存储器的层次结构CPU对存储器的要求容量大、速度快、价格低（每位价格）目前技术下，存储器的特点是：速度快的存储器价格贵，容量小；价格低的存储器速度慢，容量大不可能三角:既要。。。又要。。。。还要。。。。从在容量，速度和价格作折中考虑，建立存储器层次结构6存储系统层次结构存储速度访问频率单位成本存储容量外存/辅存内存-7-83.1.2存储器分级结构三级存储系统3.1.3存储器的编址和端模式存放一个字节的单元称为字节存储单元，其地址称为字节地址一个字由多个字节组成，存放一个字的单元称为字存储单元，其地址称为字地址存储器编址编址的最小单位是字单元，称为按字编址编址的最小单位是字节单元，称为按字节编址既可以按字编址，也可以按字节编址存储器访问按地址访问：按字节地址访问、按字地址访问。9字的概念字：wordawordisthenaturalunitofdatausedbyaparticularprocessordesign.一串固定长度的二进制数，对应部件处理数据的固定长度。不同的部件其字长不同计算机字长、机器字长、运算器字长存储器字长、存储芯片字长指令字长10存储器的编址11字节地址机器字长32位16个字节存储单元组成存储器按字节编址存储器的编址12机器字长32位16个字节存储单元组成存储器按字编址存储器的编址13字节地址机器字长32位，16个字节存储单元字节编址下按字访问存储该字的第一个字节的字节单元地址为该字的字地址存储器的编址14字节地址机器字长16位，16个字节存储单元存储器的编址设有一个1MB容量的存储器，字长32位，问：按字节编址，按字编址各自的寻址范围?按字节编址：20位字节地址，0x0~0xFFFFF按字编址：18位字地址，0x0~0x3FFFF15数据的存储和排列顺序上世纪80年代开始，几乎所有计算机都以字节编址存储系统和指令设计时要考虑的问题（按字节编址，按字访问）：一个字如何在字节单元存放？-字的存放顺序问题(端模式\字节序\端序\尾序)字地址与字节地址关系-字的边界对齐问题存储器的端模式：存储字为多个字节时，在存储器中存放顺序大端(big-endian)：大尾端优先存储，高字节在低地址MIPS，IBM360/370,Sparc,网络传输小端(little-endian)：小尾端优先存储，低字节在低地址。X86(高高低低)ARM的端模式可通过寄存器改变-16-3F27LSBMSBA831D0D313F27LSBMSBA831D0D31数据在内存中的存放顺序将0x12345678写入到以0x0000开始的内存中-19-内存地址对齐20内存按字节编址16位访问对齐32位访问对齐字节编址下的按字访问：以一个字中最低字节的字节地址作为该字的字地址对齐：字地址能被字节数整除。字长为16位，包含2个字节，其字地址能被2整除，地址最低位为0；字长为32位，包含4个字节，其字地址能被4整除，最低两位为0.Alignment(对齐)-21-如：inti,shortk,doublex,charc,shortj,……则：&i=0;&k=4;&x=8;&c=16;&j=18;……x：2个周期j：1个周期目前来看，浪费一点存储空间没有关系！则：&i=0;&k=4;&x=6;&c=14;&j=15;……x：3个周期j：2个周期存储器按字节编址，CPU按字对齐访问，字长32位变量地址没有对齐变量地址对齐虽节省了空间，但增加了访存次数！22#include<stdio.h>//内存对齐测试intmemory_display(longunsignedintaddr)//以16进制输出addr开始的16个内存字节单元{inti,j;for(i=0;i<4;i++){printf("0x%lX:\t",addr+i*4);for(j=0;j<4;j++){printf("0x%X\t",*(unsignedchar*)(addr+i*4+j));}printf("\n");}return0;}intmain(){inti=13457;shortj=345;charc='A';intk=123;printf("i=0x%X\n",i);printf("j=0x%X\n",j);printf("c=0x%X\n",c);printf("k=0x%X\n",k);printf("intImemoryaddressis0x%lX\n",(longunsignedint)&i);printf("shortjmemoryaddressis0x%lX\n",(longunsignedint)&j);printf("charcmemoryaddressis0x%lX\n",(longunsignedint)&c);printf("intkmemoryaddressis0x%lX\n",(longunsignedint)&k);memory_display((longunsignedint)&i-16);memory_display((longunsignedint)&i);}23内存对齐是一种软硬件协同提高性能的一种方式3.1.4主存储器的技术指标3.2SRAM存储器内部存储器是半导体存储器根据信息存储的机理不同可以分为两类：静态读写存储器(SRAM-Static)：速度快、成本高、容量小、功耗低，一般用作Cache动态读写存储器(DRAM-Dynamic)：容量大、成本低、速度慢、功耗高、用作主存25263.2.1基本的静态存储元阵列存储位元SRAM的存储位元是由两个MOS反相器交叉耦合而成的触发器，一个存储位元存储一位二进制代码六管SRAM存储元的电路结构示意图3.2.1基本的静态存储元阵列三组信号线地址线字数数据线字长控制线27单译码结构：1个译码器N位地址，寻址2n个存储单元存储元阵列又称存储芯片63芯片容量=字数X字长=存储单元数量X存储单元字长3.2.2基本的SRAM逻辑结构大容量SRAM芯片采用双译码方式：将地址分成行、列两部分，降低译码电路的规模CS：ChipSelect片选3.2.3读/写周期波形图先给地址，再给片选和读信号3.2.3读/写周期波形图先给地址，再给片选和是写信号3.3.1DRAM存储位元的记忆原理DRAM存储器的存储位元是由一个MOS晶体管和电容器组成的记忆电路31电容用于存储电荷，有电荷代表1，否则代表0MOS管电容器读放读出1是破坏性读出由于(c)中读出1是破坏性读出，必须恢复存储位元中原存的1输入缓冲器关闭，刷新缓冲器打开，输出缓冲器读放打开，DOUT=1经刷新缓冲器送到位线上，再经MOS管写到电容上3.2.2DRAM芯片的逻辑结构两个电源Vcc两个地线脚一个空管教NC11个地址线A0~A114个数据线D1~D436方法：复用地址线A0-A9存储器需要地址20位，但芯片物理地址引脚只有11位，如何处理？1M×4位DRAM芯片的管脚图373.2.2DRAM芯片的逻辑结构与SRAM芯片不同之处增加了行地址锁存器和列地址锁存器增加了刷新控制电路DRAM读出后必须刷新，而未读写的存储元也要定期刷新（电容自放电），按行刷新，刷新计数器的长度等于行地址锁存器刷新操作与读/写操作交替进行通过2选1开关来选择刷新行地址或正常读/写的行地址383.3.3读/写周期、刷新周期39先给行地址和行选通，再给列地址和列选通403.3.3读/写周期、刷新周期3.3.3刷新周期刷新：DRAM存储元基于电容器上的电荷存储信息，电荷量随着时间和温度而减少，因此必须定期地刷新，以保持原来记忆的正确信息刷新过程：将原有信息读出，再由刷新放大器形成原信息并重新写入的过程刷新按行进行刷新周期：从上次对整个存储器刷新结束到下次对整个存储器全部刷新一遍为止的时间间隔称为刷新周期集中式刷新分散式刷新41集中刷新方式例:1024行,工作周期=500ns,刷新周期=8ms8ms内集中安排所有刷新周期总工作周期数=8ms/500ns=16000个用在实时要求不高的场合集中式刷新：DRAM的所有行在每一个刷新周期中都被刷新刷新期间停止正常读写分散刷新方式各刷新周期分散安排在8ms内每隔一段时间刷新一行每隔15.5微秒提一次刷新请求，刷新一行；8毫秒内刷新完所有行用在大多数计算机中8ms1024行≈7.8微秒=7800ns主存储器特点由半导体存储器组成存储单元：字存储单元，字节存储单元编址：按字节编址按地址进行访问：字节地址访问字，访问字节属于随机访问存储器RAMDRAM需要刷新-44-3.3.5高级的DRAM结构FPMDRAM：快速页模式动态存储器SDRAM同步动态存储器读写操作与CPU时钟同步,猝发式读取：输入一个行地址，一个列地址，连续读出后续几个列地址数据45输入一个行地址，连续输入多个列地址，该行中的对应列的存储单元数据就连续输出DDRSDRAMDDR：DoubleDateRateDDR在相同时钟频率下的数据传输速率比SDRAM提高一倍上下沿都传输数据DDR2、DDR3：时钟频率比上一代提高一倍，速率提高一倍46DDRSDRAM47全球DRAM产业三星技术最先进，产量最大2021年10月开始大规模生产基于EUV的14nmDDR54849中国DRAM产业发展1975年，中国第一块1KDRAM诞生，但总体技术力量薄弱，和国外差距比较大，没有竞争力。21世纪后，通过政府扶持、自主研发、技术引进、收购等方式逐步建立起国产DRAM产业。2015年的紫光收购德国奇梦达、收购美国ISSI。目前，国产DRAM市场的主要厂家紫光国芯、福建晋华、合肥长鑫、长江存储等。2019年9月，合肥长鑫宣布正式量产DDR42023年预计将试产17nmDDR5,产能大约能占到全球内存产能的3%，目前最被看好50困难和阻力全球半导体需求将近1/3来自中国2016年开始，美光开始对福建晋华发起诉讼2018年10月30日，美国商务部将福建晋华添加进实体清单，导致整个企业进度不理想2017年，美光曾对从台湾华亚科跳槽到合肥长鑫的上百名员工发存证信函51砥砺前行从DRAM内存的角度来说，中国企业在技术、产业链方面，距离全球顶尖的厂商都有较大的差距，产品自给率方面更是不容乐观。我们需要进一步加大企业自主创新+国家意志支持的力度，坚定IDM的发展模式，进行产业全链路的布局，高度重视技术、专利的原创性，避开巨头们的干扰、阻挠。只有做到这些，才能在机遇和风险并存的产业环境中不断前行，实现我们在半导体产业独立自主的目标。5213.4只读存储器3.4.1只读存储器概述3.4.2Flash存储器3.4.3存储器容量扩展23.4.1只读存储器概述只读存储器ROM：Read-OnlyMemory在正常工作状态下只能读取数据，不能写入数据掉电不易失ROM和RAM都属于内部存储器，属于同一个内存空间用于保存计算机运行所需的最基础、最核心的程序。BIOS：基本输入输出系统引导程序等8086内存空间3总容量1MBRAMROMRAMROM43.4.1只读存储器概述ROM中写数据称为编程(program)，包括擦除和写入根据是否可编程，分为：掩模ROM：制造中写入信息，用户无法更改可编程ROM：用户可写入内容PROM：可编程一次EPROM和E2PROM：可多次编程EPROM：紫外线擦除，专用设备写入E2PROM：电擦除，联机写入EPROM-ErasePROM紫外线擦除，编程器写入EPROM上方有一个石英窗口。将芯片置于紫外灯下，以擦除其中的内容，相当于存储器又存了全“1”。然后用专用的设备将信息重新写入6E2PROME2PROM为ElectricErasePROM电擦除，擦除时间较快联机写入无需把器件从电路板取下E2PROM允许改写上千次，编程大约需20ms，数据可存储20年以上73.4.2Flash存储器在E2PROM基础上发展而来高密度、非失易失性有很高的读取速度，易于擦除和重写，功耗小FLASH存储器的逻辑结构8(重点)存储器容量扩充一、存储芯片简介二、存储器容量扩展的三种方法位扩展字扩展字位扩展一、背景知识——存储芯片简介存储芯片的引脚芯片容量：字数×字长(存储单元数量×存储单元的位数)9二、存储器容量扩展的三种方法1、位扩展给定芯片的字长较短，不满足存储器字长要求，要用多片来扩展字长2、字扩展给定的芯片字数少，用多片给来扩展字数3、字位扩展从字长和字数两个方向扩展101、位扩展111、位扩展12存储器一个存储单元分为高4位和低4位分别位于两个芯片中两个芯片并行工作1、位扩展总容量=210×8位131、位扩展142、字扩展152、字扩展162、字扩展分析地址：存储器地址线A10~A0A10用于选择芯片A9~A0用于选择芯片内的某一存储单元172、字扩展182、字扩展192、字扩展203、字位扩展需扩展的存储器容量为M×N位,已有芯片的容量为L×K位(L<M,K<N)21用M/L组芯片进行字扩展每组内有N/K个芯片进行位扩展222324每4片一组进行位扩展258组进行字扩展26存器容量与地址范围的关系高3位通过3：8译码器产生每组的片选信号278组进行字扩展28字位扩展一起画29例：设CPU有16根地址线，8根数据线，并用MREQ#作访存控制信号，用R/W#作读/写控制信号。现有下列存储芯片：SRAM：1K×4、4K×8、8K×8；ROM：2K×8、4K×8、8K×8；及3：8译码器和各种门电路主存的地址空间满足下述条件：最小8KB地址为系统程序区(ROM区)，与其相邻的16KB地址为用户程序区(RAM区)，最大4KB地址空间为系统程序区(ROM区)。请画出CPU与存储器的连接图。三、主存储器与CPU的连接确定各区域地址范围；根据存储器容量，确定存储芯片的数目和扩展方法；分配地址线地址线低位直接连接存储芯片的地址线；高位地址线参与形成存储芯片的片选信号；连接数据线、读写控制等其他信号线MREQ#可用作地址译码器的使能信号3031解：1）根据题目的地址范围写出相应的二进制地址码。存器容量与地址范围的关系32333.5并行存储器加速CPU与存储器之间的数据传输的方式：采用更高速性能的存储器，加大字长采用并行操作的双端口存储器在CPU和主存之间使用高速缓存Cache在每个存储周期中存取多个字多模块交叉存储器DDR34353.5.1双端口存储器结构特点：具有左右两个端口，每一个端口都有独立的读写控制电路读写冲突：若左、右端口同时对相同的存储单元进行读写操作左读右写、右读左写、左写右写解决方法：判断逻辑决定对哪个端口优先进行读写操作，而暂时关闭另一个被延迟的端口，即置其忙信号BUSY#=0。36双端口存储器IDT7133逻辑框图R37双端口存储器读写时序CE判断：如果地址匹配且在CE之前有效，片上的控制逻辑在CEL和CER之间进行判断来选择端口。383.5.2多模块交叉存储器设存储器由M个的独立的存储模块组成，每个模块有相同的容量和存取速度存储模块就是存储芯片存储器地址的编排方式：顺序方式和交叉方式。顺序方式：地址按顺序分配给一个模块后，又按顺序为下个模块分配39内存地址模块2bit字3bitM0M1M2M3数据总线顺序方式5位地址：高2位选模块，低3位选块内地址故障隔离扩充容量比较方便连续地址单元在同一个模块，各模块串行工作带宽没有提升403.5.2多模块交叉存储器交叉方式：两个相邻地址的物理单元不属于同一个存储模块，一般在相邻的存储模块中；同一个存储模块内的地址都不连续。41内存地址模块2bit字3bitM0M1M2M3数据总线交叉方式5位地址：高3位选块内地址，低2位选模块连续地址单元在不同同模块，各模块并行工作存储对齐（软件）+交叉编址（硬件）可以系统运行速度3.5并行存储器42地址总线ABUSM0M1M2M3单字长数据总线DBUS交叉编址ARARARARCPU每个模块独立工作各模块分时使用数据总线进行信息传递。流水线方式数据总线是瓶颈43多体交叉存储器流水线方式存取示意图连续读取m个字所需的时间为模块内访问一个存储单元（字）的存储周期是T多体并行存储器44地址总线ABUSM0M1M2M3多字长数据总线DBUS交叉编址ARARARARCPU也称为多通道优化瓶颈多模块应用两条4G内存条单条8G内存条性能差异？-45-双通道内存实例128bit-46-双通道内存性能评测SiSoftwareSandraProBusiness2011HPDL120G7IntelSandyBridge-47-新型存储器:PCRAM相变储存器又称PCM和CRAM，它利用相变材料作为储存介质。相变材料在非晶相态时具有较高的电阻值；在结晶相态时具有较低的电阻值非易失性存储器对相变材料施加不同时长的电脉冲，使相变材料呈现出不同的结晶状态，并在两种状态之间快速切换储存密度较DRAM更高48新型存储器:ReRAM电阻式存储器也称RRAM，是以非导性材料（金属氧化物）为存储介质的非易失性存储器施加电压，材料的电阻在高阻态和低阻态间发生相应变化，并利用这种性质储存各种信息。RRAM不仅高读写速度和高存储密度，同时延迟更低49新型存储器:MRAM和FRAMMRAM是一种利用磁性工作的非易失性随机存储器。基于两个铁磁层磁化状态来存储信息，当电流流过时会表现出不同的阻值。FRAM，采用铅锆钛形成结晶体存储数据。通过判断晶体内的电荷高低来读取数据。503.6Cache存储器13.6Cache存储器为什么要引入Cache？解决CPU和主存之间的速度不匹配问题延迟（ns）和带宽（GB/s）2CPU带宽简单测算个人电脑的DDR4-3200内存单通道带宽25600MB/sCPU默认频率位1500MHz，4核心64位处理器，每次运算需要2个数据CPU所需带宽：1500x4x(8+8)=96000MB/s内存墙（memorywall）343.6Cache存储器在CPU和内存之间设置一个小容量的存储器Cache，保存的内容是主存内容的一个子集Cache存取速度要比主存快，用SRAM实现Cache功能全由硬件调度，对所有用户透明运行过程无需软件参与52.Cache基本原理程序的局部性原理在一段时间内，程序的执行仅限于程序中的某一部分。相应地，执行所访问的存储空间也局限于某个内存区域时间局部性：被访问过一次的内存区域在未来会被多次访问空间局部性：如果一个内存区域被访问，那么将来它附近的单元也会被访问6sum=0;for(i=0;i<n;i++)sum+=a[i].x+a[i].y;returnsum;程序局部性举例数据数组元素访问(空间)结构体、数据库记录访问(空间)局部变量，计数器，指针等被重复使用(时间)指令顺序访问的指令(空间)重复使用的循环体(时间)子函数(时间)-7-程序局部性举例程序1：inta[M][N];for(i=0;i<M;i++)for(j=0;j<N;j++)sum+=a[i][j];程序2：inta[M][N];for(j=0;j<N;j++)for(i=0;i<M;i++)sum+=a[i][j];哪个程序具有更好的局部性-8-93.Cache的命中率10Cache的平均访问时间11Cache的访问效率12例3.4CPU执行一段程序时，Cache完成存取的次数为1900次，主存完成存取的次数为100次，已知Cache存取周期为50ns，主存存取周期为250ns，求Cache/主存系统的效率和平均访问时间。解：13背景：相联存储器（CAM）普通存储器都是按地址访问相联存储器是按内容访问ContentAddressableMemory相联存储器的基本原理存放在相联存储器中的内容：标记+数据查找的主要操作是比较按地址访问存储器按地址访问：存储器只保存数据，数据的地址不保存寻址时译码器根据地址直接选中对应数据14按地址访问：存储器只保存数据，数据的地址不保存寻址时译码器根据地址选中对应存储单元15按地址访问存储器按内容访问：增加标记(标识、Tag)，一般用地址的部分或全部查找时，将访问地址和表中的所有标记比较，相同的一行就是要访问的存储单元16CAM存储器按内容访问：增加标记(标识、Tag)存储，一般用地址的部分或全部作为标记查找时，将访问地址和标记存储中的所有标记比较，相同的一行就是要访问的存储单元17CAM存储器相联存储器在计算机系统中，CAM主要用于需要快速查找的领域：虚拟存储器中存放段表、页表和快表；Cache网络设备中路由的查找18193.6.2主存与Cache的地址映射203.6.2主存与Cache的地址映射Cache分为若干行（Line），每行的容量和主存块相同Cache与主存的数据交换是以块为单位Cache按内容访问，主存按地址访问必须应用某种方法，把主存的地址定位到Cache中的确切位置——地址映射例题主存地址空间大小为256MB，按字节编址。主存块大小为64B。数据Cache有8行假定int型数据为32位补码，数组a按行优先方式存放，首地址为320（十进制）1）数据Cache的总容量是多少？2）数组元素a[0][31],a[1][1]所在主存块分别是多少?inta[256][256];Cache原理图22主存分块Cache替换管理Cache与主存之间的数据交换是以块为单位CPU与Cache/主存之间的数据交换是以字为单位标记存储Cache数据存储Cache的基本工作原理示意图23CPU将内存地址同时发往Cache和主存。Cache的四个问题当把一块调入Cache时，放在哪行?（映射方式）全相联、直接映射、组相联如何判断当所要访问的地址在Cache中?（地址变换）当发生失效时，应替换哪一行？（替换算法）当进行写操作时，应进行哪些操作?（写策略）保证数据的一致性241.全相联多对多：主存一个块可以放到Cache任一行将整个块地址作为Cache行的标记25XXXXXXXXXX主存地址：块号（s位）块内偏移（w位）2r=8行2s=256块2w=4字B0B1B2B3B124B124B3B1B0B21.全相联26主存256块，每块4个字，Cache有8行1.全相联地址变换CPU将内存地址同时发往Cache和主存发往Cache的访存地址会分为块地址和块内偏移块地址同时和Cache中所有行的Tag进行比较相同表示命中，再根据块内偏移从该行中读取一个字，同时撤销内存寻址过程若没有命中，则等待访存过程结束，然后将被访问内存的相对应块调入Cache270000000000000001000000100000001101011000010110010000001001011001010000001010000000100000000101011001块地址（块号）1.全相联地址变换内存地址11111111281.全相联特点：优点：冲突概率小，Cache的利用高。冲突：所选择的Cache行包含近期要使用的信息缺点：比较电路实现成本高适用于小容量的Cache292.直接映射30312.直接映射Cache将s位块地址分为两部分：低r位作为Cache的行号（index）:r=log2m高s-r位作为该行tag直接映射的Cache组织32332.直接映射-地址变换第一步：用访存地址中的块号的r位行号找到Cache中对应的一行第二步：用块号的s-r位与该行的tag比较。若命中，而后用低w位读取所要求的字若不命中，访问主存二、直接映射映射检索过程000000000000000100000010000000110101100001011001010110110101101001011111010000001011010111100101011块号蓝色：行号；绿色：字地址Cache地址000Cache地址010Cache地址111342.直接映射优点：硬件简单，成本低缺点：每个块只有一个固定的行可存放，容易产生冲突频繁置换会导致Cache抖动，效率下降适合大容量Cache采用更多行减小冲突353.组相联将Cache分成u组，每组v行组间采用直接映射，组内采用全相联映射主存中的每一块可以被放置到Cache中唯一的组的任何一行组相联是全相联和直接映射的折中方案q组号，j主存块地址、m为Cache总行数m＝u×v组号q＝jmodu设u＝2d，q=log2d:363.组相联映射方式低d位表示组号(组索引，组index)高s-d位作为tag37Cache分为4组，每组2行383.组相联映-地址变换第一步：用块号的低d位找到对应组第二步：将块号的高s-d位与该组中所有行的标记同时进行比较命中，选中该行，用内存地址的低w位选择相应的字不命中，则访问内存39三、组相联映射地址变换000000000000000100000010000000110101100001011001111111110101101001011000110000001001001011000000010110000000010110块号蓝色：组号；绿色：字地址403.组相联映射方式特点：比全相联容易实现，冲突低u=1，则为全相联映射方式v表示每组的行数，称之为v路组相联Cache。v=1，则为直接映射方式得到普遍采用41全相联映射载入过程221011022611010222101102261641618载入载入命中命中载入载入命中载入t222616418主存32块，Cache8行42直接相联映射载入过程22（10110）22261641618载入载入命中命中载入载入命中替换t2226164161826（11010）主存32块，Cache8行432路组相联映射载入过程222622261641618载入载入命中命中载入载入命中载入t222616418主存32块，Cache8行44Cache基本概念Cache的作用：解决CPU和主存之间的速度不匹配问题小容量存储器，用SRAM实现对用户透明Cache的原理程序局部性：时间和空间Cache性能命中率、平均访问时间、效率1Cache基本概念CAM按内容访问、比较器主存地址：块地址和块内偏移Cache分为若干行（Line），每行的容量和主存块相同Cache与主存的数据交换是以块为单位21.全相联多对多：主存一个块可以放到Cache任一行将全部块地址作为Cache行的标记31.全相联地址变换CPU发出的访存地址中的块地址同时和Cache中所有的Tag进行比较。特点冲突概率小，成本高适用于小容量的Cache42.直接映射多对一：一个主存块只能映射到Cache的一个特定行上562.直接映射-地址变换地址变换用访存地址中的块号的r位行索引找到Cache中对应的行然后用块号的s-r位与该行的tag比较。特点硬件简单，成本低，容易产生冲突频繁置换会导致Cache抖动，效率下降适合大容量Cache采用3.组相联将Cache分成u组，每组v行V路组相联组间采用直接映射，组内采用全相联映射73.组相联映-地址变换地址变换首先访存地址的块地址的低d位找到对应组，然后将块地址的高s-d位与该组v行中的所有tag同时进行比较。特点比全相联容易实现，冲突低全相联映射和直接映射的折衷得到普遍采用8910一个4路组相联Cache由64行组成，主存储器包含4K个块，每块128字。请表示主存地址的格式？典型题组相联映射下的主存地址格式如下：每块128字块内的字地址需要7位Cache由64个行组成，每组4行Cache共包含16组，需4位组号主存包含4K个块主存块号为12位标记位12－4=8位7位4位8位解：主存容量1M=220，主存地址共20位块大小=24字节，字号(块内偏移)w=4块地址：20-4=16位全相联映射，标记位数等于块地址位数，为16位主存格式主存地址(F0010)16=(11110000000000010000)2对应的标记=1111000000000001字号=000011有一个存储体系，主存容量1MB，字长1B，块大小16B，Cache容量64KB。若Cache采用全相联映射，对内存地址（F0010H）给出相应的标记和字号。例：某PC主存容量为128KB,Cache容量4KB,每块32B。主存多少块？块地址多少位？Cache多少行？主存块：128K/32=4K，块地址占12位Cache行：4K/32=128=27用直接映射时，Cache标记几位？12位块地址中，低7位定位Cache行，高5位为标记用全相联映射，Cache标记几位？12位12例：某计算机的Cache有16行，采用二路组相联映射方式，每个主存块大小为32字节，按字节编址。则主存129号单元的主存块装如Cache的组号是：A、0B、2C、4D、6解：二路组相联，共有16/2=8组，组号占3位。每块32字节，所以块内地址占5位。129转化为二进制：100_00001：前3位为组号，组号为4。129/32=4，4mod8=413块地址=块号块内偏移=块内地址=字地址=字号143.6.3替换策略当从主存向Cache传送一个新块，而Cache中可用位置已被占满时，就会产生替换问题直接映射：替换Cache中指定的一行全相联和组相联：从所有行或组内所有行中选取一行换出Cache的常用替换算法：最不经常使用LFU算法近期最少使用LRU算法随机153.6.3替换策略最不经常使用LFU(LeastFrequentlyUsed)算法每行设置一个计数器，0开始计数每访问一次，被访行的计数器增1。当需要替换时，将计数值最小的行换出，同时将该行的计数器都清零。不能严格反映近期访问情况。刚调入Cache的新行很容易被换出16173.6.3替换策略例子：设Cache有1、2、3、4共4行(全相联映射)，a、b、c、d、e等为主存中的块,访问顺序一次如下：a、b、c、d、c、b、c、e、d、d、a,e。1）采用LFU算法替换18计数器从0开始计数每访问一次，该行的计数器增1。将计数值最小的行换出，该行计数器清零。3.6.3替换策略近期最少使用(LRU-LeastRecentlyUsed的)算法将近期内长久未被访问过的行换出每行设置一个计数器访问时，命中行的计数器清零，其它各行的计数器增1替换时，将计数值最大的行换出保护了刚拷贝到Cache中的新行，提高了命中率随机替换随机地选取一行换出1920命中行的计数器清零，其它各行的计数器增1将计数值最大的行换出。3.6.4Cache的写操作策略Cache的内容只是主存部分内容的副本对Cache的写入导致与主存内容的不一致三种写策略写回法（Write-Back）全写法（Write-Through、写穿透、写直达）写一次法（Write-Once）考虑写命中和写不命中两种情况21(1)写回法写命中：修改Cache的内容，而不立即写入主存只有当此行被替换时才写回主写未命中：首先将内存中对应块调入Cache，然后对其修改当此行换出时，写回主存特点减少了访问主存的次数存在不一致的隐患每行配置一个修改位，以反映此行是否被CPU修改过。被修改过的行称为脏行（dirty）22例题(2)全写法写命中时：同时写入Cache与主存写未命中时：直接向主存进行写入特点：无需增加修改位写Cache和写主存同步进行，不存在数据不一致的情况一定程度上降低了Cache的性能24(3)写一次法写回法+全写法写命中时：第一次：采取全写法不是第一次：采取写回法写未命中时：与写回法相同主要用于多处理器系统25Inteli7Cache结构262728例题主存地址空间大小为256MB，按字节编址。指令数据Cache，均有8行，Cache行大小为64B，数据Cache直接相联。现有两功能相同的程序A，B，其伪代码如下所示：假定int型数据为32位补码，程序编译时i,j,sum均分配在寄存器中，数组a按行优先方式存放，首地址为320（十进制）。1）数组元素a[0][31],a[1][1]所在主存块对应的Cache行分别是多少，行号从零开始。2)程序A，B的数据访问命中率各是多少？那个程序的执行时间更短?inta[256][256];for(i=0;i<256;i++)for(j=0;j<256;j++)sum+=a[i][j];inta[256][256];for(j=0;j<256;j++)for(i=0;i<256;i++)sum+=a[i][j];程序A程序B3.7虚拟存储器原因？多用户、多任务的出现，要求每个程序有自己独立的内存空间用户编程时希望不考虑实际程序的运行空间？虚拟存储器只是一个容量非常大的存储器的逻辑模型，它借助于磁盘等辅助存储器来扩大主存容量，使之为更大或更多的程序所使用。3.7虚拟存储器1.实地址与虚地址用户编制程序时使用的地址称为虚地址或逻辑地址，其对应的存储空间称为虚存空间或逻辑地址空间；计算机物理内存的访问地址则称为实地址或物理地址，其对应的存储空间称为物理存储空间或主存空间。程序进行虚地址到实地址转换的过程称为程序的再定位。注意：物理地址由CPU地址引脚送出，用于访问主存的地址。虚拟地址由编译程序生成的，是程序的逻辑地址。主存～外存层次所用的地址变换映射方法和替换策略与cache～主存层次所用的方法和策略是相同的，即都基于程序局部性原理。它们遵循的原则是：3.7虚拟存储器2.虚存访问过程：虚存空间用户程序按照虚地址编程并存放于辅存之中运行时，操作系统将程序的部分调入内存。每次访存时，判断：虚地址对应部分是否在内存？若在：虚实地址转换不在：从辅存中调入3.7虚拟存储器虚存是概念模型，不是实物对系统程序不透明、对应用程序透明虚存能有效提高存储体系性能Cache主存辅存Cache-主存访问机制主存-辅存访问机制3.7虚拟存储器3.Cache与虚存的异同：出发点相同：提高存储系统性能原理相同：局部性原理侧重点不同：Cache：解决速度差异，提高访存速度；虚存：容量、分配、保护等数据通路不同：CPU与主存和Cache有直接通路；CPU不能直接访问辅存3.7虚拟存储器3.Cache与虚存的异同：透明性不同：Cache：完全由硬件完成，透明；虚存：硬件软件完成，仅对用户程序透明未命中损失不同：Cache：未命中时间损失小虚存：未命中时间损失大3.7虚拟存储器4.虚存机制要解决的关键问题调度问题：哪些程序、数据调入主存？地址映射问题：虚实地址变换替换问题：决定哪些程序和数据应被调出主存更新问题：主存、辅存内容一致性3.7虚拟存储器不同的虚拟存储器机制页式虚拟存储器段式虚拟存储器和段页式虚拟存储器不同的替换算法：FIFO、LRU、LFU3.7.2页式虚拟存储器页式虚拟存储系统中，虚拟空间分成页，称为逻辑页；主存空间也分成同样大小的页，称为物理页。虚存地址分为两个字段：逻辑页号+页内行地址。实存地址也分两个字段：物理页号+页内行地址。页表中每一个虚存逻辑页号有一个表目，表目内容包含该逻辑页所在的主存页面地址(物理页号)，用它作为实存地址的高字段，与虚存地址的页内行地址字段相拼接，产生完整的实主存地址，据此来访问主存页式虚拟存储器结构页表通常在主存中，也至少要访问两次物理存储器才能实现一次访存，这将使虚拟存储器的存取时间加倍。为了避免对主存访问次数的增多，把页表中的最活跃的部分存放在高速存储器中，这个专用于页表缓存的高速存储部件通常称为转换后援缓冲器(TLB)。保存在主存中的完整页表则称为慢表。3.6.2页式虚拟存储器TLB的地址映射过程3.7.3段式虚拟存储器和段页式虚拟存储器1、段式虚拟存储器段是按照程序的自然分界划分的长度可以动态改变的区域。子程序、操作数和常数等划分到不同的段中，并且每个程序可以有多个相同类型的段。虚地址由段号和段内地址（偏移量）组成。虚地址到实主存地址的变换通过段表实现。14段式虚拟存储器地址变换段页式虚拟存储器是段式虚拟存储器和页式虚拟存储器的结合。它把程序按逻辑单位分段以后，再把每段分成固定大小的页。程序对主存的调入调出是按页面进行的，但它又可以按段实现共享和保护，兼备页式和段式的优点。缺点是在映象过程中需要多次查表。段页式虚拟存储器在段页式虚拟存储系统中，每道程序是通过一个段表和一组页表来进行定位的。段表中的每个表目对应一个段，每个表目有一个指向该段的页表起始地址及该段的控制保护信息。如果有多个用户在机器上运行，多道程序的每一道需要一个基号，由它指明该道程序的段表起始地址。虚拟地址格式如下：段页式虚拟存储器【例10】假设有三道程序(用户标志号为A，B，C)，其基址寄存器内容分别为SA，SB，SC，逻辑地址到物理地址的变换过程如下图所示。在主存中，每道程序都有一张段表，A程序有4段，C程序有3段。每段应有一张页表，段表的每行就表示相应页表的起始位置，而页表内的每行即为相应的物理页号。请说明虚实地址变换过程。3.7.4替换算法虚拟存储器中的页面替换策略和cache中的行替换策略有很多相似之处，但有三点显著不同：(1)缺页至少要涉及一次磁盘存取，读取所缺的页，缺页使系统蒙受的损失要比cache未命中大得多。(2)页面替换是由操作系统软件实现的。(3)页面替换的选择余地很大，属于一个进程的页面都可替换。虚拟存储器中的替换策略一般采用LRU算法、LFU算法、FIFO算法，或将两种算法结合起来使用。对于将被替换出去的页面，假如该页调入主存后没有被修改，就不必进行处理，否则就把该页重新写入外存，以保证外存中数据的正确性。为此，在页表的每一行应设置一修改位。21【例7】假设主存只有a,b,c三个页框，组成a进c出的FIFO队列，进程访问页面的序列是0，1，2，4，2，3，0，2，1，3，2号。若采用①FIFO算法，②FIFO算法+LRU算法，用列表法分别求两种替换策略情况下的命中率。3.8虚拟存储器实例1.奔腾PC机的虚地址模式奔腾PC的存储管理部件MMU包括分段部件SU和分页部件PU两部份，可允许SU，PU单独工作或同时工作。分段不分页模式：虚拟地址由一个16位的段参照和一个32位的偏移组成。分段部件SU将二维的分段虚拟地址转换成一维的32位线性地址。优点是无需访问页目录和页表，地址转换速度快。对段提供的一些保护定义可以一直贯通到段的单个字节级。分段分页模式：在分段基础上增加分页存储管理的模式。即将SU部件转换后的32位线性地址看成由页目录、页表、页内偏移三个字段组成，再由PU部件完成两级页表的查找，将其转换成32位物理地址。兼顾了分段和分页两种方式的优点。不分段分页模式：这种模式下SU不工作，只是分页部件PU工作。程序也不提供段参照，寄存器提供的32位地址被看成是由页目录、页表、页内偏移三个字段组成。由PU完成虚拟地址到物理地址的转换。这种模式减少了虚拟空间，但能提供保护机制，比分段模式具有更大的灵活性。2.保护模式的分页地址转换奔腾页面大小为4MB使用单级页表。32位线性地址分为高10位的页面和低22位的页内偏移两个字段。页表项的I位指示页面大小，P位为出现位，A位为访问过位，D位为修改过位。RW位用于读/写控制，US位用于用户/监督控制，PCD位用于页cache禁止的控制，PWT位用于页全写法的控制。奔腾4MB分页方式地址变换3.9存储保护当多个用户共享主存时，就有多个用户和系统软件存于主存中，为使系统能正常工作，应防止由于一个用户程序出错而破坏其他用户的程序和系统软件，还要防止一个用户程序不合法地访问不是分配给它的主存区域。为此，系统应提供存储保护。通常采用的方式是：1存储区域保护2访问方式保护3.9.1存储区域保护非虚拟存储器的主存系统可采用界限寄存器方式。由系统软件经特权指令设置上、下界寄存器，为每个程序划定存储区域，禁止越界访问。界限寄存器方式只适用于每个用户占用一个或几个连续的主存区域。在虚拟存储系统中，通常采用页表保护、段表保护和键式保护方法。1.页表保护和段表保护每个程序的段表和页表本身都有自己的保护功能。每个程序的虚页号是固定的，经过虚地址向实地址变换后的实存页号也就固定了。那么不论虚地址如何出错，也只能影响到相对的几个主存页面。不会侵犯其他程序空间。段表和页表的保护功能相同，但段表中除包括段表起点外，还包括段长。2.键保护方式为主存的每一页配一个键，称为存储键每个用户的实存页面的键都相同。为了打开这个锁,必须有钥匙，称为访问键。访问键赋予每道程序，并保存在该道程序的状态寄存器中。当数据要写入主存的某一页时，访问键要与存储键相比较。若两键相符，则允许访问该页，否则拒绝访问。3.环保护方式对正在执行的程序本身的核心部分或关键部分进行保护。它是按程序的重要性及对整个系统的正常运行的影响程度进行分层，每一层叫做一个环。在现行程序运行前由操作系统定好程序各页的环号，并置入页表中。然后把该道程序的开始环号送入CPU的现行环号寄存器。程序可以访问任何外层空间；访问内层空间则需由操作系统的环控例行程序判断这个向内访问是否合法。3.9.2访问方式保护对主存信息的使用可以有三种方式：读、写和执行。相应的访问方式保护就有R、W、E三种方式形成的逻辑组合。这些访问方式保护通常作为程序状态寄存器的保护位，并且和区域保护结合起来实现。表3.11访问方式保护的逻辑组合35本章小结对存储器的要求是容量大、速度快、成本低。为了解决了这三方面的矛盾，计算机采用多级存储体系结构，即cache、主存和外存。存储器的技术指标有存储容量、存取时间、存储周期、存储器带宽。SRAM、DRAM和ROM各自的特性第四章指令系统4.1指令系统的发展与性能要求4.2指令格式4.3操作数类型4.4指令和数据的寻址方式4.5典型指令14.1指令系统的发展与性能要求冯诺依曼结构主要思想五大部件存储程序程序控制计算机程序由一系列的机器指令组成指令是计算机执行某种操作的命令每个指令的执行过程依靠硬件实现24.1指令系统的发展与性能要求指令是软件和硬件分界面(Interface)硬件设计人员采用各种手段实现它；软件设计人员则利用它编制系统软件和应用软件指令系统：一台计算机中所有机器指令的集合表征一台计算机性能的重要因素影响计算机的硬件结构、系统软件，机器的适用范围指令集架构(InstructionSetArchitecture,ISA)3指令系统44.1.1指令系统的发展系列计算机基本指令系统相同、基本体系结构相同的一系列计算机同一系列的各机种有共同的指令集指令集向下兼容X86系列、ARM系列54.1.1指令系统的发展复杂指令系统计算机CISC-ComplexInstructionSetComputer单条指令功能复杂，整个指令系统数量庞大控制器研制开发周期变长，正确性难以保证，调试维护困难X86、IA32\IA64、IBMSystem/360IntelMCS-51精简指令系统计算机RISC-ReducedInstructionSetComputer克服CISC缺点，便于VLSI技术实现单条指令功能简单2/8规则：80%的指令完成20%的功能控制器设计难度降低ARM:AdvancedRISCMachineRISC-V、MIPSAVR:AlfandVegard'sRISCprocessor64.2指令格式表示一条指令的二进制串称为指令字，指令指令格式：用二进制代码表示的结构形式操作码（OP-OperationCode）该指令执行的操作，编码表示地址码（AC-AddressCode）描述指令的操作对象，可以是操作数本身，也可以是操作数的位置存储器单元----存储器地址寄存器----寄存器编号I/O设备中的缓冲-----端口号74.2.2地址码操作数有被操作数、操作数及操作结果这三种数形成了三种指令格式8三地址指令二地址指令一地址指令零地址指令4.2.2地址码零地址指令指令字中只有操作码，而没有地址码一种是无需操作数如NOP、HLT停机指令等另一种是操作数为默认的（或称隐含的）如操作数在累加器或者堆栈中9零地址指令4.2.2地址码一地址指令常称为单操作数指令，指令中只有一个地址码可能是单操作数运算给出的地址既作为操作数的地址，也作为结果的地址OP(A)->A也可能是二元运算指令中提供一个操作数，另一个操作数则是隐含的(A)OP(AC)->A10一地址指令4.2.2地址码二地址指令最常见的指令格式，又称为双操作数指令运算结果保存在其中一个地址码中，原来的数据被覆盖（A1）OP（A2）→A1地址码A1兼做存放操作结果114.2.2地址码三地址指令(A1)OP(A2)->A3A1和A2为源操作数A3为目的操作数124.2.2地址码在二地址和三地址指令格式中，从操作数的物理位置划分为三种类型存储器-存储器(Storage-Storage,SS)型指令：从内存单元中取操作数，操作结果存放至内存单元需要多次访问内存寄存器-寄存器(Register-Register,RR)型指令：从寄存器中取操作数，把操作结果放到另一寄存器这类指令的速度很快，因为不需要访问内存寄存器-存储器(Register-Storage,RS)型指令：此类指令既要访问内存单元，又要访问寄存器134.2.3指令字长度指令字长度：一条指令的二进制位数为了取指方便，一般为机器字长倍数半字长、单字长、双字长多字长指令指令字长度等于两个或多个机器字长优点：地址码更多，解决内存的寻址问题；缺点：多次访存才能取得一条指令，降低了速度，占用存储空间大144.2.3指令字长度指令集中所有指令长度是否相等等长指令：所有指令长度相等结构简单，控制线路简单MIPS、ARM变长指令：指令字长度随功能而异结构灵活，控制较复杂X86现在指令字长一般为32位固定长度154.2.4指令助记符为了便于书写和阅读，指令通常用3个或4个英文缩写字母来表示，叫做指令助记符16指令格式举例：ARM指令格式指令长度为32位，定长指令单字长指令RR型指令、三地址指令17指令格式举例X86指令格式变长指令，1~15字节，典型的CISC指令系统多字长指令18X86指令格式JE20HCallPUSHESIMOVEBX,[EDI+45][例1]机器字长16位，指令格式如下所示，其中OP为操作码，试分析指令格式的特点。1597430[解]：(1)单字长二地址指令(2)操作码字段OP可以指定27=128条指令(3)源寄存器和目标寄存器都是通用寄存器（总共16个），所以是RR型指令，两个操作数均在寄存器中[例2]机器字长16位，指令格式如下所示，OP为操作码字段，试分析指令格式特点。15107430(1)双字长二地址指令(2)操作码字段OP为6位，可以指定64种操作(3)一个操作数在源寄存器，另一个操作数在存储器中,所以是RS型指令。通用寄存器（总共16个)H&P和RISCJohnHennessyMIPS是在是其在Stanford的研究成果Hennessy于1984年在硅谷创立了MIPS公司后任Stanford大学校长DavidPatterson加州大学伯克利分校教授，研究成果发展出SUN公司SPARC处理器是谷歌的杰出工程师RISC-VFoundation董事会副主席H&P和RISC两人出版了两本著名的教科书：ComputerOrganizationandDesign:TheHardware/SoftwareInterface(计算机组成与设计：硬件/软件接口)ComputerArchitecture:AQuantitativeApproach(计算机体系结构：量化方法)2017ACM图灵奖MIPS架构历史MIPS（MicroprocessorwithoutInterlockedPipelinedStages）ISA是经典的RISC架构之一1981年由斯坦福大学的Hennessy团队研制1984年被MIPSTechnologies公司商业化,1992年SGI收购2013年ImaginationTechnologies公司收购2017年卖给Tallwood,2018年WaveComputing收购（命运多舛）2019年成为MIPSOpen，正式开源（2020年闭源）MIPSISA版本MIPS32/MIPS64多个版本基于MIPSISA的处理器龙芯系列，君正系列MIPS指令集特点单字长指令指令长度为4字节=32位定长指令大部分为三地址指令，RR型32个32位的通用寄存器$0,$1,$2,…$30,$31内存按字节编址，内存严格4字节对齐访问MIPS里没有状态码，没有标志寄存器MIPS指令格式OPRSRtshamtRd6bitsfunct5bits5bits5bits5bits6bitsOPRSRt6bits偏移量5bits5bits16bitsOP6bits地址26bitsR型指令I型指令J型指令RegisterformatImmediateformatJumpformatMIPS指令格式（R型指令）OPRSRtshamtRd6bitsfunct5bits5bits5bits5bits6bits例：add$s1,$s2,$s300000010010100111000100000100000MIPS指令格式(R型指令)0x02538820$s2+$s3=$s1MIPS指令格式（I型指令）OP：操作码Rs：第1个源操作数寄存器Rt：目的操作寄存器偏移量：第二个原操作数OPRSRt6bits偏移量5bits5bits16bitsMIPS指令格式（J型指令）OP：操作码跳转指令，用一个26位的立即数作为跳转的目标地址OP6bits立即数26bits314.3操作数类型操作数类型地址数据：地址是无符号整数。数值数据：定点数、浮点数字符数据：字符或字符串，使用ASCII码逻辑数据：一个单元中有几位二进制bit项组成，每个bit的值可以是1或0。当数据以这种方式看待时，称为逻辑性数据RISC-V完全开放大道至简包含一个最小的核心ISA适合硬件实现轻装上阵的后发优势模块化的可扩展指令集方便简化硬件实现，提升性能更规整的指令编码、更简洁的运算指令和访存模式高效分支跳转指令（减少指令数目）、简洁的子程序调用无条件码执行、无分支延迟槽、无零开销硬件循环（支持for循环的硬件支撑）MIPS32&RISC-V指令助记符及语法格式大同小异RISC-V分支预测，MIPS延迟槽RISC-V支持变长指令扩展RISC-V将源寄存器rs1，rs2和目标寄存器（rd）固定在同样位置，以简化指令译码立即数分散在不同位置，但符号位固定在第31位，可加速符号扩展电路RISC-V（2022年）34三大事件：第一，发布首台RISC-V的便携式计算机第二，Intel设立创新基金，支持RISC-V生态；第三，SiFive估值超25亿美元RISC-V全球会员超过3100家，超过160个核开源；SPECint首次超过10分，进入高性能计算行列在IoT领域的应用规模超过100亿颗中国公司的出货量占据50%RISC-V（2022年）阿里平头哥发布了高性能RISC-V芯片平台“无剑600”及SoC原型“曳影1520”，兼容龙蜥操作系统,并成功运行LibreOffice无剑600平台是当前全球性能最高的可量产RISC-V平台：支持4核RISC-V处理器，主频可达2.5GHz，CPU+XPU异构架构；支持64位LPDDR4X，最高吞吐率4266MT；整合4TOPs的Int8AI算力35RISC发展1964年SeymourCray设计的CDC6600采用了load/store设计，被认为是RISC架构的先驱70年代，RISC的概念由IBM的约翰·科克（JohnCocke）和斯坦福大学的约翰·亨尼（JohnHennessy）等人提出1981年，斯坦福大学的Hennessy发布了首款MIPS芯片1981年，加州大学伯克利分校的DavidPatterson推出了RISC-I1983年RISC-II；1984年发布了RISC-III；1988年发布了RISC-IV2010年，发布了RISC-V1987年，SUN公司在RISC-II基础上开发了SPARC处理器36RISC架构在1980年代末至1990年代得到了广泛的应用和普及。许多公司开始推出基于RISC架构的处理器，如IBM的POWER架构、DEC的Alpha架构和HP的PA-RISC架构等。RISC-V是一种开源的RISC架构，在2010开始兴起，并得到了全球范围内的关注和采用。RISC-V的开放性和灵活性使得它成为教育、研究和嵌入式系统等领域的理想选择。3714.4指令和数据的寻址方式存储器中既存放指令，也存放数据在存储器中，操作数或指令字写入或读出的方式，有地址指定方式、相联存储方式和堆栈存取方式几乎所有计算机在内存中都采用地址指定方式当采用地址指定方式时，形成操作数或指令地址的方式，称为寻址方式24.4指令和数据的寻址方式寻址方式问题确定本条指令中各操作数的地址下一条指令的地址寻址方式分为两类顺序寻址方式(1)指令寻址方式跳跃寻址方式(2)数据寻址方式1.顺序寻址方式指令地址在内存中按序排放执行程序时，通常是顺序执行称为指令的顺序寻址方式使用程序计数器PC（programcounter）保存指令的顺序号顺序号就是指令在内存中的地址新指令地址：PC=PC+常量常量就是当前指令的长度MIPS：PC+43图4.1指令的寻址方式2.跳跃寻址方式当程序转移执行顺序时，指令寻址采取跳跃寻址方式所谓跳跃，是指下条指令的地址码不是由PC给出，而是由本条指令直接给出程序跳跃后，按新的指令地址开始顺序执行PC的内容也必须相应改变，以便及时跟踪新的指令地址2.跳跃寻址方式6跳跃寻址方式功能实现程序转移或构成循环程序或将某些程序作为公共程序引用（子程序调用）各种条件转移或无条件转移指令，属于跳跃寻址4.4.2操作数寻址方式形成操作数的有效地址（EA-EffectiveAddress）的方法，称为操作数的寻址方式地址码由形式地址（偏移量）和寻址方式特征位组合形成例如，一种单地址指令中用X，I，A各字段组成该指令的地址码寻址方式特征位指明如何对形式地址进行变换784.4.2操作数基本寻址方式计算机中操作数的存放位置有操作数包含在指令中；操作数包含在CPU的某一个内部寄存器中；操作数包含在主存中；操作数包含在I/O设备的端口中根据操作数放在不同的地方，从而派生各种不同的寻址方式4.4.2操作数寻址方式91、隐含寻址在指令中不明显的给出而是隐含着操作数的地址例如，单地址指令、双地址指令102、立即寻址地址码中不是操作数的地址，而是操作数本身也叫立即数特点：操作码和操作数被同时取出，提高了指令的执行速度操作数是指令的一部分，不能修改操作数的大小将受到指令长度的限制，寻址方式灵活性差例如：ADDBX,33H;33H为立即数（X86）addi$3,$0,3;3为立即数（MIPS）113.直接寻址直接寻址：形式地址A就是操作数的有效地址EAEA＝A直接寻址方式由寻址方式特征位给予指示12X86：MOVAX,[200]EA=AImm为寻址方式特征位3.直接寻址77200200内存4、间接寻址间接寻址：形式地址A是操作数内存地址的指示，A单元的内容才是操作数的有效地址。结合直接寻址和间接寻址，定义指令格式如下：I＝0，表示直接寻址，有效地址EA＝AI＝1，表示间接寻址，有效地址EA＝(A)144、间接寻址间接寻址要比直接寻址灵活至少需要两次访问主存储器才能取出操作数400788300300400间接寻址方式示意图5、寄存器寻址操作数在通用寄存器中地址码为通用寄存器编号，即EA=R从寄存器中取操作数比访问主存快X86：MOVAX,BXMIPS:add$4,$15,$17166、寄存器间接寻址寄存器中存放的不是操作数，而是操作数的内存地址地址码给出通用寄存器的编号，有EA=(R)17300R7.偏移寻址偏移寻址是直接寻址和寄存器间接寻址的结合有效地址EA=A+（R）。寻址特征位指明某个专用寄存器常用的三种偏移寻址是相对寻址、基址寻址、变址寻址。187.偏移寻址7.1相对寻址方式专用寄存器是程序计数器PC即有效地址EA=A+(PC)。“相对”寻址，就是相对于PC的地址形式地址A可正可负一种指令寻址方式207.1相对寻址方式2000PC2100程序指令计数器7.2基址寻址方式专用寄存器是基址寄存器形式地址A是通常是无符号整数可以扩大寻址能力，基址寄存器的位数长，可以访问较大的地址范围MIPS:LW$18,8($15)#EA=$15+8227.3变址寻址方式专用寄存器是变址寄存器目的而在于实现程序块的规律性变化例如，一个数组在内存的首地址为X，将首地址X作为指令中的形式地址A，并在变址寄存器中指出元素的序号，便可访问任一元素X86：MOVAX,200[SI]SI,DI都称为变址寄存器237.3变址寻址方式X86：MOVAX,200[SI]SI,DI都称为变址寄存器243000操作数R3200内存8.段寻址Intel8086/8088微机中，ALU16位运算，但其内存容量可到1M，即地址有20位将整个1M空间存储器以64K为单位划分成若干段。在形成20位物理地址时，段寄存器中的16位数会自动左移4位，然后以16位偏移量相加9.堆栈寻址方式堆栈有寄存器堆栈和存储器堆栈两种形式，都以先进后出的方式存取数据不论哪种堆栈，需要一个隐式或显式的堆栈寄存器来指明栈顶（栈指针）的位置（地址）X86中，SP(StackPoint,栈顶指针)BP(BasePoint,栈底)269.堆栈寻址方式根据栈顶状态不同，堆栈分为：满栈：栈指针指向栈顶元素位置空栈：栈指针指向下一个空位置根据增长方向不同，堆栈分为：递减栈：堆栈向内存地址减小的方向生长，即向下生长。递增栈：堆栈向内存地址增加的方向生长，即向上生长。X86:满栈、递减栈27栈指针指向最后压入堆栈的有效数据项，称为满栈（先改变SP，再放数据）；栈指针指向下一个待压入数据的空位置，称为空栈（先放数据，再改变SP）。0x12345678栈底栈区0x123456780x12345678递增栈：递减栈：30寻址方式举例：PentiumEA=段寄存器+描述符寄存器+基址寄存器+变址寄存器*比例因子+偏移量寻址方式举例：MIPS31寻址方式举例：RISC-V32[例]一种二地址RS型指令的结构如下所示：6位4位1位2位16位其中I为间接寻址标志位，X为寻址模式字段，A为偏移量字段。通过I，X，A的组合，可构成下表所示的寻址方式。请写出六种寻址方式的名称。20050011002001005008001002002100OPXA=100PC=1000R基=2000寻址方式X操作数立即0100直接1200间接2500相对3100基址4200有效地址EAEA=A=100EA=(A)=200EA=PC+A=1100EA=(R)+A=2100例设某机的指令格式、有关寄存器和主存内容如下，X为寻址方式，A为形式地址，请在下表中填入有效地址EA及操作数的值。？指令格式设计举例例.某机字长32位，采用三地址指令，支持8种寻址操作，完成60种操作，各寻址方式均可在2K主存范围内取得操作数，并可在1K范围内保存运算结果。问应采用什么样的指令格式？指令字长最少应为多少位？执行一条直接寻址模式指令最多要访问多少次主存？47位指令字需占用2个存储字取指需访存2次，取源操作数访存2次，写结果1次，共5次4.5.1指令的分类按指令的功能：数据传送实现主存和寄存器之间，或寄存器和寄存器之间的数据传送数据处理定点或浮点算术运算，向量运算、逻辑运算与移位等程序控制用于控制程序的执行方向分支、转移、调用子程序其他指令系统控制，特权，安全等3637设存储字长和指令字长均为24位，若指令系统可完成108种操作，且具有直接、间接、变址、基址、相对和立即6种寻址方式。在保证最大范围内直接寻址的前提下，指令字中操作码占几位？寻址特征位占几位？可直接寻址的范围是多少？间接寻址的范围是多少？38某计算机的字长为16位，数据用补码表示，存储器按字编址，访存指令格式为16位，其中5位操作码，3位寻址方式字段，分别表示立即寻址、直接寻址、间接寻址、变址寻址和相对寻址这5种，8位地址码字段。设PC和Rx分别为程序计数器和变址寄存器(其中Rx的位数为16位)问：立即寻址的数据范围多大？各种寻址方式的寻址范围大小是多少？下列关于各种寻址方式获取操作数快慢的说法中，正确的是I.立即寻址快于堆栈寻址II.堆栈寻址快于寄存器寻址III.寄存器间接寻址快于变址寻址IV.变址寻址快于间接寻址11:2139MIPS指令系统MIPS指令集特点定长指令，指令长度固定4字节简单的load/store结构，内存中的数据访问严格4字节对齐load/store结构：只有load/store类指令可以访问存储器寻址方式简单，每条指令的操作也简单易于流水线设计易于编译器开发MIPS寄存器字长32位32个通用寄存器$0,$1,$2,…$30,$313个特殊寄存器PC（程序计数器）HI和LOHI乘积高32位(余数)，LO：乘积低32位（商）；除了用在乘除法之外，也不能有做其他用途硬件没有强制性的指定寄存器使用规则，但是在实际使用中，这些寄存器的用法都遵循一系列约定MIPS里没有状态码，没有标志寄存器32个通用寄存器IA-32的寄存器组织8个通用寄存器两个专用寄存器6个段寄存器MIPS寻址方式数据寻址方式立即寻址寄存器寻址基址寻址基址寄存器+偏移量任一通用寄存器都可以作为基址寄存器MIPS寻址方式指令寻址顺序寻址：PC=PC+4PC相对寻址PC=偏移量左移两位+PC伪直接寻址（跳跃寻址）26位偏移量PC={PC[31..28],偏移量,00}MIPS指令格式OPRSRtshamtRd6bitsfunct5bits5bits5bits5bits6bitsOPRSRt6bits偏移量5bits5bits16bitsOP6bits偏移量26bitsR型指令I型指令J型指令RegisterformatImmediateformatJumpformatMIPS指令格式（R型指令）主要是运算类指令OP：操作码，所有R型指令OP为全0Rs：第1个源操作数寄存器Rt：第2个源操作数寄存器Rd：存放结果的目的操作数寄存器shamt：用于移位指令，指明移位次数funct：功能码，对操作码进行补充OPRSRtshamtRd6bitsfunct5bits5bits5bits5bits6bitsR型指令MIPS指令格式(R型指令)寄存器寻址汇编格式：opRd,Rs,Rt例：add$s1,$s2,$s3指令编码：00000010010100111000100000100000MIPS指令格式(R型指令)0x02538820$s2+$s3=$s1MIPS指令格式（I型指令）L/S指令和分支指令Rt：目的操作数寄存器Rs和偏移量：源操作数OPRSRt6bits偏移量5bits5bits16bitsI型指令汇编格式：opRt,(偏移量)RsMIPS指令格式（I型指令）三地址，RR型，立即数运算指令Rs：第1个源操作数寄存器Rt：目的操作寄存器偏移量：第2个源操作数(立即数)OPRSRt6bits偏移量5bits5bits16bitsI型指令汇编格式：opRt,Rs,偏移量MIPS指令格式(I型指令)立即寻址基址寻址相对寻址MIPS指令格式(I型指令)addi$21,$22,-50op=810rs=2210(原操作数寄存器)rt=2110(目的寄存器)偏移量=-5010,负数用补码表示请写出指令的机器码十进制指令格式:二进制指令代码:0x22D5FFCE十六进制指令代码:MIPS指令格式（J型指令）单地址指令跳转指令，用一个26位的偏移量作为跳转的目标地址OP6bits偏移量26bitsJ型指令汇编格式：op偏移量MIPS指令格式（J型指令）伪直接寻址——跳转地址为指令中的26位偏移量与PC中的高4位拼接得到新的PC={PC[31..28],目标地址,00}例：j100000x0800271000001000000000000010011100010000指令编码：新PCMIPS指令系统（1）数据传送类：（2）算术/逻辑运算类：（3）控制类：1、数据传送类：内存数据访问指令读内存指令：lwlblh（I型指令）w:wordb:byteh:halfword访问元素A[8]，A[0]保存在$t3lw$t0,32($t3)#基址寻址写内存指令：swsbsh（I型指令）$t0的数据保存到A[12]；sw$t0,48($t3)2、算术/逻辑运算类：加减指令加法add（R型指令）add$s4,$s1,$s2#$s1+$s2=$s4减法sub（R型指令）sub$s3,$s4,$s5#$s4-$s5=$s3-20-2、算术/逻辑运算类：加减指令如何编译下面的C语言表达式?a=b+c+d-e;编译成多行汇编指令add$t0,$s1,$s2#temp=b+cadd$t0,$t0,$s3#temp=temp+dsub$s0,$t0,$s4#a=temp-e2、算术/逻辑运算类：加立即数立即数相加指令addi（I型指令）addi$s3,$s3,4#$s3=$s3+4立即数传送addi$s3,$zero,1#$s3=1寄存器间数据传送add$s3,$s2,$0#$s3=$s2利用$zero($0)实现寄存器之间的数据传输2、算术/逻辑运算类：逻辑运算逻辑移位指令sll、srl、sra（R型指令）sll$s1,$s2,2#$s2左移两位srl$s1,$s2,2#$s2右移两位逻辑运算and/or/xor/addi/ori/xori（R型和I型指令）and$t0,$t1,$t2#t0=t1&t2or$t0,$t1,$t2#t0=t1|t2andi$t0,$t1,100#t0=t1&100ori$t0,$t1,100#t0=t1|1003、控制类指令:跳转指令3、控制类指令C语言条件判断指令If(a==b){i=1;}else{i=2;}等效C指令If(a==b)gotoL1;i=2;gotoL2;L1:i=1;L2:等效MIPS指令beq$s0,$s1,L1addi$s3,$zero,2jL2;L1:addi$s3,$zero,1L2:-25-等效MIPS指令$s0=a$s1=b$s3=i3、控制类指令:比较指令sltslti比较指令(slt:SetonLessThan)sltreg1,reg2,reg3如果reg2<reg3,则reg1=1先比较，再分支If($s1<$s2)gotoLess;slt$t0,$s1,$s2#$t0=1if$s1<$s2bne$t0,$0,Less#if$t0!=0gotoLess-26-循环结构C语言简单循环结构，A为int数组do{g=g+A[i];i=i+j;}while(i!=h);重写代码Loop:g=g+A[i];i=i+j;if(i!=h)gotoLoop;编译后的变量映射:循环结构最后编译的MIPS代码:Loop:sll$t1,$s3,2#$t1=4*iadd$t1,$t1,$s5#$t1=&A[0]+4ilw$t1,0($t1)#$t1=A[i]add$s1,$s1,$t1#g=g+A[i]add$s3,$s3,$s4#i=i+jbne$s3,$s2,Loop#ifi!=hgotoLoop原始C代码:Loop:g=g+A[i];i=i+j;if(i!=h)gotoLoop;循环结构最后编译的MIPS代码:Loop:sll$t1,$s3,2#$t1=4*iadd$t1,$t1,$s5#$t1=&A[0]+4ilw$t1,0($t1)#$t1=A[i]add$s1,$s1,$t1#g=g+A[i]add$s3,$s3,$s4#i=i+jbne$s3,$s2,Loop#ifi!=hgotoLoop#原始C代码:Loop:g=g+A[i];i=i+j;if(i!=h)gotoLoop;MIPS函数调用C语言函数调用intfunction(inta,intb){return(a+b);}MIPS实现函数调用的机制返回地址寄存器$ra参数寄存器$a0,$a1,$a2,$a3返回值寄存器$v0$v1局部变量$s0~$s7堆栈指针$sp过程调用实现机制sum(a,b);/*a,b:$s0,$s1*/}intsum(intx,inty){returnx+y;}1000add$a0,$s0,$zero#x=a1004add$a1,$s1,$zero#y=b1008addi$ra,$zero,1016#$ra=10161012jsum#调用函数sum1016…2000sum:add$v0,$a0,$a1#过程入口2004jr$ra#new#返回主程序instruction过程调用实现机制sum(a,b);/*a,b:$s0,$s1*/}intsum(intx,inty){returnx+y;}1000add$a0,$s0,$zero#x=a1004add$a1,$s1,$zero#y=b1008addi$ra,$zero,1016#$ra=10161012jsum#调用函数sum1016…2000sum:add$v0,$a0,$a1#过程入口2004jr$ra#new#返回主程序instructionJ10161008jalsum1012过程调用机制jallabel#linkandjump$ra=PC+4;#savenextinstructionaddressjLabel过程返回指令jr$ra#returntomainprogram在32位MIPS体系结构下，最多可寻址4GB地址空间0xFFFFFFFF0xA00000000xC00000000xBFFFFFFF0x800000000x9FFFFFFF0x7FFFFFFF0x00000000MIPS内存地址空间数据通路流水线化MARS开源MIPS仿真器，汇编器MIPSX86差异4.5.3精简指令系统RISC选取使用频率最高的一些功能实现，指令条数少便于硬件实现，用软件实现复杂指令功能指令长度固定，指令格式简单，寻址方式简单只有存数/取数指令可以访问存储器(RS型)，其余指令的操作都在寄存器之间进行(RR型)设置大量寄存器（32~192）一个机器周期完成一条机器指令RISCCPU采用硬布线控制，CISC采用微程序CSIC与RISC互相融合382010研究生统考例题例.某计算机字长为16位，主存地址空间大小为128KB，按字编址。采用单字长指令格式，指令各字段定义如图，转移地址采用相对寻址方式，相对偏移量用补码表示。寻址方式如图。注(x)表示存储器地址x或寄存器x的内容（1）该指令系统最多可有多少条指令？该计算机最多有多少个通用寄存器？存储器地址寄存器MAR和存储器数据寄存器MDR至少需要多少位？2010研究生统考例题注(x)表示存储器地址x或寄存器x的内容（2）转移指令的目标地址范围是多少？例.某计算机字长为16位，主存地址空间大小为128KB，按字编址。采用单字长指令格式，指令各字段定义如图，转移地址采用相对寻址方式，相对偏移量用补码表示。寻址方式如表。2010研究生统考例题注(x)表示存储器地址x或寄存器x的内容（3）若操作码0010B表示加法操作，助记符为add，寄存器R4，R5的编号分别为100B和101B，R4的内容为1234H，R5的内容为5678H，地址1234H中的内容为5678H，地址5678H中的内容为1234H，则汇编语句add(R4),(R5)+逗号前为源操作数，逗号后为目的操作数，对应的机器码是多少？用十六进制表示。该指令执行以后，哪些寄存器和存储单元的内容会发生改变？改变后的内容是什么？例.某计算机字长为16位，主存地址空间大小为128KB，按字编址。采用单字长指令格式，指令各字段定义如图，转移地址采用相对寻址方式，相对偏移量用补码表示。寻址方式如图。MIPS仿真工具MARSMIPS汇编程序汇编源程序由数据声明段和代码段组成。汇编程序文件以.s或.asm为后缀数据声明以.data开始，声明在代码中使用的变量、常量在主存中创建了对应的空间代码段以.text开始，由指令构成的程序代码代码以main:开始。程序的注释使用#符号进行注释。MIPS汇编程序模板#Title:Filename:#Author:Date:#Description:#Input:#Output:###############数据段/Datasegment#################.data...#自定义的数据###############代码段/Codesegment##################.text.globlmainmain:#mainprogramentry...#自己写的代码li$v0,10#Exitprogramsyscall数据声明格式：val_name:storage_typevalue(s)创建一个以val_name为变量名，value(s)为初值，存储类型是storage_type的变量。变量名后要跟一个英文冒号数据存储类型storage_type.word，.half，.byte–字、半字、字节.asciiz-字符串，以null结尾var1:.word3#var1为一个字变量，初值为3，整数array1:.byte‘a’,‘b’#array1为两个元素的字节数组，初值#分别为a和b的ASCII码array2:.space40#分配一块连续的内存区域，容量为40字节string1:.asciiz“Printthis.\n”#定义一个字符串汇编指令语句代码部分的语句格式：[label:]mnemonic[operands][#comment]Label:(标记)标记一条指令在内存中的位置，以英文冒号结尾Moemonic(助记符)MIPS机器指令、汇编伪指令（比如add,sub,等)Operands(操作数)根据指令格式定义的操作数，可以是寄存器、内存变量、常量L1:addiu$t0,$t0,1#$t0加1系统调用(syscall)1.取数、存数#################codesegment#####################.datavalue:.word10,20,0.text.globlmainmain:#main入口la$t0,value#将变量value的地址装入$t0#la是伪指令lw$t1,0($t0)#将地址($t0+0)的字数据装入$t1lw$t2,4($t0)#将地址($t0+4)的字数据装入$t2add$t3,$t1,$t2#$t1+$t2=$t3sw$t3,8($t0)#将$t3中的数据存入地址($t0+8)li$v0,10#退出syscall机器指令与汇编语言伪指令汇编器定义的，用于增强汇编程序可读性和提高编程效率编译时，汇编器将伪指令翻译为一条或多条机器指令汇编器建立符号表，以记录每个变量和标记的内存地址例符号表.DATAvar1:.byte1,2,'Z'str1:.asciiz"MyString\n"var2:.word0x12345678.ALIGN3var3:.half1000符号表-symboltableLabelvar1str1var2var3Address0x100100000x100100030x100100100x100100182.读取并显示一个整数#################codesegment#####################.text.globlmainmain:#mainprogramentryli$v0,5#5号功能调用，读取整数syscall#$v0=读取的值move$a0,$v0#$a0=要显示的整数值li$v0,1#1号功能调用，显示整数syscallli$v0,10#退出程序syscallMARS仿真步骤点击工具栏编译程序（快捷键F3）运行（快捷键F5），“RunI/O”窗口显示并输出程序运行结束，系统复位(F12)，重新开始3.输入并显示字符串#################Datasegment#####################.datastr:.space10#arrayof10bytes#################Codesegment#####################.text.globlmainmain:#mainprogramentryla$a0,str#$a0=addressofstrli$a1,10#$a1=maxstringlengthli$v0,8#readstringsyscallli$v0,4#Printstringstrsyscallli$v0,10#Exitprogramsyscall4.三个整数相加（1/2）#Input:分别输入三个整数#Output:输出和###################Datasegment###################.dataprompt:.asciiz"Pleaseenterthreenumbers:\n"sum_msg:.asciiz"Thesumis:"###################Codesegment###################.text.globlmainmain:la$a0,prompt#显示提示字符串promptli$v0,4syscallli$v0,5#读第一个数到$t0syscallmove$t0,$v04.三个整数相加（2/2）li$v0,5#读第二个数到$t1syscallmove$t1,$v0li$v0,5#读第三个数到$t2syscallmove$t2,$v0addu$t0,$t0,$t1#累加addu$t0,$t0,$t2la$a0,sum_msg#writesummessageli$v0,4syscallmove$a0,$t0#输出结果li$v0,1syscallli$v0,10#exitsyscall运行结果5.小写字母到大写转换(1/2)#Objective:小写字母转换到大写#Input:输入一个字符串.#Output:以大写形式输出.###################Datasegment#####################.dataname_prompt:.asciiz"Pleasetypeastring:"out_msg:.asciiz"Yournameincapitalsis:"in_name:.space31#spaceforinputstring###################Codesegment#####################.text.globlmainmain:la$a0,name_prompt#printpromptstringli$v0,4syscallla$a0,in_name#readtheinputstringli$a1,31#atmost30chars+1nullcharli$v0,8syscall5.小写字母到大写转换(2/2)la$a0,out_msg#writeoutputmessageli$v0,4syscallla$t0,in_name#t0为输入字符串的首地址loop:lb$t1,($t0)#load一个字节beqz$t1,exit_loop#ift1=0,退出循环blt$t1,‘a’,no_change#t1<‘a’,表示大写，处理下一个字符bgt$t1,‘z’,no_change#t1>‘z’,表示非字母字符，处理下一个字符addiu$t1,$t1,-32#‘a’<t1<‘z’小写转大写:'A'-'a'=-32sb$t1,($t0)#保存于字符原位置no_change:addiu$t0,$t0,1#t0指向下一个字符jloopexit_loop:la$a0,in_name#输出转换完成的大写字符串li$v0,4syscallli$v0,10#exitsyscall第五章中央处理器本章讨论CPU的功能组成，控制器的工作原理和实现方法，微程序控制原理，基本控制单元的设计以及先进的CPU系统设计技术1返回第五章中央处理器5.1CPU功能和组成5.2指令周期5.3时序产生器和控制方式5.4微程序控制器5.5硬布线控制器5.6流水CPU5.7RISCCPU235.1CPU的功能和组成5.1.1CPU的功能冯.诺依曼的“存储程序、程序控制”用计算机解决某个问题时，首先编写程序程序是一个指令序列，这个序列明确告诉计算机应该逐步执行什么操作（操作码）在什么地方找到用来操作的数据，结果存到何处（地址码）45.1.1CPU的功能计算机进行信息处理的过程可分为两步：①将程序和数据装入存储器；②从程序入口开始取指令，执行指令，得到所需结果，然后结束运行中央处理器是控制计算机自动完成取出指令和执行指令任务的部件计算机的核心部件，简称为CPU（CentralProcessingUnit）5.1.1CPU的功能指令控制：保证控制器按顺序执行程序操作控制管理并产生一系列操作信号，将它们送往相应的部件时间控制：对各种操作实施时间上的定时数据加工：对数据进行算术和逻辑运算565.1.2CPU的基本组成早期的CPU由运算器和控制器两大部分组成现在将外围的一些逻辑功能部件纷纷移入CPU，使CPU的组成越来越复杂789运算器数据加工处理部件组成ALU、通用寄存器、DR和PSW主要功能执行算术运算执行逻辑运算10控制器协调和指挥整个计算机系统的操作组成PC、IR、指令译码器、时序发生器和操作控制器功能(1)从指令Cache中取出一条指令，生成下一条指令在指令Cache的位置；(2)对指令进行译码，产生相应的操作控制信号(3)控制CPU、内存和输入/输出设备间的数据流动115.1.3CPU中的主要寄存器在CPU中主要有以下六类寄存器1.数据寄存器（DR-DataRegister）2.指令寄存器（IR-InstructionRegister）3.程序计数器（PC-ProgramCounter）4.数据地址寄存器（AR-AddressRegister）5.通用寄存器（R0~R3–GeneralRegister）6.状态字寄存器（PSW-ProgramStatusWord）1.数据寄存器（DR）暂时保存要写入寄存器的数据122.指令寄存器（IR）InstructionRegister保存当前正在执行的指令内容OP字段的输出作为指令译码器的输入3.程序计数器（PC）ProgramCounter保存下一条指令的地址在程序开始执行前必须将起始地址(入口地址)送入PC修改PC的内容顺序寻址：PC=PC+常量；常量与指令长度有关相对寻址：PC=PC+偏移量跳跃寻址：PC=偏移量X86：EIPMIPS：PC4.数据地址寄存器（AR）保存访问数据Cache的地址本例中为保持访问数据Cache单元的地址5.通用寄存器模型中有4个通用寄存器（R0~R3）作为ALU的数据源和目的寄存器用作地址指示器、变址寄存器、堆栈指示器等6.状态字寄存器（PSW）一个由各种状态标志拼凑而成的寄存器模型机中的PSW由ALU的运算结果设置还保存中断和系统工作状态等X86：FLAGSMIPS：无185.1.4操作控制器和时序发生器数据通路：部件之间传送信息的通路操作控制器在各部件之间建立数据通路操作控制器根据指令OP码和时序信号，生成各种操作控制信号，以便正确地建立数据通路，从而完成取指令和执行指令的控制195.1.4操作控制器和时序产生器操作控制器分为硬布线控制器，采用时序逻辑技术实现微程序控制器，采用存储逻辑实现时序产生器产生并发出计算机所需要的时序信号对各种控制信号实施时间上的控制205.2指令周期指令周期的基本概念MOV、的指令周期LAD指令的指令周期ADD指令的指令周期STO指令的指令周期JMP指令的指令周期用方框图语言表示指令周期指令格式设计-编码操作码位数地址码位数：双地址码、单地址码偏移量、寄存器位数数据寻址方式直接寻址、寄存器寻址、寄存器间接寻址指令寻址方式顺序寻址、跳跃寻址不设定寻址特征位，由操作码默认指定寻址方式215.2.1指令周期的基本概念运行程序第一步：从内存中取一条指令第二步：执行该指令周而复始235.2.1指令周期的基本概念上述步骤所需时间从内存取出一条指令的时间：取指周期分析并执行这条指令的时间：执行周期指令周期=取指周期+执行周期从内存取出一条指令、分析并执行这条指令的时间总和指令功能不同，其指令周期不同245.2.1指令周期的基本概念一个指令周期划分为若干CPU周期CPU周期又称机器周期通常指从内存读一个字的最短时间取指周期包含若干CPU周期执行周期包含若干CPU周期功能不同的指令，可能包含不同数目的CPU周期255.2.1指令周期的基本概念一个CPU周期包含若干时钟周期时钟周期：T周期、节拍脉冲处理操作的最基本时间单位ALU完成一次正确的运算寄存器间的一次数据传送等相互关系：1个指令周期=取指周期+执行周期=若干个CPU周期1个CPU周期=若干时钟周期265.2.1指令周期的基本概念指令周期=取指周期+执行周期取指周期=1个CPU周期执行周期=1个CPU周期1CPU周期=4个T周期单周期CPU和多周期CPU单周期CPU在一个CPU周期内完成从取指、译码到执行的所有工作效率低多周期CPU把指令执行周期分成多个阶段，每个阶段在一个CPU周期完成容易流水线执行，效率高27简单定义一个指令集6条指令，单字长，字长为1B，4个寄存器MOV寄存器数据传输RR型LAD/STO取数/存数RS型ADD/AND加法/与RR型JMP转移RS型28简单定义一个指令集指令寻址方式顺序寻址：PC+1跳跃寻址：PC=偏移量数据寻址方式直接寻址：EA=偏移量寄存器寻址：EA=R寄存器间接寻址：EA=(R)29指令格式设计操作码（OP）定义6条指令：MOV/LAD/STO/ADD/AND/JMP30MOV寄存器寻址双地址码，功能：Rs->RdLAD直接寻址，功能：(A)->RsSTO寄存器间接寻址，Rs->(Rd)指令格式设计(类MIPS)31JMP跳跃寻址A->PCADD寄存器寻址Rs+Rd->RdAND寄存器寻址Rs&Rd->Rd指令格式设计32一个小程序33一个小程序34六条典型指令组成的简单程序示例35程序运行到105地址时，各寄存器的值是多少？36如何设计指令周期前提：掌握每个指令要执行的操作识别出各个部件的控制命令两个阶段取指阶段、执行阶段两个步骤找出数据通路：数据从哪里来，经过哪些部件，最终达到哪里确定操作信号：形成上述数据通路所需的操作控制信号37图5.1的结构控制信号总线三态门：C1、C2、C3存储器：数据Cache读/写(RD(D))、指令Cache读(RD(I))寄存器：每个寄存器都有输入和输出控制信号输入控制信号：PCin、Riin，DRin等输出控制信号：PCout、Riout等PC：PC+1ALU：加、与、传送3839DCache读/写ICache读+\&\MDRinPCoutPCinARinRioutRiinIRin如何设计指令周期时间设计：各个操作在哪个时钟周期发生取指周期=？CPU周期执行周期=？CPU周期1个CPU周期定义从内存读/写一个数据或使用共享总线传输一个数据，总线只能有一个源一个CPU周期内数据不能产生冲突图5.1中IBUS是独占的、DBUS是共享的1个CPU周期包括4个T周期：T1~T440指令周期从内存取出一条指令、分析并执行这条指令的时间总和指令周期=取指周期+执行周期=若干个CPU周期1个CPU周期=若干时钟周期1如何设计指令周期前提：掌握每个指令完成的功能，要执行的操作识别出各个部件的控制命令分两个阶段取指阶段、执行阶段三个步骤1.找出数据通路：数据从哪里来，经过哪些部件/总线，最终达到哪里2.确定操作信号：形成上述数据通路所需的操作控制信号3.分配CPU周期2如何设计指令周期分配CPU周期：各个操作信号在哪个CPU周期发出取指周期=？CPU周期执行周期=？CPU周期1个CPU周期定义从内存读/写一个数据或使用共享总线传输一个数据，总线只能有一个源一个CPU周期内数据不能产生冲突344DCache读/写ICache读+\&\MDRinPCoutPCinARinRioutRiinIRinIBUS是独占的、DBUS是共享的1个CPU周期包括4个T周期：T1~T45.2.2MOV指令的指令周期MOVR0,R1单字长，RR型取指阶段：数据通路：从指令Cache中取出指令经过IBUS写入IRPCABUS(I)ICacheIBUSIR操作控制：形成上述数据通路的控制信号PC内容输出到指令Cache指令Cache读操作，通过IBUS写入IRPC+1，为取下一条指令做好准备对IR中的OP译码，以确定进行什么操作5PCoutIRinICache读65.2.2MOV指令的指令周期1.取指周期：完成三件事从指令Cache取出指令到IRPC+1，为取下一条指令做好准备对IR中的OP译码，以确定进行什么操作2.执行周期将数据从R1传送到R0由于操作简单，只需要一个CPU周期7PC中装入第一条指令地址101；1018101①PC的内容被放到ABUS（I）上，指令Cache进行译码，发出读命令；101R②从101号地址读出的MOV指令通过IBUS装入IR；③PC+1，变成102，为取下一条指令做好准备；102④对IR中的OP译码，识别出是MOV指令，取指阶段即告结束MOV指令的取指阶段95.2.2MOV指令的取指周期操作PC内容输出到指令Cache读指令Cache取出，指令写入IRPC+1；对IR中的OP译码时间访问内存取一条指令，需要1个CPU周期10MOV指令的执行周期将数据从R1传送到R0(1)OC送出控制信号到通用寄存器，选择R1做源寄存器，选择R0作目标寄存器；(2)OC送出控制信号到ALU，指定ALU做传送动作；(3)OC送出控制信号，打开ALU输出三态门C1，将ALU输出送到DBUS上；(4)OC送出控制信号，将DBUS上的数据打入到DR(5)OC送出控制信号，将DR中的数据打入R0，R0的内容由00变为10至此，MOV指令执行结束11MOV指令的执行阶段MDRinRioutRiin5.2.2MOV指令的指令周期MOVR0,R1单字长，RR型执行阶段：数据通路：寄存器R1的数据传输到R0R1ALUDBUSDRR0操作控制：形成上述数据通路的控制信号选择R1做源寄存器，指定ALU做传送动作打开ALU输出三态门C1，将ALU输出送到DBUS上将DBUS上的数据写入到DR将DR中的数据写入R0，R0的内容由00变为101213①OC送出控制信号到通用寄存器，选择R1做源寄存器，指定ALU做传送操作M10②OC送出控制信号，打开C1，将ALU输出送到DBUS上③将DBUS上的数据10打入到DR；④将DR中的数据打入到R0，R0的内容由00变为10MOV指令的执行周期DRinR1outR0inMOV指令的执行周期操作(1)选择R1做源寄存器，指定ALU做传送动作；(2)打开ALU输出三态门C1，将ALU输出送到DBUS上；(3)将DBUS上的数据写入DR(4)将DR中的数据写入R0时间：使用一次共享总线DBUS，需要1个CPU周期14155.2.2MOV指令的指令周期1.取指2.执行165.2.2MOV指令的指令周期（简化）1.取指2.执行只考虑一个CPU周期内的操作175.2.2MOV指令的指令周期（再简化）5.2.2MOV指令的指令周期MOVR0,R1取指周期1个CPU周期执行周期1个CPU周期185.2.3LAD指令LADR1,6单字长，RS型取指阶段同MOV指令相同执行阶段数据通路：访问内存地址6的单元，取出数据写入R1IRARABUS(D)DBUSDRR11920控制信号：打开C3，将地址码6放到DBUS上；将地址码6装入AR，数存进行地址译码；读数存6号单元，数100读出到DBUS上；将DBUS上的数据100写入DR；将DR中的数据100写入R1ARinDCache读DRinR1in21LAD指令的执行周期控制信号：打开C3，将地址码6放到DBUS上；将地址码6装入AR，DCache进行地址译码；读数存6号单元，数100读出到DBUS上；将DBUS上的数据100写入DR；将DR中的数据100写入R122LAD指令的执行周期时间设计：序号1和2，访问一次内存并使用DBUS，需要1个CPU周期序号3、4和5，使用一次DBUS，需要1个CPU周期23LAD指令的执行周期（简化）5.2.3LAD指令的指令周期245.2.3LAD指令的指令周期LADR1,6单字长RS型25取指令PC+1译码指令取出操作数取下条指令PC+1取指周期开始执行周期装入通用寄存器5.2.3LAD指令的指令周期LADR1,6单字长RS型26取指令PC+1译码指令取出操作数取下条指令PC+1取指周期开始执行周期装入通用寄存器5.2.5ADD指令的指令周期ADDR1,R2单字长，RR型执行阶段2728OC送出控制信号到通用寄存器，选择R1和R2做源寄存器10020OC送出控制信号到ALU，指定ALU做加法120打开C1，将运算结果120输出送到DBUS上OC送出控制命令，将DBUS上的数据打入到DR120OC送出控制命令，将120装入R2，R2的内容由20变为120ADD指令的执行R1outR2out+DRinR2in29ADD指令的执行数据通路R1→ALU、R2→ALU，ALU→DBUS→DR→R2操作控制(1)选择R1和选择R2，R1和R2加法操作(3)打开三态门C1，将运算结果120输出送到DBUS；(4)将DBUS上的数据打入DR；(5)将DR中的数据120写入R2，R2的内容由20变为12030ADD指令的执行周期(1)选择R1和R2输出到ALU，指定让ALU做加法操作；(2)打开C1，运算结果120输出送到DBUS；(3)DBUS上的数据写入DR；(4)DR中的数据写入R2时间：占用一次DBUS总线，1个CPU周期315.2.2ADD指令的指令周期5.2.5ADD指令的指令周期ADDR1,R2单字长RR型取指周期：1个CPU周期执行周期：1个CPU周期325.2.5STO指令的指令周期STOR2,(R3)单字长、RS型执行阶段数据通路：R3通过DBUS到AR，数据Cache地址译码，R2的内容通过Dbus写入数据Cache3321:1634（1）OC送出操作命令到通用寄存器，选择R3；STO指令的执行R3out35（2）OC送出命令,打开C2，将地址30放到DBUS上；30STO指令的执行36（3）OC发出操作命令，将30装入AR，数存开始地址译码3030STO指令的执行ARin37（4）OC发出命令到通用寄存器，选择R230STO指令的执行R2out38（5）OC发出操作命令，打开三态门C2，将数据120放到DBUS上；12012030STO指令的执行39（6）OC发出命令，将数据120写入30号单元，它原先的数据40被覆盖30120STO指令的执行DCache写40STO指令的执行(1)选择R3，打开三态门C2，将地址30放到DBUS上；(2)地址30装入AR；(3)选择R2，打开三态门C2，将数据120放到DBUS上；(4)将数据120写入数存30号单元时间：使用两次DBUS，需要两个CPU周期21:055.2.5STO指令的指令周期415.2.5STO指令的指令周期21:0542STOR2,(R3)单字长RS型3个CPU周期5.2.6JMP指令的指令周期JMP101无条件转移指令，改变程序的执行顺序单字长、单地址执行阶段数据通路：IP中的101通过DBUS到达PC操作控制4321:0544（1）打开三态门C3，将IR中的地址码101发送到DBUS上JMP指令的执行45（2）将DBUS上的地址码101打入到PC中，PC中原先的内容106被覆盖JMP指令的执行PCin465.2.6JMP指令的执行周期(1)打开C3，地址码101发送到DBUS(2)DBUS上的地址码101写入到PC时间：占用一次总线，需要1个CPU周期21:05475.2.6JMP指令的指令周期5.2.6JMP指令的指令周期JMP1012个CPU周期21:05485.2.7指令周期495.2.7指令周期505.2.7用方框图语言表示指令周期采用方框图（指令流程图）来表示指令周期一个矩形框代表一个CPU周期矩形框中的内容表示数据通路矩形框右边写出控制信号菱形框表示判断或测试时间上依附于前一个方框的CPU周期，不独占一个CPU周期公操作符号“～”一条指令执行完毕后CPU进行的一些共性操作，中断请求、DMA请求等5121:055.2.2指令周期52译码PCout,,IRin,PC+1PCIR5.2.7方框图表示指令周期由上图可见，对于图5.1的模型机所有指令的取指周期是完全相同的，而且是一个CPU周期。在执行周期，由于各条指令的功能不同，所用的CPU周期也是各不相同MOV、ADD、JMP指令是一个CPU周期LAD、STO指令是两个CPU周期，需要访问内存5321:05R1iR1oR2oR2i例1的数据通路图R1iR1oR2oR2i画出下面指令的指令周期流程图，假设该指令的地址已放入PC中。列出相应的微操作控制信号序列“ADDR2，R0”指令完成(R2)+(R0)→R0的功能(2)“SUBR1，R3”指令完成(R3)-(R1)→R3的操作基本步骤取指周期写出取指周期数据通路PCxxxxIR写出的控制信号形成上述数据通路要记得PC+1设定操作控制信号的时间使用一次总线或访问一次内存为一个CPU周期根据经验执行周期根据执行周期要完成的操作写出数据通路具体指令具体分析，依据具体功能写出形成上述数据通路的控制信号设定操作控制信号的时间RS型指令需要更多的CPU周期56取指周期(ADDR2，R0)数据通路：PCBGAARMDRBGAIR57取指周期(ADDR2，R0)数据通路：PCBGAARMDRBGAIR控制信号：PCo、G、ARiRDRo，G、IRi58取指周期(ADDR2，R0)时间分配数据通路：控制信号PCBGAAR：PCo、G、ARi（1个CPU周期）MDR：R（1个CPU周期）DRBGAIR：DRo，G、IRi（1个CPU周期）59取指周期(ADDR2，R0)60PCARPCo、G、ARiMDRRDRIRDRo，G、IRi，PC+1ADD指令执行周期(ADDR2，R0)ADDR2，R0”指令完成(R2)+(R0)→R0的功能数据通路：R2BGAX；R0BGAY；ALUBGAR061执行周期(ADDR2，R0)ADDR2，R0”指令完成(R2)+(R0)→R0的功能数据通路：控制信号R2BGAX:R2o，G、XiR0BGAY:R0o，G、YiALUBGAR0:+，ALUo，G、R0i62执行周期(ADDR2，R0)时间分配ADDR2，R0”指令完成(R2)+(R0)→R0的功能数据通路：控制信号R2BGAX:R2o，G、Xi（1个CPU周期）R0BGAY:R0o，G、Yi（1个CPU周期）ALUBGAR0:+，ALUo，G、R0i（1个CPU周期）63执行周期(ADDR2，R0)64R2XR2o，G、XiR0YR0o，G、YiALUR0+，ALUo，G、R0i65(1)“ADDR2，R0”指令是一条RR型加法指令图的右边部分标注了每一个机器周期中用到的微操作控制信号序列。ALU0R066(2)“SUBR1，R3”在执行阶段，微操作控制信号序列与ADD指令有所不同。ALU05.3时序产生器和控制方式5.3.1时序产生器作用和体制5.3.2时序信号产生器5.3.3控制方式111:2325.3.1时序产生器作用和体制计算机的协调动作需要时间标志，而时间标志则是用时序信号来体现用时序信号辨认从内存中取出的是指令还是数据，是取指周期还是执行周期一个CPU周期中时钟脉冲对CPU的动作有严格的约束操作控制器发出的各种信号是时间（时序信号）和空间（部件操作信号）的函数11:23数据：电位控制信号：脉冲5.3.1、时序产生器作用和体制时序信号的基本体制是电位—脉冲制（以触发器为例）电位：用电平的高低进行控制脉冲：用信号的边沿进行控制11:233在微程序控制器中，采用节拍电位-节拍脉冲二级体制时序信号产生电路简单一个CPU周期称为一个节拍电位45.3.1、时序产生器作用和体制ΦT1T2T3T4节拍电位节拍脉冲11:23C1C2在微程序控制器中，采用节拍电位-节拍脉冲二级体制时序信号产生电路简单一个CPU周期称为一个节拍电位55.3.1、时序产生器作用和体制ΦT1T2T3T4CPU周期CPU周期节拍电位节拍脉冲11:23硬布线控制器中，时序信号往往采用状态周期-节拍电位-节拍脉冲三级体制时序信号产生电路复杂状态周期是电位信号，指明当前指令处于哪个状态比如，一个指令的状态周期包括取值周期和执行周期两个状态，取指周期包括1个CPU周期，执行周期包括2个CPU周期65.3.1、时序产生器作用和体制11:23ΦT1T2T3T4CPU周期CPU周期节拍电位节拍脉冲状态周期状态周期-节拍电位-节拍脉冲三级体制11:237取指周期执行周期C1C2C385.3.2、时序信号产生器时钟源:石英晶体振荡器环形脉冲发生器节拍脉冲启停控制逻辑本书模型机启动时，一定要从T1前沿开始；停机时一定要在T4结束后关闭时序产生器11:2391.时钟源时钟源用来为环形脉冲发生器提供频率稳定且电平匹配的方波脉冲信号它通常由石英晶体振荡器和与非门组成的正反馈振荡电路组成，其输出为一个理想的方波11:232、环形脉冲发生器C4C1C2C3Φ作用：产生一组有序间隔相等或不等的脉冲序列11:23103、节拍脉冲1111:233、节拍脉冲1211:233、时序信号举例MOVR0R1该指令的取指周期的需要一个节拍电位，即一个CPU周期，操作信号的节拍脉冲划分为：PC->ABus(I)：T1IBus->IR：T2IR中OP->指令译码器：T311:23133、时序信号举例MOVR0，R1该指令的执行周期需要一个节拍电位操作信号的节拍脉冲划分为：设置ALU完成传送操作：T1R1->ALU：T2DBus->DR：T3DR->R0：T4在一个节拍电位中完成四个有时序关系的操作11:231411:2315T1T2T3T4CPU周期节拍脉冲DBus->DR：T3信号来自译码器，持续一个节拍电位时间4、节拍脉冲和读/写时序1611:2317节拍脉冲节拍电位11:234.启停控制逻辑启动、停机具有随机性当计算机启动时，一定要从节拍点位T1前沿开始工作停机时一定要在节拍点位T4结束后关闭时序产生器1811:235.3.3控制方式指令周期由若干个CPU周期组成每条指令所需的时间各不相同每个操作控制信号所需的时间及出现的次序各不相同形成控制操作序列的方法，称作控制器的控制方式有同步控制、异步控制、联合控制三种方式1911:231.同步控制方式CPU周期数固定、时钟周期数固定节拍电位数固定，节拍脉冲数固定与指令功能、操作复杂度、操作数类型无关设计时固定，与指令的执行无关具体方案：(1)采用统一的CPU周期(2)采用不定长CPU周期(3)中央控制与局部控制结合大部分采用统一CPU周期，个别指令采用不定长CPU周期2011:23212.异步控制方式CPU周期数可变、时钟周期数可变可变：在指令执行时变化每条指令的指令周期所需的CPU周期数不等需要多少时间就占用多少时间反馈机制：执行部件完成操作后发“回答”信号11:23223.联合控制方式同步控制和异步控制相结合的方式两种实现方法1.大部分指令同步控制，少数操作采用异步方式2.CPU周期数可变、时钟周期数固定11:235.4微程序控制器英国剑桥大学的M·V·Wilkes教授于1951年首先提出1964年，IBM公司在IBM360系列机上成功地采用了微程序设计技术20世纪70年代以来，由于VLSI技术的发展，推动了微程序设计技术的发展和应用目前，x86系列几乎都采用微程序设计技术，ARM采用微程序和硬连线相结合2311:23245.4微程序控制器微程序控制（microprogrammingcontrol）基本思想把操作控制信号编制成微指令，存放到只读存储器（控制存储器）里；运行时，从控存中取出这些微指令，从而产生所需的各种操作控制信号微程序设计技术是用软件方法来设计硬件11:235.4.1微程序控制原理1微命令和微操作部件分为两种：控制部件和执行部件微命令：控制部件通过控制线向执行部件发出的控制命令微操作：执行部件接受微命令后所进行的操作微操作在执行部件中是最小、最基本的操作2511:231.微命令和微操作微命令和微操作一一对应控制门电位信号的变化、寄存器输入端的控制、ALU的基本执行过程…微操作可分为相容和互斥两种：互斥：是指不能同时或不能在同一个CPU周期内并行执行的微操作相容：是指能够同时或在同一个CPU周期并行执行的微操作2611:2327（+，-，M）在同一个CPU周期中只能选择一个，因而是互斥的微命令类似地，4，6，8也是互斥的微命令1，2，3是可以同时进行的，所以是相容的微命令X输入控制4，6，8和Y输入的5，7，9中任意两个微命令也是相容的11:23282微指令和微程序微指令(Micro-instruction)：在一个CPU周期中，一组实现一定操作功能的微命令的组合在同一CPU周期内并行或并发执行的微命令的组合微指令存储在控制器中的控制存储器中11:232微指令和微程序微程序一系列微指令的有序集合就是微程序一段微程序对应一条机器指令微地址：存放微指令的控制存储器的单元地址机器指令-》微程序-》微指令-》微命令-》微操作以简单运算器通路图的微指令格式为例：2911:233011:23PC+1LDIRLDARLDDRRD312.微指令和微程序微指令格式举例微指令字长为23位，由操作控制和顺序控制两大部分组成11:232.微指令和微程序操作控制字段，发出控制信号每一位表示一个微命令某一位为1表示发出相应的微命令，为0不发出3211:23335.4.2微指令和微程序顺序控制字段，产生下一条微指令的地址（微地址）后四位：直接微地址P1P2：判断测试标志P1P2=00：使用后四位直接微地址P1P2=01：P2测试条件满足，新微地址=直接微地址条件不满足，新微地址=对直接微地址修改P1P2=10：P1测试11:233.微程序控制器原理框图它主要由控制存储器、微指令寄存器和地址转移逻辑三大部分组成34AR11:23(1)控制存储器(CM：ControlMemory)CM是微程序控制器的核心部件存放微程序只读存储器CM的字长是微指令字的长度字数=微指令数量存储容量=微指令字的长度X微指令数量3511:23控制存储器用于存放微程序控制存储器与主存对比11:2336（2）微指令寄存器(μIR)微地址寄存器和微命令寄存器组成微地址寄存器μAR：下一条微指令的微地址微命令寄存器：微指令的操作控制字段和判别测试字段3711:23（3）地址转移逻辑修改微地址根据IP中的OP字段译码产生微地址（入口微地址）顺序控制字段中的直接微地址给出下一条微指令的地址通过判别测试字段P和执行部件的反馈信息，形成新的微地址3811:234微程序举例假设在某编程环境下，需要完成BCD码加法运算，代码：b=b+a假定该代码的汇编语言是b-》R2，a-》R1对于该指令，共耗费3~4个CPU周期(异步控制)指令:ADDBR2R111:233940十进制加法指令周期流程图取指令a+b运算a+b+6运算减6运算P1测试，表示译码操作，用OP字段作为形成微指令的地址加法运算P2测试，用Cy的状态来修改微地址寄存器的最后一位本条微指令的微地址默认后继微地址11:234.微程序举例一条微指令对应一个方框微指令周期等于一个CPU周期一个方框对应与一个CPU周期指令流程图中有多少方框意味着该指令对应的微程序包含多少条微指令4111:23第一条是取指微指令，要发出的微命令是LDIR、PC+1，LDARP1译码测试4.微程序举例420000000000000010000011111:234.微程序举例第二条微指令的二进制编码是第二条微指令发出的微命令是R1X，R2Y，+，LDR2`11:23434.微程序举例第三条微指令的二进制编码是第三条微指令发出的微命令是R2X，R3Y，+，LDR2`P2判断测试11:23444.微程序举例第四条微指令的二进制编码是第四条微指令发出的微命令是R2X，R3Y，-，LDR2`11:2345000010010000000000000000111100100010010010000000微程序存放示意图顺序控制地址……11011100101110101001……0010000100000000操作控制字段…0101001001000000001000100110000000…控制存储器CM取指微指令R2-R3->R2微指令R2+R3->R2微指令R1+R2->R2微指令…指令:ADDBR2R10100001011:2346执行微程序一条机器指令的微程序由取指微程序和执行微程序组成微程序存放图5.1的主存控存CM11:2347微程序控制器的工作过程(1)取指微程序执行取指周期的操作PCIR，PC+1译码：OP字段输出到地址转移逻辑，产生对应的执行微程序的入口地址，送入μAR11:2348微程序控制器的工作过程(2)根据μAR从CM中取出微指令，并产生下一条微指令的地址送入μAR11:2349微程序控制器的工作过程(3)执行微程序的最后一条微指令执行完毕后，将μAR设为取指微程序的入口地址，从而返回第(1)步周而复始，直到所有机器指令执行完毕11:2350515.CPU周期和微指令周期的关系一个微指令周期与CPU周期时间相等T1,T2,T3时间执行微指令(如运算等)T4上升沿打入结果至寄存器T4时间读取微指令11:236.机器指令与微指令的关系一条机器指令对应一段微程序一段微程序由若干条微指令组成一个微指令包含多个微命令机器指令、程序和地址与内存有关微指令、微程序和微地址与控制存储器有关5211:2353写控制读控制选择WA1WA0W选择RA1RA0R不写入**0不读出**0R3111R3111R2011R2011R1101R1101R0001R0001例设某计算机运算器框图如图所示，其中ALU为16位的补码加法器，SA,SB为16位暂存器，4个通用寄存器的读、写控制功能见下表11:23机器采用微程序控制方式，微指令操作控制字段格式如下(未考虑顺序控制字段)：11:2354要求：写出如下指令执行周期微程序的编码：(1)“ADDR0，R1”指令，即(R0)+(R1)→R1(2)“SUBR2，R3”指令，即(R3)-(R2)→R3(3)“MOVR2，R3”指令，即(R2)→(R3)11:23552.写出微程序：00**1010000001**10010000**01010010011.画出ADDR0，R1指令的流程图RA0RA1=00RLDSALDSBRA0RA1=01RSB-ALUWA0WA1=01W~11:2356572.写出微程序：11**1010000010**10010000**11010001011.画出SUB指令的流程图RA0RA1=11RLDSALDSBRA0RA1=10RWA0WA1=11W~11:23582.写出微程序：10**10100000**11010010111.画出MOV指令的流程图RA0RA1=10RLDSASB-ALUWA0WA1=11W~Reset11:23595.4.2微程序设计技术设计微指令应当追求的目标缩短微指令的长度减小控制存储器的容量提高微程序的执行速度便于对微指令的修改提高微程序设计的灵活性操作控制字段和顺序控制字段的设计如何用二进制表示各种操作控制信号如何形成下一个微地址目标可能是矛盾的！11:231、微命令编码操作控制字段采用的表示方法直接表示法编码表示法混合表示法6011:23（1）直接表示法每一位表示一个微命令“0”表示不发出该微命令“1”表示发出该微命令优点：结构简单，并行性强，操作速度快缺点：每条微指令要包含所有的微命令，微指令太长，导致CM容量较大6111:23（2）编码表示法把相斥的微命令编成一个小组，然后通过译码器对小组信号进行译码，输出作为微命令微指令字缩短，译码电路使微指令的执行速度减慢比如：4个微命令如何编码？要考虑不发出任何微命令的状态6211:23（3）混合表示法直接表示法与编码法结合综合考虑指令字长、灵活性、执行微程序速度等方面的要求6311:232、微地址的形成方法确定下一条微指令的微地址下一条微指令的微地址成为后继微地址1.计数器方式2.多路转移方式（断定方式）6411:23（1）计数器方式顺序执行时后继微地址=当前微地址+增量；类似指令的顺序寻址非顺序执行（分支）时后继微地址=微地址字段类似跳跃寻址特点顺序控制字段较短，微地址产生机构简单多路并行转移功能较弱，速度较慢，灵活性较差6511:232）多路转移方式（断定方式）一条微指令具有多个转移分支的能力称为多路转移顺序执行时后继微地址=微地址字段非顺序执行（分支）时按“判别测试”标志和“状态条件”信息产生一个微地址6611:232）多路转移方式特点：能以较短的顺序控制字段配合，实现多路并行转移，灵活性好，速度较快，需要设计地址转移逻辑6711:2368某计算机采用微程序控制器，共有32条机器指令，公共的取指令微程序包含2条微指令，各指令对应的执行微程序平均由4条微指令组成，采用多路转移法确定下条微指令地址，则微指令中下址字段(微地址字段)的位数至少是()A.5B.6C.7D.811:2369微指令分类微指令格式分成两类：水平型微指令和垂直型微指令（1）水平型微指令一次能定义并执行多个并行操作微命令的微指令，叫做水平型微指令11:2370微指令中设置微操作码字段，由微操作码规定微指令的功能，称为垂直型微指令其结构类似于机器指令的结构每条微指令的功能简单采用较长的微程序结构去换取较短的微指令结构（2）垂直型微指令11:2371垂直型微指令寄存器-寄存器传送型运算控制型访问主存条件转移11:23水平型微指令与垂直型微指令水平型微指令并行操作能力强，效率高，执行时间短、灵活性强微指令字较长，微程序短，控存容量大，性能佳垂直型微指令字长短，微程序长，控存容量小，性能差垂直型与指令相似，易于掌握7211:23微指令设计与微指令格式7311:2374微程序设计静态微程序设计微程序设计好之后，存放在ROM中，无法修改动态微程序设计采用EPROM/Flash作为控制存储器，微程序可以根据改变指令仿真在一台机器上实现不同类型的指令系统11:237511:235.5硬连线控制器硬连线控制器(Hard-wiredcontroller)也称为硬布线控制器把控制器看作产生控制信号的逻辑电路由门电路和触发器构成12返回1.基本思想输出信号微操作控制信号(微命令)CPU结构3LDIR(T4)LDDR(T3)PC+1LDPC(T4)RD(I)RD(D)WE(D)(T3)LDR(T4)LDAR(T4)CPU结构4LDIR(T4)LDDR(T3)PC+1LDPC(T4)RD(I)RD(D)WE(D)(T3)LDR(T4)LDAR(T4)每个操作控制信号的含义是：RD(I)—读指存RD(D)—读数存WE(D)—写数存LDPC—写入PCLDIR—写入IRLDAR—写入ARLDDR—写入DRPC+1LDR2—写入R2寄存器指令周期流程图5如何区分不同的CPU周期？指令周期流程图6如何区分不同的CPU周期？硬连线控制器时序设定M1、M2、M3三个电位信号，各自等于一个CPU周期每个CPU周期包括4个节拍脉冲（T1~T4）三级时序同步控制M1M2固定3个机器周期，12个节拍M3节拍电位硬连线控制器的指令周期流程图采用同步控制方式，将所有指令的指令周期都设为3个CPU周期图中M1、M2、M3为节拍电位信号，各自等于一个CPU周期MOV、ADD和JMP指令在M3不执行任何操作103.微操作控制信号产生在微程序控制器中微命令由微指令产生。在硬连线控制器中微命令由布尔代数表达式描述的输出函数产生。11硬连线控制器设计方法画出指令周期流程图，明确各节拍控制信号找出产生同一个微操作信号的所有条件，建立操作时间表与时序信号组合，写出逻辑表达式化简、用门电路或可编程器件物理实现。12[例3]根据图5.29，写出以下操作控制信号RD(I)、RD(D)、WE(D)、LDPC、LDIR、LDAR、LDDR、PC+1、LDR2的逻辑表达式。其中每个操作控制信号的含义是：RD(I)—指存读命令RD(D)—数存读命令WE(D)——数存写命令LDPC—打入程序计数器LDIR—打入指令寄存器LDAR—打入数存地址寄存器LDDR—打入数据缓冲寄存器PC+1—程序计数器加1LDR2—打入R2寄存器13LDIR(T4)LDDR(T3)PC+1LDPC(T4)RD(I)RD(D)WE(D)(T3)LDR(T4)LDAR(T4)每个操作控制信号的含义是：RD(I)—读指存RD(D)—读数存WE(D)—写数存LDPC—写入PCLDIR—写入IRLDAR—写入ARLDDR—写入DRPC+1LDR2—写入R2寄存器[例3]根据图5.1，写出以下操作控制信号RD(I)、RD(D)、WE(D)、LDPC、LDIR、LDAR、LDDR、PC+1、LDR2的逻辑表达式。解：（1）画出指令周期流程图15（2）列出微操作时间表（根据数据通路和操作流程图）16（2）列出微操作时间表（根据数据通路和操作流程图）列出在每个微命令在哪个电位、哪个节拍、哪个指令发产生？17（2）列出微操作时间表（根据数据通路和操作流程图）设M1、M2、M3是节拍电位信号；T1、T2、T3、T4为一个CPU周期中的节拍脉冲信号；MOV、LAD、ADD、STO、JMP是机器指令OP操作码字段译码输出信号18（3）进行微操作信号的组合得到如下逻辑表达式：LDIR=M1·T4LDAR=M2·T4·(LAD+STO)LDDR=M2·T3·(MOV+ADD)+M3·T3·LADPC+1=M1LDR2=M2·T4·ADD（4）最后给出电路（省略）硬连线与微程序控制器比较硬连线控制器执行速度快硬连线控制器设计复杂，代价昂贵微程序控制器设计简单，便于维护修改205.6.4PentiumCPU1989年初0.8um工艺，310万晶体管5V电压，功耗20W非固定长度指令格式，9种寻址方式，191条指令，兼具有RISC和CISC特性提供了更加灵活的存储器寻址结构，可以支持传统的4k大小的页面，也可以支持4M大小的页面（TLB）动态转移预测技术（BTB转移目标缓存）21Pentium结构图哈佛结构Cache2路超标量32位CPU80位FPU外部数据总线宽度为64位，外部地址总线宽度为32位微程序控制器225.7RISCCPU三个要素：(1)一个有限的简单的指令集；(2)配备大量的通用寄存器；(3)对指令流水线的优化编译技术5.7RISCCPURISC机器的特征：(1)使用等长指令（4B）(2)寻址方式少且简单(3)只有取数指令、存数指令访问存储器(4)指令数目相对较少，指令格式简单(5)指令功能简单，控制器多采用硬连线方式(6)指令的执行平均时间(CPI)为一个时钟周期。(7)配置大量寄存器、优化使用。(9)支持指令流水并强调指令流水的优化使用。(10)RISC技术的复杂性在它的编译程序23RISC与CISC的主要特征对比25MIPSAptiv框图硬布线控制器指令缓存数据缓存总线接口内存管理单元算术与逻辑运算器协处理器指令译码器通用寄存器浮点运算器26ARM处理器框图平均微程序为1.8条微指令本章重点内容CPU的功能（控制器的功能、6类寄存器）指令周期基本概念设计指令周期，画指令周期流程图时序产生器和控制方式基本原理微程序控制器工作原理微程序设计基本概念硬连线控制器基本概念本章容易混淆的一些概念周期表示一段时间。指令周期指机器指令从取指到执行完成所花的时间，包括取指周期和执行周期。CPU周期=机器周期，一个CPU周期包括多个节拍脉冲。节拍脉冲=T周期，处理操作的最基本单位指令周期＞CPU/机器周期＞节拍脉冲数据通路举例某机字长16位，指令16位定长；指令ADD(R1)，R0的功能为(R0)+((R1))(R1)，即将R0中数据与R1内容所指向的主存单元的数据相加，并将结果送入R1内容所指向的主存单元中；数据通路图中控制信号为1表示有效，假设MAR输出一直处于使能状态；数据通路举例---取指令周期C1C2C3MARMDRPCIR下表为取指令和译码阶段每个节拍(时钟周期)的功能和控制信号，请按相同方式给出执行阶段各节拍的功能和有效控制信号。数据通路举例---执行指令周期C1C2C3MARMDRA((R1))A数据通路举例---执行指令周期C4C5MARMDRAAC(R0)+((R1))(R1)5.6流水CPU5.6.1并行处理技术5.6.2流水CPU的结构5.6.3流水线中的主要问题5.6.4PentiumCPU15.6.1并行处理技术并行性的两种含义：同时性指两个以上事件在同一时刻发生；并发性指两个以上事件在同一时间间隔内发生。计算机的并行处理技术主要有以下三种形式：1.时间并行2.空间并行3.时间并行+空间并行21.时间并行让多个处理过程在时间上相互错开，轮流重叠地使用同一套硬件设备的各个部分，以加快硬件周转而赢得速度。实现方式是采用流水处理部件。目前的高性能微型机几乎无一例外地使用了流水技术。35.6.1并行处理技术5.6.1并行处理技术2.空间并行指资源重复（空间因素），以“数量取胜”VLSI为其提供了技术保证。3.时间并行+空间并行指时间重叠和资源重复的综合应用4流水线原理1.时间并行把任务分成若干子任务，使子任务在流水线的各阶段并发地执行2.空间并行资源重复多处理器系统和多计算机系统3.时间并行+空间并行时间重叠和资源重复的综合应用。奔腾CPU采用超标量流水技术，一个机器周期执行两条指令。指令周期细分取指令IF(InstructionFetch)指令译码ID(InstructionDecode)执行运算EX(Execution)访存阶段MEM结果写回WB(WriteBack)一条指令不一定经历所有阶段IFIDEXMEMWB非流水线时空图流水线时空图完成N条指令需要的时间5+(n-1)超标量流水线时空图时间TIFIDEXWB空间SI12I34I1I2I3I4I1I2I3I4I1I2I3I4I1I2I3I4具有两条以上的指令流水线。满载时，每一时钟周期可以执行2条指令I56I78流水线分类1.指令流水线取指---译码---取数---执行2.算术流水线加法器,乘法器,快速傅里叶变换器3.处理机流水线由一串级连的处理机组成.每台处理机负责某一特定任务.11一个计算机系统可以在不同的并行等级上采用流水线常见流水线有：处理机流水线：程序步骤的并行由一串级联的处理机构成流水线的各个过程段，每台处理机负责某一特定的任务。处理机流水线应用在多机系统中。指令流水线：指令步骤的并行将指令流处理过程分为取指令、译码、执行、写回等几个并行处理过程段。算术流水线：运算操作步骤的并行如流水加法器、流水乘法器、流水除法器等。3.流水线分类流水线的相关冲突（hazzard）资源相关取操作数与取指令都需要访问主存计算PC、分支地址，运算指令复用ALU增加部件消除数据相关指令操作数依赖于前一条指令的执行结果引起流水线停顿直到数据写回分支相关转移指令使得流水线发生中断提前取出的指令作废，流水线清空理想指令流水线将指令过程分成5个阶段IF、ID、EX、MEM、WB不同阶段之间设置缓冲接口部件（绿色部分）接口部件本质是寄存器各段通过接口传递与指令相关的数据，控制，反馈信息对数据的加工处理依赖于前段接口传递过来的信息MIPS经典5段流水线14流水线段间寄存器5.6.3流水线中的主要问题流水线要有良好的性能，必须能够畅通流动，不发生断流流水过程中通常会出现以下三种相关冲突（Hazard），使流水线断流。1.资源相关2.数据相关3.控制相关15数据相关处理增加相关检测判定逻辑当前指令读寄存器与后续3条指令写寄存器相同当前指令可能有0~2个读寄存器后续3条指令可能有0~1个写寄存器相关处理逻辑流水线停顿数据重定向-16-数据相关处理机制软件方法（编译器完成）插入空指令调整程序顺序，使相关性在流水线中消失硬件方法寄存器堆写入和读出分离（先写后读，下跳沿写）插入气泡（空操作）数据重定向bypass（数据旁路）将后端处理后的数据（还没来得及写回）重定向数据在哪就从哪送到运算器1.资源相关多条指令进入流水线后在同一段时间内争用同一个功能部件所发生的冲突。在时钟4时，I1与I4两条指令发生争用存储器资源的相关冲突解决资源冲突的办法：(1)冲突指令停顿若干周期，直到冲突消失；(2)增设一个存储器，将指令和数据分别放在两个存储器中。182.数据相关在流水计算机中，由于多条指令的重叠处理，当后继指令所需的操作数，刚好是前一指令的运算结果时，便发生数据相关冲突。如下表所示，ADD指令与SUB指令发生了数据相关冲突。202.数据相关例：两条指令发生数据相关冲突ADDR1,R2,R3R2+R3-->R1SUBR4,R1,R5R1-R5-->R4ANDR6,R1,R7R1^R7-->R62.数据相关RAW(ReadAfterWrite)后面指令用到前面指令所写的数据WAW(WriteAfterWrite)两条指令写同一个单元WAR(WriteAfterRead)后面指令覆盖前面指令所读的单元解决办法：可以推后后继指令对相关单元的读操作设置转发通路（Forwarding）21【例4】流水线中有三类数据相关冲突：写后读相关；读后写相关；写后写相关。判断以下三组指令各存在哪种类型的数据相关。I1:ADDR1，R2，R3；(R2)+(R3)->R1I2:SUBR4，R1，R5；(R1)-(R5)->R4(2)I3:STOM(x)，R3；(R3)->M(x)，M(x)是存储器单元I4:ADDR3，R4，R5；(R4)+(R5)->R3I5:MULR3，R1，R2；(R1)×(R2)->R3I6:ADDR3，R4，R5；(R4)+(R5)->R3写后读RAW相关读后写WAR相关写后写WAW相关233.控制相关由转移指令引起的。当前指令有跳转，但流水已经开启后续指令处理过程解决技术：延迟转移法由编译程序重排指令序列，让跳转的指令接在最后流水入口转移预测法用硬件预测将来的行为，提前让转移指令进流水。指令调度为了充分发挥指令流水线的效率，减小断流，降低指令间的相关性，在保证程序正确执行的前提下，需要对指令的执行顺序进行重新编排静态调度由编译器在编译过程中对指令进行调度动态调度由控制器在指令执行过程中进行调度，对程序员透明乱序执行（OutOfOrder）记分牌算法，Tomasulo算法255.6.4PentiumCPU1989年初0.8um工艺，310万晶体管5V电压，功耗20W非固定长度指令格式，9种寻址方式，191条指令，兼具有RISC和CISC特性提供了更加灵活的存储器寻址结构，可以支持传统的4k大小的页面，也可以支持4M大小的页面（TLB）动态转移预测技术（BTB转移目标缓存）26Pentium结构图哈佛结构Cache2路超标量32位CPU80位FPU外部数据总线宽度为64位，外部地址总线宽度为36位微程序控制器27IntelHaswell结构图285.7RISCCPU三个要素：(1)一个有限的简单的指令集；(2)配备大量的通用寄存器；(3)对指令流水线的优化编译技术5.7RISCCPURISC机器的特征：(1)使用等长指令（4B）(2)寻址方式少且简单(3)只有取数指令、存数指令访问存储器(4)指令数目相对较少，指令格式简单(5)指令功能简单，控制器多采用硬连线方式(6)指令的执行平均时间(CPI)为一个时钟周期。(7)配置大量寄存器、优化使用。(9)支持指令流水并强调指令流水的优化使用。(10)RISC技术的复杂性在它的编译程序29RISC与CISC的主要特征对比多周期流水线3132MIPSAptiv框图硬布线控制器指令缓存数据缓存总线接口内存管理单元算术与逻辑运算器协处理器指令译码器通用寄存器浮点运算器33ARM处理器框图平均微程序为1.8条微指令本章重点内容CPU的功能（控制器的功能、6类寄存器）指令周期基本概念五种基本指令的指令周期及其数据通路流程时序产生器和控制方式基本原理微程序控制器工作原理微程序设计基本概念硬连线控制器基本概念本章容易混淆的一些概念微命令控制部件通过控制线向执行部件发出的各种控制命令微操作执行部件接受微命令以后所进行的操作公操作一条指令执行完毕以后，CPU所进行的操作本章容易混淆的一些概念微指令在机器的一个CPU周期中，一组实现一定操作功能的微命令的组合，构成一条微指令微程序:一条指令均对应一段微程序，微程序固化在控制存储器中。机器指令本章容易混淆的一些概念周期表示一段时间。指令周期指机器指令从取指到执行完成所花的时间，包括取指周期和执行周期。CPU周期=机器周期，一个CPU周期包括多个节拍脉冲。节拍脉冲=T周期，处理操作的最基本单位指令周期＞CPU/机器周期＞节拍脉冲1第六章总线系统6.1总线的概念和结构形态6.2总线接口6.3总线仲裁6.4总线的定时和数据传送模式6.5PCI总线和PCIe总线6.1.1总线的基本概念总线(BUS)是构成计算机系统的互连机构是多个系统功能部件之间进行数据传送的公共通路借助于总线各系统功能部件之间实现地址、数据和控制信息的交换在争用资源的基础上进行工作26.1.1总线的基本概念一个单处理器系统中的总线大致分为：内部总线：CPU内连接各寄存器及运算器部件之间的总线系统总线：CPU和其他高速功能部件（如存储器、通道等）相互连接的总线I/O总线：中低速I/O设备相互连接的总线3物理特性：总线的物理连接方式，包括根数、插头形状，引脚线的排列方式功能特性：描述总线中每一根线的功能：地址、数据、控制三类电气特性：定义每一根线上信号的传递方向（单/双向）及有效电平范围时间特性：规定了总线上各信号有效的时序关系，每根总线在什么时间有效41.总线的特性2.总线的标准化对总线的四个特性定义一个广泛认可的标准实现不同厂家的功能部件互换使用USB、PCI-E53.总线带宽6常见总线带宽86.1.2总线的连接方式外围设备和总线的连接部件称为适配器(adapter)：完成CPU和外设之间的数据传送和控制实现传输速率匹配和同步；通常称为接口(interface)96.1.2总线的连接方式总线影响计算机系统性能，单处理器计算机中采用的总线结构有两种基本类型：单总线结构和多总线结构单总线结构CPU是主控设备（发起通信的设备）结构简单、容易扩充多部件共享总线，分时工作传输效率低处理器结构对总线有影响10112.多总线结构主要解决各种设备速率不匹配的问题位于CPU内部，速度最快连接主存高速I/O设备低速I/O设备连接不同速率的总线总线的效率和吞吐量得以提高高速、中速、低速设备连接到不同的总线上同时进行工作现代计算机中的多总线结构126.2总线接口6.2.1信息的传送方式计算机系统中，传输信息有两种方式：串行传送并行传送131.串行传送按顺序传送一个数码（一个字节）的所有二进制位(bit)，每次一位一般先传低位，后传高位使用一条物理传输线：单端传输两条传输线：差分传输数据传送前：并—串变换数据接收后：串—并变换141.串行传送特点：成本较低、速度慢位时间：每个比特在传输线上占用的时间长度波特率(baud)：每秒钟传送的比特数波特率是位时间的倒数串行传送的数据格式编码起始位(1b)+数据位(1B)+校验位(1b)+停止位(1b)1516【例2】利用串行方式传送字符，设数据传送速率是120个字符/秒，每一个字符格式规定包含10个比特位（起始位、停止位、8个数据位）问波特率是多少?位时间是多少?【解】：波特率为：10位×120/秒=1200波特位时间是波特率的倒数：Td=1/1200=0.833×10-3s=0.833ms2.并行传送同时传输多个比特，对每个数据位都需要单独一条传输线数据传送比串行数据传送快得多（传输频率较低时）17发展趋势并行传输距离受限频率越高，线间串扰越严重，带宽无法继续提高串行传输距离长无串扰现象、提供更高的带宽随着总线频率的增加，并行逐渐转向串行SCSISASPATASATAPCIPCI-E183.分时传送功能复用：某个传输线上既传送地址信息，又传送数据信息分时复用：共享总线的部件分时使用总线必须划分时间片196.2.2总线接口的基本概念I/O接口即I/O设备适配器指CPU和主存、外围设备之间通过总线进行连接的标准化逻辑部件I/O接口部件在连接的两个部件之间起着“转换器”的作用，实现彼此之间的信息传送一个接口可连接一个设备，也可连接多个设备206.2.2总线接口的基本概念外部设备有自己的设备控制器设备控制器通过I/O接口和总线连接，进而与CPU交换信息外围设备的连接方法6.2.2总线接口的基本概念一个适配器的两个接口：连接系统总线的接口连接外设的接口接口的典型功能：控制、缓冲、状态、转换、整理、程序中断226.3总线仲裁总线上的设备有主方和从方两种形态主方启动一个总线周期、从方响应主方请求每次总线操作，只能有一个主方，可以有多个从方为了解决多个主方争用总线的问题，设置总线仲裁部件（arbitrator）采用优先级策略或公平策略按照总线仲裁电路的位置不同，分为集中式和分布式231.集中式仲裁一个中央仲裁器，连接线：送往仲裁器的总线请求信号线BR(BusRequest)仲裁器送出的总线授权信号线BG(BusGrant)表征总线是否空闲的信号BS（BusBusy）集中式仲裁采用三种方式(1)链式查询方式（菊花链查询-Daisychain）(2)计数器定时查询方式(3)独立请求方式24(1)链式查询方式接口发出总线请求信号BR（置BR为高）仲裁器在总线空闲的时候（BS为低）开始仲裁总线授权信号BG依次从一个I/O接口传送到下一个I/O接口（串行查询）假如BG到达的接口无总线请求，则继续往下传递；假如BG到达的接口有总线请求，该接口获得总线控制权（将BS置为1），BG信号便不再往下传递25BS--总线忙BR--总线请求BG--总线授权查询过程(1)链式查询方式特点：优先级固定：离仲裁器最近的设备具有最高优先级，离仲裁器越远，优先级越低用线少，易扩充;对查询链的电路故障很敏感，单点故障26(2)计数器定时查询方式每个设备分配一个地址，设备内部有地址判别电路仲裁器内部有个计数器，其输出和设备地址线连接对设备地址计数27(2)计数器定时查询方式设备通过BR线发出总线请求仲裁器在BS为低时让计数器开始计数，计数值通过设备地址线广播设备内部的地址判别电路，判断地址线上的计数值与自身设备地址是否一致如果一致且该设备的BR为高，获得了总线使用权，则置BS线为1如果没有设备获得总线使用权，计数值加一，再次广播仲裁器判断BS为高，中止计数查询2829(2)计数器定时查询方式每次计数可以从“0”开始，也可以从中止点开发始固定优先级：每次从“0”开始计数，优先级的顺序是固定的公平优先级：从中止点开始计数，每个设备都有可能成为最高优先级可变优先级：软件修改计数器初值缺点：控制线较多、扩展性较差（与计数器的位数有关）计数器(3)独立请求方式每个设备均有独立的总线请求线BRi和总线授权线BGi中央仲裁器中的排队电路决定首先响应哪个设备的请求，给设备以授权信号Bgi特点：响应速度快控制灵活，优先级可通过程序改变；控制线数多、总线裁决机构较复杂30312.分布式仲裁每个功能设备都有自己的仲裁号以及仲裁器仲裁过程通过协商完成6.4.1总线的定时总线信息传送过程，可分为：请求总线，总线仲裁，寻址，信息传送，状态返回定时：事件出现在总线上的时序关系同步定时：事件出现在总线上的时刻由总线时钟信号确定总线信号中包含公共时钟线异步定时：建立在应答式或互锁机制基础上后一事件出现在总线上的时刻取决于前一事件的完成不需要统一的公共时钟信号326.5PCI总线和PCIe总线PCI-（PeripheralComponentInterconnect）是美国SIG推出的32～64位总线（并行总线）频率为33～66MHz，数据传输率为132～528MB/s基于PCI总线计算机结构处理器处理器主存控制器主存PCI设备PCI设备HOST桥主设备目标设备PCI/LAGACY总线桥PCI/PCI桥LAGACY设备LAGACY设备PCI设备PCI设备HOST总线PCI总线PCI总线LAGACY总线（遗留）现代计算机中的多总线结构35PCI总线特点允许智能设备在适当的时候取得总线控制权以加速数据传输和对高度专门化任务的支持支持猝发传输模式与ISA／EISA／MCA兼容设有特别的缓存，实现外设与CPU隔离，外设或CPU的单独升级都不会带来问题同步时序、集中式仲裁PCIExpress总线PCIExpress是一种基于串行技术、高带宽连接点、点到点连接的新型总线技术PCIExpress采用4根信号线差分传输，全双工、可靠性高、速度快多种连接方式，扩展性好如×1、×4、×8、×16以及×32通道的连接器支持热插拔和热交换软件层与PCI兼容37PCIExpress总线PCIExpress总线插槽38PCIExpress总线39共享式hub独占式switchUSB（UniversalSerialBus）由Compaq、Intel、Microsoft、NEC等公司于96年共同研制发布传输速度高、使用简单、编程复杂适合计算机中所有高、中、低速传输外部总线USB1.1/2.04线传输、半双工USB（UniversalSerialBus）USB3.0全双工Type-C物理接口不区分正反面USB标准演进42USB标准演进431第七章外围设备7.1外围设备概述7.2磁盘存储设备7.3磁带存储设备7.4光盘和磁光盘存储设备7.5显示设备7.6输入设备和打印设备7.1.1外围设备的一般功能外围设备又称外部设备：功能:在计算机和其他设备之间，以及计算机与用户之间提供联系每一种外围设备，都是在它自己的设备控制器控制下进行工作，而设备控制器则通过I/O接口和主机相连，并受主机控制7.2磁盘存储设备磁表面存储：将磁性材料涂在载磁体（铝或塑料）存储信息磁盘存储器、磁带存储器优点：存储容量大，位价格低；可以重复使用；信息可以长期保存；缺点：存取速度较慢，机械结构复杂31.磁性材料物理特性B---磁感应强度H---外加磁场强度I----电流2.磁表面存储器的读写原理利用磁头来形成和判别磁性材料的不同磁化状态磁性材料排列方式磁性材料均匀排列在圆形载磁体上水平排列密度低、容量小垂直排列密度高、容量大7.2.2磁盘的组成和分类目前硬磁盘主要是温彻斯特磁盘，简称温盘，是一种可移动磁头固定盘片的磁盘机密封组合、悬浮磁头防尘性能好，可靠性高，对使用环境要求不高7优点：没有摩擦、寿命长硬盘磁头与盘片的接触方式：悬浮式优点：没有摩擦、寿命长温盘原理101.44MB软盘软盘：固定磁头，可移动盘片硬磁盘驱动器主要3个部件组成定位驱动系统：控制磁头臂径向运动主轴系统：控制磁盘旋转数据转换系统：磁电互换117.2.3硬盘驱动器和控制器7.2.4磁盘上信息的分布盘片的上下两面都能记录信息，称为记录面（surface）一个记录面对应一个磁头（Head），用磁头表示记录面记录面上一系列同心圆称为磁道（Track）由外向内依次编号，最外侧为0磁道每个磁道等弧度分为若干个扇区（Sector）信息按扇区存放，每个扇区的存储信息量是相同的，为512B127.2.4磁盘上信息的分布扇区之间有间隙(gap)，用于隔离扇区spindlesurfacetrackstrackksectorsgaps磁头和盘片的运动盘片旋转磁头悬浮，沿半径方向运动.-14-7.2.4磁盘上信息的分布所有记录面上相同编号的磁道形成一个圆柱面(Cylinder)，简称柱面柱面数等于磁道数柱面是逻辑、虚拟概念所有磁盘统一转动，所有磁头一起移动磁盘访问过程：1.OS计算出要访问的位置(C、H、S)2.控制磁头移动到对应的柱面3.磁盘旋转到起始扇区4.磁盘继续旋转，磁头开始读写信息15硬盘上的一个扇区要用三个参数来定位（CHS模式）：柱面号、磁头号、扇区号标准记录格式硬盘容量=柱面数×磁头数×扇区数×512字节7.2.4磁盘上信息的分布7.2.4磁盘上信息的分布如果某文件长度超过一个磁道的容量，应将它记录在同一个记录面上，还是记录在同一个柱面上?17磁头的移动都需要时间，而且在磁盘访问总时间中占比较大如果某文件长度超过一个磁道的容量，应将它记录在同一个柱面上，因为不需要移动磁头，读/写速度快7.2.4磁盘上信息的分布柱面号10位，磁头号8位，扇区为6位，得到CHS模式容量限制8.4G现代磁盘采用LBA（逻辑区块地址(LogicalBlockAddress）187.2.5磁盘存储器的技术指标存储密度：道密度：沿磁盘半径方向单位长度上的磁道数位密度：磁道单位长度上能记录的二进制位数面密度：位密度和道密度的乘积一个磁盘存储器所能存储的字节总数，称为磁盘存储器的存储容量格式化容量和非格式化容量197.2.5磁盘存储器的技术指标20217.2.5磁盘存储器的技术指标磁盘存取时间23【例1】磁盘有6片磁盘，每片有两个记录面，最上最下两个面不用存储区域内径22cm，外径33cm，道密度为40道/cm，内层位密度400位/cm，转速6000转/分问：(1)共有多少柱面?(2)总存储容量是多少?(3)数据传输率多少?24解：(1)共有多少柱面?有效存储区域=16.5-11=5.5(cm)因为道密度=40道/cm，共有40×5.5=220道，即220个圆柱面(2)总存储容量是多少?内层磁道周长为2πR=2×3.14×11=69.08(cm)每道信息量=400位/cm×69.08cm=27632位=3454B每面信息量=3454B×220=759880B总容量=759880B×10=7598800B(3)数据传输率多少?磁盘数据传输率Dr=rNN为每条磁道容量，N=3454Br为磁盘转速，r=6000转/60秒=100转/秒Dr=rN=100×3454B=345400B/s-25-硬盘发展趋势充氦气：缩短碟片距离，增加碟片数量4K扇区：与OS文件管理匹配，减少扇区浪费叠瓦SMR、二维TDMR、微波辅助磁记录(MAMR)、热辅助磁记录(HAMR)增大单碟容量容量将到达100TB26固态硬盘固态硬盘SSD（solidstateDisk）由控制单元和ROM存储单元（FLASH芯片）组成速度快、抗震、零噪音、重量轻等优点28297.3磁带存储设备磁带的记录原理与磁盘基本相同，只是它的载磁体是一种带状塑料，叫做磁带磁带采用顺序访问方式，速度比磁盘速度慢通常用作为数据备份的海量存储设备307.4光盘和磁光盘存储设备光盘上的信息以坑点形式分布凹坑表示“1”，凸点表示为“0”读出时，当激光束照射在凹坑上时反射率低；而照射在凸点上时反射率高根据反射光的光强变化并进行光电转换，即可读出记录信息只读型CD光盘CD-DA数字唱盘，记录数字化信息，74分钟数字立体声信息CD-ROM容量640MB可写CD写一次型CD-R利用激光改变有机染料记录面对光的反射率可多次的重复写入磁光盘CD-MO(Magneto-Optical)利用激光产生高温来改变磁场CD-RW(Rewritable)利用激光改变相变材料的晶态和非晶态两种状态DVDDVD使用较短波长的激光束，使盘片数据的密度达4.7GB，是CD产品容量的7倍，如果采取双面双层的记录方式，容量更可高达17GBDVD-ROMDVD-VideoDVD-AudioDVD-RDVD-RAM-33-不同盘片比较TrackPitch:1.6μmMinimumPitLength：0.8μmStorageDensity:0.41Gb/inch2TrackPitch:0.74μmMinimumPitLength：0.4μmStorageDensity:2.77Gb/inch2TrackPitch:0.32μmMinimumPitLength：0.15μmStorageDensity:14.73Gb/inch2CD0.7GBDVD4.7GBBlu_rayDisc25GB-34-光驱的速度1倍速CD在1小时内读完一张CD盘的速度定义为1倍速，150KB/SDVD的1倍速则在1350KB/s左右X倍速：指是最初光驱读取速率的多少倍的读取速率的光驱1第八章输入输出系统8.1CPU和外设之间的信息交换方式8.2程序查询方式8.3程序中断方式8.4DMA方式8.5通道方式8.6通用I/O标准接口返回8.1CPU与外设之间的信息交换方式I/O设备同CPU交换数据的过程：输入过程：(1)CPU把一个地址放在地址总线，选择某一输入设备；(2)CPU等候输入设备的数据有效；(3)CPU从数据总线读入数据，并放在一个相应的寄存器中输出过程：(1)CPU把一个地址放在地址总线，选择输出设备；(2)CPU把数据放在数据总线上；(3)输出设备认为数据有效，从而把数据取走问题的关键在于：如何找到对应的外部设备?编址方式什么时候数据才有效?定时方式2外围设备编址方式编址对象I/O设备中的控制寄存器、数据寄存器、状态寄存器3外围设备编址方式:独立编址（IsolatedI/O）内存单元和I/O寄存器各自独立编址：两个地址空间I/O寄存器地址称为端口号访问I/O寄存器有专门的I/O指令X86：out80H,AX4外围设备编址方式:统一编址也称为内存映射I/O：MemoryMappedI/O，MMIOI/O寄存器和内存单元一起编址：一个地址空间同一地址空间中的不同部分来区分I/O寄存器和内存单元访存指令访问I/O设备和内存，Load/StoreARM、RISC-V、MIPS5MIPS处理器内存映射I/O6【例1】假设有一个运行时间为100秒的基准程序，其中90秒是CPU时间，剩下的是I/O占用的时间如果在以后的5年里，CPU的速度每年提高50%但I/O时间保持不变，那么5年后运行程序要耗费多少时间？I/O时间所占的比例是多少?解：耗费的时间=CPU时间+I/O时间目前，I/O时间=100-90=10秒今后五年内CPU时间、I/O时间及其所占比例如下表：外设定时如何判断数据有效是外设定时的关键根据外围设备的速度分为3种定时：速度极慢或简单的外围设备(机械开关，显示二极管)直接输入输出慢速或中速的外围设备异步定时高速的外围设备同步定时8.1.4CPU与I/O接口之间的数据传送CPU管理外围设备的方式：无条件传送方式（简单I/O方式）程序查询方式程序中断方式直接内存访问(DMA)通道方式单片机多采用程序查询、程序中断PC采用程序中断和DMA通道方式用在大型计算机中98.2程序查询方式又叫程序控制I/O方式当需要输入/输出时，CPU暂停执行主程序，转去执行设备输入/输出的服务程序，进行数据传输异步定时：查询设备状态，判断是否有效103、程序查询方式的接口11设备选择电路用于判断地址总线上呼叫的设备是否为本设备数据缓存寄存器缓存从外设读出的数据或者CPU输出到外设的数据设备状态标志用于标志设备的工作状态，4、程序查询输入/输出方式信息交换完全由CPU执行程序实现启动设备;反复查询设备直至设备准备好;传输单个数据重复2-3步直至数据传输完毕CPU和外设串行工作，反复查询设备状态占用较多CPU时间，系统效率低CPU占用率取决于查询频率用于单片机4、程序查询输入/输出方式有多个设备时，CPU周期性地(轮询)调用各I/O设备的子程序138.2程序查询方式处理器速度为10MIPS，I/O设备为键盘，其操作速度为10字符/s，采用程序查询方式进行控制，那么对于每个输入操作，CPU等待的时间可以执行__万条指令148.2程序查询方式特点：数据传输完全依赖于程序控制硬件结构简单频繁的查询动作浪费了大量的CPU时间实时性差，随机事件响应慢目前只用在单片机中168.3程序中断方式8.3.1中断的基本概念8.3.2中断服务程序入口地址的获取8.3.3程序中断方式的基本I/O接口8.3.4单级中断8.3.5多级中断8.3.6Pentium中断机制8.3.1中断的基本概念中断（Interrupt）是指CPU暂时中止现行程序，转去处理随机发生的事件，处理完后自动返回原程序的功能和技术也称为异常(exception)中断系统是计算机实现中断功能的软硬件总称一般在CPU中设置中断机构在外设接口中设置中断控制寄存器在软件上设置相应的中断服务程序178.3.1中断的基本概念中断源:产生中断的事件与I/O设备信息交换：网络通信故障处理：硬件故障：掉电、校验错软件故障：溢出、除数0实时事件处理：键盘、鼠标程序调度，时间片划分软中断188.3.1中断的基本概念中断处理过程：某一外设的数据准备就绪后，“主动”向CPU发出中断请求信号；当CPU响应此中断，暂停运行主程序，自动转去该设备的中断服务程序；当中断服务程序执行完毕后，CPU又回到原来的主程序继续执行中断适合于处理随机出现的事件198.3.1中断的基本概念响应中断的时机什么时候对外设的中断请求进行响应？断点保护问题如何在处理完中断后正确返回主程序？多重中断处理中断处理过程中又有外设发出中断请求怎么办？中断功能实现的软硬件分工哪些功能用软件实现，哪些功能需要硬件支持？208.3.1中断的基本概念21单级中断处理过程流程图(1)响应中断的时机外设的中断请求存放在接口中的中断源锁存器里，并通过中断请求线连至CPU外设的中断请求是随机的，CPU只有在当前指令执行完毕，转入公操作时才受理中断请求(2)断点保护问题:正确返主程序断点：主程序被中断的地方（PC）现场：当前指令执行结束后CPU的状态(包括寄存器值和一些状态标志位)保存现场：现场保存到堆栈中恢复现场从堆栈中恢复PC和CPU状态，以便从断点处继续执行主程序(3)多重中断处理中断处理过程中又有新外设发出中断请求怎么办？在CPU中有一个中断屏蔽寄存器置“1”(设置屏蔽)，关中断，不受理中断请求置“0”(取掉屏蔽)，开中断，受理中断请求可以通过程序控制实现中断嵌套(4)中断功能实现的软硬件分工中断周期的操作由硬件实现也称为“中断处理的隐操作”，程序员看不到响应中断、关中断、保存断点、找出中断源顺序很重要中断服务程序由软件实现保存现场、对发起中断的设备服务、恢复现场、开中断、返回主程序8.3.2中断服务程序入口地址的获取转移到中断服务程序：找到中断服务程序的入口地址向量中断：当CPU响应中断时，由硬件直接产生一个地址(即向量地址)向量地址:设备的中断服务程序入口地址查询中断：硬件为所有中断安排一个公共的中断服务程序该公共程序查询并跳转至相应中断服务程序入口268.3.3程序中断方式的基本I/O接口:向量中断27准备就绪的标志(RD-Ready)允许中断寄存器(EI-EnableInterrupt)中断请求寄存器(IR-InterruptRequest)中断屏蔽寄存器(IM-InterruptMask)8.3.3程序中断方式数据输入的执行过程28①由程序启动外设，将该外设接口的BS标志置“1”，RD标志清“0”；②接口向外设发出启动信号；④当设备动作结束或数据缓冲寄存器填满时，设备送出控制信号，将RD置“1”；⑧设备的中断向量逻辑讲中断向量发到数据总线，CPU将中断向量赋值给PC，跳转到中断服务程序③外设传送数据到接口的数据缓冲寄存器；⑤当EI为“1”时，接口向CPU发出中断请求；⑥在一条指令执行公操作时，CPU检查IR寄存器如果标志IM为“0”，进入中断周期；⑨中断服务程序把接口中数据缓冲寄存器的数据读至CPU中的寄存器；（10）CPU发出控制信号C将接口中的BS和RD标志复位⑦CPU受理中断请求，向外设发出中断响应信号INTA并关闭中断；8.3.4单级中断所有中断源通过INTA链式查询方式连接，属于同一级离CPU近的中断源优先权高不允许任何中断源打断中断服务程序，即使优先权比它高也不能CPU中有1个IM，1个IR29INTA：InterruptAuthorization中断授权信号单级中断源的识别串行排队链法IR1，IR2，IR3为中断请求信号IS1，IS2，IS3为中断选中信号308.3.5多级中断中断源分成多个级别两级优先权每级有一个级别优先权每级内又有级内优先权中断级别高的中断源可以打断级别低的中断源，称为中断嵌套31328.3.5多级中断一维多级中断：每级中断只有一个中断源二维多级中断：每级中断有多个中断源一个系统有n级中断，则CPU中有n个IR，n个IM338.3.5多级中断某级中断被响应后，则关闭本级和低于本级的IM，开放更高级的IM不同级别的中断可以嵌套，但同一级的中断不允许嵌套中断服务程序中使用多级堆栈保存现场（包括IM）中断请求的处理方法:单级中断优先权顺序：A>B>C中断请求到达顺序中断请求的处理方法:多级中断优先权顺序：A>B>C中断请求到达顺序多级中断源的识别采用了独立请求方式和链式查询方式相结合的方式级间采用独立请求方式优先排队电路中断向量产生电路级内采用链式查询方式36开放和屏蔽中断屏蔽中断指CPU中的中断屏蔽寄存器IM置1处于“关中断”所有可屏蔽中断源的中断请求得不到响应开放中断指CPU中的IM置0处于“开中断”可以响应中断源的中断请求37允许和禁止中断禁止中断指某个中断源接口中的中断允许寄存器EI被置0对应的中断源不能发出中断请求处于“中断封锁”允许中断中断接口中的EI置1中断源处于“中断开放”允许中断源发出中断请求38【例1】参见图所示的二维中断系统请问：(1)在中断情况下，CPU和设备的优先级如何考虑?请按降序排列各设备的中断优先级【解】(1)在中断情况下，CPU的优先级最低各设备的优先次序降序排列是：A→B→C→D→E→F→G→H→I→CPU39(2)若CPU现执行设备B的中断服务程序，IM2，IM1，IM0的状态是什么?如果CPU执行设备D的中断服务程序，IM2，IM1，IM0的状态又是什么?【解】执行设备B的中断服务程序时IM2IM1IM0=111；执行设备D的中断服务程序时，IM2IM1IM0=011多级中断中，某级中断被响应后，则关闭本级和低于本级的IM，开放更高级的IM40(3)每一级的IM能否对某个优先级内的个别设备单独进行屏蔽?如果不能，采取什么办法可达到目的?【解】(3)每一级的IM标志不能对某个优先级内的个别设备进行单独屏蔽。可将接口中的EI(中断允许)标志清“0”，它禁止设备发出中断请求41(4)假如设备C一提出中断请求，CPU立即进行响应，如何调整才能满足此要求?【解】(4)要让设备C的中断请求及时得到响应，可将设备C从第2级取出来，单独放在第3级上，使第3级的优先级最高即可42【例2】参见图8.9所示的系统，只考虑A，B，C三个设备组成的单级中断结构，它要求CPU在执行完当前指令时对中断请求进行服务假设：(1)CPU“中断批准”机构在响应一个新的中断之前，先要让被中断的程序的一条指令一定要执行完毕；(2)TDC为查询链中每个设备的延迟时间；(3)TA，TB，TC分别为设备A，B，C的服务程序所需的执行时间；(4)TS,TR为保存现场和恢复现场所需的时间；(5)主存工作周期为TM试问：就这个中断请求环境来说，系统在什么情况下达到中断饱和?43例假定多级中断，其中断优先级由低到高为L0→L1→L2，试设置中断屏蔽字，将中断优先级由低到高改为L1→L2→L0原先的屏蔽字例假定多级中断，其中断优先级由低到高为L0→L1→L2，试设置中断屏蔽字，将中断优先级由低到高改为L1→L2→L0新的屏蔽字A、B、C是与主机连接的3台设备，采用多级中断实现中断优先级处理，其各自的中断服务程序中对中断屏蔽码的设置如下表所示:解：从中断屏蔽字看出，其处理优先级为：A>C>B>CPU故CPU执行程序轨迹如下：A服务B服务C服务CPUABC204060808.3.6Pentium中断机制1.中断类型Pentium有两类中断：中断和异常中断通常称为外部中断，由外部硬件信号引发有两种情况：(1)可屏蔽中断：可通过CPU中标志寄存器屏蔽(2)非屏蔽中断：这类中断不能被屏蔽异常由指令执行引发(1)执行异常：执行一条指令过程中出现错误、故障等(2)执行软件中断指令：如执行INT0，INT3，INTn等指令Pentium共有256种中断和异常，每一个有中断向量号(0～255)中断优先级分为5级482.中断服务程序中断服务程序的入口地址信息存于实模式为中断向量表IVT保护模式为中断描述符表IDTPentium取得中断向量号的途径有三种：(1)指令给出：INT20H(2)外部提供：8259中断控制器(3)CPU识别错误、故障现象49508.4DMA方式8.4.1DMA的基本概念8.4.2DMA传送方式8.4.3基本的DMAC8.4.4选择型和多路型DMAC121:398.4.1DMA的基本概念DirectMemoryAccess：直接内存访问完全由硬件执行I/O数据交换DMAC（DMAController）接管对总线的控制数据交换不经过CPU，直接在内存和I/O设备之间进行DMAC向内存发出地址和控制信号用于高速传送成组数据21:3928.4.1DMA的基本概念优点数据传输速度快省去了CPU取指令、取数、送数等操作没有保存现场、恢复现场之类的工作主存地址的修改、传送字个数的计数用硬件实现21:3938.4.1DMA的基本概念基本操作：(1)外围设备发出DMA请求；(2)CPU响应请求，DMAC接管总线的控制；单总线系统中CPU具有总线仲裁功能(3)DMAC对内存寻址，即决定数据传送的内存地址及传送个数，并执行数据传送的操作；(4)向CPU报告DMA操作结束数据传送前的准备，传送结束后的处理，均由程序承担，而DMAC仅负责数据传送的工作21:3948.4.2DMA传送方式DMA方式进行数据传送时，CPU仍执行主程序DMAC与CPU可能同时要访问主存，引起冲突处理访存冲突1.停止CPU访问内存2.周期挪用3.DMAC与CPU交替访内存原则：I/O的数据要尽快处理，以防丢失521:391.停止CPU访问内存DMAC使用总线，控制内存，CPU处于等待状态优点：控制简单缺点：内存的效能没有充分发挥621:39一个数据块的传送过程2、周期挪用CPU让出一个或多个周期（内存读/写周期）的总线控制权，由DMAC挪用，进行一次数据传送传送结束后，CPU继续工作重复，直到数据块传送完较好地发挥了内存和CPU的效率21:39783、DMAC和CPU交替访问内存工作周期分为C1和C2两个子周期，一个供CPU访存，一个供DMAC访存总线分时控制适合DMAC频繁访问内存的场合硬件逻辑复杂DMA传送效率很高，没有总线申请时间21:3998.4.3基本的DMAC1、DMAC的基本组成21:392、DMAC数据传输过程10三个阶段：传送前预处理、正式传送、传送后处理停止CPU访内方式的DMA流程图21:392、DMA数据传输过程传输前，主机向DMAC传送以下信息(软件)：测试设备状态向内存地址计数器送数据块在内存中的首地址启动设备向字计数器送数据字个数这些工作做完之后，CPU继续原来的工作1121:392、DMA数据传输过程数据传送阶段（硬件）：外设准备好收发数据，由DMAC向主机发DMA请求CPU响应该请求，让出总线使用权DMAC接管总线控制权，发送内存地址、读/写命令每传送一个字，内存地址计数器加1，字计数器加1若字计数器为0时，进入传送后处理阶段传送后处理阶段（软件）：DMAC向CPU发出中断请求，报告数据传送结束1221:398.4.4选择型和多路型DMAC1.选择型(selectorDMAC)物理上可以连接多个设备：物理多个同时只能为一个设备服务：逻辑一个21:39132.多路型DMACMultiplexerDMAC物理上连接多个外围设备：物理多个允许外围设备同时工作：逻辑多个适合于同时为多个慢速外围设备服务每个DMA通路都有独立的寄存器组保存各自的传送参数21:3914DMA方式与中断方式比较数据传送方式不同中断方式通过程序实现数据传送，而DMA直接用硬件来实现响应时机不同执行完一条指令后响应中断，而在一个机器周期结束后响应DMA请求功能不同中断方式不仅能传送数据，还能处理异常事件；而DMA只能进行数据传送DMA利用了中断技术响应时间不同中断方式需要切换程序、保护现场和恢复现场；DMA不改变CPU现场DMA请求比中断请求优先级高，为防止丢失DMA高速传送的数据1521:39168.5通道方式(Channel)通道是一个特殊功能的处理器设有专用通道指令专门负责数据输入输出的传输控制CPU只负责“数据处理”,进一步提高了CPU的效率21:39通道结构178.5.2通道的类型选择通道-theselectorchannels在物理上可以连接多个设备，设备不能同时工作，只能选择一个设备工作多路通道-themultiplexorchannels在同一时间能处理多个I/O设备的数据传输分为数组多路通道和字节多路通道21:3921:391821:391920本章小结在计算机系统中，CPU对外围设备的管理方式有：①程序查询方式；②程序中断方式；③DMA方式；④通道方式程序中断方式使用广泛它“主动”向CPU发出请求信号CPU响应中断请求后，暂停运行主程序，自动转移到该设备的中断服务子程序，为该设备进行服务，结束时返回主程序中断处理过程可以嵌套进行，优先级高的设备可以中断优先级低的中断服务程序DMA技术使得外围设备可以直接访问内存，CPU可以继续程序DMA采用以下三种方法：①停止CPU访内；②周期挪用；③DMA与CPU交替访问21:39计算机组成原理教师：闫江毓办公室：主楼E705邮箱：yabjy@ncepu.edu.cn微信:1计算机组成原理课程目的：掌握计算机的工作原理,深刻理解程序在计算机硬件上执行的过程课程任务：掌握计算机硬件系统各组成部件的工作功能、原理和逻辑实现理解各部件联结成整机并协调运转的方法了解当代计算机系统的新技术和新成果2计算机组成原理3课程依赖关系主要内容编译技术操作系统组成原理数字电路数理逻辑布尔逻辑掌握逻辑描述的方法编译器操作系统计算机软件计算机组成原理课时安排：56学时（54讲课+2复习）1-14周最后成绩：到课情况(5%-课堂派考勤)作业情况(5%-课堂派习题)实验(20%)期末考试(70%-闭卷)4白中英主编(第六版)主要教材5电子版图书馆网址-》电子图书-》科学文库http://reading.sciencepress.cn/搜索“计算机组成原理”只能在校园网内使用北京大学计算机组成慕课https://www.icourse163.org/course/preview/PKU-1205809805?tid=1206107207华中科技大学计算机组成原理慕课https://www.icourse163.org/course/HUST-10031590016慕课资源目录第一章计算机系统概论第二章运算方法和运算器第三章多层次的存储器第四章指令系统第五章中央处理器第六章总线系统第七章外存与I/O设备第八章输入输出系统7课程安排（56学时）82024/6/5第一章计算机系统概论1.1计算机的分类1.2计算机的发展简史1.3计算机的硬件1.4计算机的软件1.5计算机系统的层次结构91.1计算机的分类电子计算机从总体上来说分为两大类：电子模拟计算机特点是数值由连续量来表示，运算过程也是连续的。电子数字计算机主要特点是按位运算，并且不连续地跳动计算。10111958年完成的我国自行研制的模拟计算机红旗-551，慈云桂121960年，我国自行设计的第一台电子数字计算机107机中科院计算机夏培肃领导研制她也是我国计算机事业的奠基者现在计算机中的一些术语和专业名词都是她翻译的。中国计算机之母131.1.1计算机的分类根据性能、经济性和适应性，可以划分为两类：专用计算机：专用机是最有效、最经济和最快速的计算机，但是它的适应性很差。通用计算机：通用计算机适应性很大，但是牺牲了效率、速度和经济性。通用计算机分类可以分为：超级计算机大型机服务器工作站微型机单片机区别在于：体积、简易性、功耗、性能指标、数据存储容量、指令系统规模和机器价格等141.2计算机发展简史计算机的五代变化1946—1957年，电子管计算机：数据处理1958—1964年，晶体管计算机：工业控制1965—1971年，中小规模集成电路计算机：小型计算机1972—1990年，大规模和超大规模集成电路计算机：微型计算机1991年至今，甚大规模集成电路计算机：单片机151.2.2半导体存储器的发展20世纪50～60年代，所有计算机存储器都是由微小的铁磁体环构成1970年，仙童半导体公司生产出了第一个较大容量半导体存储器从1970年起，半导体存储器经历了若干代：单个芯片1KB~1MB~1GB。其中1K=1031M=103K=106,1G=103M=1091bit表示1个二进制位，1B=8bit规范的二进制位计数：1Ki=210,1Mi=220,1Gi=230161.2.3微处理器的发展1971年Intel公司开发出4004。1972年出现的8008，这是第一个8位微处理器1974年出现了8080，这是第一个通用微处理器。171.2.3微处理器的发展20世纪70年代末出现通用16位微处理器8086Intel于1985年推出了32位微处理器80386。到现在的64位处理器和多核处理器18我国计算机技术的发展1953年起步，1958年第一台103型通用计算机50年来相继研究出了第二代，第三代计算机。80年代研究出每秒１亿次的巨型机，银河I,II,曙光等。85年6月，第一台实现中文化系统、并量产的国产微机长城0520CH正式研发成功。在高性能计算，并行计算上已紧跟国际先进水平，但计算机的核心部件CPU技术还远远落后。191.2.3微处理器的发展微处理器一般称为CPU：CentralProcessUnit目前CPU芯片主要设计/生产商Intel：酷睿、奔腾、赛扬、至强！AMD：速龙、闪龙、皓龙、APU-天津海光VIA：C3、C7-上海兆芯IBM：-苏州国芯龙芯：嵌入式、桌面、专用计算机ARM：三星、高通、华为海思、华为鲲鹏201.2.3微处理器的发展龙芯属于MIPS架构（LoongArch）上海兆芯属于X86架构华为麒麟/鲲鹏属于ARM架构阿里平头哥属于RISC-V架构中国有着全球数量最多的芯片设计公司展讯、寒武纪等小米，百度、VIVO、OPPO都在布局芯片还未形成规模效益、人才缺口非常大通用计算机分类可以分为：超级计算机大型机服务器工作站微型机单片机区别在于：体积、简易性、功耗、性能指标、数据存储容量、指令系统规模和机器价格等22超级计算机-Top500（2023.5）1、Frontier(美),处理器核：8,730,112；峰值1102PFlop/s；AMD处理器2、Fugaku(日),处理器核：7,630,848；峰值442PFlop/s；ARM处理器2、LUMI(芬兰),处理器核：1,110,144；峰值151.9PFlop/s；AMD处理器+NVIDIATeslaV1007、神威太湖之光,处理器核：10,649,600；峰值93.01PFlop/s；神威处理器10、天河2A,处理器核：4,981,760；峰值61.4PFlop/s；Intel+国产Matrix-2000加速卡23超级计算机-Top500（2024.5）1、Frontier(美),处理器核：8,699,904；峰值1.206EFlop/s；AMD处理器2、Aurora(美),处理器核：9,264,128；峰值1.012EFlop/s；Intel处理器3、Eagle(美),处理器核：2,073,600；峰值561.2PFlop/s；Intel处理器+NVIDIAH1004、Fugaku(日),处理器核：7,630,848；峰值442PFlop/s；ARM处理器5、LUMI(芬兰),处理器核：2,752,704；峰值379.7PFlop/s；AMD处理器+NVIDIATeslaV100Top500组织在最新发布的报告中指出，中国已决定不再参加Top500的HPL基准测试。24日本Fugaku-富岳富士通和日本理化学研究所共同研制拥有超过7,630,848个核心，内存4752TB富士通A64FX处理器，ARMv8.2-A，配备32GBHBM2内存，带宽1TB/s，浮点性能2.7TFLOPS，使用台积电7nm工艺生产，晶体管数量878.6亿A64FX包含48个计算核心和2~4个辅助核心，没有GPU加速器，封装HBM2内存。252024/6/5神威-太湖之光2017年TOP500第一，2020年第四拥有40960个计算节点，内存1.31PB使用了国产众核芯片申威26010采用28nm制程工艺，主频1.45GHz拥有260个核心，浮点峰值达到3.06TFlops64位261.2.4计算机的性能指标272024/6/51.2.4计算机的性能指标CPU执行时间：表示一段程序执行过程中所占用的CPU时间。CPU时间=执行某段程序所使用的CPU周期数×CPU时钟周期CPI：CyclePerInstruction执行一条指令所需的平均周期数执行某段程序所使用的CPU周期数÷程序总指令数MIPS：MillionInstructionsPerSecond每秒百万指令数MIPS=程序总指令数÷(程序执行时间×106)2024/6/5281.2.4计算机的性能指标2024/6/529CPU性能公式30CPU性能公式31CPU性能公式322024/6/533[例2]用一台50MHz处理机执行标准测试程序，它包含的混合指令数和相应所需的平均时钟周期如下表所示：解341.3计算机的硬件1.3.1硬件组成要素控制器运算器存储器输入设备输出设备冯·诺依曼型计算机VonNeumann1.3计算机的硬件冯·诺依曼型计算机五大组成部分二进制表示存储程序程序控制35冯诺依曼架构361.3.2运算器37ALU-ArithmeticLogicUnit（算术逻辑运算单元）算术运算和逻辑运算在计算机中参与运算的数是二进制运算器的长度一般是8、16、32或64位计算机的字长381.3.3存储器存储数据和程序运算开始前，必须先将程序和数据存入存储器（存储程序思想）一个存储单元中存入一个二进制数据串。存储器按存储单元组织，存储器中有大量的存储单元。为了方便查找，每个存储单元都被分配一个地址。通常，存储器都是按地址查找，线性编址。391.3.3.存储器存储器的容量一般都按字节计算存储器单位：210Byte＝1KiB210KiB＝1MiB210MiB＝1GiB210GiB＝1TiB分类：内存、外存1.3.3.存储器内存有两种操作：写入：数据存入存储器写入新数据后，会“覆盖”旧数据读出：从存储器取出数据读出并不破坏存取器中的数据可以从同一存储单元中反复的读出同一数据401.3.4控制器控制器是计算机中发号施令的部件控制计算机的各部件有条不紊地工作任务：从内存中取出指令加以分析,然后执行某种操作（指令控制）一条指令（instruction）完成一种操作算术运算或者逻辑运算、传输数据等将复杂的问题简化为一系列简单操作每个简单操作用一条指令完成，一系列指令的有序集合叫做程序（program）411.3.4控制器(2)指令的形式指令的内容由两部分组成，即操作的性质和操作数的地址。每条指令应当明确告诉控制器，从存储器的哪个单元取数，并进行何种操作。指令系统：计算机的全部指令集合。42范例-模型计算机43存储器运算器和控制器存储单元44模型计算机存储器运算器和控制器范例45范例4647存储器中的机器语言程序10111213987654321指令集构造机器指令将汉语表达转为二进制表示汇编源程序同一个问题在不同实现的计算机上解决，步骤是不同的。编译器48要考虑两个问题：数据存储数据处理模型计算机存储器49表1.4计算y=ax+b-c的程序表1.5指令的操作码定义51(2)指令的形式数码化的指令和数据都放入存储器，两种方式：冯诺依曼结构（VonNeumannArchitecture）：存储器的任何位置既可以存放数据也可以存放指令哈佛结构（HarvardArchitecture）：指令和数据存储器物理上独立52冯诺依曼结构哈佛结构(2)指令的形式存储程序：将程序（指令序列）和数据存放到存储器中程序控制：控制器依据存储的程序来全机协调地计算任务53控制器执行程序的过程2024/6/554取指令1011001执行（9）→A取指令0111100执行(12)→B;(A)*(B)→A取指令0011010执行(10)→B;(A)+(B)→A取指令0101011执行(11)→B;(A)-(B)→A取指令1101101执行A→(13)取指令1110000执行StopSTO13LAD9MUL12ADD10SUB11SLT1.3.4(3)控制器的基本任务按照特定的顺序一条接着一条取指令、执行指令。55取指令1011001执行（9）→A取指令0111100执行(12)→B;(A)*(B)→A取指令0011010执行(10)→B;(A)+(B)→A取指令0101011执行(11)→B;(A)-(B)→A取指令1101101执行A→(13)取指令1110000执行Stop1.3.4(3)控制器的基本任务每取出一条指令，控制器中的指令计数器就加1，下一条指令做好准备指令计数器(Programcounter:PC)保存指令的地址指令要顺序存放每条指令在存储器都有地址56存储器中的机器语言程序7654321指令地址1.3.4(3)控制器的基本任务时间因素取指周期：从存储器中取指令到控制器的时间执行周期：在控制器中执行指令的时间57时间t1.3.4（4）指令流和数据流如何区分内存输出的是指令流？还是数据流？根据不同的时间取指周期中从内存读出的信息流是指令流，它流向控制器执行周期中从内存读出的信息流是数据流，它由内存流向运算器。581.3.4控制器其他任务：保证指令按规定序列自动连续地执行。对各种异常情况及时响应和处理。控制器向计算机各功能部件提供每一时刻协同运行所需要的控制信号591.3.5适配器与输入输出设备输入设备：把人们所熟悉的信息形式变换为二进制信息形式输出设备：把计算机处理结果变换为人或其他机器设备所能接收和识别的信息形式总线：构成计算机系统的骨架，是多个系统部件之间进行数据传送的公共通路。601.4计算机的软件1.4.1软件的组成与分类611.4.2软件的发展演变编程语言的发展手编程序：机器语言程序，手工编译二进制码汇编程序：符号语言程序，汇编程序汇编62可执行程序目的程序机器语言可执行程序目的程序汇编语言手工编写汇编源程序汇编程序翻译1.4.2软件的发展演变编程语言的发展高级程序：算法语言/高级语言编译系统：把源程序全部翻译成目的程序，然后机器执行目的程序解释系统：逐一翻译源程序语句并立即执行该语句。63源程序可执行程序目标程序编辑程序汇编或编译程序联接程序高级语言1.4.2软件的发展演变系统软件的发展操作系统：用来管理计算机软硬件资源和自动用户作业调度，而使多个用户能有效地共用一套计算机系统。数据库管理系统：数据库和数据库管理软件分布式系统软件641.5计算机系统的层次结构计算机是一个硬、软件结合而成的整体。它通常由五级组成。不同的计算机使用者看到的计算机的形式是不同的651.5计算机系统的层次结构高级语言级：方便用户编写应用程序，由各种高级语言编译程序支持和执行。汇编语言级：提供一种符号形式语言，以便能够精确地操作控制硬件。操作系统级：它由操作系统程序实现，管理所有的硬件资源661.5计算机系统的层次结构一般机器级：由微程序解释机器指令系统。微程序设计级：实际执行指令、处理数据的数字电路。671.5.2软件与硬件逻辑等价性随着大规模集成电路技术的发展任何操作可以由软件来实现，也可以由硬件来实现；采用哪种方案？应综合考虑各个因素：价格、速度、可靠性、存储容量、变更周期固件：介于传统的软件和硬件间的实体。功能------软件形态------硬件实现------软件写入ROM------固化68第一章小结计算机的分类冯·诺依曼型计算机特点计算机硬件的基本组成部分五大部件运算器、控制器、存储器计算机软件计算机的性能指标计算机层次结构69返回作业P15：4、5、6、7、8、1470一段C程序intmain(){inta=2,b=3;intc,d;c=a+b;d=a*b;}在线编程网站https://gcc.godbolt.org/X86架构的指令序列X86架构的指令序列8051单片机架构的指令序列SPARCV8架构的指令序列人工智能四层架构762024/6/5AI不同计算任务需要不同芯片77GPU与AI模型训练78FPGA：分布式+可定制79ASIC：实现性能和功耗均衡80国产服务器CPU81自动驾驶芯片指标AI算力TOPS根据地平线数据，L2级自动驾驶的算力需求为2-2.5TOPS，L3级自动驾驶算力需求为20-30TOPS,L4级自动驾驶算力需求为200TOPS以上，L5级自动驾驶算力需求为2000TOPS以上。82算力单位TOPSTOPS(TeraOperationsPerSecond)，表示每秒执行1万亿次(10^12)运算，用于衡量自动驾驶芯片的AI算力。TOPS描述芯片MAC(MultiplyAccumulate，乘积累加运算)的运算能力，并没有指定数据类型，具体算力评估需要结合数据类型及精度。MAC运算包括相乘和相加(a←a+b*c)。对于卷积、点积、矩阵等运算而言，MAC指令可以大幅提高运算效率。TOPS计算公式：理论峰值=MAC矩阵行*MAC矩阵列*主频*28384现代GPU集群极度耗电。GPT4在训练过程中使用了约50GWh的能量。相当于30辆普通汽车环绕地球300次。谷歌表示一次搜索使用0.28瓦时，而与谷歌搜索相比，GoogleGPT4使用的能量大约是谷歌搜索的四倍。8586SM（StreamingMultiprocessors）称为流式多处理器，是NVIDIAGPU的基本构建模块。每个SM包含CUDA核心（用于通用计算的处理单元）、张量核心（专门用于AI工作负载）以及其他用于图形和计算操作的组件。SM具有高度并行性，使GPU能够同时执行许多操作。主芯片上共有144个SM。但它们的参数产量约为90％，这意味着我们可以使用大约130个。在生产过程中发生故障的部分会被关闭。此外，如果看一下主芯片的尺寸，那是一个相当大的芯片，非常接近现代工厂机器的限制。。87HBM（高带宽内存）HBM是一种具有高带宽接口的堆叠内存类型。与传统的GDDR内存相比，HBM提供了显著更多的带宽，可以实现GPU和内存之间的数据传输速率更快，这对于对带宽需求高的任务（如深度学习和大数据分析）特别有益。如果查看内存控制器，您会看到有6个，但NVIDIA只启用了其中的5个。8889第二章运算方法和运算器2.1数据与文字的表示方法2.2定点加法、减法运算2.3定点乘法运算2.4定点除法运算2.5定点运算器的组成2.6浮点运算方法与浮点运算器1返回22.1数据与文字的表示方法2.1.1数据格式2.1.2数的机器码表示2.1.3字符与字符串的表示方法2.1.4汉字的表示方法2.1.5校验码32.1数据与文字的表示方法两大类数据：符号数据：非数字符号的表示（字符、汉字、图形等）数值数据：数字数据的表示方式（定点、浮点）编码：用少量、简单的基本符号，选择合适的规则表示尽量多的信息，同时利于信息处理（速度、方便）ASCII、GB、UnicodeMP3、FLAC、JPG、H.264、H.265等二进制与易经系统的提出二进制观点的是德国的数学家和哲学家莱布尼茨据说他根据易经发明了二进制太极生两仪，两仪生四象，四象生八卦两仪：阴和阳2024/6/54易经八卦2024/6/552024/6/562.1.1数据格式计算机数据的表示方式，考虑几个因素：数的类型（小数、整数、实数、复数）数值范围数值精度存储、处理、传送的硬件代价软件兼容性72.1.1数据格式8十进制转二进制整数部分除2取余小数部分乘2取整52100.625*210.25*200.5*210.0除尽为止1011低高求得位数满足要求为止进制转换的简单运算方法－17/128的二进制表示?大数的转换方法，记住几个常用的2的幂925＝3226＝6427＝12828＝25629＝512210＝1024(1Kilo)211＝2048212＝4096213＝8182214＝16364215＝32728216＝65536220＝1Mega230＝1Giga(吉)240＝1Tera(太)更大的单位是多少？250＝1Peta260＝1Exa270＝1Zetta280＝1Yotta千、兆、吉、太、拍、艾、泽、尧分、厘、毫、微、纳进制转换的简单运算方法1015=24-1＝16-1=10000-1=111131=25-1＝32-1=100000-1=11111127=27-1＝128-1=10000000-1=111_1111255=28-1＝256-1=1111_11111023=210-1＝1024-1=11_1111_111165535=216-1＝65536-1=1111_1111_1111_1111几个简化运算的例子130=?=128+2=27+2=10000000+10=1000001065539=?=65536+3=216+3=1_0000_0000_0000_00112010=?=2047-37=2048-1-32-4-1=211-1-25-22-1=111_1111_1111-25-22-1=111_1101_1010111111110111＝?=212-1-817/128=10001/27=0.0010001-11-计算机中使用的计量单位12我国传统文化中的数量单位132.1.1数据格式计算机中数值数据表示格式：定点表示：小数点位置固定浮点表示：小数点位置不固定定点格式容许的数值范围有限（字长一定），硬件简单。浮点格式容许的数值范围很大，硬件复杂。2024/6/5141.定点数的表示方法约定数据的小数点位置固定小数点不使用记号”.”表示将数据表示成纯小数或纯整数定点数表示：带符号数不带符号数运算器利用寄存器存储数据寄存器中每个位称bit(BinaryDigit)最高有效位(MSB)、最低有效位(LSB)2024/6/5152024/6/5161.定点数的表示方法xnxn-1xn-2…x1x0数的表示范围:符号：0代表正号1代表负号量值小数点位于符号位之后，不需专门存放位置带符号定点纯小数2024/6/517定点纯整数xnxn-1xn-2…x1x0MSB为符号量值小数点固定于LSB之后例：字长8位X=+1010110.纯整数：X=01010110正数，符号位取0Y=-1101001.纯整数：Y=11101001（原码）负数，符号位取1X=+0.11011Y=-0.10101符号位取0纯小数：X=01101100符号位取1纯小数：X=11010100（原码）2024/6/5191.定点数的表示方法纯整数的表示范围(n+1位)1.定点数的表示方法受字长限制，表示数的范围有限;定点小数表示的精度有限目前计算机中采用定点数表示纯整数，因此将定点数表示的运算简称为整数运算。2024/6/5202.浮点数的表示方法2024/6/5212024/6/5222.浮点数的表示方法指数e基数R尾数M2.浮点数的表示方法一个浮点数由阶码和尾数及其符号位组成尾数M：用定点小数表示，表明有效数字的位数，决定了浮点数的表示精度阶码E：用定点整数表示，指明小数点的位置，决定了浮点数的表示范围2024/6/523IEEE754标准2024/6/524IEEE75432位单精度浮点数标准2024/6/525浮点数的规格化例：156.78=15.678×101=1.5678×102=0.15678×103=RE×M对于二进制数1011.1101=0.10111101×2+4=0.0010111101×2+6=1.0111101×2+3那么，计算机中究竟采用哪种数据形式？多种数据形式规格化表示法2024/6/527IEEE754标准规格化：同一真值浮点数具有唯一的表示形式规格化尾数应为如下形式：1.xxxxxxxxx整数位的1属于隐藏位，在实际存储时，尾数域只存储小数点后面的数值。规格化表示：当尾数不为0，尾数左移1位（小数点右移1位），同时阶码减1（左规）尾数右移1位（小数点左移1位），同时阶码加1（右规）IEEE754标准一个规格化的32位浮点数x的真值表示为x=(-1)S×(1.M)×2E-12764位的浮点数（双精度浮点数）符号位1位，阶码域11位，尾数域52位，指数偏移值是1023。规格化的64位浮点数x的真值为：x=(-1)S×(1.M)×2E-10232024/6/5282024/6/5292.浮点数的表示方法【例1】若浮点数x的754标准存储格式为(41360000)16，求其浮点数的十进制数值。解：将16进制数展开后，可得二制数格式为指数e=阶码-127=10000010-01111111=00000011=(3)10包括隐藏位1的尾数1.M=1.011_0110_0000_0000_0000_0000=1.011011于是x=(-1)S×1.M×2e=+(1.011011)×23=+1011.011=(11.375)102024/6/5302.浮点数的表示方法【例2】将数(20.59375)10转换成754标准的32位浮点数的二进制存储格式（16进制表示）。解:首先分别将整数和分数部分转换成二进制数：20.59375=10100.10011规格化，尾数右移4位10100.10011=1.010010011×24e=4，于是得到：S=0,E=4+127=131,M=010010011最后得到32位浮点数的二进制存储格式为：0100_0001_1010_0100_1100_0000_0000_0000=(41A4C000)16真值0的机器数（机器零）阶码E＝0，尾数M＝0正0：S＝0，负0：S＝1非规格化浮点数：阶码E＝0，尾数M≠0规格化浮点数：阶码E＝1～254（11111110）无穷大的机器数阶码E＝全1（11111111），尾数M＝0＋∞：S＝0，－∞：S＝1NaN（notanumber，不是一个数）阶码E＝全1（11111111），尾数M≠0用来通知异常情况IEEE754标准32位单精度浮点数单精度IEEE浮点数区间2024/6/5321≦E≦254E=255E=0M=0M≠0M=0M≠0规格化浮点数的范围正0或负0正/负无穷大NaN非规格化数2024/6/5332.浮点数的表示范围浮点数所表示的范围远比定点数大一般计算机中同时采用定点、浮点表示。单片机中多采用定点表示。IEEE754单精度在线转换https://www.h-schmidt.net/FloatConverter/IEEE754.html2024/6/5343.十进制数串的表示方法有时十进制数在计算机中需要以十进制的方式进行运算，需要对十进制进行编码二-十进制编码（BCD码）每个十进制符号由4位二进制数表示8421有权码名称表示每一位的位权（8、4、2、1）每位的数码与相应的位权相乘，再求和，得到它所代表的十进制数码74.56表示：01110100010101102024/6/5352024/6/512.1.2数的机器码表示一般书写表示的数，称为真值计算机中表示的数，称为机器数在计算机中，为了妥善的处理好符号位问题，主要是负数的运算问题，引入4种表示方法：原码、补码、反码、移码。1.原码表示法定点整数的原码形式为xnxn-1…x1x0字长8位：X＝+105，则[X]原＝01101001X＝-105，则[X]原＝10000000+1101001＝111010010使用原码有两种表达形式[+0]原=00000000[-0]原=100000002024/6/531.原码表示法特点：表示简单，易于同真值之间进行转换，实现乘除运算简单。进行减法运算麻烦。要比较绝对值的大小，然后绝对值大的数减去绝对值小数，最后给结果选择符号。为了解决这些矛盾，找到了补码表示法。2024/6/542.补码表示法2024/6/552.补码表示法2024/6/563.反码表示法定义：正数的反码表示与原码相同负数的反码符号位不变，数值位是将原码的数值位按位取反。电路很容易实现，触发器的输出正负两值。2024/6/573.反码表示法反码表示有正0和负0之分[+0]反=00000000[-0]反=11111111负整数补码：反码加1解决了求补码还要减法的问题[-105]补＝10010110＋1＝10010111负数求补负数原码“符号位不变，数值位取反加1”得对应补码负数补码再求补得到负数原码补码：11100000原码：1[1100000]求反＋1＝10011111+1＝101000002024/6/594.移码表示法传统定义和754标准浮点数阶码的定义不同2024/6/510移码和补码尾数相同，符号位相反[例8]设机器字长16位,定点表示,尾数15位,数符1位,问：定点原码整数表示时，最大正数是多少?最小负数是多少?[解:]定点原码整数表示最大正数值＝(215－1)10＝(＋32767)10最小负数值＝－(215－1)10＝(－32767)10数的机器码表示正数的原码、反码、补码等于真值，只有负数才分别有不同的表示方法采用补码，减法运算可以用加法运算实现，节省硬件，目前机器中广泛采用补码表示法有些机器用原码进行存储和传送，运算时改用补码移码表示法主要用于表示浮点数的阶码，可以直接比较大小。表示范围和补码相同，只有最高位相反同一代码的不同含义一个代码，采用不同编码，其数值不一样计算机内一个二进制数：10000001不同的含义无符号二进制数：1298421BCD码：81有符号整数的原码：-1有符号整数的反码：-126有符号整数的补码：-1272.1.3字符和字符串的表示方法非数值数据通常指的是字符、字符串、图形符号、汉字等数据必须按照一定的规则用一组二进制编码来表示ASCII美国国家标准局（ANSI）制定的ASCII（AmericanStandardCodeforInformationInterchange，美国信息交换标准码）是现今最为通用的单字节编码系统主要用于显示现代英文字母和符号1516ASCII码用7位二进制编码表示一个字符，总共可以表示128个字符计算机用一个字节来存放一个ASCII字符，最高位固定为02024/6/517IBMPC104键盘keyboard(Windows格式)182.1.4汉字的表示方法1.汉字的输入编码用西文标准键盘上对汉字进行编码：数字编码：是用数字串代表一个汉字的输入,如区位码等。最大优点是无重码,但难记.字音编码：以汉语拼音作为编码基础。简单易学,但重码很高,有微软拼音、智能ABC输入法等。字形编码法：将汉字的字形信息分解归类而给出的编码。具有重码少的优点。常用的有表五笔字型、郑码等。音形编码法：音形编码吸取了音码和形码的优点，使编码规则简化,重码少。常用的有全息码等。2.1.4汉字的表示方法2.汉字内码汉字内码是汉字的机内代码。一般采用两个字节表示。为了与ASCII区别，汉字内码中两个字节的MSB规定为“1”。汉字字符集编码查询https://www.qqxiuzi.cn/bianma/zifuji.php2024/6/5192024/6/520汉字内码1981年，国标码字符集GB2312每个编码2个字节，共收集常用简体汉字6763个1984年，BIG5字符集称大五码，共收录13053个中文字，港台地区使用1995年，GBK字符集共收录汉字21003个，支持繁体中文、日韩汉字2000年，GB18030字符集收录了27484个汉字，覆盖中、日、朝鲜语和中国少数民族文字向下兼容GBK、GB23122024/6/5212024年6月5日星期三22Unicode码容纳全世界所有语言中任意一种符号为每种语言中的每个字符设定惟一的二进制编码，以满足跨语言、跨平台进行文本转换、处理的要求UCS-22-byteUniversalCharacterSet，每个字符占用2个字节，实际使用比较多UCS-4每个字符占用4个字节，理论上可以表示231=2147483648个字符Unicode码为了解决Unicode的传输、存储问题，主要是网络传输，对Unicode进行二次编码UTF：UnicodeTransformationFormatUTF-8可变长格式对英文使用1个字节，中文使用3个字节来编码UTF-16拿2个字节来表示字符字符编码查询https://www.qqxiuzi.cn/bianma/zifuji.php2024/6/5232024/6/524Chrome浏览器中打开的web页面，点击右键，选择“查看网页源代码”华电主页www.ncepu.edu.cn的编码记事本编码区别？-25-2.1.4汉字的表示方法3.汉字输出码为了能显示和打印汉字，必须先存储汉字的字形，这就是汉字字形码两类字形码：点阵字形和矢量字形2024/6/5263.汉字输出码点阵字形又称字模码每个字由m×n个像素的位图表示，称m×n点阵点阵中的每个点都只有两种状态1表示有笔画，对应像素应置为字符颜色；0表示无笔画，对应像素应置为背景颜色或不改变272.1.4汉字的表示方法一个16点阵字形（左图），一行用2个字节描述，总供有16行，它的信息量是2*16=32个字节。一个48点阵字形用6个字节乘48行组成，它的信息量是6*48=288个字节。复原字形速度快，但缩放后的字形质量难以保证2.1.4汉字的表示方法矢量字形通过数学方程来描述包含了字形边界上的关键点、连线的导数信息等在显示、打印时，要经过一系列的数学运算输出结果字体可以无限放大而不产生变形目前主流的矢量字体格式有3种：Type1，TrueType和OpenType292.1.5校验码数据在存取和传送的过程中可能会发生错误产生错误的原因可能有很多种设备的临界工作状态外界高频干扰收发设备中的间歇性故障等为减少和避免错误提高硬件本身的可靠性对数据采用专门的逻辑电路进行编码，以检测错误，甚至校正错误302.1.5校验码方法在每个字上添加一些校验位，用来确定字中出现错误的位置计算机中常用的检错或纠错技术奇偶校验ParityCheckCRC循环冗余校验(CyclicRedundancyCheck)Hamming码，ECC校验2024/6/531若干位有效信息（如1个字节）加上1位校验位组成校验码奇校验：校验码中1的个数为奇数偶校验：校验码中1的个数为偶数奇偶校验码32奇校验码设8位信息码组为D7D6D5D4D3D2D1D0：若D7~D0中有奇数个“1”，则奇校验位=0奇校验位D奇=D7⊕D6⊕D5⊕D4⊕D3⊕D2⊕D1⊕D0读出数据时，将9位校验码送入校验电路G=D7⊕D6⊕D5⊕D4⊕D3⊕D2⊕D1⊕D0⊕D奇若G=0，则无错误若G=1，则传输出现错误3334【例10】已知下表中左面一栏有5个字节的数据。请分别用奇校验和偶校验进行编码,填在右面2栏。【解】假定最低一位为校验位，高8位为数据位，列表如下：校验位的值取0还是取1，是由数据位中1的个数决定的奇偶校验码奇偶校验码是一种最简单且应用广泛硬件成本很低可以检测出一位或奇数位错误，但不能确定出错位置，也不能检测出偶数位错误一位出错的概率比多位同时出错的概率要高得多常用于存储器读写检查或ASCII字符传送过程检查2024/6/5352024/6/512.2定点加法、减法运算2.2.1补码加法2.2.2补码减法2.2.3溢出概念与检测方法2.2.4基本的二进制加法/减法器2024/6/522.2.1补码加法2024/6/53[ｘ]补＋[ｙ]补＝[ｘ＋ｙ]补证明2024/6/54[ｘ]补＋[ｙ]补＝[ｘ＋ｙ]补证明(3)ｘ<0,ｙ>0,则ｘ＋ｙ>0或ｘ＋ｙ<0这种情况和第2种情况一样,把ｘ和ｙ的位置对调即得证。(4)ｘ<0,ｙ<0,则ｘ＋ｙ<0相加两数都是负数,则其和也一定是负数。∵[ｘ]补＝2n+1＋ｘ,[ｙ]补＝2n+1＋ｙ∴[ｘ]补＋[ｙ]补＝2n+1＋ｘ＋2n+1＋ｙ＝2n+1＋(2n+1＋ｘ＋ｙ)=[ｘ＋ｙ]补在模2n+1意义下,任意两数的补码之和等于该两数之和的补码。[例11]设字长5位,ｘ＝+1001,ｙ＝+0101,用补码求ｘ＋ｙ[解:][ｘ]补＝01001,[ｙ]补＝00101[ｘ]补01001＋[ｙ]补00101[ｘ＋ｙ]补01110所以ｘ＋ｙ＝＋1110[例11]设字长6位,ｘ＝+1001,ｙ＝+0101,用补码求ｘ＋ｙ[解:][ｘ]补＝001001,[ｙ]补＝000101[ｘ]补001001＋[ｙ]补000101[ｘ＋ｙ]补001110所以ｘ＋ｙ＝＋1110[例12]设字长5位,ｘ＝＋1011,ｙ＝－0101,用补码求ｘ＋ｙ。[解:][ｘ]补＝01011,[ｙ]补＝11011[ｘ]补01011＋[ｙ]补11011[ｘ＋ｙ]补100110所以ｘ＋ｙ＝+0110补码加法的特点，一是符号位要作为数的一部分参加运算二是符号位的进位要丢掉2024/6/582.2.2补码减法数用补码表示时，减法运算的公式为[ｘ－ｙ]补＝[ｘ]补－[ｙ]补＝[ｘ]补＋[-ｙ]补只要证明[－ｙ]补＝－[ｙ]补,上式即得证。现证明如下：∵[ｘ＋ｙ]补＝[ｘ]补＋[ｙ]补(模2n+1)∴[ｙ]补＝[ｘ＋ｙ]补－[ｘ]补(2.15)又∵[ｘ－ｙ]补＝[ｘ＋(－ｙ)]补＝[ｘ]补＋[－ｙ]补∴[－ｙ]补＝[ｘ－ｙ]补－[ｘ]补(2.16)将式(2.15)与(2.16)相加,得[－ｙ]补＋[ｙ]补＝[ｘ＋ｙ]补＋[ｘ－ｙ]补－[ｘ]补－[ｘ]补＝[ｘ＋ｙ＋ｘ－ｙ]补－[ｘ]补－[ｘ]补＝[ｘ＋ｘ]补－[ｘ]补－[ｘ]补＝0故[－ｙ]补＝－[ｙ]补(模2n+1)从[ｙ]补求[－ｙ]补的法则：对[ｙ]补包括符号位“按位求反且加1”，即可得到[－ｙ]补。写成运算表达式，则为其中符号﹁表示对[ｙ]补作包括符号位在内的求反操作[例13]设字长5位，已知ｘ1＝－1110,ｘ2＝＋1101,求：[ｘ1]补,[－ｘ1]补,[ｘ2]补,[－ｘ2]补。[解:][ｘ1]补＝10010[－ｘ1]补＝﹁[ｘ1]补＋1＝01101＋00001＝01110[ｘ2]补＝01101[－ｘ2]补＝﹁[ｘ2]补＋1＝10010＋00001＝10011[例14]设字长5位，ｘ＝＋1101,ｙ＝＋0110,求ｘ－ｙ。[解:][ｘ]补＝01101[ｙ]补＝00110[－ｙ]补＝11010[ｘ]补01101＋[－ｙ]补11010[ｘ－ｙ]补100111所以ｘ－ｙ＝＋0111[练习]设字长5位，ｘ＝-1001,ｙ＝-0110,求ｘ－ｙ。[解:][ｘ]补＝10111[ｙ]补＝11010[－ｙ]补＝00110[ｘ]补10111＋[－ｙ]补00110[ｘ－ｙ]补11101所以ｘ－ｙ＝-0011[例15]ｘ＝＋1011,ｙ＝＋1001,求ｘ＋ｙ。[解:][ｘ]补＝01011[ｙ]补＝01001[ｘ]补01011＋[ｙ]补01001[ｘ＋ｙ]补10100两个正数相加的结果成为负数,这显然是错误的。[例16]ｘ＝－1101,ｙ＝－1011,求ｘ＋ｙ。[解:][ｘ]补＝10011[ｙ]补＝10101[ｘ]补10011＋[ｙ]补10101[ｘ＋ｙ]补01000两个负数相加的结果成为正数,这同样是错误的。2.2.3溢出的概念与检测方法2024/6/5152.2.3溢出的概念与检测方法溢出的检测方法单符号位法和双符号位法双符号位法：用两个符号位表示一个数据，也称为“变形补码”两个符号位一样参与运算最高符号位产生的进位要丢弃2024/6/5162024/6/5172.2.3溢出的概念与检测方法用双符号位法检测溢出结果的两个符号位一致则没有溢出如果两个符号位不一致则发生溢出判断溢出的逻辑表达式为V=Sf1⊕Sf2,可以用异或门来实现2024/6/5182.2.3溢出的概念与检测方法二、检验举例：ｘ＝＋1100,ｙ＝＋1000,求ｘ＋ｙｘ＝－1100,ｙ＝－1000,求ｘ＋ｙ结果出现了01或10的情况就为溢出[例]设字长5位ｘ＝＋1100,ｙ＝＋1000,求ｘ+ｙ。[解:][ｘ]补＝001101[ｙ]补＝001000[ｘ]补001101＋[ｙ]补001000[ｘ+ｙ]补010101结果两个符号不同，表示溢出2024/6/5202.2.3溢出的概念与检测方法2、单符号位法其中Cf为符号位产生的进位,C0为最高有效位产生溢出检测V=Cf⊕C02.2.4基本的二进制加法/减法器2024/6/521[X]补＝XnXn-1………X0[Y]补＝YnYn-1…….…Y0+?n?n-1…….…?0多位加法运算依赖于各位逐位相加的运算，所以先讨论一位全加器2.2.4基本的二进制加法/减法器半加器两个二进制位相加2024/6/522Si＝Ai⊕BiCi+1＝AiBi全加器的真值表与表达式23Si＝Ai⊕Bi⊕CiCi＋1＝AiBi＋BiCi＋CiAi=AiBi＋(Ai⊕Bi)Ci输入:加数Ai、Bi、低位进位输入Ci输出:和Si，进位输出Ci+12024/6/524FA逻辑电路和框图FA（全加器）逻辑电路图延迟分析：设异或门延迟为3T，与非门延迟为T对一位全加器(FA)来说，Si的时间延迟为6T，Ci＋1的时间延迟为5T。FA框图4位补码加法器2024/6/525FAFAFAFAB0B1B2B3A0A1A2A3C0=0S0C1S1S2S3C2C3C4溢出符号位单符号法检测溢出只能完成补码加法加法器的改造2024/6/526FAFAFAFAA3MS0C1S1S2S3C2C3C4溢出符号位B3A2B2A1B1A0B0能完成补码加法和补码减法[ｘ]补＋[ｙ]补＝[ｘ＋ｙ]补[ｘ]补＋[-ｙ]补＝[ｘ-ｙ]补4位补码加法器2024/6/527进位依次从地位传递高位，称为行波进位当M＝0，加法[A]补＋[B]补运算；当M＝1，减法[A]补-[B]补转化成[A]补＋[－B]补运算，异或。4位补码加法器2024/6/528延迟分析：找出时延最长的路径B0->C1为3T+3T+2T=8TC1->C2为10TC2->C3为12TC3->C4为14T溢出为17T2024/6/529n位行波进位补码加法器总延迟：从C0到溢出产生的延迟为(2n+9)T8T(B0->C1)+2(n-1)T(C1->Cn)+3T(溢出)=(8+2n-2+3)T=(2n+9)T加法器是算术运算电路的核心所有算术运算都基于加法器实现加法器不区分符号数与无符号数2024/6/5302.3定点乘法运算采用软件实现乘法运算利用加法运算指令，编写实现乘法的循环子程序所需的硬件最少，但速度最慢采用硬件实现乘法运算串行乘法器被乘数每次和一位乘数相乘并行乘法器被乘数同时和乘数所有二进制位相乘硬件乘法器，需要乘法指令1硬件增加新的功能需要提供必要的指令2当前CPU支持的新指令2.3.1原码并行乘法31.人工算法步骤4设ｘ＝1101,ｙ＝10111101(ｘ)×1011(ｙ)110111010000＋110110001111(ｚ)1.人工算法步骤5设ｘ＝1101,ｙ＝10111101(ｘ)×1011(ｙ)110111010000＋110110001111(ｚ)求部分积：从乘数y的最低位开始逐位与被乘数相乘（与运算）根据权重移位：每个部分积根据乘数的权相应左移部分积相加：部分积统统加起来得到乘积z（z的位数扩大一倍）。1.人工算法步骤求部分积：从乘数y的最低位开始逐位与被乘数相乘（与运算）根据权重移位：每个部分积根据乘数的权相应左移部分积相加：将移位后的部分积统统加起来便得到最后乘积z（z的位数扩大一倍）。6计算机乘法的困难两大困难其一：两个n位数相乘，乘积为2n位。部分积、乘积如何存储?其二：只有两个操作数相加的加法器如何将n个部分积相加？设计高速并行乘法器的基本问题就在于缩短部分积的加法时间7a4a3a2a1a0两个5位的二进制无符号数相乘乘数a和被乘数b都为5位，乘积P为10位阵列乘法器b0b1b2b3b4×8a3b2a2b2a1b2a0b2a4b2a3b3a2b3a1b3a0b3a4b3a4b0a3b0a2b0a1b0a0b0a4b1a3b4a2b4a0b4a4b4a1b4两个5位的二进制无符号数相乘乘数a和被乘数b都为5位，乘积P为10位生成所有部分积9p1p0a3b2a2b2a1b2a0b2a4b2a3b3a2b3a1b3a0b3a4b3a4b0a3b0a2b0a1b0a0b0a4b1a3b4a2b4a0b4a4b4a1b4表示全加器斜线表示进位，竖线表示和10p2p1p0a3b2a2b2a1b2a0b2a4b2a3b3a2b3a1b3a0b3a4b3a4b0a3b0a2b0a1b0a0b0a4b1a3b4a2b4a0b4a4b4a1b4表示全加器斜线表示进位，竖线表示和11p2p1p0a3b2a2b2a1b2a0b2a4b2a3b3a2b3a1b3a0b3a4b3a4b0a3b0a2b0a1b0a0b0a4b1p3a3b4a2b4a0b4a4b4a1b4表示全加器斜线表示进位，竖线表示和12p2p1p0a3b2a2b2a1b2a0b2a4b2a3b3a2b3a1b3a0b3a4b3a4b0a3b0a2b0a1b0a0b0a4b1p3p4a3b4a2b4a0b4a4b4a1b4表示全加器斜线表示进位，竖线表示和13p2p1p0a3b2a2b2a1b2a0b2a4b2a3b3a2b3a1b3a0b3a4b3a4b0a3b0a2b0a1b0a0b0a4b1p3p4p5a3b4a2b4a0b4a4b4a1b4表示全加器斜线表示进位，竖线表示和014p2p1p0a3b2a2b2a1b2a0b2a4b2a3b3a2b3a1b3a0b3a4b3a4b0a3b0a2b0a1b0a0b0a4b1p6p3p4p5a3b4a2b4a0b4a4b4a1b4表示全加器斜线表示进位，竖线表示和015p2p1p0a3b2a2b2a1b2a0b2a4b2a3b3a2b3a1b3a0b3a4b3a4b0a3b0a2b0a1b0a0b0a4b1p6p7p3p4p5a3b4a2b4a0b4a4b4a1b4表示全加器斜线表示进位，竖线表示和016p8p2p1p0a3b2a2b2a1b2a0b2a4b2a3b3a2b3a1b3a0b3a4b3a4b0a3b0a2b0a1b0a0b0a4b1p6p7p3p4p5p9a3b4a2b4a0b4a4b4a1b4表示全加器斜线表示进位，竖线表示和017p8p2p1p0a3b2a2b2a1b2a0b2a4b2a3b3a2b3a1b3a0b3a4b3a4b0a3b0a2b0a1b0a0b0a4b1p6p7p3p4p5p90a3b4a2b4a0b4a4b4a1b44*5个全加器斜线表示进位，竖线表示和表示全加器进位保留加法器行波进位加法器18192、不带符号的阵列乘法器不带符号阵列乘法器逻辑图2、不带符号的阵列乘法器203、带符号的阵列乘法器对于补码表示的乘数和被乘数在使用阵列乘法器前，需先将补码转换为原码求补电路21E=1，求补E=0，直通输出求补电路223、带符号的阵列乘法器求补器与原码阵列乘法器结合组成带符号的阵列乘法器共使用三个求补器。两个算前求补器：将操作数A和B变成正整数。算后求补器：输出结果的补码。23243、带符号的阵列乘法器原码／补码2.4定点除法运算25260.1101商q2.4.1原码除法运算原理设被除数ｘ＝0.1001，除数ｙ＝0.1011，模仿十进制除法运算，以手算方法求ｘ÷ｙ的过程如下：10111001r0被除数小于除数，不够减，商0－1011被除数低位补零，够减除数,商1111r1得余数r1低位补零－1011够减除数,商111r2得余数r2低位补零1011不够减除数,商0110r3余数r3低位补零－1011够减除数,商11r4得余数r4270.1101商q2.4.1原码除法运算原理设被除数ｘ＝0.1001，除数ｙ＝0.1011，模仿十进制除法运算，以手算方法求ｘ÷ｙ的过程如下：00002.4.1原码除法运算原理二进制除法实质:“被除数（余数）减除数，求新余数”人工算法：求商时从高位向低位逐位求，商符单独处理每次上商都是由心算来比较余数和除数的大小，确定商1还是0每做一次减法，总是保持余数不动，低位补0，再减去右移后的除数。重复上一步骤，直到余数为0，或商的位数满足要求282.4.1原码除法运算原理292.4.1原码除法运算原理补充：编码的移位机器数为正时，不论左移或右移，添补代码均为0。负数原码在移位时符号位不变，其空位均添0。负数反码在移位时符号位不变，其空位均添1。负数补码在移位时，符号位不变，左移添0，右移添1.30补充：编码的移位实例：A=-26，用8位二进制表示，写出三种机器数左移一位、右移一位、左移两位和右移两位后的表示形式及其真值。101101001000110111101000100001101100101111110010100101111111100111001100111100111001100011111001-52-13-104-6-52-13-104-6-52-13-104-731[例23]ｘ＝0.101001,ｙ＝0.111,求ｘ÷ｙ。（恢复余数法计算）[解:][ｙ]补＝0.111[-ｙ]补＝1.001被除数ｘ0.101001减ｙ1.001余数为负1.110001＜0q4＝0不够减，恢复余数加ｙ0.1110.101001y右移1位减1.1001余数为正0.001101＞0q3＝1右移2位减1.11001余数为负1.111111＜0q2＝0不够减，恢复余数加ｙ0.001110.001101ｙ右移3位减1.111001余数为正0.000110＞0q1＝1故得商q＝q4.q3q2q1＝0.101322.4.1原码除法运算原理33恢复余数法34不恢复余数法（加减交替法）3536YN结束YNYN37382、不恢复余数的除法2024/6/512.5定点运算器的组成2.5.1逻辑运算2.5.2多功能算术/逻辑运算单元ALU2.5.3内部总线2.5.4定点运算器的基本结构2024/6/522.5.1逻辑运算计算机中的逻辑运算，主要是指逻辑非、逻辑加、逻辑乘、逻辑异或四种基本运算。非运算：按位反逻辑加：按位或逻辑乘：按位与异或运算：又称“按位加”移位运算左移n位等于乘2n右移n位等于除2n移位和加法结合，实现乘（除）运算有符号数的移位称算术移位空出位补0或1无符号数的移位称逻辑移位空出位补0移位运算-算术移位有符号数的移位叫算术移位机器数为正时，不论左移或右移，添补代码均为0。负数原码在移位时符号位不变，其空位均添0。负数反码在移位时符号位不变，其空位均添1。负数补码在移位时，符号位不变，左移添0，右移添1.补充：编码的移位实例：A=-26，用8位二进制表示，写出三种机器数左移一位、右移一位、左移两位和右移两位后的表示形式及其真值。101101001000110111101000100001101100101111110010100101111111100111001100111100111001100011111001-52-13-104-6-52-13-104-6-52-13-104-72024/6/562.5.2多功能算术/逻辑运算单元ALU由全加器构成的加法器，可以实现补码的加法/减法运算。问题：由于串行进位它的运算时间很长不能完成逻辑运算以加法器为核心的算术/逻辑运算单元(ALU-ArithmeticLogicUnit)具有算术和逻辑运算的功能先行进位逻辑，能实现高速加法运算2024/6/572.5.2多功能算术/逻辑运算单元ALU改变FA的输入端Ai和Bi来实现算术运算和逻辑运算功能。一位全加器FA将Ai和Bi输入一个函数发生器得到输出Xi和Yi，作为一位全加器的输入。2024/6/581位ALU的逻辑图与逻辑表达式控制参数2024/6/592.5.2多功能算术/逻辑运算单元ALU可以处理16种算术\逻辑运算，每种运算只针对1位二进制102.5.2多功能算术/逻辑运算单元ALU进一步化简得到下式代入全加器的求和与进位表达式，可得如下逻辑表达式2.5.2多功能算术/逻辑运算单元ALU2024/6/5112.5.2多功能算术/逻辑运算单元ALU2024/6/5122024/6/5132.5.2多功能算术/逻辑运算单元ALU4位ALU:4个1位ALU串行连接能进行4位算术和逻辑运算进位信号太慢2024/6/5142.5.2多功能算术/逻辑运算单元ALU串行进位，速度慢Cn＋1Cn＋2Cn＋3Cn＋415对串行进位的改进串行改并行先行进位（CLA-CarryLookAhead）2.5.2多功能算术/逻辑运算单元ALUCn＋4＝Y3＋Y2X3＋Y1X2X3＋Y0X1X2X3＋X0X1X2X3Cn令G＝Y3＋Y2X3＋Y1X2X3＋Y0X1X2X3P＝X0X1X2X3G(Generation)为进位发生函数P(Propagation)为进位传递函数增加P和G的目的在于实现多片ALU之间的先行进位Cn＋4＝G＋PCn16逻辑电路图2024/6/517G＝Y3＋Y2X3＋Y1X2X3＋Y0X1X2X3P＝X0X1X2X32024/6/518741814位ALU逻辑图函数发生器先行进位运算方式控制A=B？2024/6/51974181功能202.5.2多功能算术/逻辑运算单元ALU4片74181组成16位ALU片内先行进位，片间串行进位212.5.2多功能算术/逻辑运算单元ALU4片74181组成16位ALUC4=G0+P0C0C8=G1+P1C4C12=G2+P2C8C16=G3+P3C12Cn＋ｘ＝G0＋P0CnCn＋ｙ＝G1＋P1Cn＋ｘ＝G1＋G0P1＋P0P1CnCn＋ｚ＝G2＋P2Cn＋ｙ＝G2＋G1P2＋G0P1P2＋P0P1P2CnCn＋4＝G3＋P3Cn＋ｚ＝G3＋G2P3＋G1P1P2＋G0P1P2P3＋P0P1P2P3Cn＝G*＋P*CnP*＝P0P1P2P3G*＝G3＋G2P3＋G1P1P2＋G0P1P2P3根据以上表达式实现的部件称为74182（组间先行进位产生器），与4个74181配合使用74182的逻辑电路图232024/6/52416位先行进位ALU片内先行进位，片间先行进位2024/6/52532位ALU2片741828片7418164位先行进位系统16片74181，5片74182芯片组成多级先行进位2.5.3内部总线将计算机各个部件之间的数据传送通路加以归并，组成总线结构任何一个时刻，总线上只能有一个来源的数据，数据源独占总线不同来源的信息在总线上分时传送只要数据源不撤销数据，该数据在总线上一直存在根据所在位置分类：内部总线：CPU内各部件的连线外部总线：CPU与存储器、I/O系统之间的连线2024/6/5272.5.3内部总线按总线的逻辑结构分：单向总线：信息只能向一个方向传送。传送地址信息或控制信息的总线双向总线：信息可以两个方向传送数据总线既可以发送数据，也可以接收数据。总线的基本电路是三态门逻辑1、逻辑0、高阻2024/6/528292.5.4定点运算器的基本结构基本组成包括：ALU：核心部件乘除法器，组合逻辑电路数据存储部件：存放参与计算的数据及运算结果暂存器：只对硬件设计者可见通用寄存器：可以被软件设计者所访问内部总线：连接各个部件的通道302.5.4定点运算器的基本结构一个二元运算需要两个操作数，产生一个结果操作数op操作数=操作结果按照数据从存储部件传输到ALU的方式将ALU分为三种结构单总线，双总线，三总线1、单总线结构的运算器两个操作数要分两次输入到ALU需要A、B两个暂存器临时保存操作数操作速度慢、控制简单2024/6/531一次运算要三步完成：通用寄存器->A通用寄存器->BA+B,ALU->通用寄存器2、双总线结构的运算器两个操作数通过两条总线同时输入到ALU进行运算ALU的输出经过缓冲器送入通用寄存器因为ALU的输入数据没有暂存器，计算过程中，两条总线都被输入数据占据，必须在ALU输出端设置缓冲器。2024/6/532一次运算要两步完成：通用寄存器->总线1，通用寄存器->总线2，总线1+总线2>缓冲器缓冲器->通用寄存器3、三总线结构的运算器总线旁路器：总线之间的数据传送一次运算一步完成：通用寄存器->总线1，通用寄存器->总线2，总线1+总线2>总线3，总线3->通用寄存器速度快，硬件复杂，成本高33Intel8086运算器结构34通用寄存器暂存器标志寄存器16位ALU单总线结构ARM的ALU35三总线结构通用寄存器Intelpentuim的ALU36三总线结构通用寄存器CPU和GPU37GPU中有海量的ALU，因而其计算能力很强大GPU的ALU38GTX1080的核心GP104每个SM有128个CUDA内核（绿色方块）CUDA内部392024/6/512.6浮点运算方法和浮点运算器2.6.1浮点加法、减法运算2.6.2浮点乘法、除法运算2.6.3浮点运算流水线2.6.4浮点运算器实例2.6.1浮点加法、减法运算22024/6/532.6.1浮点加法、减法运算浮点加减运算步骤如下：1.0操作数检查；2.比较阶码大小并完成对阶；3.尾数求和/差运算；4.结果规格化5.舍入处理6.溢出处理2024/6/542.6.1浮点加法、减法运算0操作数检查能否简化操作、节省运算时间比较阶码大小并完成对阶对阶：使得小数部分可以按位权值相加变为定点数定点加法器运算小数点位置是否对齐对阶:小阶向大阶看齐2.6.1浮点加法、减法运算两个浮点数相加：1.11011×231.11011×25浮点格式中，尾数为定点小数如果向小阶对齐，尾数左移易导致高位数据丢失如果向大阶对齐，尾数右移丢失的是低位数据52024/6/562.6.1浮点加法、减法运算2024/6/572.6.1浮点加法、减法运算2024/6/58IEEE754的四种舍入方法就近舍入：类似于四舍五入，多余位：最低有效位之后的若干位，用于舍入判断多余位中间值位：100…0多余位比100…0大，进位；比100…0小，舍去对于100……0的情况：有效位末尾是1：进1有效位末尾是0：舍弃例：保留有效位到0.0010.10111-0.001010.11110-0.01010IEEE754的四种舍入方法朝0舍入：截尾保留有效位到0.001：0.10111-0.001010.11110-0.0101092024/6/510IEEE754的四种舍入方法IEEE754的四种舍入方法11M＝10011001100110011001100110011例题：真值0.2，求32位单精度浮点数②移动小数点，使其在第1、2位之间S＝0e＝-3，E＝-3+127＝124＝01111100③得到32位浮点数的二进制存储格式为：00111110010011001100110011001101＝(3E4CCCCD)1623位就近舍入2024/6/5132.6.1浮点加法、减法运算真值0的机器数（机器零）阶码E＝0，尾数M＝0正0：S＝0，负0：S＝1非规格化浮点数：阶码E＝0，尾数M≠0规格化浮点数：阶码E＝1～254（11111110）无穷大的机器数阶码E＝全1（11111111），尾数M＝0＋∞：S＝0，－∞：S＝1NaN（notanumber，不是一个数）阶码E＝全1（11111111），尾数M≠0用来通知异常情况IEEE754标准32位单精度浮点数2024/6/5152.6.1浮点加法、减法运算2.6.2浮点乘法、除法运算222.6.2浮点乘法、除法运算232.浮点乘、除法运算步骤浮点数的乘除运算大体分为六步：①0操作数检查；②阶码加/减操作；③尾数乘/除操作；④结果规格化；⑤舍入处理；⑥确定积的符号；2.6.2浮点乘法、除法运算(1)浮点数的阶码运算乘法：两阶码求和，减偏移量除法：两阶码求差，加偏移量(2)尾数处理规格化与舍入与浮点加减法相同24现代处理中的浮点运算单元浮点运算单元FPU，floating-pointUnit27华为海思麒麟9904个ALU、2个FPUARMA77中的FPU28RISC-V中的FPU用于物联网的一种处理器架构平头哥玄铁9103个ALU、1个FPU29龙芯3A400030FP32浮点性能比较31以CNN为例，用于输入图像大小为224×224的分类任务的典型CNN模型需要高达390亿次(39G)FLOP和500MB以上的模型参数。第二章小结一个定点有符号数由符号位和数值域两部分组成。按小数点位置不同，定点数有纯小数和纯整数两种表示方法。按IEEE754标准，一个单精度浮点数由符号位S、阶码E、尾数M三个域组成。阶码E等于指数的真值e加上固定偏移值12732第二章小结数的真值变成机器码时四种表示方法：原码，反码、补码和移码移码主要用于表示浮点数的阶码字符信息属于符号数据，国际上采用的字符系统是7位的ASCII码。汉字有输入码、汉字内码和输出码三种不同用途的编码。为运算器构造的简单性，运算方法中算术运算通常采用补码加、减法，原码乘除法。33第2章教学要求-1掌握定点整数（有符号数和无符号数）的表示范围掌握IEEE754单精度浮点格式的表示，规格化，与真值的相互转换理解真值和机器数，掌握定点整数的补码、反码、原码，理解移码表示法了解汉字输入编码、机内码、输出码理解检验码的作用，掌握奇偶校验第2章教学要求-2掌握补码加减法运算掌握溢出的概念及检测方法理解运算器的三种组成方式掌握浮点加减法运算步骤理解IEEE754标准的4种舍入处理方法，掌握就近舍入C语言数据表示非数值数据char(8位)数值数据定点整数signed/unsignedchar(8位)/short（16位）/int（32位）/long（64位）浮点数Float（32位）/double（64位）-1-C语言中的整数（定点数）无符号整数unsignedchar/unsignedshort/unsignedint一般用于地址运算有符号整数char/short/int/long采用补码表示无符号整数/带符号整数的最大值8位无符号整数最大是255（11111111）8位带符号整数最大为+127（01111111）-2-编程实践在线编程网站https://c.runoob.com/compile/9c、c++、python等https://gcc.godbolt.org/离线python：anacondac：ubuntu、gcc数据的真值、机器码、存储值间的关系3C语言中的机器码？ex2_1.c-4-intmain(){chara=127,b=128,c=129,d=257;printf("%d\n",a);printf("%d\n",b);printf("%d\n",c);printf("%d\n",d);}127-127-128？？？？无符号数赋值补码真值输出变量a,b,c,d机器码实际存储值是多少？1变量的内存值ex2_2.c-5-main(){chara=127,b=128,c=129,d=257;printf("a=%d=%X\n",a,a);printf("b=%d=%X\n",b,b);printf("c=%d=%X\n",c,c);printf("d=%d=%X\n",d,d);}a=127=7Fb=-128=FFFFFF80c=-127=FFFFFF81d=1=1补码输出机器码输出32位补码表示范围[-231，231-1]-6-00000000000000000000000000000000two=01000000000000000000000000000000001two=+11000000000000000000000000000000010two=+210...01111111111111111111111111111110two=+2,147,483,646ten01111111111111111111111111111111two=+2,147,483,647ten10000000000000000000000000000000two=–2,147,483,648ten10000000000000000000000000000001two=–2,147,483,647ten10000000000000000000000000000010two=–2,147,483,646ten...11111111111111111111111111111101two=–3ten11111111111111111111111111111110two=–2ten11111111111111111111111111111111two=–1ten程序ex2_3.c-7-main(){intx=-1;unsignedu=2147483648;printf("x=%u=%X=%d\n",x,x,x);printf("u=%u=%X=%d\n",u,u,u);}机器码输出真值赋值x=4294967295=FFFFFFFF=-1u=2147483648=80000000=-2147483648无符号数输出一个奇怪的程序ex2_4.c8main(){doublea,b,c;intd;b=3.3;c=1.1;a=b/c;d=b/c;printf("%f,%d\n",a,d);if(3.0!=a)printf("Really?3.0!=a\n");}3.000000,2??????????Really?3.0!=a二进制存储浮点数不是精确数浮点转整数只保留浮点数的整数部分Double3.3/1.1ex2_5.cmain(){doublea,b,c;b=3.3;c=1.1;a=b/c;printf("a=%.60f\n",a);printf("b=%.60f\n",b);printf("c=%.60f\n",c);printf("a=%f,n",a);}-9-a=2.999999999999999555910790149937383830547332763671875000000000b=3.299999999999999822364316059974953532218933105468750000000000c=1.100000000000000088817841970012523233890533447265625000000000a=3.000000一个奇怪的程序ex2_6.c10main(){floata,b,c;intd;b=3.3;c=1.1;a=b/c;d=b/c;printf("%f,%d\n",a,d);if(3.0!=a)printf("Yeah!\n");}3.000000,3Float3.3/1.1ex2_7.cmain(){floata,b,c;b=3.3;c=1.1;a=b/c;printf("=%.60f\n",a);printf("b=%.60f\n",b);printf("c=%.60f\n",c);}-11-a=3.000000000000000000000000000000000000000000000000000000000000b=3.299999952316284179687500000000000000000000000000000000000000c=1.100000023841857910156250000000000000000000000000000000000000a=3.000000舍入的影响例题假定变量i、f和d的数据类型分别为int、float和double（int用补码表示，float和double分别用IEEE754单精度和双精度浮点数格式表示），已知i=785，f=1.5678e3，d=1.5e100。若在32位机器中执行下列关系表达式，则结果为“真”的是I．i==(int)(float)iII．f==(float)(int)fIII．f==(float)(double)fIV．(d+f)-d==fA．仅I和IIB．仅I和IIIC．仅II和IIID．仅III和IV解答float到double的转换完全相等double到float转换可能会发生舍入float/double到int，小数部分会丢弃int到float，当int有效数字超过24位，转换时需要舍入int到double，double尾数53位，能精确表示int型13I．i==(int)(float)ifloat是单精度，尾数24位int型有效数字有31位i=785,能实现精确转换，条件成立若i=16777217=224-114II．f==(float)(int)ff=1.5678e3浮点转换整数，只保留整数部分，小数部分舍去条件不成立15III．f==(float)(double)f双精度尾数53位f=1.5678e3,单精度float转double有效数字不变,条件成立若doublef=1.5678e3f==(double)(float)f则不成立16IV．(d+f)-d==f浮点运算不满足交换律、结合律(d+f)-d不等于(d-d)+f(d+f)-d不等于d+(f-d)C语言中单双精度混合运算，都按照双精度处理大数吃小数，两个差别巨大的浮点数相加，较小的数由于有效数字位数不够，会被舍去17浮点处理精度造成的事故1990年2月25日，海湾战争期间，在沙特的爱国者导弹防御系统未能拦截一枚伊拉克飞毛腿导弹，造成28名美军死亡。原因是浮点数舍入误差导致爱国者反导系统的计算机精度仅有24位，存在0.0001%的计时误差，所以有效时间阙值是20个小时。当系统运行100个小时以后，已经积累了0.3422秒的误差。这个误差导致导弹系统不能正确地瞄准目标。浮点处理精度造成的事故19失之毫厘，谬以千里浮点处理精度问题解决办法制度：每隔二十小时重启一次硬件：修改24位为32位或64位软件：升级软件20其他案例1996年6月4日，在阿丽亚娜五号运载火箭发射后37秒，偏离预定轨道炸毁。原因是软件系统将64位浮点数转换为16位浮点数，造成计算错误。温哥华证券交易所在1982年推出一项股票指数，指数的值是1000.000。后来，重新计算时多次运用舍入到小数点后三位的操作。22个月以后，指数的值是524.881，然而事实上应该是1009.81121浮点处理精度问题树立计算机系统的思想，理解软硬件的相互影响小概率事件常会导致大损失，在工程实践中要精益求精221第三章多层次存储器3.1存储器概述3.2SRAM存储器3.3DRAM存储器3.4只读存储器和闪速存储器3.5并行存储器3.6Cache存储器3.7虚拟存储器3.8奔腾系列机的虚存组织3.1存储器概述存储器是计算机系统中的记忆设备，用来存放程序和数据存储器中最小的存储单位叫存储元，可存储1bit若干个存储元组成一个存储单元许多存储单元组成一个存储器23.1.1存储器的分类按存储介质满足两个基本要求：有两个明显区别的状态，分别表示0和1两个状态的改变速度要快，影响存储器的读写速度半导体存储器：内存，闪存速度快、容量小，成本高磁表面存储器：磁带、磁盘容量大，速度慢、成本低光盘存储器：DVD、蓝光容量大，速度慢，成本低按存取方式随机存储器RAM（RandomAccessMemory）任何存储单元的内容都能被随机存取，且存取时间和存储单元的物理位置无关内存顺序存储器按顺序存取，存取时间和存储单元的物理位置有关磁带、磁盘33.1.1存储器的分类按信息掉电易失性非易失性存储器Non-VolatileMemory断电后仍能保存信息磁表面存储器、光盘存储器、闪存易失性存储器VolatileMemory断电后信息立即消失内存(SRAM、DRAM)半导体存储器按其存储内容可变性只读存储器(ROM-ReadOnlyMemory)存储的内容一般是固定不变的，只能读出而不能写入随机读写存储器(RAM)：既能读出又能写入43.1.1存储器的分类按在计算机系统中的作用主存储器：和CPU直接交换信息辅助存储器：主存的后援存储器高速缓冲存储器Cache：用于两个速度不同的部件之间，起到缓冲作用控制存储器等53.1.2存储器的层次结构CPU对存储器的要求容量大、速度快、价格低（每位价格）目前技术下，存储器的特点是：速度快的存储器价格贵，容量小；价格低的存储器速度慢，容量大不可能三角:既要。。。又要。。。。还要。。。。从在容量，速度和价格作折中考虑，建立存储器层次结构6存储系统层次结构存储速度访问频率单位成本存储容量外存/辅存内存-7-83.1.2存储器分级结构三级存储系统3.1.3存储器的编址和端模式存放一个字节的单元称为字节存储单元，其地址称为字节地址一个字由多个字节组成，存放一个字的单元称为字存储单元，其地址称为字地址存储器编址编址的最小单位是字单元，称为按字编址编址的最小单位是字节单元，称为按字节编址既可以按字编址，也可以按字节编址存储器访问按地址访问：按字节地址访问、按字地址访问。9字的概念字：wordawordisthenaturalunitofdatausedbyaparticularprocessordesign.一串固定长度的二进制数，对应部件处理数据的固定长度。不同的部件其字长不同计算机字长、机器字长、运算器字长存储器字长、存储芯片字长指令字长10存储器的编址11字节地址机器字长32位16个字节存储单元组成存储器按字节编址存储器的编址12机器字长32位16个字节存储单元组成存储器按字编址存储器的编址13字节地址机器字长32位，16个字节存储单元字节编址下按字访问存储该字的第一个字节的字节单元地址为该字的字地址存储器的编址14字节地址机器字长16位，16个字节存储单元存储器的编址设有一个1MB容量的存储器，字长32位，问：按字节编址，按字编址各自的寻址范围?按字节编址：20位字节地址，0x0~0xFFFFF按字编址：18位字地址，0x0~0x3FFFF15数据的存储和排列顺序上世纪80年代开始，几乎所有计算机都以字节编址存储系统和指令设计时要考虑的问题（按字节编址，按字访问）：一个字如何在字节单元存放？-字的存放顺序问题(端模式\字节序\端序\尾序)字地址与字节地址关系-字的边界对齐问题存储器的端模式：存储字为多个字节时，在存储器中存放顺序大端(big-endian)：大尾端优先存储，高字节在低地址MIPS，IBM360/370,Sparc,网络传输小端(little-endian)：小尾端优先存储，低字节在低地址。X86(高高低低)ARM的端模式可通过寄存器改变-16-3F27LSBMSBA831D0D313F27LSBMSBA831D0D31数据在内存中的存放顺序将0x12345678写入到以0x0000开始的内存中-19-内存地址对齐20内存按字节编址16位访问对齐32位访问对齐字节编址下的按字访问：以一个字中最低字节的字节地址作为该字的字地址对齐：字地址能被字节数整除。字长为16位，包含2个字节，其字地址能被2整除，地址最低位为0；字长为32位，包含4个字节，其字地址能被4整除，最低两位为0.Alignment(对齐)-21-如：inti,shortk,doublex,charc,shortj,……则：&i=0;&k=4;&x=8;&c=16;&j=18;……x：2个周期j：1个周期目前来看，浪费一点存储空间没有关系！则：&i=0;&k=4;&x=6;&c=14;&j=15;……x：3个周期j：2个周期存储器按字节编址，CPU按字对齐访问，字长32位变量地址没有对齐变量地址对齐虽节省了空间，但增加了访存次数！22#include<stdio.h>//内存对齐测试intmemory_display(longunsignedintaddr)//以16进制输出addr开始的16个内存字节单元{inti,j;for(i=0;i<4;i++){printf("0x%lX:\t",addr+i*4);for(j=0;j<4;j++){printf("0x%X\t",*(unsignedchar*)(addr+i*4+j));}printf("\n");}return0;}intmain(){inti=13457;shortj=345;charc='A';intk=123;printf("i=0x%X\n",i);printf("j=0x%X\n",j);printf("c=0x%X\n",c);printf("k=0x%X\n",k);printf("intImemoryaddressis0x%lX\n",(longunsignedint)&i);printf("shortjmemoryaddressis0x%lX\n",(longunsignedint)&j);printf("charcmemoryaddressis0x%lX\n",(longunsignedint)&c);printf("intkmemoryaddressis0x%lX\n",(longunsignedint)&k);memory_display((longunsignedint)&i-16);memory_display((longunsignedint)&i);}23内存对齐是一种软硬件协同提高性能的一种方式3.1.4主存储器的技术指标3.2SRAM存储器内部存储器是半导体存储器根据信息存储的机理不同可以分为两类：静态读写存储器(SRAM-Static)：速度快、成本高、容量小、功耗低，一般用作Cache动态读写存储器(DRAM-Dynamic)：容量大、成本低、速度慢、功耗高、用作主存25263.2.1基本的静态存储元阵列存储位元SRAM的存储位元是由两个MOS反相器交叉耦合而成的触发器，一个存储位元存储一位二进制代码六管SRAM存储元的电路结构示意图3.2.1基本的静态存储元阵列三组信号线地址线字数数据线字长控制线27单译码结构：1个译码器N位地址，寻址2n个存储单元存储元阵列又称存储芯片63芯片容量=字数X字长=存储单元数量X存储单元字长3.2.2基本的SRAM逻辑结构大容量SRAM芯片采用双译码方式：将地址分成行、列两部分，降低译码电路的规模CS：ChipSelect片选3.2.3读/写周期波形图先给地址，再给片选和读信号3.2.3读/写周期波形图先给地址，再给片选和是写信号3.3.1DRAM存储位元的记忆原理DRAM存储器的存储位元是由一个MOS晶体管和电容器组成的记忆电路31电容用于存储电荷，有电荷代表1，否则代表0MOS管电容器读放读出1是破坏性读出由于(c)中读出1是破坏性读出，必须恢复存储位元中原存的1输入缓冲器关闭，刷新缓冲器打开，输出缓冲器读放打开，DOUT=1经刷新缓冲器送到位线上，再经MOS管写到电容上3.2.2DRAM芯片的逻辑结构两个电源Vcc两个地线脚一个空管教NC11个地址线A0~A114个数据线D1~D436方法：复用地址线A0-A9存储器需要地址20位，但芯片物理地址引脚只有11位，如何处理？1M×4位DRAM芯片的管脚图373.2.2DRAM芯片的逻辑结构与SRAM芯片不同之处增加了行地址锁存器和列地址锁存器增加了刷新控制电路DRAM读出后必须刷新，而未读写的存储元也要定期刷新（电容自放电），按行刷新，刷新计数器的长度等于行地址锁存器刷新操作与读/写操作交替进行通过2选1开关来选择刷新行地址或正常读/写的行地址383.3.3读/写周期、刷新周期39先给行地址和行选通，再给列地址和列选通403.3.3读/写周期、刷新周期3.3.3刷新周期刷新：DRAM存储元基于电容器上的电荷存储信息，电荷量随着时间和温度而减少，因此必须定期地刷新，以保持原来记忆的正确信息刷新过程：将原有信息读出，再由刷新放大器形成原信息并重新写入的过程刷新按行进行刷新周期：从上次对整个存储器刷新结束到下次对整个存储器全部刷新一遍为止的时间间隔称为刷新周期集中式刷新分散式刷新41集中刷新方式例:1024行,工作周期=500ns,刷新周期=8ms8ms内集中安排所有刷新周期总工作周期数=8ms/500ns=16000个用在实时要求不高的场合集中式刷新：DRAM的所有行在每一个刷新周期中都被刷新刷新期间停止正常读写分散刷新方式各刷新周期分散安排在8ms内每隔一段时间刷新一行每隔15.5微秒提一次刷新请求，刷新一行；8毫秒内刷新完所有行用在大多数计算机中8ms1024行≈7.8微秒=7800ns主存储器特点由半导体存储器组成存储单元：字存储单元，字节存储单元编址：按字节编址按地址进行访问：字节地址访问字，访问字节属于随机访问存储器RAMDRAM需要刷新-44-3.3.5高级的DRAM结构FPMDRAM：快速页模式动态存储器SDRAM同步动态存储器读写操作与CPU时钟同步,猝发式读取：输入一个行地址，一个列地址，连续读出后续几个列地址数据45输入一个行地址，连续输入多个列地址，该行中的对应列的存储单元数据就连续输出DDRSDRAMDDR：DoubleDateRateDDR在相同时钟频率下的数据传输速率比SDRAM提高一倍上下沿都传输数据DDR2、DDR3：时钟频率比上一代提高一倍，速率提高一倍46DDRSDRAM47全球DRAM产业三星技术最先进，产量最大2021年10月开始大规模生产基于EUV的14nmDDR54849中国DRAM产业发展1975年，中国第一块1KDRAM诞生，但总体技术力量薄弱，和国外差距比较大，没有竞争力。21世纪后，通过政府扶持、自主研发、技术引进、收购等方式逐步建立起国产DRAM产业。2015年的紫光收购德国奇梦达、收购美国ISSI。目前，国产DRAM市场的主要厂家紫光国芯、福建晋华、合肥长鑫、长江存储等。2019年9月，合肥长鑫宣布正式量产DDR42023年预计将试产17nmDDR5,产能大约能占到全球内存产能的3%，目前最被看好50困难和阻力全球半导体需求将近1/3来自中国2016年开始，美光开始对福建晋华发起诉讼2018年10月30日，美国商务部将福建晋华添加进实体清单，导致整个企业进度不理想2017年，美光曾对从台湾华亚科跳槽到合肥长鑫的上百名员工发存证信函51砥砺前行从DRAM内存的角度来说，中国企业在技术、产业链方面，距离全球顶尖的厂商都有较大的差距，产品自给率方面更是不容乐观。我们需要进一步加大企业自主创新+国家意志支持的力度，坚定IDM的发展模式，进行产业全链路的布局，高度重视技术、专利的原创性，避开巨头们的干扰、阻挠。只有做到这些，才能在机遇和风险并存的产业环境中不断前行，实现我们在半导体产业独立自主的目标。5213.4只读存储器3.4.1只读存储器概述3.4.2Flash存储器3.4.3存储器容量扩展23.4.1只读存储器概述只读存储器ROM：Read-OnlyMemory在正常工作状态下只能读取数据，不能写入数据掉电不易失ROM和RAM都属于内部存储器，属于同一个内存空间用于保存计算机运行所需的最基础、最核心的程序。BIOS：基本输入输出系统引导程序等8086内存空间3总容量1MBRAMROMRAMROM43.4.1只读存储器概述ROM中写数据称为编程(program)，包括擦除和写入根据是否可编程，分为：掩模ROM：制造中写入信息，用户无法更改可编程ROM：用户可写入内容PROM：可编程一次EPROM和E2PROM：可多次编程EPROM：紫外线擦除，专用设备写入E2PROM：电擦除，联机写入EPROM-ErasePROM紫外线擦除，编程器写入EPROM上方有一个石英窗口。将芯片置于紫外灯下，以擦除其中的内容，相当于存储器又存了全“1”。然后用专用的设备将信息重新写入6E2PROME2PROM为ElectricErasePROM电擦除，擦除时间较快联机写入无需把器件从电路板取下E2PROM允许改写上千次，编程大约需20ms，数据可存储20年以上73.4.2Flash存储器在E2PROM基础上发展而来高密度、非失易失性有很高的读取速度，易于擦除和重写，功耗小FLASH存储器的逻辑结构8(重点)存储器容量扩充一、存储芯片简介二、存储器容量扩展的三种方法位扩展字扩展字位扩展一、背景知识——存储芯片简介存储芯片的引脚芯片容量：字数×字长(存储单元数量×存储单元的位数)9二、存储器容量扩展的三种方法1、位扩展给定芯片的字长较短，不满足存储器字长要求，要用多片来扩展字长2、字扩展给定的芯片字数少，用多片给来扩展字数3、字位扩展从字长和字数两个方向扩展101、位扩展111、位扩展12存储器一个存储单元分为高4位和低4位分别位于两个芯片中两个芯片并行工作1、位扩展总容量=210×8位131、位扩展142、字扩展152、字扩展162、字扩展分析地址：存储器地址线A10~A0A10用于选择芯片A9~A0用于选择芯片内的某一存储单元172、字扩展182、字扩展192、字扩展203、字位扩展需扩展的存储器容量为M×N位,已有芯片的容量为L×K位(L<M,K<N)21用M/L组芯片进行字扩展每组内有N/K个芯片进行位扩展222324每4片一组进行位扩展258组进行字扩展26存器容量与地址范围的关系高3位通过3：8译码器产生每组的片选信号278组进行字扩展28字位扩展一起画29例：设CPU有16根地址线，8根数据线，并用MREQ#作访存控制信号，用R/W#作读/写控制信号。现有下列存储芯片：SRAM：1K×4、4K×8、8K×8；ROM：2K×8、4K×8、8K×8；及3：8译码器和各种门电路主存的地址空间满足下述条件：最小8KB地址为系统程序区(ROM区)，与其相邻的16KB地址为用户程序区(RAM区)，最大4KB地址空间为系统程序区(ROM区)。请画出CPU与存储器的连接图。三、主存储器与CPU的连接确定各区域地址范围；根据存储器容量，确定存储芯片的数目和扩展方法；分配地址线地址线低位直接连接存储芯片的地址线；高位地址线参与形成存储芯片的片选信号；连接数据线、读写控制等其他信号线MREQ#可用作地址译码器的使能信号3031解：1）根据题目的地址范围写出相应的二进制地址码。存器容量与地址范围的关系32333.5并行存储器加速CPU与存储器之间的数据传输的方式：采用更高速性能的存储器，加大字长采用并行操作的双端口存储器在CPU和主存之间使用高速缓存Cache在每个存储周期中存取多个字多模块交叉存储器DDR34353.5.1双端口存储器结构特点：具有左右两个端口，每一个端口都有独立的读写控制电路读写冲突：若左、右端口同时对相同的存储单元进行读写操作左读右写、右读左写、左写右写解决方法：判断逻辑决定对哪个端口优先进行读写操作，而暂时关闭另一个被延迟的端口，即置其忙信号BUSY#=0。36双端口存储器IDT7133逻辑框图R37双端口存储器读写时序CE判断：如果地址匹配且在CE之前有效，片上的控制逻辑在CEL和CER之间进行判断来选择端口。383.5.2多模块交叉存储器设存储器由M个的独立的存储模块组成，每个模块有相同的容量和存取速度存储模块就是存储芯片存储器地址的编排方式：顺序方式和交叉方式。顺序方式：地址按顺序分配给一个模块后，又按顺序为下个模块分配39内存地址模块2bit字3bitM0M1M2M3数据总线顺序方式5位地址：高2位选模块，低3位选块内地址故障隔离扩充容量比较方便连续地址单元在同一个模块，各模块串行工作带宽没有提升403.5.2多模块交叉存储器交叉方式：两个相邻地址的物理单元不属于同一个存储模块，一般在相邻的存储模块中；同一个存储模块内的地址都不连续。41内存地址模块2bit字3bitM0M1M2M3数据总线交叉方式5位地址：高3位选块内地址，低2位选模块连续地址单元在不同同模块，各模块并行工作存储对齐（软件）+交叉编址（硬件）可以系统运行速度3.5并行存储器42地址总线ABUSM0M1M2M3单字长数据总线DBUS交叉编址ARARARARCPU每个模块独立工作各模块分时使用数据总线进行信息传递。流水线方式数据总线是瓶颈43多体交叉存储器流水线方式存取示意图连续读取m个字所需的时间为模块内访问一个存储单元（字）的存储周期是T多体并行存储器44地址总线ABUSM0M1M2M3多字长数据总线DBUS交叉编址ARARARARCPU也称为多通道优化瓶颈多模块应用两条4G内存条单条8G内存条性能差异？-45-双通道内存实例128bit-46-双通道内存性能评测SiSoftwareSandraProBusiness2011HPDL120G7IntelSandyBridge-47-新型存储器:PCRAM相变储存器又称PCM和CRAM，它利用相变材料作为储存介质。相变材料在非晶相态时具有较高的电阻值；在结晶相态时具有较低的电阻值非易失性存储器对相变材料施加不同时长的电脉冲，使相变材料呈现出不同的结晶状态，并在两种状态之间快速切换储存密度较DRAM更高48新型存储器:ReRAM电阻式存储器也称RRAM，是以非导性材料（金属氧化物）为存储介质的非易失性存储器施加电压，材料的电阻在高阻态和低阻态间发生相应变化，并利用这种性质储存各种信息。RRAM不仅高读写速度和高存储密度，同时延迟更低49新型存储器:MRAM和FRAMMRAM是一种利用磁性工作的非易失性随机存储器。基于两个铁磁层磁化状态来存储信息，当电流流过时会表现出不同的阻值。FRAM，采用铅锆钛形成结晶体存储数据。通过判断晶体内的电荷高低来读取数据。503.6Cache存储器13.6Cache存储器为什么要引入Cache？解决CPU和主存之间的速度不匹配问题延迟（ns）和带宽（GB/s）2CPU带宽简单测算个人电脑的DDR4-3200内存单通道带宽25600MB/sCPU默认频率位1500MHz，4核心64位处理器，每次运算需要2个数据CPU所需带宽：1500x4x(8+8)=96000MB/s内存墙（memorywall）343.6Cache存储器在CPU和内存之间设置一个小容量的存储器Cache，保存的内容是主存内容的一个子集Cache存取速度要比主存快，用SRAM实现Cache功能全由硬件调度，对所有用户透明运行过程无需软件参与52.Cache基本原理程序的局部性原理在一段时间内，程序的执行仅限于程序中的某一部分。相应地，执行所访问的存储空间也局限于某个内存区域时间局部性：被访问过一次的内存区域在未来会被多次访问空间局部性：如果一个内存区域被访问，那么将来它附近的单元也会被访问6sum=0;for(i=0;i<n;i++)sum+=a[i].x+a[i].y;returnsum;程序局部性举例数据数组元素访问(空间)结构体、数据库记录访问(空间)局部变量，计数器，指针等被重复使用(时间)指令顺序访问的指令(空间)重复使用的循环体(时间)子函数(时间)-7-程序局部性举例程序1：inta[M][N];for(i=0;i<M;i++)for(j=0;j<N;j++)sum+=a[i][j];程序2：inta[M][N];for(j=0;j<N;j++)for(i=0;i<M;i++)sum+=a[i][j];哪个程序具有更好的局部性-8-93.Cache的命中率10Cache的平均访问时间11Cache的访问效率12例3.4CPU执行一段程序时，Cache完成存取的次数为1900次，主存完成存取的次数为100次，已知Cache存取周期为50ns，主存存取周期为250ns，求Cache/主存系统的效率和平均访问时间。解：13背景：相联存储器（CAM）普通存储器都是按地址访问相联存储器是按内容访问ContentAddressableMemory相联存储器的基本原理存放在相联存储器中的内容：标记+数据查找的主要操作是比较按地址访问存储器按地址访问：存储器只保存数据，数据的地址不保存寻址时译码器根据地址直接选中对应数据14按地址访问：存储器只保存数据，数据的地址不保存寻址时译码器根据地址选中对应存储单元15按地址访问存储器按内容访问：增加标记(标识、Tag)，一般用地址的部分或全部查找时，将访问地址和表中的所有标记比较，相同的一行就是要访问的存储单元16CAM存储器按内容访问：增加标记(标识、Tag)存储，一般用地址的部分或全部作为标记查找时，将访问地址和标记存储中的所有标记比较，相同的一行就是要访问的存储单元17CAM存储器相联存储器在计算机系统中，CAM主要用于需要快速查找的领域：虚拟存储器中存放段表、页表和快表；Cache网络设备中路由的查找18193.6.2主存与Cache的地址映射203.6.2主存与Cache的地址映射Cache分为若干行（Line），每行的容量和主存块相同Cache与主存的数据交换是以块为单位Cache按内容访问，主存按地址访问必须应用某种方法，把主存的地址定位到Cache中的确切位置——地址映射例题主存地址空间大小为256MB，按字节编址。主存块大小为64B。数据Cache有8行假定int型数据为32位补码，数组a按行优先方式存放，首地址为320（十进制）1）数据Cache的总容量是多少？2）数组元素a[0][31],a[1][1]所在主存块分别是多少?inta[256][256];Cache原理图22主存分块Cache替换管理Cache与主存之间的数据交换是以块为单位CPU与Cache/主存之间的数据交换是以字为单位标记存储Cache数据存储Cache的基本工作原理示意图23CPU将内存地址同时发往Cache和主存。Cache的四个问题当把一块调入Cache时，放在哪行?（映射方式）全相联、直接映射、组相联如何判断当所要访问的地址在Cache中?（地址变换）当发生失效时，应替换哪一行？（替换算法）当进行写操作时，应进行哪些操作?（写策略）保证数据的一致性241.全相联多对多：主存一个块可以放到Cache任一行将整个块地址作为Cache行的标记25XXXXXXXXXX主存地址：块号（s位）块内偏移（w位）2r=8行2s=256块2w=4字B0B1B2B3B124B124B3B1B0B21.全相联26主存256块，每块4个字，Cache有8行1.全相联地址变换CPU将内存地址同时发往Cache和主存发往Cache的访存地址会分为块地址和块内偏移块地址同时和Cache中所有行的Tag进行比较相同表示命中，再根据块内偏移从该行中读取一个字，同时撤销内存寻址过程若没有命中，则等待访存过程结束，然后将被访问内存的相对应块调入Cache270000000000000001000000100000001101011000010110010000001001011001010000001010000000100000000101011001块地址（块号）1.全相联地址变换内存地址11111111281.全相联特点：优点：冲突概率小，Cache的利用高。冲突：所选择的Cache行包含近期要使用的信息缺点：比较电路实现成本高适用于小容量的Cache292.直接映射30312.直接映射Cache将s位块地址分为两部分：低r位作为Cache的行号（index）:r=log2m高s-r位作为该行tag直接映射的Cache组织32332.直接映射-地址变换第一步：用访存地址中的块号的r位行号找到Cache中对应的一行第二步：用块号的s-r位与该行的tag比较。若命中，而后用低w位读取所要求的字若不命中，访问主存二、直接映射映射检索过程000000000000000100000010000000110101100001011001010110110101101001011111010000001011010111100101011块号蓝色：行号；绿色：字地址Cache地址000Cache地址010Cache地址111342.直接映射优点：硬件简单，成本低缺点：每个块只有一个固定的行可存放，容易产生冲突频繁置换会导致Cache抖动，效率下降适合大容量Cache采用更多行减小冲突353.组相联将Cache分成u组，每组v行组间采用直接映射，组内采用全相联映射主存中的每一块可以被放置到Cache中唯一的组的任何一行组相联是全相联和直接映射的折中方案q组号，j主存块地址、m为Cache总行数m＝u×v组号q＝jmodu设u＝2d，q=log2d:363.组相联映射方式低d位表示组号(组索引，组index)高s-d位作为tag37Cache分为4组，每组2行383.组相联映-地址变换第一步：用块号的低d位找到对应组第二步：将块号的高s-d位与该组中所有行的标记同时进行比较命中，选中该行，用内存地址的低w位选择相应的字不命中，则访问内存39三、组相联映射地址变换000000000000000100000010000000110101100001011001111111110101101001011000110000001001001011000000010110000000010110块号蓝色：组号；绿色：字地址403.组相联映射方式特点：比全相联容易实现，冲突低u=1，则为全相联映射方式v表示每组的行数，称之为v路组相联Cache。v=1，则为直接映射方式得到普遍采用41全相联映射载入过程221011022611010222101102261641618载入载入命中命中载入载入命中载入t222616418主存32块，Cache8行42直接相联映射载入过程22（10110）22261641618载入载入命中命中载入载入命中替换t2226164161826（11010）主存32块，Cache8行432路组相联映射载入过程222622261641618载入载入命中命中载入载入命中载入t222616418主存32块，Cache8行44Cache基本概念Cache的作用：解决CPU和主存之间的速度不匹配问题小容量存储器，用SRAM实现对用户透明Cache的原理程序局部性：时间和空间Cache性能命中率、平均访问时间、效率1Cache基本概念CAM按内容访问、比较器主存地址：块地址和块内偏移Cache分为若干行（Line），每行的容量和主存块相同Cache与主存的数据交换是以块为单位21.全相联多对多：主存一个块可以放到Cache任一行将全部块地址作为Cache行的标记31.全相联地址变换CPU发出的访存地址中的块地址同时和Cache中所有的Tag进行比较。特点冲突概率小，成本高适用于小容量的Cache42.直接映射多对一：一个主存块只能映射到Cache的一个特定行上562.直接映射-地址变换地址变换用访存地址中的块号的r位行索引找到Cache中对应的行然后用块号的s-r位与该行的tag比较。特点硬件简单，成本低，容易产生冲突频繁置换会导致Cache抖动，效率下降适合大容量Cache采用3.组相联将Cache分成u组，每组v行V路组相联组间采用直接映射，组内采用全相联映射73.组相联映-地址变换地址变换首先访存地址的块地址的低d位找到对应组，然后将块地址的高s-d位与该组v行中的所有tag同时进行比较。特点比全相联容易实现，冲突低全相联映射和直接映射的折衷得到普遍采用8910一个4路组相联Cache由64行组成，主存储器包含4K个块，每块128字。请表示主存地址的格式？典型题组相联映射下的主存地址格式如下：每块128字块内的字地址需要7位Cache由64个行组成，每组4行Cache共包含16组，需4位组号主存包含4K个块主存块号为12位标记位12－4=8位7位4位8位解：主存容量1M=220，主存地址共20位块大小=24字节，字号(块内偏移)w=4块地址：20-4=16位全相联映射，标记位数等于块地址位数，为16位主存格式主存地址(F0010)16=(11110000000000010000)2对应的标记=1111000000000001字号=000011有一个存储体系，主存容量1MB，字长1B，块大小16B，Cache容量64KB。若Cache采用全相联映射，对内存地址（F0010H）给出相应的标记和字号。例：某PC主存容量为128KB,Cache容量4KB,每块32B。主存多少块？块地址多少位？Cache多少行？主存块：128K/32=4K，块地址占12位Cache行：4K/32=128=27用直接映射时，Cache标记几位？12位块地址中，低7位定位Cache行，高5位为标记用全相联映射，Cache标记几位？12位12例：某计算机的Cache有16行，采用二路组相联映射方式，每个主存块大小为32字节，按字节编址。则主存129号单元的主存块装如Cache的组号是：A、0B、2C、4D、6解：二路组相联，共有16/2=8组，组号占3位。每块32字节，所以块内地址占5位。129转化为二进制：100_00001：前3位为组号，组号为4。129/32=4，4mod8=413块地址=块号块内偏移=块内地址=字地址=字号143.6.3替换策略当从主存向Cache传送一个新块，而Cache中可用位置已被占满时，就会产生替换问题直接映射：替换Cache中指定的一行全相联和组相联：从所有行或组内所有行中选取一行换出Cache的常用替换算法：最不经常使用LFU算法近期最少使用LRU算法随机153.6.3替换策略最不经常使用LFU(LeastFrequentlyUsed)算法每行设置一个计数器，0开始计数每访问一次，被访行的计数器增1。当需要替换时，将计数值最小的行换出，同时将该行的计数器都清零。不能严格反映近期访问情况。刚调入Cache的新行很容易被换出16173.6.3替换策略例子：设Cache有1、2、3、4共4行(全相联映射)，a、b、c、d、e等为主存中的块,访问顺序一次如下：a、b、c、d、c、b、c、e、d、d、a,e。1）采用LFU算法替换18计数器从0开始计数每访问一次，该行的计数器增1。将计数值最小的行换出，该行计数器清零。3.6.3替换策略近期最少使用(LRU-LeastRecentlyUsed的)算法将近期内长久未被访问过的行换出每行设置一个计数器访问时，命中行的计数器清零，其它各行的计数器增1替换时，将计数值最大的行换出保护了刚拷贝到Cache中的新行，提高了命中率随机替换随机地选取一行换出1920命中行的计数器清零，其它各行的计数器增1将计数值最大的行换出。3.6.4Cache的写操作策略Cache的内容只是主存部分内容的副本对Cache的写入导致与主存内容的不一致三种写策略写回法（Write-Back）全写法（Write-Through、写穿透、写直达）写一次法（Write-Once）考虑写命中和写不命中两种情况21(1)写回法写命中：修改Cache的内容，而不立即写入主存只有当此行被替换时才写回主写未命中：首先将内存中对应块调入Cache，然后对其修改当此行换出时，写回主存特点减少了访问主存的次数存在不一致的隐患每行配置一个修改位，以反映此行是否被CPU修改过。被修改过的行称为脏行（dirty）22例题(2)全写法写命中时：同时写入Cache与主存写未命中时：直接向主存进行写入特点：无需增加修改位写Cache和写主存同步进行，不存在数据不一致的情况一定程度上降低了Cache的性能24(3)写一次法写回法+全写法写命中时：第一次：采取全写法不是第一次：采取写回法写未命中时：与写回法相同主要用于多处理器系统25Inteli7Cache结构262728例题主存地址空间大小为256MB，按字节编址。指令数据Cache，均有8行，Cache行大小为64B，数据Cache直接相联。现有两功能相同的程序A，B，其伪代码如下所示：假定int型数据为32位补码，程序编译时i,j,sum均分配在寄存器中，数组a按行优先方式存放，首地址为320（十进制）。1）数组元素a[0][31],a[1][1]所在主存块对应的Cache行分别是多少，行号从零开始。2)程序A，B的数据访问命中率各是多少？那个程序的执行时间更短?inta[256][256];for(i=0;i<256;i++)for(j=0;j<256;j++)sum+=a[i][j];inta[256][256];for(j=0;j<256;j++)for(i=0;i<256;i++)sum+=a[i][j];程序A程序B3.7虚拟存储器原因？多用户、多任务的出现，要求每个程序有自己独立的内存空间用户编程时希望不考虑实际程序的运行空间？虚拟存储器只是一个容量非常大的存储器的逻辑模型，它借助于磁盘等辅助存储器来扩大主存容量，使之为更大或更多的程序所使用。3.7虚拟存储器1.实地址与虚地址用户编制程序时使用的地址称为虚地址或逻辑地址，其对应的存储空间称为虚存空间或逻辑地址空间；计算机物理内存的访问地址则称为实地址或物理地址，其对应的存储空间称为物理存储空间或主存空间。程序进行虚地址到实地址转换的过程称为程序的再定位。注意：物理地址由CPU地址引脚送出，用于访问主存的地址。虚拟地址由编译程序生成的，是程序的逻辑地址。主存～外存层次所用的地址变换映射方法和替换策略与cache～主存层次所用的方法和策略是相同的，即都基于程序局部性原理。它们遵循的原则是：3.7虚拟存储器2.虚存访问过程：虚存空间用户程序按照虚地址编程并存放于辅存之中运行时，操作系统将程序的部分调入内存。每次访存时，判断：虚地址对应部分是否在内存？若在：虚实地址转换不在：从辅存中调入3.7虚拟存储器虚存是概念模型，不是实物对系统程序不透明、对应用程序透明虚存能有效提高存储体系性能Cache主存辅存Cache-主存访问机制主存-辅存访问机制3.7虚拟存储器3.Cache与虚存的异同：出发点相同：提高存储系统性能原理相同：局部性原理侧重点不同：Cache：解决速度差异，提高访存速度；虚存：容量、分配、保护等数据通路不同：CPU与主存和Cache有直接通路；CPU不能直接访问辅存3.7虚拟存储器3.Cache与虚存的异同：透明性不同：Cache：完全由硬件完成，透明；虚存：硬件软件完成，仅对用户程序透明未命中损失不同：Cache：未命中时间损失小虚存：未命中时间损失大3.7虚拟存储器4.虚存机制要解决的关键问题调度问题：哪些程序、数据调入主存？地址映射问题：虚实地址变换替换问题：决定哪些程序和数据应被调出主存更新问题：主存、辅存内容一致性3.7虚拟存储器不同的虚拟存储器机制页式虚拟存储器段式虚拟存储器和段页式虚拟存储器不同的替换算法：FIFO、LRU、LFU3.7.2页式虚拟存储器页式虚拟存储系统中，虚拟空间分成页，称为逻辑页；主存空间也分成同样大小的页，称为物理页。虚存地址分为两个字段：逻辑页号+页内行地址。实存地址也分两个字段：物理页号+页内行地址。页表中每一个虚存逻辑页号有一个表目，表目内容包含该逻辑页所在的主存页面地址(物理页号)，用它作为实存地址的高字段，与虚存地址的页内行地址字段相拼接，产生完整的实主存地址，据此来访问主存页式虚拟存储器结构页表通常在主存中，也至少要访问两次物理存储器才能实现一次访存，这将使虚拟存储器的存取时间加倍。为了避免对主存访问次数的增多，把页表中的最活跃的部分存放在高速存储器中，这个专用于页表缓存的高速存储部件通常称为转换后援缓冲器(TLB)。保存在主存中的完整页表则称为慢表。3.6.2页式虚拟存储器TLB的地址映射过程3.7.3段式虚拟存储器和段页式虚拟存储器1、段式虚拟存储器段是按照程序的自然分界划分的长度可以动态改变的区域。子程序、操作数和常数等划分到不同的段中，并且每个程序可以有多个相同类型的段。虚地址由段号和段内地址（偏移量）组成。虚地址到实主存地址的变换通过段表实现。14段式虚拟存储器地址变换段页式虚拟存储器是段式虚拟存储器和页式虚拟存储器的结合。它把程序按逻辑单位分段以后，再把每段分成固定大小的页。程序对主存的调入调出是按页面进行的，但它又可以按段实现共享和保护，兼备页式和段式的优点。缺点是在映象过程中需要多次查表。段页式虚拟存储器在段页式虚拟存储系统中，每道程序是通过一个段表和一组页表来进行定位的。段表中的每个表目对应一个段，每个表目有一个指向该段的页表起始地址及该段的控制保护信息。如果有多个用户在机器上运行，多道程序的每一道需要一个基号，由它指明该道程序的段表起始地址。虚拟地址格式如下：段页式虚拟存储器【例10】假设有三道程序(用户标志号为A，B，C)，其基址寄存器内容分别为SA，SB，SC，逻辑地址到物理地址的变换过程如下图所示。在主存中，每道程序都有一张段表，A程序有4段，C程序有3段。每段应有一张页表，段表的每行就表示相应页表的起始位置，而页表内的每行即为相应的物理页号。请说明虚实地址变换过程。3.7.4替换算法虚拟存储器中的页面替换策略和cache中的行替换策略有很多相似之处，但有三点显著不同：(1)缺页至少要涉及一次磁盘存取，读取所缺的页，缺页使系统蒙受的损失要比cache未命中大得多。(2)页面替换是由操作系统软件实现的。(3)页面替换的选择余地很大，属于一个进程的页面都可替换。虚拟存储器中的替换策略一般采用LRU算法、LFU算法、FIFO算法，或将两种算法结合起来使用。对于将被替换出去的页面，假如该页调入主存后没有被修改，就不必进行处理，否则就把该页重新写入外存，以保证外存中数据的正确性。为此，在页表的每一行应设置一修改位。21【例7】假设主存只有a,b,c三个页框，组成a进c出的FIFO队列，进程访问页面的序列是0，1，2，4，2，3，0，2，1，3，2号。若采用①FIFO算法，②FIFO算法+LRU算法，用列表法分别求两种替换策略情况下的命中率。3.8虚拟存储器实例1.奔腾PC机的虚地址模式奔腾PC的存储管理部件MMU包括分段部件SU和分页部件PU两部份，可允许SU，PU单独工作或同时工作。分段不分页模式：虚拟地址由一个16位的段参照和一个32位的偏移组成。分段部件SU将二维的分段虚拟地址转换成一维的32位线性地址。优点是无需访问页目录和页表，地址转换速度快。对段提供的一些保护定义可以一直贯通到段的单个字节级。分段分页模式：在分段基础上增加分页存储管理的模式。即将SU部件转换后的32位线性地址看成由页目录、页表、页内偏移三个字段组成，再由PU部件完成两级页表的查找，将其转换成32位物理地址。兼顾了分段和分页两种方式的优点。不分段分页模式：这种模式下SU不工作，只是分页部件PU工作。程序也不提供段参照，寄存器提供的32位地址被看成是由页目录、页表、页内偏移三个字段组成。由PU完成虚拟地址到物理地址的转换。这种模式减少了虚拟空间，但能提供保护机制，比分段模式具有更大的灵活性。2.保护模式的分页地址转换奔腾页面大小为4MB使用单级页表。32位线性地址分为高10位的页面和低22位的页内偏移两个字段。页表项的I位指示页面大小，P位为出现位，A位为访问过位，D位为修改过位。RW位用于读/写控制，US位用于用户/监督控制，PCD位用于页cache禁止的控制，PWT位用于页全写法的控制。奔腾4MB分页方式地址变换3.9存储保护当多个用户共享主存时，就有多个用户和系统软件存于主存中，为使系统能正常工作，应防止由于一个用户程序出错而破坏其他用户的程序和系统软件，还要防止一个用户程序不合法地访问不是分配给它的主存区域。为此，系统应提供存储保护。通常采用的方式是：1存储区域保护2访问方式保护3.9.1存储区域保护非虚拟存储器的主存系统可采用界限寄存器方式。由系统软件经特权指令设置上、下界寄存器，为每个程序划定存储区域，禁止越界访问。界限寄存器方式只适用于每个用户占用一个或几个连续的主存区域。在虚拟存储系统中，通常采用页表保护、段表保护和键式保护方法。1.页表保护和段表保护每个程序的段表和页表本身都有自己的保护功能。每个程序的虚页号是固定的，经过虚地址向实地址变换后的实存页号也就固定了。那么不论虚地址如何出错，也只能影响到相对的几个主存页面。不会侵犯其他程序空间。段表和页表的保护功能相同，但段表中除包括段表起点外，还包括段长。2.键保护方式为主存的每一页配一个键，称为存储键每个用户的实存页面的键都相同。为了打开这个锁,必须有钥匙，称为访问键。访问键赋予每道程序，并保存在该道程序的状态寄存器中。当数据要写入主存的某一页时，访问键要与存储键相比较。若两键相符，则允许访问该页，否则拒绝访问。3.环保护方式对正在执行的程序本身的核心部分或关键部分进行保护。它是按程序的重要性及对整个系统的正常运行的影响程度进行分层，每一层叫做一个环。在现行程序运行前由操作系统定好程序各页的环号，并置入页表中。然后把该道程序的开始环号送入CPU的现行环号寄存器。程序可以访问任何外层空间；访问内层空间则需由操作系统的环控例行程序判断这个向内访问是否合法。3.9.2访问方式保护对主存信息的使用可以有三种方式：读、写和执行。相应的访问方式保护就有R、W、E三种方式形成的逻辑组合。这些访问方式保护通常作为程序状态寄存器的保护位，并且和区域保护结合起来实现。表3.11访问方式保护的逻辑组合35本章小结对存储器的要求是容量大、速度快、成本低。为了解决了这三方面的矛盾，计算机采用多级存储体系结构，即cache、主存和外存。存储器的技术指标有存储容量、存取时间、存储周期、存储器带宽。SRAM、DRAM和ROM各自的特性第四章指令系统4.1指令系统的发展与性能要求4.2指令格式4.3操作数类型4.4指令和数据的寻址方式4.5典型指令14.1指令系统的发展与性能要求冯诺依曼结构主要思想五大部件存储程序程序控制计算机程序由一系列的机器指令组成指令是计算机执行某种操作的命令每个指令的执行过程依靠硬件实现24.1指令系统的发展与性能要求指令是软件和硬件分界面(Interface)硬件设计人员采用各种手段实现它；软件设计人员则利用它编制系统软件和应用软件指令系统：一台计算机中所有机器指令的集合表征一台计算机性能的重要因素影响计算机的硬件结构、系统软件，机器的适用范围指令集架构(InstructionSetArchitecture,ISA)3指令系统44.1.1指令系统的发展系列计算机基本指令系统相同、基本体系结构相同的一系列计算机同一系列的各机种有共同的指令集指令集向下兼容X86系列、ARM系列54.1.1指令系统的发展复杂指令系统计算机CISC-ComplexInstructionSetComputer单条指令功能复杂，整个指令系统数量庞大控制器研制开发周期变长，正确性难以保证，调试维护困难X86、IA32\IA64、IBMSystem/360IntelMCS-51精简指令系统计算机RISC-ReducedInstructionSetComputer克服CISC缺点，便于VLSI技术实现单条指令功能简单2/8规则：80%的指令完成20%的功能控制器设计难度降低ARM:AdvancedRISCMachineRISC-V、MIPSAVR:AlfandVegard'sRISCprocessor64.2指令格式表示一条指令的二进制串称为指令字，指令指令格式：用二进制代码表示的结构形式操作码（OP-OperationCode）该指令执行的操作，编码表示地址码（AC-AddressCode）描述指令的操作对象，可以是操作数本身，也可以是操作数的位置存储器单元----存储器地址寄存器----寄存器编号I/O设备中的缓冲-----端口号74.2.2地址码操作数有被操作数、操作数及操作结果这三种数形成了三种指令格式8三地址指令二地址指令一地址指令零地址指令4.2.2地址码零地址指令指令字中只有操作码，而没有地址码一种是无需操作数如NOP、HLT停机指令等另一种是操作数为默认的（或称隐含的）如操作数在累加器或者堆栈中9零地址指令4.2.2地址码一地址指令常称为单操作数指令，指令中只有一个地址码可能是单操作数运算给出的地址既作为操作数的地址，也作为结果的地址OP(A)->A也可能是二元运算指令中提供一个操作数，另一个操作数则是隐含的(A)OP(AC)->A10一地址指令4.2.2地址码二地址指令最常见的指令格式，又称为双操作数指令运算结果保存在其中一个地址码中，原来的数据被覆盖（A1）OP（A2）→A1地址码A1兼做存放操作结果114.2.2地址码三地址指令(A1)OP(A2)->A3A1和A2为源操作数A3为目的操作数124.2.2地址码在二地址和三地址指令格式中，从操作数的物理位置划分为三种类型存储器-存储器(Storage-Storage,SS)型指令：从内存单元中取操作数，操作结果存放至内存单元需要多次访问内存寄存器-寄存器(Register-Register,RR)型指令：从寄存器中取操作数，把操作结果放到另一寄存器这类指令的速度很快，因为不需要访问内存寄存器-存储器(Register-Storage,RS)型指令：此类指令既要访问内存单元，又要访问寄存器134.2.3指令字长度指令字长度：一条指令的二进制位数为了取指方便，一般为机器字长倍数半字长、单字长、双字长多字长指令指令字长度等于两个或多个机器字长优点：地址码更多，解决内存的寻址问题；缺点：多次访存才能取得一条指令，降低了速度，占用存储空间大144.2.3指令字长度指令集中所有指令长度是否相等等长指令：所有指令长度相等结构简单，控制线路简单MIPS、ARM变长指令：指令字长度随功能而异结构灵活，控制较复杂X86现在指令字长一般为32位固定长度154.2.4指令助记符为了便于书写和阅读，指令通常用3个或4个英文缩写字母来表示，叫做指令助记符16指令格式举例：ARM指令格式指令长度为32位，定长指令单字长指令RR型指令、三地址指令17指令格式举例X86指令格式变长指令，1~15字节，典型的CISC指令系统多字长指令18X86指令格式JE20HCallPUSHESIMOVEBX,[EDI+45][例1]机器字长16位，指令格式如下所示，其中OP为操作码，试分析指令格式的特点。1597430[解]：(1)单字长二地址指令(2)操作码字段OP可以指定27=128条指令(3)源寄存器和目标寄存器都是通用寄存器（总共16个），所以是RR型指令，两个操作数均在寄存器中[例2]机器字长16位，指令格式如下所示，OP为操作码字段，试分析指令格式特点。15107430(1)双字长二地址指令(2)操作码字段OP为6位，可以指定64种操作(3)一个操作数在源寄存器，另一个操作数在存储器中,所以是RS型指令。通用寄存器（总共16个)H&P和RISCJohnHennessyMIPS是在是其在Stanford的研究成果Hennessy于1984年在硅谷创立了MIPS公司后任Stanford大学校长DavidPatterson加州大学伯克利分校教授，研究成果发展出SUN公司SPARC处理器是谷歌的杰出工程师RISC-VFoundation董事会副主席H&P和RISC两人出版了两本著名的教科书：ComputerOrganizationandDesign:TheHardware/SoftwareInterface(计算机组成与设计：硬件/软件接口)ComputerArchitecture:AQuantitativeApproach(计算机体系结构：量化方法)2017ACM图灵奖MIPS架构历史MIPS（MicroprocessorwithoutInterlockedPipelinedStages）ISA是经典的RISC架构之一1981年由斯坦福大学的Hennessy团队研制1984年被MIPSTechnologies公司商业化,1992年SGI收购2013年ImaginationTechnologies公司收购2017年卖给Tallwood,2018年WaveComputing收购（命运多舛）2019年成为MIPSOpen，正式开源（2020年闭源）MIPSISA版本MIPS32/MIPS64多个版本基于MIPSISA的处理器龙芯系列，君正系列MIPS指令集特点单字长指令指令长度为4字节=32位定长指令大部分为三地址指令，RR型32个32位的通用寄存器$0,$1,$2,…$30,$31内存按字节编址，内存严格4字节对齐访问MIPS里没有状态码，没有标志寄存器MIPS指令格式OPRSRtshamtRd6bitsfunct5bits5bits5bits5bits6bitsOPRSRt6bits偏移量5bits5bits16bitsOP6bits地址26bitsR型指令I型指令J型指令RegisterformatImmediateformatJumpformatMIPS指令格式（R型指令）OPRSRtshamtRd6bitsfunct5bits5bits5bits5bits6bits例：add$s1,$s2,$s300000010010100111000100000100000MIPS指令格式(R型指令)0x02538820$s2+$s3=$s1MIPS指令格式（I型指令）OP：操作码Rs：第1个源操作数寄存器Rt：目的操作寄存器偏移量：第二个原操作数OPRSRt6bits偏移量5bits5bits16bitsMIPS指令格式（J型指令）OP：操作码跳转指令，用一个26位的立即数作为跳转的目标地址OP6bits立即数26bits314.3操作数类型操作数类型地址数据：地址是无符号整数。数值数据：定点数、浮点数字符数据：字符或字符串，使用ASCII码逻辑数据：一个单元中有几位二进制bit项组成，每个bit的值可以是1或0。当数据以这种方式看待时，称为逻辑性数据RISC-V完全开放大道至简包含一个最小的核心ISA适合硬件实现轻装上阵的后发优势模块化的可扩展指令集方便简化硬件实现，提升性能更规整的指令编码、更简洁的运算指令和访存模式高效分支跳转指令（减少指令数目）、简洁的子程序调用无条件码执行、无分支延迟槽、无零开销硬件循环（支持for循环的硬件支撑）MIPS32&RISC-V指令助记符及语法格式大同小异RISC-V分支预测，MIPS延迟槽RISC-V支持变长指令扩展RISC-V将源寄存器rs1，rs2和目标寄存器（rd）固定在同样位置，以简化指令译码立即数分散在不同位置，但符号位固定在第31位，可加速符号扩展电路RISC-V（2022年）34三大事件：第一，发布首台RISC-V的便携式计算机第二，Intel设立创新基金，支持RISC-V生态；第三，SiFive估值超25亿美元RISC-V全球会员超过3100家，超过160个核开源；SPECint首次超过10分，进入高性能计算行列在IoT领域的应用规模超过100亿颗中国公司的出货量占据50%RISC-V（2022年）阿里平头哥发布了高性能RISC-V芯片平台“无剑600”及SoC原型“曳影1520”，兼容龙蜥操作系统,并成功运行LibreOffice无剑600平台是当前全球性能最高的可量产RISC-V平台：支持4核RISC-V处理器，主频可达2.5GHz，CPU+XPU异构架构；支持64位LPDDR4X，最高吞吐率4266MT；整合4TOPs的Int8AI算力35RISC发展1964年SeymourCray设计的CDC6600采用了load/store设计，被认为是RISC架构的先驱70年代，RISC的概念由IBM的约翰·科克（JohnCocke）和斯坦福大学的约翰·亨尼（JohnHennessy）等人提出1981年，斯坦福大学的Hennessy发布了首款MIPS芯片1981年，加州大学伯克利分校的DavidPatterson推出了RISC-I1983年RISC-II；1984年发布了RISC-III；1988年发布了RISC-IV2010年，发布了RISC-V1987年，SUN公司在RISC-II基础上开发了SPARC处理器36RISC架构在1980年代末至1990年代得到了广泛的应用和普及。许多公司开始推出基于RISC架构的处理器，如IBM的POWER架构、DEC的Alpha架构和HP的PA-RISC架构等。RISC-V是一种开源的RISC架构，在2010开始兴起，并得到了全球范围内的关注和采用。RISC-V的开放性和灵活性使得它成为教育、研究和嵌入式系统等领域的理想选择。3714.4指令和数据的寻址方式存储器中既存放指令，也存放数据在存储器中，操作数或指令字写入或读出的方式，有地址指定方式、相联存储方式和堆栈存取方式几乎所有计算机在内存中都采用地址指定方式当采用地址指定方式时，形成操作数或指令地址的方式，称为寻址方式24.4指令和数据的寻址方式寻址方式问题确定本条指令中各操作数的地址下一条指令的地址寻址方式分为两类顺序寻址方式(1)指令寻址方式跳跃寻址方式(2)数据寻址方式1.顺序寻址方式指令地址在内存中按序排放执行程序时，通常是顺序执行称为指令的顺序寻址方式使用程序计数器PC（programcounter）保存指令的顺序号顺序号就是指令在内存中的地址新指令地址：PC=PC+常量常量就是当前指令的长度MIPS：PC+43图4.1指令的寻址方式2.跳跃寻址方式当程序转移执行顺序时，指令寻址采取跳跃寻址方式所谓跳跃，是指下条指令的地址码不是由PC给出，而是由本条指令直接给出程序跳跃后，按新的指令地址开始顺序执行PC的内容也必须相应改变，以便及时跟踪新的指令地址2.跳跃寻址方式6跳跃寻址方式功能实现程序转移或构成循环程序或将某些程序作为公共程序引用（子程序调用）各种条件转移或无条件转移指令，属于跳跃寻址4.4.2操作数寻址方式形成操作数的有效地址（EA-EffectiveAddress）的方法，称为操作数的寻址方式地址码由形式地址（偏移量）和寻址方式特征位组合形成例如，一种单地址指令中用X，I，A各字段组成该指令的地址码寻址方式特征位指明如何对形式地址进行变换784.4.2操作数基本寻址方式计算机中操作数的存放位置有操作数包含在指令中；操作数包含在CPU的某一个内部寄存器中；操作数包含在主存中；操作数包含在I/O设备的端口中根据操作数放在不同的地方，从而派生各种不同的寻址方式4.4.2操作数寻址方式91、隐含寻址在指令中不明显的给出而是隐含着操作数的地址例如，单地址指令、双地址指令102、立即寻址地址码中不是操作数的地址，而是操作数本身也叫立即数特点：操作码和操作数被同时取出，提高了指令的执行速度操作数是指令的一部分，不能修改操作数的大小将受到指令长度的限制，寻址方式灵活性差例如：ADDBX,33H;33H为立即数（X86）addi$3,$0,3;3为立即数（MIPS）113.直接寻址直接寻址：形式地址A就是操作数的有效地址EAEA＝A直接寻址方式由寻址方式特征位给予指示12X86：MOVAX,[200]EA=AImm为寻址方式特征位3.直接寻址77200200内存4、间接寻址间接寻址：形式地址A是操作数内存地址的指示，A单元的内容才是操作数的有效地址。结合直接寻址和间接寻址，定义指令格式如下：I＝0，表示直接寻址，有效地址EA＝AI＝1，表示间接寻址，有效地址EA＝(A)144、间接寻址间接寻址要比直接寻址灵活至少需要两次访问主存储器才能取出操作数400788300300400间接寻址方式示意图5、寄存器寻址操作数在通用寄存器中地址码为通用寄存器编号，即EA=R从寄存器中取操作数比访问主存快X86：MOVAX,BXMIPS:add$4,$15,$17166、寄存器间接寻址寄存器中存放的不是操作数，而是操作数的内存地址地址码给出通用寄存器的编号，有EA=(R)17300R7.偏移寻址偏移寻址是直接寻址和寄存器间接寻址的结合有效地址EA=A+（R）。寻址特征位指明某个专用寄存器常用的三种偏移寻址是相对寻址、基址寻址、变址寻址。187.偏移寻址7.1相对寻址方式专用寄存器是程序计数器PC即有效地址EA=A+(PC)。“相对”寻址，就是相对于PC的地址形式地址A可正可负一种指令寻址方式207.1相对寻址方式2000PC2100程序指令计数器7.2基址寻址方式专用寄存器是基址寄存器形式地址A是通常是无符号整数可以扩大寻址能力，基址寄存器的位数长，可以访问较大的地址范围MIPS:LW$18,8($15)#EA=$15+8227.3变址寻址方式专用寄存器是变址寄存器目的而在于实现程序块的规律性变化例如，一个数组在内存的首地址为X，将首地址X作为指令中的形式地址A，并在变址寄存器中指出元素的序号，便可访问任一元素X86：MOVAX,200[SI]SI,DI都称为变址寄存器237.3变址寻址方式X86：MOVAX,200[SI]SI,DI都称为变址寄存器243000操作数R3200内存8.段寻址Intel8086/8088微机中，ALU16位运算，但其内存容量可到1M，即地址有20位将整个1M空间存储器以64K为单位划分成若干段。在形成20位物理地址时，段寄存器中的16位数会自动左移4位，然后以16位偏移量相加9.堆栈寻址方式堆栈有寄存器堆栈和存储器堆栈两种形式，都以先进后出的方式存取数据不论哪种堆栈，需要一个隐式或显式的堆栈寄存器来指明栈顶（栈指针）的位置（地址）X86中，SP(StackPoint,栈顶指针)BP(BasePoint,栈底)269.堆栈寻址方式根据栈顶状态不同，堆栈分为：满栈：栈指针指向栈顶元素位置空栈：栈指针指向下一个空位置根据增长方向不同，堆栈分为：递减栈：堆栈向内存地址减小的方向生长，即向下生长。递增栈：堆栈向内存地址增加的方向生长，即向上生长。X86:满栈、递减栈27栈指针指向最后压入堆栈的有效数据项，称为满栈（先改变SP，再放数据）；栈指针指向下一个待压入数据的空位置，称为空栈（先放数据，再改变SP）。0x12345678栈底栈区0x123456780x12345678递增栈：递减栈：30寻址方式举例：PentiumEA=段寄存器+描述符寄存器+基址寄存器+变址寄存器*比例因子+偏移量寻址方式举例：MIPS31寻址方式举例：RISC-V32[例]一种二地址RS型指令的结构如下所示：6位4位1位2位16位其中I为间接寻址标志位，X为寻址模式字段，A为偏移量字段。通过I，X，A的组合，可构成下表所示的寻址方式。请写出六种寻址方式的名称。20050011002001005008001002002100OPXA=100PC=1000R基=2000寻址方式X操作数立即0100直接1200间接2500相对3100基址4200有效地址EAEA=A=100EA=(A)=200EA=PC+A=1100EA=(R)+A=2100例设某机的指令格式、有关寄存器和主存内容如下，X为寻址方式，A为形式地址，请在下表中填入有效地址EA及操作数的值。？指令格式设计举例例.某机字长32位，采用三地址指令，支持8种寻址操作，完成60种操作，各寻址方式均可在2K主存范围内取得操作数，并可在1K范围内保存运算结果。问应采用什么样的指令格式？指令字长最少应为多少位？执行一条直接寻址模式指令最多要访问多少次主存？47位指令字需占用2个存储字取指需访存2次，取源操作数访存2次，写结果1次，共5次4.5.1指令的分类按指令的功能：数据传送实现主存和寄存器之间，或寄存器和寄存器之间的数据传送数据处理定点或浮点算术运算，向量运算、逻辑运算与移位等程序控制用于控制程序的执行方向分支、转移、调用子程序其他指令系统控制，特权，安全等3637设存储字长和指令字长均为24位，若指令系统可完成108种操作，且具有直接、间接、变址、基址、相对和立即6种寻址方式。在保证最大范围内直接寻址的前提下，指令字中操作码占几位？寻址特征位占几位？可直接寻址的范围是多少？间接寻址的范围是多少？38某计算机的字长为16位，数据用补码表示，存储器按字编址，访存指令格式为16位，其中5位操作码，3位寻址方式字段，分别表示立即寻址、直接寻址、间接寻址、变址寻址和相对寻址这5种，8位地址码字段。设PC和Rx分别为程序计数器和变址寄存器(其中Rx的位数为16位)问：立即寻址的数据范围多大？各种寻址方式的寻址范围大小是多少？下列关于各种寻址方式获取操作数快慢的说法中，正确的是I.立即寻址快于堆栈寻址II.堆栈寻址快于寄存器寻址III.寄存器间接寻址快于变址寻址IV.变址寻址快于间接寻址11:2139MIPS指令系统MIPS指令集特点定长指令，指令长度固定4字节简单的load/store结构，内存中的数据访问严格4字节对齐load/store结构：只有load/store类指令可以访问存储器寻址方式简单，每条指令的操作也简单易于流水线设计易于编译器开发MIPS寄存器字长32位32个通用寄存器$0,$1,$2,…$30,$313个特殊寄存器PC（程序计数器）HI和LOHI乘积高32位(余数)，LO：乘积低32位（商）；除了用在乘除法之外，也不能有做其他用途硬件没有强制性的指定寄存器使用规则，但是在实际使用中，这些寄存器的用法都遵循一系列约定MIPS里没有状态码，没有标志寄存器32个通用寄存器IA-32的寄存器组织8个通用寄存器两个专用寄存器6个段寄存器MIPS寻址方式数据寻址方式立即寻址寄存器寻址基址寻址基址寄存器+偏移量任一通用寄存器都可以作为基址寄存器MIPS寻址方式指令寻址顺序寻址：PC=PC+4PC相对寻址PC=偏移量左移两位+PC伪直接寻址（跳跃寻址）26位偏移量PC={PC[31..28],偏移量,00}MIPS指令格式OPRSRtshamtRd6bitsfunct5bits5bits5bits5bits6bitsOPRSRt6bits偏移量5bits5bits16bitsOP6bits偏移量26bitsR型指令I型指令J型指令RegisterformatImmediateformatJumpformatMIPS指令格式（R型指令）主要是运算类指令OP：操作码，所有R型指令OP为全0Rs：第1个源操作数寄存器Rt：第2个源操作数寄存器Rd：存放结果的目的操作数寄存器shamt：用于移位指令，指明移位次数funct：功能码，对操作码进行补充OPRSRtshamtRd6bitsfunct5bits5bits5bits5bits6bitsR型指令MIPS指令格式(R型指令)寄存器寻址汇编格式：opRd,Rs,Rt例：add$s1,$s2,$s3指令编码：00000010010100111000100000100000MIPS指令格式(R型指令)0x02538820$s2+$s3=$s1MIPS指令格式（I型指令）L/S指令和分支指令Rt：目的操作数寄存器Rs和偏移量：源操作数OPRSRt6bits偏移量5bits5bits16bitsI型指令汇编格式：opRt,(偏移量)RsMIPS指令格式（I型指令）三地址，RR型，立即数运算指令Rs：第1个源操作数寄存器Rt：目的操作寄存器偏移量：第2个源操作数(立即数)OPRSRt6bits偏移量5bits5bits16bitsI型指令汇编格式：opRt,Rs,偏移量MIPS指令格式(I型指令)立即寻址基址寻址相对寻址MIPS指令格式(I型指令)addi$21,$22,-50op=810rs=2210(原操作数寄存器)rt=2110(目的寄存器)偏移量=-5010,负数用补码表示请写出指令的机器码十进制指令格式:二进制指令代码:0x22D5FFCE十六进制指令代码:MIPS指令格式（J型指令）单地址指令跳转指令，用一个26位的偏移量作为跳转的目标地址OP6bits偏移量26bitsJ型指令汇编格式：op偏移量MIPS指令格式（J型指令）伪直接寻址——跳转地址为指令中的26位偏移量与PC中的高4位拼接得到新的PC={PC[31..28],目标地址,00}例：j100000x0800271000001000000000000010011100010000指令编码：新PCMIPS指令系统（1）数据传送类：（2）算术/逻辑运算类：（3）控制类：1、数据传送类：内存数据访问指令读内存指令：lwlblh（I型指令）w:wordb:byteh:halfword访问元素A[8]，A[0]保存在$t3lw$t0,32($t3)#基址寻址写内存指令：swsbsh（I型指令）$t0的数据保存到A[12]；sw$t0,48($t3)2、算术/逻辑运算类：加减指令加法add（R型指令）add$s4,$s1,$s2#$s1+$s2=$s4减法sub（R型指令）sub$s3,$s4,$s5#$s4-$s5=$s3-20-2、算术/逻辑运算类：加减指令如何编译下面的C语言表达式?a=b+c+d-e;编译成多行汇编指令add$t0,$s1,$s2#temp=b+cadd$t0,$t0,$s3#temp=temp+dsub$s0,$t0,$s4#a=temp-e2、算术/逻辑运算类：加立即数立即数相加指令addi（I型指令）addi$s3,$s3,4#$s3=$s3+4立即数传送addi$s3,$zero,1#$s3=1寄存器间数据传送add$s3,$s2,$0#$s3=$s2利用$zero($0)实现寄存器之间的数据传输2、算术/逻辑运算类：逻辑运算逻辑移位指令sll、srl、sra（R型指令）sll$s1,$s2,2#$s2左移两位srl$s1,$s2,2#$s2右移两位逻辑运算and/or/xor/addi/ori/xori（R型和I型指令）and$t0,$t1,$t2#t0=t1&t2or$t0,$t1,$t2#t0=t1|t2andi$t0,$t1,100#t0=t1&100ori$t0,$t1,100#t0=t1|1003、控制类指令:跳转指令3、控制类指令C语言条件判断指令If(a==b){i=1;}else{i=2;}等效C指令If(a==b)gotoL1;i=2;gotoL2;L1:i=1;L2:等效MIPS指令beq$s0,$s1,L1addi$s3,$zero,2jL2;L1:addi$s3,$zero,1L2:-25-等效MIPS指令$s0=a$s1=b$s3=i3、控制类指令:比较指令sltslti比较指令(slt:SetonLessThan)sltreg1,reg2,reg3如果reg2<reg3,则reg1=1先比较，再分支If($s1<$s2)gotoLess;slt$t0,$s1,$s2#$t0=1if$s1<$s2bne$t0,$0,Less#if$t0!=0gotoLess-26-循环结构C语言简单循环结构，A为int数组do{g=g+A[i];i=i+j;}while(i!=h);重写代码Loop:g=g+A[i];i=i+j;if(i!=h)gotoLoop;编译后的变量映射:循环结构最后编译的MIPS代码:Loop:sll$t1,$s3,2#$t1=4*iadd$t1,$t1,$s5#$t1=&A[0]+4ilw$t1,0($t1)#$t1=A[i]add$s1,$s1,$t1#g=g+A[i]add$s3,$s3,$s4#i=i+jbne$s3,$s2,Loop#ifi!=hgotoLoop原始C代码:Loop:g=g+A[i];i=i+j;if(i!=h)gotoLoop;循环结构最后编译的MIPS代码:Loop:sll$t1,$s3,2#$t1=4*iadd$t1,$t1,$s5#$t1=&A[0]+4ilw$t1,0($t1)#$t1=A[i]add$s1,$s1,$t1#g=g+A[i]add$s3,$s3,$s4#i=i+jbne$s3,$s2,Loop#ifi!=hgotoLoop#原始C代码:Loop:g=g+A[i];i=i+j;if(i!=h)gotoLoop;MIPS函数调用C语言函数调用intfunction(inta,intb){return(a+b);}MIPS实现函数调用的机制返回地址寄存器$ra参数寄存器$a0,$a1,$a2,$a3返回值寄存器$v0$v1局部变量$s0~$s7堆栈指针$sp过程调用实现机制sum(a,b);/*a,b:$s0,$s1*/}intsum(intx,inty){returnx+y;}1000add$a0,$s0,$zero#x=a1004add$a1,$s1,$zero#y=b1008addi$ra,$zero,1016#$ra=10161012jsum#调用函数sum1016…2000sum:add$v0,$a0,$a1#过程入口2004jr$ra#new#返回主程序instruction过程调用实现机制sum(a,b);/*a,b:$s0,$s1*/}intsum(intx,inty){returnx+y;}1000add$a0,$s0,$zero#x=a1004add$a1,$s1,$zero#y=b1008addi$ra,$zero,1016#$ra=10161012jsum#调用函数sum1016…2000sum:add$v0,$a0,$a1#过程入口2004jr$ra#new#返回主程序instructionJ10161008jalsum1012过程调用机制jallabel#linkandjump$ra=PC+4;#savenextinstructionaddressjLabel过程返回指令jr$ra#returntomainprogram在32位MIPS体系结构下，最多可寻址4GB地址空间0xFFFFFFFF0xA00000000xC00000000xBFFFFFFF0x800000000x9FFFFFFF0x7FFFFFFF0x00000000MIPS内存地址空间数据通路流水线化MARS开源MIPS仿真器，汇编器MIPSX86差异4.5.3精简指令系统RISC选取使用频率最高的一些功能实现，指令条数少便于硬件实现，用软件实现复杂指令功能指令长度固定，指令格式简单，寻址方式简单只有存数/取数指令可以访问存储器(RS型)，其余指令的操作都在寄存器之间进行(RR型)设置大量寄存器（32~192）一个机器周期完成一条机器指令RISCCPU采用硬布线控制，CISC采用微程序CSIC与RISC互相融合382010研究生统考例题例.某计算机字长为16位，主存地址空间大小为128KB，按字编址。采用单字长指令格式，指令各字段定义如图，转移地址采用相对寻址方式，相对偏移量用补码表示。寻址方式如图。注(x)表示存储器地址x或寄存器x的内容（1）该指令系统最多可有多少条指令？该计算机最多有多少个通用寄存器？存储器地址寄存器MAR和存储器数据寄存器MDR至少需要多少位？2010研究生统考例题注(x)表示存储器地址x或寄存器x的内容（2）转移指令的目标地址范围是多少？例.某计算机字长为16位，主存地址空间大小为128KB，按字编址。采用单字长指令格式，指令各字段定义如图，转移地址采用相对寻址方式，相对偏移量用补码表示。寻址方式如表。2010研究生统考例题注(x)表示存储器地址x或寄存器x的内容（3）若操作码0010B表示加法操作，助记符为add，寄存器R4，R5的编号分别为100B和101B，R4的内容为1234H，R5的内容为5678H，地址1234H中的内容为5678H，地址5678H中的内容为1234H，则汇编语句add(R4),(R5)+逗号前为源操作数，逗号后为目的操作数，对应的机器码是多少？用十六进制表示。该指令执行以后，哪些寄存器和存储单元的内容会发生改变？改变后的内容是什么？例.某计算机字长为16位，主存地址空间大小为128KB，按字编址。采用单字长指令格式，指令各字段定义如图，转移地址采用相对寻址方式，相对偏移量用补码表示。寻址方式如图。MIPS仿真工具MARSMIPS汇编程序汇编源程序由数据声明段和代码段组成。汇编程序文件以.s或.asm为后缀数据声明以.data开始，声明在代码中使用的变量、常量在主存中创建了对应的空间代码段以.text开始，由指令构成的程序代码代码以main:开始。程序的注释使用#符号进行注释。MIPS汇编程序模板#Title:Filename:#Author:Date:#Description:#Input:#Output:###############数据段/Datasegment#################.data...#自定义的数据###############代码段/Codesegment##################.text.globlmainmain:#mainprogramentry...#自己写的代码li$v0,10#Exitprogramsyscall数据声明格式：val_name:storage_typevalue(s)创建一个以val_name为变量名，value(s)为初值，存储类型是storage_type的变量。变量名后要跟一个英文冒号数据存储类型storage_type.word，.half，.byte–字、半字、字节.asciiz-字符串，以null结尾var1:.word3#var1为一个字变量，初值为3，整数array1:.byte‘a’,‘b’#array1为两个元素的字节数组，初值#分别为a和b的ASCII码array2:.space40#分配一块连续的内存区域，容量为40字节string1:.asciiz“Printthis.\n”#定义一个字符串汇编指令语句代码部分的语句格式：[label:]mnemonic[operands][#comment]Label:(标记)标记一条指令在内存中的位置，以英文冒号结尾Moemonic(助记符)MIPS机器指令、汇编伪指令（比如add,sub,等)Operands(操作数)根据指令格式定义的操作数，可以是寄存器、内存变量、常量L1:addiu$t0,$t0,1#$t0加1系统调用(syscall)1.取数、存数#################codesegment#####################.datavalue:.word10,20,0.text.globlmainmain:#main入口la$t0,value#将变量value的地址装入$t0#la是伪指令lw$t1,0($t0)#将地址($t0+0)的字数据装入$t1lw$t2,4($t0)#将地址($t0+4)的字数据装入$t2add$t3,$t1,$t2#$t1+$t2=$t3sw$t3,8($t0)#将$t3中的数据存入地址($t0+8)li$v0,10#退出syscall机器指令与汇编语言伪指令汇编器定义的，用于增强汇编程序可读性和提高编程效率编译时，汇编器将伪指令翻译为一条或多条机器指令汇编器建立符号表，以记录每个变量和标记的内存地址例符号表.DATAvar1:.byte1,2,'Z'str1:.asciiz"MyString\n"var2:.word0x12345678.ALIGN3var3:.half1000符号表-symboltableLabelvar1str1var2var3Address0x100100000x100100030x100100100x100100182.读取并显示一个整数#################codesegment#####################.text.globlmainmain:#mainprogramentryli$v0,5#5号功能调用，读取整数syscall#$v0=读取的值move$a0,$v0#$a0=要显示的整数值li$v0,1#1号功能调用，显示整数syscallli$v0,10#退出程序syscallMARS仿真步骤点击工具栏编译程序（快捷键F3）运行（快捷键F5），“RunI/O”窗口显示并输出程序运行结束，系统复位(F12)，重新开始3.输入并显示字符串#################Datasegment#####################.datastr:.space10#arrayof10bytes#################Codesegment#####################.text.globlmainmain:#mainprogramentryla$a0,str#$a0=addressofstrli$a1,10#$a1=maxstringlengthli$v0,8#readstringsyscallli$v0,4#Printstringstrsyscallli$v0,10#Exitprogramsyscall4.三个整数相加（1/2）#Input:分别输入三个整数#Output:输出和###################Datasegment###################.dataprompt:.asciiz"Pleaseenterthreenumbers:\n"sum_msg:.asciiz"Thesumis:"###################Codesegment###################.text.globlmainmain:la$a0,prompt#显示提示字符串promptli$v0,4syscallli$v0,5#读第一个数到$t0syscallmove$t0,$v04.三个整数相加（2/2）li$v0,5#读第二个数到$t1syscallmove$t1,$v0li$v0,5#读第三个数到$t2syscallmove$t2,$v0addu$t0,$t0,$t1#累加addu$t0,$t0,$t2la$a0,sum_msg#writesummessageli$v0,4syscallmove$a0,$t0#输出结果li$v0,1syscallli$v0,10#exitsyscall运行结果5.小写字母到大写转换(1/2)#Objective:小写字母转换到大写#Input:输入一个字符串.#Output:以大写形式输出.###################Datasegment#####################.dataname_prompt:.asciiz"Pleasetypeastring:"out_msg:.asciiz"Yournameincapitalsis:"in_name:.space31#spaceforinputstring###################Codesegment#####################.text.globlmainmain:la$a0,name_prompt#printpromptstringli$v0,4syscallla$a0,in_name#readtheinputstringli$a1,31#atmost30chars+1nullcharli$v0,8syscall5.小写字母到大写转换(2/2)la$a0,out_msg#writeoutputmessageli$v0,4syscallla$t0,in_name#t0为输入字符串的首地址loop:lb$t1,($t0)#load一个字节beqz$t1,exit_loop#ift1=0,退出循环blt$t1,‘a’,no_change#t1<‘a’,表示大写，处理下一个字符bgt$t1,‘z’,no_change#t1>‘z’,表示非字母字符，处理下一个字符addiu$t1,$t1,-32#‘a’<t1<‘z’小写转大写:'A'-'a'=-32sb$t1,($t0)#保存于字符原位置no_change:addiu$t0,$t0,1#t0指向下一个字符jloopexit_loop:la$a0,in_name#输出转换完成的大写字符串li$v0,4syscallli$v0,10#exitsyscall第五章中央处理器本章讨论CPU的功能组成，控制器的工作原理和实现方法，微程序控制原理，基本控制单元的设计以及先进的CPU系统设计技术1返回第五章中央处理器5.1CPU功能和组成5.2指令周期5.3时序产生器和控制方式5.4微程序控制器5.5硬布线控制器5.6流水CPU5.7RISCCPU235.1CPU的功能和组成5.1.1CPU的功能冯.诺依曼的“存储程序、程序控制”用计算机解决某个问题时，首先编写程序程序是一个指令序列，这个序列明确告诉计算机应该逐步执行什么操作（操作码）在什么地方找到用来操作的数据，结果存到何处（地址码）45.1.1CPU的功能计算机进行信息处理的过程可分为两步：①将程序和数据装入存储器；②从程序入口开始取指令，执行指令，得到所需结果，然后结束运行中央处理器是控制计算机自动完成取出指令和执行指令任务的部件计算机的核心部件，简称为CPU（CentralProcessingUnit）5.1.1CPU的功能指令控制：保证控制器按顺序执行程序操作控制管理并产生一系列操作信号，将它们送往相应的部件时间控制：对各种操作实施时间上的定时数据加工：对数据进行算术和逻辑运算565.1.2CPU的基本组成早期的CPU由运算器和控制器两大部分组成现在将外围的一些逻辑功能部件纷纷移入CPU，使CPU的组成越来越复杂789运算器数据加工处理部件组成ALU、通用寄存器、DR和PSW主要功能执行算术运算执行逻辑运算10控制器协调和指挥整个计算机系统的操作组成PC、IR、指令译码器、时序发生器和操作控制器功能(1)从指令Cache中取出一条指令，生成下一条指令在指令Cache的位置；(2)对指令进行译码，产生相应的操作控制信号(3)控制CPU、内存和输入/输出设备间的数据流动115.1.3CPU中的主要寄存器在CPU中主要有以下六类寄存器1.数据寄存器（DR-DataRegister）2.指令寄存器（IR-InstructionRegister）3.程序计数器（PC-ProgramCounter）4.数据地址寄存器（AR-AddressRegister）5.通用寄存器（R0~R3–GeneralRegister）6.状态字寄存器（PSW-ProgramStatusWord）1.数据寄存器（DR）暂时保存要写入寄存器的数据122.指令寄存器（IR）InstructionRegister保存当前正在执行的指令内容OP字段的输出作为指令译码器的输入3.程序计数器（PC）ProgramCounter保存下一条指令的地址在程序开始执行前必须将起始地址(入口地址)送入PC修改PC的内容顺序寻址：PC=PC+常量；常量与指令长度有关相对寻址：PC=PC+偏移量跳跃寻址：PC=偏移量X86：EIPMIPS：PC4.数据地址寄存器（AR）保存访问数据Cache的地址本例中为保持访问数据Cache单元的地址5.通用寄存器模型中有4个通用寄存器（R0~R3）作为ALU的数据源和目的寄存器用作地址指示器、变址寄存器、堆栈指示器等6.状态字寄存器（PSW）一个由各种状态标志拼凑而成的寄存器模型机中的PSW由ALU的运算结果设置还保存中断和系统工作状态等X86：FLAGSMIPS：无185.1.4操作控制器和时序发生器数据通路：部件之间传送信息的通路操作控制器在各部件之间建立数据通路操作控制器根据指令OP码和时序信号，生成各种操作控制信号，以便正确地建立数据通路，从而完成取指令和执行指令的控制195.1.4操作控制器和时序产生器操作控制器分为硬布线控制器，采用时序逻辑技术实现微程序控制器，采用存储逻辑实现时序产生器产生并发出计算机所需要的时序信号对各种控制信号实施时间上的控制205.2指令周期指令周期的基本概念MOV、的指令周期LAD指令的指令周期ADD指令的指令周期STO指令的指令周期JMP指令的指令周期用方框图语言表示指令周期指令格式设计-编码操作码位数地址码位数：双地址码、单地址码偏移量、寄存器位数数据寻址方式直接寻址、寄存器寻址、寄存器间接寻址指令寻址方式顺序寻址、跳跃寻址不设定寻址特征位，由操作码默认指定寻址方式215.2.1指令周期的基本概念运行程序第一步：从内存中取一条指令第二步：执行该指令周而复始235.2.1指令周期的基本概念上述步骤所需时间从内存取出一条指令的时间：取指周期分析并执行这条指令的时间：执行周期指令周期=取指周期+执行周期从内存取出一条指令、分析并执行这条指令的时间总和指令功能不同，其指令周期不同245.2.1指令周期的基本概念一个指令周期划分为若干CPU周期CPU周期又称机器周期通常指从内存读一个字的最短时间取指周期包含若干CPU周期执行周期包含若干CPU周期功能不同的指令，可能包含不同数目的CPU周期255.2.1指令周期的基本概念一个CPU周期包含若干时钟周期时钟周期：T周期、节拍脉冲处理操作的最基本时间单位ALU完成一次正确的运算寄存器间的一次数据传送等相互关系：1个指令周期=取指周期+执行周期=若干个CPU周期1个CPU周期=若干时钟周期265.2.1指令周期的基本概念指令周期=取指周期+执行周期取指周期=1个CPU周期执行周期=1个CPU周期1CPU周期=4个T周期单周期CPU和多周期CPU单周期CPU在一个CPU周期内完成从取指、译码到执行的所有工作效率低多周期CPU把指令执行周期分成多个阶段，每个阶段在一个CPU周期完成容易流水线执行，效率高27简单定义一个指令集6条指令，单字长，字长为1B，4个寄存器MOV寄存器数据传输RR型LAD/STO取数/存数RS型ADD/AND加法/与RR型JMP转移RS型28简单定义一个指令集指令寻址方式顺序寻址：PC+1跳跃寻址：PC=偏移量数据寻址方式直接寻址：EA=偏移量寄存器寻址：EA=R寄存器间接寻址：EA=(R)29指令格式设计操作码（OP）定义6条指令：MOV/LAD/STO/ADD/AND/JMP30MOV寄存器寻址双地址码，功能：Rs->RdLAD直接寻址，功能：(A)->RsSTO寄存器间接寻址，Rs->(Rd)指令格式设计(类MIPS)31JMP跳跃寻址A->PCADD寄存器寻址Rs+Rd->RdAND寄存器寻址Rs&Rd->Rd指令格式设计32一个小程序33一个小程序34六条典型指令组成的简单程序示例35程序运行到105地址时，各寄存器的值是多少？36如何设计指令周期前提：掌握每个指令要执行的操作识别出各个部件的控制命令两个阶段取指阶段、执行阶段两个步骤找出数据通路：数据从哪里来，经过哪些部件，最终达到哪里确定操作信号：形成上述数据通路所需的操作控制信号37图5.1的结构控制信号总线三态门：C1、C2、C3存储器：数据Cache读/写(RD(D))、指令Cache读(RD(I))寄存器：每个寄存器都有输入和输出控制信号输入控制信号：PCin、Riin，DRin等输出控制信号：PCout、Riout等PC：PC+1ALU：加、与、传送3839DCache读/写ICache读+\&\MDRinPCoutPCinARinRioutRiinIRin如何设计指令周期时间设计：各个操作在哪个时钟周期发生取指周期=？CPU周期执行周期=？CPU周期1个CPU周期定义从内存读/写一个数据或使用共享总线传输一个数据，总线只能有一个源一个CPU周期内数据不能产生冲突图5.1中IBUS是独占的、DBUS是共享的1个CPU周期包括4个T周期：T1~T440指令周期从内存取出一条指令、分析并执行这条指令的时间总和指令周期=取指周期+执行周期=若干个CPU周期1个CPU周期=若干时钟周期1如何设计指令周期前提：掌握每个指令完成的功能，要执行的操作识别出各个部件的控制命令分两个阶段取指阶段、执行阶段三个步骤1.找出数据通路：数据从哪里来，经过哪些部件/总线，最终达到哪里2.确定操作信号：形成上述数据通路所需的操作控制信号3.分配CPU周期2如何设计指令周期分配CPU周期：各个操作信号在哪个CPU周期发出取指周期=？CPU周期执行周期=？CPU周期1个CPU周期定义从内存读/写一个数据或使用共享总线传输一个数据，总线只能有一个源一个CPU周期内数据不能产生冲突344DCache读/写ICache读+\&\MDRinPCoutPCinARinRioutRiinIRinIBUS是独占的、DBUS是共享的1个CPU周期包括4个T周期：T1~T45.2.2MOV指令的指令周期MOVR0,R1单字长，RR型取指阶段：数据通路：从指令Cache中取出指令经过IBUS写入IRPCABUS(I)ICacheIBUSIR操作控制：形成上述数据通路的控制信号PC内容输出到指令Cache指令Cache读操作，通过IBUS写入IRPC+1，为取下一条指令做好准备对IR中的OP译码，以确定进行什么操作5PCoutIRinICache读65.2.2MOV指令的指令周期1.取指周期：完成三件事从指令Cache取出指令到IRPC+1，为取下一条指令做好准备对IR中的OP译码，以确定进行什么操作2.执行周期将数据从R1传送到R0由于操作简单，只需要一个CPU周期7PC中装入第一条指令地址101；1018101①PC的内容被放到ABUS（I）上，指令Cache进行译码，发出读命令；101R②从101号地址读出的MOV指令通过IBUS装入IR；③PC+1，变成102，为取下一条指令做好准备；102④对IR中的OP译码，识别出是MOV指令，取指阶段即告结束MOV指令的取指阶段95.2.2MOV指令的取指周期操作PC内容输出到指令Cache读指令Cache取出，指令写入IRPC+1；对IR中的OP译码时间访问内存取一条指令，需要1个CPU周期10MOV指令的执行周期将数据从R1传送到R0(1)OC送出控制信号到通用寄存器，选择R1做源寄存器，选择R0作目标寄存器；(2)OC送出控制信号到ALU，指定ALU做传送动作；(3)OC送出控制信号，打开ALU输出三态门C1，将ALU输出送到DBUS上；(4)OC送出控制信号，将DBUS上的数据打入到DR(5)OC送出控制信号，将DR中的数据打入R0，R0的内容由00变为10至此，MOV指令执行结束11MOV指令的执行阶段MDRinRioutRiin5.2.2MOV指令的指令周期MOVR0,R1单字长，RR型执行阶段：数据通路：寄存器R1的数据传输到R0R1ALUDBUSDRR0操作控制：形成上述数据通路的控制信号选择R1做源寄存器，指定ALU做传送动作打开ALU输出三态门C1，将ALU输出送到DBUS上将DBUS上的数据写入到DR将DR中的数据写入R0，R0的内容由00变为101213①OC送出控制信号到通用寄存器，选择R1做源寄存器，指定ALU做传送操作M10②OC送出控制信号，打开C1，将ALU输出送到DBUS上③将DBUS上的数据10打入到DR；④将DR中的数据打入到R0，R0的内容由00变为10MOV指令的执行周期DRinR1outR0inMOV指令的执行周期操作(1)选择R1做源寄存器，指定ALU做传送动作；(2)打开ALU输出三态门C1，将ALU输出送到DBUS上；(3)将DBUS上的数据写入DR(4)将DR中的数据写入R0时间：使用一次共享总线DBUS，需要1个CPU周期14155.2.2MOV指令的指令周期1.取指2.执行165.2.2MOV指令的指令周期（简化）1.取指2.执行只考虑一个CPU周期内的操作175.2.2MOV指令的指令周期（再简化）5.2.2MOV指令的指令周期MOVR0,R1取指周期1个CPU周期执行周期1个CPU周期185.2.3LAD指令LADR1,6单字长，RS型取指阶段同MOV指令相同执行阶段数据通路：访问内存地址6的单元，取出数据写入R1IRARABUS(D)DBUSDRR11920控制信号：打开C3，将地址码6放到DBUS上；将地址码6装入AR，数存进行地址译码；读数存6号单元，数100读出到DBUS上；将DBUS上的数据100写入DR；将DR中的数据100写入R1ARinDCache读DRinR1in21LAD指令的执行周期控制信号：打开C3，将地址码6放到DBUS上；将地址码6装入AR，DCache进行地址译码；读数存6号单元，数100读出到DBUS上；将DBUS上的数据100写入DR；将DR中的数据100写入R122LAD指令的执行周期时间设计：序号1和2，访问一次内存并使用DBUS，需要1个CPU周期序号3、4和5，使用一次DBUS，需要1个CPU周期23LAD指令的执行周期（简化）5.2.3LAD指令的指令周期245.2.3LAD指令的指令周期LADR1,6单字长RS型25取指令PC+1译码指令取出操作数取下条指令PC+1取指周期开始执行周期装入通用寄存器5.2.3LAD指令的指令周期LADR1,6单字长RS型26取指令PC+1译码指令取出操作数取下条指令PC+1取指周期开始执行周期装入通用寄存器5.2.5ADD指令的指令周期ADDR1,R2单字长，RR型执行阶段2728OC送出控制信号到通用寄存器，选择R1和R2做源寄存器10020OC送出控制信号到ALU，指定ALU做加法120打开C1，将运算结果120输出送到DBUS上OC送出控制命令，将DBUS上的数据打入到DR120OC送出控制命令，将120装入R2，R2的内容由20变为120ADD指令的执行R1outR2out+DRinR2in29ADD指令的执行数据通路R1→ALU、R2→ALU，ALU→DBUS→DR→R2操作控制(1)选择R1和选择R2，R1和R2加法操作(3)打开三态门C1，将运算结果120输出送到DBUS；(4)将DBUS上的数据打入DR；(5)将DR中的数据120写入R2，R2的内容由20变为12030ADD指令的执行周期(1)选择R1和R2输出到ALU，指定让ALU做加法操作；(2)打开C1，运算结果120输出送到DBUS；(3)DBUS上的数据写入DR；(4)DR中的数据写入R2时间：占用一次DBUS总线，1个CPU周期315.2.2ADD指令的指令周期5.2.5ADD指令的指令周期ADDR1,R2单字长RR型取指周期：1个CPU周期执行周期：1个CPU周期325.2.5STO指令的指令周期STOR2,(R3)单字长、RS型执行阶段数据通路：R3通过DBUS到AR，数据Cache地址译码，R2的内容通过Dbus写入数据Cache3321:1634（1）OC送出操作命令到通用寄存器，选择R3；STO指令的执行R3out35（2）OC送出命令,打开C2，将地址30放到DBUS上；30STO指令的执行36（3）OC发出操作命令，将30装入AR，数存开始地址译码3030STO指令的执行ARin37（4）OC发出命令到通用寄存器，选择R230STO指令的执行R2out38（5）OC发出操作命令，打开三态门C2，将数据120放到DBUS上；12012030STO指令的执行39（6）OC发出命令，将数据120写入30号单元，它原先的数据40被覆盖30120STO指令的执行DCache写40STO指令的执行(1)选择R3，打开三态门C2，将地址30放到DBUS上；(2)地址30装入AR；(3)选择R2，打开三态门C2，将数据120放到DBUS上；(4)将数据120写入数存30号单元时间：使用两次DBUS，需要两个CPU周期21:055.2.5STO指令的指令周期415.2.5STO指令的指令周期21:0542STOR2,(R3)单字长RS型3个CPU周期5.2.6JMP指令的指令周期JMP101无条件转移指令，改变程序的执行顺序单字长、单地址执行阶段数据通路：IP中的101通过DBUS到达PC操作控制4321:0544（1）打开三态门C3，将IR中的地址码101发送到DBUS上JMP指令的执行45（2）将DBUS上的地址码101打入到PC中，PC中原先的内容106被覆盖JMP指令的执行PCin465.2.6JMP指令的执行周期(1)打开C3，地址码101发送到DBUS(2)DBUS上的地址码101写入到PC时间：占用一次总线，需要1个CPU周期21:05475.2.6JMP指令的指令周期5.2.6JMP指令的指令周期JMP1012个CPU周期21:05485.2.7指令周期495.2.7指令周期505.2.7用方框图语言表示指令周期采用方框图（指令流程图）来表示指令周期一个矩形框代表一个CPU周期矩形框中的内容表示数据通路矩形框右边写出控制信号菱形框表示判断或测试时间上依附于前一个方框的CPU周期，不独占一个CPU周期公操作符号“～”一条指令执行完毕后CPU进行的一些共性操作，中断请求、DMA请求等5121:055.2.2指令周期52译码PCout,,IRin,PC+1PCIR5.2.7方框图表示指令周期由上图可见，对于图5.1的模型机所有指令的取指周期是完全相同的，而且是一个CPU周期。在执行周期，由于各条指令的功能不同，所用的CPU周期也是各不相同MOV、ADD、JMP指令是一个CPU周期LAD、STO指令是两个CPU周期，需要访问内存5321:05R1iR1oR2oR2i例1的数据通路图R1iR1oR2oR2i画出下面指令的指令周期流程图，假设该指令的地址已放入PC中。列出相应的微操作控制信号序列“ADDR2，R0”指令完成(R2)+(R0)→R0的功能(2)“SUBR1，R3”指令完成(R3)-(R1)→R3的操作基本步骤取指周期写出取指周期数据通路PCxxxxIR写出的控制信号形成上述数据通路要记得PC+1设定操作控制信号的时间使用一次总线或访问一次内存为一个CPU周期根据经验执行周期根据执行周期要完成的操作写出数据通路具体指令具体分析，依据具体功能写出形成上述数据通路的控制信号设定操作控制信号的时间RS型指令需要更多的CPU周期56取指周期(ADDR2，R0)数据通路：PCBGAARMDRBGAIR57取指周期(ADDR2，R0)数据通路：PCBGAARMDRBGAIR控制信号：PCo、G、ARiRDRo，G、IRi58取指周期(ADDR2，R0)时间分配数据通路：控制信号PCBGAAR：PCo、G、ARi（1个CPU周期）MDR：R（1个CPU周期）DRBGAIR：DRo，G、IRi（1个CPU周期）59取指周期(ADDR2，R0)60PCARPCo、G、ARiMDRRDRIRDRo，G、IRi，PC+1ADD指令执行周期(ADDR2，R0)ADDR2，R0”指令完成(R2)+(R0)→R0的功能数据通路：R2BGAX；R0BGAY；ALUBGAR061执行周期(ADDR2，R0)ADDR2，R0”指令完成(R2)+(R0)→R0的功能数据通路：控制信号R2BGAX:R2o，G、XiR0BGAY:R0o，G、YiALUBGAR0:+，ALUo，G、R0i62执行周期(ADDR2，R0)时间分配ADDR2，R0”指令完成(R2)+(R0)→R0的功能数据通路：控制信号R2BGAX:R2o，G、Xi（1个CPU周期）R0BGAY:R0o，G、Yi（1个CPU周期）ALUBGAR0:+，ALUo，G、R0i（1个CPU周期）63执行周期(ADDR2，R0)64R2XR2o，G、XiR0YR0o，G、YiALUR0+，ALUo，G、R0i65(1)“ADDR2，R0”指令是一条RR型加法指令图的右边部分标注了每一个机器周期中用到的微操作控制信号序列。ALU0R066(2)“SUBR1，R3”在执行阶段，微操作控制信号序列与ADD指令有所不同。ALU05.3时序产生器和控制方式5.3.1时序产生器作用和体制5.3.2时序信号产生器5.3.3控制方式111:2325.3.1时序产生器作用和体制计算机的协调动作需要时间标志，而时间标志则是用时序信号来体现用时序信号辨认从内存中取出的是指令还是数据，是取指周期还是执行周期一个CPU周期中时钟脉冲对CPU的动作有严格的约束操作控制器发出的各种信号是时间（时序信号）和空间（部件操作信号）的函数11:23数据：电位控制信号：脉冲5.3.1、时序产生器作用和体制时序信号的基本体制是电位—脉冲制（以触发器为例）电位：用电平的高低进行控制脉冲：用信号的边沿进行控制11:233在微程序控制器中，采用节拍电位-节拍脉冲二级体制时序信号产生电路简单一个CPU周期称为一个节拍电位45.3.1、时序产生器作用和体制ΦT1T2T3T4节拍电位节拍脉冲11:23C1C2在微程序控制器中，采用节拍电位-节拍脉冲二级体制时序信号产生电路简单一个CPU周期称为一个节拍电位55.3.1、时序产生器作用和体制ΦT1T2T3T4CPU周期CPU周期节拍电位节拍脉冲11:23硬布线控制器中，时序信号往往采用状态周期-节拍电位-节拍脉冲三级体制时序信号产生电路复杂状态周期是电位信号，指明当前指令处于哪个状态比如，一个指令的状态周期包括取值周期和执行周期两个状态，取指周期包括1个CPU周期，执行周期包括2个CPU周期65.3.1、时序产生器作用和体制11:23ΦT1T2T3T4CPU周期CPU周期节拍电位节拍脉冲状态周期状态周期-节拍电位-节拍脉冲三级体制11:237取指周期执行周期C1C2C385.3.2、时序信号产生器时钟源:石英晶体振荡器环形脉冲发生器节拍脉冲启停控制逻辑本书模型机启动时，一定要从T1前沿开始；停机时一定要在T4结束后关闭时序产生器11:2391.时钟源时钟源用来为环形脉冲发生器提供频率稳定且电平匹配的方波脉冲信号它通常由石英晶体振荡器和与非门组成的正反馈振荡电路组成，其输出为一个理想的方波11:232、环形脉冲发生器C4C1C2C3Φ作用：产生一组有序间隔相等或不等的脉冲序列11:23103、节拍脉冲1111:233、节拍脉冲1211:233、时序信号举例MOVR0R1该指令的取指周期的需要一个节拍电位，即一个CPU周期，操作信号的节拍脉冲划分为：PC->ABus(I)：T1IBus->IR：T2IR中OP->指令译码器：T311:23133、时序信号举例MOVR0，R1该指令的执行周期需要一个节拍电位操作信号的节拍脉冲划分为：设置ALU完成传送操作：T1R1->ALU：T2DBus->DR：T3DR->R0：T4在一个节拍电位中完成四个有时序关系的操作11:231411:2315T1T2T3T4CPU周期节拍脉冲DBus->DR：T3信号来自译码器，持续一个节拍电位时间4、节拍脉冲和读/写时序1611:2317节拍脉冲节拍电位11:234.启停控制逻辑启动、停机具有随机性当计算机启动时，一定要从节拍点位T1前沿开始工作停机时一定要在节拍点位T4结束后关闭时序产生器1811:235.3.3控制方式指令周期由若干个CPU周期组成每条指令所需的时间各不相同每个操作控制信号所需的时间及出现的次序各不相同形成控制操作序列的方法，称作控制器的控制方式有同步控制、异步控制、联合控制三种方式1911:231.同步控制方式CPU周期数固定、时钟周期数固定节拍电位数固定，节拍脉冲数固定与指令功能、操作复杂度、操作数类型无关设计时固定，与指令的执行无关具体方案：(1)采用统一的CPU周期(2)采用不定长CPU周期(3)中央控制与局部控制结合大部分采用统一CPU周期，个别指令采用不定长CPU周期2011:23212.异步控制方式CPU周期数可变、时钟周期数可变可变：在指令执行时变化每条指令的指令周期所需的CPU周期数不等需要多少时间就占用多少时间反馈机制：执行部件完成操作后发“回答”信号11:23223.联合控制方式同步控制和异步控制相结合的方式两种实现方法1.大部分指令同步控制，少数操作采用异步方式2.CPU周期数可变、时钟周期数固定11:235.4微程序控制器英国剑桥大学的M·V·Wilkes教授于1951年首先提出1964年，IBM公司在IBM360系列机上成功地采用了微程序设计技术20世纪70年代以来，由于VLSI技术的发展，推动了微程序设计技术的发展和应用目前，x86系列几乎都采用微程序设计技术，ARM采用微程序和硬连线相结合2311:23245.4微程序控制器微程序控制（microprogrammingcontrol）基本思想把操作控制信号编制成微指令，存放到只读存储器（控制存储器）里；运行时，从控存中取出这些微指令，从而产生所需的各种操作控制信号微程序设计技术是用软件方法来设计硬件11:235.4.1微程序控制原理1微命令和微操作部件分为两种：控制部件和执行部件微命令：控制部件通过控制线向执行部件发出的控制命令微操作：执行部件接受微命令后所进行的操作微操作在执行部件中是最小、最基本的操作2511:231.微命令和微操作微命令和微操作一一对应控制门电位信号的变化、寄存器输入端的控制、ALU的基本执行过程…微操作可分为相容和互斥两种：互斥：是指不能同时或不能在同一个CPU周期内并行执行的微操作相容：是指能够同时或在同一个CPU周期并行执行的微操作2611:2327（+，-，M）在同一个CPU周期中只能选择一个，因而是互斥的微命令类似地，4，6，8也是互斥的微命令1，2，3是可以同时进行的，所以是相容的微命令X输入控制4，6，8和Y输入的5，7，9中任意两个微命令也是相容的11:23282微指令和微程序微指令(Micro-instruction)：在一个CPU周期中，一组实现一定操作功能的微命令的组合在同一CPU周期内并行或并发执行的微命令的组合微指令存储在控制器中的控制存储器中11:232微指令和微程序微程序一系列微指令的有序集合就是微程序一段微程序对应一条机器指令微地址：存放微指令的控制存储器的单元地址机器指令-》微程序-》微指令-》微命令-》微操作以简单运算器通路图的微指令格式为例：2911:233011:23PC+1LDIRLDARLDDRRD312.微指令和微程序微指令格式举例微指令字长为23位，由操作控制和顺序控制两大部分组成11:232.微指令和微程序操作控制字段，发出控制信号每一位表示一个微命令某一位为1表示发出相应的微命令，为0不发出3211:23335.4.2微指令和微程序顺序控制字段，产生下一条微指令的地址（微地址）后四位：直接微地址P1P2：判断测试标志P1P2=00：使用后四位直接微地址P1P2=01：P2测试条件满足，新微地址=直接微地址条件不满足，新微地址=对直接微地址修改P1P2=10：P1测试11:233.微程序控制器原理框图它主要由控制存储器、微指令寄存器和地址转移逻辑三大部分组成34AR11:23(1)控制存储器(CM：ControlMemory)CM是微程序控制器的核心部件存放微程序只读存储器CM的字长是微指令字的长度字数=微指令数量存储容量=微指令字的长度X微指令数量3511:23控制存储器用于存放微程序控制存储器与主存对比11:2336（2）微指令寄存器(μIR)微地址寄存器和微命令寄存器组成微地址寄存器μAR：下一条微指令的微地址微命令寄存器：微指令的操作控制字段和判别测试字段3711:23（3）地址转移逻辑修改微地址根据IP中的OP字段译码产生微地址（入口微地址）顺序控制字段中的直接微地址给出下一条微指令的地址通过判别测试字段P和执行部件的反馈信息，形成新的微地址3811:234微程序举例假设在某编程环境下，需要完成BCD码加法运算，代码：b=b+a假定该代码的汇编语言是b-》R2，a-》R1对于该指令，共耗费3~4个CPU周期(异步控制)指令:ADDBR2R111:233940十进制加法指令周期流程图取指令a+b运算a+b+6运算减6运算P1测试，表示译码操作，用OP字段作为形成微指令的地址加法运算P2测试，用Cy的状态来修改微地址寄存器的最后一位本条微指令的微地址默认后继微地址11:234.微程序举例一条微指令对应一个方框微指令周期等于一个CPU周期一个方框对应与一个CPU周期指令流程图中有多少方框意味着该指令对应的微程序包含多少条微指令4111:23第一条是取指微指令，要发出的微命令是LDIR、PC+1，LDARP1译码测试4.微程序举例420000000000000010000011111:234.微程序举例第二条微指令的二进制编码是第二条微指令发出的微命令是R1X，R2Y，+，LDR2`11:23434.微程序举例第三条微指令的二进制编码是第三条微指令发出的微命令是R2X，R3Y，+，LDR2`P2判断测试11:23444.微程序举例第四条微指令的二进制编码是第四条微指令发出的微命令是R2X，R3Y，-，LDR2`11:2345000010010000000000000000111100100010010010000000微程序存放示意图顺序控制地址……11011100101110101001……0010000100000000操作控制字段…0101001001000000001000100110000000…控制存储器CM取指微指令R2-R3->R2微指令R2+R3->R2微指令R1+R2->R2微指令…指令:ADDBR2R10100001011:2346执行微程序一条机器指令的微程序由取指微程序和执行微程序组成微程序存放图5.1的主存控存CM11:2347微程序控制器的工作过程(1)取指微程序执行取指周期的操作PCIR，PC+1译码：OP字段输出到地址转移逻辑，产生对应的执行微程序的入口地址，送入μAR11:2348微程序控制器的工作过程(2)根据μAR从CM中取出微指令，并产生下一条微指令的地址送入μAR11:2349微程序控制器的工作过程(3)执行微程序的最后一条微指令执行完毕后，将μAR设为取指微程序的入口地址，从而返回第(1)步周而复始，直到所有机器指令执行完毕11:2350515.CPU周期和微指令周期的关系一个微指令周期与CPU周期时间相等T1,T2,T3时间执行微指令(如运算等)T4上升沿打入结果至寄存器T4时间读取微指令11:236.机器指令与微指令的关系一条机器指令对应一段微程序一段微程序由若干条微指令组成一个微指令包含多个微命令机器指令、程序和地址与内存有关微指令、微程序和微地址与控制存储器有关5211:2353写控制读控制选择WA1WA0W选择RA1RA0R不写入**0不读出**0R3111R3111R2011R2011R1101R1101R0001R0001例设某计算机运算器框图如图所示，其中ALU为16位的补码加法器，SA,SB为16位暂存器，4个通用寄存器的读、写控制功能见下表11:23机器采用微程序控制方式，微指令操作控制字段格式如下(未考虑顺序控制字段)：11:2354要求：写出如下指令执行周期微程序的编码：(1)“ADDR0，R1”指令，即(R0)+(R1)→R1(2)“SUBR2，R3”指令，即(R3)-(R2)→R3(3)“MOVR2，R3”指令，即(R2)→(R3)11:23552.写出微程序：00**1010000001**10010000**01010010011.画出ADDR0，R1指令的流程图RA0RA1=00RLDSALDSBRA0RA1=01RSB-ALUWA0WA1=01W~11:2356572.写出微程序：11**1010000010**10010000**11010001011.画出SUB指令的流程图RA0RA1=11RLDSALDSBRA0RA1=10RWA0WA1=11W~11:23582.写出微程序：10**10100000**11010010111.画出MOV指令的流程图RA0RA1=10RLDSASB-ALUWA0WA1=11W~Reset11:23595.4.2微程序设计技术设计微指令应当追求的目标缩短微指令的长度减小控制存储器的容量提高微程序的执行速度便于对微指令的修改提高微程序设计的灵活性操作控制字段和顺序控制字段的设计如何用二进制表示各种操作控制信号如何形成下一个微地址目标可能是矛盾的！11:231、微命令编码操作控制字段采用的表示方法直接表示法编码表示法混合表示法6011:23（1）直接表示法每一位表示一个微命令“0”表示不发出该微命令“1”表示发出该微命令优点：结构简单，并行性强，操作速度快缺点：每条微指令要包含所有的微命令，微指令太长，导致CM容量较大6111:23（2）编码表示法把相斥的微命令编成一个小组，然后通过译码器对小组信号进行译码，输出作为微命令微指令字缩短，译码电路使微指令的执行速度减慢比如：4个微命令如何编码？要考虑不发出任何微命令的状态6211:23（3）混合表示法直接表示法与编码法结合综合考虑指令字长、灵活性、执行微程序速度等方面的要求6311:232、微地址的形成方法确定下一条微指令的微地址下一条微指令的微地址成为后继微地址1.计数器方式2.多路转移方式（断定方式）6411:23（1）计数器方式顺序执行时后继微地址=当前微地址+增量；类似指令的顺序寻址非顺序执行（分支）时后继微地址=微地址字段类似跳跃寻址特点顺序控制字段较短，微地址产生机构简单多路并行转移功能较弱，速度较慢，灵活性较差6511:232）多路转移方式（断定方式）一条微指令具有多个转移分支的能力称为多路转移顺序执行时后继微地址=微地址字段非顺序执行（分支）时按“判别测试”标志和“状态条件”信息产生一个微地址6611:232）多路转移方式特点：能以较短的顺序控制字段配合，实现多路并行转移，灵活性好，速度较快，需要设计地址转移逻辑6711:2368某计算机采用微程序控制器，共有32条机器指令，公共的取指令微程序包含2条微指令，各指令对应的执行微程序平均由4条微指令组成，采用多路转移法确定下条微指令地址，则微指令中下址字段(微地址字段)的位数至少是()A.5B.6C.7D.811:2369微指令分类微指令格式分成两类：水平型微指令和垂直型微指令（1）水平型微指令一次能定义并执行多个并行操作微命令的微指令，叫做水平型微指令11:2370微指令中设置微操作码字段，由微操作码规定微指令的功能，称为垂直型微指令其结构类似于机器指令的结构每条微指令的功能简单采用较长的微程序结构去换取较短的微指令结构（2）垂直型微指令11:2371垂直型微指令寄存器-寄存器传送型运算控制型访问主存条件转移11:23水平型微指令与垂直型微指令水平型微指令并行操作能力强，效率高，执行时间短、灵活性强微指令字较长，微程序短，控存容量大，性能佳垂直型微指令字长短，微程序长，控存容量小，性能差垂直型与指令相似，易于掌握7211:23微指令设计与微指令格式7311:2374微程序设计静态微程序设计微程序设计好之后，存放在ROM中，无法修改动态微程序设计采用EPROM/Flash作为控制存储器，微程序可以根据改变指令仿真在一台机器上实现不同类型的指令系统11:237511:235.5硬连线控制器硬连线控制器(Hard-wiredcontroller)也称为硬布线控制器把控制器看作产生控制信号的逻辑电路由门电路和触发器构成12返回1.基本思想输出信号微操作控制信号(微命令)CPU结构3LDIR(T4)LDDR(T3)PC+1LDPC(T4)RD(I)RD(D)WE(D)(T3)LDR(T4)LDAR(T4)CPU结构4LDIR(T4)LDDR(T3)PC+1LDPC(T4)RD(I)RD(D)WE(D)(T3)LDR(T4)LDAR(T4)每个操作控制信号的含义是：RD(I)—读指存RD(D)—读数存WE(D)—写数存LDPC—写入PCLDIR—写入IRLDAR—写入ARLDDR—写入DRPC+1LDR2—写入R2寄存器指令周期流程图5如何区分不同的CPU周期？指令周期流程图6如何区分不同的CPU周期？硬连线控制器时序设定M1、M2、M3三个电位信号，各自等于一个CPU周期每个CPU周期包括4个节拍脉冲（T1~T4）三级时序同步控制M1M2固定3个机器周期，12个节拍M3节拍电位硬连线控制器的指令周期流程图采用同步控制方式，将所有指令的指令周期都设为3个CPU周期图中M1、M2、M3为节拍电位信号，各自等于一个CPU周期MOV、ADD和JMP指令在M3不执行任何操作103.微操作控制信号产生在微程序控制器中微命令由微指令产生。在硬连线控制器中微命令由布尔代数表达式描述的输出函数产生。11硬连线控制器设计方法画出指令周期流程图，明确各节拍控制信号找出产生同一个微操作信号的所有条件，建立操作时间表与时序信号组合，写出逻辑表达式化简、用门电路或可编程器件物理实现。12[例3]根据图5.29，写出以下操作控制信号RD(I)、RD(D)、WE(D)、LDPC、LDIR、LDAR、LDDR、PC+1、LDR2的逻辑表达式。其中每个操作控制信号的含义是：RD(I)—指存读命令RD(D)—数存读命令WE(D)——数存写命令LDPC—打入程序计数器LDIR—打入指令寄存器LDAR—打入数存地址寄存器LDDR—打入数据缓冲寄存器PC+1—程序计数器加1LDR2—打入R2寄存器13LDIR(T4)LDDR(T3)PC+1LDPC(T4)RD(I)RD(D)WE(D)(T3)LDR(T4)LDAR(T4)每个操作控制信号的含义是：RD(I)—读指存RD(D)—读数存WE(D)—写数存LDPC—写入PCLDIR—写入IRLDAR—写入ARLDDR—写入DRPC+1LDR2—写入R2寄存器[例3]根据图5.1，写出以下操作控制信号RD(I)、RD(D)、WE(D)、LDPC、LDIR、LDAR、LDDR、PC+1、LDR2的逻辑表达式。解：（1）画出指令周期流程图15（2）列出微操作时间表（根据数据通路和操作流程图）16（2）列出微操作时间表（根据数据通路和操作流程图）列出在每个微命令在哪个电位、哪个节拍、哪个指令发产生？17（2）列出微操作时间表（根据数据通路和操作流程图）设M1、M2、M3是节拍电位信号；T1、T2、T3、T4为一个CPU周期中的节拍脉冲信号；MOV、LAD、ADD、STO、JMP是机器指令OP操作码字段译码输出信号18（3）进行微操作信号的组合得到如下逻辑表达式：LDIR=M1·T4LDAR=M2·T4·(LAD+STO)LDDR=M2·T3·(MOV+ADD)+M3·T3·LADPC+1=M1LDR2=M2·T4·ADD（4）最后给出电路（省略）硬连线与微程序控制器比较硬连线控制器执行速度快硬连线控制器设计复杂，代价昂贵微程序控制器设计简单，便于维护修改205.6.4PentiumCPU1989年初0.8um工艺，310万晶体管5V电压，功耗20W非固定长度指令格式，9种寻址方式，191条指令，兼具有RISC和CISC特性提供了更加灵活的存储器寻址结构，可以支持传统的4k大小的页面，也可以支持4M大小的页面（TLB）动态转移预测技术（BTB转移目标缓存）21Pentium结构图哈佛结构Cache2路超标量32位CPU80位FPU外部数据总线宽度为64位，外部地址总线宽度为32位微程序控制器225.7RISCCPU三个要素：(1)一个有限的简单的指令集；(2)配备大量的通用寄存器；(3)对指令流水线的优化编译技术5.7RISCCPURISC机器的特征：(1)使用等长指令（4B）(2)寻址方式少且简单(3)只有取数指令、存数指令访问存储器(4)指令数目相对较少，指令格式简单(5)指令功能简单，控制器多采用硬连线方式(6)指令的执行平均时间(CPI)为一个时钟周期。(7)配置大量寄存器、优化使用。(9)支持指令流水并强调指令流水的优化使用。(10)RISC技术的复杂性在它的编译程序23RISC与CISC的主要特征对比25MIPSAptiv框图硬布线控制器指令缓存数据缓存总线接口内存管理单元算术与逻辑运算器协处理器指令译码器通用寄存器浮点运算器26ARM处理器框图平均微程序为1.8条微指令本章重点内容CPU的功能（控制器的功能、6类寄存器）指令周期基本概念设计指令周期，画指令周期流程图时序产生器和控制方式基本原理微程序控制器工作原理微程序设计基本概念硬连线控制器基本概念本章容易混淆的一些概念周期表示一段时间。指令周期指机器指令从取指到执行完成所花的时间，包括取指周期和执行周期。CPU周期=机器周期，一个CPU周期包括多个节拍脉冲。节拍脉冲=T周期，处理操作的最基本单位指令周期＞CPU/机器周期＞节拍脉冲数据通路举例某机字长16位，指令16位定长；指令ADD(R1)，R0的功能为(R0)+((R1))(R1)，即将R0中数据与R1内容所指向的主存单元的数据相加，并将结果送入R1内容所指向的主存单元中；数据通路图中控制信号为1表示有效，假设MAR输出一直处于使能状态；数据通路举例---取指令周期C1C2C3MARMDRPCIR下表为取指令和译码阶段每个节拍(时钟周期)的功能和控制信号，请按相同方式给出执行阶段各节拍的功能和有效控制信号。数据通路举例---执行指令周期C1C2C3MARMDRA((R1))A数据通路举例---执行指令周期C4C5MARMDRAAC(R0)+((R1))(R1)5.6流水CPU5.6.1并行处理技术5.6.2流水CPU的结构5.6.3流水线中的主要问题5.6.4PentiumCPU15.6.1并行处理技术并行性的两种含义：同时性指两个以上事件在同一时刻发生；并发性指两个以上事件在同一时间间隔内发生。计算机的并行处理技术主要有以下三种形式：1.时间并行2.空间并行3.时间并行+空间并行21.时间并行让多个处理过程在时间上相互错开，轮流重叠地使用同一套硬件设备的各个部分，以加快硬件周转而赢得速度。实现方式是采用流水处理部件。目前的高性能微型机几乎无一例外地使用了流水技术。35.6.1并行处理技术5.6.1并行处理技术2.空间并行指资源重复（空间因素），以“数量取胜”VLSI为其提供了技术保证。3.时间并行+空间并行指时间重叠和资源重复的综合应用4流水线原理1.时间并行把任务分成若干子任务，使子任务在流水线的各阶段并发地执行2.空间并行资源重复多处理器系统和多计算机系统3.时间并行+空间并行时间重叠和资源重复的综合应用。奔腾CPU采用超标量流水技术，一个机器周期执行两条指令。指令周期细分取指令IF(InstructionFetch)指令译码ID(InstructionDecode)执行运算EX(Execution)访存阶段MEM结果写回WB(WriteBack)一条指令不一定经历所有阶段IFIDEXMEMWB非流水线时空图流水线时空图完成N条指令需要的时间5+(n-1)超标量流水线时空图时间TIFIDEXWB空间SI12I34I1I2I3I4I1I2I3I4I1I2I3I4I1I2I3I4具有两条以上的指令流水线。满载时，每一时钟周期可以执行2条指令I56I78流水线分类1.指令流水线取指---译码---取数---执行2.算术流水线加法器,乘法器,快速傅里叶变换器3.处理机流水线由一串级连的处理机组成.每台处理机负责某一特定任务.11一个计算机系统可以在不同的并行等级上采用流水线常见流水线有：处理机流水线：程序步骤的并行由一串级联的处理机构成流水线的各个过程段，每台处理机负责某一特定的任务。处理机流水线应用在多机系统中。指令流水线：指令步骤的并行将指令流处理过程分为取指令、译码、执行、写回等几个并行处理过程段。算术流水线：运算操作步骤的并行如流水加法器、流水乘法器、流水除法器等。3.流水线分类流水线的相关冲突（hazzard）资源相关取操作数与取指令都需要访问主存计算PC、分支地址，运算指令复用ALU增加部件消除数据相关指令操作数依赖于前一条指令的执行结果引起流水线停顿直到数据写回分支相关转移指令使得流水线发生中断提前取出的指令作废，流水线清空理想指令流水线将指令过程分成5个阶段IF、ID、EX、MEM、WB不同阶段之间设置缓冲接口部件（绿色部分）接口部件本质是寄存器各段通过接口传递与指令相关的数据，控制，反馈信息对数据的加工处理依赖于前段接口传递过来的信息MIPS经典5段流水线14流水线段间寄存器5.6.3流水线中的主要问题流水线要有良好的性能，必须能够畅通流动，不发生断流流水过程中通常会出现以下三种相关冲突（Hazard），使流水线断流。1.资源相关2.数据相关3.控制相关15数据相关处理增加相关检测判定逻辑当前指令读寄存器与后续3条指令写寄存器相同当前指令可能有0~2个读寄存器后续3条指令可能有0~1个写寄存器相关处理逻辑流水线停顿数据重定向-16-数据相关处理机制软件方法（编译器完成）插入空指令调整程序顺序，使相关性在流水线中消失硬件方法寄存器堆写入和读出分离（先写后读，下跳沿写）插入气泡（空操作）数据重定向bypass（数据旁路）将后端处理后的数据（还没来得及写回）重定向数据在哪就从哪送到运算器1.资源相关多条指令进入流水线后在同一段时间内争用同一个功能部件所发生的冲突。在时钟4时，I1与I4两条指令发生争用存储器资源的相关冲突解决资源冲突的办法：(1)冲突指令停顿若干周期，直到冲突消失；(2)增设一个存储器，将指令和数据分别放在两个存储器中。182.数据相关在流水计算机中，由于多条指令的重叠处理，当后继指令所需的操作数，刚好是前一指令的运算结果时，便发生数据相关冲突。如下表所示，ADD指令与SUB指令发生了数据相关冲突。202.数据相关例：两条指令发生数据相关冲突ADDR1,R2,R3R2+R3-->R1SUBR4,R1,R5R1-R5-->R4ANDR6,R1,R7R1^R7-->R62.数据相关RAW(ReadAfterWrite)后面指令用到前面指令所写的数据WAW(WriteAfterWrite)两条指令写同一个单元WAR(WriteAfterRead)后面指令覆盖前面指令所读的单元解决办法：可以推后后继指令对相关单元的读操作设置转发通路（Forwarding）21【例4】流水线中有三类数据相关冲突：写后读相关；读后写相关；写后写相关。判断以下三组指令各存在哪种类型的数据相关。I1:ADDR1，R2，R3；(R2)+(R3)->R1I2:SUBR4，R1，R5；(R1)-(R5)->R4(2)I3:STOM(x)，R3；(R3)->M(x)，M(x)是存储器单元I4:ADDR3，R4，R5；(R4)+(R5)->R3I5:MULR3，R1，R2；(R1)×(R2)->R3I6:ADDR3，R4，R5；(R4)+(R5)->R3写后读RAW相关读后写WAR相关写后写WAW相关233.控制相关由转移指令引起的。当前指令有跳转，但流水已经开启后续指令处理过程解决技术：延迟转移法由编译程序重排指令序列，让跳转的指令接在最后流水入口转移预测法用硬件预测将来的行为，提前让转移指令进流水。指令调度为了充分发挥指令流水线的效率，减小断流，降低指令间的相关性，在保证程序正确执行的前提下，需要对指令的执行顺序进行重新编排静态调度由编译器在编译过程中对指令进行调度动态调度由控制器在指令执行过程中进行调度，对程序员透明乱序执行（OutOfOrder）记分牌算法，Tomasulo算法255.6.4PentiumCPU1989年初0.8um工艺，310万晶体管5V电压，功耗20W非固定长度指令格式，9种寻址方式，191条指令，兼具有RISC和CISC特性提供了更加灵活的存储器寻址结构，可以支持传统的4k大小的页面，也可以支持4M大小的页面（TLB）动态转移预测技术（BTB转移目标缓存）26Pentium结构图哈佛结构Cache2路超标量32位CPU80位FPU外部数据总线宽度为64位，外部地址总线宽度为36位微程序控制器27IntelHaswell结构图285.7RISCCPU三个要素：(1)一个有限的简单的指令集；(2)配备大量的通用寄存器；(3)对指令流水线的优化编译技术5.7RISCCPURISC机器的特征：(1)使用等长指令（4B）(2)寻址方式少且简单(3)只有取数指令、存数指令访问存储器(4)指令数目相对较少，指令格式简单(5)指令功能简单，控制器多采用硬连线方式(6)指令的执行平均时间(CPI)为一个时钟周期。(7)配置大量寄存器、优化使用。(9)支持指令流水并强调指令流水的优化使用。(10)RISC技术的复杂性在它的编译程序29RISC与CISC的主要特征对比多周期流水线3132MIPSAptiv框图硬布线控制器指令缓存数据缓存总线接口内存管理单元算术与逻辑运算器协处理器指令译码器通用寄存器浮点运算器33ARM处理器框图平均微程序为1.8条微指令本章重点内容CPU的功能（控制器的功能、6类寄存器）指令周期基本概念五种基本指令的指令周期及其数据通路流程时序产生器和控制方式基本原理微程序控制器工作原理微程序设计基本概念硬连线控制器基本概念本章容易混淆的一些概念微命令控制部件通过控制线向执行部件发出的各种控制命令微操作执行部件接受微命令以后所进行的操作公操作一条指令执行完毕以后，CPU所进行的操作本章容易混淆的一些概念微指令在机器的一个CPU周期中，一组实现一定操作功能的微命令的组合，构成一条微指令微程序:一条指令均对应一段微程序，微程序固化在控制存储器中。机器指令本章容易混淆的一些概念周期表示一段时间。指令周期指机器指令从取指到执行完成所花的时间，包括取指周期和执行周期。CPU周期=机器周期，一个CPU周期包括多个节拍脉冲。节拍脉冲=T周期，处理操作的最基本单位指令周期＞CPU/机器周期＞节拍脉冲1第六章总线系统6.1总线的概念和结构形态6.2总线接口6.3总线仲裁6.4总线的定时和数据传送模式6.5PCI总线和PCIe总线6.1.1总线的基本概念总线(BUS)是构成计算机系统的互连机构是多个系统功能部件之间进行数据传送的公共通路借助于总线各系统功能部件之间实现地址、数据和控制信息的交换在争用资源的基础上进行工作26.1.1总线的基本概念一个单处理器系统中的总线大致分为：内部总线：CPU内连接各寄存器及运算器部件之间的总线系统总线：CPU和其他高速功能部件（如存储器、通道等）相互连接的总线I/O总线：中低速I/O设备相互连接的总线3物理特性：总线的物理连接方式，包括根数、插头形状，引脚线的排列方式功能特性：描述总线中每一根线的功能：地址、数据、控制三类电气特性：定义每一根线上信号的传递方向（单/双向）及有效电平范围时间特性：规定了总线上各信号有效的时序关系，每根总线在什么时间有效41.总线的特性2.总线的标准化对总线的四个特性定义一个广泛认可的标准实现不同厂家的功能部件互换使用USB、PCI-E53.总线带宽6常见总线带宽86.1.2总线的连接方式外围设备和总线的连接部件称为适配器(adapter)：完成CPU和外设之间的数据传送和控制实现传输速率匹配和同步；通常称为接口(interface)96.1.2总线的连接方式总线影响计算机系统性能，单处理器计算机中采用的总线结构有两种基本类型：单总线结构和多总线结构单总线结构CPU是主控设备（发起通信的设备）结构简单、容易扩充多部件共享总线，分时工作传输效率低处理器结构对总线有影响10112.多总线结构主要解决各种设备速率不匹配的问题位于CPU内部，速度最快连接主存高速I/O设备低速I/O设备连接不同速率的总线总线的效率和吞吐量得以提高高速、中速、低速设备连接到不同的总线上同时进行工作现代计算机中的多总线结构126.2总线接口6.2.1信息的传送方式计算机系统中，传输信息有两种方式：串行传送并行传送131.串行传送按顺序传送一个数码（一个字节）的所有二进制位(bit)，每次一位一般先传低位，后传高位使用一条物理传输线：单端传输两条传输线：差分传输数据传送前：并—串变换数据接收后：串—并变换141.串行传送特点：成本较低、速度慢位时间：每个比特在传输线上占用的时间长度波特率(baud)：每秒钟传送的比特数波特率是位时间的倒数串行传送的数据格式编码起始位(1b)+数据位(1B)+校验位(1b)+停止位(1b)1516【例2】利用串行方式传送字符，设数据传送速率是120个字符/秒，每一个字符格式规定包含10个比特位（起始位、停止位、8个数据位）问波特率是多少?位时间是多少?【解】：波特率为：10位×120/秒=1200波特位时间是波特率的倒数：Td=1/1200=0.833×10-3s=0.833ms2.并行传送同时传输多个比特，对每个数据位都需要单独一条传输线数据传送比串行数据传送快得多（传输频率较低时）17发展趋势并行传输距离受限频率越高，线间串扰越严重，带宽无法继续提高串行传输距离长无串扰现象、提供更高的带宽随着总线频率的增加，并行逐渐转向串行SCSISASPATASATAPCIPCI-E183.分时传送功能复用：某个传输线上既传送地址信息，又传送数据信息分时复用：共享总线的部件分时使用总线必须划分时间片196.2.2总线接口的基本概念I/O接口即I/O设备适配器指CPU和主存、外围设备之间通过总线进行连接的标准化逻辑部件I/O接口部件在连接的两个部件之间起着“转换器”的作用，实现彼此之间的信息传送一个接口可连接一个设备，也可连接多个设备206.2.2总线接口的基本概念外部设备有自己的设备控制器设备控制器通过I/O接口和总线连接，进而与CPU交换信息外围设备的连接方法6.2.2总线接口的基本概念一个适配器的两个接口：连接系统总线的接口连接外设的接口接口的典型功能：控制、缓冲、状态、转换、整理、程序中断226.3总线仲裁总线上的设备有主方和从方两种形态主方启动一个总线周期、从方响应主方请求每次总线操作，只能有一个主方，可以有多个从方为了解决多个主方争用总线的问题，设置总线仲裁部件（arbitrator）采用优先级策略或公平策略按照总线仲裁电路的位置不同，分为集中式和分布式231.集中式仲裁一个中央仲裁器，连接线：送往仲裁器的总线请求信号线BR(BusRequest)仲裁器送出的总线授权信号线BG(BusGrant)表征总线是否空闲的信号BS（BusBusy）集中式仲裁采用三种方式(1)链式查询方式（菊花链查询-Daisychain）(2)计数器定时查询方式(3)独立请求方式24(1)链式查询方式接口发出总线请求信号BR（置BR为高）仲裁器在总线空闲的时候（BS为低）开始仲裁总线授权信号BG依次从一个I/O接口传送到下一个I/O接口（串行查询）假如BG到达的接口无总线请求，则继续往下传递；假如BG到达的接口有总线请求，该接口获得总线控制权（将BS置为1），BG信号便不再往下传递25BS--总线忙BR--总线请求BG--总线授权查询过程(1)链式查询方式特点：优先级固定：离仲裁器最近的设备具有最高优先级，离仲裁器越远，优先级越低用线少，易扩充;对查询链的电路故障很敏感，单点故障26(2)计数器定时查询方式每个设备分配一个地址，设备内部有地址判别电路仲裁器内部有个计数器，其输出和设备地址线连接对设备地址计数27(2)计数器定时查询方式设备通过BR线发出总线请求仲裁器在BS为低时让计数器开始计数，计数值通过设备地址线广播设备内部的地址判别电路，判断地址线上的计数值与自身设备地址是否一致如果一致且该设备的BR为高，获得了总线使用权，则置BS线为1如果没有设备获得总线使用权，计数值加一，再次广播仲裁器判断BS为高，中止计数查询2829(2)计数器定时查询方式每次计数可以从“0”开始，也可以从中止点开发始固定优先级：每次从“0”开始计数，优先级的顺序是固定的公平优先级：从中止点开始计数，每个设备都有可能成为最高优先级可变优先级：软件修改计数器初值缺点：控制线较多、扩展性较差（与计数器的位数有关）计数器(3)独立请求方式每个设备均有独立的总线请求线BRi和总线授权线BGi中央仲裁器中的排队电路决定首先响应哪个设备的请求，给设备以授权信号Bgi特点：响应速度快控制灵活，优先级可通过程序改变；控制线数多、总线裁决机构较复杂30312.分布式仲裁每个功能设备都有自己的仲裁号以及仲裁器仲裁过程通过协商完成6.4.1总线的定时总线信息传送过程，可分为：请求总线，总线仲裁，寻址，信息传送，状态返回定时：事件出现在总线上的时序关系同步定时：事件出现在总线上的时刻由总线时钟信号确定总线信号中包含公共时钟线异步定时：建立在应答式或互锁机制基础上后一事件出现在总线上的时刻取决于前一事件的完成不需要统一的公共时钟信号326.5PCI总线和PCIe总线PCI-（PeripheralComponentInterconnect）是美国SIG推出的32～64位总线（并行总线）频率为33～66MHz，数据传输率为132～528MB/s基于PCI总线计算机结构处理器处理器主存控制器主存PCI设备PCI设备HOST桥主设备目标设备PCI/LAGACY总线桥PCI/PCI桥LAGACY设备LAGACY设备PCI设备PCI设备HOST总线PCI总线PCI总线LAGACY总线（遗留）现代计算机中的多总线结构35PCI总线特点允许智能设备在适当的时候取得总线控制权以加速数据传输和对高度专门化任务的支持支持猝发传输模式与ISA／EISA／MCA兼容设有特别的缓存，实现外设与CPU隔离，外设或CPU的单独升级都不会带来问题同步时序、集中式仲裁PCIExpress总线PCIExpress是一种基于串行技术、高带宽连接点、点到点连接的新型总线技术PCIExpress采用4根信号线差分传输，全双工、可靠性高、速度快多种连接方式，扩展性好如×1、×4、×8、×16以及×32通道的连接器支持热插拔和热交换软件层与PCI兼容37PCIExpress总线PCIExpress总线插槽38PCIExpress总线39共享式hub独占式switchUSB（UniversalSerialBus）由Compaq、Intel、Microsoft、NEC等公司于96年共同研制发布传输速度高、使用简单、编程复杂适合计算机中所有高、中、低速传输外部总线USB1.1/2.04线传输、半双工USB（UniversalSerialBus）USB3.0全双工Type-C物理接口不区分正反面USB标准演进42USB标准演进431第七章外围设备7.1外围设备概述7.2磁盘存储设备7.3磁带存储设备7.4光盘和磁光盘存储设备7.5显示设备7.6输入设备和打印设备7.1.1外围设备的一般功能外围设备又称外部设备：功能:在计算机和其他设备之间，以及计算机与用户之间提供联系每一种外围设备，都是在它自己的设备控制器控制下进行工作，而设备控制器则通过I/O接口和主机相连，并受主机控制7.2磁盘存储设备磁表面存储：将磁性材料涂在载磁体（铝或塑料）存储信息磁盘存储器、磁带存储器优点：存储容量大，位价格低；可以重复使用；信息可以长期保存；缺点：存取速度较慢，机械结构复杂31.磁性材料物理特性B---磁感应强度H---外加磁场强度I----电流2.磁表面存储器的读写原理利用磁头来形成和判别磁性材料的不同磁化状态磁性材料排列方式磁性材料均匀排列在圆形载磁体上水平排列密度低、容量小垂直排列密度高、容量大7.2.2磁盘的组成和分类目前硬磁盘主要是温彻斯特磁盘，简称温盘，是一种可移动磁头固定盘片的磁盘机密封组合、悬浮磁头防尘性能好，可靠性高，对使用环境要求不高7优点：没有摩擦、寿命长硬盘磁头与盘片的接触方式：悬浮式优点：没有摩擦、寿命长温盘原理101.44MB软盘软盘：固定磁头，可移动盘片硬磁盘驱动器主要3个部件组成定位驱动系统：控制磁头臂径向运动主轴系统：控制磁盘旋转数据转换系统：磁电互换117.2.3硬盘驱动器和控制器7.2.4磁盘上信息的分布盘片的上下两面都能记录信息，称为记录面（surface）一个记录面对应一个磁头（Head），用磁头表示记录面记录面上一系列同心圆称为磁道（Track）由外向内依次编号，最外侧为0磁道每个磁道等弧度分为若干个扇区（Sector）信息按扇区存放，每个扇区的存储信息量是相同的，为512B127.2.4磁盘上信息的分布扇区之间有间隙(gap)，用于隔离扇区spindlesurfacetrackstrackksectorsgaps磁头和盘片的运动盘片旋转磁头悬浮，沿半径方向运动.-14-7.2.4磁盘上信息的分布所有记录面上相同编号的磁道形成一个圆柱面(Cylinder)，简称柱面柱面数等于磁道数柱面是逻辑、虚拟概念所有磁盘统一转动，所有磁头一起移动磁盘访问过程：1.OS计算出要访问的位置(C、H、S)2.控制磁头移动到对应的柱面3.磁盘旋转到起始扇区4.磁盘继续旋转，磁头开始读写信息15硬盘上的一个扇区要用三个参数来定位（CHS模式）：柱面号、磁头号、扇区号标准记录格式硬盘容量=柱面数×磁头数×扇区数×512字节7.2.4磁盘上信息的分布7.2.4磁盘上信息的分布如果某文件长度超过一个磁道的容量，应将它记录在同一个记录面上，还是记录在同一个柱面上?17磁头的移动都需要时间，而且在磁盘访问总时间中占比较大如果某文件长度超过一个磁道的容量，应将它记录在同一个柱面上，因为不需要移动磁头，读/写速度快7.2.4磁盘上信息的分布柱面号10位，磁头号8位，扇区为6位，得到CHS模式容量限制8.4G现代磁盘采用LBA（逻辑区块地址(LogicalBlockAddress）187.2.5磁盘存储器的技术指标存储密度：道密度：沿磁盘半径方向单位长度上的磁道数位密度：磁道单位长度上能记录的二进制位数面密度：位密度和道密度的乘积一个磁盘存储器所能存储的字节总数，称为磁盘存储器的存储容量格式化容量和非格式化容量197.2.5磁盘存储器的技术指标20217.2.5磁盘存储器的技术指标磁盘存取时间23【例1】磁盘有6片磁盘，每片有两个记录面，最上最下两个面不用存储区域内径22cm，外径33cm，道密度为40道/cm，内层位密度400位/cm，转速6000转/分问：(1)共有多少柱面?(2)总存储容量是多少?(3)数据传输率多少?24解：(1)共有多少柱面?有效存储区域=16.5-11=5.5(cm)因为道密度=40道/cm，共有40×5.5=220道，即220个圆柱面(2)总存储容量是多少?内层磁道周长为2πR=2×3.14×11=69.08(cm)每道信息量=400位/cm×69.08cm=27632位=3454B每面信息量=3454B×220=759880B总容量=759880B×10=7598800B(3)数据传输率多少?磁盘数据传输率Dr=rNN为每条磁道容量，N=3454Br为磁盘转速，r=6000转/60秒=100转/秒Dr=rN=100×3454B=345400B/s-25-硬盘发展趋势充氦气：缩短碟片距离，增加碟片数量4K扇区：与OS文件管理匹配，减少扇区浪费叠瓦SMR、二维TDMR、微波辅助磁记录(MAMR)、热辅助磁记录(HAMR)增大单碟容量容量将到达100TB26固态硬盘固态硬盘SSD（solidstateDisk）由控制单元和ROM存储单元（FLASH芯片）组成速度快、抗震、零噪音、重量轻等优点28297.3磁带存储设备磁带的记录原理与磁盘基本相同，只是它的载磁体是一种带状塑料，叫做磁带磁带采用顺序访问方式，速度比磁盘速度慢通常用作为数据备份的海量存储设备307.4光盘和磁光盘存储设备光盘上的信息以坑点形式分布凹坑表示“1”，凸点表示为“0”读出时，当激光束照射在凹坑上时反射率低；而照射在凸点上时反射率高根据反射光的光强变化并进行光电转换，即可读出记录信息只读型CD光盘CD-DA数字唱盘，记录数字化信息，74分钟数字立体声信息CD-ROM容量640MB可写CD写一次型CD-R利用激光改变有机染料记录面对光的反射率可多次的重复写入磁光盘CD-MO(Magneto-Optical)利用激光产生高温来改变磁场CD-RW(Rewritable)利用激光改变相变材料的晶态和非晶态两种状态DVDDVD使用较短波长的激光束，使盘片数据的密度达4.7GB，是CD产品容量的7倍，如果采取双面双层的记录方式，容量更可高达17GBDVD-ROMDVD-VideoDVD-AudioDVD-RDVD-RAM-33-不同盘片比较TrackPitch:1.6μmMinimumPitLength：0.8μmStorageDensity:0.41Gb/inch2TrackPitch:0.74μmMinimumPitLength：0.4μmStorageDensity:2.77Gb/inch2TrackPitch:0.32μmMinimumPitLength：0.15μmStorageDensity:14.73Gb/inch2CD0.7GBDVD4.7GBBlu_rayDisc25GB-34-光驱的速度1倍速CD在1小时内读完一张CD盘的速度定义为1倍速，150KB/SDVD的1倍速则在1350KB/s左右X倍速：指是最初光驱读取速率的多少倍的读取速率的光驱1第八章输入输出系统8.1CPU和外设之间的信息交换方式8.2程序查询方式8.3程序中断方式8.4DMA方式8.5通道方式8.6通用I/O标准接口返回8.1CPU与外设之间的信息交换方式I/O设备同CPU交换数据的过程：输入过程：(1)CPU把一个地址放在地址总线，选择某一输入设备；(2)CPU等候输入设备的数据有效；(3)CPU从数据总线读入数据，并放在一个相应的寄存器中输出过程：(1)CPU把一个地址放在地址总线，选择输出设备；(2)CPU把数据放在数据总线上；(3)输出设备认为数据有效，从而把数据取走问题的关键在于：如何找到对应的外部设备?编址方式什么时候数据才有效?定时方式2外围设备编址方式编址对象I/O设备中的控制寄存器、数据寄存器、状态寄存器3外围设备编址方式:独立编址（IsolatedI/O）内存单元和I/O寄存器各自独立编址：两个地址空间I/O寄存器地址称为端口号访问I/O寄存器有专门的I/O指令X86：out80H,AX4外围设备编址方式:统一编址也称为内存映射I/O：MemoryMappedI/O，MMIOI/O寄存器和内存单元一起编址：一个地址空间同一地址空间中的不同部分来区分I/O寄存器和内存单元访存指令访问I/O设备和内存，Load/StoreARM、RISC-V、MIPS5MIPS处理器内存映射I/O6【例1】假设有一个运行时间为100秒的基准程序，其中90秒是CPU时间，剩下的是I/O占用的时间如果在以后的5年里，CPU的速度每年提高50%但I/O时间保持不变，那么5年后运行程序要耗费多少时间？I/O时间所占的比例是多少?解：耗费的时间=CPU时间+I/O时间目前，I/O时间=100-90=10秒今后五年内CPU时间、I/O时间及其所占比例如下表：外设定时如何判断数据有效是外设定时的关键根据外围设备的速度分为3种定时：速度极慢或简单的外围设备(机械开关，显示二极管)直接输入输出慢速或中速的外围设备异步定时高速的外围设备同步定时8.1.4CPU与I/O接口之间的数据传送CPU管理外围设备的方式：无条件传送方式（简单I/O方式）程序查询方式程序中断方式直接内存访问(DMA)通道方式单片机多采用程序查询、程序中断PC采用程序中断和DMA通道方式用在大型计算机中98.2程序查询方式又叫程序控制I/O方式当需要输入/输出时，CPU暂停执行主程序，转去执行设备输入/输出的服务程序，进行数据传输异步定时：查询设备状态，判断是否有效103、程序查询方式的接口11设备选择电路用于判断地址总线上呼叫的设备是否为本设备数据缓存寄存器缓存从外设读出的数据或者CPU输出到外设的数据设备状态标志用于标志设备的工作状态，4、程序查询输入/输出方式信息交换完全由CPU执行程序实现启动设备;反复查询设备直至设备准备好;传输单个数据重复2-3步直至数据传输完毕CPU和外设串行工作，反复查询设备状态占用较多CPU时间，系统效率低CPU占用率取决于查询频率用于单片机4、程序查询输入/输出方式有多个设备时，CPU周期性地(轮询)调用各I/O设备的子程序138.2程序查询方式处理器速度为10MIPS，I/O设备为键盘，其操作速度为10字符/s，采用程序查询方式进行控制，那么对于每个输入操作，CPU等待的时间可以执行__万条指令148.2程序查询方式特点：数据传输完全依赖于程序控制硬件结构简单频繁的查询动作浪费了大量的CPU时间实时性差，随机事件响应慢目前只用在单片机中168.3程序中断方式8.3.1中断的基本概念8.3.2中断服务程序入口地址的获取8.3.3程序中断方式的基本I/O接口8.3.4单级中断8.3.5多级中断8.3.6Pentium中断机制8.3.1中断的基本概念中断（Interrupt）是指CPU暂时中止现行程序，转去处理随机发生的事件，处理完后自动返回原程序的功能和技术也称为异常(exception)中断系统是计算机实现中断功能的软硬件总称一般在CPU中设置中断机构在外设接口中设置中断控制寄存器在软件上设置相应的中断服务程序178.3.1中断的基本概念中断源:产生中断的事件与I/O设备信息交换：网络通信故障处理：硬件故障：掉电、校验错软件故障：溢出、除数0实时事件处理：键盘、鼠标程序调度，时间片划分软中断188.3.1中断的基本概念中断处理过程：某一外设的数据准备就绪后，“主动”向CPU发出中断请求信号；当CPU响应此中断，暂停运行主程序，自动转去该设备的中断服务程序；当中断服务程序执行完毕后，CPU又回到原来的主程序继续执行中断适合于处理随机出现的事件198.3.1中断的基本概念响应中断的时机什么时候对外设的中断请求进行响应？断点保护问题如何在处理完中断后正确返回主程序？多重中断处理中断处理过程中又有外设发出中断请求怎么办？中断功能实现的软硬件分工哪些功能用软件实现，哪些功能需要硬件支持？208.3.1中断的基本概念21单级中断处理过程流程图(1)响应中断的时机外设的中断请求存放在接口中的中断源锁存器里，并通过中断请求线连至CPU外设的中断请求是随机的，CPU只有在当前指令执行完毕，转入公操作时才受理中断请求(2)断点保护问题:正确返主程序断点：主程序被中断的地方（PC）现场：当前指令执行结束后CPU的状态(包括寄存器值和一些状态标志位)保存现场：现场保存到堆栈中恢复现场从堆栈中恢复PC和CPU状态，以便从断点处继续执行主程序(3)多重中断处理中断处理过程中又有新外设发出中断请求怎么办？在CPU中有一个中断屏蔽寄存器置“1”(设置屏蔽)，关中断，不受理中断请求置“0”(取掉屏蔽)，开中断，受理中断请求可以通过程序控制实现中断嵌套(4)中断功能实现的软硬件分工中断周期的操作由硬件实现也称为“中断处理的隐操作”，程序员看不到响应中断、关中断、保存断点、找出中断源顺序很重要中断服务程序由软件实现保存现场、对发起中断的设备服务、恢复现场、开中断、返回主程序8.3.2中断服务程序入口地址的获取转移到中断服务程序：找到中断服务程序的入口地址向量中断：当CPU响应中断时，由硬件直接产生一个地址(即向量地址)向量地址:设备的中断服务程序入口地址查询中断：硬件为所有中断安排一个公共的中断服务程序该公共程序查询并跳转至相应中断服务程序入口268.3.3程序中断方式的基本I/O接口:向量中断27准备就绪的标志(RD-Ready)允许中断寄存器(EI-EnableInterrupt)中断请求寄存器(IR-InterruptRequest)中断屏蔽寄存器(IM-InterruptMask)8.3.3程序中断方式数据输入的执行过程28①由程序启动外设，将该外设接口的BS标志置“1”，RD标志清“0”；②接口向外设发出启动信号；④当设备动作结束或数据缓冲寄存器填满时，设备送出控制信号，将RD置“1”；⑧设备的中断向量逻辑讲中断向量发到数据总线，CPU将中断向量赋值给PC，跳转到中断服务程序③外设传送数据到接口的数据缓冲寄存器；⑤当EI为“1”时，接口向CPU发出中断请求；⑥在一条指令执行公操作时，CPU检查IR寄存器如果标志IM为“0”，进入中断周期；⑨中断服务程序把接口中数据缓冲寄存器的数据读至CPU中的寄存器；（10）CPU发出控制信号C将接口中的BS和RD标志复位⑦CPU受理中断请求，向外设发出中断响应信号INTA并关闭中断；8.3.4单级中断所有中断源通过INTA链式查询方式连接，属于同一级离CPU近的中断源优先权高不允许任何中断源打断中断服务程序，即使优先权比它高也不能CPU中有1个IM，1个IR29INTA：InterruptAuthorization中断授权信号单级中断源的识别串行排队链法IR1，IR2，IR3为中断请求信号IS1，IS2，IS3为中断选中信号308.3.5多级中断中断源分成多个级别两级优先权每级有一个级别优先权每级内又有级内优先权中断级别高的中断源可以打断级别低的中断源，称为中断嵌套31328.3.5多级中断一维多级中断：每级中断只有一个中断源二维多级中断：每级中断有多个中断源一个系统有n级中断，则CPU中有n个IR，n个IM338.3.5多级中断某级中断被响应后，则关闭本级和低于本级的IM，开放更高级的IM不同级别的中断可以嵌套，但同一级的中断不允许嵌套中断服务程序中使用多级堆栈保存现场（包括IM）中断请求的处理方法:单级中断优先权顺序：A>B>C中断请求到达顺序中断请求的处理方法:多级中断优先权顺序：A>B>C中断请求到达顺序多级中断源的识别采用了独立请求方式和链式查询方式相结合的方式级间采用独立请求方式优先排队电路中断向量产生电路级内采用链式查询方式36开放和屏蔽中断屏蔽中断指CPU中的中断屏蔽寄存器IM置1处于“关中断”所有可屏蔽中断源的中断请求得不到响应开放中断指CPU中的IM置0处于“开中断”可以响应中断源的中断请求37允许和禁止中断禁止中断指某个中断源接口中的中断允许寄存器EI被置0对应的中断源不能发出中断请求处于“中断封锁”允许中断中断接口中的EI置1中断源处于“中断开放”允许中断源发出中断请求38【例1】参见图所示的二维中断系统请问：(1)在中断情况下，CPU和设备的优先级如何考虑?请按降序排列各设备的中断优先级【解】(1)在中断情况下，CPU的优先级最低各设备的优先次序降序排列是：A→B→C→D→E→F→G→H→I→CPU39(2)若CPU现执行设备B的中断服务程序，IM2，IM1，IM0的状态是什么?如果CPU执行设备D的中断服务程序，IM2，IM1，IM0的状态又是什么?【解】执行设备B的中断服务程序时IM2IM1IM0=111；执行设备D的中断服务程序时，IM2IM1IM0=011多级中断中，某级中断被响应后，则关闭本级和低于本级的IM，开放更高级的IM40(3)每一级的IM能否对某个优先级内的个别设备单独进行屏蔽?如果不能，采取什么办法可达到目的?【解】(3)每一级的IM标志不能对某个优先级内的个别设备进行单独屏蔽。可将接口中的EI(中断允许)标志清“0”，它禁止设备发出中断请求41(4)假如设备C一提出中断请求，CPU立即进行响应，如何调整才能满足此要求?【解】(4)要让设备C的中断请求及时得到响应，可将设备C从第2级取出来，单独放在第3级上，使第3级的优先级最高即可42【例2】参见图8.9所示的系统，只考虑A，B，C三个设备组成的单级中断结构，它要求CPU在执行完当前指令时对中断请求进行服务假设：(1)CPU“中断批准”机构在响应一个新的中断之前，先要让被中断的程序的一条指令一定要执行完毕；(2)TDC为查询链中每个设备的延迟时间；(3)TA，TB，TC分别为设备A，B，C的服务程序所需的执行时间；(4)TS,TR为保存现场和恢复现场所需的时间；(5)主存工作周期为TM试问：就这个中断请求环境来说，系统在什么情况下达到中断饱和?43例假定多级中断，其中断优先级由低到高为L0→L1→L2，试设置中断屏蔽字，将中断优先级由低到高改为L1→L2→L0原先的屏蔽字例假定多级中断，其中断优先级由低到高为L0→L1→L2，试设置中断屏蔽字，将中断优先级由低到高改为L1→L2→L0新的屏蔽字A、B、C是与主机连接的3台设备，采用多级中断实现中断优先级处理，其各自的中断服务程序中对中断屏蔽码的设置如下表所示:解：从中断屏蔽字看出，其处理优先级为：A>C>B>CPU故CPU执行程序轨迹如下：A服务B服务C服务CPUABC204060808.3.6Pentium中断机制1.中断类型Pentium有两类中断：中断和异常中断通常称为外部中断，由外部硬件信号引发有两种情况：(1)可屏蔽中断：可通过CPU中标志寄存器屏蔽(2)非屏蔽中断：这类中断不能被屏蔽异常由指令执行引发(1)执行异常：执行一条指令过程中出现错误、故障等(2)执行软件中断指令：如执行INT0，INT3，INTn等指令Pentium共有256种中断和异常，每一个有中断向量号(0～255)中断优先级分为5级482.中断服务程序中断服务程序的入口地址信息存于实模式为中断向量表IVT保护模式为中断描述符表IDTPentium取得中断向量号的途径有三种：(1)指令给出：INT20H(2)外部提供：8259中断控制器(3)CPU识别错误、故障现象4950
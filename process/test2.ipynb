{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'G:\\python_codes\\Principles_of_Computer_Construction_KG\\output\\first_epoch_entities.txt', 'r', encoding='utf-8') as f:\n",
    "    entity_list = eval(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_dict = dict()\n",
    "for i in entity_list:\n",
    "    entity_dict[i[0]] = i[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1449"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(entity_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'G:\\python_codes\\Principles_of_Computer_Construction_KG\\output\\first_epoch_trainset.json', 'r', encoding='utf-8') as f:\n",
    "    first_epoch_trainset = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'G:\\python_codes\\Principles_of_Computer_Construction_KG\\output\\test_set.json', 'r', encoding='utf-8') as f:\n",
    "    test_set = json.loads(f.read())\n",
    "with open(r'G:\\python_codes\\Principles_of_Computer_Construction_KG\\output\\validset.json', 'r', encoding='utf-8') as f:\n",
    "    validset = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_label(dataset: dict, entity_dict: dict):\n",
    "    \"\"\"更新数据集标签\n",
    "\n",
    "    Args:\n",
    "        dataset (dict): 数据集\n",
    "        entity_dict (dict): 实体词典\n",
    "    \"\"\"\n",
    "    # 代码有问题\n",
    "    # 会把已经标注的标签会被多次标注，这不符合实体识别的原则，一个实体只能被标注一次\n",
    "    for i, labels in enumerate(dataset['labels']):\n",
    "        text = dataset['corpus'][i]\n",
    "        existing_spans = {label['span'] for label in labels['output']}\n",
    "\n",
    "        # 更新已有的标签\n",
    "        for label in labels['output']:\n",
    "            span = label['span']\n",
    "            if span in entity_dict:\n",
    "                # 更新type\n",
    "                label['type'] = entity_dict[span]\n",
    "                # 更新start和end\n",
    "                start = text.find(span)\n",
    "                if start != -1:\n",
    "                    label['start'] = start\n",
    "                    label['end'] = start + len(span)\n",
    "                # 更新span\n",
    "                label['span'] = span\n",
    "\n",
    "        # 按照长度排序实体词典，确保最长的实体优先匹配\n",
    "        sorted_entities = sorted(entity_dict.items(), key=lambda item: len(item[0]), reverse=True)\n",
    "\n",
    "\n",
    "        # 添加未识别出的实体标签\n",
    "        for span, entity_type in sorted_entities:\n",
    "            start = text.find(span)\n",
    "            if start != -1:\n",
    "                overlap = False\n",
    "                for label in labels['output']:\n",
    "                    if (start >= label['start'] and start < label['end']) or (start + len(span) > label['start'] and start + len(span) <= label['end']):\n",
    "                        overlap = True\n",
    "                        break\n",
    "                if not overlap:\n",
    "                    new_label = {\n",
    "                        'type': entity_type,\n",
    "                        'start': start,\n",
    "                        'end': start + len(span),\n",
    "                        'prob': 0.0,  # 可以根据需要设置默认值\n",
    "                        'span': span\n",
    "                    }\n",
    "                    labels['output'].append(new_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_label(test_set, entity_dict)\n",
    "update_label(validset, entity_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'G:\\python_codes\\Principles_of_Computer_Construction_KG\\output\\test_set_v2.json', 'w', encoding='utf-8') as f:\n",
    "    f.write(json.dumps(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'G:\\python_codes\\Principles_of_Computer_Construction_KG\\output\\validset_v2.json', 'w', encoding='utf-8') as f:\n",
    "    f.write(json.dumps(validset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'G:\\python_codes\\Principles_of_Computer_Construction_KG\\output\\first_epoch_trainset_v3.json', 'r', encoding='utf-8') as f:\n",
    "    first_epoch_trainset_v3 = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_set = set()\n",
    "for i, row in enumerate(first_epoch_trainset_v3):\n",
    "    if row.get('label'):\n",
    "        entities = [label['text'] for label in row['label']]\n",
    "        entities_type = [label['labels'][0] for label in row['label']]\n",
    "        for item in dict(zip(entities, entities_type)).items():\n",
    "            entity_set.add(item)\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_list = list(entity_set)\n",
    "with open(r'G:\\python_codes\\Principles_of_Computer_Construction_KG\\output\\first_epoch_entities.json', 'w', encoding='utf-8') as f:\n",
    "    f.write(json.dumps(entity_list))\n",
    "with open(r'G:\\python_codes\\Principles_of_Computer_Construction_KG\\output\\first_epoch_entities.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(str(entity_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validset 标记完之后，更新词典\n",
    "with open(r'G:\\python_codes\\Principles_of_Computer_Construction_KG\\output\\first_epoch_entities.txt', 'r', encoding='utf-8') as f:\n",
    "    first_epoch_entities = set(eval(f.read()))\n",
    "with open(r'G:\\python_codes\\Principles_of_Computer_Construction_KG\\output\\validset_v3.json', 'r', encoding='utf-8') as f:\n",
    "    validset_v3 = json.loads(f.read())\n",
    "\n",
    "for i, row in enumerate(validset_v3):\n",
    "    if row.get('label'):\n",
    "        entities = [label['text'] for label in row['label']]\n",
    "        entities_type = [label['labels'][0] for label in row['label']]\n",
    "        for item in dict(zip(entities, entities_type)).items():\n",
    "            first_epoch_entities.add(item)\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "with open(r'G:\\python_codes\\Principles_of_Computer_Construction_KG\\output\\first_epoch_entities.json', 'w', encoding='utf-8') as f:\n",
    "    f.write(json.dumps(list(first_epoch_entities)))\n",
    "with open(r'G:\\python_codes\\Principles_of_Computer_Construction_KG\\output\\first_epoch_entities.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(str(first_epoch_entities))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adaseq数据集格式\n",
    "```json\n",
    "{\n",
    "    \"text\": \"鲁迅文学院组织有关专家\",\n",
    "    \"labels\": [\"B-ORG\", \"I-ORG\", \"I-ORG\", \"I-ORG\", \"I-ORG\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_labels(dataset: list):\n",
    "    new_dataset = []\n",
    "    for i, row in enumerate(dataset):\n",
    "        tmp = ['O'] * len(row['text'])\n",
    "        if row.get('label'):\n",
    "            labels = row['label']\n",
    "            for label in labels:\n",
    "                for idx in range(label['start'], label['end']):\n",
    "                    tmp[idx] = f'I-{label['labels'][0]}' if idx != label['start'] else f'B-{label['labels'][0]}'\n",
    "        new_dataset.append(\n",
    "                {\n",
    "                    'text': row['text'],\n",
    "                    'labels': tmp\n",
    "                }\n",
    "        )\n",
    "\n",
    "    return new_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_epoch_trainset_v4 = process_labels(first_epoch_trainset_v3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'G:\\python_codes\\Principles_of_Computer_Construction_KG\\output\\first_epoch_trainset_v4.json', 'w', encoding='utf-8') as f:\n",
    "    f.write(json.dumps(first_epoch_trainset_v4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validset_v4 = process_labels(validset_v3)\n",
    "with open(r'G:\\python_codes\\Principles_of_Computer_Construction_KG\\output\\validset_v4.json', 'w', encoding='utf-8') as f:\n",
    "    f.write(json.dumps(validset_v4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'G:\\python_codes\\Principles_of_Computer_Construction_KG\\output\\first_epoch_trainset_v4.json', 'r', encoding='utf-8') as f:\n",
    "    first_epoch_trainset_v4 = json.loads(f.read())\n",
    "with open(r'G:\\python_codes\\Principles_of_Computer_Construction_KG\\output\\validset_v4.json', 'r', encoding='utf-8') as f:\n",
    "    validset_v4 = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'G:\\python_codes\\Principles_of_Computer_Construction_KG\\output\\test_set_v3.json', 'r', encoding='utf-8') as f:\n",
    "    test_set_v3 = json.loads(f.read())\n",
    "test_set_v4 = process_labels(test_set_v3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'G:\\python_codes\\Principles_of_Computer_Construction_KG\\output\\test_set_v4.json', 'w', encoding='utf-8') as f:\n",
    "    f.write(json.dumps(test_set_v4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def json2conll(source, target):\n",
    "    with open(source, \"r\", encoding=\"utf-8\") as json_file:\n",
    "        data_list = json.loads(json_file.read())\n",
    "\n",
    "    conll_format = \"\"\n",
    "\n",
    "    for data in data_list:\n",
    "        text = data[\"text\"]\n",
    "        labels = data[\"labels\"]\n",
    "\n",
    "        for char, label in zip(text, labels):\n",
    "            conll_format += f\"{char}\\t{label}\\n\"\n",
    "\n",
    "        conll_format += \"\\n\"  # Add a newline to separate sentences\n",
    "\n",
    "    with open(target, 'w', encoding='utf-8') as conll:\n",
    "        conll.write(conll_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "json2conll(r'G:\\python_codes\\Principles_of_Computer_Construction_KG\\output\\first_epoch_trainset_v4.json', r'G:\\python_codes\\Principles_of_Computer_Construction_KG\\output\\first_epoch_trainset_v4.txt')\n",
    "json2conll(r'G:\\python_codes\\Principles_of_Computer_Construction_KG\\output\\validset_v4.json', r'G:\\python_codes\\Principles_of_Computer_Construction_KG\\output\\validset_v4.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "json2conll(r'G:\\python_codes\\Principles_of_Computer_Construction_KG\\output\\test_set_v4.json', r'G:\\python_codes\\Principles_of_Computer_Construction_KG\\output\\test_set_v4.txt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

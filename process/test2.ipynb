{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'G:\\python_codes\\Principles_of_Computer_Construction_KG\\output\\first_epoch_entities.txt', 'r', encoding='utf-8') as f:\n",
    "    entity_list = eval(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_dict = dict()\n",
    "for i in entity_list:\n",
    "    entity_dict[i[0]] = i[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(entity_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'G:\\python_codes\\Principles_of_Computer_Construction_KG\\output\\first_epoch_trainset_v5.json', 'r', encoding='utf-8') as f:\n",
    "    first_epoch_trainset = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'G:\\python_codes\\Principles_of_Computer_Construction_KG\\output\\test_set_v5.json', 'r', encoding='utf-8') as f:\n",
    "    test_set = json.loads(f.read())\n",
    "with open(r'G:\\python_codes\\Principles_of_Computer_Construction_KG\\output\\validset_v5.json', 'r', encoding='utf-8') as f:\n",
    "    validset = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def update_label(dataset: dict, entity_dict: dict):\n",
    "    \"\"\"更新数据集标签\n",
    "    Args:\n",
    "        dataset (dict): 数据集\n",
    "        entity_dict (dict): 实体词典\n",
    "    \"\"\"\n",
    "\n",
    "    for i, labels in enumerate(dataset['labels']):\n",
    "        text = dataset['corpus'][i]\n",
    "        existing_spans = {label['span'] for label in labels['output']}\n",
    "\n",
    "        # 更新已有的标签，并删除不在entity_dict中的标签\n",
    "        new_output = []\n",
    "        for label in labels['output']:\n",
    "            span = label['span']\n",
    "            if span in entity_dict:\n",
    "                # 更新type\n",
    "                label['type'] = entity_dict[span]\n",
    "                # 更新start和end\n",
    "                # 这里有问题\n",
    "                # 假设句子里有多个相同实体，那么这个find会多次返回第一个匹配实体的位置，导致重叠\n",
    "                # 使用正则表达式找到所有匹配的位置\n",
    "                for match in re.finditer(re.escape(span), text):\n",
    "                    start = match.start()\n",
    "                    end = match.end()\n",
    "                    if not any(start < l['end'] and end > l['start'] for l in new_output):\n",
    "                        label['start'] = start\n",
    "                        label['end'] = end\n",
    "                        label['span'] = span\n",
    "                        new_output.append(label)\n",
    "                        break  # 只更新第一个匹配的位置\n",
    "        labels['output'] = new_output\n",
    "\n",
    "        # 按照长度排序实体词典，确保最长的实体优先匹配\n",
    "        sorted_entities = sorted(entity_dict.items(), key=lambda item: len(item[0]), reverse=True)\n",
    "\n",
    "        # 添加未识别出的实体标签\n",
    "        for span, entity_type in sorted_entities:\n",
    "            # 使用正则表达式匹配所有结果\n",
    "            for match in re.finditer(re.escape(span), text):\n",
    "                start = match.start()\n",
    "                end = match.end()\n",
    "                overlap = False\n",
    "                for label in labels['output']:\n",
    "                    if (start < label['end'] and end > label['start']):\n",
    "                        overlap = True\n",
    "                        break\n",
    "                if not overlap:\n",
    "                    new_label = {\n",
    "                        'type': entity_type,\n",
    "                        'start': start,\n",
    "                        'end': end,\n",
    "                        'prob': 0.0,  # 可以根据需要设置默认值\n",
    "                        'span': span\n",
    "                    }\n",
    "                    labels['output'].append(new_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_label(test_set, entity_dict)\n",
    "update_label(validset, entity_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_label(first_epoch_trainset, entity_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'G:\\python_codes\\Principles_of_Computer_Construction_KG\\output\\test_set_v6.json', 'w', encoding='utf-8') as f:\n",
    "    f.write(json.dumps(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'G:\\python_codes\\Principles_of_Computer_Construction_KG\\output\\validset_v6.json', 'w', encoding='utf-8') as f:\n",
    "    f.write(json.dumps(validset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'G:\\python_codes\\Principles_of_Computer_Construction_KG\\output\\first_epoch_trainset_v6.json', 'w', encoding='utf-8') as f:\n",
    "    f.write(json.dumps(first_epoch_trainset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'G:\\python_codes\\Principles_of_Computer_Construction_KG\\output\\first_epoch_trainset_v3.json', 'r', encoding='utf-8') as f:\n",
    "    first_epoch_trainset_v3 = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_set = set()\n",
    "for i, row in enumerate(first_epoch_trainset_v3):\n",
    "    if row.get('label'):\n",
    "        entities = [label['text'] for label in row['label']]\n",
    "        entities_type = [label['labels'][0] for label in row['label']]\n",
    "        for item in dict(zip(entities, entities_type)).items():\n",
    "            entity_set.add(item)\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_list = list(entity_set)\n",
    "with open(r'G:\\python_codes\\Principles_of_Computer_Construction_KG\\output\\first_epoch_entities.json', 'w', encoding='utf-8') as f:\n",
    "    f.write(json.dumps(entity_list))\n",
    "with open(r'G:\\python_codes\\Principles_of_Computer_Construction_KG\\output\\first_epoch_entities.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(str(entity_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validset 标记完之后，更新词典\n",
    "with open(r'G:\\python_codes\\Principles_of_Computer_Construction_KG\\output\\first_epoch_entities.txt', 'r', encoding='utf-8') as f:\n",
    "    first_epoch_entities = set(eval(f.read()))\n",
    "with open(r'G:\\python_codes\\Principles_of_Computer_Construction_KG\\output\\validset_v3.json', 'r', encoding='utf-8') as f:\n",
    "    validset_v3 = json.loads(f.read())\n",
    "\n",
    "for i, row in enumerate(validset_v3):\n",
    "    if row.get('label'):\n",
    "        entities = [label['text'] for label in row['label']]\n",
    "        entities_type = [label['labels'][0] for label in row['label']]\n",
    "        for item in dict(zip(entities, entities_type)).items():\n",
    "            first_epoch_entities.add(item)\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "with open(r'G:\\python_codes\\Principles_of_Computer_Construction_KG\\output\\first_epoch_entities.json', 'w', encoding='utf-8') as f:\n",
    "    f.write(json.dumps(list(first_epoch_entities)))\n",
    "with open(r'G:\\python_codes\\Principles_of_Computer_Construction_KG\\output\\first_epoch_entities.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(str(first_epoch_entities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 转换标记完之后的数据\n",
    "# 该函数只对first_epoch_trainset_v3、testset_v3、validset_v3进行处理，其他数据集请勿使用\n",
    "def jsonMin2Original(json_min_filename: str, output_filename: str):\n",
    "    with open(json_min_filename, 'r', encoding='utf-8') as json_file:\n",
    "        json_min = json.loads(json_file.read())\n",
    "\n",
    "    output = {\n",
    "            'corpus': [],\n",
    "            'labels': []\n",
    "        }\n",
    "    for item in json_min:\n",
    "        output['corpus'].append(item['text'])\n",
    "        new_item = {'output': []}\n",
    "        if item.get('label'):\n",
    "            for label in item['label']:\n",
    "                new_item['output'].append(\n",
    "                        {\n",
    "                            'type': label['labels'][0],\n",
    "                            \"start\": label[\"start\"],\n",
    "                            \"end\": label[\"end\"],\n",
    "                            \"prob\": None,\n",
    "                            \"span\": label[\"text\"]\n",
    "                        }\n",
    "                    )\n",
    "        output['labels'].append(new_item)\n",
    "\n",
    "    with open(output_filename, 'w', encoding='utf-8') as output_file:\n",
    "        output_file.write(json.dumps(output))\n",
    "\n",
    "\n",
    "jsonMin2Original(r'G:\\python_codes\\Principles_of_Computer_Construction_KG\\output\\first_epoch_trainset_v3.json', r'G:\\python_codes\\Principles_of_Computer_Construction_KG\\output\\first_epoch_trainset_v5.json')\n",
    "jsonMin2Original(r'G:\\python_codes\\Principles_of_Computer_Construction_KG\\output\\validset_v3.json', r'G:\\python_codes\\Principles_of_Computer_Construction_KG\\output\\validset_v5.json')\n",
    "jsonMin2Original(r'G:\\python_codes\\Principles_of_Computer_Construction_KG\\output\\test_set_v3.json', r'G:\\python_codes\\Principles_of_Computer_Construction_KG\\output\\test_set_v5.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_labels_by_BIOES(dataset: list):\n",
    "    new_dataset = []\n",
    "    for i, row in enumerate(dataset):\n",
    "        tmp = ['O'] * len(row['text'])\n",
    "        if row.get('label'):\n",
    "            labels = row['label']\n",
    "            for label in labels:\n",
    "                start, end, label_type = label['start'], label['end'], label['labels'][0]\n",
    "                if end - start == 1:\n",
    "                    tmp[start] = f'S-{label_type}'\n",
    "                else:\n",
    "                    tmp[start] = f'B-{label_type}'\n",
    "                    for idx in range(start + 1, end - 1):\n",
    "                        tmp[idx] = f'I-{label_type}'\n",
    "                    tmp[end - 1] = f'E-{label_type}'\n",
    "        new_dataset.append(\n",
    "            {\n",
    "                'text': row['text'],\n",
    "                'labels': tmp\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return new_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'G:\\python_codes\\Principles_of_Computer_Construction_KG\\output\\first_epoch_trainset_v7.json', 'r', encoding='utf-8')as f:\n",
    "    first_epoch_trainset_v7 = json.loads(f.read())\n",
    "with open(r'G:\\python_codes\\Principles_of_Computer_Construction_KG\\output\\validset_v7.json', 'r', encoding='utf-8')as f:\n",
    "    validset_v7 = json.loads(f.read())\n",
    "with open(r'G:\\python_codes\\Principles_of_Computer_Construction_KG\\output\\test_set_v7.json', 'r', encoding='utf-8')as f:\n",
    "    test_set_v7 = json.loads(f.read())\n",
    "\n",
    "with open(r'G:\\python_codes\\Principles_of_Computer_Construction_KG\\output\\first_epoch_trainset_v8.json', 'w', encoding='utf-8')as f:\n",
    "    first_epoch_trainset_v8 = f.write(json.dumps(process_labels_by_BIOES(first_epoch_trainset_v7)))\n",
    "with open(r'G:\\python_codes\\Principles_of_Computer_Construction_KG\\output\\validset_v8.json', 'w', encoding='utf-8')as f:\n",
    "    validset_v8 = f.write(json.dumps(process_labels_by_BIOES(validset_v7)))\n",
    "with open(r'G:\\python_codes\\Principles_of_Computer_Construction_KG\\output\\test_set_v8.json', 'w', encoding='utf-8')as f:\n",
    "    test_set_v8 = f.write(json.dumps(process_labels_by_BIOES(test_set_v7)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_epoch_trainset_v4 = process_labels_by_BIOES(first_epoch_trainset_v3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'G:\\python_codes\\Principles_of_Computer_Construction_KG\\output\\first_epoch_trainset_v4.json', 'w', encoding='utf-8') as f:\n",
    "    f.write(json.dumps(first_epoch_trainset_v4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'G:\\python_codes\\Principles_of_Computer_Construction_KG\\output\\validset_v3.json', 'r', encoding='utf-8') as f:\n",
    "    validset_v3 = json.loads(f.read())\n",
    "validset_v4 = process_labels_by_BIOES(validset_v3)\n",
    "with open(r'G:\\python_codes\\Principles_of_Computer_Construction_KG\\output\\validset_v4.json', 'w', encoding='utf-8') as f:\n",
    "    f.write(json.dumps(validset_v4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'G:\\python_codes\\Principles_of_Computer_Construction_KG\\output\\first_epoch_trainset_v4.json', 'r', encoding='utf-8') as f:\n",
    "    first_epoch_trainset_v4 = json.loads(f.read())\n",
    "with open(r'G:\\python_codes\\Principles_of_Computer_Construction_KG\\output\\validset_v4.json', 'r', encoding='utf-8') as f:\n",
    "    validset_v4 = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'G:\\python_codes\\Principles_of_Computer_Construction_KG\\output\\test_set_v3.json', 'r', encoding='utf-8') as f:\n",
    "    test_set_v3 = json.loads(f.read())\n",
    "test_set_v4 = process_labels_by_BIOES(test_set_v3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'G:\\python_codes\\Principles_of_Computer_Construction_KG\\output\\test_set_v4.json', 'w', encoding='utf-8') as f:\n",
    "    f.write(json.dumps(test_set_v4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def json2conll(source, target):\n",
    "    with open(source, \"r\", encoding=\"utf-8\") as json_file:\n",
    "        data_list = json.loads(json_file.read())\n",
    "\n",
    "    conll_format = \"\"\n",
    "\n",
    "    for data in data_list:\n",
    "        text = data[\"text\"]\n",
    "        labels = data[\"labels\"]\n",
    "\n",
    "        for char, label in zip(text, labels):\n",
    "            conll_format += f\"{char}\\t{label}\\n\"\n",
    "\n",
    "        conll_format += \"\\n\"  # Add a newline to separate sentences\n",
    "\n",
    "    with open(target, 'w', encoding='utf-8') as conll:\n",
    "        conll.write(conll_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json2conll(r'G:\\python_codes\\Principles_of_Computer_Construction_KG\\output\\first_epoch_trainset_v4.json', r'G:\\python_codes\\Principles_of_Computer_Construction_KG\\output\\first_epoch_trainset_v4.txt')\n",
    "json2conll(r'G:\\python_codes\\Principles_of_Computer_Construction_KG\\output\\validset_v4.json', r'G:\\python_codes\\Principles_of_Computer_Construction_KG\\output\\validset_v4.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json2conll(r'G:\\python_codes\\Principles_of_Computer_Construction_KG\\output\\test_set_v4.json', r'G:\\python_codes\\Principles_of_Computer_Construction_KG\\output\\test_set_v4.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "json2conll(r'G:\\python_codes\\Principles_of_Computer_Construction_KG\\output\\first_epoch_trainset_v8.json', r'G:\\python_codes\\Principles_of_Computer_Construction_KG\\output\\first_epoch_trainset_v8.txt')\n",
    "json2conll(r'G:\\python_codes\\Principles_of_Computer_Construction_KG\\output\\validset_v8.json', r'G:\\python_codes\\Principles_of_Computer_Construction_KG\\output\\validset_v8.txt')\n",
    "json2conll(r'G:\\python_codes\\Principles_of_Computer_Construction_KG\\output\\test_set_v8.json', r'G:\\python_codes\\Principles_of_Computer_Construction_KG\\output\\test_set_v8.txt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
